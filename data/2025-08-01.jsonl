{"id": "2507.22954", "pdf": "https://arxiv.org/pdf/2507.22954", "abs": "https://arxiv.org/abs/2507.22954", "authors": ["Ridvan Yesiloglu", "Wei Peng", "Md Tauhidul Islam", "Ehsan Adeli"], "title": "Neural Autoregressive Modeling of Brain Aging", "categories": ["cs.LG", "eess.IV", "q-bio.NC"], "comment": "Accepted at Deep Generative Models Workshop @ MICCAI 2025", "summary": "Brain aging synthesis is a critical task with broad applications in clinical\nand computational neuroscience. The ability to predict the future structural\nevolution of a subject's brain from an earlier MRI scan provides valuable\ninsights into aging trajectories. Yet, the high-dimensionality of data, subtle\nchanges of structure across ages, and subject-specific patterns constitute\nchallenges in the synthesis of the aging brain. To overcome these challenges,\nwe propose NeuroAR, a novel brain aging simulation model based on generative\nautoregressive transformers. NeuroAR synthesizes the aging brain by\nautoregressively estimating the discrete token maps of a future scan from a\nconvenient space of concatenated token embeddings of a previous and future\nscan. To guide the generation, it concatenates into each scale the subject's\nprevious scan, and uses its acquisition age and the target age at each block\nvia cross-attention. We evaluate our approach on both the elderly population\nand adolescent subjects, demonstrating superior performance over\nstate-of-the-art generative models, including latent diffusion models (LDM) and\ngenerative adversarial networks, in terms of image fidelity. Furthermore, we\nemploy a pre-trained age predictor to further validate the consistency and\nrealism of the synthesized images with respect to expected aging patterns.\nNeuroAR significantly outperforms key models, including LDM, demonstrating its\nability to model subject-specific brain aging trajectories with high fidelity."}
{"id": "2507.22956", "pdf": "https://arxiv.org/pdf/2507.22956", "abs": "https://arxiv.org/abs/2507.22956", "authors": ["Dong Hyun Roh", "Rajesh Kumar", "An Ngo"], "title": "LLM-Assisted Cheating Detection in Korean Language via Keystrokes", "categories": ["cs.LG", "cs.HC", "K.3.1"], "comment": "This paper has 11 pages, 6 figures, 2 tables, and has been accepted\n  for publication at IEEE-IJCB 2025", "summary": "This paper presents a keystroke-based framework for detecting LLM-assisted\ncheating in Korean, addressing key gaps in prior research regarding language\ncoverage, cognitive context, and the granularity of LLM involvement. Our\nproposed dataset includes 69 participants who completed writing tasks under\nthree conditions: Bona fide writing, paraphrasing ChatGPT responses, and\ntranscribing ChatGPT responses. Each task spans six cognitive processes defined\nin Bloom's Taxonomy (remember, understand, apply, analyze, evaluate, and\ncreate). We extract interpretable temporal and rhythmic features and evaluate\nmultiple classifiers under both Cognition-Aware and Cognition-Unaware settings.\nTemporal features perform well under Cognition-Aware evaluation scenarios,\nwhile rhythmic features generalize better under cross-cognition scenarios.\nMoreover, detecting bona fide and transcribed responses was easier than\nparaphrased ones for both the proposed models and human evaluators, with the\nmodels significantly outperforming the humans. Our findings affirm that\nkeystroke dynamics facilitate reliable detection of LLM-assisted writing across\nvarying cognitive demands and writing strategies, including paraphrasing and\ntranscribing LLM-generated responses."}
{"id": "2507.22959", "pdf": "https://arxiv.org/pdf/2507.22959", "abs": "https://arxiv.org/abs/2507.22959", "authors": ["Salah A. Faroughi", "Farinaz Mostajeran", "Amin Hamed Mashhadzadeh", "Shirko Faroughi"], "title": "Scientific Machine Learning with Kolmogorov-Arnold Networks", "categories": ["cs.LG", "cs.CE", "math-ph", "math.MP"], "comment": null, "summary": "The field of scientific machine learning, which originally utilized\nmultilayer perceptrons (MLPs), is increasingly adopting Kolmogorov-Arnold\nNetworks (KANs) for data encoding. This shift is driven by the limitations of\nMLPs, including poor interpretability, fixed activation functions, and\ndifficulty capturing localized or high-frequency features. KANs address these\nissues with enhanced interpretability and flexibility, enabling more efficient\nmodeling of complex nonlinear interactions and effectively overcoming the\nconstraints associated with conventional MLP architectures. This review\ncategorizes recent progress in KAN-based models across three distinct\nperspectives: (i) data-driven learning, (ii) physics-informed modeling, and\n(iii) deep operator learning. Each perspective is examined through the lens of\narchitectural design, training strategies, application efficacy, and\ncomparative evaluation against MLP-based counterparts. By benchmarking KANs\nagainst MLPs, we highlight consistent improvements in accuracy, convergence,\nand spectral representation, clarifying KANs' advantages in capturing complex\ndynamics while learning more effectively. Finally, this review identifies\ncritical challenges and open research questions in KAN development,\nparticularly regarding computational efficiency, theoretical guarantees,\nhyperparameter tuning, and algorithm complexity. We also outline future\nresearch directions aimed at improving the robustness, scalability, and\nphysical consistency of KAN-based frameworks."}
{"id": "2507.22962", "pdf": "https://arxiv.org/pdf/2507.22962", "abs": "https://arxiv.org/abs/2507.22962", "authors": ["Boyuan Zheng", "Victor W. Chu"], "title": "Multi-Hazard Early Warning Systems for Agriculture with Featural-Temporal Explanations", "categories": ["cs.LG"], "comment": "Pre-print v0.8 2025-07-30", "summary": "Climate extremes present escalating risks to agriculture intensifying the\nneed for reliable multi-hazard early warning systems (EWS). The situation is\nevolving due to climate change and hence such systems should have the\nintelligent to continue to learn from recent climate behaviours. However,\ntraditional single-hazard forecasting methods fall short in capturing complex\ninteractions among concurrent climatic events. To address this deficiency, in\nthis paper, we combine sequential deep learning models and advanced Explainable\nArtificial Intelligence (XAI) techniques to introduce a multi-hazard\nforecasting framework for agriculture. In our experiments, we utilize\nmeteorological data from four prominent agricultural regions in the United\nStates (between 2010 and 2023) to validate the predictive accuracy of our\nframework on multiple severe event types, which are extreme cold, floods,\nfrost, hail, heatwaves, and heavy rainfall, with tailored models for each area.\nThe framework uniquely integrates attention mechanisms with TimeSHAP (a\nrecurrent XAI explainer for time series) to provide comprehensive temporal\nexplanations revealing not only which climatic features are influential but\nprecisely when their impacts occur. Our results demonstrate strong predictive\naccuracy, particularly with the BiLSTM architecture, and highlight the system's\ncapacity to inform nuanced, proactive risk management strategies. This research\nsignificantly advances the explainability and applicability of multi-hazard\nEWS, fostering interdisciplinary trust and effective decision-making process\nfor climate risk management in the agricultural industry."}
{"id": "2507.22963", "pdf": "https://arxiv.org/pdf/2507.22963", "abs": "https://arxiv.org/abs/2507.22963", "authors": ["Abdelrhman Gaber", "Hassan Abd-Eltawab", "John Elgallab", "Youssif Abuzied", "Dineo Mpanya", "Turgay Celik", "Swarun Kumar", "Tamer ElBatt"], "title": "FedCVD++: Communication-Efficient Federated Learning for Cardiovascular Risk Prediction with Parametric and Non-Parametric Model Optimization", "categories": ["cs.LG", "q-bio.OT"], "comment": null, "summary": "Cardiovascular diseases (CVD) cause over 17 million deaths annually\nworldwide, highlighting the urgent need for privacy-preserving predictive\nsystems. We introduce FedCVD++, an enhanced federated learning (FL) framework\nthat integrates both parametric models (logistic regression, SVM, neural\nnetworks) and non-parametric models (Random Forest, XGBoost) for coronary heart\ndisease risk prediction. To address key FL challenges, we propose: (1)\ntree-subset sampling that reduces Random Forest communication overhead by 70%,\n(2) XGBoost-based feature extraction enabling lightweight federated ensembles,\nand (3) federated SMOTE synchronization for resolving cross-institutional class\nimbalance.\n  Evaluated on the Framingham dataset (4,238 records), FedCVD++ achieves\nstate-of-the-art results: federated XGBoost (F1 = 0.80) surpasses its\ncentralized counterpart (F1 = 0.78), and federated Random Forest (F1 = 0.81)\nmatches non-federated performance. Additionally, our communication-efficient\nstrategies reduce bandwidth consumption by 3.2X while preserving 95% accuracy.\n  Compared to existing FL frameworks, FedCVD++ delivers up to 15% higher\nF1-scores and superior scalability for multi-institutional deployment. This\nwork represents the first practical integration of non-parametric models into\nfederated healthcare systems, providing a privacy-preserving solution validated\nunder real-world clinical constraints."}
{"id": "2507.23000", "pdf": "https://arxiv.org/pdf/2507.23000", "abs": "https://arxiv.org/abs/2507.23000", "authors": ["Shengao Yi", "Xiaojiang Li", "Wei Tu", "Tianhong Zhao"], "title": "Planning for Cooler Cities: A Multimodal AI Framework for Predicting and Mitigating Urban Heat Stress through Urban Landscape Transformation", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "As extreme heat events intensify due to climate change and urbanization,\ncities face increasing challenges in mitigating outdoor heat stress. While\ntraditional physical models such as SOLWEIG and ENVI-met provide detailed\nassessments of human-perceived heat exposure, their computational demands limit\nscalability for city-wide planning. In this study, we propose GSM-UTCI, a\nmultimodal deep learning framework designed to predict daytime average\nUniversal Thermal Climate Index (UTCI) at 1-meter hyperlocal resolution. The\nmodel fuses surface morphology (nDSM), high-resolution land cover data, and\nhourly meteorological conditions using a feature-wise linear modulation (FiLM)\narchitecture that dynamically conditions spatial features on atmospheric\ncontext. Trained on SOLWEIG-derived UTCI maps, GSM-UTCI achieves near-physical\naccuracy, with an R2 of 0.9151 and a mean absolute error (MAE) of 0.41{\\deg}C,\nwhile reducing inference time from hours to under five minutes for an entire\ncity. To demonstrate its planning relevance, we apply GSM-UTCI to simulate\nsystematic landscape transformation scenarios in Philadelphia, replacing bare\nearth, grass, and impervious surfaces with tree canopy. Results show spatially\nheterogeneous but consistently strong cooling effects, with impervious-to-tree\nconversion producing the highest aggregated benefit (-4.18{\\deg}C average\nchange in UTCI across 270.7 km2). Tract-level bivariate analysis further\nreveals strong alignment between thermal reduction potential and land cover\nproportions. These findings underscore the utility of GSM-UTCI as a scalable,\nfine-grained decision support tool for urban climate adaptation, enabling\nscenario-based evaluation of greening strategies across diverse urban\nenvironments."}
{"id": "2507.23009", "pdf": "https://arxiv.org/pdf/2507.23009", "abs": "https://arxiv.org/abs/2507.23009", "authors": ["Tom Sühr", "Florian E. Dorner", "Olawale Salaudeen", "Augustin Kelava", "Samira Samadi"], "title": "Stop Evaluating AI with Human Tests, Develop Principled, AI-specific Tests instead", "categories": ["cs.LG", "cs.AI", "91E45", "I.2"], "comment": null, "summary": "Large Language Models (LLMs) have achieved remarkable results on a range of\nstandardized tests originally designed to assess human cognitive and\npsychological traits, such as intelligence and personality. While these results\nare often interpreted as strong evidence of human-like characteristics in LLMs,\nthis paper argues that such interpretations constitute an ontological error.\nHuman psychological and educational tests are theory-driven measurement\ninstruments, calibrated to a specific human population. Applying these tests to\nnon-human subjects without empirical validation, risks mischaracterizing what\nis being measured. Furthermore, a growing trend frames AI performance on\nbenchmarks as measurements of traits such as ``intelligence'', despite known\nissues with validity, data contamination, cultural bias and sensitivity to\nsuperficial prompt changes. We argue that interpreting benchmark performance as\nmeasurements of human-like traits, lacks sufficient theoretical and empirical\njustification. This leads to our position: Stop Evaluating AI with Human Tests,\nDevelop Principled, AI-specific Tests instead. We call for the development of\nprincipled, AI-specific evaluation frameworks tailored to AI systems. Such\nframeworks might build on existing frameworks for constructing and validating\npsychometrics tests, or could be created entirely from scratch to fit the\nunique context of AI."}
{"id": "2507.23010", "pdf": "https://arxiv.org/pdf/2507.23010", "abs": "https://arxiv.org/abs/2507.23010", "authors": ["Siwoo Park"], "title": "Investigating the Invertibility of Multimodal Latent Spaces: Limitations of Optimization-Based Methods", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.SD", "eess.AS"], "comment": null, "summary": "This paper investigates the inverse capabilities and broader utility of\nmultimodal latent spaces within task-specific AI (Artificial Intelligence)\nmodels. While these models excel at their designed forward tasks (e.g.,\ntext-to-image generation, audio-to-text transcription), their potential for\ninverse mappings remains largely unexplored. We propose an optimization-based\nframework to infer input characteristics from desired outputs, applying it\nbidirectionally across Text-Image (BLIP, Flux.1-dev) and Text-Audio\n(Whisper-Large-V3, Chatterbox-TTS) modalities.\n  Our central hypothesis posits that while optimization can guide models\ntowards inverse tasks, their multimodal latent spaces will not consistently\nsupport semantically meaningful and perceptually coherent inverse mappings.\nExperimental results consistently validate this hypothesis. We demonstrate that\nwhile optimization can force models to produce outputs that align textually\nwith targets (e.g., a text-to-image model generating an image that an image\ncaptioning model describes correctly, or an ASR model transcribing optimized\naudio accurately), the perceptual quality of these inversions is chaotic and\nincoherent. Furthermore, when attempting to infer the original semantic input\nfrom generative models, the reconstructed latent space embeddings frequently\nlack semantic interpretability, aligning with nonsensical vocabulary tokens.\n  These findings highlight a critical limitation. multimodal latent spaces,\nprimarily optimized for specific forward tasks, do not inherently possess the\nstructure required for robust and interpretable inverse mappings. Our work\nunderscores the need for further research into developing truly semantically\nrich and invertible multimodal latent spaces."}
{"id": "2507.23035", "pdf": "https://arxiv.org/pdf/2507.23035", "abs": "https://arxiv.org/abs/2507.23035", "authors": ["Xueying Wu", "Baijun Zhou", "Zhihui Gao", "Yuzhe Fu", "Qilin Zheng", "Yintao He", "Hai Li"], "title": "KLLM: Fast LLM Inference with K-Means Quantization", "categories": ["cs.LG", "cs.AR"], "comment": null, "summary": "Large language model (LLM) inference poses significant challenges due to its\nintensive memory and computation demands. Weight and activation quantization\n(WAQ) offers a promising solution by reducing both memory footprint and\narithmetic complexity. However, two key challenges remain in the existing WAQ\ndesigns. (1) Traditional WAQ designs rely on uniform integer-based quantization\nfor hardware efficiency, but this often results in significant accuracy\ndegradation at low precision. K-Means-based quantization, a non-uniform\nquantization technique, achieves higher accuracy by matching the Gaussian-like\ndistributions of weights and activations in LLMs. However, its non-uniform\nnature prevents direct execution on low-precision compute units, requiring\ndequantization and floating-point matrix multiplications (MatMuls) during\ninference. (2) Activation outliers further hinder effective low-precision WAQ.\nOffline thresholding methods for outlier detection can lead to significant\nmodel performance degradation, while existing online detection techniques\nintroduce substantial runtime overhead.\n  To address the aforementioned challenges and fully unleash the potential of\nWAQ with K-Means quantization for LLM inference, in this paper, we propose\nKLLM, a hardware-software co-design framework. KLLM features an index-based\ncomputation scheme for efficient execution of MatMuls and nonlinear operations\non K-Means-quantized data, which avoids most of the dequantization and\nfull-precision computations. Moreover, KLLM incorporates a novel outlier\ndetection engine, Orizuru, that efficiently identifies the top-$k$ largest and\nsmallest elements in the activation data stream during online inference.\n  Extensive experiments show that, on average, KLLM achieves speedups of 9.67x,\n7.03x and energy efficiency improvements of 229.50x, 150.21x compared to the\nA100 GPU and Atom, respectively."}
{"id": "2507.23037", "pdf": "https://arxiv.org/pdf/2507.23037", "abs": "https://arxiv.org/abs/2507.23037", "authors": ["Aurélie Leribaux", "Rafael Oyamada", "Johannes De Smedt", "Zahra Dasht Bozorgi", "Artem Polyvyanyy", "Jochen De Weerdt"], "title": "Linking Actor Behavior to Process Performance Over Time", "categories": ["cs.LG"], "comment": "Accepted for presentation at the 5th Workshop on Change, Drift, and\n  Dynamics of Organizational Processes (ProDy), BPM 2025", "summary": "Understanding how actor behavior influences process outcomes is a critical\naspect of process mining. Traditional approaches often use aggregate and static\nprocess data, overlooking the temporal and causal dynamics that arise from\nindividual actor behavior. This limits the ability to accurately capture the\ncomplexity of real-world processes, where individual actor behavior and\ninteractions between actors significantly shape performance. In this work, we\naddress this gap by integrating actor behavior analysis with Granger causality\nto identify correlating links in time series data. We apply this approach to\nrealworld event logs, constructing time series for actor interactions, i.e.\ncontinuation, interruption, and handovers, and process outcomes. Using Group\nLasso for lag selection, we identify a small but consistently influential set\nof lags that capture the majority of causal influence, revealing that actor\nbehavior has direct and measurable impacts on process performance, particularly\nthroughput time. These findings demonstrate the potential of actor-centric,\ntime series-based methods for uncovering the temporal dependencies that drive\nprocess outcomes, offering a more nuanced understanding of how individual\nbehaviors impact overall process efficiency."}
{"id": "2507.23043", "pdf": "https://arxiv.org/pdf/2507.23043", "abs": "https://arxiv.org/abs/2507.23043", "authors": ["Junyi Fan", "Li Sun", "Shuheng Chen", "Yong Si", "Minoo Ahmadi", "Greg Placencia", "Elham Pishgar", "Kamiar Alaei", "Maryam Pishgar"], "title": "Prediction of Significant Creatinine Elevation in First ICU Stays with Vancomycin Use: A retrospective study through Catboost", "categories": ["cs.LG"], "comment": null, "summary": "Background: Vancomycin, a key antibiotic for severe Gram-positive infections\nin ICUs, poses a high nephrotoxicity risk. Early prediction of kidney injury in\ncritically ill patients is challenging. This study aimed to develop a machine\nlearning model to predict vancomycin-related creatinine elevation using routine\nICU data.\n  Methods: We analyzed 10,288 ICU patients (aged 18-80) from the MIMIC-IV\ndatabase who received vancomycin. Kidney injury was defined by KDIGO criteria\n(creatinine rise >=0.3 mg/dL within 48h or >=50% within 7d). Features were\nselected via SelectKBest (top 30) and Random Forest ranking (final 15). Six\nalgorithms were tested with 5-fold cross-validation. Interpretability was\nevaluated using SHAP, Accumulated Local Effects (ALE), and Bayesian posterior\nsampling.\n  Results: Of 10,288 patients, 2,903 (28.2%) developed creatinine elevation.\nCatBoost performed best (AUROC 0.818 [95% CI: 0.801-0.834], sensitivity 0.800,\nspecificity 0.681, negative predictive value 0.900). Key predictors were\nphosphate, total bilirubin, magnesium, Charlson index, and APSIII. SHAP\nconfirmed phosphate as a major risk factor. ALE showed dose-response patterns.\nBayesian analysis estimated mean risk 60.5% (95% credible interval: 16.8-89.4%)\nin high-risk cases.\n  Conclusions: This machine learning model predicts vancomycin-associated\ncreatinine elevation from routine ICU data with strong accuracy and\ninterpretability, enabling early risk detection and supporting timely\ninterventions in critical care."}
{"id": "2507.23073", "pdf": "https://arxiv.org/pdf/2507.23073", "abs": "https://arxiv.org/abs/2507.23073", "authors": ["Annalisa Barbara", "Joseph Lazzaro", "Ciara Pike-Burke"], "title": "Locally Differentially Private Thresholding Bandits", "categories": ["cs.LG"], "comment": "18th European Workshop on Reinforcement Learning (EWRL 2025)", "summary": "This work investigates the impact of ensuring local differential privacy in\nthe thresholding bandit problem. We consider both the fixed budget and fixed\nconfidence settings. We propose methods that utilize private responses,\nobtained through a Bernoulli-based differentially private mechanism, to\nidentify arms with expected rewards exceeding a predefined threshold. We show\nthat this procedure provides strong privacy guarantees and derive theoretical\nperformance bounds on the proposed algorithms. Additionally, we present general\nlower bounds that characterize the additional loss incurred by any\ndifferentially private mechanism, and show that the presented algorithms match\nthese lower bounds up to poly-logarithmic factors. Our results provide valuable\ninsights into privacy-preserving decision-making frameworks in bandit problems."}
{"id": "2507.23077", "pdf": "https://arxiv.org/pdf/2507.23077", "abs": "https://arxiv.org/abs/2507.23077", "authors": ["Agnese Marcato", "Aleksandra Pachalieva", "Ryley G. Hill", "Kai Gao", "Xiaoyu Wang", "Esteban Rougier", "Zhou Lei", "Vinamra Agrawal", "Janel Chua", "Qinjun Kang", "Jeffrey D. Hyman", "Abigail Hunter", "Nathan DeBardeleben", "Earl Lawrence", "Hari Viswanathan", "Daniel O'Malley", "Javier E. Santos"], "title": "A Foundation Model for Material Fracture Prediction", "categories": ["cs.LG", "cond-mat.mtrl-sci", "physics.geo-ph"], "comment": null, "summary": "Accurately predicting when and how materials fail is critical to designing\nsafe, reliable structures, mechanical systems, and engineered components that\noperate under stress. Yet, fracture behavior remains difficult to model across\nthe diversity of materials, geometries, and loading conditions in real-world\napplications. While machine learning (ML) methods show promise, most models are\ntrained on narrow datasets, lack robustness, and struggle to generalize.\nMeanwhile, physics-based simulators offer high-fidelity predictions but are\nfragmented across specialized methods and require substantial high-performance\ncomputing resources to explore the input space. To address these limitations,\nwe present a data-driven foundation model for fracture prediction, a\ntransformer-based architecture that operates across simulators, a wide range of\nmaterials (including plastic-bonded explosives, steel, aluminum, shale, and\ntungsten), and diverse loading conditions. The model supports both structured\nand unstructured meshes, combining them with large language model embeddings of\ntextual input decks specifying material properties, boundary conditions, and\nsolver settings. This multimodal input design enables flexible adaptation\nacross simulation scenarios without changes to the model architecture. The\ntrained model can be fine-tuned with minimal data on diverse downstream tasks,\nincluding time-to-failure estimation, modeling fracture evolution, and adapting\nto combined finite-discrete element method simulations. It also generalizes to\nunseen materials such as titanium and concrete, requiring as few as a single\nsample, dramatically reducing data needs compared to standard ML. Our results\nshow that fracture prediction can be unified under a single model architecture,\noffering a scalable, extensible alternative to simulator-specific workflows."}
{"id": "2507.23093", "pdf": "https://arxiv.org/pdf/2507.23093", "abs": "https://arxiv.org/abs/2507.23093", "authors": ["Ghazal Sobhani", "Md. Monzurul Amin Ifath", "Tushar Sharma", "Israat Haque"], "title": "On the Sustainability of AI Inferences in the Edge", "categories": ["cs.LG", "cs.AI", "cs.PF"], "comment": "14 pages, 8 figures, 6 tables, in preparation for journal submission", "summary": "The proliferation of the Internet of Things (IoT) and its cutting-edge\nAI-enabled applications (e.g., autonomous vehicles and smart industries)\ncombine two paradigms: data-driven systems and their deployment on the edge.\nUsually, edge devices perform inferences to support latency-critical\napplications. In addition to the performance of these resource-constrained edge\ndevices, their energy usage is a critical factor in adopting and deploying edge\napplications. Examples of such devices include Raspberry Pi (RPi), Intel Neural\nCompute Stick (INCS), NVIDIA Jetson nano (NJn), and Google Coral USB (GCU).\nDespite their adoption in edge deployment for AI inferences, there is no study\non their performance and energy usage for informed decision-making on the\ndevice and model selection to meet the demands of applications. This study\nfills the gap by rigorously characterizing the performance of traditional,\nneural networks, and large language models on the above-edge devices.\nSpecifically, we analyze trade-offs among model F1 score, inference time,\ninference power, and memory usage. Hardware and framework optimization, along\nwith external parameter tuning of AI models, can balance between model\nperformance and resource usage to realize practical edge AI deployments."}
{"id": "2507.23111", "pdf": "https://arxiv.org/pdf/2507.23111", "abs": "https://arxiv.org/abs/2507.23111", "authors": ["Richard Williams", "Eric Nalisnick", "Andrew Holbrook"], "title": "Scalable Generative Modeling of Weighted Graphs", "categories": ["cs.LG"], "comment": "25 pages, 5 figures, included appendix. code at\n  https://github.com/rlwilliams34/BiGG-E", "summary": "Weighted graphs are ubiquitous throughout biology, chemistry, and the social\nsciences, motivating the development of generative models for abstract weighted\ngraph data using deep neural networks. However, most current deep generative\nmodels are either designed for unweighted graphs and are not easily extended to\nweighted topologies or incorporate edge weights without consideration of a\njoint distribution with topology. Furthermore, learning a distribution over\nweighted graphs must account for complex nonlocal dependencies between both the\nedges of the graph and corresponding weights of each edge. We develop an\nautoregressive model BiGG-E, a nontrivial extension of the BiGG model, that\nlearns a joint distribution over weighted graphs while still exploiting\nsparsity to generate a weighted graph with $n$ nodes and $m$ edges in $O((n +\nm)\\log n)$ time. Simulation studies and experiments on a variety of benchmark\ndatasets demonstrate that BiGG-E best captures distributions over weighted\ngraphs while remaining scalable and computationally efficient."}
{"id": "2507.23115", "pdf": "https://arxiv.org/pdf/2507.23115", "abs": "https://arxiv.org/abs/2507.23115", "authors": ["David J Goetze", "Dahlia J Felten", "Jeannie R Albrecht", "Rohit Bhattacharya"], "title": "FLOSS: Federated Learning with Opt-Out and Straggler Support", "categories": ["cs.LG", "cs.AI"], "comment": "5 pages", "summary": "Previous work on data privacy in federated learning systems focuses on\nprivacy-preserving operations for data from users who have agreed to share\ntheir data for training. However, modern data privacy agreements also empower\nusers to use the system while opting out of sharing their data as desired. When\ncombined with stragglers that arise from heterogeneous device capabilities, the\nresult is missing data from a variety of sources that introduces bias and\ndegrades model performance. In this paper, we present FLOSS, a system that\nmitigates the impacts of such missing data on federated learning in the\npresence of stragglers and user opt-out, and empirically demonstrate its\nperformance in simulations."}
{"id": "2507.23128", "pdf": "https://arxiv.org/pdf/2507.23128", "abs": "https://arxiv.org/abs/2507.23128", "authors": ["Anaïs Baranger", "Lucas Maison"], "title": "Evaluating and Improving the Robustness of Speech Command Recognition Models to Noise and Distribution Shifts", "categories": ["cs.LG"], "comment": "Submitted to ICASSP 2026", "summary": "Although prior work in computer vision has shown strong correlations between\nin-distribution (ID) and out-of-distribution (OOD) accuracies, such\nrelationships remain underexplored in audio-based models. In this study, we\ninvestigate how training conditions and input features affect the robustness\nand generalization abilities of spoken keyword classifiers under OOD\nconditions. We benchmark several neural architectures across a variety of\nevaluation sets. To quantify the impact of noise on generalization, we make use\nof two metrics: Fairness (F), which measures overall accuracy gains compared to\na baseline model, and Robustness (R), which assesses the convergence between ID\nand OOD performance. Our results suggest that noise-aware training improves\nrobustness in some configurations. These findings shed new light on the\nbenefits and limitations of noise-based augmentation for generalization in\nspeech models."}
{"id": "2507.23136", "pdf": "https://arxiv.org/pdf/2507.23136", "abs": "https://arxiv.org/abs/2507.23136", "authors": ["Erin George", "Deanna Needell", "Berk Ustun"], "title": "Observational Multiplicity", "categories": ["cs.LG"], "comment": null, "summary": "Many prediction tasks can admit multiple models that can perform almost\nequally well. This phenomenon can can undermine interpretability and safety\nwhen competing models assign conflicting predictions to individuals. In this\nwork, we study how arbitrariness can arise in probabilistic classification\ntasks as a result of an effect that we call \\emph{observational multiplicity}.\nWe discuss how this effect arises in a broad class of practical applications\nwhere we learn a classifier to predict probabilities $p_i \\in [0,1]$ but are\ngiven a dataset of observations $y_i \\in \\{0,1\\}$. We propose to evaluate the\narbitrariness of individual probability predictions through the lens of\n\\emph{regret}. We introduce a measure of regret for probabilistic\nclassification tasks, which measures how the predictions of a model could\nchange as a result of different training labels change. We present a\ngeneral-purpose method to estimate the regret in a probabilistic classification\ntask. We use our measure to show that regret is higher for certain groups in\nthe dataset and discuss potential applications of regret. We demonstrate how\nestimating regret promote safety in real-world applications by abstention and\ndata collection."}
{"id": "2507.23141", "pdf": "https://arxiv.org/pdf/2507.23141", "abs": "https://arxiv.org/abs/2507.23141", "authors": ["Xiangshu Gong", "Zhiqiang Xie", "Xiaowei Jin", "Chen Wang", "Yanling Qu", "Wangmeng Zuo", "Hui Li"], "title": "AI paradigm for solving differential equations: first-principles data generation and scale-dilation operator AI solver", "categories": ["cs.LG", "physics.comp-ph"], "comment": null, "summary": "Many problems are governed by differential equations (DEs). Artificial\nintelligence (AI) is a new path for solving DEs. However, data is very scarce\nand existing AI solvers struggle with approximation of high frequency\ncomponents (AHFC). We propose an AI paradigm for solving diverse DEs, including\nDE-ruled first-principles data generation methodology and scale-dilation\noperator (SDO) AI solver. Using either prior knowledge or random fields, we\ngenerate solutions and then substitute them into the DEs to derive the sources\nand initial/boundary conditions through balancing DEs, thus producing\narbitrarily vast amount of, first-principles-consistent training datasets at\nextremely low computational cost. We introduce a reversible SDO that leverages\nthe Fourier transform of the multiscale solutions to fix AHFC, and design a\nspatiotemporally coupled, attention-based Transformer AI solver of DEs with\nSDO. An upper bound on the Hessian condition number of the loss function is\nproven to be proportional to the squared 2-norm of the solution gradient,\nrevealing that SDO yields a smoother loss landscape, consequently fixing AHFC\nwith efficient training. Extensive tests on diverse DEs demonstrate that our AI\nparadigm achieves consistently superior accuracy over state-of-the-art methods.\nThis work makes AI solver of DEs to be truly usable in broad nature and\nengineering fields."}
{"id": "2507.23154", "pdf": "https://arxiv.org/pdf/2507.23154", "abs": "https://arxiv.org/abs/2507.23154", "authors": ["Sofiane Bouaziz", "Adel Hafiane", "Raphael Canals", "Rachid Nedjai"], "title": "FuseTen: A Generative Model for Daily 10 m Land Surface Temperature Estimation from Spatio-Temporal Satellite Observations", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "Accepted in the 2025 International Conference on Machine Intelligence\n  for GeoAnalytics and Remote Sensing (MIGARS)", "summary": "Urban heatwaves, droughts, and land degradation are pressing and growing\nchallenges in the context of climate change. A valuable approach to studying\nthem requires accurate spatio-temporal information on land surface conditions.\nOne of the most important variables for assessing and understanding these\nphenomena is Land Surface Temperature (LST), which is derived from satellites\nand provides essential information about the thermal state of the Earth's\nsurface. However, satellite platforms inherently face a trade-off between\nspatial and temporal resolutions. To bridge this gap, we propose FuseTen, a\nnovel generative framework that produces daily LST observations at a fine 10 m\nspatial resolution by fusing spatio-temporal observations derived from\nSentinel-2, Landsat 8, and Terra MODIS. FuseTen employs a generative\narchitecture trained using an averaging-based supervision strategy grounded in\nphysical principles. It incorporates attention and normalization modules within\nthe fusion process and uses a PatchGAN discriminator to enforce realism.\nExperiments across multiple dates show that FuseTen outperforms linear\nbaselines, with an average 32.06% improvement in quantitative metrics and\n31.42% in visual fidelity. To the best of our knowledge, this is the first\nnon-linear method to generate daily LST estimates at such fine spatial\nresolution."}
{"id": "2507.23170", "pdf": "https://arxiv.org/pdf/2507.23170", "abs": "https://arxiv.org/abs/2507.23170", "authors": ["Jinan Zhou", "Rajat Ghosh", "Vaishnavi Bhargava", "Debojyoti Dutta", "Aryan Singhal"], "title": "BAR Conjecture: the Feasibility of Inference Budget-Constrained LLM Services with Authenticity and Reasoning", "categories": ["cs.LG"], "comment": null, "summary": "When designing LLM services, practitioners care about three key properties:\ninference-time budget, factual authenticity, and reasoning capacity. However,\nour analysis shows that no model can simultaneously optimize for all three. We\nformally prove this trade-off and propose a principled framework named The BAR\nTheorem for LLM-application design."}
{"id": "2507.23186", "pdf": "https://arxiv.org/pdf/2507.23186", "abs": "https://arxiv.org/abs/2507.23186", "authors": ["Peter Sharpe"], "title": "NaN-Propagation: A Novel Method for Sparsity Detection in Black-Box Computational Functions", "categories": ["cs.LG", "cs.PL"], "comment": null, "summary": "Sparsity detection in black-box functions enables significant computational\nspeedups in gradient-based optimization through Jacobian compression, but\nexisting finite-difference methods suffer from false negatives due to\ncoincidental zero gradients. These false negatives can silently corrupt\ngradient calculations, leading to difficult-to-diagnose errors. We introduce\nNaN-propagation, which exploits the universal contamination property of IEEE\n754 Not-a-Number floating-point values to trace input-output dependencies\nthrough floating-point numerical computations. By systematically contaminating\ninputs with NaN and observing which outputs become NaN, the method reconstructs\nconservative sparsity patterns that eliminate false negatives. We demonstrate\nthe approach on an aerospace wing weight model, achieving a 1.52x speedup while\ndetecting dozens of dependencies missed by conventional methods -- a\nsignificant improvement since gradient computation is the bottleneck in many\noptimization workflows. The technique leverages IEEE 754 compliance to work\nacross programming languages and math libraries without modifying existing\nblack-box codes. Advanced strategies including NaN payload encoding enable\nfaster-than-linear time complexity, improving upon existing black-box sparsity\ndetection methods. Practical algorithms are also proposed to mitigate\nchallenges from branching code execution common in engineering applications."}
{"id": "2507.23217", "pdf": "https://arxiv.org/pdf/2507.23217", "abs": "https://arxiv.org/abs/2507.23217", "authors": ["Hyeon Seong Jeong", "Sangwoo Jo", "Byeong Hyun Yoon", "Yoonseok Heo", "Haedong Jeong", "Taehoon Kim"], "title": "Zero-Shot Document Understanding using Pseudo Table of Contents-Guided Retrieval-Augmented Generation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Understanding complex multimodal documents remains challenging due to their\nstructural inconsistencies and limited training data availability. We introduce\n\\textit{DocsRay}, a training-free document understanding system that integrates\npseudo Table of Contents (TOC) generation with hierarchical Retrieval-Augmented\nGeneration (RAG). Our approach leverages multimodal Large Language Models'\n(LLMs) native capabilities to seamlessly process documents containing diverse\nelements such as text, images, charts, and tables without requiring specialized\nmodels or additional training. DocsRay's framework synergistically combines\nthree key techniques: (1) a semantic structuring module using prompt-based LLM\ninteractions to generate a hierarchical pseudo-TOC, (2) zero-shot multimodal\nanalysis that converts diverse document elements into unified, text-centric\nrepresentations using the inherent capabilities of multimodal LLMs, and (3) an\nefficient two-stage hierarchical retrieval system that reduces retrieval\ncomplexity from $O(N)$ to $O(S + k_1 \\cdot N_s)$. Evaluated on documents\naveraging 49.4 pages and 20,971 textual tokens, DocsRay reduced query latency\nfrom 3.89 to 2.12 seconds, achieving a 45% efficiency improvement. On the\nMMLongBench-Doc benchmark, DocsRay-Pro attains an accuracy of 64.7%,\nsubstantially surpassing previous state-of-the-art results."}
{"id": "2507.23221", "pdf": "https://arxiv.org/pdf/2507.23221", "abs": "https://arxiv.org/abs/2507.23221", "authors": ["Charles O'Neill", "Slava Chalnev", "Chi Chi Zhao", "Max Kirkby", "Mudith Jayasekara"], "title": "A Single Direction of Truth: An Observer Model's Linear Residual Probe Exposes and Steers Contextual Hallucinations", "categories": ["cs.LG"], "comment": null, "summary": "Contextual hallucinations -- statements unsupported by given context --\nremain a significant challenge in AI. We demonstrate a practical\ninterpretability insight: a generator-agnostic observer model detects\nhallucinations via a single forward pass and a linear probe on its residual\nstream. This probe isolates a single, transferable linear direction separating\nhallucinated from faithful text, outperforming baselines by 5-27 points and\nshowing robust mid-layer performance across Gemma-2 models (2B to 27B).\nGradient-times-activation localises this signal to sparse, late-layer MLP\nactivity. Critically, manipulating this direction causally steers generator\nhallucination rates, proving its actionability. Our results offer novel\nevidence of internal, low-dimensional hallucination tracking linked to specific\nMLP sub-circuits, exploitable for detection and mitigation. We release the\n2000-example ContraTales benchmark for realistic assessment of such solutions."}
{"id": "2507.23257", "pdf": "https://arxiv.org/pdf/2507.23257", "abs": "https://arxiv.org/abs/2507.23257", "authors": ["Jiawei Liu", "Chenwang Wu", "Defu Lian", "Enhong Chen"], "title": "Efficient Machine Unlearning via Influence Approximation", "categories": ["cs.LG", "cs.AI"], "comment": "12 pages, 4 figures", "summary": "Due to growing privacy concerns, machine unlearning, which aims at enabling\nmachine learning models to ``forget\" specific training data, has received\nincreasing attention. Among existing methods, influence-based unlearning has\nemerged as a prominent approach due to its ability to estimate the impact of\nindividual training samples on model parameters without retraining. However,\nthis approach suffers from prohibitive computational overhead arising from the\nnecessity to compute the Hessian matrix and its inverse across all training\nsamples and parameters, rendering it impractical for large-scale models and\nscenarios involving frequent data deletion requests. This highlights the\ndifficulty of forgetting. Inspired by cognitive science, which suggests that\nmemorizing is easier than forgetting, this paper establishes a theoretical link\nbetween memorizing (incremental learning) and forgetting (unlearning). This\nconnection allows machine unlearning to be addressed from the perspective of\nincremental learning. Unlike the time-consuming Hessian computations in\nunlearning (forgetting), incremental learning (memorizing) typically relies on\nmore efficient gradient optimization, which supports the aforementioned\ncognitive theory. Based on this connection, we introduce the Influence\nApproximation Unlearning (IAU) algorithm for efficient machine unlearning from\nthe incremental perspective. Extensive empirical evaluations demonstrate that\nIAU achieves a superior balance among removal guarantee, unlearning efficiency,\nand comparable model utility, while outperforming state-of-the-art methods\nacross diverse datasets and model architectures. Our code is available at\nhttps://github.com/Lolo1222/IAU."}
{"id": "2507.23261", "pdf": "https://arxiv.org/pdf/2507.23261", "abs": "https://arxiv.org/abs/2507.23261", "authors": ["Hui Yi Leong", "Yuqing Wu"], "title": "DynaSwarm: Dynamically Graph Structure Selection for LLM-based Multi-agent System", "categories": ["cs.LG", "cs.AI", "cs.MA"], "comment": null, "summary": "Current multi-agent systems (MAS) frameworks often rely on manually designed\nand static collaboration graph structures, limiting adaptability and\nperformance. To address these limitations, we propose DynaSwarm, a dynamic\nframework that enhances LLM-based MAS through two key innovations: (1) an\nactor-critic reinforcement learning (A2C) mechanism to optimize graph\nstructures with improved stability over prior RL methods, and (2) a dynamic\ngraph selector that adaptively chooses the optimal graph structure for each\ninput sample via parameter-efficient LLM fine-tuning. DynaSwarm eliminates the\nneed for rigid, one-fits-all graph architectures, instead leveraging\nsample-specific idiosyncrasies to dynamically route queries through specialized\nagent networks. (c) We propose to fine-tune the demonstration retriever to\nfully exploit the power of in-context learning (ICL). Extensive experiments on\nquestion answering, mathematical reasoning, and coding tasks demonstrate that\nDynaSwarm consistently outperforms state-of-the-art single-agent and MAS\nbaselines across multiple LLM backbones. Our findings highlight the importance\nof sample-aware structural flexibility in LLM MAS designs."}
{"id": "2507.23291", "pdf": "https://arxiv.org/pdf/2507.23291", "abs": "https://arxiv.org/abs/2507.23291", "authors": ["Yuetian Chen", "Zhiqi Wang", "Nathalie Baracaldo", "Swanand Ravindra Kadhe", "Lei Yu"], "title": "Evaluating the Dynamics of Membership Privacy in Deep Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Membership inference attacks (MIAs) pose a critical threat to the privacy of\ntraining data in deep learning. Despite significant progress in attack\nmethodologies, our understanding of when and how models encode membership\ninformation during training remains limited. This paper presents a dynamic\nanalytical framework for dissecting and quantifying privacy leakage dynamics at\nthe individual sample level. By tracking per-sample vulnerabilities on an\nFPR-TPR plane throughout training, our framework systematically measures how\nfactors such as dataset complexity, model architecture, and optimizer choice\ninfluence the rate and severity at which samples become vulnerable. Crucially,\nwe discover a robust correlation between a sample's intrinsic learning\ndifficulty, and find that the privacy risk of samples highly vulnerable in the\nfinal trained model is largely determined early during training. Our results\nthus provide a deeper understanding of how privacy risks dynamically emerge\nduring training, laying the groundwork for proactive, privacy-aware model\ntraining strategies."}
{"id": "2507.23292", "pdf": "https://arxiv.org/pdf/2507.23292", "abs": "https://arxiv.org/abs/2507.23292", "authors": ["RJ Skerry-Ryan", "Julian Salazar", "Soroosh Mariooryad", "David Kao", "Daisy Stanton", "Eric Battenberg", "Matt Shannon", "Ron J. Weiss", "Robin Scheibler", "Jonas Rothfuss", "Tom Bagby"], "title": "SequenceLayers: Sequence Processing and Streaming Neural Networks Made Easy", "categories": ["cs.LG", "cs.CL", "cs.PL", "cs.SE", "eess.AS"], "comment": null, "summary": "We introduce a neural network layer API and library for sequence modeling,\ndesigned for easy creation of sequence models that can be executed both\nlayer-by-layer (e.g., teacher-forced training) and step-by-step (e.g.,\nautoregressive sampling). To achieve this, layers define an explicit\nrepresentation of their state over time (e.g., a Transformer KV cache, a\nconvolution buffer, an RNN hidden state), and a step method that evolves that\nstate, tested to give identical results to a stateless layer-wise invocation.\nThis and other aspects of the SequenceLayers contract enables complex models to\nbe immediately streamable, mitigates a wide range of common bugs arising in\nboth streaming and parallel sequence processing, and can be implemented in any\ndeep learning library. A composable and declarative API, along with a\ncomprehensive suite of layers and combinators, streamlines the construction of\nproduction-scale models from simple streamable components while preserving\nstrong correctness guarantees. Our current implementations of SequenceLayers\n(JAX, TensorFlow 2) are available at https://github.com/google/sequence-layers."}
{"id": "2507.23303", "pdf": "https://arxiv.org/pdf/2507.23303", "abs": "https://arxiv.org/abs/2507.23303", "authors": ["Luca Corbucci", "Javier Alejandro Borges Legrottaglie", "Francesco Spinnato", "Anna Monreale", "Riccardo Guidotti"], "title": "An Interpretable Data-Driven Unsupervised Approach for the Prevention of Forgotten Items", "categories": ["cs.LG"], "comment": null, "summary": "Accurately identifying items forgotten during a supermarket visit and\nproviding clear, interpretable explanations for recommending them remains an\nunderexplored problem within the Next Basket Prediction (NBP) domain. Existing\nNBP approaches typically only focus on forecasting future purchases, without\nexplicitly addressing the detection of unintentionally omitted items. This gap\nis partly due to the scarcity of real-world datasets that allow for the\nreliable estimation of forgotten items. Furthermore, most current NBP methods\nrely on black-box models, which lack transparency and limit the ability to\njustify recommendations to end users. In this paper, we formally introduce the\nforgotten item prediction task and propose two novel interpretable-by-design\nalgorithms. These methods are tailored to identify forgotten items while\noffering intuitive, human-understandable explanations. Experiments on a\nreal-world retail dataset show our algorithms outperform state-of-the-art NBP\nbaselines by 10-15% across multiple evaluation metrics."}
{"id": "2507.23317", "pdf": "https://arxiv.org/pdf/2507.23317", "abs": "https://arxiv.org/abs/2507.23317", "authors": ["Tao He", "Rongchuan Mu", "Lizi Liao", "Yixin Cao", "Ming Liu", "Bing Qin"], "title": "Good Learners Think Their Thinking: Generative PRM Makes Large Reasoning Model More Efficient Math Learner", "categories": ["cs.LG"], "comment": "33 pages, 3 figures, 19 tables", "summary": "Large reasoning models (LRMs) have recently shown promise in solving complex\nmath problems when optimized with Reinforcement Learning (RL). But conventional\napproaches rely on outcome-only rewards that provide sparse feedback, resulting\nin inefficient optimization process. In this work, we investigate the function\nof process reward models (PRMs) to accelerate the RL training for LRMs. We\npropose a novel intrinsic signal-driven generative process evaluation mechanism\noperating at the thought level to address major bottlenecks in RL-based\ntraining. Specifically, instead of requiring PRMs to know how to solve\nproblems, our method uses intrinsic signals in solutions to judge stepwise\ncorrectness and aggregate contiguous correct/incorrect steps into coherent\n'thought' units. This structured, thought-level rewards enable more reliable\ncredit assignment by reducing ambiguity in step segmentation and alleviating\nreward hacking. We further introduce a capability-adaptive reward mechanism\nthat dynamically balances exploration and exploitation based on the LRM's\ncurrent proficiency, guiding learning without stifling creative\ntrial-and-error. These innovations are integrated into a new off-policy RL\nalgorithm, TP-GRPO, which extends grouped proximal optimization with\nprocess-based rewards and improves training efficiency. Experiments on 1.5B and\n7B parameter LRMs demonstrate that our method achieves higher problem-solving\naccuracy with significantly fewer training samples than outcome-only reward\nbaselines. The results validate that well-structured process rewards can\nsubstantially accelerate LRM optimization in math reasoning tasks. Code is\navailable at https://github.com/cs-holder/tp_grpo."}
{"id": "2507.23335", "pdf": "https://arxiv.org/pdf/2507.23335", "abs": "https://arxiv.org/abs/2507.23335", "authors": ["Qilin Zhou", "Haipeng Wang", "Zhengyuan Wei", "W. K. Chan"], "title": "Scalable and Precise Patch Robustness Certification for Deep Learning Models with Top-k Predictions", "categories": ["cs.LG", "cs.SE"], "comment": "accepted by QRS 2025", "summary": "Patch robustness certification is an emerging verification approach for\ndefending against adversarial patch attacks with provable guarantees for deep\nlearning systems. Certified recovery techniques guarantee the prediction of the\nsole true label of a certified sample. However, existing techniques, if\napplicable to top-k predictions, commonly conduct pairwise comparisons on those\nvotes between labels, failing to certify the sole true label within the top k\nprediction labels precisely due to the inflation on the number of votes\ncontrolled by the attacker (i.e., attack budget); yet enumerating all\ncombinations of vote allocation suffers from the combinatorial explosion\nproblem. We propose CostCert, a novel, scalable, and precise voting-based\ncertified recovery defender. CostCert verifies the true label of a sample\nwithin the top k predictions without pairwise comparisons and combinatorial\nexplosion through a novel design: whether the attack budget on the sample is\ninfeasible to cover the smallest total additional votes on top of the votes\nuncontrollable by the attacker to exclude the true labels from the top k\nprediction labels. Experiments show that CostCert significantly outperforms the\ncurrent state-of-the-art defender PatchGuard, such as retaining up to 57.3% in\ncertified accuracy when the patch size is 96, whereas PatchGuard has already\ndropped to zero."}
{"id": "2507.23344", "pdf": "https://arxiv.org/pdf/2507.23344", "abs": "https://arxiv.org/abs/2507.23344", "authors": ["Tatsuya Mitomi", "Fumiyasu Makinoshima", "Fumiya Makihara", "Eigo Segawa"], "title": "Designing Dynamic Pricing for Bike-sharing Systems via Differentiable Agent-based Simulation", "categories": ["cs.LG", "cs.MA"], "comment": null, "summary": "Bike-sharing systems are emerging in various cities as a new ecofriendly\ntransportation system. In these systems, spatiotemporally varying user demands\nlead to imbalanced inventory at bicycle stations, resulting in additional\nrelocation costs. Therefore, it is essential to manage user demand through\noptimal dynamic pricing for the system. However, optimal pricing design for\nsuch a system is challenging because the system involves users with diverse\nbackgrounds and their probabilistic choices. To address this problem, we\ndevelop a differentiable agent-based simulation to rapidly design dynamic\npricing in bike-sharing systems, achieving balanced bicycle inventory despite\nspatiotemporally heterogeneous trips and probabilistic user decisions. We first\nvalidate our approach against conventional methods through numerical\nexperiments involving 25 bicycle stations and five time slots, yielding 100\nparameters. Compared to the conventional methods, our approach obtains a more\naccurate solution with a 73% to 78% reduction in loss while achieving more than\na 100-fold increase in convergence speed. We further validate our approach on a\nlarge-scale urban bike-sharing system scenario involving 289 bicycle stations,\nresulting in a total of 1156 parameters. Through simulations using the obtained\npricing policies, we confirm that these policies can naturally induce balanced\ninventory without any manual relocation. Additionally, we find that the cost of\ndiscounts to induce the balanced inventory can be minimized by setting\nappropriate initial conditions."}
{"id": "2507.23389", "pdf": "https://arxiv.org/pdf/2507.23389", "abs": "https://arxiv.org/abs/2507.23389", "authors": ["David Komnick", "Kathrin Lammers", "Barbara Hammer", "Valerie Vaquet", "Fabian Hinder"], "title": "Causal Explanation of Concept Drift -- A Truly Actionable Approach", "categories": ["cs.LG"], "comment": "This manuscript is accepted to be presented at the TempXAI workshop\n  at the European Conference on Machine Learning and Principles and Practice of\n  Knowledge Discovery in Databases (ECMLPKDD 2025)", "summary": "In a world that constantly changes, it is crucial to understand how those\nchanges impact different systems, such as industrial manufacturing or critical\ninfrastructure. Explaining critical changes, referred to as concept drift in\nthe field of machine learning, is the first step towards enabling targeted\ninterventions to avoid or correct model failures, as well as malfunctions and\nerrors in the physical world. Therefore, in this work, we extend model-based\ndrift explanations towards causal explanations, which increases the\nactionability of the provided explanations. We evaluate our explanation\nstrategy on a number of use cases, demonstrating the practical usefulness of\nour framework, which isolates the causally relevant features impacted by\nconcept drift and, thus, allows for targeted intervention."}
{"id": "2507.23391", "pdf": "https://arxiv.org/pdf/2507.23391", "abs": "https://arxiv.org/abs/2507.23391", "authors": ["Tung M. Luu", "Donghoon Lee", "Younghwan Lee", "Chang D. Yoo"], "title": "Policy Learning from Large Vision-Language Model Feedback without Reward Modeling", "categories": ["cs.LG", "cs.RO"], "comment": "Accepted to IROS 2025", "summary": "Offline reinforcement learning (RL) provides a powerful framework for\ntraining robotic agents using pre-collected, suboptimal datasets, eliminating\nthe need for costly, time-consuming, and potentially hazardous online\ninteractions. This is particularly useful in safety-critical real-world\napplications, where online data collection is expensive and impractical.\nHowever, existing offline RL algorithms typically require reward labeled data,\nwhich introduces an additional bottleneck: reward function design is itself\ncostly, labor-intensive, and requires significant domain expertise. In this\npaper, we introduce PLARE, a novel approach that leverages large\nvision-language models (VLMs) to provide guidance signals for agent training.\nInstead of relying on manually designed reward functions, PLARE queries a VLM\nfor preference labels on pairs of visual trajectory segments based on a\nlanguage task description. The policy is then trained directly from these\npreference labels using a supervised contrastive preference learning objective,\nbypassing the need to learn explicit reward models. Through extensive\nexperiments on robotic manipulation tasks from the MetaWorld, PLARE achieves\nperformance on par with or surpassing existing state-of-the-art VLM-based\nreward generation methods. Furthermore, we demonstrate the effectiveness of\nPLARE in real-world manipulation tasks with a physical robot, further\nvalidating its practical applicability."}
{"id": "2507.23412", "pdf": "https://arxiv.org/pdf/2507.23412", "abs": "https://arxiv.org/abs/2507.23412", "authors": ["Mokhtar A. Al-Awadhi", "Ratnadeep R. Deshmukh"], "title": "A Machine Learning Approach for Honey Adulteration Detection using Mineral Element Profiles", "categories": ["cs.LG"], "comment": null, "summary": "This paper aims to develop a Machine Learning (ML)-based system for detecting\nhoney adulteration utilizing honey mineral element profiles. The proposed\nsystem comprises two phases: preprocessing and classification. The\npreprocessing phase involves the treatment of missing-value attributes and\nnormalization. In the classifica-tion phase, we use three supervised ML models:\nlogistic regression, decision tree, and random forest, to dis-criminate between\nauthentic and adulterated honey. To evaluate the performance of the ML models,\nwe use a public dataset comprising measurements of mineral element content of\nauthentic honey, sugar syrups, and adul-terated honey. Experimental findings\nshow that mineral element content in honey provides robust discriminative\ninformation for detecting honey adulteration. Results also demonstrate that the\nrandom forest-based classifier outperforms other classifiers on this dataset,\nachieving the highest cross-validation accuracy of 98.37%."}
{"id": "2507.23418", "pdf": "https://arxiv.org/pdf/2507.23418", "abs": "https://arxiv.org/abs/2507.23418", "authors": ["Mokhtar A. Al-Awadhi", "Ratnadeep R. Deshmukh"], "title": "Detection of Adulteration in Coconut Milk using Infrared Spectroscopy and Machine Learning", "categories": ["cs.LG"], "comment": null, "summary": "In this paper, we propose a system for detecting adulteration in coconut\nmilk, utilizing infrared spectroscopy. The machine learning-based proposed\nsystem comprises three phases: preprocessing, feature extraction, and\nclassification. The first phase involves removing irrelevant data from coconut\nmilk spectral signals. In the second phase, we employ the Linear Discriminant\nAnalysis (LDA) algorithm for extracting the most discriminating features. In\nthe third phase, we use the K-Nearest Neighbor (KNN) model to classify coconut\nmilk samples into authentic or adulterated. We evaluate the performance of the\nproposed system using a public dataset comprising Fourier Transform Infrared\n(FTIR) spectral information of pure and contaminated coconut milk samples.\nFindings show that the proposed method successfully detects adulteration with a\ncross-validation accuracy of 93.33%."}
{"id": "2507.23428", "pdf": "https://arxiv.org/pdf/2507.23428", "abs": "https://arxiv.org/abs/2507.23428", "authors": ["Nodens F. Koren", "Samuel Lanthaler"], "title": "Merging Memory and Space: A Spatiotemporal State Space Neural Operator", "categories": ["cs.LG"], "comment": null, "summary": "We propose the Spatiotemporal State Space Neural Operator (ST-SSM), a compact\narchitecture for learning solution operators of time-dependent partial\ndifferential equations (PDEs). ST-SSM introduces a novel factorization of the\nspatial and temporal dimensions, using structured state-space models to\nindependently model temporal evolution and spatial interactions. This design\nenables parameter efficiency and flexible modeling of long-range spatiotemporal\ndynamics. A theoretical connection is established between SSMs and neural\noperators, and a unified universality theorem is proved for the resulting class\nof architectures. Empirically, we demonstrate that our factorized formulation\noutperforms alternative schemes such as zigzag scanning and parallel\nindependent processing on several PDE benchmarks, including 1D Burgers'\nequation, 1D Kuramoto-Sivashinsky equation, and 2D Navier-Stokes equations\nunder varying physical conditions. Our model performs competitively with\nexisting baselines while using significantly fewer parameters. In addition, our\nresults reinforce previous findings on the benefits of temporal memory by\nshowing improved performance under partial observability. Our results highlight\nthe advantages of dimensionally factorized operator learning for efficient and\ngeneralizable PDE modeling, and put this approach on a firm theoretical\nfooting."}
{"id": "2507.23437", "pdf": "https://arxiv.org/pdf/2507.23437", "abs": "https://arxiv.org/abs/2507.23437", "authors": ["Yinhui Ma", "Tomomasa Yamasaki", "Zhehui Wang", "Tao Luo", "Bo Wang"], "title": "Coflex: Enhancing HW-NAS with Sparse Gaussian Processes for Efficient and Scalable DNN Accelerator Design", "categories": ["cs.LG", "I.2.6; C.1.3; C.3"], "comment": "Accepted to ICCAD 2025 (camera-ready); 9 pages, 5 figures", "summary": "Hardware-Aware Neural Architecture Search (HW-NAS) is an efficient approach\nto automatically co-optimizing neural network performance and hardware energy\nefficiency, making it particularly useful for the development of Deep Neural\nNetwork accelerators on the edge. However, the extensive search space and high\ncomputational cost pose significant challenges to its practical adoption. To\naddress these limitations, we propose Coflex, a novel HW-NAS framework that\nintegrates the Sparse Gaussian Process (SGP) with multi-objective Bayesian\noptimization. By leveraging sparse inducing points, Coflex reduces the GP\nkernel complexity from cubic to near-linear with respect to the number of\ntraining samples, without compromising optimization performance. This enables\nscalable approximation of large-scale search space, substantially decreasing\ncomputational overhead while preserving high predictive accuracy. We evaluate\nthe efficacy of Coflex across various benchmarks, focusing on\naccelerator-specific architecture. Our experi- mental results show that Coflex\noutperforms state-of-the-art methods in terms of network accuracy and\nEnergy-Delay-Product, while achieving a computational speed-up ranging from\n1.9x to 9.5x."}
{"id": "2507.23449", "pdf": "https://arxiv.org/pdf/2507.23449", "abs": "https://arxiv.org/abs/2507.23449", "authors": ["Shervin Rahimzadeh Arashloo"], "title": "Manifold-regularised Signature Kernel Large-Margin $\\ell_p$-SVDD for Multidimensional Time Series Anomaly Detection", "categories": ["cs.LG"], "comment": null, "summary": "We generalise the recently introduced large-margin $\\ell_p$-SVDD approach to\nexploit the geometry of data distribution via manifold regularising and a\nsignature kernel representation for time series anomaly detection.\nSpecifically, we formulate a manifold-regularised variant of the $\\ell_p$-SVDD\nmethod to encourage label smoothness on the underlying manifold to capture\nstructural information for improved detection performance. Drawing on an\nexisting Representer theorem, we then provide an effective optimisation\ntechnique for the proposed method and show that it can benefit from the\nsignature kernel to capture time series complexities for anomaly detection.\n  We theoretically study the proposed approach using Rademacher complexities to\nanalyse its generalisation performance and also provide an experimental\nassessment of the proposed method across various data sets to compare its\nperformance against other methods."}
{"id": "2507.23491", "pdf": "https://arxiv.org/pdf/2507.23491", "abs": "https://arxiv.org/abs/2507.23491", "authors": ["Olga Vershinina", "Jacopo Sabbatinelli", "Anna Rita Bonfigli", "Dalila Colombaretti", "Angelica Giuliani", "Mikhail Krivonosov", "Arseniy Trukhanov", "Claudio Franceschi", "Mikhail Ivanchenko", "Fabiola Olivieri"], "title": "Explainable artificial intelligence model predicting the risk of all-cause mortality in patients with type 2 diabetes mellitus", "categories": ["cs.LG"], "comment": null, "summary": "Objective. Type 2 diabetes mellitus (T2DM) is a highly prevalent\nnon-communicable chronic disease that substantially reduces life expectancy.\nAccurate estimation of all-cause mortality risk in T2DM patients is crucial for\npersonalizing and optimizing treatment strategies. Research Design and Methods.\nThis study analyzed a cohort of 554 patients (aged 40-87 years) with diagnosed\nT2DM over a maximum follow-up period of 16.8 years, during which 202 patients\n(36%) died. Key survival-associated features were identified, and multiple\nmachine learning (ML) models were trained and validated to predict all-cause\nmortality risk. To improve model interpretability, Shapley additive\nexplanations (SHAP) was applied to the best-performing model. Results. The\nextra survival trees (EST) model, incorporating ten key features, demonstrated\nthe best predictive performance. The model achieved a C-statistic of 0.776,\nwith the area under the receiver operating characteristic curve (AUC) values of\n0.86, 0.80, 0.841, and 0.826 for 5-, 10-, 15-, and 16.8-year all-cause\nmortality predictions, respectively. The SHAP approach was employed to\ninterpret the model's individual decision-making processes. Conclusions. The\ndeveloped model exhibited strong predictive performance for mortality risk\nassessment. Its clinically interpretable outputs enable potential bedside\napplication, improving the identification of high-risk patients and supporting\ntimely treatment optimization."}
{"id": "2507.23495", "pdf": "https://arxiv.org/pdf/2507.23495", "abs": "https://arxiv.org/abs/2507.23495", "authors": ["Maurits Kaptein"], "title": "Incorporating structural uncertainty in causal decision making", "categories": ["cs.LG", "math.ST", "stat.TH"], "comment": "This work is under review at the Journal of Causal Inference", "summary": "Practitioners making decisions based on causal effects typically ignore\nstructural uncertainty. We analyze when this uncertainty is consequential\nenough to warrant methodological solutions (Bayesian model averaging over\ncompeting causal structures). Focusing on bivariate relationships ($X\n\\rightarrow Y$ vs. $X \\leftarrow Y$), we establish that model averaging is\nbeneficial when: (1) structural uncertainty is moderate to high, (2) causal\neffects differ substantially between structures, and (3) loss functions are\nsufficiently sensitive to the size of the causal effect. We prove optimality\nresults of our suggested methodological solution under regularity conditions\nand demonstrate through simulations that modern causal discovery methods can\nprovide, within limits, the necessary quantification. Our framework complements\nexisting robust causal inference approaches by addressing a distinct source of\nuncertainty typically overlooked in practice."}
{"id": "2507.23501", "pdf": "https://arxiv.org/pdf/2507.23501", "abs": "https://arxiv.org/abs/2507.23501", "authors": ["Nicklas Werge", "Yi-Shan Wu", "Bahareh Tasdighi", "Melih Kandemir"], "title": "Directional Ensemble Aggregation for Actor-Critics", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Off-policy reinforcement learning in continuous control tasks depends\ncritically on accurate $Q$-value estimates. Conservative aggregation over\nensembles, such as taking the minimum, is commonly used to mitigate\noverestimation bias. However, these static rules are coarse, discard valuable\ninformation from the ensemble, and cannot adapt to task-specific needs or\ndifferent learning regimes. We propose Directional Ensemble Aggregation (DEA),\nan aggregation method that adaptively combines $Q$-value estimates in\nactor-critic frameworks. DEA introduces two fully learnable directional\nparameters: one that modulates critic-side conservatism and another that guides\nactor-side policy exploration. Both parameters are learned using ensemble\ndisagreement-weighted Bellman errors, which weight each sample solely by the\ndirection of its Bellman error. This directional learning mechanism allows DEA\nto adjust conservatism and exploration in a data-driven way, adapting\naggregation to both uncertainty levels and the phase of training. We evaluate\nDEA across continuous control benchmarks and learning regimes - from\ninteractive to sample-efficient - and demonstrate its effectiveness over static\nensemble strategies."}
{"id": "2507.23504", "pdf": "https://arxiv.org/pdf/2507.23504", "abs": "https://arxiv.org/abs/2507.23504", "authors": ["Maurits Kaptein"], "title": "A Verifier Hierarchy", "categories": ["cs.LG"], "comment": "This paper is primarily relevant to cs.CC, but submitted under cs.ML\n  due to lack of endorsement. The paper is under review at \"Information and\n  Communication\"", "summary": "We investigate the trade-off between certificate length and verifier runtime.\nWe prove a Verifier Trade-off Theorem showing that reducing the inherent\nverification time of a language from \\(f(n)\\) to \\(g(n)\\), where \\(f(n) \\ge\ng(n)\\), requires certificates of length at least \\(\\Omega(\\log(f(n) / g(n)))\\).\nThis theorem induces a natural hierarchy based on certificate complexity. We\ndemonstrate its applicability to analyzing conjectured separations between\ncomplexity classes (e.g., \\(\\np\\) and \\(\\exptime\\)) and to studying natural\nproblems such as string periodicity and rotation detection. Additionally, we\nprovide perspectives on the \\(\\p\\) vs. \\(\\np\\) problem by relating it to the\nexistence of sub-linear certificates."}
{"id": "2507.23512", "pdf": "https://arxiv.org/pdf/2507.23512", "abs": "https://arxiv.org/abs/2507.23512", "authors": ["Saleh Vatan Khah", "Savelii Chezhegov", "Shahrokh Farahmand", "Samuel Horváth", "Eduard Gorbunov"], "title": "Differentially Private Clipped-SGD: High-Probability Convergence with Arbitrary Clipping Level", "categories": ["cs.LG", "math.OC"], "comment": "60 pages", "summary": "Gradient clipping is a fundamental tool in Deep Learning, improving the\nhigh-probability convergence of stochastic first-order methods like SGD,\nAdaGrad, and Adam under heavy-tailed noise, which is common in training large\nlanguage models. It is also a crucial component of Differential Privacy (DP)\nmechanisms. However, existing high-probability convergence analyses typically\nrequire the clipping threshold to increase with the number of optimization\nsteps, which is incompatible with standard DP mechanisms like the Gaussian\nmechanism. In this work, we close this gap by providing the first\nhigh-probability convergence analysis for DP-Clipped-SGD with a fixed clipping\nlevel, applicable to both convex and non-convex smooth optimization under\nheavy-tailed noise, characterized by a bounded central $\\alpha$-th moment\nassumption, $\\alpha \\in (1,2]$. Our results show that, with a fixed clipping\nlevel, the method converges to a neighborhood of the optimal solution with a\nfaster rate than the existing ones. The neighborhood can be balanced against\nthe noise introduced by DP, providing a refined trade-off between convergence\nspeed and privacy guarantees."}
{"id": "2507.23534", "pdf": "https://arxiv.org/pdf/2507.23534", "abs": "https://arxiv.org/abs/2507.23534", "authors": ["Chih-Fan Hsu", "Ming-Ching Chang", "Wei-Chao Chen"], "title": "Continual Learning with Synthetic Boundary Experience Blending", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Continual learning (CL) aims to address catastrophic forgetting in models\ntrained sequentially on multiple tasks. While experience replay has shown\npromise, its effectiveness is often limited by the sparse distribution of\nstored key samples, leading to overly simplified decision boundaries. We\nhypothesize that introducing synthetic data near the decision boundary\n(Synthetic Boundary Data, or SBD) during training serves as an implicit\nregularizer, improving boundary stability and mitigating forgetting. To\nvalidate this hypothesis, we propose a novel training framework, {\\bf\nExperience Blending}, which integrates knowledge from both stored key samples\nand synthetic, boundary-adjacent data. Experience blending consists of two core\ncomponents: (1) a multivariate Differential Privacy (DP) noise mechanism that\ninjects batch-wise noise into low-dimensional feature representations,\ngenerating SBD; and (2) an end-to-end training strategy that jointly leverages\nboth stored key samples and SBD. Extensive experiments on CIFAR-10, CIFAR-100,\nand Tiny ImageNet demonstrate that our method outperforms nine CL baselines,\nachieving accuracy improvements of 10%, 6%, and 13%, respectively."}
{"id": "2507.23535", "pdf": "https://arxiv.org/pdf/2507.23535", "abs": "https://arxiv.org/abs/2507.23535", "authors": ["Dhanesh Ramachandram", "Himanshu Joshi", "Judy Zhu", "Dhari Gandhi", "Lucas Hartman", "Ananya Raval"], "title": "Transparent AI: The Case for Interpretability and Explainability", "categories": ["cs.LG", "cs.AI", "cs.CY"], "comment": null, "summary": "As artificial intelligence systems increasingly inform high-stakes decisions\nacross sectors, transparency has become foundational to responsible and\ntrustworthy AI implementation. Leveraging our role as a leading institute in\nadvancing AI research and enabling industry adoption, we present key insights\nand lessons learned from practical interpretability applications across diverse\ndomains. This paper offers actionable strategies and implementation guidance\ntailored to organizations at varying stages of AI maturity, emphasizing the\nintegration of interpretability as a core design principle rather than a\nretrospective add-on."}
{"id": "2507.23536", "pdf": "https://arxiv.org/pdf/2507.23536", "abs": "https://arxiv.org/abs/2507.23536", "authors": ["Georg Slamanig", "Francesco Corti", "Olga Saukh"], "title": "From LLMs to Edge: Parameter-Efficient Fine-Tuning on Edge Devices", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Parameter-efficient fine-tuning (PEFT) methods reduce the computational costs\nof updating deep learning models by minimizing the number of additional\nparameters used to adapt a model to a down- stream task. While extensively\nresearched in large language models (LLMs), their application to smaller models\nused on edge devices, such as convolutional neural networks, remains\nunderexplored. This paper benchmarks and analyzes popular PEFT methods on\nconvolutional architectures typically deployed in resource-constrained edge\nenvironments. We evaluate LoRA, DoRA, and GaLore for updating standard and\ndepthwise convolutional architectures to handle distribution shifts and\naccommodate unseen classes. We utilize recently proposed PyTorch profilers to\ncompare the updated model performance and computational costs of these PEFT\nmethods with traditional fine-tuning approaches. With resource efficiency in\nmind, we investigate their update behavior across different rank dimensions. We\nfind that the evaluated PEFT methods are only half as memory-efficient when\napplied to depthwise-separable convolution architectures, compared to their\nefficiency with LLMs. Conversely, when targeting convolu- tional architectures\noptimized for edge deployment, adapter-based PEFT methods can reduce floating\npoint operations (FLOPs) during model updates by up to 95%. These insights\noffer valuable guidance for selecting PEFT methods based on hardware\nconstraints, performance requirements, and application needs. Our code is\nonline."}
{"id": "2507.23539", "pdf": "https://arxiv.org/pdf/2507.23539", "abs": "https://arxiv.org/abs/2507.23539", "authors": ["Piotr Indyk", "Michael Kapralov", "Kshiteej Sheth", "Tal Wagner"], "title": "Improved Algorithms for Kernel Matrix-Vector Multiplication Under Sparsity Assumptions", "categories": ["cs.LG", "cs.DS"], "comment": "Published in ICLR 2025", "summary": "Motivated by the problem of fast processing of attention matrices, we study\nfast algorithms for computing matrix-vector products for asymmetric Gaussian\nKernel matrices $K\\in \\mathbb{R}^{n\\times n}$. $K$'s columns are indexed by a\nset of $n$ keys $k_1,k_2\\ldots, k_n\\in \\mathbb{R}^d$, rows by a set of $n$\nqueries $q_1,q_2,\\ldots,q_n\\in \\mathbb{R}^d $, and its $i,j$ entry is $K_{ij} =\ne^{-\\|q_i-k_j\\|_2^2/2\\sigma^2}$ for some bandwidth parameter $\\sigma>0$. Given\na vector $x\\in \\mathbb{R}^n$ and error parameter $\\epsilon>0$, our task is to\noutput a $y\\in \\mathbb{R}^n$ such that $\\|Kx-y\\|_2\\leq \\epsilon \\|x\\|_2$ in\ntime subquadratic in $n$ and linear in $d$. Our algorithms rely on the\nfollowing modelling assumption about the matrices $K$: the sum of the entries\nof $K$ scales linearly in $n$, as opposed to worst case quadratic growth. We\nvalidate this assumption experimentally, for Gaussian kernel matrices\nencountered in various settings such as fast attention computation in LLMs. We\nobtain the first subquadratic-time algorithm that works under this assumption,\nfor unrestricted vectors."}
{"id": "2507.23562", "pdf": "https://arxiv.org/pdf/2507.23562", "abs": "https://arxiv.org/abs/2507.23562", "authors": ["Sirine Arfa", "Bernhard Vogginger", "Christian Mayr"], "title": "Hardware-Aware Fine-Tuning of Spiking Q-Networks on the SpiNNaker2 Neuromorphic Platform", "categories": ["cs.LG", "cs.AR"], "comment": "8 pages, 5 figures, 3 tables", "summary": "Spiking Neural Networks (SNNs) promise orders-of-magnitude lower power\nconsumption and low-latency inference on neuromorphic hardware for a wide range\nof robotic tasks. In this work, we present an energy-efficient implementation\nof a reinforcement learning (RL) algorithm using quantized SNNs to solve two\nclassical control tasks. The network is trained using the Q-learning algorithm,\nthen fine-tuned and quantized to low-bit (8-bit) precision for embedded\ndeployment on the SpiNNaker2 neuromorphic chip. To evaluate the comparative\nadvantage of SpiNNaker2 over conventional computing platforms, we analyze\ninference latency, dynamic power consumption, and energy cost per inference for\nour SNN models, comparing performance against a GTX 1650 GPU baseline. Our\nresults demonstrate SpiNNaker2's strong potential for scalable, low-energy\nneuromorphic computing, achieving up to 32x reduction in energy consumption.\nInference latency remains on par with GPU-based execution, with improvements\nobserved in certain task settings, reinforcing SpiNNaker2's viability for\nreal-time neuromorphic control and making the neuromorphic approach a\ncompelling direction for efficient deep Q-learning."}
{"id": "2507.23568", "pdf": "https://arxiv.org/pdf/2507.23568", "abs": "https://arxiv.org/abs/2507.23568", "authors": ["Fernando Martínez-García", "Álvaro Rubio-García", "Samuel Fernández-Lorenzo", "Juan José García-Ripoll", "Diego Porras"], "title": "Optimised Feature Subset Selection via Simulated Annealing", "categories": ["cs.LG", "cond-mat.stat-mech", "stat.ML"], "comment": "12 pages, 2 figures", "summary": "We introduce SA-FDR, a novel algorithm for $\\ell_0$-norm feature selection\nthat considers this task as a combinatorial optimisation problem and solves it\nby using simulated annealing to perform a global search over the space of\nfeature subsets. The optimisation is guided by the Fisher discriminant ratio,\nwhich we use as a computationally efficient proxy for model quality in\nclassification tasks. Our experiments, conducted on datasets with up to\nhundreds of thousands of samples and hundreds of features, demonstrate that\nSA-FDR consistently selects more compact feature subsets while achieving a high\npredictive accuracy. This ability to recover informative yet minimal sets of\nfeatures stems from its capacity to capture inter-feature dependencies often\nmissed by greedy optimisation approaches. As a result, SA-FDR provides a\nflexible and effective solution for designing interpretable models in\nhigh-dimensional settings, particularly when model sparsity, interpretability,\nand performance are crucial."}
{"id": "2507.23581", "pdf": "https://arxiv.org/pdf/2507.23581", "abs": "https://arxiv.org/abs/2507.23581", "authors": ["Chuanyue Yu", "Kuo Zhao", "Yuhan Li", "Heng Chang", "Mingjian Feng", "Xiangzhe Jiang", "Yufei Sun", "Jia Li", "Yuzhi Zhang", "Jianxin Li", "Ziwei Zhang"], "title": "GraphRAG-R1: Graph Retrieval-Augmented Generation with Process-Constrained Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "Graph Retrieval-Augmented Generation (GraphRAG) has shown great effectiveness\nin enhancing the reasoning abilities of LLMs by leveraging graph structures for\nknowledge representation and modeling complex real-world relationships.\nHowever, existing GraphRAG methods still face significant bottlenecks when\nhandling complex problems that require multi-hop reasoning, as their query and\nretrieval phases are largely based on pre-defined heuristics and do not fully\nutilize the reasoning potentials of LLMs. To address this problem, we propose\nGraphRAG-R1, an adaptive GraphRAG framework by training LLMs with\nprocess-constrained outcome-based reinforcement learning (RL) to enhance the\nmulti-hop reasoning ability. Our method can decompose complex problems,\nautonomously invoke retrieval tools to acquire necessary information, and\nperform effective reasoning. Specifically, we utilize a modified version of\nGroup Relative Policy Optimization (GRPO) that supports rollout-with-thinking\ncapability. Next, we design two process-constrained reward functions. To handle\nthe shallow retrieval problem, we design a Progressive Retrieval Attenuation\n(PRA) reward to encourage essential retrievals. Then, to handle the\nover-thinking problem, we design Cost-Aware F1 (CAF) reward to balance the\nmodel performance with computational costs. We further design a phase-dependent\ntraining strategy, containing three training stages corresponding to cold start\nand these two rewards. Lastly, our method adopts a hybrid graph-textual\nretrieval to improve the reasoning capacity. Extensive experimental results\ndemonstrate that GraphRAG-R1 boosts LLM capabilities in solving complex\nreasoning problems compared to state-of-the-art GraphRAG methods on both\nin-domain and out-of-domain datasets. Furthermore, our framework can be\nflexibly integrated with various existing retrieval methods, consistently\ndelivering performance improvements."}
{"id": "2507.23600", "pdf": "https://arxiv.org/pdf/2507.23600", "abs": "https://arxiv.org/abs/2507.23600", "authors": ["Yu-Tang Chang", "Shih-Fang Chen"], "title": "EB-gMCR: Energy-Based Generative Modeling for Signal Unmixing and Multivariate Curve Resolution", "categories": ["cs.LG", "cs.CE", "G.1.6; G.3; G.4; I.6.5"], "comment": null, "summary": "Signal unmixing analysis decomposes data into basic patterns and is widely\napplied in chemical and biological research. Multivariate curve resolution\n(MCR), a branch of signal unmixing, separates mixed chemical signals into base\npatterns (components) and their concentrations, playing a key role in\nunderstanding composition. Classical MCR is typically framed as matrix\nfactorization (MF) and requires a user-specified component count, usually\nunknown in real data. As dataset size or component count increases, the\nscalability and reliability of MF-based MCR face significant challenges. This\nstudy reformulates MCR as a generative process (gMCR), and introduces an\nenergy-based deep learning solver, EB-gMCR, that automatically discovers the\nsmallest component set able to reconstruct the data faithfully. EB-gMCR starts\nfrom a large candidate pool (e.g., 1024 spectra) and employs a differentiable\ngating network to retain only active components while estimating their\nconcentrations. On noisy synthetic datasets containing up to 256 latent\nsources, EB-gMCR maintained R^2 >= 0.98 and recovered the component count\nwithin 5% of the ground truth; at lower noise it achieved R^2 >= 0.99 with near\nexact component estimation. Additional chemical priors, such as non-negativity\nor nonlinear mixing, enter as simple plug-in functions, enabling adaptation to\nother instruments or domains without altering the core learning process. By\nuniting high-capacity generative modeling and hard component selection, EB-gMCR\noffers a practical route to large-scale signal unmixing analysis, including\nchemical library-driven scenarios. The source code is available at\nhttps://github.com/b05611038/ebgmcr_solver."}
{"id": "2507.23604", "pdf": "https://arxiv.org/pdf/2507.23604", "abs": "https://arxiv.org/abs/2507.23604", "authors": ["Tommaso Marzi", "Cesare Alippi", "Andrea Cini"], "title": "Hierarchical Message-Passing Policies for Multi-Agent Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "Decentralized Multi-Agent Reinforcement Learning (MARL) methods allow for\nlearning scalable multi-agent policies, but suffer from partial observability\nand induced non-stationarity. These challenges can be addressed by introducing\nmechanisms that facilitate coordination and high-level planning. Specifically,\ncoordination and temporal abstraction can be achieved through communication\n(e.g., message passing) and Hierarchical Reinforcement Learning (HRL)\napproaches to decision-making. However, optimization issues limit the\napplicability of hierarchical policies to multi-agent systems. As such, the\ncombination of these approaches has not been fully explored. To fill this void,\nwe propose a novel and effective methodology for learning multi-agent\nhierarchies of message-passing policies. We adopt the feudal HRL framework and\nrely on a hierarchical graph structure for planning and coordination among\nagents. Agents at lower levels in the hierarchy receive goals from the upper\nlevels and exchange messages with neighboring agents at the same level. To\nlearn hierarchical multi-agent policies, we design a novel reward-assignment\nmethod based on training the lower-level policies to maximize the advantage\nfunction associated with the upper levels. Results on relevant benchmarks show\nthat our method performs favorably compared to the state of the art."}
{"id": "2507.23607", "pdf": "https://arxiv.org/pdf/2507.23607", "abs": "https://arxiv.org/abs/2507.23607", "authors": ["Tien Huu Do", "Antoine Masquelier", "Nae Eoun Lee", "Jonathan Crowther"], "title": "Deep Learning-based Prediction of Clinical Trial Enrollment with Uncertainty Estimates", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Clinical trials are a systematic endeavor to assess the safety and efficacy\nof new drugs or treatments. Conducting such trials typically demands\nsignificant financial investment and meticulous planning, highlighting the need\nfor accurate predictions of trial outcomes. Accurately predicting patient\nenrollment, a key factor in trial success, is one of the primary challenges\nduring the planning phase. In this work, we propose a novel deep learning-based\nmethod to address this critical challenge. Our method, implemented as a neural\nnetwork model, leverages pre-trained language models (PLMs) to capture the\ncomplexities and nuances of clinical documents, transforming them into\nexpressive representations. These representations are then combined with\nencoded tabular features via an attention mechanism. To account for\nuncertainties in enrollment prediction, we enhance the model with a\nprobabilistic layer based on the Gamma distribution, which enables range\nestimation. We apply the proposed model to predict clinical trial duration,\nassuming site-level enrollment follows a Poisson-Gamma process. We carry out\nextensive experiments on real-world clinical trial data, and show that the\nproposed method can effectively predict the number of patients enrolled at a\nnumber of sites for a given clinical trial, outperforming established baseline\nmodels."}
{"id": "2507.23615", "pdf": "https://arxiv.org/pdf/2507.23615", "abs": "https://arxiv.org/abs/2507.23615", "authors": ["Luis Roque", "Carlos Soares", "Vitor Cerqueira", "Luis Torgo"], "title": "L-GTA: Latent Generative Modeling for Time Series Augmentation", "categories": ["cs.LG", "cs.AI", "68T01", "I.5.1; G.3; H.2.8; I.2.1"], "comment": null, "summary": "Data augmentation is gaining importance across various aspects of time series\nanalysis, from forecasting to classification and anomaly detection tasks. We\nintroduce the Latent Generative Transformer Augmentation (L-GTA) model, a\ngenerative approach using a transformer-based variational recurrent\nautoencoder. This model uses controlled transformations within the latent space\nof the model to generate new time series that preserve the intrinsic properties\nof the original dataset. L-GTA enables the application of diverse\ntransformations, ranging from simple jittering to magnitude warping, and\ncombining these basic transformations to generate more complex synthetic time\nseries datasets. Our evaluation of several real-world datasets demonstrates the\nability of L-GTA to produce more reliable, consistent, and controllable\naugmented data. This translates into significant improvements in predictive\naccuracy and similarity measures compared to direct transformation methods."}
{"id": "2507.23632", "pdf": "https://arxiv.org/pdf/2507.23632", "abs": "https://arxiv.org/abs/2507.23632", "authors": ["Gabriel Mongaras", "Eric C. Larson"], "title": "On the Expressiveness of Softmax Attention: A Recurrent Neural Network Perspective", "categories": ["cs.LG"], "comment": null, "summary": "Since its introduction, softmax attention has become the backbone of modern\ntransformer architectures due to its expressiveness and scalability across a\nwide range of tasks. However, the main drawback of softmax attention is the\nquadratic memory requirement and computational complexity with respect to the\nsequence length. By replacing the softmax nonlinearity, linear attention and\nsimilar methods have been introduced to avoid the quadratic bottleneck of\nsoftmax attention. Despite these linear forms of attention being derived from\nthe original softmax formulation, they typically lag in terms of downstream\naccuracy. While strong intuition of the softmax nonlinearity on the query and\nkey inner product suggests that it has desirable properties compared to other\nnonlinearities, the question of why this discrepancy exists still remains\nunanswered. This work demonstrates that linear attention is an approximation of\nsoftmax attention by deriving the recurrent form of softmax attention. Using\nthis form, each part of softmax attention can be described in the language of\nrecurrent neural networks (RNNs). Describing softmax attention as an RNN allows\nfor the ablation of the components of softmax attention to understand the\nimportance of each part and how they interact. In this way, our work helps\nexplain why softmax attention is more expressive than its counterparts."}
{"id": "2507.23638", "pdf": "https://arxiv.org/pdf/2507.23638", "abs": "https://arxiv.org/abs/2507.23638", "authors": ["Mohammad Karami", "Fatemeh Ghassemi", "Hamed Kebriaei", "Hamid Azadegan"], "title": "OptiGradTrust: Byzantine-Robust Federated Learning with Multi-Feature Gradient Analysis and Reinforcement Learning-Based Trust Weighting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Federated Learning (FL) enables collaborative model training across\ndistributed medical institutions while preserving patient privacy, but remains\nvulnerable to Byzantine attacks and statistical heterogeneity. We present\nOptiGradTrust, a comprehensive defense framework that evaluates gradient\nupdates through a novel six-dimensional fingerprint including VAE\nreconstruction error, cosine similarity metrics, $L_2$ norm, sign-consistency\nratio, and Monte Carlo Shapley value, which drive a hybrid RL-attention module\nfor adaptive trust scoring. To address convergence challenges under data\nheterogeneity, we develop FedBN-Prox (FedBN-P), combining Federated Batch\nNormalization with proximal regularization for optimal accuracy-convergence\ntrade-offs. Extensive evaluation across MNIST, CIFAR-10, and Alzheimer's MRI\ndatasets under various Byzantine attack scenarios demonstrates significant\nimprovements over state-of-the-art defenses, achieving up to +1.6 percentage\npoints over FLGuard under non-IID conditions while maintaining robust\nperformance against diverse attack patterns through our adaptive learning\napproach."}
{"id": "2507.23665", "pdf": "https://arxiv.org/pdf/2507.23665", "abs": "https://arxiv.org/abs/2507.23665", "authors": ["Amal Saadallah"], "title": "SHAP-Guided Regularization in Machine Learning Models", "categories": ["cs.LG"], "comment": null, "summary": "Feature attribution methods such as SHapley Additive exPlanations (SHAP) have\nbecome instrumental in understanding machine learning models, but their role in\nguiding model optimization remains underexplored. In this paper, we propose a\nSHAP-guided regularization framework that incorporates feature importance\nconstraints into model training to enhance both predictive performance and\ninterpretability. Our approach applies entropy-based penalties to encourage\nsparse, concentrated feature attributions while promoting stability across\nsamples. The framework is applicable to both regression and classification\ntasks. Our first exploration started with investigating a tree-based model\nregularization using TreeSHAP. Through extensive experiments on benchmark\nregression and classification datasets, we demonstrate that our method improves\ngeneralization performance while ensuring robust and interpretable feature\nattributions. The proposed technique offers a novel, explainability-driven\nregularization approach, making machine learning models both more accurate and\nmore reliable."}
{"id": "2507.23674", "pdf": "https://arxiv.org/pdf/2507.23674", "abs": "https://arxiv.org/abs/2507.23674", "authors": ["Muhammad Taha Cheema", "Abeer Aamir", "Khawaja Gul Muhammad", "Naveed Anwar Bhatti", "Ihsan Ayyub Qazi", "Zafar Ayyub Qazi"], "title": "TweakLLM: A Routing Architecture for Dynamic Tailoring of Cached Responses", "categories": ["cs.LG", "cs.CL"], "comment": "13 pages, 9 figures", "summary": "Large Language Models (LLMs) process millions of queries daily, making\nefficient response caching a compelling optimization for reducing cost and\nlatency. However, preserving relevance to user queries using this approach\nproves difficult due to the personalized nature of chatbot interactions and the\nlimited accuracy of semantic similarity search. To address this, we present\nTweakLLM, a novel routing architecture that employs a lightweight LLM to\ndynamically adapt cached responses to incoming prompts. Through comprehensive\nevaluation, including user studies with side-by-side comparisons, satisfaction\nvoting, as well as multi-agent LLM debates, we demonstrate that TweakLLM\nmaintains response quality comparable to frontier models while significantly\nimproving cache effectiveness. Our results across real-world datasets highlight\nTweakLLM as a scalable, resource-efficient caching solution for high-volume LLM\ndeployments without compromising user experience."}
{"id": "2507.23675", "pdf": "https://arxiv.org/pdf/2507.23675", "abs": "https://arxiv.org/abs/2507.23675", "authors": ["Tianyi Chen", "Haitong Ma", "Na Li", "Kai Wang", "Bo Dai"], "title": "One-Step Flow Policy Mirror Descent", "categories": ["cs.LG"], "comment": null, "summary": "Diffusion policies have achieved great success in online reinforcement\nlearning (RL) due to their strong expressive capacity. However, the inference\nof diffusion policy models relies on a slow iterative sampling process, which\nlimits their responsiveness. To overcome this limitation, we propose Flow\nPolicy Mirror Descent (FPMD), an online RL algorithm that enables 1-step\nsampling during policy inference. Our approach exploits a theoretical\nconnection between the distribution variance and the discretization error of\nsingle-step sampling in straight interpolation flow matching models, and\nrequires no extra distillation or consistency training. We present two\nalgorithm variants based on flow policy and MeanFlow policy parametrizations,\nrespectively. Extensive empirical evaluations on MuJoCo benchmarks demonstrate\nthat our algorithms show strong performance comparable to diffusion policy\nbaselines while requiring hundreds of times fewer function evaluations during\ninference."}
{"id": "2507.23676", "pdf": "https://arxiv.org/pdf/2507.23676", "abs": "https://arxiv.org/abs/2507.23676", "authors": ["Rabeya Tus Sadia", "Qiang Cheng"], "title": "DepMicroDiff: Diffusion-Based Dependency-Aware Multimodal Imputation for Microbiome Data", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Microbiome data analysis is essential for understanding host health and\ndisease, yet its inherent sparsity and noise pose major challenges for accurate\nimputation, hindering downstream tasks such as biomarker discovery. Existing\nimputation methods, including recent diffusion-based models, often fail to\ncapture the complex interdependencies between microbial taxa and overlook\ncontextual metadata that can inform imputation. We introduce DepMicroDiff, a\nnovel framework that combines diffusion-based generative modeling with a\nDependency-Aware Transformer (DAT) to explicitly capture both mutual pairwise\ndependencies and autoregressive relationships. DepMicroDiff is further enhanced\nby VAE-based pretraining across diverse cancer datasets and conditioning on\npatient metadata encoded via a large language model (LLM). Experiments on TCGA\nmicrobiome datasets show that DepMicroDiff substantially outperforms\nstate-of-the-art baselines, achieving higher Pearson correlation (up to 0.712),\ncosine similarity (up to 0.812), and lower RMSE and MAE across multiple cancer\ntypes, demonstrating its robustness and generalizability for microbiome\nimputation."}
{"id": "2507.23712", "pdf": "https://arxiv.org/pdf/2507.23712", "abs": "https://arxiv.org/abs/2507.23712", "authors": ["Aymane Abdali", "Bartosz Boguslawski", "Lucas Drumetz", "Vincent Gripon"], "title": "Anomalous Samples for Few-Shot Anomaly Detection", "categories": ["cs.LG"], "comment": null, "summary": "Several anomaly detection and classification methods rely on large amounts of\nnon-anomalous or \"normal\" samples under the assump- tion that anomalous data is\ntypically harder to acquire. This hypothesis becomes questionable in Few-Shot\nsettings, where as little as one anno- tated sample can make a significant\ndifference. In this paper, we tackle the question of utilizing anomalous\nsamples in training a model for bi- nary anomaly classification. We propose a\nmethodology that incorporates anomalous samples in a multi-score anomaly\ndetection score leveraging recent Zero-Shot and memory-based techniques. We\ncompare the utility of anomalous samples to that of regular samples and study\nthe benefits and limitations of each. In addition, we propose an\naugmentation-based validation technique to optimize the aggregation of the\ndifferent anomaly scores and demonstrate its effectiveness on popular\nindustrial anomaly detection datasets."}
{"id": "2507.23756", "pdf": "https://arxiv.org/pdf/2507.23756", "abs": "https://arxiv.org/abs/2507.23756", "authors": ["Diana Mortagua"], "title": "Improving annotator selection in Active Learning using a mood and fatigue-aware Recommender System", "categories": ["cs.LG", "cs.HC"], "comment": null, "summary": "This study centers on overcoming the challenge of selecting the best\nannotators for each query in Active Learning (AL), with the objective of\nminimizing misclassifications. AL recognizes the challenges related to cost and\ntime when acquiring labeled data, and decreases the number of labeled data\nneeded. Nevertheless, there is still the necessity to reduce annotation errors,\naiming to be as efficient as possible, to achieve the expected accuracy faster.\nMost strategies for query-annotator pairs do not consider internal factors that\naffect productivity, such as mood, attention, motivation, and fatigue levels.\nThis work addresses this gap in the existing literature, by not only\nconsidering how the internal factors influence annotators (mood and fatigue\nlevels) but also presenting a new query-annotator pair strategy, using a\nKnowledge-Based Recommendation System (RS). The RS ranks the available\nannotators, allowing to choose one or more to label the queried instance using\ntheir past accuracy values, and their mood and fatigue levels, as well as\ninformation about the instance queried. This work bases itself on existing\nliterature on mood and fatigue influence on human performance, simulating\nannotators in a realistic manner, and predicting their performance with the RS.\nThe results show that considering past accuracy values, as well as mood and\nfatigue levels reduces the number of annotation errors made by the annotators,\nand the uncertainty of the model through its training, when compared to not\nusing internal factors. Accuracy and F1-score values were also better in the\nproposed approach, despite not being as substantial as the aforementioned. The\nmethodologies and findings presented in this study begin to explore the open\nchallenge of human cognitive factors affecting AL."}
{"id": "2507.23771", "pdf": "https://arxiv.org/pdf/2507.23771", "abs": "https://arxiv.org/abs/2507.23771", "authors": ["Justin Kay", "Grant Van Horn", "Subhransu Maji", "Daniel Sheldon", "Sara Beery"], "title": "Consensus-Driven Active Model Selection", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "ICCV 2025 Highlight. 16 pages, 8 figures", "summary": "The widespread availability of off-the-shelf machine learning models poses a\nchallenge: which model, of the many available candidates, should be chosen for\na given data analysis task? This question of model selection is traditionally\nanswered by collecting and annotating a validation dataset -- a costly and\ntime-intensive process. We propose a method for active model selection, using\npredictions from candidate models to prioritize the labeling of test data\npoints that efficiently differentiate the best candidate. Our method, CODA,\nperforms consensus-driven active model selection by modeling relationships\nbetween classifiers, categories, and data points within a probabilistic\nframework. The framework uses the consensus and disagreement between models in\nthe candidate pool to guide the label acquisition process, and Bayesian\ninference to update beliefs about which model is best as more information is\ncollected. We validate our approach by curating a collection of 26 benchmark\ntasks capturing a range of model selection scenarios. CODA outperforms existing\nmethods for active model selection significantly, reducing the annotation\neffort required to discover the best model by upwards of 70% compared to the\nprevious state-of-the-art. Code and data are available at\nhttps://github.com/justinkay/coda."}
{"id": "1908.01212", "pdf": "https://arxiv.org/pdf/1908.01212", "abs": "https://arxiv.org/abs/1908.01212", "authors": ["Fatimah Rita Ahmadi"], "title": "Typing Tensor Calculus in 2-Categories (I)", "categories": ["math.CT", "cs.LG", "cs.SE"], "comment": "28 pages; extended introduction, more explanation", "summary": "To formalize calculations in linear algebra for the development of efficient\nalgorithms and a framework suitable for functional programming languages and\nfaster parallelized computations, we adopt an approach that treats elements of\nlinear algebra, such as matrices, as morphisms in the category of matrices,\n$\\mathbf{Mat_{k}}$. This framework is further extended by generalizing the\nresults to arbitrary monoidal semiadditive categories. To enrich this\nperspective and accommodate higher-rank matrices (tensors), we define\nsemiadditive 2-categories, where matrices $T_{ij}$ are represented as\n1-morphisms, and tensors with four indices $T_{ijkl}$ as 2-morphisms. This\nformalization provides an index-free, typed linear algebra framework that\nincludes matrices and tensors with up to four indices. Furthermore, we extend\nthe framework to monoidal semiadditive 2-categories and demonstrate detailed\noperations and vectorization within the 2-category of 2Vec introduced by\nKapranov and Voevodsky."}
{"id": "2507.22906", "pdf": "https://arxiv.org/pdf/2507.22906", "abs": "https://arxiv.org/abs/2507.22906", "authors": ["Bin Deng", "Jiatong Bai", "Feilong Zhao", "Zuming Xie", "Maolin Li", "Yan Wang", "Feng Shu"], "title": "DNN-based Methods of Jointly Sensing Number and Directions of Targets via a Green Massive H2AD MIMO Receiver", "categories": ["eess.SP", "cs.AI", "cs.IT", "cs.LG", "math.IT"], "comment": null, "summary": "As a green MIMO structure, the heterogeneous hybrid analog-digital H2AD MIMO\narchitecture has been shown to own a great potential to replace the massive or\nextremely large-scale fully-digital MIMO in the future wireless networks to\naddress the three challenging problems faced by the latter: high energy\nconsumption, high circuit cost, and high complexity. However, how to\nintelligently sense the number and direction of multi-emitters via such a\nstructure is still an open hard problem. To address this, we propose a\ntwo-stage sensing framework that jointly estimates the number and direction\nvalues of multiple targets. Specifically, three target number sensing methods\nare designed: an improved eigen-domain clustering (EDC) framework, an enhanced\ndeep neural network (DNN) based on five key statistical features, and an\nimproved one-dimensional convolutional neural network (1D-CNN) utilizing full\neigenvalues. Subsequently, a low-complexity and high-accuracy DOA estimation is\nachieved via the introduced online micro-clustering (OMC-DOA) method.\nFurthermore, we derive the Cram\\'er-Rao lower bound (CRLB) for the H2AD under\nmultiple-source conditions as a theoretical performance benchmark. Simulation\nresults show that the developed three methods achieve 100\\% number of targets\nsensing at moderate-to-high SNRs, while the improved 1D-CNN exhibits superior\nunder extremely-low SNR conditions. The introduced OMC-DOA outperforms existing\nclustering and fusion-based DOA methods in multi-source environments."}
{"id": "2507.22908", "pdf": "https://arxiv.org/pdf/2507.22908", "abs": "https://arxiv.org/abs/2507.22908", "authors": ["Abhishek Sawaika", "Swetang Krishna", "Tushar Tomar", "Durga Pritam Suggisetti", "Aditi Lal", "Tanmaya Shrivastav", "Nouhaila Innan", "Muhammad Shafique"], "title": "A Privacy-Preserving Federated Framework with Hybrid Quantum-Enhanced Learning for Financial Fraud Detection", "categories": ["q-fin.CP", "cs.AI", "cs.LG", "I.2"], "comment": "To be published in proceedings of IEEE International Conference on\n  Quantum Computing and Engineering (QCE) 2025", "summary": "Rapid growth of digital transactions has led to a surge in fraudulent\nactivities, challenging traditional detection methods in the financial sector.\nTo tackle this problem, we introduce a specialised federated learning framework\nthat uniquely combines a quantum-enhanced Long Short-Term Memory (LSTM) model\nwith advanced privacy preserving techniques. By integrating quantum layers into\nthe LSTM architecture, our approach adeptly captures complex\ncross-transactional patters, resulting in an approximate 5% performance\nimprovement across key evaluation metrics compared to conventional models.\nCentral to our framework is \"FedRansel\", a novel method designed to defend\nagainst poisoning and inference attacks, thereby reducing model degradation and\ninference accuracy by 4-8%, compared to standard differential privacy\nmechanisms. This pseudo-centralised setup with a Quantum LSTM model, enhances\nfraud detection accuracy and reinforces the security and confidentiality of\nsensitive financial data."}
{"id": "2507.22912", "pdf": "https://arxiv.org/pdf/2507.22912", "abs": "https://arxiv.org/abs/2507.22912", "authors": ["Navid Yazdanjue", "Morteza Rakhshaninejad", "Hossein Yazdanjouei", "Mohammad Sadegh Khorshidi", "Mikko S. Niemela", "Fang Chen", "Amir H. Gandomi"], "title": "A Language Model-Driven Semi-Supervised Ensemble Framework for Illicit Market Detection Across Deep/Dark Web and Social Platforms", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T07, 68T50"], "comment": "16 pages, 5 figures, 9 tables", "summary": "Illegal marketplaces have increasingly shifted to concealed parts of the\ninternet, including the deep and dark web, as well as platforms such as\nTelegram, Reddit, and Pastebin. These channels enable the anonymous trade of\nillicit goods including drugs, weapons, and stolen credentials. Detecting and\ncategorizing such content remains challenging due to limited labeled data, the\nevolving nature of illicit language, and the structural heterogeneity of online\nsources. This paper presents a hierarchical classification framework that\ncombines fine-tuned language models with a semi-supervised ensemble learning\nstrategy to detect and classify illicit marketplace content across diverse\nplatforms. We extract semantic representations using ModernBERT, a transformer\nmodel for long documents, finetuned on domain-specific data from deep and dark\nweb pages, Telegram channels, Subreddits, and Pastebin pastes to capture\nspecialized jargon and ambiguous linguistic patterns. In addition, we\nincorporate manually engineered features such as document structure, embedded\npatterns including Bitcoin addresses, emails, and IPs, and metadata, which\ncomplement language model embeddings. The classification pipeline operates in\ntwo stages. The first stage uses a semi-supervised ensemble of XGBoost, Random\nForest, and SVM with entropy-based weighted voting to detect sales-related\ndocuments. The second stage further classifies these into drug, weapon, or\ncredential sales. Experiments on three datasets, including our multi-source\ncorpus, DUTA, and CoDA, show that our model outperforms several baselines,\nincluding BERT, ModernBERT, DarkBERT, ALBERT, Longformer, and BigBird. The\nmodel achieves an accuracy of 0.96489, an F1-score of 0.93467, and a TMCC of\n0.95388, demonstrating strong generalization, robustness under limited\nsupervision, and effectiveness in real-world illicit content detection."}
{"id": "2507.22918", "pdf": "https://arxiv.org/pdf/2507.22918", "abs": "https://arxiv.org/abs/2507.22918", "authors": ["Daniel Son", "Sanjana Rathore", "Andrew Rufail", "Adrian Simon", "Daniel Zhang", "Soham Dave", "Cole Blondin", "Kevin Zhu", "Sean O'Brien"], "title": "Semantic Convergence: Investigating Shared Representations Across Scaled LLMs", "categories": ["cs.CL", "cs.LG", "68T50", "I.2.6; I.2.7"], "comment": "Submitted to ACL 2025 Student Research Workshop (poster)", "summary": "We investigate feature universality in Gemma-2 language models (Gemma-2-2B\nand Gemma-2-9B), asking whether models with a four-fold difference in scale\nstill converge on comparable internal concepts. Using the Sparse Autoencoder\n(SAE) dictionary-learning pipeline, we utilize SAEs on each model's\nresidual-stream activations, align the resulting monosemantic features via\nactivation correlation, and compare the matched feature spaces with SVCCA and\nRSA. Middle layers yield the strongest overlap, while early and late layers\nshow far less similarity. Preliminary experiments extend the analysis from\nsingle tokens to multi-token subspaces, showing that semantically similar\nsubspaces interact similarly with language models. These results strengthen the\ncase that large language models carve the world into broadly similar,\ninterpretable features despite size differences, reinforcing universality as a\nfoundation for cross-model interpretability."}
{"id": "2507.22941", "pdf": "https://arxiv.org/pdf/2507.22941", "abs": "https://arxiv.org/abs/2507.22941", "authors": ["Paul Minchella", "Loïc Verlingue", "Stéphane Chrétien", "Rémi Vaucher", "Guillaume Metzler"], "title": "SigBERT: Combining Narrative Medical Reports and Rough Path Signature Theory for Survival Risk Estimation in Oncology", "categories": ["cs.CL", "cs.CY", "cs.LG", "stat.AP"], "comment": "12 pages, 2 figures, accepted for ECML PKDD 2025", "summary": "Electronic medical reports (EHR) contain a vast amount of information that\ncan be leveraged for machine learning applications in healthcare. However,\nexisting survival analysis methods often struggle to effectively handle the\ncomplexity of textual data, particularly in its sequential form. Here, we\npropose SigBERT, an innovative temporal survival analysis framework designed to\nefficiently process a large number of clinical reports per patient. SigBERT\nprocesses timestamped medical reports by extracting and averaging word\nembeddings into sentence embeddings. To capture temporal dynamics from the time\nseries of sentence embedding coordinates, we apply signature extraction from\nrough path theory to derive geometric features for each patient, which\nsignificantly enhance survival model performance by capturing complex temporal\ndynamics. These features are then integrated into a LASSO-penalized Cox model\nto estimate patient-specific risk scores. The model was trained and evaluated\non a real-world oncology dataset from the L\\'eon B\\'erard Center corpus, with a\nC-index score of 0.75 (sd 0.014) on the independent test cohort. SigBERT\nintegrates sequential medical data to enhance risk estimation, advancing\nnarrative-based survival analysis."}
{"id": "2507.22947", "pdf": "https://arxiv.org/pdf/2507.22947", "abs": "https://arxiv.org/abs/2507.22947", "authors": ["Shou'ang Wei", "Xinyun Wang", "Shuzhen Bi", "Jian Chen", "Ruijia Li", "Bo Jiang", "Xin Lin", "Min Zhang", "Yu Song", "BingDong Li", "Aimin Zhou", "Hao Hao"], "title": "ELMES: An Automated Framework for Evaluating Large Language Models in Educational Scenarios", "categories": ["cs.CY", "cs.CL", "cs.LG"], "comment": null, "summary": "The emergence of Large Language Models (LLMs) presents transformative\nopportunities for education, generating numerous novel application scenarios.\nHowever, significant challenges remain: evaluation metrics vary substantially\nacross different educational scenarios, while many emerging scenarios lack\nappropriate assessment metrics. Current benchmarks predominantly measure\ngeneral intelligence rather than pedagogical capabilities. To address this gap,\nwe introduce ELMES, an open-source automated evaluation framework specifically\ndesigned for assessing LLMs in educational settings. ELMES features a modular\narchitecture that enables researchers to create dynamic, multi-agent dialogues\nthrough simple configuration files, facilitating flexible scenario design\nwithout requiring extensive programming expertise. The framework incorporates a\nhybrid evaluation engine that objectively quantifies traditionally subjective\npedagogical metrics using an LLM-as-a-Judge methodology. We conduct systematic\nbenchmarking of state-of-the-art LLMs across four critical educational\nscenarios: Knowledge Point Explanation, Guided Problem-Solving Teaching,\nInterdisciplinary Lesson Plan Generation, and Contextualized Question\nGeneration, employing fine-grained metrics developed in collaboration with\neducation specialists. Our results demonstrate distinct capability\ndistributions among models, revealing context-specific strengths and\nlimitations. ELMES provides educators and researchers with an accessible\nevaluation framework that significantly reduces adaptation barriers for diverse\neducational applications while advancing the practical implementation of LLMs\nin pedagogy. The framework is publicly available at\n\\emph{https://github.com/sii-research/elmes.git}."}
{"id": "2507.22951", "pdf": "https://arxiv.org/pdf/2507.22951", "abs": "https://arxiv.org/abs/2507.22951", "authors": ["Alessandro Lonardi", "Samy Badreddine", "Tarek R. Besold", "Pablo Sanchez Martin"], "title": "Unifying Post-hoc Explanations of Knowledge Graph Completions", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Post-hoc explainability for Knowledge Graph Completion (KGC) lacks\nformalization and consistent evaluations, hindering reproducibility and\ncross-study comparisons. This paper argues for a unified approach to post-hoc\nexplainability in KGC. First, we propose a general framework to characterize\npost-hoc explanations via multi-objective optimization, balancing their\neffectiveness and conciseness. This unifies existing post-hoc explainability\nalgorithms in KGC and the explanations they produce. Next, we suggest and\nempirically support improved evaluation protocols using popular metrics like\nMean Reciprocal Rank and Hits@$k$. Finally, we stress the importance of\ninterpretability as the ability of explanations to address queries meaningful\nto end-users. By unifying methods and refining evaluation standards, this work\naims to make research in KGC explainability more reproducible and impactful."}
{"id": "2507.22952", "pdf": "https://arxiv.org/pdf/2507.22952", "abs": "https://arxiv.org/abs/2507.22952", "authors": ["Harry Shomer", "Jiejun Xu"], "title": "Automated Label Placement on Maps via Large Language Models", "categories": ["cs.HC", "cs.CV", "cs.LG"], "comment": "Workshop on AI for Data Editing (AI4DE) at KDD 2025", "summary": "Label placement is a critical aspect of map design, serving as a form of\nspatial annotation that directly impacts clarity and interpretability. Despite\nits importance, label placement remains largely manual and difficult to scale,\nas existing automated systems struggle to integrate cartographic conventions,\nadapt to context, or interpret labeling instructions. In this work, we\nintroduce a new paradigm for automatic label placement (ALP) that formulates\nthe task as a data editing problem and leverages large language models (LLMs)\nfor context-aware spatial annotation. To support this direction, we curate\nMAPLE, the first known benchmarking dataset for evaluating ALP on real-world\nmaps, encompassing diverse landmark types and label placement annotations from\nopen-source data. Our method retrieves labeling guidelines relevant to each\nlandmark type leveraging retrieval-augmented generation (RAG), integrates them\ninto prompts, and employs instruction-tuned LLMs to generate ideal label\ncoordinates. We evaluate four open-source LLMs on MAPLE, analyzing both overall\nperformance and generalization across different types of landmarks. This\nincludes both zero-shot and instruction-tuned performance. Our results\ndemonstrate that LLMs, when guided by structured prompts and domain-specific\nretrieval, can learn to perform accurate spatial edits, aligning the generated\noutputs with expert cartographic standards. Overall, our work presents a\nscalable framework for AI-assisted map finishing and demonstrates the potential\nof foundation models in structured data editing tasks. The code and data can be\nfound at https://github.com/HarryShomer/MAPLE."}
{"id": "2507.22955", "pdf": "https://arxiv.org/pdf/2507.22955", "abs": "https://arxiv.org/abs/2507.22955", "authors": ["Ekta Gujral", "Apurva Sinha"], "title": "LLMs Between the Nodes: Community Discovery Beyond Vectors", "categories": ["cs.SI", "cs.LG"], "comment": null, "summary": "Community detection in social network graphs plays a vital role in uncovering\ngroup dynamics, influence pathways, and the spread of information. Traditional\nmethods focus primarily on graph structural properties, but recent advancements\nin Large Language Models (LLMs) open up new avenues for integrating semantic\nand contextual information into this task. In this paper, we present a detailed\ninvestigation into how various LLM-based approaches perform in identifying\ncommunities within social graphs. We introduce a two-step framework called\nCommLLM, which leverages the GPT-4o model along with prompt-based reasoning to\nfuse language model outputs with graph structure. Evaluations are conducted on\nsix real-world social network datasets, measuring performance using key metrics\nsuch as Normalized Mutual Information (NMI), Adjusted Rand Index (ARI),\nVariation of Information (VOI), and cluster purity. Our findings reveal that\nLLMs, particularly when guided by graph-aware strategies, can be successfully\napplied to community detection tasks in small to medium-sized graphs. We\nobserve that the integration of instruction-tuned models and carefully\nengineered prompts significantly improves the accuracy and coherence of\ndetected communities. These insights not only highlight the potential of LLMs\nin graph-based research but also underscore the importance of tailoring model\ninteractions to the specific structure of graph data."}
{"id": "2507.22958", "pdf": "https://arxiv.org/pdf/2507.22958", "abs": "https://arxiv.org/abs/2507.22958", "authors": ["Ruslan Khrulev"], "title": "CHECK-MAT: Checking Hand-Written Mathematical Answers for the Russian Unified State Exam", "categories": ["cs.CV", "cs.AI", "cs.LG", "68T07, 97D50", "I.2.7; I.4; K.3.1"], "comment": "15 pages, 3 figures, 10 tables. Code is available at:\n  https://github.com/Karifannaa/Auto-check-EGE-math", "summary": "This paper introduces a novel benchmark, EGE-Math Solutions Assessment\nBenchmark, for evaluating Vision-Language Models (VLMs) on their ability to\nassess hand-written mathematical solutions. Unlike existing benchmarks that\nfocus on problem solving, our approach centres on understanding student\nsolutions, identifying mistakes, and assigning grades according to fixed\ncriteria. We compile 122 scanned solutions from the Russian Unified State Exam\n(EGE) together with official expert grades, and evaluate seven modern VLMs from\nGoogle, OpenAI, Arcee AI, and Alibaba Cloud in three inference modes. The\nresults reveal current limitations in mathematical reasoning and human-rubric\nalignment, opening new research avenues in AI-assisted assessment. You can find\ncode in https://github.com/Karifannaa/Auto-check-EGE-math"}
{"id": "2507.23015", "pdf": "https://arxiv.org/pdf/2507.23015", "abs": "https://arxiv.org/abs/2507.23015", "authors": ["Abhinav Jain", "Cindy Grimm", "Stefan Lee"], "title": "Learning to Prune Branches in Modern Tree-Fruit Orchards", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Dormant tree pruning is labor-intensive but essential to maintaining modern\nhighly-productive fruit orchards. In this work we present a closed-loop\nvisuomotor controller for robotic pruning. The controller guides the cutter\nthrough a cluttered tree environment to reach a specified cut point and ensures\nthe cutters are perpendicular to the branch. We train the controller using a\nnovel orchard simulation that captures the geometric distribution of branches\nin a target apple orchard configuration. Unlike traditional methods requiring\nfull 3D reconstruction, our controller uses just optical flow images from a\nwrist-mounted camera. We deploy our learned policy in simulation and the\nreal-world for an example V-Trellis envy tree with zero-shot transfer,\nachieving a 30% success rate -- approximately half the performance of an oracle\nplanner."}
{"id": "2507.23017", "pdf": "https://arxiv.org/pdf/2507.23017", "abs": "https://arxiv.org/abs/2507.23017", "authors": ["Tyler Maunu", "Gabriel Abreu"], "title": "A Smoothing Newton Method for Rank-one Matrix Recovery", "categories": ["stat.ML", "cs.LG", "math.OC"], "comment": "12 pages, 4 figures", "summary": "We consider the phase retrieval problem, which involves recovering a rank-one\npositive semidefinite matrix from rank-one measurements. A recently proposed\nalgorithm based on Bures-Wasserstein gradient descent (BWGD) exhibits\nsuperlinear convergence, but it is unstable, and existing theory can only prove\nlocal linear convergence for higher rank matrix recovery. We resolve this gap\nby revealing that BWGD implements Newton's method with a nonsmooth and\nnonconvex objective. We develop a smoothing framework that regularizes the\nobjective, enabling a stable method with rigorous superlinear convergence\nguarantees. Experiments on synthetic data demonstrate this superior stability\nwhile maintaining fast convergence."}
{"id": "2507.23018", "pdf": "https://arxiv.org/pdf/2507.23018", "abs": "https://arxiv.org/abs/2507.23018", "authors": ["Wesley Brewer", "Patrick Widener", "Valentine Anantharaj", "Feiyi Wang", "Tom Beck", "Arjun Shankar", "Sarp Oral"], "title": "Data Readiness for Scientific AI at Scale", "categories": ["cs.AI", "cs.CE", "cs.DC", "cs.LG", "I.2.6"], "comment": "10 pages, 1 figure, 2 tables", "summary": "This paper examines how Data Readiness for AI (DRAI) principles apply to\nleadership-scale scientific datasets used to train foundation models. We\nanalyze archetypal workflows across four representative domains - climate,\nnuclear fusion, bio/health, and materials - to identify common preprocessing\npatterns and domain-specific constraints. We introduce a two-dimensional\nreadiness framework composed of Data Readiness Levels (raw to AI-ready) and\nData Processing Stages (ingest to shard), both tailored to high performance\ncomputing (HPC) environments. This framework outlines key challenges in\ntransforming scientific data for scalable AI training, emphasizing\ntransformer-based generative models. Together, these dimensions form a\nconceptual maturity matrix that characterizes scientific data readiness and\nguides infrastructure development toward standardized, cross-domain support for\nscalable and reproducible AI for science."}
{"id": "2507.23042", "pdf": "https://arxiv.org/pdf/2507.23042", "abs": "https://arxiv.org/abs/2507.23042", "authors": ["Santosh Patapati", "Trisanth Srinivasan"], "title": "Early Goal-Guided Multi-Scale Fusion for Real-Time Vision-Language Driving", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM", "cs.RO", "I.2.6; I.2.9; I.2.10; C.3.3"], "comment": "6 pages", "summary": "Autonomous vehicles must react in milliseconds while reasoning about road\ngeometry and traffic intent to navigate complex situations. We introduce\nNovaDrive, a single-branch vision-language architecture that processes\nfront-camera images, HD-map tiles, LiDAR depth, and textual waypoints in a\nsingle branch. A lightweight, two-stage cross-attention block first aligns\nwaypoint tokens with the HD map, then refines attention over fine-grained image\nand depth patches. Coupled with a novel smoothness loss that discourages abrupt\nsteering and speed changes, this design eliminates the need for recurrent\nmemory. We fine-tune the top 15 layers of an 11B LLaMA-3.2 vision-language\nbackbone, enabling real-time inference. On the nuScenes / Waymo subset of the\nMD-NEX Outdoor benchmark, NovaDrive raises success rate to 84% (+4%), boosts\npath-efficiency (SPL) to 0.66 (+0.11), and reduces collision frequency from\n2.6% to 1.2% (-1.4%) relative to the previous state-of-the-art. Our ablations\nconfirm that waypoint tokens, partial VLM fine-tuning, and the cross-attention\nfusion each contribute the most to these gains. Beyond safety, NovaDrive's\nshorter routes (resulting from the novel smoothness loss) translate to lower\nfuel or battery usage, pointing toward leaner, more easily updated driving\nstacks. NovaDrive can be extended to other embodied-AI domains as well."}
{"id": "2507.23064", "pdf": "https://arxiv.org/pdf/2507.23064", "abs": "https://arxiv.org/abs/2507.23064", "authors": ["Santosh Patapati", "Trisanth Srinivasan", "Murari Ambati"], "title": "Vision-Language Fusion for Real-Time Autonomous Driving: Goal-Centered Cross-Attention of Camera, HD-Map, & Waypoints", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO", "I.4.8; I.2.10; I.2.6; C.3.3; I.4.9"], "comment": "5 pages", "summary": "Autonomous cars need geometric accuracy and semantic understanding to\nnavigate complex environments, yet most stacks handle them separately. We\npresent XYZ-Drive, a single vision-language model that reads a front-camera\nframe, a 25m $\\times$ 25m overhead map, and the next waypoint, then outputs\nsteering and speed. A lightweight goal-centered cross-attention layer lets\nwaypoint tokens highlight relevant image and map patches, supporting both\naction and textual explanations, before the fused tokens enter a partially\nfine-tuned LLaMA-3.2 11B model.\n  On the MD-NEX Outdoor-Driving benchmark XYZ-Drive attains 95% success and\n0.80 Success weighted by Path Length (SPL), surpassing PhysNav-DG by 15%. and\nhalving collisions, all while significantly improving efficiency by using only\na single branch. Sixteen ablations explain the gains. Removing any modality\n(vision, waypoint, map) drops success by up to 11%, confirming their\ncomplementary roles and rich connections. Replacing goal-centered attention\nwith simple concatenation cuts 3% in performance, showing query-based fusion\ninjects map knowledge more effectively. Keeping the transformer frozen loses\n5%, showing the importance of fine-tuning when applying VLMs for specific tasks\nsuch as autonomous driving. Coarsening map resolution from 10 cm to 40 cm blurs\nlane edges and raises crash rate.\n  Overall, these results demonstrate that early, token-level fusion of intent\nand map layout enables accurate, transparent, real-time driving."}
{"id": "2507.23104", "pdf": "https://arxiv.org/pdf/2507.23104", "abs": "https://arxiv.org/abs/2507.23104", "authors": ["Jeffrey Eben", "Aitzaz Ahmad", "Stephen Lau"], "title": "RASL: Retrieval Augmented Schema Linking for Massive Database Text-to-SQL", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Despite advances in large language model (LLM)-based natural language\ninterfaces for databases, scaling to enterprise-level data catalogs remains an\nunder-explored challenge. Prior works addressing this challenge rely on\ndomain-specific fine-tuning - complicating deployment - and fail to leverage\nimportant semantic context contained within database metadata. To address these\nlimitations, we introduce a component-based retrieval architecture that\ndecomposes database schemas and metadata into discrete semantic units, each\nseparately indexed for targeted retrieval. Our approach prioritizes effective\ntable identification while leveraging column-level information, ensuring the\ntotal number of retrieved tables remains within a manageable context budget.\nExperiments demonstrate that our method maintains high recall and accuracy,\nwith our system outperforming baselines over massive databases with varying\nstructure and available metadata. Our solution enables practical text-to-SQL\nsystems deployable across diverse enterprise settings without specialized\nfine-tuning, addressing a critical scalability gap in natural language database\ninterfaces."}
{"id": "2507.23155", "pdf": "https://arxiv.org/pdf/2507.23155", "abs": "https://arxiv.org/abs/2507.23155", "authors": ["Jincheng Cao", "Ruichen Jiang", "Erfan Yazdandoost Hamedani", "Aryan Mokhtari"], "title": "On the Complexity of Finding Stationary Points in Nonconvex Simple Bilevel Optimization", "categories": ["math.OC", "cs.LG"], "comment": null, "summary": "In this paper, we study the problem of solving a simple bilevel optimization\nproblem, where the upper-level objective is minimized over the solution set of\nthe lower-level problem. We focus on the general setting in which both the\nupper- and lower-level objectives are smooth but potentially nonconvex. Due to\nthe absence of additional structural assumptions for the lower-level\nobjective-such as convexity or the Polyak-{\\L}ojasiewicz (PL)\ncondition-guaranteeing global optimality is generally intractable. Instead, we\nintroduce a suitable notion of stationarity for this class of problems and aim\nto design a first-order algorithm that finds such stationary points in\npolynomial time. Intuitively, stationarity in this setting means the\nupper-level objective cannot be substantially improved locally without causing\na larger deterioration in the lower-level objective. To this end, we show that\na simple and implementable variant of the dynamic barrier gradient descent\n(DBGD) framework can effectively solve the considered nonconvex simple bilevel\nproblems up to stationarity. Specifically, to reach an $(\\epsilon_f,\n\\epsilon_g)$-stationary point-where $\\epsilon_f$ and $\\epsilon_g$ denote the\ntarget stationarity accuracies for the upper- and lower-level objectives,\nrespectively-the considered method achieves a complexity of\n$\\mathcal{O}\\left(\\max\\left(\\epsilon_f^{-\\frac{3+p}{1+p}},\n\\epsilon_g^{-\\frac{3+p}{2}}\\right)\\right)$, where $p \\geq 0$ is an arbitrary\nconstant balancing the terms. To the best of our knowledge, this is the first\ncomplexity result for a discrete-time algorithm that guarantees joint\nstationarity for both levels in general nonconvex simple bilevel problems."}
{"id": "2507.23160", "pdf": "https://arxiv.org/pdf/2507.23160", "abs": "https://arxiv.org/abs/2507.23160", "authors": ["Daisuke Makino", "Tatsuya Goto", "Yoshinori Suga"], "title": "Extended Factorization Machine Annealing for Rapid Discovery of Transparent Conducting Materials", "categories": ["cond-mat.mtrl-sci", "cs.LG"], "comment": "12pages, 6figures", "summary": "The development of novel transparent conducting materials (TCMs) is essential\nfor enhancing the performance and reducing the cost of next-generation devices\nsuch as solar cells and displays. In this research, we focus on the\n(Al$_x$Ga$_y$In$_z$)$_2$O$_3$ system and extend the FMA framework, which\ncombines a Factorization Machine (FM) and annealing, to search for optimal\ncompositions and crystal structures with high accuracy and low cost. The\nproposed method introduces (i) the binarization of continuous variables, (ii)\nthe utilization of good solutions using a Hopfield network, (iii) the\nactivation of global search through adaptive random flips, and (iv) fine-tuning\nvia a bit-string local search. Validation using the\n(Al$_x$Ga$_y$In$_z$)$_2$O$_3$ data from the Kaggle \"Nomad2018 Predicting\nTransparent Conductors\" competition demonstrated that our method achieves\nfaster and more accurate searches than Bayesian optimization and genetic\nalgorithms. Furthermore, its application to multi-objective optimization showed\nits capability in designing materials by simultaneously considering both the\nband gap and formation energy. These results suggest that applying our method\nto larger, more complex search problems and diverse material designs that\nreflect realistic experimental conditions is expected to contribute to the\nfurther advancement of materials informatics."}
{"id": "2507.23167", "pdf": "https://arxiv.org/pdf/2507.23167", "abs": "https://arxiv.org/abs/2507.23167", "authors": ["Jizhou Guo"], "title": "LENS: Learning Ensemble Confidence from Neural States for Multi-LLM Answer Integration", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.MA"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated impressive performance across\nvarious tasks, with different models excelling in distinct domains and specific\nabilities. Effectively combining the predictions of multiple LLMs is crucial\nfor enhancing system robustness and performance. However, existing ensemble\nmethods often rely on simple techniques like voting or logits ensembling, which\noverlook the varying confidence and reliability of models in different\ncontexts. In this work, we propose LENS (Learning ENsemble confidence from\nNeural States), a novel approach that learns to estimate model confidence by\nanalyzing internal representations. For each LLM, we train a lightweight linear\nconfidence predictor that leverages layer-wise hidden states and normalized\nprobabilities as inputs. This allows for more nuanced weighting of model\npredictions based on their context-dependent reliability. Our method does not\nrequire modifying the model parameters and requires negligible additional\ncomputation. Experimental results on multiple-choice and boolean\nquestion-answering tasks demonstrate that LENS outperforms traditional ensemble\nmethods by a substantial margin. Our findings suggest that internal\nrepresentations provide valuable signals for determining model confidence and\ncan be effectively leveraged for ensemble learning."}
{"id": "2507.23174", "pdf": "https://arxiv.org/pdf/2507.23174", "abs": "https://arxiv.org/abs/2507.23174", "authors": ["Beatriz Díaz Peón", "Jorge Torres Gómez", "Ariel Fajardo Márquez"], "title": "CNN-based solution for mango classification in agricultural environments", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "This article exemplifies the design of a fruit detection and classification\nsystem using Convolutional\n  Neural Networks (CNN). The goal is to develop a system that automatically\nassesses fruit quality for\n  farm inventory management. Specifically, a method for mango fruit\nclassification was developed using\n  image processing, ensuring both accuracy and efficiency. Resnet-18 was\nselected as the preliminary\n  architecture for classification, while a cascade detector was used for\ndetection, balancing execution speed\n  and computational resource consumption. Detection and classification results\nwere displayed through a\n  graphical interface developed in MatLab App Designer, streamlining system\ninteraction. The integration\n  of convolutional neural networks and cascade detectors proffers a reliable\nsolution for fruit classification\n  and detection, with potential applications in agricultural quality control."}
{"id": "2507.23194", "pdf": "https://arxiv.org/pdf/2507.23194", "abs": "https://arxiv.org/abs/2507.23194", "authors": ["Jianghui Wang", "Vinay Joshi", "Saptarshi Majumder", "Xu Chao", "Bin Ding", "Ziqiong Liu", "Pratik Prabhanjan Brahma", "Dong Li", "Zicheng Liu", "Emad Barsoum"], "title": "Geak: Introducing Triton Kernel AI Agent & Evaluation Benchmarks", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "The demand for AI-generated GPU kernels is rapidly growing, influenced by the\nneed for scalable, hardware-optimized solutions in both industry and academia.\nAs deep learning workloads grow in complexity and diversity, it is imperative\nto automate low-level kernel development to meet performance and productivity\ndemands. Major cloud providers, semiconductor companies, and research\ninstitutions are now investing heavily in AI-driven code generation for GPUs,\naiming to reduce manual optimization efforts while achieving near-expert\nperformance on hardware like AMD MI300X. The Triton language, a Python-based\nDSL for GPU programming, has emerged as a popular target for such AI-generated\nkernels due to its balance of performance and ease-of-coding. In this work, we\npresent an evaluation suite for Triton-based GPU kernels and GEAK (Generating\nEfficient AI-centric GPU Kernels)-a framework that leverages cutting-edge LLMs\nto generate performant Triton code specifically for AMD GPUs, including the AMD\nMI300X and MI250. GEAK leverages inference-time compute scaling to produce\nTriton-based GPU kernels using a reasoning loop adapted from Reflexion-style\nfeedback mechanisms. On two evaluation benchmarks, GEAK significantly\noutperformed the baselines of directly prompting frontier LLMs as well as\nReflexion-based generation pipelines by achieving correctness up to $63$% and\nexecution speed up of up to $2.59$X. These results highlight the promise of\nGEAK-like agentic code generation for accelerating the adoption of diverse\nhardware platforms and democratizing access to expert-level kernel performance."}
{"id": "2507.23208", "pdf": "https://arxiv.org/pdf/2507.23208", "abs": "https://arxiv.org/abs/2507.23208", "authors": ["Jiayu Li", "Ziyi Ye", "Guohao Jian", "Zhiqiang Guo", "Weizhi Ma", "Qingyao Ai", "Min Zhang"], "title": "Are Recommenders Self-Aware? Label-Free Recommendation Performance Estimation via Model Uncertainty", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "Can a recommendation model be self-aware? This paper investigates the\nrecommender's self-awareness by quantifying its uncertainty, which provides a\nlabel-free estimation of its performance. Such self-assessment can enable more\ninformed understanding and decision-making before the recommender engages with\nany users. To this end, we propose an intuitive and effective method,\nprobability-based List Distribution uncertainty (LiDu). LiDu measures\nuncertainty by determining the probability that a recommender will generate a\ncertain ranking list based on the prediction distributions of individual items.\nWe validate LiDu's ability to represent model self-awareness in two settings:\n(1) with a matrix factorization model on a synthetic dataset, and (2) with\npopular recommendation algorithms on real-world datasets. Experimental results\nshow that LiDu is more correlated with recommendation performance than a series\nof label-free performance estimators. Additionally, LiDu provides valuable\ninsights into the dynamic inner states of models throughout training and\ninference. This work establishes an empirical connection between recommendation\nuncertainty and performance, framing it as a step towards more transparent and\nself-evaluating recommender systems."}
{"id": "2507.23209", "pdf": "https://arxiv.org/pdf/2507.23209", "abs": "https://arxiv.org/abs/2507.23209", "authors": ["Wei-Wei Du", "Takuma Udagawa", "Kei Tateno"], "title": "Not Just What, But When: Integrating Irregular Intervals to LLM for Sequential Recommendation", "categories": ["cs.IR", "cs.LG"], "comment": "Accepted by RecSys 2025 short paper track", "summary": "Time intervals between purchasing items are a crucial factor in sequential\nrecommendation tasks, whereas existing approaches focus on item sequences and\noften overlook by assuming the intervals between items are static. However,\ndynamic intervals serve as a dimension that describes user profiling on not\nonly the history within a user but also different users with the same item\nhistory. In this work, we propose IntervalLLM, a novel framework that\nintegrates interval information into LLM and incorporates the novel\ninterval-infused attention to jointly consider information of items and\nintervals. Furthermore, unlike prior studies that address the cold-start\nscenario only from the perspectives of users and items, we introduce a new\nviewpoint: the interval perspective to serve as an additional metric for\nevaluating recommendation methods on the warm and cold scenarios. Extensive\nexperiments on 3 benchmarks with both traditional- and LLM-based baselines\ndemonstrate that our IntervalLLM achieves not only 4.4% improvements in average\nbut also the best-performing warm and cold scenarios across all users, items,\nand the proposed interval perspectives. In addition, we observe that the cold\nscenario from the interval perspective experiences the most significant\nperformance drop among all recommendation methods. This finding underscores the\nnecessity of further research on interval-based cold challenges and our\nintegration of interval information in the realm of sequential recommendation\ntasks. Our code is available here:\nhttps://github.com/sony/ds-research-code/tree/master/recsys25-IntervalLLM."}
{"id": "2507.23220", "pdf": "https://arxiv.org/pdf/2507.23220", "abs": "https://arxiv.org/abs/2507.23220", "authors": ["Carolina Zheng", "Nicolas Beltran-Velez", "Sweta Karlekar", "Claudia Shi", "Achille Nazaret", "Asif Mallik", "Amir Feder", "David M. Blei"], "title": "Model Directions, Not Words: Mechanistic Topic Models Using Sparse Autoencoders", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Traditional topic models are effective at uncovering latent themes in large\ntext collections. However, due to their reliance on bag-of-words\nrepresentations, they struggle to capture semantically abstract features. While\nsome neural variants use richer representations, they are similarly constrained\nby expressing topics as word lists, which limits their ability to articulate\ncomplex topics. We introduce Mechanistic Topic Models (MTMs), a class of topic\nmodels that operate on interpretable features learned by sparse autoencoders\n(SAEs). By defining topics over this semantically rich space, MTMs can reveal\ndeeper conceptual themes with expressive feature descriptions. Moreover,\nuniquely among topic models, MTMs enable controllable text generation using\ntopic-based steering vectors. To properly evaluate MTM topics against\nword-list-based approaches, we propose \\textit{topic judge}, an LLM-based\npairwise comparison evaluation framework. Across five datasets, MTMs match or\nexceed traditional and neural baselines on coherence metrics, are consistently\npreferred by topic judge, and enable effective steering of LLM outputs."}
{"id": "2507.23227", "pdf": "https://arxiv.org/pdf/2507.23227", "abs": "https://arxiv.org/abs/2507.23227", "authors": ["Sophie Kearney", "Shu Yang", "Zixuan Wen", "Bojian Hou", "Duy Duong-Tran", "Tianlong Chen", "Jason Moore", "Marylyn Ritchie", "Li Shen"], "title": "Enabling Few-Shot Alzheimer's Disease Diagnosis on Tabular Biomarker Data with LLMs", "categories": ["cs.CL", "cs.LG", "q-bio.QM"], "comment": null, "summary": "Early and accurate diagnosis of Alzheimer's disease (AD), a complex\nneurodegenerative disorder, requires analysis of heterogeneous biomarkers\n(e.g., neuroimaging, genetic risk factors, cognitive tests, and cerebrospinal\nfluid proteins) typically represented in a tabular format. With flexible\nfew-shot reasoning, multimodal integration, and natural-language-based\ninterpretability, large language models (LLMs) offer unprecedented\nopportunities for prediction with structured biomedical data. We propose a\nnovel framework called TAP-GPT, Tabular Alzheimer's Prediction GPT, that adapts\nTableGPT2, a multimodal tabular-specialized LLM originally developed for\nbusiness intelligence tasks, for AD diagnosis using structured biomarker data\nwith small sample sizes. Our approach constructs few-shot tabular prompts using\nin-context learning examples from structured biomedical data and finetunes\nTableGPT2 using the parameter-efficient qLoRA adaption for a clinical binary\nclassification task of AD or cognitively normal (CN). The TAP-GPT framework\nharnesses the powerful tabular understanding ability of TableGPT2 and the\nencoded prior knowledge of LLMs to outperform more advanced general-purpose\nLLMs and a tabular foundation model (TFM) developed for prediction tasks. To\nour knowledge, this is the first application of LLMs to the prediction task\nusing tabular biomarker data, paving the way for future LLM-driven multi-agent\nframeworks in biomedical informatics."}
{"id": "2507.23242", "pdf": "https://arxiv.org/pdf/2507.23242", "abs": "https://arxiv.org/abs/2507.23242", "authors": ["Sungguk Cha", "DongWook Kim", "Taeseung Hahn", "Mintae Kim", "Youngsub Han", "Byoung-Ki Jeon"], "title": "Generalized Reinforcement Learning for Retriever-Specific Query Rewriter with Unstructured Real-World Documents", "categories": ["cs.CV", "cs.CL", "cs.LG"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) systems rely heavily on effective query\nformulation to unlock external knowledge, yet optimizing queries for diverse,\nunstructured real-world documents remains a challenge. We introduce\n\\textbf{RL-QR}, a reinforcement learning framework for retriever-specific query\nrewriting that eliminates the need for human-annotated datasets and extends\napplicability to both text-only and multi-modal databases. By synthesizing\nscenario-question pairs and leveraging Generalized Reward Policy Optimization\n(GRPO), RL-QR trains query rewriters tailored to specific retrievers, enhancing\nretrieval performance across varied domains. Experiments on industrial in-house\ndata demonstrate significant improvements, with\n$\\text{RL-QR}_{\\text{multi-modal}}$ achieving an 11\\% relative gain in NDCG@3\nfor multi-modal RAG and $\\text{RL-QR}_{\\text{lexical}}$ yielding a 9\\% gain for\nlexical retrievers. However, challenges persist with semantic and hybrid\nretrievers, where rewriters failed to improve performance, likely due to\ntraining misalignments. Our findings highlight RL-QR's potential to\nrevolutionize query optimization for RAG systems, offering a scalable,\nannotation-free solution for real-world retrieval tasks, while identifying\navenues for further refinement in semantic retrieval contexts."}
{"id": "2507.23248", "pdf": "https://arxiv.org/pdf/2507.23248", "abs": "https://arxiv.org/abs/2507.23248", "authors": ["Shimanto Bhowmik", "Tawsif Tashwar Dipto", "Md Sazzad Islam", "Sheryl Hsu", "Tahsin Reasat"], "title": "Evaluating LLMs' Multilingual Capabilities for Bengali: Benchmark Creation and Performance Analysis", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Bengali is an underrepresented language in NLP research. However, it remains\na challenge due to its unique linguistic structure and computational\nconstraints. In this work, we systematically investigate the challenges that\nhinder Bengali NLP performance by focusing on the absence of standardized\nevaluation benchmarks. We then evaluated 10 recent open source Large Language\nModels (LLMs) in 8 of the translated datasets and performed a comprehensive\nerror analysis to pinpoint their primary failure modes. Our findings reveal\nconsistent performance gaps for Bengali compared to English, particularly for\nsmaller models and specific model families like Mistral. We also identified\npromising robustness in certain architectures, such as DeepSeek, that maintain\nmore stable performance across languages. Our analysis reveals an inverse\nrelationship between tokenization efficiency and LLM accuracy where models tend\nto perform worse when inputs are excessively tokenized, whereas more efficient\n\\& concise tokenization results in improved performance. These findings\nhighlight critical areas where current models fall short and underscore the\nneed for improved dataset quality and evaluation methodologies tailored to\nmultilingual contexts. This work will catalyze further research on NLP for\nunderrepresented languages, helping to democratize access to advanced language\ntechnologies worldwide. The code and dataset used in this research is publicly\navailable at https://github.com/BengaliAI/bn-llm-benchmark."}
{"id": "2507.23297", "pdf": "https://arxiv.org/pdf/2507.23297", "abs": "https://arxiv.org/abs/2507.23297", "authors": ["A. Gavrikov", "A. Serafini", "D. Dolzhikov", "A. Garfagnini", "M. Gonchar", "M. Grassi", "R. Brugnera", "V. Cerrone", "L. V. D'Auria", "R. M. Guizzetti", "L. Lastrucci", "G. Andronico", "V. Antonelli", "A. Barresi", "D. Basilico", "M. Beretta", "A. Bergnoli", "M. Borghesi", "A. Brigatti", "R. Bruno", "A. Budano", "B. Caccianiga", "A. Cammi", "R. Caruso", "D. Chiesa", "C. Clementi", "C. Coletta", "S. Dusini", "A. Fabbri", "G. Felici", "G. Ferrante", "M. G. Giammarchi", "N. Giudice", "N. Guardone", "F. Houria", "C. Landini", "I. Lippi", "L. Loi", "P. Lombardi", "F. Mantovani", "S. M. Mari", "A. Martini", "L. Miramonti", "M. Montuschi", "M. Nastasi", "D. Orestano", "F. Ortica", "A. Paoloni", "L. Pelicci", "E. Percalli", "F. Petrucci", "E. Previtali", "G. Ranucci", "A. C. Re", "B. Ricci", "A. Romani", "C. Sirignano", "M. Sisti", "L. Stanco", "E. Stanescu Farilla", "V. Strati", "M. D. C Torri", "C. Tuvè", "C. Venettacci", "G. Verde", "L. Votano"], "title": "Simulation-based inference for Precision Neutrino Physics through Neural Monte Carlo tuning", "categories": ["physics.data-an", "cs.LG", "hep-ex", "hep-ph", "physics.ins-det"], "comment": null, "summary": "Precise modeling of detector energy response is crucial for next-generation\nneutrino experiments which present computational challenges due to lack of\nanalytical likelihoods. We propose a solution using neural likelihood\nestimation within the simulation-based inference framework. We develop two\ncomplementary neural density estimators that model likelihoods of calibration\ndata: conditional normalizing flows and a transformer-based regressor. We adopt\nJUNO - a large neutrino experiment - as a case study. The energy response of\nJUNO depends on several parameters, all of which should be tuned, given their\nnon-linear behavior and strong correlations in the calibration data. To this\nend, we integrate the modeled likelihoods with Bayesian nested sampling for\nparameter inference, achieving uncertainties limited only by statistics with\nnear-zero systematic biases. The normalizing flows model enables unbinned\nlikelihood analysis, while the transformer provides an efficient binned\nalternative. By providing both options, our framework offers flexibility to\nchoose the most appropriate method for specific needs. Finally, our approach\nestablishes a template for similar applications across experimental neutrino\nand broader particle physics."}
{"id": "2507.23315", "pdf": "https://arxiv.org/pdf/2507.23315", "abs": "https://arxiv.org/abs/2507.23315", "authors": ["Vineet Kumar Rakesh", "Soumya Mazumdar", "Tapas Samanta", "Sarbajit Pal", "Amitabha Das"], "title": "Impact of Hyperparameter Optimization on the Accuracy of Lightweight Deep Learning Models for Real-Time Image Classification", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "13 pages, 4 figures, 4 tables. Includes ablation study and evaluation\n  on 7 lightweight deep learning models. Code and logs available at\n  https://github.com/VineetKumarRakesh/lcnn-opt", "summary": "Lightweight convolutional and transformer-based models have become vital for\nreal-time image classification in resource-constrained applications, such as\nembedded systems and edge devices. This work analyzes the influence of\nhyperparameter adjustment on the accuracy and convergence behavior of seven\nefficient deep learning architectures: EfficientNetV2-S, ConvNeXt-T, MobileViT\nv2 (XXS/XS/S), MobileNetV3-L, TinyViT-21M, and RepVGG-A2. All models are\ntrained on the ImageNet-1K dataset under consistent training settings, with an\nemphasis on real-time practicality. An comprehensive ablation study is\nundertaken to separate the effect of critical hyperparameters, including\nlearning rate schedules, batch sizes, input resolution, data augmentation,\nregularization approaches, and optimizer choice. To assess appropriateness for\nreal-time applications, each model is assessed not only in terms of Top-1 and\nTop-5 classification accuracy, but also in terms of inference time, parameter\ncount, model size, and frames-per-second (FPS) on a GPU-accelerated edge\ndeployment simulation. Results demonstrate that cosine learning rate decay and\nadjustable batch size may greatly boost both accuracy and convergence speed,\nwhile keeping low latency and memory cost. Notably, RepVGG-A2 achieves over 80%\nTop-1 accuracy with efficient inference performance, offering a compelling\nbalance between accuracy and deployment cost for VGG-style models. The results\ngive practical guidance for constructing resource-efficient deep learning\nmodels appropriate for real-time image processing pipelines. All code and\ntraining logs are publicly accessible at\nhttps://github.com/VineetKumarRakesh/lcnn-opt."}
{"id": "2507.23334", "pdf": "https://arxiv.org/pdf/2507.23334", "abs": "https://arxiv.org/abs/2507.23334", "authors": ["Daeyong Kwon", "SeungHeon Doh", "Juhan Nam"], "title": "MUST-RAG: MUSical Text Question Answering with Retrieval Augmented Generation", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "comment": "8 pages, 2 figures", "summary": "Recent advancements in Large language models (LLMs) have demonstrated\nremarkable capabilities across diverse domains. While they exhibit strong\nzero-shot performance on various tasks, LLMs' effectiveness in music-related\napplications remains limited due to the relatively small proportion of\nmusic-specific knowledge in their training data. To address this limitation, we\npropose MusT-RAG, a comprehensive framework based on Retrieval Augmented\nGeneration (RAG) to adapt general-purpose LLMs for text-only music question\nanswering (MQA) tasks. RAG is a technique that provides external knowledge to\nLLMs by retrieving relevant context information when generating answers to\nquestions. To optimize RAG for the music domain, we (1) propose MusWikiDB, a\nmusic-specialized vector database for the retrieval stage, and (2) utilizes\ncontext information during both inference and fine-tuning processes to\neffectively transform general-purpose LLMs into music-specific models. Our\nexperiment demonstrates that MusT-RAG significantly outperforms traditional\nfine-tuning approaches in enhancing LLMs' music domain adaptation capabilities,\nshowing consistent improvements across both in-domain and out-of-domain MQA\nbenchmarks. Additionally, our MusWikiDB proves substantially more effective\nthan general Wikipedia corpora, delivering superior performance and\ncomputational efficiency."}
{"id": "2507.23348", "pdf": "https://arxiv.org/pdf/2507.23348", "abs": "https://arxiv.org/abs/2507.23348", "authors": ["Han Li", "Yuling Shi", "Shaoxin Lin", "Xiaodong Gu", "Heng Lian", "Xin Wang", "Yantao Jia", "Tao Huang", "Qianxiang Wang"], "title": "SWE-Debate: Competitive Multi-Agent Debate for Software Issue Resolution", "categories": ["cs.SE", "cs.CL", "cs.LG"], "comment": "Our code and data are available at\n  https://github.com/YerbaPage/SWE-Debate", "summary": "Issue resolution has made remarkable progress thanks to the advanced\nreasoning capabilities of large language models (LLMs). Recently, agent-based\nframeworks such as SWE-agent have further advanced this progress by enabling\nautonomous, tool-using agents to tackle complex software engineering tasks.\nWhile existing agent-based issue resolution approaches are primarily based on\nagents' independent explorations, they often get stuck in local solutions and\nfail to identify issue patterns that span across different parts of the\ncodebase. To address this limitation, we propose SWE-Debate, a competitive\nmulti-agent debate framework that encourages diverse reasoning paths and\nachieves more consolidated issue localization. SWE-Debate first creates\nmultiple fault propagation traces as localization proposals by traversing a\ncode dependency graph. Then, it organizes a three-round debate among\nspecialized agents, each embodying distinct reasoning perspectives along the\nfault propagation trace. This structured competition enables agents to\ncollaboratively converge on a consolidated fix plan. Finally, this consolidated\nfix plan is integrated into an MCTS-based code modification agent for patch\ngeneration. Experiments on the SWE-bench benchmark show that SWE-Debate\nachieves new state-of-the-art results in open-source agent frameworks and\noutperforms baselines by a large margin."}
{"id": "2507.23349", "pdf": "https://arxiv.org/pdf/2507.23349", "abs": "https://arxiv.org/abs/2507.23349", "authors": ["Wenhai Cui", "Xiaoting Ji", "Wen Su", "Xiaodong Yan", "Xingqiu Zhao"], "title": "Optimal Transport Learning: Balancing Value Optimization and Fairness in Individualized Treatment Rules", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Individualized treatment rules (ITRs) have gained significant attention due\nto their wide-ranging applications in fields such as precision medicine,\nridesharing, and advertising recommendations. However, when ITRs are influenced\nby sensitive attributes such as race, gender, or age, they can lead to outcomes\nwhere certain groups are unfairly advantaged or disadvantaged. To address this\ngap, we propose a flexible approach based on the optimal transport theory,\nwhich is capable of transforming any optimal ITR into a fair ITR that ensures\ndemographic parity. Recognizing the potential loss of value under fairness\nconstraints, we introduce an ``improved trade-off ITR,\" designed to balance\nvalue optimization and fairness while accommodating varying levels of fairness\nthrough parameter adjustment. To maximize the value of the improved trade-off\nITR under specific fairness levels, we propose a smoothed fairness constraint\nfor estimating the adjustable parameter. Additionally, we establish a\ntheoretical upper bound on the value loss for the improved trade-off ITR. We\ndemonstrate performance of the proposed method through extensive simulation\nstudies and application to the Next 36 entrepreneurial program dataset."}
{"id": "2507.23361", "pdf": "https://arxiv.org/pdf/2507.23361", "abs": "https://arxiv.org/abs/2507.23361", "authors": ["Silin Chen", "Shaoxin Lin", "Xiaodong Gu", "Yuling Shi", "Heng Lian", "Longfei Yun", "Dong Chen", "Weiguo Sun", "Lin Cao", "Qianxiang Wang"], "title": "SWE-Exp: Experience-Driven Software Issue Resolution", "categories": ["cs.SE", "cs.CL", "cs.LG"], "comment": "Our code and data are available at\n  https://github.com/YerbaPage/SWE-Exp", "summary": "Recent advances in large language model (LLM) agents have shown remarkable\nprogress in software issue resolution, leveraging advanced techniques such as\nmulti-agent collaboration and Monte Carlo Tree Search (MCTS). However, current\nagents act as memoryless explorers - treating each problem separately without\nretaining or reusing knowledge from previous repair experiences. This leads to\nredundant exploration of failed trajectories and missed chances to adapt\nsuccessful issue resolution methods to similar problems. To address this\nproblem, we introduce SWE-Exp, an experience - enhanced approach that distills\nconcise and actionable experience from prior agent trajectories, enabling\ncontinuous learning across issues. Our method introduces a multi-faceted\nexperience bank that captures both successful and failed repair attempts.\nSpecifically, it extracts reusable issue resolution knowledge at different\nlevels - from high-level problem comprehension to specific code changes.\nExperiments show that SWE-Exp achieves state-of-the-art resolution rate (41.6%\nPass@1) on SWE-bench-Verified under open-source agent frameworks. Our approach\nestablishes a new paradigm in which automated software engineering agents\nsystematically accumulate and leverage repair expertise, fundamentally shifting\nfrom trial-and-error exploration to strategic, experience-driven issue\nresolution."}
{"id": "2507.23402", "pdf": "https://arxiv.org/pdf/2507.23402", "abs": "https://arxiv.org/abs/2507.23402", "authors": ["Wei Li", "Xun Gong", "Jiao Li", "Xiaobin Sun"], "title": "AGA: An adaptive group alignment framework for structured medical cross-modal representation learning", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Learning medical visual representations from paired images and reports is a\npromising direction in representation learning. However, current\nvision-language pretraining methods in the medical domain often simplify\nclinical reports into single entities or fragmented tokens, ignoring their\ninherent structure. In addition, contrastive learning frameworks typically\ndepend on large quantities of hard negative samples, which is impractical for\nsmall-scale medical datasets. To tackle these challenges, we propose Adaptive\nGrouped Alignment (AGA), a new framework that captures structured semantics\nfrom paired medical images and reports. AGA introduces a bidirectional grouping\nmechanism based on a sparse similarity matrix. For each image-report pair, we\ncompute fine-grained similarities between text tokens and image patches. Each\ntoken selects its top-matching patches to form a visual group, and each patch\nselects its most related tokens to form a language group. To enable adaptive\ngrouping, we design two threshold gating modules, called Language Grouped\nThreshold Gate and Vision Grouped Threshold Gate, which learn grouping\nthresholds dynamically. Group representations are computed as weighted averages\nbased on similarity scores. To align each token with its group representation,\nwe introduce an Instance Aware Group Alignment loss that operates within each\nimage-text pair, removing the need for external negatives. Finally, a\nBidirectional Cross-modal Grouped Alignment module is applied to enhance\nfine-grained alignment between visual and linguistic group representations.\nExtensive experiments on public and private datasets show that our method\nachieves strong performance on image-text retrieval and classification tasks\nunder both fine-tuning and zero-shot settings."}
{"id": "2507.23416", "pdf": "https://arxiv.org/pdf/2507.23416", "abs": "https://arxiv.org/abs/2507.23416", "authors": ["Mokhtar A. Al-Awadhi", "Ratnadeep R. Deshmukh"], "title": "Honey Adulteration Detection using Hyperspectral Imaging and Machine Learning", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "This paper aims to develop a machine learning-based system for automatically\ndetecting honey adulteration with sugar syrup, based on honey hyperspectral\nimaging data. First, the floral source of a honey sample is classified by a\nbotanical origin identification subsystem. Then, the sugar syrup adulteration\nis identified, and its concentration is quantified by an adulteration detection\nsubsystem. Both subsystems consist of two steps. The first step involves\nextracting relevant features from the honey sample using Linear Discriminant\nAnalysis (LDA). In the second step, we utilize the K-Nearest Neighbors (KNN)\nmodel to classify the honey botanical origin in the first subsystem and\nidentify the adulteration level in the second subsystem. We assess the proposed\nsystem performance on a public honey hyperspectral image dataset. The result\nindicates that the proposed system can detect adulteration in honey with an\noverall cross-validation accuracy of 96.39%, making it an appropriate\nalternative to the current chemical-based detection methods."}
{"id": "2507.23443", "pdf": "https://arxiv.org/pdf/2507.23443", "abs": "https://arxiv.org/abs/2507.23443", "authors": ["Long Chen", "Emre Oezkaya", "Jan Rottmayer", "Nicolas R. Gauger", "Zebang Shen", "Yinyu Ye"], "title": "Adjoint-Based Aerodynamic Shape Optimization with a Manifold Constraint Learned by Diffusion Models", "categories": ["cs.CE", "cs.LG", "math.OC"], "comment": null, "summary": "We introduce an adjoint-based aerodynamic shape optimization framework that\nintegrates a diffusion model trained on existing designs to learn a smooth\nmanifold of aerodynamically viable shapes. This manifold is enforced as an\nequality constraint to the shape optimization problem. Central to our method is\nthe computation of adjoint gradients of the design objectives (e.g., drag and\nlift) with respect to the manifold space. These gradients are derived by first\ncomputing shape derivatives with respect to conventional shape design\nparameters (e.g., Hicks-Henne parameters) and then backpropagating them through\nthe diffusion model to its latent space via automatic differentiation. Our\nframework preserves mathematical rigor and can be integrated into existing\nadjoint-based design workflows with minimal modification. Demonstrated on\nextensive transonic RANS airfoil design cases using off-the-shelf and\ngeneral-purpose nonlinear optimizers, our approach eliminates ad hoc parameter\ntuning and variable scaling, maintains robustness across initialization and\noptimizer choices, and achieves superior aerodynamic performance compared to\nconventional approaches. This work establishes how AI generated priors\nintegrates effectively with adjoint methods to enable robust, high-fidelity\naerodynamic shape optimization through automatic differentiation."}
{"id": "2507.23455", "pdf": "https://arxiv.org/pdf/2507.23455", "abs": "https://arxiv.org/abs/2507.23455", "authors": ["Shereiff Garrett", "Abhinav Adhikari", "Sarina Gautam", "DaShawn Marquis Morris", "Chandra Mani Adhikari"], "title": "Machine learning and machine learned prediction in chest X-ray images", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "8 pages, 7 figures", "summary": "Machine learning and artificial intelligence are fast-growing fields of\nresearch in which data is used to train algorithms, learn patterns, and make\npredictions. This approach helps to solve seemingly intricate problems with\nsignificant accuracy without explicit programming by recognizing complex\nrelationships in data. Taking an example of 5824 chest X-ray images, we\nimplement two machine learning algorithms, namely, a baseline convolutional\nneural network (CNN) and a DenseNet-121, and present our analysis in making\nmachine-learned predictions in predicting patients with ailments. Both baseline\nCNN and DenseNet-121 perform very well in the binary classification problem\npresented in this work. Gradient-weighted class activation mapping shows that\nDenseNet-121 correctly focuses on essential parts of the input chest X-ray\nimages in its decision-making more than the baseline CNN."}
{"id": "2507.23523", "pdf": "https://arxiv.org/pdf/2507.23523", "abs": "https://arxiv.org/abs/2507.23523", "authors": ["Hongzhe Bi", "Lingxuan Wu", "Tianwei Lin", "Hengkai Tan", "Zhizhong Su", "Hang Su", "Jun Zhu"], "title": "H-RDT: Human Manipulation Enhanced Bimanual Robotic Manipulation", "categories": ["cs.RO", "cs.CV", "cs.LG"], "comment": null, "summary": "Imitation learning for robotic manipulation faces a fundamental challenge:\nthe scarcity of large-scale, high-quality robot demonstration data. Recent\nrobotic foundation models often pre-train on cross-embodiment robot datasets to\nincrease data scale, while they face significant limitations as the diverse\nmorphologies and action spaces across different robot embodiments make unified\ntraining challenging. In this paper, we present H-RDT (Human to Robotics\nDiffusion Transformer), a novel approach that leverages human manipulation data\nto enhance robot manipulation capabilities. Our key insight is that large-scale\negocentric human manipulation videos with paired 3D hand pose annotations\nprovide rich behavioral priors that capture natural manipulation strategies and\ncan benefit robotic policy learning. We introduce a two-stage training\nparadigm: (1) pre-training on large-scale egocentric human manipulation data,\nand (2) cross-embodiment fine-tuning on robot-specific data with modular action\nencoders and decoders. Built on a diffusion transformer architecture with 2B\nparameters, H-RDT uses flow matching to model complex action distributions.\nExtensive evaluations encompassing both simulation and real-world experiments,\nsingle-task and multitask scenarios, as well as few-shot learning and\nrobustness assessments, demonstrate that H-RDT outperforms training from\nscratch and existing state-of-the-art methods, including Pi0 and RDT, achieving\nsignificant improvements of 13.9% and 40.5% over training from scratch in\nsimulation and real-world experiments, respectively. The results validate our\ncore hypothesis that human manipulation data can serve as a powerful foundation\nfor learning bimanual robotic manipulation policies."}
{"id": "2507.23609", "pdf": "https://arxiv.org/pdf/2507.23609", "abs": "https://arxiv.org/abs/2507.23609", "authors": ["Halid Ziya Yerebakan", "Gerardo Hermosillo Valadez"], "title": "Consistent Point Matching", "categories": ["cs.CV", "cs.DC", "cs.LG"], "comment": null, "summary": "This study demonstrates that incorporating a consistency heuristic into the\npoint-matching algorithm \\cite{yerebakan2023hierarchical} improves robustness\nin matching anatomical locations across pairs of medical images. We validated\nour approach on diverse longitudinal internal and public datasets spanning CT\nand MRI modalities. Notably, it surpasses state-of-the-art results on the Deep\nLesion Tracking dataset. Additionally, we show that the method effectively\naddresses landmark localization. The algorithm operates efficiently on standard\nCPU hardware and allows configurable trade-offs between speed and robustness.\nThe method enables high-precision navigation between medical images without\nrequiring a machine learning model or training data."}
{"id": "2507.23620", "pdf": "https://arxiv.org/pdf/2507.23620", "abs": "https://arxiv.org/abs/2507.23620", "authors": ["Yucheng Xie", "Fu Feng", "Ruixiao Shi", "Jing Wang", "Yong Rui", "Xin Geng"], "title": "DivControl: Knowledge Diversion for Controllable Image Generation", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Diffusion models have advanced from text-to-image (T2I) to image-to-image\n(I2I) generation by incorporating structured inputs such as depth maps,\nenabling fine-grained spatial control. However, existing methods either train\nseparate models for each condition or rely on unified architectures with\nentangled representations, resulting in poor generalization and high adaptation\ncosts for novel conditions. To this end, we propose DivControl, a decomposable\npretraining framework for unified controllable generation and efficient\nadaptation. DivControl factorizes ControlNet via SVD into basic\ncomponents-pairs of singular vectors-which are disentangled into\ncondition-agnostic learngenes and condition-specific tailors through knowledge\ndiversion during multi-condition training. Knowledge diversion is implemented\nvia a dynamic gate that performs soft routing over tailors based on the\nsemantics of condition instructions, enabling zero-shot generalization and\nparameter-efficient adaptation to novel conditions. To further improve\ncondition fidelity and training efficiency, we introduce a representation\nalignment loss that aligns condition embeddings with early diffusion features.\nExtensive experiments demonstrate that DivControl achieves state-of-the-art\ncontrollability with 36.4$\\times$ less training cost, while simultaneously\nimproving average performance on basic conditions. It also delivers strong\nzero-shot and few-shot performance on unseen conditions, demonstrating superior\nscalability, modularity, and transferability."}
{"id": "2507.23673", "pdf": "https://arxiv.org/pdf/2507.23673", "abs": "https://arxiv.org/abs/2507.23673", "authors": ["Alfie Roddan", "Tobias Czempiel", "Chi Xu", "Daniel S. Elson", "Stamatia Giannarou"], "title": "SAMSA: Segment Anything Model Enhanced with Spectral Angles for Hyperspectral Interactive Medical Image Segmentation", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Hyperspectral imaging (HSI) provides rich spectral information for medical\nimaging, yet encounters significant challenges due to data limitations and\nhardware variations. We introduce SAMSA, a novel interactive segmentation\nframework that combines an RGB foundation model with spectral analysis. SAMSA\nefficiently utilizes user clicks to guide both RGB segmentation and spectral\nsimilarity computations. The method addresses key limitations in HSI\nsegmentation through a unique spectral feature fusion strategy that operates\nindependently of spectral band count and resolution. Performance evaluation on\npublicly available datasets has shown 81.0% 1-click and 93.4% 5-click DICE on a\nneurosurgical and 81.1% 1-click and 89.2% 5-click DICE on an intraoperative\nporcine hyperspectral dataset. Experimental results demonstrate SAMSA's\neffectiveness in few-shot and zero-shot learning scenarios and using minimal\ntraining examples. Our approach enables seamless integration of datasets with\ndifferent spectral characteristics, providing a flexible framework for\nhyperspectral medical image analysis."}
{"id": "2507.23682", "pdf": "https://arxiv.org/pdf/2507.23682", "abs": "https://arxiv.org/abs/2507.23682", "authors": ["Xiaoyu Chen", "Hangxing Wei", "Pushi Zhang", "Chuheng Zhang", "Kaixin Wang", "Yanjiang Guo", "Rushuai Yang", "Yucen Wang", "Xinquan Xiao", "Li Zhao", "Jianyu Chen", "Jiang Bian"], "title": "villa-X: Enhancing Latent Action Modeling in Vision-Language-Action Models", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "Project page: https://aka.ms/villa-x", "summary": "Visual-Language-Action (VLA) models have emerged as a popular paradigm for\nlearning robot manipulation policies that can follow language instructions and\ngeneralize to novel scenarios. Recent work has begun to explore the\nincorporation of latent actions, an abstract representation of visual change\nbetween two frames, into VLA pre-training. In this paper, we introduce villa-X,\na novel Visual-Language-Latent-Action (ViLLA) framework that advances latent\naction modeling for learning generalizable robot manipulation policies. Our\napproach improves both how latent actions are learned and how they are\nincorporated into VLA pre-training. Together, these contributions enable\nvilla-X to achieve superior performance across simulated environments including\nSIMPLER and LIBERO, as well as on two real-world robot setups including gripper\nand dexterous hand manipulation. We believe the ViLLA paradigm holds\nsignificant promise, and that our villa-X provides a strong foundation for\nfuture research."}
{"id": "2507.23736", "pdf": "https://arxiv.org/pdf/2507.23736", "abs": "https://arxiv.org/abs/2507.23736", "authors": ["Kyle Naddeo", "Nikolas Koutsoubis", "Rahul Krish", "Ghulam Rasool", "Nidhal Bouaynaya", "Tony OSullivan", "Raj Krish"], "title": "DICOM De-Identification via Hybrid AI and Rule-Based Framework for Scalable, Uncertainty-Aware Redaction", "categories": ["stat.ML", "cs.LG"], "comment": "15 pages, 6 figures,", "summary": "Access to medical imaging and associated text data has the potential to drive\nmajor advances in healthcare research and patient outcomes. However, the\npresence of Protected Health Information (PHI) and Personally Identifiable\nInformation (PII) in Digital Imaging and Communications in Medicine (DICOM)\nfiles presents a significant barrier to the ethical and secure sharing of\nimaging datasets. This paper presents a hybrid de-identification framework\ndeveloped by Impact Business Information Solutions (IBIS) that combines\nrule-based and AI-driven techniques, and rigorous uncertainty quantification\nfor comprehensive PHI/PII removal from both metadata and pixel data.\n  Our approach begins with a two-tiered rule-based system targeting explicit\nand inferred metadata elements, further augmented by a large language model\n(LLM) fine-tuned for Named Entity Recognition (NER), and trained on a suite of\nsynthetic datasets simulating realistic clinical PHI/PII. For pixel data, we\nemploy an uncertainty-aware Faster R-CNN model to localize embedded text,\nextract candidate PHI via Optical Character Recognition (OCR), and apply the\nNER pipeline for final redaction. Crucially, uncertainty quantification\nprovides confidence measures for AI-based detections to enhance automation\nreliability and enable informed human-in-the-loop verification to manage\nresidual risks.\n  This uncertainty-aware deidentification framework achieves robust performance\nacross benchmark datasets and regulatory standards, including DICOM, HIPAA, and\nTCIA compliance metrics. By combining scalable automation, uncertainty\nquantification, and rigorous quality assurance, our solution addresses critical\nchallenges in medical data de-identification and supports the secure, ethical,\nand trustworthy release of imaging data for research."}
{"id": "2507.23740", "pdf": "https://arxiv.org/pdf/2507.23740", "abs": "https://arxiv.org/abs/2507.23740", "authors": ["Nasim Shirvani-Mahdavi", "Devin Wingfield", "Amin Ghasemi", "Chengkai Li"], "title": "Rule2Text: Natural Language Explanation of Logical Rules in Knowledge Graphs", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Knowledge graphs (KGs) often contain sufficient information to support the\ninference of new facts. Identifying logical rules not only improves the\ncompleteness of a knowledge graph but also enables the detection of potential\nerrors, reveals subtle data patterns, and enhances the overall capacity for\nreasoning and interpretation. However, the complexity of such rules, combined\nwith the unique labeling conventions of each KG, can make them difficult for\nhumans to understand. In this paper, we explore the potential of large language\nmodels to generate natural language explanations for logical rules.\nSpecifically, we extract logical rules using the AMIE 3.5.1 rule discovery\nalgorithm from the benchmark dataset FB15k-237 and two large-scale datasets,\nFB-CVT-REV and FB+CVT-REV. We examine various prompting strategies, including\nzero- and few-shot prompting, including variable entity types, and\nchain-of-thought reasoning. We conduct a comprehensive human evaluation of the\ngenerated explanations based on correctness, clarity, and hallucination, and\nalso assess the use of large language models as automatic judges. Our results\ndemonstrate promising performance in terms of explanation correctness and\nclarity, although several challenges remain for future research. All scripts\nand data used in this study are publicly available at\nhttps://github.com/idirlab/KGRule2NL}{https://github.com/idirlab/KGRule2NL."}
{"id": "2507.23767", "pdf": "https://arxiv.org/pdf/2507.23767", "abs": "https://arxiv.org/abs/2507.23767", "authors": ["Jonathan R. Landers"], "title": "Scaled Beta Models and Feature Dilution for Dynamic Ticket Pricing", "categories": ["stat.ML", "cs.LG", "68T05, 62H30, 62F10, 68Q32", "F.2.2; I.2.6; I.5.2; G.3"], "comment": "27 pages, 11 figures, 3 tables", "summary": "A novel approach is presented for identifying distinct signatures of\nperforming acts in the secondary ticket resale market by analyzing dynamic\npricing distributions. Using a newly curated, time series dataset from the\nSeatGeek API, we model ticket pricing distributions as scaled Beta\ndistributions. This enables accurate parameter estimation from incomplete\nstatistical data using a hybrid of quantile matching and the method of moments.\nIncorporating the estimated $\\alpha$ and $\\beta$ parameters into Random Forest\nclassifiers significantly improves pairwise artist classification accuracy,\ndemonstrating the unique economic signatures in event pricing data.\nAdditionally, we provide theoretical and empirical evidence that incorporating\nzero-variance (constant-value) features into Random Forest models acts as an\nimplicit regularizer, enhancing feature variety and robustness. This\nregularization promotes deeper, more varied trees in the ensemble, improving\nthe bias-variance tradeoff and mitigating overfitting to dominant features.\nThese findings are validated on both the new ticket pricing dataset and the\nstandard UCI ML handwritten digits dataset."}
{"id": "2507.23768", "pdf": "https://arxiv.org/pdf/2507.23768", "abs": "https://arxiv.org/abs/2507.23768", "authors": ["Nathan Wycoff", "Ali Arab", "Lisa O. Singh"], "title": "Formal Bayesian Transfer Learning via the Total Risk Prior", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "In analyses with severe data-limitations, augmenting the target dataset with\ninformation from ancillary datasets in the application domain, called source\ndatasets, can lead to significantly improved statistical procedures. However,\nexisting methods for this transfer learning struggle to deal with situations\nwhere the source datasets are also limited and not guaranteed to be\nwell-aligned with the target dataset. A typical strategy is to use the\nempirical loss minimizer on the source data as a prior mean for the target\nparameters, which places the estimation of source parameters outside of the\nBayesian formalism. Our key conceptual contribution is to use a risk minimizer\nconditional on source parameters instead. This allows us to construct a single\njoint prior distribution for all parameters from the source datasets as well as\nthe target dataset. As a consequence, we benefit from full Bayesian uncertainty\nquantification and can perform model averaging via Gibbs sampling over\nindicator variables governing the inclusion of each source dataset. We show how\na particular instantiation of our prior leads to a Bayesian Lasso in a\ntransformed coordinate system and discuss computational techniques to scale our\napproach to moderately sized datasets. We also demonstrate that recently\nproposed minimax-frequentist transfer learning techniques may be viewed as an\napproximate Maximum a Posteriori approach to our model. Finally, we demonstrate\nsuperior predictive performance relative to the frequentist baseline on a\ngenetics application, especially when the source data are limited."}
{"id": "2507.23773", "pdf": "https://arxiv.org/pdf/2507.23773", "abs": "https://arxiv.org/abs/2507.23773", "authors": ["Mingkai Deng", "Jinyu Hou", "Yilin Shen", "Hongxia Jin", "Graham Neubig", "Zhiting Hu", "Eric Xing"], "title": "SimuRA: Towards General Goal-Oriented Agent via Simulative Reasoning Architecture with LLM-Based World Model", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.RO"], "comment": null, "summary": "AI agents built on large language models (LLMs) hold enormous promise, but\ncurrent practice focuses on a one-task-one-agent approach, which not only falls\nshort of scalability and generality, but also suffers from the fundamental\nlimitations of autoregressive LLMs. On the other hand, humans are general\nagents who reason by mentally simulating the outcomes of their actions and\nplans. Moving towards a more general and powerful AI agent, we introduce\nSimuRA, a goal-oriented architecture for generalized agentic reasoning. Based\non a principled formulation of optimal agent in any environment, \\modelname\novercomes the limitations of autoregressive reasoning by introducing a world\nmodel for planning via simulation. The generalized world model is implemented\nusing LLM, which can flexibly plan in a wide range of environments using the\nconcept-rich latent space of natural language. Experiments on difficult web\nbrowsing tasks show that \\modelname improves the success of flight search from\n0\\% to 32.2\\%. World-model-based planning, in particular, shows consistent\nadvantage of up to 124\\% over autoregressive planning, demonstrating the\nadvantage of world model simulation as a reasoning paradigm. We are excited\nabout the possibility for training a single, general agent model based on LLMs\nthat can act superintelligently in all environments. To start, we make SimuRA,\na web-browsing agent built on \\modelname with pretrained LLMs, available as a\nresearch demo for public testing."}
{"id": "2507.23777", "pdf": "https://arxiv.org/pdf/2507.23777", "abs": "https://arxiv.org/abs/2507.23777", "authors": ["Dian Chen", "Yansong Qu", "Xinyang Li", "Ming Li", "Shengchuan Zhang"], "title": "XSpecMesh: Quality-Preserving Auto-Regressive Mesh Generation Acceleration via Multi-Head Speculative Decoding", "categories": ["cs.GR", "cs.CV", "cs.LG"], "comment": null, "summary": "Current auto-regressive models can generate high-quality, topologically\nprecise meshes; however, they necessitate thousands-or even tens of\nthousands-of next-token predictions during inference, resulting in substantial\nlatency. We introduce XSpecMesh, a quality-preserving acceleration method for\nauto-regressive mesh generation models. XSpecMesh employs a lightweight,\nmulti-head speculative decoding scheme to predict multiple tokens in parallel\nwithin a single forward pass, thereby accelerating inference. We further\npropose a verification and resampling strategy: the backbone model verifies\neach predicted token and resamples any tokens that do not meet the quality\ncriteria. In addition, we propose a distillation strategy that trains the\nlightweight decoding heads by distilling from the backbone model, encouraging\ntheir prediction distributions to align and improving the success rate of\nspeculative predictions. Extensive experiments demonstrate that our method\nachieves a 1.7x speedup without sacrificing generation quality. Our code will\nbe released."}
{"id": "2507.23784", "pdf": "https://arxiv.org/pdf/2507.23784", "abs": "https://arxiv.org/abs/2507.23784", "authors": ["Jessica Bader", "Leander Girrbach", "Stephan Alaniz", "Zeynep Akata"], "title": "SUB: Benchmarking CBM Generalization via Synthetic Attribute Substitutions", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted at ICCV 2025", "summary": "Concept Bottleneck Models (CBMs) and other concept-based interpretable models\nshow great promise for making AI applications more transparent, which is\nessential in fields like medicine. Despite their success, we demonstrate that\nCBMs struggle to reliably identify the correct concepts under distribution\nshifts. To assess the robustness of CBMs to concept variations, we introduce\nSUB: a fine-grained image and concept benchmark containing 38,400 synthetic\nimages based on the CUB dataset. To create SUB, we select a CUB subset of 33\nbird classes and 45 concepts to generate images which substitute a specific\nconcept, such as wing color or belly pattern. We introduce a novel Tied\nDiffusion Guidance (TDG) method to precisely control generated images, where\nnoise sharing for two parallel denoising processes ensures that both the\ncorrect bird class and the correct attribute are generated. This novel\nbenchmark enables rigorous evaluation of CBMs and similar interpretable models,\ncontributing to the development of more robust methods. Our code is available\nat https://github.com/ExplainableML/sub and the dataset at\nhttp://huggingface.co/datasets/Jessica-bader/SUB."}
