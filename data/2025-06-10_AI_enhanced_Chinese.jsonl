{"id": "2506.05426", "pdf": "https://arxiv.org/pdf/2506.05426", "abs": "https://arxiv.org/abs/2506.05426", "authors": ["Wenhao Wu", "Fuhong Liu", "Haoru Li", "Zican Hu", "Daoyi Dong", "Chunlin Chen", "Zhi Wang"], "title": "Mixture-of-Experts Meets In-Context Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "26 pages, 13 figures", "summary": "In-context reinforcement learning (ICRL) has emerged as a promising paradigm\nfor adapting RL agents to downstream tasks through prompt conditioning.\nHowever, two notable challenges remain in fully harnessing in-context learning\nwithin RL domains: the intrinsic multi-modality of the state-action-reward data\nand the diverse, heterogeneous nature of decision tasks. To tackle these\nchallenges, we propose \\textbf{T2MIR} (\\textbf{T}oken- and \\textbf{T}ask-wise\n\\textbf{M}oE for \\textbf{I}n-context \\textbf{R}L), an innovative framework that\nintroduces architectural advances of mixture-of-experts (MoE) into\ntransformer-based decision models. T2MIR substitutes the feedforward layer with\ntwo parallel layers: a token-wise MoE that captures distinct semantics of input\ntokens across multiple modalities, and a task-wise MoE that routes diverse\ntasks to specialized experts for managing a broad task distribution with\nalleviated gradient conflicts. To enhance task-wise routing, we introduce a\ncontrastive learning method that maximizes the mutual information between the\ntask and its router representation, enabling more precise capture of\ntask-relevant information. The outputs of two MoE components are concatenated\nand fed into the next layer. Comprehensive experiments show that T2MIR\nsignificantly facilitates in-context learning capacity and outperforms various\ntypes of baselines. We bring the potential and promise of MoE to ICRL, offering\na simple and scalable architectural enhancement to advance ICRL one step closer\ntoward achievements in language and vision communities. Our code is available\nat https://github.com/NJU-RL/T2MIR.", "AI": {"tldr": "T2MIR\u662f\u4e00\u4e2a\u57fa\u4e8e\u6df7\u5408\u4e13\u5bb6\uff08MoE\uff09\u7684\u6846\u67b6\uff0c\u901a\u8fc7token-wise\u548ctask-wise MoE\u89e3\u51b3ICRL\u4e2d\u7684\u591a\u6a21\u6001\u548c\u4efb\u52a1\u591a\u6837\u6027\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3ICRL\u4e2d\u72b6\u6001-\u52a8\u4f5c-\u5956\u52b1\u6570\u636e\u7684\u591a\u6a21\u6001\u6027\u548c\u4efb\u52a1\u591a\u6837\u6027\u5e26\u6765\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faT2MIR\u6846\u67b6\uff0c\u5305\u542btoken-wise MoE\u548ctask-wise MoE\uff0c\u5e76\u5f15\u5165\u5bf9\u6bd4\u5b66\u4e60\u4f18\u5316\u4efb\u52a1\u8def\u7531\u3002", "result": "\u5b9e\u9a8c\u8868\u660eT2MIR\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\u3002", "conclusion": "T2MIR\u4e3aICRL\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u4e14\u53ef\u6269\u5c55\u7684\u67b6\u6784\u6539\u8fdb\uff0c\u63a8\u52a8\u4e86\u5176\u5728\u8bed\u8a00\u548c\u89c6\u89c9\u9886\u57df\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.05427", "pdf": "https://arxiv.org/pdf/2506.05427", "abs": "https://arxiv.org/abs/2506.05427", "authors": ["Zishan Shu", "Yufan Deng", "Hongyu Zhang", "Zhiwei Nie", "Jie Chen"], "title": "MTPNet: Multi-Grained Target Perception for Unified Activity Cliff Prediction", "categories": ["cs.LG", "cs.AI", "cs.CE"], "comment": null, "summary": "Activity cliff prediction is a critical task in drug discovery and material\ndesign. Existing computational methods are limited to handling single binding\ntargets, which restricts the applicability of these prediction models. In this\npaper, we present the Multi-Grained Target Perception network (MTPNet) to\nincorporate the prior knowledge of interactions between the molecules and their\ntarget proteins. Specifically, MTPNet is a unified framework for activity cliff\nprediction, which consists of two components: Macro-level Target Semantic (MTS)\nguidance and Micro-level Pocket Semantic (MPS) guidance. By this way, MTPNet\ndynamically optimizes molecular representations through multi-grained protein\nsemantic conditions. To our knowledge, it is the first time to employ the\nreceptor proteins as guiding information to effectively capture critical\ninteraction details. Extensive experiments on 30 representative activity cliff\ndatasets demonstrate that MTPNet significantly outperforms previous approaches,\nachieving an average RMSE improvement of 18.95% on top of several mainstream\nGNN architectures. Overall, MTPNet internalizes interaction patterns through\nconditional deep learning to achieve unified predictions of activity cliffs,\nhelping to accelerate compound optimization and design. Codes are available at:\nhttps://github.com/ZishanShu/MTPNet.", "AI": {"tldr": "MTPNet\u662f\u4e00\u79cd\u591a\u7c92\u5ea6\u76ee\u6807\u611f\u77e5\u7f51\u7edc\uff0c\u7528\u4e8e\u9884\u6d4b\u6d3b\u6027\u60ac\u5d16\uff0c\u901a\u8fc7\u7ed3\u5408\u5206\u5b50\u4e0e\u9776\u86cb\u767d\u7684\u4ea4\u4e92\u77e5\u8bc6\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u8ba1\u7b97\u65b9\u6cd5\u4ec5\u80fd\u5904\u7406\u5355\u4e00\u7ed3\u5408\u76ee\u6807\uff0c\u9650\u5236\u4e86\u9884\u6d4b\u6a21\u578b\u7684\u9002\u7528\u6027\u3002", "method": "MTPNet\u5305\u542b\u5b8f\u89c2\u76ee\u6807\u8bed\u4e49\uff08MTS\uff09\u548c\u5fae\u89c2\u53e3\u888b\u8bed\u4e49\uff08MPS\uff09\u6307\u5bfc\uff0c\u52a8\u6001\u4f18\u5316\u5206\u5b50\u8868\u793a\u3002", "result": "\u572830\u4e2a\u4ee3\u8868\u6027\u6570\u636e\u96c6\u4e0a\uff0cMTPNet\u5e73\u5747RMSE\u63d0\u534718.95%\u3002", "conclusion": "MTPNet\u901a\u8fc7\u6761\u4ef6\u6df1\u5ea6\u5b66\u4e60\u5b9e\u73b0\u6d3b\u6027\u60ac\u5d16\u7684\u7edf\u4e00\u9884\u6d4b\uff0c\u52a0\u901f\u5316\u5408\u7269\u4f18\u5316\u4e0e\u8bbe\u8ba1\u3002"}}
{"id": "2506.05428", "pdf": "https://arxiv.org/pdf/2506.05428", "abs": "https://arxiv.org/abs/2506.05428", "authors": ["Zhihao Tang", "Chaozhuo Li", "Litian Zhang", "Xi Zhang"], "title": "Diffusion with a Linguistic Compass: Steering the Generation of Clinically Plausible Future sMRI Representations for Early MCI Conversion Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Early prediction of Mild Cognitive Impairment (MCI) conversion is hampered by\na trade-off between immediacy--making fast predictions from a single baseline\nsMRI--and accuracy--leveraging longitudinal scans to capture disease\nprogression. We propose MCI-Diff, a diffusion-based framework that synthesizes\nclinically plausible future sMRI representations directly from baseline data,\nachieving both real-time risk assessment and high predictive performance.\nFirst, a multi-task sequence reconstruction strategy trains a shared denoising\nnetwork on interpolation and extrapolation tasks to handle irregular follow-up\nsampling and learn robust latent trajectories. Second, an LLM-driven\n\"linguistic compass\" is introduced for clinical plausibility sampling:\ngenerated feature candidates are quantized, tokenized, and scored by a\nfine-tuned language model conditioned on expected structural biomarkers,\nguiding autoregressive generation toward realistic disease patterns.\nExperiments on ADNI and AIBL cohorts show that MCI-Diff outperforms\nstate-of-the-art baselines, improving early conversion accuracy by 5-12%.", "AI": {"tldr": "MCI-Diff\u662f\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u57fa\u7ebf\u6570\u636e\u5408\u6210\u672a\u6765sMRI\u8868\u793a\uff0c\u5b9e\u73b0\u5b9e\u65f6\u98ce\u9669\u8bc4\u4f30\u548c\u9ad8\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u65e9\u671f\u9884\u6d4b\u8f7b\u5ea6\u8ba4\u77e5\u969c\u788d\uff08MCI\uff09\u8f6c\u5316\u9762\u4e34\u5373\u65f6\u6027\uff08\u4ece\u5355\u6b21\u57fa\u7ebfsMRI\u5feb\u901f\u9884\u6d4b\uff09\u4e0e\u51c6\u786e\u6027\uff08\u5229\u7528\u7eb5\u5411\u626b\u63cf\u6355\u6349\u75be\u75c5\u8fdb\u5c55\uff09\u4e4b\u95f4\u7684\u6743\u8861\u3002", "method": "\u63d0\u51fa\u591a\u4efb\u52a1\u5e8f\u5217\u91cd\u5efa\u7b56\u7565\u8bad\u7ec3\u5171\u4eab\u53bb\u566a\u7f51\u7edc\uff0c\u7ed3\u5408LLM\u9a71\u52a8\u7684\u201c\u8bed\u8a00\u6307\u5357\u201d\u8fdb\u884c\u4e34\u5e8a\u5408\u7406\u6027\u91c7\u6837\u3002", "result": "\u5728ADNI\u548cAIBL\u6570\u636e\u96c6\u4e0a\uff0cMCI-Diff\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u65e9\u671f\u8f6c\u5316\u9884\u6d4b\u51c6\u786e\u7387\u63d0\u9ad85-12%\u3002", "conclusion": "MCI-Diff\u5728\u5b9e\u65f6\u6027\u548c\u51c6\u786e\u6027\u4e0a\u53d6\u5f97\u5e73\u8861\uff0c\u4e3aMCI\u8f6c\u5316\u9884\u6d4b\u63d0\u4f9b\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.05432", "pdf": "https://arxiv.org/pdf/2506.05432", "abs": "https://arxiv.org/abs/2506.05432", "authors": ["Yuxuan Yue", "Zukang Xu", "Zhihang Yuan", "Dawei Yang", "Jianglong Wu", "Liqiang Nie"], "title": "PCDVQ: Enhancing Vector Quantization for Large Language Models via Polar Coordinate Decoupling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) face significant challenges in edge deployment\ndue to their massive parameter scale. Vector Quantization (VQ), a\nclustering-based quantization method, serves as a prevalent solution to this\nissue for its extremely low-bit (even at 2-bit) and considerable accuracy.\nSince a vector is a quantity in mathematics and physics that has both direction\nand magnitude, existing VQ works typically quantize them in a coupled manner.\nHowever, we find that direction exhibits significantly greater sensitivity to\nquantization compared to the magnitude. For instance, when separately\nclustering the directions and magnitudes of weight vectors in LLaMA-2-7B, the\naccuracy drop of zero-shot tasks are 46.5\\% and 2.3\\%, respectively. This gap\neven increases with the reduction of clustering centers. Further, Euclidean\ndistance, a common metric to access vector similarities in current VQ works,\nplaces greater emphasis on reducing the magnitude error. This property is\ncontrary to the above finding, unavoidably leading to larger quantization\nerrors. To these ends, this paper proposes Polar Coordinate Decoupled Vector\nQuantization (PCDVQ), an effective and efficient VQ framework consisting of two\nkey modules: 1) Polar Coordinate Decoupling (PCD), which transforms vectors\ninto their polar coordinate representations and perform independent\nquantization of the direction and magnitude parameters.2) Distribution Aligned\nCodebook Construction (DACC), which optimizes the direction and magnitude\ncodebooks in accordance with the source distribution. Experimental results show\nthat PCDVQ outperforms baseline methods at 2-bit level by at least 1.5\\%\nzero-shot accuracy, establishing a novel paradigm for accurate and highly\ncompressed LLMs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPCDVQ\u7684\u5411\u91cf\u91cf\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u89e3\u8026\u65b9\u5411\u4e0e\u5e45\u5ea6\u7684\u91cf\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8fb9\u7f18\u90e8\u7f72\u4e2d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u538b\u7f29\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u5411\u91cf\u91cf\u5316\u65b9\u6cd5\u5728\u91cf\u5316\u65b9\u5411\u65f6\u8bef\u5dee\u8f83\u5927\uff0c\u4e14\u6b27\u6c0f\u8ddd\u79bb\u4f5c\u4e3a\u76f8\u4f3c\u6027\u5ea6\u91cf\u66f4\u5173\u6ce8\u5e45\u5ea6\u8bef\u5dee\uff0c\u4e0e\u65b9\u5411\u5bf9\u91cf\u5316\u66f4\u654f\u611f\u7684\u7279\u6027\u76f8\u77db\u76fe\u3002", "method": "\u63d0\u51faPCDVQ\u6846\u67b6\uff0c\u5305\u62ec\u6781\u5750\u6807\u89e3\u8026\uff08PCD\uff09\u548c\u5206\u5e03\u5bf9\u9f50\u7801\u672c\u6784\u5efa\uff08DACC\uff09\uff0c\u5206\u522b\u72ec\u7acb\u91cf\u5316\u65b9\u5411\u4e0e\u5e45\u5ea6\uff0c\u5e76\u4f18\u5316\u7801\u672c\u5206\u5e03\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cPCDVQ\u57282-bit\u91cf\u5316\u6c34\u5e73\u4e0b\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u81f3\u5c11\u63d0\u53471.5%\u7684\u96f6\u6837\u672c\u51c6\u786e\u7387\u3002", "conclusion": "PCDVQ\u4e3a\u9ad8\u538b\u7f29\u4e14\u51c6\u786e\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u8303\u5f0f\u3002"}}
{"id": "2506.05433", "pdf": "https://arxiv.org/pdf/2506.05433", "abs": "https://arxiv.org/abs/2506.05433", "authors": ["Zikang Liu", "Tongtian Yue", "Yepeng Tang", "Longteng Guo", "Junxian Cai", "Qingbin Liu", "Xi Chen", "Jing Liu"], "title": "Prefix Grouper: Efficient GRPO Training through Shared-Prefix Forward", "categories": ["cs.LG", "cs.AI"], "comment": "10 pages, technical report", "summary": "Group Relative Policy Optimization (GRPO) enhances policy learning by\ncomputing gradients from relative comparisons among candidate outputs that\nshare a common input prefix. Despite its effectiveness, GRPO introduces\nsubstantial computational overhead when processing long shared prefixes, which\nmust be redundantly encoded for each group member. This inefficiency becomes a\nmajor scalability bottleneck in long-context learning scenarios. We propose\nPrefix Grouper, an efficient GRPO training algorithm that eliminates redundant\nprefix computation via a Shared-Prefix Forward strategy. In particular, by\nrestructuring self-attention into two parts, our method enables the shared\nprefix to be encoded only once, while preserving full differentiability and\ncompatibility with end-to-end training. We provide both theoretical and\nempirical evidence that Prefix Grouper is training-equivalent to standard GRPO:\nit yields identical forward outputs and backward gradients, ensuring that the\noptimization dynamics and final policy performance remain unchanged.\nEmpirically, our experiments confirm that Prefix Grouper achieves consistent\nresults while significantly reducing the computational cost of training,\nparticularly in long-prefix scenarios. The proposed method is fully\nplug-and-play: it is compatible with existing GRPO-based architectures and can\nbe seamlessly integrated into current training pipelines as a drop-in\nreplacement, requiring no structural modifications and only minimal changes to\ninput construction and attention computation. Prefix Grouper enables the use of\nlarger group sizes under the same computational budget, thereby improving the\nscalability of GRPO to more complex tasks and larger models. Code is now\navailable at https://github.com/johncaged/PrefixGrouper", "AI": {"tldr": "Prefix Grouper\u662f\u4e00\u79cd\u9ad8\u6548\u7684GRPO\u8bad\u7ec3\u7b97\u6cd5\uff0c\u901a\u8fc7\u5171\u4eab\u524d\u7f00\u8ba1\u7b97\u51cf\u5c11\u5197\u4f59\uff0c\u63d0\u5347\u957f\u4e0a\u4e0b\u6587\u5b66\u4e60\u573a\u666f\u7684\u6548\u7387\u3002", "motivation": "GRPO\u5728\u5904\u7406\u957f\u5171\u4eab\u524d\u7f00\u65f6\u5b58\u5728\u8ba1\u7b97\u5197\u4f59\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u5728\u5927\u89c4\u6a21\u4efb\u52a1\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u3002", "method": "\u63d0\u51faShared-Prefix Forward\u7b56\u7565\uff0c\u5c06\u81ea\u6ce8\u610f\u529b\u5206\u4e3a\u4e24\u90e8\u5206\uff0c\u5171\u4eab\u524d\u7f00\u4ec5\u9700\u7f16\u7801\u4e00\u6b21\uff0c\u540c\u65f6\u4fdd\u6301\u7aef\u5230\u7aef\u8bad\u7ec3\u517c\u5bb9\u6027\u3002", "result": "Prefix Grouper\u5728\u4fdd\u6301\u8bad\u7ec3\u7b49\u6548\u6027\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u5c24\u5176\u5728\u957f\u524d\u7f00\u573a\u666f\u4e2d\u3002", "conclusion": "Prefix Grouper\u662f\u4e00\u79cd\u5373\u63d2\u5373\u7528\u7684\u9ad8\u6548\u65b9\u6cd5\uff0c\u53ef\u63d0\u5347GRPO\u5728\u590d\u6742\u4efb\u52a1\u548c\u5927\u6a21\u578b\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2506.05434", "pdf": "https://arxiv.org/pdf/2506.05434", "abs": "https://arxiv.org/abs/2506.05434", "authors": ["Thomas Massena", "L\u00e9o and\u00e9ol", "Thibaut Boissin", "Franck Mamalet", "Corentin Friedrich", "Mathieu Serrurier", "S\u00e9bastien Gerchinovitz"], "title": "Efficient Robust Conformal Prediction via Lipschitz-Bounded Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Conformal Prediction (CP) has proven to be an effective post-hoc method for\nimproving the trustworthiness of neural networks by providing prediction sets\nwith finite-sample guarantees. However, under adversarial attacks, classical\nconformal guarantees do not hold anymore: this problem is addressed in the\nfield of Robust Conformal Prediction. Several methods have been proposed to\nprovide robust CP sets with guarantees under adversarial perturbations, but,\nfor large scale problems, these sets are either too large or the methods are\ntoo computationally demanding to be deployed in real life scenarios. In this\nwork, we propose a new method that leverages Lipschitz-bounded networks to\nprecisely and efficiently estimate robust CP sets. When combined with a\n1-Lipschitz robust network, we demonstrate that our lip-rcp method outperforms\nstate-of-the-art results in both the size of the robust CP sets and\ncomputational efficiency in medium and large-scale scenarios such as ImageNet.\nTaking a different angle, we also study vanilla CP under attack, and derive new\nworst-case coverage bounds of vanilla CP sets, which are valid simultaneously\nfor all adversarial attack levels. Our lip-rcp method makes this second\napproach as efficient as vanilla CP while also allowing robustness guarantees.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3alip-rcp\u7684\u65b0\u65b9\u6cd5\uff0c\u5229\u7528Lipschitz\u6709\u754c\u7f51\u7edc\u9ad8\u6548\u4f30\u8ba1\u9c81\u68d2CP\u96c6\uff0c\u5728\u4e2d\u5927\u89c4\u6a21\u573a\u666f\uff08\u5982ImageNet\uff09\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edfCP\u65b9\u6cd5\u5728\u5bf9\u6297\u653b\u51fb\u4e0b\u5931\u6548\uff0c\u73b0\u6709\u9c81\u68d2CP\u65b9\u6cd5\u5728\u5927\u89c4\u6a21\u95ee\u9898\u4e2d\u8ba1\u7b97\u6210\u672c\u9ad8\u6216\u7ed3\u679c\u96c6\u8fc7\u5927\u3002", "method": "\u7ed3\u54081-Lipschitz\u9c81\u68d2\u7f51\u7edc\uff0c\u63d0\u51falip-rcp\u65b9\u6cd5\uff0c\u7cbe\u786e\u9ad8\u6548\u5730\u4f30\u8ba1\u9c81\u68d2CP\u96c6\u3002", "result": "lip-rcp\u5728\u9c81\u68d2CP\u96c6\u5927\u5c0f\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u540c\u65f6\u4e3a\u666e\u901aCP\u96c6\u63d0\u4f9b\u4e86\u65b0\u7684\u6700\u574f\u60c5\u51b5\u8986\u76d6\u8fb9\u754c\u3002", "conclusion": "lip-rcp\u65b9\u6cd5\u5728\u4fdd\u6301\u9ad8\u6548\u7684\u540c\u65f6\u63d0\u4f9b\u4e86\u9c81\u68d2\u6027\u4fdd\u8bc1\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u573a\u666f\u3002"}}
{"id": "2506.05435", "pdf": "https://arxiv.org/pdf/2506.05435", "abs": "https://arxiv.org/abs/2506.05435", "authors": ["Manon Renault", "Hamoud Younes", "Hugo Tessier", "Ronan Le Roy", "Bastien Pasdeloup", "Mathieu L\u00e9onardon"], "title": "Event Classification of Accelerometer Data for Industrial Package Monitoring with Embedded Deep Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Package monitoring is an important topic in industrial applications, with\nsignificant implications for operational efficiency and ecological\nsustainability. In this study, we propose an approach that employs an embedded\nsystem, placed on reusable packages, to detect their state (on a Forklift, in a\nTruck, or in an undetermined location). We aim to design a system with a\nlifespan of several years, corresponding to the lifespan of reusable packages.\nOur analysis demonstrates that maximizing device lifespan requires minimizing\nwake time. We propose a pipeline that includes data processing, training, and\nevaluation of the deep learning model designed for imbalanced, multiclass time\nseries data collected from an embedded sensor. The method uses a\none-dimensional Convolutional Neural Network architecture to classify\naccelerometer data from the IoT device. Before training, two data augmentation\ntechniques are tested to solve the imbalance problem of the dataset: the\nSynthetic Minority Oversampling TEchnique and the ADAptive SYNthetic sampling\napproach. After training, compression techniques are implemented to have a\nsmall model size. On the considered twoclass problem, the methodology yields a\nprecision of 94.54% for the first class and 95.83% for the second class, while\ncompression techniques reduce the model size by a factor of four. The trained\nmodel is deployed on the IoT device, where it operates with a power consumption\nof 316 mW during inference.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5d4c\u5165\u5f0f\u7cfb\u7edf\u7684\u5305\u88c5\u72b6\u6001\u76d1\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5206\u7c7b\u52a0\u901f\u5ea6\u8ba1\u6570\u636e\uff0c\u4f18\u5316\u8bbe\u5907\u5bff\u547d\u548c\u6a21\u578b\u5927\u5c0f\u3002", "motivation": "\u5de5\u4e1a\u5e94\u7528\u4e2d\u5305\u88c5\u76d1\u6d4b\u5bf9\u6548\u7387\u548c\u53ef\u6301\u7eed\u6027\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8bbe\u8ba1\u957f\u5bff\u547d\u7cfb\u7edf\u3002", "method": "\u4f7f\u7528\u4e00\u7ef4\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5904\u7406\u4e0d\u5e73\u8861\u591a\u7c7b\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u6d4b\u8bd5\u6570\u636e\u589e\u5f3a\u6280\u672f\u5e76\u538b\u7f29\u6a21\u578b\u3002", "result": "\u6a21\u578b\u5728\u4e24\u5206\u7c7b\u95ee\u9898\u4e2d\u7cbe\u5ea6\u8fbe94.54%\u548c95.83%\uff0c\u6a21\u578b\u5927\u5c0f\u51cf\u5c11\u56db\u500d\uff0c\u529f\u8017316mW\u3002", "conclusion": "\u65b9\u6cd5\u6709\u6548\u5b9e\u73b0\u957f\u5bff\u547d\u3001\u9ad8\u6548\u80fd\u7684\u5305\u88c5\u72b6\u6001\u76d1\u6d4b\u7cfb\u7edf\u3002"}}
{"id": "2506.05438", "pdf": "https://arxiv.org/pdf/2506.05438", "abs": "https://arxiv.org/abs/2506.05438", "authors": ["Tongda Sun", "Chen Yin", "Huailiang Zheng", "Yining Dong"], "title": "An Unsupervised Framework for Dynamic Health Indicator Construction and Its Application in Rolling Bearing Prognostics", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Health indicator (HI) plays a key role in degradation assessment and\nprognostics of rolling bearings. Although various HI construction methods have\nbeen investigated, most of them rely on expert knowledge for feature extraction\nand overlook capturing dynamic information hidden in sequential degradation\nprocesses, which limits the ability of the constructed HI for degradation trend\nrepresentation and prognostics. To address these concerns, a novel dynamic HI\nthat considers HI-level temporal dependence is constructed through an\nunsupervised framework. Specifically, a degradation feature learning module\ncomposed of a skip-connection-based autoencoder first maps raw signals to a\nrepresentative degradation feature space (DFS) to automatically extract\nessential degradation features without the need for expert knowledge.\nSubsequently, in this DFS, a new HI-generating module embedded with an inner\nHI-prediction block is proposed for dynamic HI construction, where the temporal\ndependence between past and current HI states is guaranteed and modeled\nexplicitly. On this basis, the dynamic HI captures the inherent dynamic\ncontents of the degradation process, ensuring its effectiveness for degradation\ntendency modeling and future degradation prognostics. The experiment results on\ntwo bearing lifecycle datasets demonstrate that the proposed HI construction\nmethod outperforms comparison methods, and the constructed dynamic HI is\nsuperior for prognostic tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u52a8\u6001\u5065\u5eb7\u6307\u6807\uff08HI\uff09\u6784\u5efa\u65b9\u6cd5\uff0c\u901a\u8fc7\u65e0\u76d1\u7763\u6846\u67b6\u81ea\u52a8\u63d0\u53d6\u9000\u5316\u7279\u5f81\u5e76\u5efa\u6a21\u65f6\u5e8f\u4f9d\u8d56\u6027\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u5065\u5eb7\u6307\u6807\u6784\u5efa\u65b9\u6cd5\u4f9d\u8d56\u4e13\u5bb6\u77e5\u8bc6\u4e14\u5ffd\u7565\u52a8\u6001\u4fe1\u606f\uff0c\u9650\u5236\u4e86\u9000\u5316\u8d8b\u52bf\u8868\u793a\u548c\u9884\u6d4b\u80fd\u529b\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u8df3\u8dc3\u8fde\u63a5\u7684\u81ea\u7f16\u7801\u5668\u63d0\u53d6\u9000\u5316\u7279\u5f81\uff0c\u5e76\u5d4c\u5165HI\u9884\u6d4b\u5757\u6784\u5efa\u52a8\u6001HI\uff0c\u663e\u5f0f\u5efa\u6a21\u65f6\u5e8f\u4f9d\u8d56\u6027\u3002", "result": "\u5728\u4e24\u4e2a\u8f74\u627f\u751f\u547d\u5468\u671f\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u5bf9\u6bd4\u65b9\u6cd5\uff0c\u52a8\u6001HI\u5728\u9884\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u63d0\u51fa\u7684\u52a8\u6001HI\u6784\u5efa\u65b9\u6cd5\u80fd\u6709\u6548\u6355\u6349\u9000\u5316\u8fc7\u7a0b\u7684\u52a8\u6001\u5185\u5bb9\uff0c\u63d0\u5347\u9000\u5316\u8d8b\u52bf\u5efa\u6a21\u548c\u9884\u6d4b\u80fd\u529b\u3002"}}
{"id": "2506.05443", "pdf": "https://arxiv.org/pdf/2506.05443", "abs": "https://arxiv.org/abs/2506.05443", "authors": ["Yiyu Lin", "Yan Wang", "You Zhou", "Xinye Ni", "Jiahui Wu", "Sen Yang"], "title": "UniPTMs: The First Unified Multi-type PTM Site Prediction Model via Master-Slave Architecture-Based Multi-Stage Fusion Strategy and Hierarchical Contrastive Loss", "categories": ["cs.LG", "cs.AI", "q-bio.GN"], "comment": null, "summary": "As a core mechanism of epigenetic regulation in eukaryotes, protein\npost-translational modifications (PTMs) require precise prediction to decipher\ndynamic life activity networks. To address the limitations of existing deep\nlearning models in cross-modal feature fusion, domain generalization, and\narchitectural optimization, this study proposes UniPTMs: the first unified\nframework for multi-type PTM prediction. The framework innovatively establishes\na \"Master-Slave\" dual-path collaborative architecture: The master path\ndynamically integrates high-dimensional representations of protein sequences,\nstructures, and evolutionary information through a Bidirectional Gated\nCross-Attention (BGCA) module, while the slave path optimizes feature\ndiscrepancies and recalibration between structural and traditional features\nusing a Low-Dimensional Fusion Network (LDFN). Complemented by a Multi-scale\nAdaptive convolutional Pyramid (MACP) for capturing local feature patterns and\na Bidirectional Hierarchical Gated Fusion Network (BHGFN) enabling multi-level\nfeature integration across paths, the framework employs a Hierarchical Dynamic\nWeighting Fusion (HDWF) mechanism to intelligently aggregate multimodal\nfeatures. Enhanced by a novel Hierarchical Contrastive loss function for\nfeature consistency optimization, UniPTMs demonstrates significant performance\nimprovements (3.2%-11.4% MCC and 4.2%-14.3% AP increases) over state-of-the-art\nmodels across five modification types and transcends the Single-Type Prediction\nParadigm. To strike a balance between model complexity and performance, we have\nalso developed a lightweight variant named UniPTMs-mini.", "AI": {"tldr": "UniPTMs\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u591a\u7c7b\u578b\u86cb\u767d\u8d28\u7ffb\u8bd1\u540e\u4fee\u9970\uff08PTM\uff09\u9884\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u53cc\u8def\u5f84\u534f\u4f5c\u67b6\u6784\u548c\u591a\u79cd\u6a21\u5757\u4f18\u5316\u7279\u5f81\u878d\u5408\u4e0e\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u8de8\u6a21\u6001\u7279\u5f81\u878d\u5408\u3001\u9886\u57df\u6cdb\u5316\u548c\u67b6\u6784\u4f18\u5316\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u9700\u8981\u66f4\u7cbe\u786e\u7684PTM\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u63d0\u51faUniPTMs\u6846\u67b6\uff0c\u91c7\u7528\u201c\u4e3b-\u4ece\u201d\u53cc\u8def\u5f84\u534f\u4f5c\u67b6\u6784\uff0c\u7ed3\u5408BGCA\u3001LDFN\u3001MACP\u3001BHGFN\u548cHDWF\u7b49\u6a21\u5757\uff0c\u4f18\u5316\u7279\u5f81\u878d\u5408\u4e0e\u9884\u6d4b\u3002", "result": "UniPTMs\u5728\u4e94\u79cd\u4fee\u9970\u7c7b\u578b\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff08MCC\u63d0\u9ad83.2%-11.4%\uff0cAP\u63d0\u9ad84.2%-14.3%\uff09\uff0c\u5e76\u5f00\u53d1\u4e86\u8f7b\u91cf\u7248UniPTMs-mini\u3002", "conclusion": "UniPTMs\u901a\u8fc7\u591a\u6a21\u6001\u7279\u5f81\u878d\u5408\u548c\u67b6\u6784\u521b\u65b0\uff0c\u663e\u8457\u63d0\u5347\u4e86PTM\u9884\u6d4b\u6027\u80fd\uff0c\u540c\u65f6\u517c\u987e\u6a21\u578b\u590d\u6742\u5ea6\u4e0e\u6027\u80fd\u5e73\u8861\u3002"}}
{"id": "2506.05445", "pdf": "https://arxiv.org/pdf/2506.05445", "abs": "https://arxiv.org/abs/2506.05445", "authors": ["Thanh Vinh Vo", "Young Lee", "Haozhe Ma", "Chien Lu", "Tze-Yun Leong"], "title": "Causal Policy Learning in Reinforcement Learning: Backdoor-Adjusted Soft Actor-Critic", "categories": ["cs.LG", "cs.AI"], "comment": "Preprint", "summary": "Hidden confounders that influence both states and actions can bias policy\nlearning in reinforcement learning (RL), leading to suboptimal or\nnon-generalizable behavior. Most RL algorithms ignore this issue, learning\npolicies from observational trajectories based solely on statistical\nassociations rather than causal effects. We propose DoSAC (Do-Calculus Soft\nActor-Critic with Backdoor Adjustment), a principled extension of the SAC\nalgorithm that corrects for hidden confounding via causal intervention\nestimation. DoSAC estimates the interventional policy $\\pi(a | \\mathrm{do}(s))$\nusing the backdoor criterion, without requiring access to true confounders or\ncausal labels. To achieve this, we introduce a learnable Backdoor Reconstructor\nthat infers pseudo-past variables (previous state and action) from the current\nstate to enable backdoor adjustment from observational data. This module is\nintegrated into a soft actor-critic framework to compute both the\ninterventional policy and its entropy. Empirical results on continuous control\nbenchmarks show that DoSAC outperforms baselines under confounded settings,\nwith improved robustness, generalization, and policy reliability.", "AI": {"tldr": "DoSAC\u662f\u4e00\u79cd\u57fa\u4e8e\u56e0\u679c\u5e72\u9884\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u540e\u95e8\u8c03\u6574\u89e3\u51b3\u9690\u85cf\u6df7\u6742\u53d8\u91cf\u95ee\u9898\uff0c\u63d0\u5347\u7b56\u7565\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u9690\u85cf\u6df7\u6742\u53d8\u91cf\u4f1a\u5f71\u54cd\u72b6\u6001\u548c\u52a8\u4f5c\uff0c\u5bfc\u81f4\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5b66\u4e60\u5230\u6709\u504f\u7684\u7b56\u7565\uff0c\u65e0\u6cd5\u6cdb\u5316\u3002", "method": "\u63d0\u51faDoSAC\u7b97\u6cd5\uff0c\u5229\u7528\u540e\u95e8\u91cd\u6784\u5668\u4ece\u89c2\u6d4b\u6570\u636e\u4e2d\u63a8\u65ad\u4f2a\u5386\u53f2\u53d8\u91cf\uff0c\u5b9e\u73b0\u56e0\u679c\u5e72\u9884\u4f30\u8ba1\u3002", "result": "\u5728\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e2d\uff0cDoSAC\u5728\u6df7\u6742\u73af\u5883\u4e0b\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5177\u6709\u66f4\u597d\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u6027\u3002", "conclusion": "DoSAC\u901a\u8fc7\u56e0\u679c\u5e72\u9884\u6709\u6548\u89e3\u51b3\u4e86\u9690\u85cf\u6df7\u6742\u53d8\u91cf\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u7b56\u7565\u5b66\u4e60\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2506.05447", "pdf": "https://arxiv.org/pdf/2506.05447", "abs": "https://arxiv.org/abs/2506.05447", "authors": ["Andrei Mircea", "Supriyo Chakraborty", "Nima Chitsazan", "Irina Rish", "Ekaterina Lobacheva"], "title": "Training Dynamics Underlying Language Model Scaling Laws: Loss Deceleration and Zero-Sum Learning", "categories": ["cs.LG", "cs.AI", "I.2.7"], "comment": "Published as a conference paper at ACL 2025", "summary": "This work aims to understand how scaling improves language models,\nspecifically in terms of training dynamics. We find that language models\nundergo loss deceleration early in training; an abrupt slowdown in the rate of\nloss improvement, resulting in piecewise linear behaviour of the loss curve in\nlog-log space. Scaling up the model mitigates this transition by (1) decreasing\nthe loss at which deceleration occurs, and (2) improving the log-log rate of\nloss improvement after deceleration. We attribute loss deceleration to a type\nof degenerate training dynamics we term zero-sum learning (ZSL). In ZSL,\nper-example gradients become systematically opposed, leading to destructive\ninterference in per-example changes in loss. As a result, improving loss on one\nsubset of examples degrades it on another, bottlenecking overall progress. Loss\ndeceleration and ZSL provide new insights into the training dynamics underlying\nlanguage model scaling laws, and could potentially be targeted directly to\nimprove language models independent of scale. We make our code and artefacts\navailable at: https://github.com/mirandrom/zsl", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u8bed\u8a00\u6a21\u578b\u5728\u8bad\u7ec3\u65e9\u671f\u4f1a\u51fa\u73b0\u635f\u5931\u51cf\u901f\u73b0\u8c61\uff0c\u6a21\u578b\u89c4\u6a21\u7684\u6269\u5927\u53ef\u4ee5\u7f13\u89e3\u8fd9\u4e00\u73b0\u8c61\u3002", "motivation": "\u7406\u89e3\u6a21\u578b\u89c4\u6a21\u5982\u4f55\u901a\u8fc7\u8bad\u7ec3\u52a8\u6001\u6539\u5584\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u3002", "method": "\u5206\u6790\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u4e2d\u7684\u635f\u5931\u66f2\u7ebf\uff0c\u63d0\u51fa\u96f6\u548c\u5b66\u4e60\uff08ZSL\uff09\u6982\u5ff5\u89e3\u91ca\u635f\u5931\u51cf\u901f\u73b0\u8c61\u3002", "result": "\u6a21\u578b\u89c4\u6a21\u6269\u5927\u80fd\u964d\u4f4e\u635f\u5931\u51cf\u901f\u53d1\u751f\u65f6\u7684\u635f\u5931\u503c\uff0c\u5e76\u6539\u5584\u51cf\u901f\u540e\u7684\u635f\u5931\u6539\u8fdb\u901f\u7387\u3002", "conclusion": "\u635f\u5931\u51cf\u901f\u548cZSL\u73b0\u8c61\u4e3a\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u52a8\u6001\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\uff0c\u53ef\u80fd\u76f4\u63a5\u7528\u4e8e\u6539\u8fdb\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2506.05454", "pdf": "https://arxiv.org/pdf/2506.05454", "abs": "https://arxiv.org/abs/2506.05454", "authors": ["Liang Zhang", "Bingcong Li", "Kiran Koshy Thekumparampil", "Sewoong Oh", "Michael Muehlebach", "Niao He"], "title": "Zeroth-Order Optimization Finds Flat Minima", "categories": ["cs.LG", "cs.AI", "math.OC", "stat.ML"], "comment": null, "summary": "Zeroth-order methods are extensively used in machine learning applications\nwhere gradients are infeasible or expensive to compute, such as black-box\nattacks, reinforcement learning, and language model fine-tuning. Existing\noptimization theory focuses on convergence to an arbitrary stationary point,\nbut less is known on the implicit regularization that provides a fine-grained\ncharacterization on which particular solutions are finally reached. We show\nthat zeroth-order optimization with the standard two-point estimator favors\nsolutions with small trace of Hessian, which is widely used in previous work to\ndistinguish between sharp and flat minima. We further provide convergence rates\nof zeroth-order optimization to approximate flat minima for convex and\nsufficiently smooth functions, where flat minima are defined as the minimizers\nthat achieve the smallest trace of Hessian among all optimal solutions.\nExperiments on binary classification tasks with convex losses and language\nmodel fine-tuning support our theoretical findings.", "AI": {"tldr": "\u96f6\u9636\u4f18\u5316\u65b9\u6cd5\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u672c\u6587\u7814\u7a76\u5176\u9690\u5f0f\u6b63\u5219\u5316\u7279\u6027\uff0c\u53d1\u73b0\u6807\u51c6\u4e24\u70b9\u4f30\u8ba1\u5668\u503e\u5411\u4e8e\u9009\u62e9Hessian\u77e9\u9635\u8ff9\u8f83\u5c0f\u7684\u89e3\uff08\u5373\u5e73\u5766\u6700\u5c0f\u503c\uff09\uff0c\u5e76\u7ed9\u51fa\u4e86\u6536\u655b\u901f\u7387\u3002", "motivation": "\u7814\u7a76\u96f6\u9636\u4f18\u5316\u65b9\u6cd5\u5728\u68af\u5ea6\u4e0d\u53ef\u884c\u6216\u8ba1\u7b97\u6602\u8d35\u65f6\u7684\u9690\u5f0f\u6b63\u5219\u5316\u7279\u6027\uff0c\u586b\u8865\u73b0\u6709\u7406\u8bba\u5bf9\u6700\u7ec8\u89e3\u7279\u6027\u7684\u7406\u89e3\u7a7a\u767d\u3002", "method": "\u4f7f\u7528\u6807\u51c6\u4e24\u70b9\u4f30\u8ba1\u5668\u8fdb\u884c\u96f6\u9636\u4f18\u5316\uff0c\u5206\u6790\u5176\u5bf9Hessian\u77e9\u9635\u8ff9\u7684\u5f71\u54cd\uff0c\u5e76\u5b9a\u4e49\u5e73\u5766\u6700\u5c0f\u503c\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u96f6\u9636\u4f18\u5316\u503e\u5411\u4e8e\u5e73\u5766\u6700\u5c0f\u503c\uff0c\u5b9e\u9a8c\u5728\u4e8c\u5206\u7c7b\u4efb\u52a1\u548c\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u4e2d\u9a8c\u8bc1\u4e86\u7ed3\u679c\u3002", "conclusion": "\u96f6\u9636\u4f18\u5316\u65b9\u6cd5\u9690\u5f0f\u504f\u597d\u5e73\u5766\u6700\u5c0f\u503c\uff0c\u4e3a\u76f8\u5173\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2506.05479", "pdf": "https://arxiv.org/pdf/2506.05479", "abs": "https://arxiv.org/abs/2506.05479", "authors": ["Matei Gabriel Co\u015fa", "Marek Eli\u00e1\u0161"], "title": "Learning-Augmented Algorithms for MTS with Bandit Access to Multiple Predictors", "categories": ["cs.LG", "cs.DS", "68W40 (Primary), 68T05 (Secondary)"], "comment": "Accepted to ICML 2025", "summary": "We consider the following problem: We are given $\\ell$ heuristics for\nMetrical Task Systems (MTS), where each might be tailored to a different type\nof input instances. While processing an input instance received online, we are\nallowed to query the action of only one of the heuristics at each time step.\nOur goal is to achieve performance comparable to the best of the given\nheuristics. The main difficulty of our setting comes from the fact that the\ncost paid by a heuristic at time $t$ cannot be estimated unless the same\nheuristic was also queried at time $t-1$. This is related to Bandit Learning\nagainst memory bounded adversaries (Arora et al., 2012). We show how to achieve\nregret of $O(\\text{OPT}^{2/3})$ and prove a tight lower bound based on the\nconstruction of Dekel et al. (2013).", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728Metrical Task Systems\uff08MTS\uff09\u4e2d\u5982\u4f55\u901a\u8fc7\u52a8\u6001\u9009\u62e9\u542f\u53d1\u5f0f\u7b97\u6cd5\u6765\u8fbe\u5230\u6700\u4f73\u6027\u80fd\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u9057\u61be\u7684\u7b97\u6cd5\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u4e0a\u4e0b\u754c\u3002", "motivation": "\u5728MTS\u4e2d\uff0c\u4e0d\u540c\u542f\u53d1\u5f0f\u7b97\u6cd5\u53ef\u80fd\u9002\u7528\u4e8e\u4e0d\u540c\u7c7b\u578b\u7684\u8f93\u5165\u5b9e\u4f8b\uff0c\u4f46\u6bcf\u6b21\u53ea\u80fd\u67e5\u8be2\u4e00\u4e2a\u7b97\u6cd5\u7684\u52a8\u4f5c\u3002\u76ee\u6807\u662f\u8bbe\u8ba1\u4e00\u79cd\u65b9\u6cd5\uff0c\u4f7f\u5176\u6027\u80fd\u63a5\u8fd1\u6700\u4f73\u542f\u53d1\u5f0f\u7b97\u6cd5\u3002", "method": "\u901a\u8fc7\u52a8\u6001\u9009\u62e9\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u5e76\u5728\u6bcf\u6b21\u65f6\u95f4\u6b65\u4ec5\u67e5\u8be2\u4e00\u4e2a\u7b97\u6cd5\u7684\u52a8\u4f5c\uff0c\u540c\u65f6\u8003\u8651\u7b97\u6cd5\u4e4b\u95f4\u7684\u6210\u672c\u5173\u8054\u6027\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7b97\u6cd5\uff0c\u5b9e\u73b0\u4e86$O(\\text{OPT}^{2/3})$\u7684\u9057\u61be\uff0c\u5e76\u57fa\u4e8eDekel\u7b49\u4eba\u7684\u6784\u9020\u8bc1\u660e\u4e86\u5176\u4e0b\u754c\u662f\u7d27\u7684\u3002", "conclusion": "\u672c\u6587\u4e3aMTS\u4e2d\u7684\u52a8\u6001\u542f\u53d1\u5f0f\u9009\u62e9\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u5206\u6790\u9a8c\u8bc1\u4e86\u5176\u6027\u80fd\u6781\u9650\u3002"}}
{"id": "2506.05484", "pdf": "https://arxiv.org/pdf/2506.05484", "abs": "https://arxiv.org/abs/2506.05484", "authors": ["Ruihua Chen", "Bangyu Wu", "Meng Li", "Kai Yang"], "title": "Initial Model Incorporation for Deep Learning FWI: Pretraining or Denormalization?", "categories": ["cs.LG", "physics.geo-ph"], "comment": null, "summary": "Subsurface property neural network reparameterized full waveform inversion\n(FWI) has emerged as an effective unsupervised learning framework, which can\ninvert stably with an inaccurate starting model. It updates the trainable\nneural network parameters instead of fine-tuning on the subsurface model\ndirectly. There are primarily two ways to embed the prior knowledge of the\ninitial model into neural networks, that is, pretraining and denormalization.\nPretraining first regulates the neural networks' parameters by fitting the\ninitial velocity model; Denormalization directly adds the outputs of the\nnetwork into the initial models without pretraining. In this letter, we\nsystematically investigate the influence of the two ways of initial model\nincorporation for the neural network reparameterized FWI. We demonstrate that\npretraining requires inverting the model perturbation based on a constant\nvelocity value (mean) with a two-stage implementation. It leads to a complex\nworkflow and inconsistency of objective functions in the two-stage process,\ncausing the network parameters to become inactive and lose plasticity.\nExperimental results demonstrate that denormalization can simplify workflows,\naccelerate convergence, and enhance inversion accuracy compared with\npretraining.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u4e24\u79cd\u5c06\u521d\u59cb\u6a21\u578b\u77e5\u8bc6\u5d4c\u5165\u795e\u7ecf\u7f51\u7edc\u7684\u65b9\u6cd5\uff08\u9884\u8bad\u7ec3\u548c\u53bb\u5f52\u4e00\u5316\uff09\u5bf9\u5168\u6ce2\u5f62\u53cd\u6f14\uff08FWI\uff09\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u53bb\u5f52\u4e00\u5316\u65b9\u6cd5\u66f4\u4f18\u3002", "motivation": "\u63a2\u8ba8\u5982\u4f55\u5728\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\u5316FWI\u4e2d\u66f4\u6709\u6548\u5730\u5229\u7528\u521d\u59cb\u6a21\u578b\u77e5\u8bc6\uff0c\u4ee5\u63d0\u9ad8\u53cd\u6f14\u7a33\u5b9a\u6027\u548c\u51c6\u786e\u6027\u3002", "method": "\u6bd4\u8f83\u9884\u8bad\u7ec3\u548c\u53bb\u5f52\u4e00\u5316\u4e24\u79cd\u521d\u59cb\u6a21\u578b\u5d4c\u5165\u65b9\u6cd5\uff0c\u5206\u6790\u5176\u5bf9FWI\u7684\u5f71\u54cd\u3002", "result": "\u53bb\u5f52\u4e00\u5316\u65b9\u6cd5\u7b80\u5316\u4e86\u5de5\u4f5c\u6d41\u7a0b\uff0c\u52a0\u901f\u4e86\u6536\u655b\uff0c\u5e76\u63d0\u9ad8\u4e86\u53cd\u6f14\u7cbe\u5ea6\u3002", "conclusion": "\u53bb\u5f52\u4e00\u5316\u65b9\u6cd5\u4f18\u4e8e\u9884\u8bad\u7ec3\uff0c\u66f4\u9002\u5408\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\u5316FWI\u3002"}}
{"id": "2506.05497", "pdf": "https://arxiv.org/pdf/2506.05497", "abs": "https://arxiv.org/abs/2506.05497", "authors": ["Sima Noorani", "Shayan Kiyani", "George Pappas", "Hamed Hassani"], "title": "Conformal Prediction Beyond the Seen: A Missing Mass Perspective for Uncertainty Quantification in Generative Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Uncertainty quantification (UQ) is essential for safe deployment of\ngenerative AI models such as large language models (LLMs), especially in high\nstakes applications. Conformal prediction (CP) offers a principled uncertainty\nquantification framework, but classical methods focus on regression and\nclassification, relying on geometric distances or softmax scores: tools that\npresuppose structured outputs. We depart from this paradigm by studying CP in a\nquery only setting, where prediction sets must be constructed solely from\nfinite queries to a black box generative model, introducing a new trade off\nbetween coverage, test time query budget, and informativeness. We introduce\nConformal Prediction with Query Oracle (CPQ), a framework characterizing the\noptimal interplay between these objectives. Our finite sample algorithm is\nbuilt on two core principles: one governs the optimal query policy, and the\nother defines the optimal mapping from queried samples to prediction sets.\nRemarkably, both are rooted in the classical missing mass problem in\nstatistics. Specifically, the optimal query policy depends on the rate of\ndecay, or the derivative, of the missing mass, for which we develop a novel\nestimator. Meanwhile, the optimal mapping hinges on the missing mass itself,\nwhich we estimate using Good Turing estimators. We then turn our focus to\nimplementing our method for language models, where outputs are vast, variable,\nand often under specified. Fine grained experiments on three real world open\nended tasks and two LLMs, show CPQ applicability to any black box LLM and\nhighlight: (1) individual contribution of each principle to CPQ performance,\nand (2) CPQ ability to yield significantly more informative prediction sets\nthan existing conformal methods for language uncertainty quantification.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86Conformal Prediction with Query Oracle (CPQ)\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u4ec5\u67e5\u8be2\u9ed1\u76d2\u751f\u6210\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\uff0c\u4f18\u5316\u8986\u76d6\u7387\u3001\u67e5\u8be2\u9884\u7b97\u548c\u4fe1\u606f\u91cf\u4e4b\u95f4\u7684\u6743\u8861\u3002", "motivation": "\u751f\u6210\u5f0fAI\u6a21\u578b\uff08\u5982\u5927\u8bed\u8a00\u6a21\u578b\uff09\u5728\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\u9700\u8981\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff08UQ\uff09\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u7ed3\u6784\u5316\u8f93\u51fa\uff0c\u65e0\u6cd5\u76f4\u63a5\u9002\u7528\u3002", "method": "CPQ\u57fa\u4e8e\u4e24\u4e2a\u6838\u5fc3\u539f\u5219\uff1a\u6700\u4f18\u67e5\u8be2\u7b56\u7565\u548c\u6700\u4f18\u6620\u5c04\u65b9\u6cd5\uff0c\u5747\u6e90\u4e8e\u7edf\u8ba1\u4e2d\u7684\u7f3a\u5931\u8d28\u91cf\u95ee\u9898\uff0c\u5e76\u5f00\u53d1\u4e86\u65b0\u4f30\u8ba1\u5668\u3002", "result": "\u5b9e\u9a8c\u8868\u660eCPQ\u9002\u7528\u4e8e\u4efb\u4f55\u9ed1\u76d2\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u80fd\u751f\u6210\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u4fe1\u606f\u4e30\u5bcc\u7684\u9884\u6d4b\u96c6\u3002", "conclusion": "CPQ\u4e3a\u751f\u6210\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\uff0c\u5c24\u5176\u5728\u5f00\u653e\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2506.05500", "pdf": "https://arxiv.org/pdf/2506.05500", "abs": "https://arxiv.org/abs/2506.05500", "authors": ["Alex Damian", "Jason D. Lee", "Joan Bruna"], "title": "The Generative Leap: Sharp Sample Complexity for Efficiently Learning Gaussian Multi-Index Models", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "In this work we consider generic Gaussian Multi-index models, in which the\nlabels only depend on the (Gaussian) $d$-dimensional inputs through their\nprojection onto a low-dimensional $r = O_d(1)$ subspace, and we study efficient\nagnostic estimation procedures for this hidden subspace. We introduce the\n\\emph{generative leap} exponent $k^\\star$, a natural extension of the\ngenerative exponent from [Damian et al.'24] to the multi-index setting. We\nfirst show that a sample complexity of $n=\\Theta(d^{1 \\vee \\k/2})$ is necessary\nin the class of algorithms captured by the Low-Degree-Polynomial framework. We\nthen establish that this sample complexity is also sufficient, by giving an\nagnostic sequential estimation procedure (that is, requiring no prior knowledge\nof the multi-index model) based on a spectral U-statistic over appropriate\nHermite tensors. We further compute the generative leap exponent for several\nexamples including piecewise linear functions (deep ReLU networks with bias),\nand general deep neural networks (with $r$-dimensional first hidden layer).", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u9ad8\u65af\u591a\u6307\u6570\u6a21\u578b\u7684\u9ad8\u6548\u65e0\u76d1\u7763\u4f30\u8ba1\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u751f\u6210\u8df3\u8dc3\u6307\u6570\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u6837\u672c\u590d\u6742\u5ea6\u7684\u5fc5\u8981\u6027\u548c\u5145\u5206\u6027\u3002", "motivation": "\u7814\u7a76\u9ad8\u65af\u591a\u6307\u6570\u6a21\u578b\u4e2d\u4f4e\u7ef4\u5b50\u7a7a\u95f4\u7684\u9ad8\u6548\u65e0\u76d1\u7763\u4f30\u8ba1\u95ee\u9898\u3002", "method": "\u5f15\u5165\u751f\u6210\u8df3\u8dc3\u6307\u6570\uff0c\u57fa\u4e8e\u4f4e\u6b21\u591a\u9879\u5f0f\u6846\u67b6\u5206\u6790\u6837\u672c\u590d\u6742\u5ea6\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8eHermite\u5f20\u91cf\u7684\u8c31U\u7edf\u8ba1\u91cf\u7684\u5e8f\u8d2f\u4f30\u8ba1\u65b9\u6cd5\u3002", "result": "\u8bc1\u660e\u4e86\u6837\u672c\u590d\u6742\u5ea6\u7684\u5fc5\u8981\u6027\u548c\u5145\u5206\u6027\uff0c\u5e76\u8ba1\u7b97\u4e86\u751f\u6210\u8df3\u8dc3\u6307\u6570\u5728\u591a\u79cd\u6a21\u578b\u4e2d\u7684\u5177\u4f53\u503c\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u591a\u6307\u6570\u6a21\u578b\u4e2d\u9ad8\u6548\u4e14\u65e0\u9700\u5148\u9a8c\u77e5\u8bc6\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u3002"}}
{"id": "2506.05513", "pdf": "https://arxiv.org/pdf/2506.05513", "abs": "https://arxiv.org/abs/2506.05513", "authors": ["Yunfei Huang", "David S. Greenberg"], "title": "Geometric and Physical Constraints Synergistically Enhance Neural PDE Surrogates", "categories": ["cs.LG", "physics.flu-dyn"], "comment": null, "summary": "Neural PDE surrogates can improve the cost-accuracy tradeoff of classical\nsolvers, but often generalize poorly to new initial conditions and accumulate\nerrors over time. Physical and symmetry constraints have shown promise in\nclosing this performance gap, but existing techniques for imposing these\ninductive biases are incompatible with the staggered grids commonly used in\ncomputational fluid dynamics. Here we introduce novel input and output layers\nthat respect physical laws and symmetries on the staggered grids, and for the\nfirst time systematically investigate how these constraints, individually and\nin combination, affect the accuracy of PDE surrogates. We focus on two\nchallenging problems: shallow water equations with closed boundaries and\ndecaying incompressible turbulence. Compared to strong baselines, symmetries\nand physical constraints consistently improve performance across tasks,\narchitectures, autoregressive prediction steps, accuracy measures, and network\nsizes. Symmetries are more effective than physical constraints, but surrogates\nwith both performed best, even compared to baselines with data augmentation or\npushforward training, while themselves benefiting from the pushforward trick.\nDoubly-constrained surrogates also generalize better to initial conditions and\ndurations beyond the range of the training data, and more accurately predict\nreal-world ocean currents.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8f93\u5165\u548c\u8f93\u51fa\u5c42\u8bbe\u8ba1\uff0c\u4ee5\u5728\u4ea4\u9519\u7f51\u683c\u4e0a\u6ee1\u8db3\u7269\u7406\u5b9a\u5f8b\u548c\u5bf9\u79f0\u6027\uff0c\u5e76\u7cfb\u7edf\u7814\u7a76\u4e86\u8fd9\u4e9b\u7ea6\u675f\u5bf9PDE\u66ff\u4ee3\u6a21\u578b\u7cbe\u5ea6\u7684\u5f71\u54cd\u3002\u7ed3\u679c\u663e\u793a\uff0c\u5bf9\u79f0\u6027\u548c\u7269\u7406\u7ea6\u675f\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u795e\u7ecfPDE\u66ff\u4ee3\u6a21\u578b\u5728\u65b0\u521d\u59cb\u6761\u4ef6\u548c\u65f6\u95f4\u7d2f\u79ef\u8bef\u5dee\u4e0a\u6cdb\u5316\u80fd\u529b\u5dee\uff0c\u800c\u7269\u7406\u548c\u5bf9\u79f0\u7ea6\u675f\u867d\u6709\u6548\u4f46\u65e0\u6cd5\u517c\u5bb9\u4ea4\u9519\u7f51\u683c\u3002", "method": "\u8bbe\u8ba1\u4e86\u517c\u5bb9\u4ea4\u9519\u7f51\u683c\u7684\u8f93\u5165\u548c\u8f93\u51fa\u5c42\uff0c\u7ed3\u5408\u5bf9\u79f0\u6027\u548c\u7269\u7406\u7ea6\u675f\uff0c\u7814\u7a76\u4e86\u5176\u5bf9PDE\u66ff\u4ee3\u6a21\u578b\u7684\u5f71\u54cd\u3002", "result": "\u5bf9\u79f0\u6027\u548c\u7269\u7406\u7ea6\u675f\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u6cdb\u5316\u80fd\u529b\u548c\u957f\u671f\u9884\u6d4b\u4e0a\u3002", "conclusion": "\u7ed3\u5408\u5bf9\u79f0\u6027\u548c\u7269\u7406\u7ea6\u675f\u7684\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0c\u4f18\u4e8e\u6570\u636e\u589e\u5f3a\u6216\u63a8\u524d\u8bad\u7ec3\u57fa\u7ebf\uff0c\u4e14\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u4e2d\u8868\u73b0\u66f4\u597d\u3002"}}
{"id": "2506.05515", "pdf": "https://arxiv.org/pdf/2506.05515", "abs": "https://arxiv.org/abs/2506.05515", "authors": ["Adrien Cort\u00e9s", "R\u00e9mi Rehm", "Victor Letzelter"], "title": "Winner-takes-all for Multivariate Probabilistic Time Series Forecasting", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "ICML 2025", "summary": "We introduce TimeMCL, a method leveraging the Multiple Choice Learning (MCL)\nparadigm to forecast multiple plausible time series futures. Our approach\nemploys a neural network with multiple heads and utilizes the Winner-Takes-All\n(WTA) loss to promote diversity among predictions. MCL has recently gained\nattention due to its simplicity and ability to address ill-posed and ambiguous\ntasks. We propose an adaptation of this framework for time-series forecasting,\npresenting it as an efficient method to predict diverse futures, which we\nrelate to its implicit quantization objective. We provide insights into our\napproach using synthetic data and evaluate it on real-world time series,\ndemonstrating its promising performance at a light computational cost.", "AI": {"tldr": "TimeMCL\u5229\u7528\u591a\u9009\u62e9\u5b66\u4e60\uff08MCL\uff09\u8303\u5f0f\u9884\u6d4b\u591a\u4e2a\u53ef\u80fd\u7684\u65f6\u95f4\u5e8f\u5217\u672a\u6765\uff0c\u901a\u8fc7\u591a\u5934\u795e\u7ecf\u7f51\u7edc\u548cWTA\u635f\u5931\u63d0\u5347\u9884\u6d4b\u591a\u6837\u6027\u3002", "motivation": "\u89e3\u51b3\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u6a21\u7cca\u6027\u548c\u591a\u6837\u6027\u95ee\u9898\uff0cMCL\u56e0\u5176\u7b80\u5355\u6027\u548c\u5904\u7406\u6a21\u7cca\u4efb\u52a1\u7684\u80fd\u529b\u53d7\u5230\u5173\u6ce8\u3002", "method": "\u91c7\u7528\u591a\u5934\u795e\u7ecf\u7f51\u7edc\u548cWTA\u635f\u5931\uff0c\u9002\u5e94MCL\u6846\u67b6\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u548c\u771f\u5b9e\u65f6\u95f4\u5e8f\u5217\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u8ba1\u7b97\u6210\u672c\u4f4e\u3002", "conclusion": "TimeMCL\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u591a\u6837\u5316\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\u3002"}}
{"id": "2506.05526", "pdf": "https://arxiv.org/pdf/2506.05526", "abs": "https://arxiv.org/abs/2506.05526", "authors": ["Michal Klein", "Alireza Mousavi-Hosseini", "Stephen Zhang", "Marco Cuturi"], "title": "On Fitting Flow Models with Large Sinkhorn Couplings", "categories": ["cs.LG", "stat.ML"], "comment": "20 pages, 14 figures", "summary": "Flow models transform data gradually from one modality (e.g. noise) onto\nanother (e.g. images). Such models are parameterized by a time-dependent\nvelocity field, trained to fit segments connecting pairs of source and target\npoints. When the pairing between source and target points is given, training\nflow models boils down to a supervised regression problem. When no such pairing\nexists, as is the case when generating data from noise, training flows is much\nharder. A popular approach lies in picking source and target points\nindependently. This can, however, lead to velocity fields that are slow to\ntrain, but also costly to integrate at inference time. In theory, one would\ngreatly benefit from training flow models by sampling pairs from an optimal\ntransport (OT) measure coupling source and target, since this would lead to a\nhighly efficient flow solving the Benamou and Brenier dynamical OT problem. In\npractice, recent works have proposed to sample mini-batches of $n$ source and\n$n$ target points and reorder them using an OT solver to form better pairs.\nThese works have advocated using batches of size $n\\approx 256$, and considered\nOT solvers that return couplings that are either sharp (using e.g. the\nHungarian algorithm) or blurred (using e.g. entropic regularization, a.k.a.\nSinkhorn). We follow in the footsteps of these works by exploring the benefits\nof increasing $n$ by three to four orders of magnitude, and look more carefully\non the effect of the entropic regularization $\\varepsilon$ used in the Sinkhorn\nalgorithm. Our analysis is facilitated by new scale invariant quantities to\nreport the sharpness of a coupling, while our sharded computations across\nmultiple GPU or GPU nodes allow scaling up $n$. We show that in both synthetic\nand image generation tasks, flow models greatly benefit when fitted with large\nSinkhorn couplings, with a low entropic regularization $\\varepsilon$.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u901a\u8fc7\u4f18\u5316\u4f20\u8f93\uff08OT\uff09\u65b9\u6cd5\u6539\u8fdb\u6d41\u6a21\u578b\u7684\u8bad\u7ec3\u6548\u7387\uff0c\u7279\u522b\u662f\u901a\u8fc7\u5927\u89c4\u6a21Sinkhorn\u8026\u5408\u548c\u4f4e\u71b5\u6b63\u5219\u5316\u3002", "motivation": "\u6d41\u6a21\u578b\u5728\u65e0\u914d\u5bf9\u6570\u636e\uff08\u5982\u4ece\u566a\u58f0\u751f\u6210\u6570\u636e\uff09\u65f6\u8bad\u7ec3\u56f0\u96be\uff0c\u4f20\u7edf\u65b9\u6cd5\u6548\u7387\u4f4e\u4e14\u63a8\u7406\u6210\u672c\u9ad8\u3002", "method": "\u91c7\u7528\u5927\u89c4\u6a21Sinkhorn\u8026\u5408\uff08\u6279\u91cf\u5927\u5c0f\u589e\u52a03-4\u4e2a\u6570\u91cf\u7ea7\uff09\u548c\u4f4e\u71b5\u6b63\u5219\u5316\uff0c\u5229\u7528\u591aGPU\u8282\u70b9\u6269\u5c55\u8ba1\u7b97\u3002", "result": "\u5728\u5408\u6210\u548c\u56fe\u50cf\u751f\u6210\u4efb\u52a1\u4e2d\uff0c\u6d41\u6a21\u578b\u6027\u80fd\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u5927\u89c4\u6a21Sinkhorn\u8026\u5408\u548c\u4f4e\u71b5\u6b63\u5219\u5316\u80fd\u6709\u6548\u63d0\u9ad8\u6d41\u6a21\u578b\u7684\u8bad\u7ec3\u6548\u7387\u548c\u6027\u80fd\u3002"}}
{"id": "2506.05530", "pdf": "https://arxiv.org/pdf/2506.05530", "abs": "https://arxiv.org/abs/2506.05530", "authors": ["Snir Hordan", "Maya Bechler-Speicher", "Gur Lifshitz", "Nadav Dym"], "title": "Spectral Graph Neural Networks are Incomplete on Graphs with a Simple Spectrum", "categories": ["cs.LG"], "comment": "9 pages main text", "summary": "Spectral features are widely incorporated within Graph Neural Networks (GNNs)\nto improve their expressive power, or their ability to distinguish among\nnon-isomorphic graphs. One popular example is the usage of graph Laplacian\neigenvectors for positional encoding in MPNNs and Graph Transformers. The\nexpressive power of such Spectrally-enhanced GNNs (SGNNs) is usually evaluated\nvia the k-WL graph isomorphism test hierarchy and homomorphism counting. Yet,\nthese frameworks align poorly with the graph spectra, yielding limited insight\ninto SGNNs' expressive power. We leverage a well-studied paradigm of\nclassifying graphs by their largest eigenvalue multiplicity to introduce an\nexpressivity hierarchy for SGNNs. We then prove that many SGNNs are incomplete\neven on graphs with distinct eigenvalues. To mitigate this deficiency, we adapt\nrotation equivariant neural networks to the graph spectra setting to propose a\nmethod to provably improve SGNNs' expressivity on simple spectrum graphs. We\nempirically verify our theoretical claims via an image classification\nexperiment on the MNIST Superpixel dataset and eigenvector canonicalization on\ngraphs from ZINC.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u8c31\u7684GNN\u8868\u8fbe\u80fd\u529b\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u6846\u67b6\uff08\u5982k-WL\u548c\u540c\u6001\u8ba1\u6570\uff09\u4e0e\u56fe\u8c31\u5bf9\u9f50\u6027\u5dee\uff0c\u96be\u4ee5\u51c6\u786e\u8bc4\u4f30SGNN\u7684\u8868\u8fbe\u80fd\u529b\u3002", "method": "\u5229\u7528\u56fe\u7684\u6700\u5927\u7279\u5f81\u503c\u591a\u91cd\u6027\u5206\u7c7b\u65b9\u6cd5\uff0c\u63d0\u51faSGNN\u7684\u8868\u8fbe\u80fd\u529b\u5c42\u6b21\u7ed3\u6784\uff0c\u5e76\u901a\u8fc7\u65cb\u8f6c\u7b49\u53d8\u795e\u7ecf\u7f51\u7edc\u6539\u8fdbSGNN\u7684\u8868\u8fbe\u80fd\u529b\u3002", "result": "\u8bc1\u660e\u4e86\u8bb8\u591aSGNN\u5728\u5177\u6709\u4e0d\u540c\u7279\u5f81\u503c\u7684\u56fe\u4e0a\u4ecd\u4e0d\u5b8c\u6574\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u7406\u8bba\u548c\u5b9e\u9a8c\u4e0a\u5747\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\uff0c\u4e3aSGNN\u7684\u8868\u8fbe\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u7684\u8bc4\u4f30\u548c\u6539\u8fdb\u65b9\u5411\u3002"}}
{"id": "2506.05538", "pdf": "https://arxiv.org/pdf/2506.05538", "abs": "https://arxiv.org/abs/2506.05538", "authors": ["Arnesh Batra", "Anushk Kumar", "Jashn Khemani", "Arush Gumber", "Arhan Jain", "Somil Gupta"], "title": "SocialDF: Benchmark Dataset and Detection Model for Mitigating Harmful Deepfake Content on Social Media Platforms", "categories": ["cs.LG", "cs.MM"], "comment": null, "summary": "The rapid advancement of deep generative models has significantly improved\nthe realism of synthetic media, presenting both opportunities and security\nchallenges. While deepfake technology has valuable applications in\nentertainment and accessibility, it has emerged as a potent vector for\nmisinformation campaigns, particularly on social media. Existing detection\nframeworks struggle to distinguish between benign and adversarially generated\ndeepfakes engineered to manipulate public perception. To address this\nchallenge, we introduce SocialDF, a curated dataset reflecting real-world\ndeepfake challenges on social media platforms. This dataset encompasses\nhigh-fidelity deepfakes sourced from various online ecosystems, ensuring broad\ncoverage of manipulative techniques. We propose a novel LLM-based multi-factor\ndetection approach that combines facial recognition, automated speech\ntranscription, and a multi-agent LLM pipeline to cross-verify audio-visual\ncues. Our methodology emphasizes robust, multi-modal verification techniques\nthat incorporate linguistic, behavioral, and contextual analysis to effectively\ndiscern synthetic media from authentic content.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faSocialDF\u6570\u636e\u96c6\u548c\u57fa\u4e8eLLM\u7684\u591a\u56e0\u7d20\u68c0\u6d4b\u65b9\u6cd5\uff0c\u4ee5\u5e94\u5bf9\u793e\u4ea4\u5a92\u4f53\u4e0a\u6df1\u5ea6\u4f2a\u9020\u6280\u672f\u7684\u6311\u6218\u3002", "motivation": "\u6df1\u5ea6\u4f2a\u9020\u6280\u672f\u7684\u5feb\u901f\u53d1\u5c55\u5e26\u6765\u4e86\u5a31\u4e50\u548c\u53ef\u8bbf\u95ee\u6027\u7684\u673a\u4f1a\uff0c\u4f46\u4e5f\u6210\u4e3a\u4f20\u64ad\u865a\u5047\u4fe1\u606f\u7684\u5de5\u5177\uff0c\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u96be\u4ee5\u533a\u5206\u826f\u6027\u6df1\u5ea6\u4f2a\u9020\u548c\u6076\u610f\u64cd\u7eb5\u5185\u5bb9\u3002", "method": "\u63d0\u51faSocialDF\u6570\u636e\u96c6\uff0c\u5305\u542b\u591a\u79cd\u5728\u7ebf\u751f\u6001\u7cfb\u7edf\u7684\u6df1\u5ea6\u4f2a\u9020\u5185\u5bb9\uff0c\u5e76\u8bbe\u8ba1\u57fa\u4e8eLLM\u7684\u591a\u56e0\u7d20\u68c0\u6d4b\u65b9\u6cd5\uff0c\u7ed3\u5408\u9762\u90e8\u8bc6\u522b\u3001\u8bed\u97f3\u8f6c\u5f55\u548c\u591a\u4ee3\u7406LLM\u7ba1\u9053\u8fdb\u884c\u4ea4\u53c9\u9a8c\u8bc1\u3002", "result": "\u901a\u8fc7\u591a\u6a21\u6001\u9a8c\u8bc1\u6280\u672f\uff08\u8bed\u8a00\u3001\u884c\u4e3a\u548c\u4e0a\u4e0b\u6587\u5206\u6790\uff09\uff0c\u80fd\u6709\u6548\u533a\u5206\u5408\u6210\u5a92\u4f53\u548c\u771f\u5b9e\u5185\u5bb9\u3002", "conclusion": "SocialDF\u6570\u636e\u96c6\u548cLLM\u591a\u56e0\u7d20\u68c0\u6d4b\u65b9\u6cd5\u4e3a\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.05542", "pdf": "https://arxiv.org/pdf/2506.05542", "abs": "https://arxiv.org/abs/2506.05542", "authors": ["Vlastimil Martinek", "Andrea Gariboldi", "Dimosthenis Tzimotoudis", "Aitor Alberdi Escudero", "Edward Blake", "David Cechak", "Luke Cassar", "Alessandro Balestrucci", "Panagiotis Alexiou"], "title": "Agentomics-ML: Autonomous Machine Learning Experimentation Agent for Genomic and Transcriptomic Data", "categories": ["cs.LG", "cs.MA"], "comment": null, "summary": "The adoption of machine learning (ML) and deep learning methods has\nrevolutionized molecular medicine by driving breakthroughs in genomics,\ntranscriptomics, drug discovery, and biological systems modeling. The\nincreasing quantity, multimodality, and heterogeneity of biological datasets\ndemand automated methods that can produce generalizable predictive models.\nRecent developments in large language model-based agents have shown promise for\nautomating end-to-end ML experimentation on structured benchmarks. However,\nwhen applied to heterogeneous computational biology datasets, these methods\nstruggle with generalization and success rates. Here, we introduce\nAgentomics-ML, a fully autonomous agent-based system designed to produce a\nclassification model and the necessary files for reproducible training and\ninference. Our method follows predefined steps of an ML experimentation\nprocess, repeatedly interacting with the file system through Bash to complete\nindividual steps. Once an ML model is produced, training and validation metrics\nprovide scalar feedback to a reflection step to identify issues such as\noverfitting. This step then creates verbal feedback for future iterations,\nsuggesting adjustments to steps such as data representation, model\narchitecture, and hyperparameter choices. We have evaluated Agentomics-ML on\nseveral established genomic and transcriptomic benchmark datasets and show that\nit outperforms existing state-of-the-art agent-based methods in both\ngeneralization and success rates. While state-of-the-art models built by domain\nexperts still lead in absolute performance on the majority of the computational\nbiology datasets used in this work, Agentomics-ML narrows the gap for fully\nautonomous systems and achieves state-of-the-art performance on one of the used\nbenchmark datasets. The code is available at\nhttps://github.com/BioGeMT/Agentomics-ML.", "AI": {"tldr": "Agentomics-ML\u662f\u4e00\u79cd\u5168\u81ea\u52a8\u4ee3\u7406\u7cfb\u7edf\uff0c\u7528\u4e8e\u751f\u6210\u5206\u7c7b\u6a21\u578b\u548c\u53ef\u91cd\u590d\u8bad\u7ec3\u4e0e\u63a8\u7406\u7684\u6587\u4ef6\uff0c\u5728\u8ba1\u7b97\u751f\u7269\u5b66\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u751f\u7269\u6570\u636e\u96c6\u7684\u590d\u6742\u6027\u9700\u8981\u81ea\u52a8\u5316\u65b9\u6cd5\u751f\u6210\u901a\u7528\u9884\u6d4b\u6a21\u578b\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u5f02\u6784\u6570\u636e\u96c6\u4e0a\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u3002", "method": "\u7cfb\u7edf\u901a\u8fc7Bash\u4e0e\u6587\u4ef6\u7cfb\u7edf\u4ea4\u4e92\uff0c\u5b8c\u6210ML\u5b9e\u9a8c\u6b65\u9aa4\uff0c\u5e76\u901a\u8fc7\u53cd\u9988\u8c03\u6574\u6570\u636e\u8868\u793a\u3001\u6a21\u578b\u67b6\u6784\u548c\u8d85\u53c2\u6570\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u4ee3\u7406\u65b9\u6cd5\uff0c\u5e76\u5728\u4e00\u4e2a\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "Agentomics-ML\u7f29\u5c0f\u4e86\u5168\u81ea\u52a8\u7cfb\u7edf\u4e0e\u4e13\u5bb6\u6784\u5efa\u6a21\u578b\u7684\u5dee\u8ddd\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2506.05568", "pdf": "https://arxiv.org/pdf/2506.05568", "abs": "https://arxiv.org/abs/2506.05568", "authors": ["Arian Raje", "Baris Askin", "Divyansh Jhunjhunwala", "Gauri Joshi"], "title": "Ravan: Multi-Head Low-Rank Adaptation for Federated Fine-Tuning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have not yet effectively leveraged the vast\namounts of edge-device data, and federated learning (FL) offers a promising\nparadigm to collaboratively fine-tune LLMs without transferring private edge\ndata to the cloud. To operate within the computation and communication\nconstraints of edge devices, recent literature on federated fine-tuning of LLMs\nproposes the use of low-rank adaptation (LoRA) and similar parameter-efficient\nmethods. However, LoRA-based methods suffer from accuracy degradation in FL\nsettings, primarily because of data and computational heterogeneity across\nclients. We propose \\textsc{Ravan}, an adaptive multi-head LoRA method that\nbalances parameter efficiency and model expressivity by reparameterizing the\nweight updates as the sum of multiple LoRA heads\n$s_i\\textbf{B}_i\\textbf{H}_i\\textbf{A}_i$ in which only the core matrices\n$\\textbf{H}_i$ and their lightweight scaling factors $s_i$ are trained. These\ntrainable scaling factors let the optimization focus on the most useful heads,\nrecovering a higher-rank approximation of the full update without increasing\nthe number of communicated parameters since clients upload $s_i\\textbf{H}_i$\ndirectly. Experiments on vision and language benchmarks show that\n\\textsc{Ravan} improves test accuracy by 2-8\\% over prior parameter-efficient\nbaselines, making it a robust and scalable solution for federated fine-tuning\nof LLMs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRavan\u7684\u81ea\u9002\u5e94\u591a\u5934\u90e8LoRA\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u8054\u90a6\u5b66\u4e60\u4e2d\u9ad8\u6548\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u6570\u636e\u5f02\u6784\u6027\u548c\u8ba1\u7b97\u8d44\u6e90\u9650\u5236\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u6d4b\u8bd5\u51c6\u786e\u7387\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5c1a\u672a\u5145\u5206\u5229\u7528\u8fb9\u7f18\u8bbe\u5907\u6570\u636e\uff0c\u800c\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u63d0\u4f9b\u4e86\u4e00\u79cd\u5728\u4e0d\u4f20\u8f93\u79c1\u6709\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u534f\u4f5c\u5fae\u8c03LLMs\u7684\u8303\u5f0f\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684LoRA\u65b9\u6cd5\u5728FL\u4e2d\u56e0\u6570\u636e\u5f02\u6784\u6027\u548c\u8ba1\u7b97\u8d44\u6e90\u9650\u5236\u5bfc\u81f4\u51c6\u786e\u7387\u4e0b\u964d\u3002", "method": "\u63d0\u51faRavan\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u6743\u91cd\u66f4\u65b0\u91cd\u65b0\u53c2\u6570\u5316\u4e3a\u591a\u4e2aLoRA\u5934\u90e8\u7684\u548c\uff0c\u4ec5\u8bad\u7ec3\u6838\u5fc3\u77e9\u9635\u548c\u8f7b\u91cf\u7ea7\u7f29\u653e\u56e0\u5b50\uff0c\u4f18\u5316\u805a\u7126\u4e8e\u6700\u6709\u7528\u7684\u5934\u90e8\uff0c\u4ece\u800c\u5728\u4e0d\u589e\u52a0\u901a\u4fe1\u53c2\u6570\u7684\u60c5\u51b5\u4e0b\u6062\u590d\u66f4\u9ad8\u79e9\u7684\u66f4\u65b0\u3002", "result": "\u5728\u89c6\u89c9\u548c\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRavan\u6bd4\u73b0\u6709\u53c2\u6570\u9ad8\u6548\u57fa\u7ebf\u65b9\u6cd5\u63d0\u9ad8\u4e862-8%\u7684\u6d4b\u8bd5\u51c6\u786e\u7387\u3002", "conclusion": "Ravan\u662f\u4e00\u79cd\u9c81\u68d2\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u8054\u90a6\u5b66\u4e60\u4e2d\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6548\u5fae\u8c03\u3002"}}
{"id": "2506.05574", "pdf": "https://arxiv.org/pdf/2506.05574", "abs": "https://arxiv.org/abs/2506.05574", "authors": ["Chase Goddard", "Lindsay M. Smith", "Vudtiwat Ngampruetikorn", "David J. Schwab"], "title": "When can in-context learning generalize out of task distribution?", "categories": ["cs.LG", "cond-mat.dis-nn", "cond-mat.stat-mech", "q-bio.NC", "stat.ML"], "comment": null, "summary": "In-context learning (ICL) is a remarkable capability of pretrained\ntransformers that allows models to generalize to unseen tasks after seeing only\na few examples. We investigate empirically the conditions necessary on the\npretraining distribution for ICL to emerge and generalize\n\\emph{out-of-distribution}. Previous work has focused on the number of distinct\ntasks necessary in the pretraining dataset. Here, we use a different notion of\ntask diversity to study the emergence of ICL in transformers trained on linear\nfunctions. We find that as task diversity increases, transformers undergo a\ntransition from a specialized solution, which exhibits ICL only within the\npretraining task distribution, to a solution which generalizes out of\ndistribution to the entire task space. We also investigate the nature of the\nsolutions learned by the transformer on both sides of the transition, and\nobserve similar transitions in nonlinear regression problems. We construct a\nphase diagram to characterize how our concept of task diversity interacts with\nthe number of pretraining tasks. In addition, we explore how factors such as\nthe depth of the model and the dimensionality of the regression problem\ninfluence the transition.", "AI": {"tldr": "\u7814\u7a76\u4e86\u9884\u8bad\u7ec3\u5206\u5e03\u4e2d\u4efb\u52a1\u591a\u6837\u6027\u5bf9\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\u80fd\u529b\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u4efb\u52a1\u591a\u6837\u6027\u589e\u52a0\u65f6\uff0c\u6a21\u578b\u4f1a\u4ece\u4e13\u6709\u89e3\u8fc7\u6e21\u5230\u6cdb\u5316\u89e3\u3002", "motivation": "\u63a2\u7d22\u9884\u8bad\u7ec3\u5206\u5e03\u4e2d\u4efb\u52a1\u591a\u6837\u6027\u5982\u4f55\u5f71\u54cdICL\u80fd\u529b\u7684\u51fa\u73b0\u53ca\u5176\u6cdb\u5316\u6027\u80fd\u3002", "method": "\u4f7f\u7528\u7ebf\u6027\u51fd\u6570\u8bad\u7ec3\u53d8\u6362\u5668\uff0c\u5206\u6790\u4efb\u52a1\u591a\u6837\u6027\u5bf9ICL\u7684\u5f71\u54cd\uff0c\u5e76\u6269\u5c55\u5230\u975e\u7ebf\u6027\u56de\u5f52\u95ee\u9898\u3002", "result": "\u4efb\u52a1\u591a\u6837\u6027\u589e\u52a0\u65f6\uff0c\u6a21\u578b\u4ece\u4e13\u6709\u89e3\u8fc7\u6e21\u5230\u6cdb\u5316\u89e3\uff0c\u4e14\u6a21\u578b\u6df1\u5ea6\u548c\u95ee\u9898\u7ef4\u5ea6\u5f71\u54cd\u8fd9\u4e00\u8fc7\u6e21\u3002", "conclusion": "\u4efb\u52a1\u591a\u6837\u6027\u662fICL\u6cdb\u5316\u7684\u5173\u952e\u56e0\u7d20\uff0c\u6a21\u578b\u7ed3\u6784\u548c\u95ee\u9898\u590d\u6742\u5ea6\u4e5f\u4f1a\u5f71\u54cd\u5176\u8868\u73b0\u3002"}}
{"id": "2506.05577", "pdf": "https://arxiv.org/pdf/2506.05577", "abs": "https://arxiv.org/abs/2506.05577", "authors": ["Saptarshi Nath", "Christos Peridis", "Eseoghene Benjamin", "Xinran Liu", "Soheil Kolouri", "Peter Kinnell", "Zexin Li", "Cong Liu", "Shirin Dora", "Andrea Soltoggio"], "title": "Collaborative Learning in Agentic Systems: A Collective AI is Greater Than the Sum of Its Parts", "categories": ["cs.LG", "cs.AI", "cs.MA", "I.2.6; I.2.11"], "comment": "36 pages, 21 figures, 6 tables. Preprint", "summary": "Agentic AI has gained significant interest as a research paradigm focused on\nautonomy, self-directed learning, and long-term reliability of decision making.\nReal-world agentic systems operate in decentralized settings on a large set of\ntasks or data distributions with constraints such as limited bandwidth,\nasynchronous execution, and the absence of a centralized model or even common\nobjectives. We posit that exploiting previously learned skills, task\nsimilarities, and communication capabilities in a collective of agentic AI are\nchallenging but essential elements to enabling scalability, open-endedness, and\nbeneficial collaborative learning dynamics. In this paper, we introduce Modular\nSharing and Composition in Collective Learning (MOSAIC), an agentic algorithm\nthat allows multiple agents to independently solve different tasks while also\nidentifying, sharing, and reusing useful machine-learned knowledge, without\ncoordination, synchronization, or centralized control. MOSAIC combines three\nmechanisms: (1) modular policy composition via neural network masks, (2) cosine\nsimilarity estimation using Wasserstein embeddings for knowledge selection, and\n(3) asynchronous communication and policy integration. Results on a set of RL\nbenchmarks show that MOSAIC has a greater sample efficiency than isolated\nlearners, i.e., it learns significantly faster, and in some cases, finds\nsolutions to tasks that cannot be solved by isolated learners. The\ncollaborative learning and sharing dynamics are also observed to result in the\nemergence of ideal curricula of tasks, from easy to hard. These findings\nsupport the case for collaborative learning in agentic systems to achieve\nbetter and continuously evolving performance both at the individual and\ncollective levels.", "AI": {"tldr": "MOSAIC\u662f\u4e00\u79cd\u4ee3\u7406AI\u7b97\u6cd5\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u5171\u4eab\u548c\u7ec4\u5408\u5b9e\u73b0\u591a\u4ee3\u7406\u7684\u72ec\u7acb\u4efb\u52a1\u89e3\u51b3\u4e0e\u77e5\u8bc6\u5171\u4eab\uff0c\u63d0\u5347\u5b66\u4e60\u6548\u7387\u548c\u4efb\u52a1\u89e3\u51b3\u80fd\u529b\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u5728\u5206\u6563\u3001\u5f02\u6b65\u3001\u65e0\u4e2d\u5fc3\u63a7\u5236\u7684\u771f\u5b9e\u73af\u5883\u4e2d\uff0c\u901a\u8fc7\u4ee3\u7406AI\u7684\u534f\u4f5c\u5b66\u4e60\u5b9e\u73b0\u53ef\u6269\u5c55\u6027\u548c\u5f00\u653e\u6027\u3002", "method": "\u7ed3\u5408\u6a21\u5757\u5316\u7b56\u7565\u7ec4\u5408\u3001Wasserstein\u5d4c\u5165\u7684\u4f59\u5f26\u76f8\u4f3c\u6027\u4f30\u8ba1\u548c\u5f02\u6b65\u901a\u4fe1\u673a\u5236\u3002", "result": "\u5728RL\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMOSAIC\u6bd4\u72ec\u7acb\u5b66\u4e60\u8005\u66f4\u5feb\u5b66\u4e60\uff0c\u89e3\u51b3\u4e86\u4e00\u4e9b\u72ec\u7acb\u5b66\u4e60\u8005\u65e0\u6cd5\u5b8c\u6210\u7684\u4efb\u52a1\uff0c\u5e76\u89c2\u5bdf\u5230\u4efb\u52a1\u7406\u60f3\u8bfe\u7a0b\u7684\u51fa\u73b0\u3002", "conclusion": "\u534f\u4f5c\u5b66\u4e60\u5728\u4ee3\u7406\u7cfb\u7edf\u4e2d\u80fd\u5b9e\u73b0\u4e2a\u4f53\u548c\u96c6\u4f53\u6027\u80fd\u7684\u6301\u7eed\u63d0\u5347\u3002"}}
{"id": "2506.05583", "pdf": "https://arxiv.org/pdf/2506.05583", "abs": "https://arxiv.org/abs/2506.05583", "authors": ["Nien-Shao Wang", "Duygu Nur Yaldiz", "Yavuz Faruk Bakman", "Sai Praneeth Karimireddy"], "title": "Conformal Prediction Adaptive to Unknown Subpopulation Shifts", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "20 pages, 6 figures, 5 tables, submitted to NeurIPS 2025", "summary": "Conformal prediction is widely used to equip black-box machine learning\nmodels with uncertainty quantification enjoying formal coverage guarantees.\nHowever, these guarantees typically break down in the presence of distribution\nshifts, where the data distribution at test time differs from the training (or\ncalibration-time) distribution. In this work, we address subpopulation shifts,\nwhere the test environment exhibits an unknown and differing mixture of\nsubpopulations compared to the calibration data. We propose new methods that\nprovably adapt conformal prediction to such shifts, ensuring valid coverage\nwithout requiring explicit knowledge of subpopulation structure. Our algorithms\nscale to high-dimensional settings and perform effectively in realistic machine\nlearning tasks. Extensive experiments on vision (with vision transformers) and\nlanguage (with large language models) benchmarks demonstrate that our methods\nreliably maintain coverage and controls risk in scenarios where standard\nconformal prediction fails.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65b0\u65b9\u6cd5\uff0c\u89e3\u51b3\u5171\u5f62\u9884\u6d4b\u5728\u5b50\u7fa4\u4f53\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u5931\u6548\u95ee\u9898\uff0c\u786e\u4fdd\u8986\u76d6\u6709\u6548\u6027\u3002", "motivation": "\u5171\u5f62\u9884\u6d4b\u5728\u5206\u5e03\u504f\u79fb\u65f6\u8986\u76d6\u4fdd\u8bc1\u5931\u6548\uff0c\u5c24\u5176\u5728\u5b50\u7fa4\u4f53\u5206\u5e03\u672a\u77e5\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u63d0\u51fa\u65e0\u9700\u5b50\u7fa4\u4f53\u7ed3\u6784\u5148\u9a8c\u7684\u65b0\u7b97\u6cd5\uff0c\u9002\u5e94\u9ad8\u7ef4\u8bbe\u7f6e\u3002", "result": "\u5728\u89c6\u89c9\u548c\u8bed\u8a00\u4efb\u52a1\u4e2d\uff0c\u65b0\u65b9\u6cd5\u6709\u6548\u7ef4\u6301\u8986\u76d6\u5e76\u63a7\u5236\u98ce\u9669\u3002", "conclusion": "\u65b0\u65b9\u6cd5\u5728\u6807\u51c6\u5171\u5f62\u9884\u6d4b\u5931\u6548\u65f6\u4ecd\u80fd\u53ef\u9760\u5de5\u4f5c\u3002"}}
{"id": "2506.05584", "pdf": "https://arxiv.org/pdf/2506.05584", "abs": "https://arxiv.org/abs/2506.05584", "authors": ["Yuchen Zeng", "Tuan Dinh", "Wonjun Kang", "Andreas C Mueller"], "title": "TabFlex: Scaling Tabular Learning to Millions with Linear Attention", "categories": ["cs.LG"], "comment": "30 pages, ICML 2025", "summary": "Leveraging the in-context learning (ICL) capability of Large Language Models\n(LLMs) for tabular classification has gained significant attention for its\ntraining-free adaptability across diverse datasets. Recent advancements, like\nTabPFN, excel in small-scale tabular datasets but struggle to scale for large\nand complex datasets. Our work enhances the efficiency and scalability of\nTabPFN for larger datasets by incorporating linear attention mechanisms as a\nscalable alternative to complexity-quadratic self-attention. Our model,\nTabFlex, efficiently handles tabular datasets with thousands of features and\nhundreds of classes, scaling seamlessly to millions of samples. For instance,\nTabFlex processes the poker-hand dataset with over a million samples in just 5\nseconds. Our extensive evaluations demonstrate that TabFlex can achieve over a\n2x speedup compared to TabPFN and a 1.5x speedup over XGBoost, outperforming 25\ntested baselines in terms of efficiency across a diverse range of datasets.\nFurthermore, TabFlex remains highly effective on large-scale datasets,\ndelivering strong performance with significantly reduced computational costs,\nespecially when combined with data-efficient techniques such as dimensionality\nreduction and data sampling.", "AI": {"tldr": "TabFlex\u901a\u8fc7\u5f15\u5165\u7ebf\u6027\u6ce8\u610f\u529b\u673a\u5236\u63d0\u5347TabPFN\u7684\u6548\u7387\u4e0e\u53ef\u6269\u5c55\u6027\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u8868\u683c\u6570\u636e\u96c6\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\uff08\u5982TabPFN\uff09\u5728\u5c0f\u89c4\u6a21\u8868\u683c\u6570\u636e\u96c6\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u96be\u4ee5\u6269\u5c55\u5230\u5927\u89c4\u6a21\u590d\u6742\u6570\u636e\u96c6\u3002", "method": "\u91c7\u7528\u7ebf\u6027\u6ce8\u610f\u529b\u673a\u5236\u66ff\u4ee3\u590d\u6742\u5ea6\u4e3a\u4e8c\u6b21\u65b9\u7684\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff0c\u63d0\u5347\u6a21\u578b\u6548\u7387\u3002", "result": "TabFlex\u5728\u767e\u4e07\u7ea7\u6837\u672c\u6570\u636e\u96c6\u4e0a\u5904\u7406\u901f\u5ea6\u663e\u8457\u63d0\u5347\uff0c\u6bd4TabPFN\u5feb2\u500d\uff0c\u6bd4XGBoost\u5feb1.5\u500d\uff0c\u4e14\u8ba1\u7b97\u6210\u672c\u5927\u5e45\u964d\u4f4e\u3002", "conclusion": "TabFlex\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u8868\u683c\u5206\u7c7b\u65b9\u6cd5\uff0c\u5c24\u5176\u9002\u5408\u5927\u89c4\u6a21\u6570\u636e\u96c6\u3002"}}
{"id": "2506.05586", "pdf": "https://arxiv.org/pdf/2506.05586", "abs": "https://arxiv.org/abs/2506.05586", "authors": ["Isha Puri", "Amit Dhurandhar", "Tejaswini Pedapati", "Kartikeyan Shanmugam", "Dennis Wei", "Kush R. Varshney"], "title": "CoFrNets: Interpretable Neural Architecture Inspired by Continued Fractions", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In recent years there has been a considerable amount of research on local\npost hoc explanations for neural networks. However, work on building\ninterpretable neural architectures has been relatively sparse. In this paper,\nwe present a novel neural architecture, CoFrNet, inspired by the form of\ncontinued fractions which are known to have many attractive properties in\nnumber theory, such as fast convergence of approximations to real numbers. We\nshow that CoFrNets can be efficiently trained as well as interpreted leveraging\ntheir particular functional form. Moreover, we prove that such architectures\nare universal approximators based on a proof strategy that is different than\nthe typical strategy used to prove universal approximation results for neural\nnetworks based on infinite width (or depth), which is likely to be of\nindependent interest. We experiment on nonlinear synthetic functions and are\nable to accurately model as well as estimate feature attributions and even\nhigher order terms in some cases, which is a testament to the representational\npower as well as interpretability of such architectures. To further showcase\nthe power of CoFrNets, we experiment on seven real datasets spanning tabular,\ntext and image modalities, and show that they are either comparable or\nsignificantly better than other interpretable models and multilayer\nperceptrons, sometimes approaching the accuracies of state-of-the-art models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u795e\u7ecf\u7f51\u7edc\u67b6\u6784CoFrNet\uff0c\u5176\u7075\u611f\u6765\u81ea\u8fde\u5206\u6570\u7684\u5f62\u5f0f\uff0c\u5177\u6709\u9ad8\u6548\u8bad\u7ec3\u548c\u89e3\u91ca\u6027\u3002\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u8fd1\u5e74\u6765\uff0c\u5c40\u90e8\u4e8b\u540e\u89e3\u91ca\u795e\u7ecf\u7f51\u7edc\u7684\u7814\u7a76\u8f83\u591a\uff0c\u4f46\u6784\u5efa\u53ef\u89e3\u91ca\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u7684\u5de5\u4f5c\u8f83\u5c11\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u8fde\u5206\u6570\u7684CoFrNet\u67b6\u6784\uff0c\u5229\u7528\u5176\u7279\u6b8a\u51fd\u6570\u5f62\u5f0f\u5b9e\u73b0\u9ad8\u6548\u8bad\u7ec3\u548c\u89e3\u91ca\u6027\uff0c\u5e76\u8bc1\u660e\u5176\u901a\u7528\u903c\u8fd1\u80fd\u529b\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0cCoFrNet\u8868\u73b0\u4f18\u5f02\uff0c\u63a5\u8fd1\u6216\u4f18\u4e8e\u5176\u4ed6\u53ef\u89e3\u91ca\u6a21\u578b\u548c\u591a\u5c42\u611f\u77e5\u673a\u3002", "conclusion": "CoFrNet\u517c\u5177\u5f3a\u5927\u7684\u8868\u793a\u80fd\u529b\u548c\u89e3\u91ca\u6027\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u6570\u636e\u7c7b\u578b\uff0c\u4e3a\u53ef\u89e3\u91ca\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.05596", "pdf": "https://arxiv.org/pdf/2506.05596", "abs": "https://arxiv.org/abs/2506.05596", "authors": ["Jes Frellsen", "Maher M. Kassem", "Tone Bengtsen", "Lars Olsen", "Kresten Lindorff-Larsen", "Jesper Ferkinghoff-Borg", "Wouter Boomsma"], "title": "Zero-shot protein stability prediction by inverse folding models: a free energy interpretation", "categories": ["cs.LG", "cs.AI", "q-bio.BM", "stat.ML"], "comment": null, "summary": "Inverse folding models have proven to be highly effective zero-shot\npredictors of protein stability. Despite this success, the link between the\namino acid preferences of an inverse folding model and the free-energy\nconsiderations underlying thermodynamic stability remains incompletely\nunderstood. A better understanding would be of interest not only from a\ntheoretical perspective, but also potentially provide the basis for stronger\nzero-shot stability prediction. In this paper, we take steps to clarify the\nfree-energy foundations of inverse folding models. Our derivation reveals the\nstandard practice of likelihood ratios as a simplistic approximation and\nsuggests several paths towards better estimates of the relative stability. We\nempirically assess these approaches and demonstrate that considerable gains in\nzero-shot performance can be achieved with fairly simple means.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u9006\u6298\u53e0\u6a21\u578b\u4e0e\u86cb\u767d\u8d28\u7a33\u5b9a\u6027\u4e4b\u95f4\u7684\u81ea\u7531\u80fd\u57fa\u7840\u5173\u7cfb\uff0c\u63d0\u51fa\u4e86\u6539\u8fdb\u96f6-shot\u7a33\u5b9a\u6027\u9884\u6d4b\u7684\u65b9\u6cd5\u3002", "motivation": "\u7406\u89e3\u9006\u6298\u53e0\u6a21\u578b\u7684\u6c28\u57fa\u9178\u504f\u597d\u4e0e\u70ed\u529b\u5b66\u7a33\u5b9a\u6027\u81ea\u7531\u80fd\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u4ee5\u63d0\u5347\u96f6-shot\u9884\u6d4b\u6027\u80fd\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u63a8\u5bfc\u63ed\u793a\u4f3c\u7136\u6bd4\u6807\u51c6\u7684\u7b80\u5316\u8fd1\u4f3c\uff0c\u5e76\u63d0\u51fa\u6539\u8fdb\u76f8\u5bf9\u7a33\u5b9a\u6027\u4f30\u8ba1\u7684\u8def\u5f84\uff0c\u968f\u540e\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\u3002", "result": "\u5b9e\u8bc1\u8868\u660e\uff0c\u901a\u8fc7\u7b80\u5355\u65b9\u6cd5\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u96f6-shot\u6027\u80fd\u3002", "conclusion": "\u7814\u7a76\u4e3a\u9006\u6298\u53e0\u6a21\u578b\u7684\u81ea\u7531\u80fd\u57fa\u7840\u63d0\u4f9b\u4e86\u66f4\u6e05\u6670\u7684\u7406\u89e3\uff0c\u5e76\u5c55\u793a\u4e86\u6539\u8fdb\u7a33\u5b9a\u6027\u9884\u6d4b\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.05597", "pdf": "https://arxiv.org/pdf/2506.05597", "abs": "https://arxiv.org/abs/2506.05597", "authors": ["Yash Vijay", "Harini Subramanyan"], "title": "FaCTR: Factorized Channel-Temporal Representation Transformers for Efficient Time Series Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "While Transformers excel in language and vision-where inputs are semantically\nrich and exhibit univariate dependency structures-their architectural\ncomplexity leads to diminishing returns in time series forecasting. Time series\ndata is characterized by low per-timestep information density and complex\ndependencies across channels and covariates, requiring conditioning on\nstructured variable interactions. To address this mismatch and\noverparameterization, we propose FaCTR, a lightweight spatiotemporal\nTransformer with an explicitly structural design. FaCTR injects dynamic,\nsymmetric cross-channel interactions-modeled via a low-rank Factorization\nMachine into temporally contextualized patch embeddings through a learnable\ngating mechanism. It further encodes static and dynamic covariates for\nmultivariate conditioning. Despite its compact design, FaCTR achieves\nstate-of-the-art performance on eleven public forecasting benchmarks spanning\nboth short-term and long-term horizons, with its largest variant using close to\nonly 400K parameters-on average 50x smaller than competitive spatiotemporal\ntransformer baselines. In addition, its structured design enables\ninterpretability through cross-channel influence scores-an essential\nrequirement for real-world decision-making. Finally, FaCTR supports\nself-supervised pretraining, positioning it as a compact yet versatile\nfoundation for downstream time series tasks.", "AI": {"tldr": "FaCTR\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u65f6\u7a7aTransformer\uff0c\u901a\u8fc7\u52a8\u6001\u5bf9\u79f0\u8de8\u901a\u9053\u4ea4\u4e92\u548c\u4f4e\u79e9\u56e0\u5b50\u5206\u89e3\u673a\u4f18\u5316\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u4e14\u53c2\u6570\u66f4\u5c11\u3002", "motivation": "Transformer\u5728\u8bed\u8a00\u548c\u89c6\u89c9\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u56e0\u67b6\u6784\u590d\u6742\u6027\u548c\u6570\u636e\u7279\u6027\uff08\u4fe1\u606f\u5bc6\u5ea6\u4f4e\u3001\u4f9d\u8d56\u590d\u6742\uff09\u800c\u6548\u679c\u4e0d\u4f73\u3002", "method": "FaCTR\u901a\u8fc7\u4f4e\u79e9\u56e0\u5b50\u5206\u89e3\u673a\u5efa\u6a21\u8de8\u901a\u9053\u4ea4\u4e92\uff0c\u7ed3\u5408\u53ef\u5b66\u4e60\u95e8\u63a7\u673a\u5236\u548c\u9759\u6001/\u52a8\u6001\u534f\u53d8\u91cf\u7f16\u7801\uff0c\u5b9e\u73b0\u8f7b\u91cf\u5316\u548c\u7ed3\u6784\u5316\u8bbe\u8ba1\u3002", "result": "\u572811\u4e2a\u516c\u5f00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u6700\u4f18\uff0c\u6700\u5927\u6a21\u578b\u4ec5\u970040\u4e07\u53c2\u6570\uff08\u6bd4\u57fa\u7ebf\u5c0f50\u500d\uff09\uff0c\u5e76\u652f\u6301\u53ef\u89e3\u91ca\u6027\u548c\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u3002", "conclusion": "FaCTR\u662f\u65f6\u95f4\u5e8f\u5217\u4efb\u52a1\u7684\u7d27\u51d1\u4e14\u591a\u529f\u80fd\u57fa\u7840\u6a21\u578b\uff0c\u517c\u5177\u9ad8\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2506.05615", "pdf": "https://arxiv.org/pdf/2506.05615", "abs": "https://arxiv.org/abs/2506.05615", "authors": ["Ruipeng Zhang", "Ya-Chien Chang", "Sicun Gao"], "title": "When Maximum Entropy Misleads Policy Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The Maximum Entropy Reinforcement Learning (MaxEnt RL) framework is a leading\napproach for achieving efficient learning and robust performance across many RL\ntasks. However, MaxEnt methods have also been shown to struggle with\nperformance-critical control problems in practice, where non-MaxEnt algorithms\ncan successfully learn. In this work, we analyze how the trade-off between\nrobustness and optimality affects the performance of MaxEnt algorithms in\ncomplex control tasks: while entropy maximization enhances exploration and\nrobustness, it can also mislead policy optimization, leading to failure in\ntasks that require precise, low-entropy policies. Through experiments on a\nvariety of control problems, we concretely demonstrate this misleading effect.\nOur analysis leads to better understanding of how to balance reward design and\nentropy maximization in challenging control problems.", "AI": {"tldr": "MaxEnt RL\u6846\u67b6\u5728\u590d\u6742\u63a7\u5236\u4efb\u52a1\u4e2d\u53ef\u80fd\u56e0\u71b5\u6700\u5927\u5316\u8bef\u5bfc\u7b56\u7565\u4f18\u5316\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002", "motivation": "\u7814\u7a76MaxEnt RL\u5728\u6027\u80fd\u5173\u952e\u63a7\u5236\u95ee\u9898\u4e2d\u7684\u8868\u73b0\uff0c\u5206\u6790\u5176\u9c81\u68d2\u6027\u4e0e\u6700\u4f18\u6027\u4e4b\u95f4\u7684\u6743\u8861\u3002", "method": "\u901a\u8fc7\u591a\u79cd\u63a7\u5236\u95ee\u9898\u7684\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u71b5\u6700\u5927\u5316\u5bf9\u7b56\u7565\u4f18\u5316\u7684\u8bef\u5bfc\u6548\u5e94\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u71b5\u6700\u5927\u5316\u53ef\u80fd\u963b\u788d\u7cbe\u786e\u3001\u4f4e\u71b5\u7b56\u7565\u7684\u5b66\u4e60\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5728\u590d\u6742\u63a7\u5236\u95ee\u9898\u4e2d\u5e73\u8861\u5956\u52b1\u8bbe\u8ba1\u4e0e\u71b5\u6700\u5927\u5316\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2506.05617", "pdf": "https://arxiv.org/pdf/2506.05617", "abs": "https://arxiv.org/abs/2506.05617", "authors": ["Antonia van Betteray", "Matthias Rottmann", "Karsten Kahl"], "title": "LFA applied to CNNs: Efficient Singular Value Decomposition of Convolutional Mappings by Local Fourier Analysis", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The singular values of convolutional mappings encode interesting spectral\nproperties, which can be used, e.g., to improve generalization and robustness\nof convolutional neural networks as well as to facilitate model compression.\nHowever, the computation of singular values is typically very\nresource-intensive. The naive approach involves unrolling the convolutional\nmapping along the input and channel dimensions into a large and sparse\ntwo-dimensional matrix, making the exact calculation of all singular values\ninfeasible due to hardware limitations. In particular, this is true for\nmatrices that represent convolutional mappings with large inputs and a high\nnumber of channels. Existing efficient methods leverage the Fast Fourier\ntransformation (FFT) to transform convolutional mappings into the frequency\ndomain, enabling the computation of singular values for matrices representing\nconvolutions with larger input and channel dimensions. For a constant number of\nchannels in a given convolution, an FFT can compute N singular values in O(N\nlog N) complexity. In this work, we propose an approach of complexity O(N)\nbased on local Fourier analysis, which additionally exploits the shift\ninvariance of convolutional operators. We provide a theoretical analysis of our\nalgorithm's runtime and validate its efficiency through numerical experiments.\nOur results demonstrate that our proposed method is scalable and offers a\npractical solution to calculate the entire set of singular values - along with\nthe corresponding singular vectors if needed - for high-dimensional\nconvolutional mappings.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5c40\u90e8\u5085\u91cc\u53f6\u5206\u6790\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u9ad8\u6548\u8ba1\u7b97\u5377\u79ef\u6620\u5c04\u7684\u5947\u5f02\u503c\uff0c\u590d\u6742\u5ea6\u4e3aO(N)\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684O(N log N)\u3002", "motivation": "\u5377\u79ef\u6620\u5c04\u7684\u5947\u5f02\u503c\u5177\u6709\u91cd\u8981\u7684\u8c31\u7279\u6027\uff0c\u53ef\u7528\u4e8e\u63d0\u5347\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u6cdb\u5316\u6027\u548c\u9c81\u68d2\u6027\uff0c\u4ee5\u53ca\u6a21\u578b\u538b\u7f29\u3002\u7136\u800c\uff0c\u4f20\u7edf\u65b9\u6cd5\u8ba1\u7b97\u5947\u5f02\u503c\u8d44\u6e90\u6d88\u8017\u5927\uff0c\u96be\u4ee5\u5904\u7406\u9ad8\u7ef4\u8f93\u5165\u548c\u591a\u901a\u9053\u7684\u60c5\u51b5\u3002", "method": "\u5229\u7528\u5c40\u90e8\u5085\u91cc\u53f6\u5206\u6790\u548c\u5377\u79ef\u7b97\u5b50\u7684\u5e73\u79fb\u4e0d\u53d8\u6027\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u590d\u6742\u5ea6\u4e3aO(N)\u7684\u7b97\u6cd5\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u7684\u9ad8\u8d44\u6e90\u6d88\u8017\u95ee\u9898\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\uff0c\u80fd\u591f\u8ba1\u7b97\u9ad8\u7ef4\u5377\u79ef\u6620\u5c04\u7684\u5168\u90e8\u5947\u5f02\u503c\u53ca\u5176\u5bf9\u5e94\u7684\u5947\u5f02\u5411\u91cf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u8ba1\u7b97\u9ad8\u7ef4\u5377\u79ef\u6620\u5c04\u7684\u5947\u5f02\u503c\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2506.05626", "pdf": "https://arxiv.org/pdf/2506.05626", "abs": "https://arxiv.org/abs/2506.05626", "authors": ["Xiaohua Lu", "Liubov Tupikina", "Mehwish Alam"], "title": "Two-dimensional Taxonomy for N-ary Knowledge Representation Learning Methods", "categories": ["cs.LG"], "comment": null, "summary": "Real-world knowledge can take various forms, including structured,\nsemi-structured, and unstructured data. Among these, knowledge graphs are a\nform of structured human knowledge that integrate heterogeneous data sources\ninto structured representations but typically reduce complex n-ary relations to\nsimple triples, thereby losing higher-order relational details. In contrast,\nhypergraphs naturally represent n-ary relations with hyperedges, which directly\nconnect multiple entities together. Yet hypergraph representation learning\noften overlooks entity roles in hyperedges, limiting the fine-grained semantic\nmodelling. To address these issues, knowledge hypergraphs and hyper-relational\nknowledge graphs combine the advantages of knowledge graphs and hypergraphs to\nbetter capture the complex structures and role-specific semantics of real-world\nknowledge. This survey provides a comprehensive review of methods handling\nn-ary relational data, covering both knowledge hypergraphs and hyper-relational\nknowledge graphs literatures. We propose a two-dimensional taxonomy: the first\ndimension categorises models based on their methodology, i.e.,\ntranslation-based models, tensor factorisation-based models, deep neural\nnetwork-based models, logic rules-based models, and hyperedge expansion-based\nmodels. The second dimension classifies models according to their awareness of\nentity roles and positions in n-ary relations, dividing them into aware-less,\nposition-aware, and role-aware approaches. Finally, we discuss existing\ndatasets, negative sampling strategies, and outline open challenges to inspire\nfuture research.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7efc\u8ff0\u4e86\u77e5\u8bc6\u8d85\u56fe\u548c\u8d85\u5173\u7cfb\u77e5\u8bc6\u56fe\u7684\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e8c\u7ef4\u5206\u7c7b\u6cd5\uff0c\u5e76\u8ba8\u8bba\u4e86\u6570\u636e\u96c6\u3001\u8d1f\u91c7\u6837\u7b56\u7565\u53ca\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u89e3\u51b3\u77e5\u8bc6\u56fe\u8c31\u4e2d\u9ad8\u9636\u5173\u7cfb\u7ec6\u8282\u4e22\u5931\u548c\u8d85\u56fe\u4e2d\u5b9e\u4f53\u89d2\u8272\u5ffd\u89c6\u7684\u95ee\u9898\uff0c\u7ed3\u5408\u4e24\u8005\u7684\u4f18\u52bf\u4ee5\u66f4\u597d\u5730\u5efa\u6a21\u73b0\u5b9e\u4e16\u754c\u77e5\u8bc6\u3002", "method": "\u63d0\u51fa\u4e8c\u7ef4\u5206\u7c7b\u6cd5\uff1a\u7b2c\u4e00\u7ef4\u5ea6\u6309\u65b9\u6cd5\uff08\u5982\u7ffb\u8bd1\u6a21\u578b\u3001\u5f20\u91cf\u5206\u89e3\u6a21\u578b\u7b49\uff09\u5206\u7c7b\uff0c\u7b2c\u4e8c\u7ef4\u5ea6\u6309\u5bf9\u5b9e\u4f53\u89d2\u8272\u548c\u4f4d\u7f6e\u7684\u611f\u77e5\u7a0b\u5ea6\u5206\u7c7b\u3002", "result": "\u7efc\u8ff0\u4e86\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u63d0\u4f9b\u4e86\u5206\u7c7b\u6846\u67b6\uff0c\u603b\u7ed3\u4e86\u6570\u636e\u96c6\u548c\u8d1f\u91c7\u6837\u7b56\u7565\u3002", "conclusion": "\u77e5\u8bc6\u8d85\u56fe\u548c\u8d85\u5173\u7cfb\u77e5\u8bc6\u56fe\u80fd\u66f4\u597d\u5730\u6355\u6349\u590d\u6742\u7ed3\u6784\u548c\u8bed\u4e49\uff0c\u672a\u6765\u7814\u7a76\u9700\u89e3\u51b3\u73b0\u6709\u6311\u6218\u3002"}}
{"id": "2506.05628", "pdf": "https://arxiv.org/pdf/2506.05628", "abs": "https://arxiv.org/abs/2506.05628", "authors": ["Jiri Navratil", "Jarret Ross", "Payel Das", "Youssef Mroueh", "Samuel C Hoffman", "Vijil Chenthamarakshan", "Brian Belgodere"], "title": "GP-MoLFormer-Sim: Test Time Molecular Optimization through Contextual Similarity Guidance", "categories": ["cs.LG", "cs.AI"], "comment": "12 pages main article, 21 pages total", "summary": "The ability to design molecules while preserving similarity to a target\nmolecule and/or property is crucial for various applications in drug discovery,\nchemical design, and biology. We introduce in this paper an efficient\ntraining-free method for navigating and sampling from the molecular space with\na generative Chemical Language Model (CLM), while using the molecular\nsimilarity to the target as a guide. Our method leverages the contextual\nrepresentations learned from the CLM itself to estimate the molecular\nsimilarity, which is then used to adjust the autoregressive sampling strategy\nof the CLM. At each step of the decoding process, the method tracks the\ndistance of the current generations from the target and updates the logits to\nencourage the preservation of similarity in generations. We implement the\nmethod using a recently proposed $\\sim$47M parameter SMILES-based CLM,\nGP-MoLFormer, and therefore refer to the method as GP-MoLFormer-Sim, which\nenables a test-time update of the deep generative policy to reflect the\ncontextual similarity to a set of guide molecules. The method is further\nintegrated into a genetic algorithm (GA) and tested on a set of standard\nmolecular optimization benchmarks involving property optimization, molecular\nrediscovery, and structure-based drug design. Results show that,\nGP-MoLFormer-Sim, combined with GA (GP-MoLFormer-Sim+GA) outperforms existing\ntraining-free baseline methods, when the oracle remains black-box. The findings\nin this work are a step forward in understanding and guiding the generative\nmechanisms of CLMs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u5206\u5b50\u751f\u6210\u65b9\u6cd5GP-MoLFormer-Sim\uff0c\u901a\u8fc7\u5316\u5b66\u8bed\u8a00\u6a21\u578b\uff08CLM\uff09\u548c\u5206\u5b50\u76f8\u4f3c\u6027\u5f15\u5bfc\u751f\u6210\uff0c\u7ed3\u5408\u9057\u4f20\u7b97\u6cd5\uff08GA\uff09\u5728\u5206\u5b50\u4f18\u5316\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5728\u836f\u7269\u53d1\u73b0\u548c\u5316\u5b66\u8bbe\u8ba1\u4e2d\uff0c\u8bbe\u8ba1\u5206\u5b50\u65f6\u4fdd\u6301\u4e0e\u76ee\u6807\u5206\u5b50\u7684\u76f8\u4f3c\u6027\u6216\u7279\u5b9a\u6027\u8d28\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u6548\u7387\u4e0d\u8db3\u3002", "method": "\u5229\u7528CLM\u7684\u4e0a\u4e0b\u6587\u8868\u793a\u4f30\u8ba1\u5206\u5b50\u76f8\u4f3c\u6027\uff0c\u8c03\u6574\u81ea\u56de\u5f52\u91c7\u6837\u7b56\u7565\uff0c\u7ed3\u5408\u9057\u4f20\u7b97\u6cd5\u4f18\u5316\u751f\u6210\u8fc7\u7a0b\u3002", "result": "\u5728\u5206\u5b50\u4f18\u5316\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGP-MoLFormer-Sim+GA\u4f18\u4e8e\u73b0\u6709\u65e0\u9700\u8bad\u7ec3\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u7406\u89e3\u548c\u5f15\u5bfcCLM\u751f\u6210\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.05632", "pdf": "https://arxiv.org/pdf/2506.05632", "abs": "https://arxiv.org/abs/2506.05632", "authors": ["Joseph Rowan", "Buu Phan", "Ashish Khisti"], "title": "List-Level Distribution Coupling with Applications to Speculative Decoding and Lossy Compression", "categories": ["cs.LG"], "comment": "Submitted to NeurIPS 2025", "summary": "We study a relaxation of the problem of coupling probability distributions --\na list of samples is generated from one distribution and an accept is declared\nif any one of these samples is identical to the sample generated from the other\ndistribution. We propose a novel method for generating samples, which extends\nthe Gumbel-max sampling suggested in Daliri et al. (arXiv:2408.07978) for\ncoupling probability distributions. We also establish a corresponding lower\nbound on the acceptance probability, which we call the list matching lemma. We\nnext discuss two applications of our setup. First, we develop a new mechanism\nfor multi-draft speculative sampling that is simple to implement and achieves\nperformance competitive with baselines such as SpecTr and SpecInfer across a\nrange of language tasks. Our method also guarantees a certain degree of drafter\ninvariance with respect to the output tokens which is not supported by existing\nschemes. We also provide a theoretical lower bound on the token level\nacceptance probability. As our second application, we consider distributed\nlossy compression with side information in a setting where a source sample is\ncompressed and available to multiple decoders, each with independent side\ninformation. We propose a compression technique that is based on our\ngeneralization of Gumbel-max sampling and show that it provides significant\ngains in experiments involving synthetic Gaussian sources and the MNIST image\ndataset.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6982\u7387\u5206\u5e03\u8026\u5408\u65b9\u6cd5\uff0c\u6269\u5c55\u4e86Gumbel-max\u91c7\u6837\uff0c\u5e76\u5efa\u7acb\u4e86\u63a5\u53d7\u6982\u7387\u7684\u4e0b\u754c\uff08\u5217\u8868\u5339\u914d\u5f15\u7406\uff09\u3002\u8be5\u65b9\u6cd5\u5e94\u7528\u4e8e\u591a\u8349\u7a3f\u63a8\u6d4b\u91c7\u6837\u548c\u5206\u5e03\u5f0f\u6709\u635f\u538b\u7f29\uff0c\u53d6\u5f97\u4e86\u7ade\u4e89\u6027\u6027\u80fd\u3002", "motivation": "\u7814\u7a76\u6982\u7387\u5206\u5e03\u8026\u5408\u95ee\u9898\u7684\u677e\u5f1b\u5f62\u5f0f\uff0c\u63d0\u51fa\u66f4\u9ad8\u6548\u7684\u91c7\u6837\u65b9\u6cd5\uff0c\u5e76\u63a2\u7d22\u5176\u5728\u8bed\u8a00\u4efb\u52a1\u548c\u5206\u5e03\u5f0f\u538b\u7f29\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u6269\u5c55Gumbel-max\u91c7\u6837\uff0c\u63d0\u51fa\u65b0\u65b9\u6cd5\u751f\u6210\u6837\u672c\uff0c\u5e76\u5efa\u7acb\u63a5\u53d7\u6982\u7387\u4e0b\u754c\uff08\u5217\u8868\u5339\u914d\u5f15\u7406\uff09\u3002\u5e94\u7528\u4e8e\u591a\u8349\u7a3f\u63a8\u6d4b\u91c7\u6837\u548c\u5206\u5e03\u5f0f\u538b\u7f29\u3002", "result": "\u5728\u591a\u8349\u7a3f\u63a8\u6d4b\u91c7\u6837\u4e2d\u8868\u73b0\u4e0e\u57fa\u7ebf\u65b9\u6cd5\u7ade\u4e89\uff0c\u4e14\u652f\u6301\u8349\u7a3f\u4e0d\u53d8\u6027\uff1b\u5728\u5206\u5e03\u5f0f\u538b\u7f29\u4e2d\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "\u65b0\u65b9\u6cd5\u5728\u6982\u7387\u5206\u5e03\u8026\u5408\u53ca\u5176\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5177\u6709\u7406\u8bba\u548c\u5b9e\u8df5\u4ef7\u503c\u3002"}}
{"id": "2506.05634", "pdf": "https://arxiv.org/pdf/2506.05634", "abs": "https://arxiv.org/abs/2506.05634", "authors": ["Saeed Hedayatian", "Stefanos Nikolaidis"], "title": "AutoQD: Automatic Discovery of Diverse Behaviors with Quality-Diversity Optimization", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": "22 pages, 5 figures", "summary": "Quality-Diversity (QD) algorithms have shown remarkable success in\ndiscovering diverse, high-performing solutions, but rely heavily on\nhand-crafted behavioral descriptors that constrain exploration to predefined\nnotions of diversity. Leveraging the equivalence between policies and occupancy\nmeasures, we present a theoretically grounded approach to automatically\ngenerate behavioral descriptors by embedding the occupancy measures of policies\nin Markov Decision Processes. Our method, AutoQD, leverages random Fourier\nfeatures to approximate the Maximum Mean Discrepancy (MMD) between policy\noccupancy measures, creating embeddings whose distances reflect meaningful\nbehavioral differences. A low-dimensional projection of these embeddings that\ncaptures the most behaviorally significant dimensions is then used as\nbehavioral descriptors for off-the-shelf QD methods. We prove that our\nembeddings converge to true MMD distances between occupancy measures as the\nnumber of sampled trajectories and embedding dimensions increase. Through\nexperiments in multiple continuous control tasks we demonstrate AutoQD's\nability in discovering diverse policies without predefined behavioral\ndescriptors, presenting a well-motivated alternative to prior methods in\nunsupervised Reinforcement Learning and QD optimization. Our approach opens new\npossibilities for open-ended learning and automated behavior discovery in\nsequential decision making settings without requiring domain-specific\nknowledge.", "AI": {"tldr": "AutoQD\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u751f\u6210\u884c\u4e3a\u63cf\u8ff0\u7b26\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5d4c\u5165\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u7684\u7b56\u7565\u5360\u7528\u5ea6\u91cf\u6765\u66ff\u4ee3\u624b\u5de5\u8bbe\u8ba1\u7684\u63cf\u8ff0\u7b26\uff0c\u4ece\u800c\u5728\u65e0\u76d1\u7763\u5f3a\u5316\u5b66\u4e60\u548cQD\u4f18\u5316\u4e2d\u53d1\u73b0\u591a\u6837\u5316\u7684\u7b56\u7565\u3002", "motivation": "\u4f20\u7edfQD\u7b97\u6cd5\u4f9d\u8d56\u624b\u5de5\u8bbe\u8ba1\u7684\u884c\u4e3a\u63cf\u8ff0\u7b26\uff0c\u9650\u5236\u4e86\u63a2\u7d22\u7684\u591a\u6837\u6027\u3002AutoQD\u65e8\u5728\u901a\u8fc7\u81ea\u52a8\u751f\u6210\u63cf\u8ff0\u7b26\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5229\u7528\u968f\u673a\u5085\u91cc\u53f6\u7279\u5f81\u8fd1\u4f3c\u7b56\u7565\u5360\u7528\u5ea6\u91cf\u4e4b\u95f4\u7684\u6700\u5927\u5747\u503c\u5dee\u5f02\uff08MMD\uff09\uff0c\u751f\u6210\u4f4e\u7ef4\u5d4c\u5165\u4f5c\u4e3a\u884c\u4e3a\u63cf\u8ff0\u7b26\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eAutoQD\u80fd\u5728\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e2d\u53d1\u73b0\u591a\u6837\u5316\u7b56\u7565\uff0c\u65e0\u9700\u9884\u5b9a\u4e49\u63cf\u8ff0\u7b26\u3002", "conclusion": "AutoQD\u4e3a\u65e0\u9886\u57df\u77e5\u8bc6\u7684\u5f00\u653e\u5b66\u4e60\u548c\u884c\u4e3a\u53d1\u73b0\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.05636", "pdf": "https://arxiv.org/pdf/2506.05636", "abs": "https://arxiv.org/abs/2506.05636", "authors": ["Markelle Kelly", "Alex Boyd", "Sam Showalter", "Mark Steyvers", "Padhraic Smyth"], "title": "Bayesian Inference for Correlated Human Experts and Classifiers", "categories": ["cs.LG", "cs.AI"], "comment": "accepted to ICML 2025", "summary": "Applications of machine learning often involve making predictions based on\nboth model outputs and the opinions of human experts. In this context, we\ninvestigate the problem of querying experts for class label predictions, using\nas few human queries as possible, and leveraging the class probability\nestimates of pre-trained classifiers. We develop a general Bayesian framework\nfor this problem, modeling expert correlation via a joint latent\nrepresentation, enabling simulation-based inference about the utility of\nadditional expert queries, as well as inference of posterior distributions over\nunobserved expert labels. We apply our approach to two real-world medical\nclassification problems, as well as to CIFAR-10H and ImageNet-16H,\ndemonstrating substantial reductions relative to baselines in the cost of\nquerying human experts while maintaining high prediction accuracy.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8d1d\u53f6\u65af\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u9884\u8bad\u7ec3\u5206\u7c7b\u5668\u7684\u6982\u7387\u4f30\u8ba1\u548c\u4eba\u7c7b\u4e13\u5bb6\u7684\u610f\u89c1\uff0c\u4ee5\u6700\u5c11\u67e5\u8be2\u6b21\u6570\u5b9e\u73b0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u5728\u673a\u5668\u5b66\u4e60\u5e94\u7528\u4e2d\uff0c\u7ed3\u5408\u6a21\u578b\u8f93\u51fa\u548c\u4eba\u7c7b\u4e13\u5bb6\u7684\u610f\u89c1\u8fdb\u884c\u9884\u6d4b\u662f\u5e38\u89c1\u9700\u6c42\uff0c\u4f46\u5982\u4f55\u4ee5\u6700\u4f4e\u6210\u672c\u83b7\u53d6\u4e13\u5bb6\u610f\u89c1\u662f\u5173\u952e\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u8d1d\u53f6\u65af\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u5408\u6f5c\u5728\u8868\u793a\u5efa\u6a21\u4e13\u5bb6\u76f8\u5173\u6027\uff0c\u652f\u6301\u57fa\u4e8e\u6a21\u62df\u7684\u63a8\u7406\u548c\u672a\u89c2\u5bdf\u4e13\u5bb6\u6807\u7b7e\u7684\u540e\u9a8c\u63a8\u65ad\u3002", "result": "\u5728\u4e24\u4e2a\u771f\u5b9e\u533b\u7597\u5206\u7c7b\u95ee\u9898\u53caCIFAR-10H\u3001ImageNet-16H\u6570\u636e\u96c6\u4e0a\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u4e13\u5bb6\u67e5\u8be2\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u964d\u4f4e\u4e86\u4e13\u5bb6\u67e5\u8be2\u6210\u672c\uff0c\u4e3a\u7ed3\u5408\u6a21\u578b\u548c\u4e13\u5bb6\u610f\u89c1\u7684\u9884\u6d4b\u95ee\u9898\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.05641", "pdf": "https://arxiv.org/pdf/2506.05641", "abs": "https://arxiv.org/abs/2506.05641", "authors": ["Andrey Zhmoginov", "Jihwan Lee", "Mark Sandler"], "title": "Projectable Models: One-Shot Generation of Small Specialized Transformers from Large Ones", "categories": ["cs.LG", "cs.CL"], "comment": "Presented at ES-FoMo II: 2nd Workshop on Efficient Systems for\n  Foundation Models (ICML 2024)", "summary": "Modern Foundation Models (FMs) are typically trained on corpora spanning a\nwide range of different data modalities, topics and downstream tasks. Utilizing\nthese models can be very computationally expensive and is out of reach for most\nconsumer devices. Furthermore, most of the broad FM knowledge may actually be\nirrelevant for a specific task at hand. Here we explore a technique for mapping\nparameters of a large Transformer to parameters of a smaller specialized model.\nBy making this transformation task-specific, we aim to capture a narrower scope\nof the knowledge needed for performing a specific task by a smaller model. We\nstudy our method on image modeling tasks, showing that performance of generated\nmodels exceeds that of universal conditional models.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5c06\u5927\u578bTransformer\u53c2\u6570\u6620\u5c04\u5230\u5c0f\u578b\u4e13\u7528\u6a21\u578b\u53c2\u6570\u7684\u6280\u672f\uff0c\u4ee5\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u5e76\u63d0\u5347\u7279\u5b9a\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u73b0\u4ee3\u57fa\u7840\u6a21\u578b\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u901a\u7528\u77e5\u8bc6\u5bf9\u7279\u5b9a\u4efb\u52a1\u53ef\u80fd\u5197\u4f59\uff0c\u9700\u4e00\u79cd\u65b9\u6cd5\u751f\u6210\u5c0f\u578b\u4e13\u7528\u6a21\u578b\u3002", "method": "\u901a\u8fc7\u4efb\u52a1\u7279\u5b9a\u8f6c\u6362\uff0c\u5c06\u5927\u578bTransformer\u53c2\u6570\u6620\u5c04\u5230\u5c0f\u578b\u6a21\u578b\u53c2\u6570\u3002", "result": "\u5728\u56fe\u50cf\u5efa\u6a21\u4efb\u52a1\u4e2d\uff0c\u751f\u6210\u7684\u5c0f\u578b\u6a21\u578b\u6027\u80fd\u4f18\u4e8e\u901a\u7528\u6761\u4ef6\u6a21\u578b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u5e76\u63d0\u5347\u7279\u5b9a\u4efb\u52a1\u6027\u80fd\u3002"}}
{"id": "2506.05647", "pdf": "https://arxiv.org/pdf/2506.05647", "abs": "https://arxiv.org/abs/2506.05647", "authors": ["Shuangqi Li", "Hieu Le", "Jingyi Xu", "Mathieu Salzmann"], "title": "Learning to Weight Parameters for Data Attribution", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "We study data attribution in generative models, aiming to identify which\ntraining examples most influence a given output. Existing methods achieve this\nby tracing gradients back to training data. However, they typically treat all\nnetwork parameters uniformly, ignoring the fact that different layers encode\ndifferent types of information and may thus draw information differently from\nthe training set. We propose a method that models this by learning parameter\nimportance weights tailored for attribution, without requiring labeled data.\nThis allows the attribution process to adapt to the structure of the model,\ncapturing which training examples contribute to specific semantic aspects of an\noutput, such as subject, style, or background. Our method improves attribution\naccuracy across diffusion models and enables fine-grained insights into how\noutputs borrow from training data.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u751f\u6210\u6a21\u578b\u4e2d\u6570\u636e\u5f52\u5c5e\u95ee\u9898\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b66\u4e60\u53c2\u6570\u91cd\u8981\u6027\u6743\u91cd\u6765\u6539\u8fdb\u5f52\u5c5e\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u8ffd\u8e2a\u8bad\u7ec3\u6570\u636e\u5bf9\u8f93\u51fa\u7684\u5f71\u54cd\u65f6\uff0c\u901a\u5e38\u5ffd\u7565\u7f51\u7edc\u4e0d\u540c\u5c42\u7f16\u7801\u4fe1\u606f\u7684\u5dee\u5f02\uff0c\u5bfc\u81f4\u5f52\u5c5e\u4e0d\u591f\u7cbe\u786e\u3002", "method": "\u901a\u8fc7\u65e0\u76d1\u7763\u5b66\u4e60\u53c2\u6570\u91cd\u8981\u6027\u6743\u91cd\uff0c\u4f7f\u5f52\u5c5e\u8fc7\u7a0b\u9002\u5e94\u6a21\u578b\u7ed3\u6784\uff0c\u6355\u6349\u8bad\u7ec3\u6570\u636e\u5bf9\u8f93\u51fa\u8bed\u4e49\uff08\u5982\u4e3b\u9898\u3001\u98ce\u683c\u6216\u80cc\u666f\uff09\u7684\u8d21\u732e\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u6269\u6563\u6a21\u578b\u4e2d\u63d0\u9ad8\u4e86\u5f52\u5c5e\u51c6\u786e\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u5bf9\u8f93\u51fa\u5982\u4f55\u4ece\u8bad\u7ec3\u6570\u636e\u4e2d\u501f\u9274\u7684\u7ec6\u7c92\u5ea6\u89c1\u89e3\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u901a\u8fc7\u5efa\u6a21\u53c2\u6570\u91cd\u8981\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u6a21\u578b\u4e2d\u6570\u636e\u5f52\u5c5e\u7684\u51c6\u786e\u6027\u548c\u89e3\u91ca\u6027\u3002"}}
{"id": "2506.05664", "pdf": "https://arxiv.org/pdf/2506.05664", "abs": "https://arxiv.org/abs/2506.05664", "authors": ["Chao Zhang", "Li Wang", "Samson Lasaulce", "Merouane Debbah"], "title": "BAQ: Efficient Bit Allocation Quantization for Large Language Models", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Post-training model quantization is a widely adopted technique for reducing\nthe memory and computational costs of large language models (LLMs). However,\nmost existing methods rely on uniform or heuristic bitwidth assignments,\nfailing to account for the nonuniform sensitivity of weights to quantization\nnoise. In this paper, we propose a novel framework for allocating quantization\nbitwidths based on sensitivity metrics derived from a Hessian proxy. We make\nkey assumptions, which allow the layer/component-wise loss function to be\nexpressed as an explicit function of the bitwidths. This enables a neat\nformulation of the bit allocation problem as a convex optimization task, whose\nclosed-form solution adapts precision across weights to minimize the layer-wise\nquantization loss. Inspecting the solution provides several insights (such as\nthe equal-loss structure), which are then exploited to design the proposed\n\\textbf{BAQ} (Bit Allocation Quantization) algorithm. The proposed algorithm\nachieves a good trade-off between loss minimization and complexity and allows\nBAQ to be integrated into standard quantization pipelines with minimal\noverhead. Experimental results show that BAQ consistently outperforms GPTQ,\nachieving up to 56$\\times$ lower perplexity at the same bitwidth on large\nlanguage models ranging from 125M to 30B parameters. Leveraging our analytical\nresults derived from solving the optimal bit allocation problem, we also\nprovide a theoretical explanation for the observed gains. All codes of this\npaper are available at https://github.com/CSU-ModelCompression/BAQ.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eHessian\u4ee3\u7406\u7684\u91cf\u5316\u4f4d\u5bbd\u5206\u914d\u6846\u67b6BAQ\uff0c\u901a\u8fc7\u51f8\u4f18\u5316\u6700\u5c0f\u5316\u91cf\u5316\u635f\u5931\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u91cf\u5316\u65b9\u6cd5\u672a\u8003\u8651\u6743\u91cd\u5bf9\u91cf\u5316\u566a\u58f0\u7684\u975e\u5747\u5300\u654f\u611f\u6027\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0d\u4f73\u3002", "method": "\u57fa\u4e8eHessian\u4ee3\u7406\u7684\u654f\u611f\u6027\u5ea6\u91cf\uff0c\u5c06\u4f4d\u5bbd\u5206\u914d\u95ee\u9898\u8f6c\u5316\u4e3a\u51f8\u4f18\u5316\u4efb\u52a1\uff0c\u63d0\u51faBAQ\u7b97\u6cd5\u3002", "result": "\u5728125M\u523030B\u53c2\u6570\u7684LLM\u4e0a\uff0cBAQ\u6bd4GPTQ\u7684\u56f0\u60d1\u5ea6\u964d\u4f4e56\u500d\u3002", "conclusion": "BAQ\u901a\u8fc7\u4f18\u5316\u4f4d\u5bbd\u5206\u914d\uff0c\u5b9e\u73b0\u4e86\u91cf\u5316\u635f\u5931\u4e0e\u590d\u6742\u5ea6\u7684\u826f\u597d\u5e73\u8861\uff0c\u7406\u8bba\u5206\u6790\u652f\u6301\u5176\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2506.05668", "pdf": "https://arxiv.org/pdf/2506.05668", "abs": "https://arxiv.org/abs/2506.05668", "authors": ["Jiajun He", "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato", "Yuanqi Du", "Francisco Vargas"], "title": "RNE: a plug-and-play framework for diffusion density estimation and inference-time control", "categories": ["cs.LG", "stat.ML"], "comment": "39 pages; 10 figures", "summary": "In this paper, we introduce the Radon-Nikodym Estimator (RNE), a flexible,\nplug-and-play framework for diffusion inference-time density estimation and\ncontrol, based on the concept of the density ratio between path distributions.\nRNE connects and unifies a variety of existing density estimation and\ninference-time control methods under a single and intuitive perspective,\nstemming from basic variational inference and probabilistic principles\ntherefore offering both theoretical clarity and practical versatility.\nExperiments demonstrate that RNE achieves promising performances in diffusion\ndensity estimation and inference-time control tasks, including annealing,\ncomposition of diffusion models, and reward-tilting.", "AI": {"tldr": "Radon-Nikodym Estimator (RNE) \u662f\u4e00\u4e2a\u57fa\u4e8e\u8def\u5f84\u5206\u5e03\u5bc6\u5ea6\u6bd4\u7684\u7075\u6d3b\u6846\u67b6\uff0c\u7528\u4e8e\u6269\u6563\u63a8\u65ad\u65f6\u7684\u5bc6\u5ea6\u4f30\u8ba1\u548c\u63a7\u5236\uff0c\u7edf\u4e00\u4e86\u591a\u79cd\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u7ed3\u5408\u7406\u8bba\u6e05\u6670\u6027\u548c\u5b9e\u8df5\u591a\u6837\u6027\uff0c\u89e3\u51b3\u6269\u6563\u6a21\u578b\u4e2d\u7684\u5bc6\u5ea6\u4f30\u8ba1\u548c\u63a8\u65ad\u63a7\u5236\u95ee\u9898\u3002", "method": "\u5229\u7528\u53d8\u5206\u63a8\u65ad\u548c\u6982\u7387\u539f\u7406\uff0c\u901a\u8fc7\u8def\u5f84\u5206\u5e03\u7684\u5bc6\u5ea6\u6bd4\u6784\u5efa RNE \u6846\u67b6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cRNE \u5728\u6269\u6563\u5bc6\u5ea6\u4f30\u8ba1\u548c\u63a8\u65ad\u63a7\u5236\u4efb\u52a1\uff08\u5982\u9000\u706b\u3001\u6a21\u578b\u7ec4\u5408\u548c\u5956\u52b1\u503e\u659c\uff09\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "RNE \u63d0\u4f9b\u4e86\u4e00\u4e2a\u7406\u8bba\u6e05\u6670\u4e14\u5b9e\u7528\u7684\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u7edf\u4e00\u548c\u6269\u5c55\u73b0\u6709\u7684\u6269\u6563\u6a21\u578b\u5bc6\u5ea6\u4f30\u8ba1\u4e0e\u63a7\u5236\u65b9\u6cd5\u3002"}}
{"id": "2506.05672", "pdf": "https://arxiv.org/pdf/2506.05672", "abs": "https://arxiv.org/abs/2506.05672", "authors": ["Andrey Zhmoginov", "Jihwan Lee", "Max Vladymyrov", "Mark Sandler"], "title": "Contextually Guided Transformers via Low-Rank Adaptation", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) based on Transformers excel at text processing,\nbut their reliance on prompts for specialized behavior introduces computational\noverhead. We propose a modification to a Transformer architecture that\neliminates the need for explicit prompts by learning to encode context into the\nmodel's weights. Our Contextually Guided Transformer (CGT) model maintains a\ncontextual summary at each sequence position, allowing it to update the weights\non the fly based on the preceding context. This approach enables the model to\nself-specialize, effectively creating a tailored model for processing\ninformation following a given prefix. We demonstrate the effectiveness of our\nmethod on synthetic in-context learning tasks and language modeling benchmarks.\nFurthermore, we introduce techniques for enhancing the interpretability of the\nlearned contextual representations, drawing connections to Variational\nAutoencoders and promoting smoother, more consistent context encoding. This\nwork offers a novel direction for efficient and adaptable language modeling by\nintegrating context directly into the model's architecture.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684Transformer\u67b6\u6784\uff08CGT\uff09\uff0c\u901a\u8fc7\u5c06\u4e0a\u4e0b\u6587\u7f16\u7801\u5230\u6a21\u578b\u6743\u91cd\u4e2d\uff0c\u51cf\u5c11\u5bf9\u663e\u5f0f\u63d0\u793a\u7684\u4f9d\u8d56\uff0c\u4ece\u800c\u63d0\u9ad8\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eTransformer\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4f9d\u8d56\u63d0\u793a\u5b9e\u73b0\u7279\u5b9a\u884c\u4e3a\uff0c\u5bfc\u81f4\u8ba1\u7b97\u5f00\u9500\u589e\u52a0\u3002", "method": "\u8bbe\u8ba1\u4e86Contextually Guided Transformer\uff08CGT\uff09\uff0c\u901a\u8fc7\u5728\u6bcf\u4e2a\u5e8f\u5217\u4f4d\u7f6e\u7ef4\u62a4\u4e0a\u4e0b\u6587\u6458\u8981\uff0c\u52a8\u6001\u8c03\u6574\u6743\u91cd\uff0c\u5b9e\u73b0\u6a21\u578b\u7684\u81ea\u9002\u5e94\u3002", "result": "\u5728\u5408\u6210\u4efb\u52a1\u548c\u8bed\u8a00\u5efa\u6a21\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u4e86CGT\u7684\u6709\u6548\u6027\uff0c\u5e76\u63d0\u5347\u4e86\u4e0a\u4e0b\u6587\u8868\u793a\u7684\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u901a\u8fc7\u5c06\u4e0a\u4e0b\u6587\u76f4\u63a5\u96c6\u6210\u5230\u6a21\u578b\u67b6\u6784\u4e2d\uff0c\u4e3a\u9ad8\u6548\u4e14\u9002\u5e94\u6027\u5f3a\u7684\u8bed\u8a00\u5efa\u6a21\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2506.05673", "pdf": "https://arxiv.org/pdf/2506.05673", "abs": "https://arxiv.org/abs/2506.05673", "authors": ["Sajjad Abdoli", "Freeman Lewin", "Gediminas Vasiliauskas", "Fabian Schonholz"], "title": "Peer-Ranked Precision: Creating a Foundational Dataset for Fine-Tuning Vision Models from DataSeeds' Annotated Imagery", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "28 pages, 12 figures", "summary": "The development of modern Artificial Intelligence (AI) models, particularly\ndiffusion-based models employed in computer vision and image generation tasks,\nis undergoing a paradigmatic shift in development methodologies. Traditionally\ndominated by a \"Model Centric\" approach, in which performance gains were\nprimarily pursued through increasingly complex model architectures and\nhyperparameter optimization, the field is now recognizing a more nuanced\n\"Data-Centric\" approach. This emergent framework foregrounds the quality,\nstructure, and relevance of training data as the principal driver of model\nperformance. To operationalize this paradigm shift, we introduce the\nDataSeeds.AI sample dataset (the \"DSD\"), initially comprised of approximately\n10,610 high-quality human peer-ranked photography images accompanied by\nextensive multi-tier annotations. The DSD is a foundational computer vision\ndataset designed to usher in a new standard for commercial image datasets.\nRepresenting a small fraction of DataSeeds.AI's 100 million-plus image catalog,\nthe DSD provides a scalable foundation necessary for robust commercial and\nmultimodal AI development. Through this in-depth exploratory analysis, we\ndocument the quantitative improvements generated by the DSD on specific models\nagainst known benchmarks and make the code and the trained models used in our\nevaluation publicly available.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86AI\u6a21\u578b\u5f00\u53d1\u4ece\u2018\u6a21\u578b\u4e2d\u5fc3\u2019\u5411\u2018\u6570\u636e\u4e2d\u5fc3\u2019\u7684\u8f6c\u53d8\uff0c\u5e76\u4ecb\u7ecd\u4e86\u9ad8\u8d28\u91cf\u6570\u636e\u96c6DSD\u53ca\u5176\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u63d0\u5347\u3002", "motivation": "\u4f20\u7edfAI\u5f00\u53d1\u8fc7\u4e8e\u4f9d\u8d56\u590d\u6742\u6a21\u578b\u67b6\u6784\uff0c\u5ffd\u89c6\u4e86\u6570\u636e\u8d28\u91cf\u7684\u91cd\u8981\u6027\uff0c\u56e0\u6b64\u9700\u8981\u8f6c\u5411\u4ee5\u6570\u636e\u4e3a\u4e2d\u5fc3\u7684\u5f00\u53d1\u65b9\u6cd5\u3002", "method": "\u5f15\u5165DataSeeds.AI\u7684DSD\u6570\u636e\u96c6\uff0c\u5305\u542b10,610\u5f20\u9ad8\u8d28\u91cf\u56fe\u50cf\u53ca\u591a\u7ea7\u6807\u6ce8\uff0c\u7528\u4e8e\u6a21\u578b\u8bad\u7ec3\u548c\u8bc4\u4f30\u3002", "result": "DSD\u663e\u8457\u63d0\u5347\u4e86\u7279\u5b9a\u6a21\u578b\u7684\u6027\u80fd\uff0c\u4ee3\u7801\u548c\u8bad\u7ec3\u6a21\u578b\u5df2\u516c\u5f00\u3002", "conclusion": "\u6570\u636e\u4e2d\u5fc3\u65b9\u6cd5\u662fAI\u5f00\u53d1\u7684\u65b0\u65b9\u5411\uff0cDSD\u4e3a\u5546\u4e1a\u548c\u591a\u6a21\u6001AI\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u57fa\u7840\u3002"}}
{"id": "2506.05676", "pdf": "https://arxiv.org/pdf/2506.05676", "abs": "https://arxiv.org/abs/2506.05676", "authors": ["Haoyang Jiang", "Jindong Wang", "Xingquan Zhu", "Yi He"], "title": "Topology-aware Neural Flux Prediction Guided by Physics", "categories": ["cs.LG"], "comment": null, "summary": "Graph Neural Networks (GNNs) often struggle in preserving high-frequency\ncomponents of nodal signals when dealing with directed graphs. Such components\nare crucial for modeling flow dynamics, without which a traditional GNN tends\nto treat a graph with forward and reverse topologies equal.To make GNNs\nsensitive to those high-frequency components thereby being capable to capture\ndetailed topological differences, this paper proposes a novel framework that\ncombines 1) explicit difference matrices that model directional gradients and\n2) implicit physical constraints that enforce messages passing within GNNs to\nbe consistent with natural laws. Evaluations on two real-world directed graph\ndata, namely, water flux network and urban traffic flow network, demonstrate\nthe effectiveness of our proposal.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u6846\u67b6\uff0c\u7ed3\u5408\u663e\u5f0f\u5dee\u5f02\u77e9\u9635\u548c\u9690\u5f0f\u7269\u7406\u7ea6\u675f\uff0c\u4f7fGNN\u80fd\u6355\u6349\u6709\u5411\u56fe\u4e2d\u7684\u9ad8\u9891\u4fe1\u53f7\u3002", "motivation": "\u4f20\u7edfGNN\u5728\u5904\u7406\u6709\u5411\u56fe\u65f6\u96be\u4ee5\u4fdd\u7559\u9ad8\u9891\u4fe1\u53f7\uff0c\u5bfc\u81f4\u65e0\u6cd5\u533a\u5206\u6b63\u5411\u548c\u53cd\u5411\u62d3\u6251\u7ed3\u6784\u3002", "method": "\u7ed3\u5408\u663e\u5f0f\u5dee\u5f02\u77e9\u9635\u5efa\u6a21\u65b9\u5411\u68af\u5ea6\uff0c\u5e76\u5f15\u5165\u9690\u5f0f\u7269\u7406\u7ea6\u675f\u786e\u4fdd\u6d88\u606f\u4f20\u9012\u7b26\u5408\u81ea\u7136\u89c4\u5f8b\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u7684\u6c34\u901a\u91cf\u7f51\u7edc\u548c\u57ce\u5e02\u4ea4\u901a\u6d41\u7f51\u7edc\u4e0a\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u65b0\u6846\u67b6\u6210\u529f\u63d0\u5347\u4e86GNN\u5bf9\u6709\u5411\u56fe\u4e2d\u9ad8\u9891\u4fe1\u53f7\u7684\u654f\u611f\u6027\u3002"}}
{"id": "2506.05678", "pdf": "https://arxiv.org/pdf/2506.05678", "abs": "https://arxiv.org/abs/2506.05678", "authors": ["Haotian Jiang", "Zeyu Bao", "Shida Wang", "Qianxiao Li"], "title": "Numerical Investigation of Sequence Modeling Theory using Controllable Memory Functions", "categories": ["cs.LG"], "comment": null, "summary": "The evolution of sequence modeling architectures, from recurrent neural\nnetworks and convolutional models to Transformers and structured state-space\nmodels, reflects ongoing efforts to address the diverse temporal dependencies\ninherent in sequential data. Despite this progress, systematically\ncharacterizing the strengths and limitations of these architectures remains a\nfundamental challenge. In this work, we propose a synthetic benchmarking\nframework to evaluate how effectively different sequence models capture\ndistinct temporal structures. The core of this approach is to generate\nsynthetic targets, each characterized by a memory function and a parameter that\ndetermines the strength of temporal dependence. This setup allows us to produce\na continuum of tasks that vary in temporal complexity, enabling fine-grained\nanalysis of model behavior concerning specific memory properties. We focus on\nfour representative memory functions, each corresponding to a distinct class of\ntemporal structures. Experiments on several sequence modeling architectures\nconfirm existing theoretical insights and reveal new findings. These results\ndemonstrate the effectiveness of the proposed method in advancing theoretical\nunderstanding and highlight the importance of using controllable targets with\nclearly defined structures for evaluating sequence modeling architectures.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5408\u6210\u57fa\u51c6\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u4e0d\u540c\u5e8f\u5217\u6a21\u578b\u6355\u6349\u4e0d\u540c\u65f6\u95f4\u7ed3\u6784\u7684\u80fd\u529b\uff0c\u901a\u8fc7\u751f\u6210\u5177\u6709\u660e\u786e\u65f6\u95f4\u4f9d\u8d56\u6027\u7684\u5408\u6210\u76ee\u6807\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u7684\u4f18\u52bf\u548c\u5c40\u9650\u6027\u3002", "motivation": "\u7cfb\u7edf\u5730\u8bc4\u4f30\u5e8f\u5217\u6a21\u578b\u5bf9\u4e0d\u540c\u65f6\u95f4\u7ed3\u6784\u7684\u6355\u6349\u80fd\u529b\uff0c\u586b\u8865\u73b0\u6709\u7814\u7a76\u7684\u7a7a\u767d\u3002", "method": "\u8bbe\u8ba1\u4e86\u5408\u6210\u57fa\u51c6\u6846\u67b6\uff0c\u751f\u6210\u5177\u6709\u4e0d\u540c\u8bb0\u5fc6\u529f\u80fd\u548c\u65f6\u95f4\u4f9d\u8d56\u5f3a\u5ea6\u7684\u76ee\u6807\uff0c\u5bf9\u591a\u79cd\u5e8f\u5217\u6a21\u578b\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u73b0\u6709\u7406\u8bba\u89c1\u89e3\uff0c\u5e76\u63ed\u793a\u4e86\u65b0\u53d1\u73b0\uff0c\u8bc1\u660e\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u52a9\u4e8e\u7406\u8bba\u7406\u89e3\uff0c\u5e76\u5f3a\u8c03\u4e86\u4f7f\u7528\u5177\u6709\u660e\u786e\u7ed3\u6784\u7684\u53ef\u63a7\u76ee\u6807\u5bf9\u8bc4\u4f30\u5e8f\u5217\u6a21\u578b\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2506.05680", "pdf": "https://arxiv.org/pdf/2506.05680", "abs": "https://arxiv.org/abs/2506.05680", "authors": ["Tailin Zhou", "Zhilin Chen", "Wenlong Lyu", "Zhitang Chen", "Danny H. K. Tsang", "Jun Zhang"], "title": "Learning Design-Score Manifold to Guide Diffusion Models for Offline Optimization", "categories": ["cs.LG", "cs.AI"], "comment": "This manuscript is submitted and under review", "summary": "Optimizing complex systems, from discovering therapeutic drugs to designing\nhigh-performance materials, remains a fundamental challenge across science and\nengineering, as the underlying rules are often unknown and costly to evaluate.\nOffline optimization aims to optimize designs for target scores using\npre-collected datasets without system interaction. However, conventional\napproaches may fail beyond training data, predicting inaccurate scores and\ngenerating inferior designs. This paper introduces ManGO, a diffusion-based\nframework that learns the design-score manifold, capturing the design-score\ninterdependencies holistically. Unlike existing methods that treat design and\nscore spaces in isolation, ManGO unifies forward prediction and backward\ngeneration, attaining generalization beyond training data. Key to this is its\nderivative-free guidance for conditional generation, coupled with adaptive\ninference-time scaling that dynamically optimizes denoising paths. Extensive\nevaluations demonstrate that ManGO outperforms 24 single- and 10\nmulti-objective optimization methods across diverse domains, including\nsynthetic tasks, robot control, material design, DNA sequence, and real-world\nengineering optimization.", "AI": {"tldr": "ManGO\u662f\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5b66\u4e60\u8bbe\u8ba1-\u8bc4\u5206\u6d41\u5f62\uff0c\u7edf\u4e00\u524d\u5411\u9884\u6d4b\u548c\u540e\u5411\u751f\u6210\uff0c\u5b9e\u73b0\u4e86\u5728\u8bad\u7ec3\u6570\u636e\u4e4b\u5916\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u590d\u6742\u7cfb\u7edf\u7684\u4f18\u5316\u662f\u4e00\u4e2a\u57fa\u7840\u6027\u6311\u6218\uff0c\u4f20\u7edf\u79bb\u7ebf\u4f18\u5316\u65b9\u6cd5\u5728\u8bad\u7ec3\u6570\u636e\u4e4b\u5916\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u6355\u6349\u8bbe\u8ba1-\u8bc4\u5206\u4f9d\u8d56\u5173\u7cfb\u7684\u65b0\u65b9\u6cd5\u3002", "method": "ManGO\u91c7\u7528\u6269\u6563\u6a21\u578b\u5b66\u4e60\u8bbe\u8ba1-\u8bc4\u5206\u6d41\u5f62\uff0c\u7ed3\u5408\u65e0\u5bfc\u6570\u5f15\u5bfc\u7684\u6761\u4ef6\u751f\u6210\u548c\u81ea\u9002\u5e94\u63a8\u7406\u65f6\u95f4\u7f29\u653e\uff0c\u52a8\u6001\u4f18\u5316\u53bb\u566a\u8def\u5f84\u3002", "result": "ManGO\u5728\u5408\u6210\u4efb\u52a1\u3001\u673a\u5668\u4eba\u63a7\u5236\u3001\u6750\u6599\u8bbe\u8ba1\u7b49\u591a\u4e2a\u9886\u57df\u4f18\u4e8e24\u79cd\u5355\u76ee\u6807\u548c10\u79cd\u591a\u76ee\u6807\u4f18\u5316\u65b9\u6cd5\u3002", "conclusion": "ManGO\u901a\u8fc7\u7edf\u4e00\u8bbe\u8ba1-\u8bc4\u5206\u7a7a\u95f4\uff0c\u5b9e\u73b0\u4e86\u66f4\u5f3a\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u590d\u6742\u7cfb\u7edf\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.05683", "pdf": "https://arxiv.org/pdf/2506.05683", "abs": "https://arxiv.org/abs/2506.05683", "authors": ["Fardis Nadimi", "Payam Abdisarabshali", "Kasra Borazjani", "Jacob Chakareski", "Seyyedali Hosseinalipour"], "title": "Multi-Modal Multi-Task Federated Foundation Models for Next-Generation Extended Reality Systems: Towards Privacy-Preserving Distributed Intelligence in AR/VR/MR", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.MM"], "comment": "16 pages, 4 Figures, 8 Tables", "summary": "Extended reality (XR) systems, which consist of virtual reality (VR),\naugmented reality (AR), and mixed reality (XR), offer a transformative\ninterface for immersive, multi-modal, and embodied human-computer interaction.\nIn this paper, we envision that multi-modal multi-task (M3T) federated\nfoundation models (FedFMs) can offer transformative capabilities for XR systems\nthrough integrating the representational strength of M3T foundation models\n(FMs) with the privacy-preserving model training principles of federated\nlearning (FL). We present a modular architecture for FedFMs, which entails\ndifferent coordination paradigms for model training and aggregations. Central\nto our vision is the codification of XR challenges that affect the\nimplementation of FedFMs under the SHIFT dimensions: (1) Sensor and modality\ndiversity, (2) Hardware heterogeneity and system-level constraints, (3)\nInteractivity and embodied personalization, (4) Functional/task variability,\nand (5) Temporality and environmental variability. We illustrate the\nmanifestation of these dimensions across a set of emerging and anticipated\napplications of XR systems. Finally, we propose evaluation metrics, dataset\nrequirements, and design tradeoffs necessary for the development of\nresource-aware FedFMs in XR. This perspective aims to chart the technical and\nconceptual foundations for context-aware privacy-preserving intelligence in the\nnext generation of XR systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u6a21\u6001\u591a\u4efb\u52a1\uff08M3T\uff09\u8054\u90a6\u57fa\u7840\u6a21\u578b\uff08FedFMs\uff09\u7684\u6269\u5c55\u73b0\u5b9e\uff08XR\uff09\u7cfb\u7edf\u67b6\u6784\uff0c\u65e8\u5728\u901a\u8fc7\u7ed3\u5408\u57fa\u7840\u6a21\u578b\u7684\u8868\u793a\u80fd\u529b\u548c\u8054\u90a6\u5b66\u4e60\u7684\u9690\u79c1\u4fdd\u62a4\u7279\u6027\uff0c\u89e3\u51b3XR\u7cfb\u7edf\u4e2d\u7684\u5173\u952e\u6311\u6218\u3002", "motivation": "\u6269\u5c55\u73b0\u5b9e\uff08XR\uff09\u7cfb\u7edf\u9700\u8981\u5904\u7406\u591a\u6a21\u6001\u3001\u9690\u79c1\u4fdd\u62a4\u548c\u8d44\u6e90\u9650\u5236\u7b49\u590d\u6742\u95ee\u9898\uff0c\u800c\u73b0\u6709\u7684\u65b9\u6cd5\u96be\u4ee5\u517c\u987e\u8fd9\u4e9b\u9700\u6c42\u3002\u56e0\u6b64\uff0c\u8bba\u6587\u63d0\u51faFedFMs\u67b6\u6784\uff0c\u4ee5\u63d0\u4f9b\u4e00\u79cd\u9690\u79c1\u4fdd\u62a4\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u5757\u5316\u7684FedFMs\u67b6\u6784\uff0c\u5305\u62ec\u6a21\u578b\u8bad\u7ec3\u548c\u805a\u5408\u7684\u534f\u8c03\u8303\u5f0f\uff0c\u5e76\u5b9a\u4e49\u4e86\u5f71\u54cdFedFMs\u5b9e\u65bd\u7684SHIFT\u7ef4\u5ea6\uff08\u4f20\u611f\u5668\u591a\u6837\u6027\u3001\u786c\u4ef6\u5f02\u6784\u6027\u3001\u4ea4\u4e92\u6027\u3001\u4efb\u52a1\u53ef\u53d8\u6027\u548c\u65f6\u95f4\u6027\uff09\u3002", "result": "\u8bba\u6587\u5c55\u793a\u4e86FedFMs\u5728XR\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u5e76\u63d0\u51fa\u4e86\u8bc4\u4f30\u6307\u6807\u3001\u6570\u636e\u96c6\u9700\u6c42\u548c\u8bbe\u8ba1\u6743\u8861\uff0c\u4e3a\u8d44\u6e90\u611f\u77e5\u7684FedFMs\u5f00\u53d1\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "\u8bba\u6587\u4e3a\u4e0b\u4e00\u4ee3XR\u7cfb\u7edf\u4e2d\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u9690\u79c1\u4fdd\u62a4\u667a\u80fd\u6280\u672f\u5960\u5b9a\u4e86\u6280\u672f\u548c\u6982\u5ff5\u57fa\u7840\u3002"}}
{"id": "2506.05701", "pdf": "https://arxiv.org/pdf/2506.05701", "abs": "https://arxiv.org/abs/2506.05701", "authors": ["Pavel Dolin", "Weizhi Li", "Gautam Dasarathy", "Visar Berisha"], "title": "Statistically Valid Post-Deployment Monitoring Should Be Standard for AI-Based Digital Health", "categories": ["cs.LG"], "comment": null, "summary": "This position paper argues that post-deployment monitoring in clinical AI is\nunderdeveloped and proposes statistically valid and label-efficient testing\nframeworks as a principled foundation for ensuring reliability and safety in\nreal-world deployment. A recent review found that only 9% of FDA-registered\nAI-based healthcare tools include a post-deployment surveillance plan. Existing\nmonitoring approaches are often manual, sporadic, and reactive, making them\nill-suited for the dynamic environments in which clinical models operate. We\ncontend that post-deployment monitoring should be grounded in label-efficient\nand statistically valid testing frameworks, offering a principled alternative\nto current practices. We use the term \"statistically valid\" to refer to methods\nthat provide explicit guarantees on error rates (e.g., Type I/II error), enable\nformal inference under pre-defined assumptions, and support\nreproducibility--features that align with regulatory requirements.\nSpecifically, we propose that the detection of changes in the data and model\nperformance degradation should be framed as distinct statistical hypothesis\ntesting problems. Grounding monitoring in statistical rigor ensures a\nreproducible and scientifically sound basis for maintaining the reliability of\nclinical AI systems. Importantly, it also opens new research directions for the\ntechnical community--spanning theory, methods, and tools for statistically\nprincipled detection, attribution, and mitigation of post-deployment model\nfailures in real-world settings.", "AI": {"tldr": "\u672c\u6587\u4e3b\u5f20\u4e34\u5e8aAI\u7684\u90e8\u7f72\u540e\u76d1\u6d4b\u4e0d\u8db3\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u7edf\u8ba1\u6709\u6548\u6027\u548c\u6807\u7b7e\u6548\u7387\u7684\u6d4b\u8bd5\u6846\u67b6\uff0c\u4f5c\u4e3a\u786e\u4fdd\u5b9e\u9645\u90e8\u7f72\u4e2d\u53ef\u9760\u6027\u548c\u5b89\u5168\u6027\u7684\u7406\u8bba\u57fa\u7840\u3002", "motivation": "\u73b0\u6709\u4e34\u5e8aAI\u5de5\u5177\u7684\u90e8\u7f72\u540e\u76d1\u6d4b\u8ba1\u5212\u4e0d\u8db3\uff08\u4ec59%\u7684FDA\u6ce8\u518c\u5de5\u5177\u5305\u542b\uff09\uff0c\u4e14\u76d1\u6d4b\u65b9\u6cd5\u591a\u4e3a\u624b\u52a8\u3001\u96f6\u661f\u548c\u88ab\u52a8\uff0c\u65e0\u6cd5\u9002\u5e94\u52a8\u6001\u73af\u5883\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u7edf\u8ba1\u5047\u8bbe\u68c0\u9a8c\u7684\u6846\u67b6\uff0c\u5c06\u6570\u636e\u53d8\u5316\u548c\u6a21\u578b\u6027\u80fd\u9000\u5316\u89c6\u4e3a\u72ec\u7acb\u95ee\u9898\uff0c\u786e\u4fdd\u76d1\u6d4b\u7684\u79d1\u5b66\u6027\u548c\u53ef\u91cd\u590d\u6027\u3002", "result": "\u8be5\u65b9\u6cd5\u4e3a\u4e34\u5e8aAI\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u7edf\u8ba1\u4e25\u8c28\u7684\u57fa\u7840\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u7edf\u8ba1\u6709\u6548\u7684\u76d1\u6d4b\u6846\u67b6\u662f\u786e\u4fdd\u4e34\u5e8aAI\u7cfb\u7edf\u53ef\u9760\u6027\u548c\u5b89\u5168\u6027\u7684\u5173\u952e\uff0c\u5e76\u4e3a\u6280\u672f\u793e\u533a\u63d0\u4f9b\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2506.05702", "pdf": "https://arxiv.org/pdf/2506.05702", "abs": "https://arxiv.org/abs/2506.05702", "authors": ["Chaofan Pan", "Jiafen Liu", "Yanhua Li", "Linbo Xiong", "Fan Min", "Wei Wei", "Xin Yang"], "title": "Action-Adaptive Continual Learning: Enabling Policy Generalization under Dynamic Action Spaces", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Continual Learning (CL) is a powerful tool that enables agents to learn a\nsequence of tasks, accumulating knowledge learned in the past and using it for\nproblem-solving or future task learning. However, existing CL methods often\nassume that the agent's capabilities remain static within dynamic environments,\nwhich doesn't reflect real-world scenarios where capabilities dynamically\nchange. This paper introduces a new and realistic problem: Continual Learning\nwith Dynamic Capabilities (CL-DC), posing a significant challenge for CL\nagents: How can policy generalization across different action spaces be\nachieved? Inspired by the cortical functions, we propose an Action-Adaptive\nContinual Learning framework (AACL) to address this challenge. Our framework\ndecouples the agent's policy from the specific action space by building an\naction representation space. For a new action space, the encoder-decoder of\naction representations is adaptively fine-tuned to maintain a balance between\nstability and plasticity. Furthermore, we release a benchmark based on three\nenvironments to validate the effectiveness of methods for CL-DC. Experimental\nresults demonstrate that our framework outperforms popular methods by\ngeneralizing the policy across action spaces.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6301\u7eed\u5b66\u4e60\u95ee\u9898\uff08CL-DC\uff09\uff0c\u89e3\u51b3\u4e86\u52a8\u6001\u80fd\u529b\u53d8\u5316\u4e0b\u7684\u7b56\u7565\u6cdb\u5316\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e86AACL\u6846\u67b6\u3002", "motivation": "\u73b0\u6709\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\u5047\u8bbe\u80fd\u529b\u9759\u6001\uff0c\u4f46\u73b0\u5b9e\u4e2d\u80fd\u529b\u52a8\u6001\u53d8\u5316\uff0c\u56e0\u6b64\u9700\u8981\u89e3\u51b3\u52a8\u6001\u80fd\u529b\u4e0b\u7684\u7b56\u7565\u6cdb\u5316\u95ee\u9898\u3002", "method": "\u63d0\u51faAACL\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u52a8\u4f5c\u8868\u793a\u7a7a\u95f4\u89e3\u8026\u7b56\u7565\u4e0e\u52a8\u4f5c\u7a7a\u95f4\uff0c\u5e76\u81ea\u9002\u5e94\u5fae\u8c03\u7f16\u7801\u5668-\u89e3\u7801\u5668\u4ee5\u5e73\u8861\u7a33\u5b9a\u6027\u548c\u53ef\u5851\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cAACL\u5728\u4e09\u79cd\u73af\u5883\u4e2d\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u8de8\u52a8\u4f5c\u7a7a\u95f4\u7684\u7b56\u7565\u6cdb\u5316\u3002", "conclusion": "AACL\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u52a8\u6001\u80fd\u529b\u4e0b\u7684\u6301\u7eed\u5b66\u4e60\u95ee\u9898\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2506.05710", "pdf": "https://arxiv.org/pdf/2506.05710", "abs": "https://arxiv.org/abs/2506.05710", "authors": ["Xiucheng Wang", "Honggang Jia", "Nan Cheng", "Dusit Niyato"], "title": "Latent Diffusion Model Based Denoising Receiver for 6G Semantic Communication: From Stochastic Differential Theory to Application", "categories": ["cs.LG", "cs.IT", "cs.SY", "eess.SY", "math.IT"], "comment": null, "summary": "In this paper, a novel semantic communication framework empowered by\ngenerative artificial intelligence (GAI) is proposed, specifically leveraging\nthe capabilities of diffusion models (DMs). A rigorous theoretical foundation\nis established based on stochastic differential equations (SDEs), which\nelucidates the denoising properties of DMs in mitigating additive white\nGaussian noise (AWGN) in latent semantic representations. Crucially, a\nclosed-form analytical relationship between the signal-to-noise ratio (SNR) and\nthe denoising timestep is derived, enabling the optimal selection of diffusion\nparameters for any given channel condition. To address the distribution\nmismatch between the received signal and the DM's training data, a\nmathematically principled scaling mechanism is introduced, ensuring robust\nperformance across a wide range of SNRs without requiring model fine-tuning.\nBuilt upon this theoretical insight, we develop a latent diffusion model\n(LDM)-based semantic transceiver, wherein a variational autoencoder (VAE) is\nemployed for efficient semantic compression, and a pretrained DM serves as a\nuniversal denoiser. Notably, the proposed architecture is fully training-free\nat inference time, offering high modularity and compatibility with large-scale\npretrained LDMs. This design inherently supports zero-shot generalization and\nmitigates the challenges posed by out-of-distribution inputs. Extensive\nexperimental evaluations demonstrate that the proposed framework significantly\noutperforms conventional neural-network-based semantic communication baselines,\nparticularly under low SNR conditions and distributional shifts, thereby\nestablishing a promising direction for GAI-driven robust semantic transmission\nin future 6G systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\uff08GAI\uff09\u548c\u6269\u6563\u6a21\u578b\uff08DMs\uff09\u7684\u65b0\u578b\u8bed\u4e49\u901a\u4fe1\u6846\u67b6\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u6570\u5b66\u4f18\u5316\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u8bed\u4e49\u4f20\u8f93\u548c\u53bb\u566a\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u8bed\u4e49\u901a\u4fe1\u5728\u4f4e\u4fe1\u566a\u6bd4\uff08SNR\uff09\u548c\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u6027\u80fd\u4e0d\u8db3\u95ee\u9898\uff0c\u5229\u7528\u6269\u6563\u6a21\u578b\u7684\u53bb\u566a\u80fd\u529b\u63d0\u5347\u9c81\u68d2\u6027\u3002", "method": "\u57fa\u4e8e\u968f\u673a\u5fae\u5206\u65b9\u7a0b\uff08SDEs\uff09\u5efa\u7acb\u7406\u8bba\u6846\u67b6\uff0c\u63a8\u5bfcSNR\u4e0e\u53bb\u566a\u6b65\u957f\u7684\u95ed\u5f0f\u5173\u7cfb\uff0c\u8bbe\u8ba1\u65e0\u9700\u5fae\u8c03\u7684\u7f29\u653e\u673a\u5236\uff0c\u5e76\u7ed3\u5408\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09\u548c\u9884\u8bad\u7ec3\u6269\u6563\u6a21\u578b\u6784\u5efa\u8bed\u4e49\u6536\u53d1\u5668\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u4f4eSNR\u548c\u5206\u5e03\u504f\u79fb\u4e0b\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u652f\u6301\u96f6\u6837\u672c\u6cdb\u5316\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a6G\u7cfb\u7edf\u4e2dGAI\u9a71\u52a8\u7684\u9c81\u68d2\u8bed\u4e49\u4f20\u8f93\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2506.05713", "pdf": "https://arxiv.org/pdf/2506.05713", "abs": "https://arxiv.org/abs/2506.05713", "authors": ["Zhan Zhuang", "Xiequn Wang", "Wei Li", "Yulong Zhang", "Qiushi Huang", "Shuhao Chen", "Xuehao Wang", "Yanbin Wei", "Yuhe Nie", "Kede Ma", "Yu Zhang", "Ying Wei"], "title": "Come Together, But Not Right Now: A Progressive Strategy to Boost Low-Rank Adaptation", "categories": ["cs.LG"], "comment": "Accepted by ICML 2025. Code link: https://github.com/zwebzone/coto", "summary": "Low-rank adaptation (LoRA) has emerged as a leading parameter-efficient\nfine-tuning technique for adapting large foundation models, yet it often locks\nadapters into suboptimal minima near their initialization. This hampers model\ngeneralization and limits downstream operators such as adapter merging and\npruning. Here, we propose CoTo, a progressive training strategy that gradually\nincreases adapters' activation probability over the course of fine-tuning. By\nstochastically deactivating adapters, CoTo encourages more balanced\noptimization and broader exploration of the loss landscape. We provide a\ntheoretical analysis showing that CoTo promotes layer-wise dropout stability\nand linear mode connectivity, and we adopt a cooperative-game approach to\nquantify each adapter's marginal contribution. Extensive experiments\ndemonstrate that CoTo consistently boosts single-task performance, enhances\nmulti-task merging accuracy, improves pruning robustness, and reduces training\noverhead, all while remaining compatible with diverse LoRA variants. Code is\navailable at https://github.com/zwebzone/coto.", "AI": {"tldr": "CoTo\u662f\u4e00\u79cd\u6e10\u8fdb\u5f0f\u8bad\u7ec3\u7b56\u7565\uff0c\u901a\u8fc7\u9010\u6b65\u589e\u52a0\u9002\u914d\u5668\u7684\u6fc0\u6d3b\u6982\u7387\uff0c\u63d0\u5347LoRA\u7684\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "LoRA\u5728\u5fae\u8c03\u5927\u578b\u57fa\u7840\u6a21\u578b\u65f6\u5bb9\u6613\u9677\u5165\u6b21\u4f18\u89e3\uff0c\u9650\u5236\u4e86\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u548c\u4e0b\u6e38\u64cd\u4f5c\uff08\u5982\u9002\u914d\u5668\u5408\u5e76\u548c\u526a\u679d\uff09\u3002", "method": "\u63d0\u51faCoTo\u7b56\u7565\uff0c\u9010\u6b65\u589e\u52a0\u9002\u914d\u5668\u7684\u6fc0\u6d3b\u6982\u7387\uff0c\u901a\u8fc7\u968f\u673a\u505c\u7528\u9002\u914d\u5668\u4fc3\u8fdb\u66f4\u5e73\u8861\u7684\u4f18\u5316\u548c\u66f4\u5e7f\u6cdb\u7684\u635f\u5931\u7a7a\u95f4\u63a2\u7d22\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cCoTo\u63d0\u5347\u4e86\u5355\u4efb\u52a1\u6027\u80fd\u3001\u591a\u4efb\u52a1\u5408\u5e76\u51c6\u786e\u7387\u3001\u526a\u679d\u9c81\u68d2\u6027\uff0c\u5e76\u51cf\u5c11\u4e86\u8bad\u7ec3\u5f00\u9500\u3002", "conclusion": "CoTo\u662f\u4e00\u79cd\u517c\u5bb9\u6027\u5f3a\u4e14\u9ad8\u6548\u7684LoRA\u6539\u8fdb\u65b9\u6cd5\u3002"}}
{"id": "2506.05716", "pdf": "https://arxiv.org/pdf/2506.05716", "abs": "https://arxiv.org/abs/2506.05716", "authors": ["Adrian Ly", "Richard Dazeley", "Peter Vamplew", "Francisco Cruz", "Sunil Aryal"], "title": "Ensemble Elastic DQN: A novel multi-step ensemble approach to address overestimation in deep value-based reinforcement learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "While many algorithmic extensions to Deep Q-Networks (DQN) have been\nproposed, there remains limited understanding of how different improvements\ninteract. In particular, multi-step and ensemble style extensions have shown\npromise in reducing overestimation bias, thereby improving sample efficiency\nand algorithmic stability. In this paper, we introduce a novel algorithm called\nEnsemble Elastic Step DQN (EEDQN), which unifies ensembles with elastic step\nupdates to stabilise algorithmic performance. EEDQN is designed to address two\nmajor challenges in deep reinforcement learning: overestimation bias and sample\nefficiency. We evaluated EEDQN against standard and ensemble DQN variants\nacross the MinAtar benchmark, a set of environments that emphasise behavioral\nlearning while reducing representational complexity. Our results show that\nEEDQN achieves consistently robust performance across all tested environments,\noutperforming baseline DQN methods and matching or exceeding state-of-the-art\nensemble DQNs in final returns on most of the MinAtar environments. These\nfindings highlight the potential of systematically combining algorithmic\nimprovements and provide evidence that ensemble and multi-step methods, when\ncarefully integrated, can yield substantial gains.", "AI": {"tldr": "EEDQN\u7ed3\u5408\u96c6\u6210\u4e0e\u5f39\u6027\u6b65\u957f\u66f4\u65b0\uff0c\u89e3\u51b3DQN\u4e2d\u7684\u9ad8\u4f30\u504f\u5dee\u548c\u6837\u672c\u6548\u7387\u95ee\u9898\uff0c\u5728MinAtar\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u7814\u7a76\u4e0d\u540c\u6539\u8fdb\u65b9\u6cd5\uff08\u5982\u591a\u6b65\u548c\u96c6\u6210\uff09\u5982\u4f55\u76f8\u4e92\u4f5c\u7528\uff0c\u4ee5\u89e3\u51b3DQN\u4e2d\u7684\u9ad8\u4f30\u504f\u5dee\u548c\u6837\u672c\u6548\u7387\u95ee\u9898\u3002", "method": "\u63d0\u51faEEDQN\u7b97\u6cd5\uff0c\u7ed3\u5408\u96c6\u6210\u4e0e\u5f39\u6027\u6b65\u957f\u66f4\u65b0\uff0c\u7a33\u5b9a\u7b97\u6cd5\u6027\u80fd\u3002", "result": "EEDQN\u5728MinAtar\u73af\u5883\u4e2d\u8868\u73b0\u7a33\u5065\uff0c\u4f18\u4e8e\u57fa\u7ebfDQN\u65b9\u6cd5\uff0c\u5339\u914d\u6216\u8d85\u8d8a\u6700\u5148\u8fdb\u7684\u96c6\u6210DQN\u3002", "conclusion": "\u7cfb\u7edf\u7ed3\u5408\u7b97\u6cd5\u6539\u8fdb\uff08\u5982\u96c6\u6210\u4e0e\u591a\u6b65\u65b9\u6cd5\uff09\u53ef\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2506.05718", "pdf": "https://arxiv.org/pdf/2506.05718", "abs": "https://arxiv.org/abs/2506.05718", "authors": ["Pascal Jr Tikeng Notsawo", "Guillaume Dumas", "Guillaume Rabusseau"], "title": "Grokking Beyond the Euclidean Norm of Model Parameters", "categories": ["cs.LG", "cs.AI", "stat.ML", "I.2.6"], "comment": "67 pages, 35 figures. Forty-second International Conference on\n  Machine Learning (ICML), 2025", "summary": "Grokking refers to a delayed generalization following overfitting when\noptimizing artificial neural networks with gradient-based methods. In this\nwork, we demonstrate that grokking can be induced by regularization, either\nexplicit or implicit. More precisely, we show that when there exists a model\nwith a property $P$ (e.g., sparse or low-rank weights) that generalizes on the\nproblem of interest, gradient descent with a small but non-zero regularization\nof $P$ (e.g., $\\ell_1$ or nuclear norm regularization) results in grokking.\nThis extends previous work showing that small non-zero weight decay induces\ngrokking. Moreover, our analysis shows that over-parameterization by adding\ndepth makes it possible to grok or ungrok without explicitly using\nregularization, which is impossible in shallow cases. We further show that the\n$\\ell_2$ norm is not a reliable proxy for generalization when the model is\nregularized toward a different property $P$, as the $\\ell_2$ norm grows in many\ncases where no weight decay is used, but the model generalizes anyway. We also\nshow that grokking can be amplified solely through data selection, with any\nother hyperparameter fixed.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u901a\u8fc7\u6b63\u5219\u5316\uff08\u663e\u5f0f\u6216\u9690\u5f0f\uff09\u8bf1\u5bfc\u795e\u7ecf\u7f51\u7edc\u5728\u68af\u5ea6\u4f18\u5316\u4e2d\u7684\u5ef6\u8fdf\u6cdb\u5316\u73b0\u8c61\uff08grokking\uff09\uff0c\u5e76\u5206\u6790\u4e86\u4e0d\u540c\u6b63\u5219\u5316\u65b9\u6cd5\u5bf9\u6cdb\u5316\u7684\u5f71\u54cd\u3002", "motivation": "\u7814\u7a76grokking\u73b0\u8c61\u7684\u6210\u56e0\uff0c\u5c24\u5176\u662f\u6b63\u5219\u5316\u5728\u5176\u4e2d\u7684\u4f5c\u7528\uff0c\u4ee5\u6269\u5c55\u5bf9\u795e\u7ecf\u7f51\u7edc\u6cdb\u5316\u884c\u4e3a\u7684\u7406\u89e3\u3002", "method": "\u901a\u8fc7\u68af\u5ea6\u4e0b\u964d\u7ed3\u5408\u5c0f\u4f46\u975e\u96f6\u7684\u6b63\u5219\u5316\uff08\u5982\u2113\u2081\u6216\u6838\u8303\u6570\u6b63\u5219\u5316\uff09\u6765\u8bf1\u5bfcgrokking\uff0c\u5e76\u5206\u6790\u8fc7\u53c2\u6570\u5316\u548c\u6570\u636e\u9009\u62e9\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u6b63\u5219\u5316\u53ef\u4ee5\u8bf1\u5bfcgrokking\uff0c\u4e14\u8fc7\u53c2\u6570\u5316\u53ef\u4ee5\u5728\u4e0d\u4f7f\u7528\u663e\u5f0f\u6b63\u5219\u5316\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0grokking\uff1b\u2113\u2082\u8303\u6570\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u4e0d\u80fd\u53ef\u9760\u53cd\u6620\u6cdb\u5316\u6027\u80fd\u3002", "conclusion": "\u6b63\u5219\u5316\u548c\u6570\u636e\u9009\u62e9\u662f\u8bf1\u5bfcgrokking\u7684\u5173\u952e\u56e0\u7d20\uff0c\u8fc7\u53c2\u6570\u5316\u8fdb\u4e00\u6b65\u6269\u5c55\u4e86\u5176\u53ef\u80fd\u6027\uff0c\u4e3a\u7406\u89e3\u795e\u7ecf\u7f51\u7edc\u6cdb\u5316\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2506.05721", "pdf": "https://arxiv.org/pdf/2506.05721", "abs": "https://arxiv.org/abs/2506.05721", "authors": ["Dumindu Tissera", "Omar Awadallah", "Muhammad Umair Danish", "Ayan Sadhu", "Katarina Grolinger"], "title": "Any-Class Presence Likelihood for Robust Multi-Label Classification with Abundant Negative Data", "categories": ["cs.LG", "cs.AI", "cs.CV", "68T05 (Primary) 62H30 (Secondary)", "I.2.6; I.5.4"], "comment": null, "summary": "Multi-label Classification (MLC) assigns an instance to one or more\nnon-exclusive classes. A challenge arises when the dataset contains a large\nproportion of instances with no assigned class, referred to as negative data,\nwhich can overwhelm the learning process and hinder the accurate identification\nand classification of positive instances. Nevertheless, it is common in MLC\napplications such as industrial defect detection, agricultural disease\nidentification, and healthcare diagnosis to encounter large amounts of negative\ndata. Assigning a separate negative class to these instances further\ncomplicates the learning objective and introduces unnecessary redundancies. To\naddress this challenge, we redesign standard MLC loss functions by deriving a\nlikelihood of any class being present, formulated by a normalized weighted\ngeometric mean of the predicted class probabilities. We introduce a\nregularization parameter that controls the relative contribution of the absent\nclass probabilities to the any-class presence likelihood in positive instances.\nThe any-class presence likelihood complements the multi-label learning by\nencouraging the network to become more aware of implicit positive instances and\nimprove the label classification within those positive instances. Experiments\non large-scale datasets with negative data: SewerML, modified COCO, and\nChestX-ray14, across various networks and base loss functions show that our\nloss functions consistently improve MLC performance of their standard loss\ncounterparts, achieving gains of up to 6.01 percentage points in F1, 8.06 in\nF2, and 3.11 in mean average precision, all without additional parameters or\ncomputational complexity. Code available at:\nhttps://github.com/ML-for-Sensor-Data-Western/gmean-mlc", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u591a\u6807\u7b7e\u5206\u7c7b\uff08MLC\uff09\u635f\u5931\u51fd\u6570\uff0c\u901a\u8fc7\u5f52\u4e00\u5316\u52a0\u6743\u51e0\u4f55\u5e73\u5747\u9884\u6d4b\u7c7b\u522b\u6982\u7387\uff0c\u89e3\u51b3\u8d1f\u6570\u636e\u8fc7\u591a\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5206\u7c7b\u6027\u80fd\u3002", "motivation": "\u591a\u6807\u7b7e\u5206\u7c7b\u4e2d\uff0c\u5927\u91cf\u672a\u6807\u8bb0\u7684\u8d1f\u6570\u636e\u4f1a\u5e72\u6270\u5b66\u4e60\u8fc7\u7a0b\uff0c\u5f71\u54cd\u6b63\u5b9e\u4f8b\u7684\u51c6\u786e\u5206\u7c7b\u3002\u73b0\u6709\u65b9\u6cd5\u5c06\u8d1f\u6570\u636e\u5355\u72ec\u5206\u7c7b\u4f1a\u5f15\u5165\u5197\u4f59\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u91cd\u65b0\u8bbe\u8ba1MLC\u635f\u5931\u51fd\u6570\uff0c\u901a\u8fc7\u5f52\u4e00\u5316\u52a0\u6743\u51e0\u4f55\u5e73\u5747\u9884\u6d4b\u7c7b\u522b\u6982\u7387\uff0c\u5f15\u5165\u6b63\u5219\u5316\u53c2\u6570\u63a7\u5236\u8d1f\u7c7b\u6982\u7387\u5bf9\u6b63\u5b9e\u4f8b\u7684\u8d21\u732e\u3002", "result": "\u5728\u591a\u4e2a\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\uff0c\u65b0\u635f\u5931\u51fd\u6570\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\uff0cF1\u3001F2\u548c\u5e73\u5747\u7cbe\u5ea6\u5206\u522b\u63d0\u9ad8\u4e866.01\u30018.06\u548c3.11\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "\u63d0\u51fa\u7684\u635f\u5931\u51fd\u6570\u6709\u6548\u89e3\u51b3\u4e86\u8d1f\u6570\u636e\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u591a\u6807\u7b7e\u5206\u7c7b\u6027\u80fd\uff0c\u4e14\u65e0\u9700\u989d\u5916\u53c2\u6570\u6216\u8ba1\u7b97\u590d\u6742\u5ea6\u3002"}}
{"id": "2506.05736", "pdf": "https://arxiv.org/pdf/2506.05736", "abs": "https://arxiv.org/abs/2506.05736", "authors": ["En Yu", "Jie Lu", "Guangquan Zhang"], "title": "Generalized Incremental Learning under Concept Drift across Evolving Data Streams", "categories": ["cs.LG", "cs.AI"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Real-world data streams exhibit inherent non-stationarity characterized by\nconcept drift, posing significant challenges for adaptive learning systems.\nWhile existing methods address isolated distribution shifts, they overlook the\ncritical co-evolution of label spaces and distributions under limited\nsupervision and persistent uncertainty. To address this, we formalize\nGeneralized Incremental Learning under Concept Drift (GILCD), characterizing\nthe joint evolution of distributions and label spaces in open-environment\nstreaming contexts, and propose a novel framework called Calibrated Source-Free\nAdaptation (CSFA). First, CSFA introduces a training-free prototype calibration\nmechanism that dynamically fuses emerging prototypes with base representations,\nenabling stable new-class identification without optimization overhead. Second,\nwe design a novel source-free adaptation algorithm, i.e., Reliable Surrogate\nGap Sharpness-aware (RSGS) minimization. It integrates sharpness-aware\nperturbation loss optimization with surrogate gap minimization, while employing\nentropy-based uncertainty filtering to discard unreliable samples. This\nmechanism ensures robust distribution alignment and mitigates generalization\ndegradation caused by uncertainties. Therefore, CSFA establishes a unified\nframework for stable adaptation to evolving semantics and distributions in\nopen-world streaming scenarios. Extensive experiments validate the superior\nperformance and effectiveness of CSFA compared to state-of-the-art approaches.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCSFA\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u5f00\u653e\u73af\u5883\u6d41\u6570\u636e\u4e2d\u7684\u6982\u5ff5\u6f02\u79fb\u95ee\u9898\uff0c\u901a\u8fc7\u539f\u578b\u6821\u51c6\u548c\u65e0\u6e90\u9002\u5e94\u7b97\u6cd5\u5b9e\u73b0\u7a33\u5b9a\u9002\u5e94\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u6570\u636e\u6d41\u5177\u6709\u975e\u5e73\u7a33\u6027\uff0c\u73b0\u6709\u65b9\u6cd5\u5ffd\u7565\u4e86\u6807\u7b7e\u7a7a\u95f4\u548c\u5206\u5e03\u7684\u8054\u5408\u6f14\u5316\u95ee\u9898\uff0c\u5bfc\u81f4\u9002\u5e94\u5b66\u4e60\u7cfb\u7edf\u9762\u4e34\u6311\u6218\u3002", "method": "CSFA\u6846\u67b6\u5305\u542b\u8bad\u7ec3\u65e0\u5173\u7684\u539f\u578b\u6821\u51c6\u673a\u5236\u548c\u57fa\u4e8e\u53ef\u9760\u4ee3\u7406\u95f4\u9699\u7684\u9510\u5ea6\u611f\u77e5\u6700\u5c0f\u5316\u7b97\u6cd5\uff08RSGS\uff09\uff0c\u7528\u4e8e\u52a8\u6001\u9002\u5e94\u65b0\u7c7b\u522b\u548c\u5206\u5e03\u5bf9\u9f50\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eCSFA\u5728\u5f00\u653e\u4e16\u754c\u6d41\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u80fd\u591f\u7a33\u5b9a\u9002\u5e94\u8bed\u4e49\u548c\u5206\u5e03\u7684\u6f14\u5316\u3002", "conclusion": "CSFA\u4e3a\u5f00\u653e\u73af\u5883\u6d41\u6570\u636e\u4e2d\u7684\u6982\u5ff5\u6f02\u79fb\u95ee\u9898\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u9ad8\u6548\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2506.05748", "pdf": "https://arxiv.org/pdf/2506.05748", "abs": "https://arxiv.org/abs/2506.05748", "authors": ["Rudransh Agnihotri", "Ananya Pandey"], "title": "Efficient Online RFT with Plug-and-Play LLM Judges: Unlocking State-of-the-Art Performance", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reward-model training is the cost bottleneck in modern Reinforcement Learning\nHuman Feedback (RLHF) pipelines, often requiring tens of billions of parameters\nand an offline preference-tuning phase. In the proposed method, a frozen,\ninstruction-tuned 7B LLM is augmented with only a one line JSON rubric and a\nrank-16 LoRA adapter (affecting just 0.8% of the model's parameters), enabling\nit to serve as a complete substitute for the previously used heavyweight\nevaluation models. The plug-and-play judge achieves 96.2% accuracy on\nRewardBench, outperforming specialized reward networks ranging from 27B to 70B\nparameters. Additionally, it allows a 7B actor to outperform the top 70B DPO\nbaseline, which scores 61.8%, by achieving 92% exact match accuracy on GSM-8K\nutilizing online PPO. Thorough ablations indicate that (i) six in context\ndemonstrations deliver the majority of the zero-to-few-shot improvements\n(+2pp), and (ii) the LoRA effectively addresses the remaining disparity,\nparticularly in the safety and adversarial Chat-Hard segments. The proposed\nmodel introduces HH-Rationales, a subset of 10,000 pairs from Anthropic\nHH-RLHF, to examine interpretability, accompanied by human generated\njustifications. GPT-4 scoring indicates that our LoRA judge attains\napproximately = 9/10 in similarity to human explanations, while zero-shot\njudges score around =5/10. These results indicate that the combination of\nprompt engineering and tiny LoRA produces a cost effective, transparent, and\neasily adjustable reward function, removing the offline phase while achieving\nnew state-of-the-art outcomes for both static evaluation and online RLHF.", "AI": {"tldr": "\u901a\u8fc7\u51bb\u7ed3\u76847B LLM\u3001\u4e00\u884cJSON\u89c4\u5219\u548crank-16 LoRA\u9002\u914d\u5668\uff0c\u66ff\u4ee3\u4f20\u7edf\u91cd\u578b\u5956\u52b1\u6a21\u578b\uff0c\u5b9e\u73b0\u9ad8\u6548\u3001\u4f4e\u6210\u672c\u7684RLHF\uff0c\u5e76\u5728RewardBench\u548cGSM-8K\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u89e3\u51b3RLHF\u4e2d\u5956\u52b1\u6a21\u578b\u8bad\u7ec3\u7684\u9ad8\u6210\u672c\u548c\u590d\u6742\u6027\uff0c\u63d0\u51fa\u4e00\u79cd\u8f7b\u91cf\u7ea7\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u51bb\u7ed3\u76847B LLM\uff0c\u7ed3\u5408JSON\u89c4\u5219\u548cLoRA\u9002\u914d\u5668\uff0c\u65e0\u9700\u79bb\u7ebf\u8c03\u4f18\uff0c\u76f4\u63a5\u4f5c\u4e3a\u5956\u52b1\u6a21\u578b\u3002", "result": "\u5728RewardBench\u4e0a\u8fbe\u523096.2%\u51c6\u786e\u7387\uff0c\u4f18\u4e8e27B-70B\u6a21\u578b\uff1b7B\u6a21\u578b\u5728GSM-8K\u4e0a\u4ee592%\u51c6\u786e\u7387\u8d85\u8d8a70B DPO\u57fa\u7ebf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u8f7b\u91cf\u7ea7\u8bbe\u8ba1\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u900f\u660e\u4e14\u53ef\u8c03\u7684\u5956\u52b1\u529f\u80fd\uff0c\u4e3aRLHF\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.05752", "pdf": "https://arxiv.org/pdf/2506.05752", "abs": "https://arxiv.org/abs/2506.05752", "authors": ["Zhongying Wang", "Thoai D. Ngo", "Hamidreza Zoraghein", "Benjamin Lucas", "Morteza Karimzadeh"], "title": "Integrating Spatiotemporal Features in LSTM for Spatially Informed COVID-19 Hospitalization Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": "36 pages, 12 figures. This is the accepted version of the article\n  published in International Journal of Geographical Information Science. DOI\n  will be added upon publication", "summary": "The COVID-19 pandemic's severe impact highlighted the need for accurate,\ntimely hospitalization forecasting to support effective healthcare planning.\nHowever, most forecasting models struggled, especially during variant surges,\nwhen they were needed most. This study introduces a novel Long Short-Term\nMemory (LSTM) framework for forecasting daily state-level incident\nhospitalizations in the United States. We present a spatiotemporal feature,\nSocial Proximity to Hospitalizations (SPH), derived from Facebook's Social\nConnectedness Index to improve forecasts. SPH serves as a proxy for interstate\npopulation interaction, capturing transmission dynamics across space and time.\nOur parallel LSTM architecture captures both short- and long-term temporal\ndependencies, and our multi-horizon ensembling strategy balances consistency\nand forecasting error. Evaluation against COVID-19 Forecast Hub ensemble models\nduring the Delta and Omicron surges reveals superiority of our model. On\naverage, our model surpasses the ensemble by 27, 42, 54, and 69\nhospitalizations per state on the $7^{th}$, $14^{th}$, $21^{st}$, and $28^{th}$\nforecast days, respectively, during the Omicron surge. Data-ablation\nexperiments confirm SPH's predictive power, highlighting its effectiveness in\nenhancing forecasting models. This research not only advances hospitalization\nforecasting but also underscores the significance of spatiotemporal features,\nsuch as SPH, in refining predictive performance in modeling the complex\ndynamics of infectious disease spread.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLSTM\u7684\u65b0\u6846\u67b6\uff0c\u7ed3\u5408\u65f6\u7a7a\u7279\u5f81SPH\uff0c\u663e\u8457\u63d0\u5347\u4e86COVID-19\u4f4f\u9662\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u5c24\u5176\u5728\u53d8\u5f02\u682a\u6d41\u884c\u671f\u95f4\u8868\u73b0\u7a81\u51fa\u3002", "motivation": "COVID-19\u5927\u6d41\u884c\u51f8\u663e\u4e86\u51c6\u786e\u3001\u53ca\u65f6\u9884\u6d4b\u4f4f\u9662\u9700\u6c42\u7684\u91cd\u8981\u6027\uff0c\u4f46\u73b0\u6709\u6a21\u578b\u5728\u53d8\u5f02\u682a\u6d41\u884c\u671f\u95f4\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u91c7\u7528LSTM\u6846\u67b6\uff0c\u5f15\u5165\u65f6\u7a7a\u7279\u5f81SPH\uff0c\u5e76\u7ed3\u5408\u591a\u65f6\u95f4\u8303\u56f4\u96c6\u6210\u7b56\u7565\u3002", "result": "\u6a21\u578b\u5728Delta\u548cOmicron\u6d41\u884c\u671f\u95f4\u7684\u9884\u6d4b\u8868\u73b0\u4f18\u4e8e\u57fa\u51c6\u6a21\u578b\uff0c\u5c24\u5176\u5728Omicron\u671f\u95f4\u63d0\u5347\u663e\u8457\u3002", "conclusion": "\u7814\u7a76\u4e0d\u4ec5\u6539\u8fdb\u4e86\u4f4f\u9662\u9884\u6d4b\uff0c\u8fd8\u8bc1\u660e\u4e86\u65f6\u7a7a\u7279\u5f81\u5728\u4f20\u67d3\u75c5\u4f20\u64ad\u5efa\u6a21\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2506.05755", "pdf": "https://arxiv.org/pdf/2506.05755", "abs": "https://arxiv.org/abs/2506.05755", "authors": ["Yang Li", "Zhi Chen"], "title": "FlowOE: Imitation Learning with Flow Policy from Ensemble RL Experts for Optimal Execution under Heston Volatility and Concave Market Impacts", "categories": ["cs.LG", "cs.AI", "cs.CE", "q-fin.CP", "q-fin.TR"], "comment": "3 figures, 3 algorithms, 7 tables", "summary": "Optimal execution in financial markets refers to the process of strategically\ntransacting a large volume of assets over a period to achieve the best possible\noutcome by balancing the trade-off between market impact costs and timing or\nvolatility risks. Traditional optimal execution strategies, such as static\nAlmgren-Chriss models, often prove suboptimal in dynamic financial markets.\nThis paper propose flowOE, a novel imitation learning framework based on flow\nmatching models, to address these limitations. FlowOE learns from a diverse set\nof expert traditional strategies and adaptively selects the most suitable\nexpert behavior for prevailing market conditions. A key innovation is the\nincorporation of a refining loss function during the imitation process,\nenabling flowOE not only to mimic but also to improve upon the learned expert\nactions. To the best of our knowledge, this work is the first to apply flow\nmatching models in a stochastic optimal execution problem. Empirical\nevaluations across various market conditions demonstrate that flowOE\nsignificantly outperforms both the specifically calibrated expert models and\nother traditional benchmarks, achieving higher profits with reduced risk. These\nresults underscore the practical applicability and potential of flowOE to\nenhance adaptive optimal execution.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6d41\u5339\u914d\u6a21\u578b\u7684\u6a21\u4eff\u5b66\u4e60\u6846\u67b6flowOE\uff0c\u7528\u4e8e\u4f18\u5316\u91d1\u878d\u5e02\u573a\u7684\u52a8\u6001\u6267\u884c\u7b56\u7565\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u6700\u4f18\u6267\u884c\u7b56\u7565\uff08\u5982\u9759\u6001Almgren-Chriss\u6a21\u578b\uff09\u5728\u52a8\u6001\u5e02\u573a\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u7684\u65b9\u6cd5\u3002", "method": "flowOE\u901a\u8fc7\u6a21\u4eff\u5b66\u4e60\u4ece\u591a\u79cd\u4e13\u5bb6\u7b56\u7565\u4e2d\u81ea\u9002\u5e94\u9009\u62e9\u6700\u4f73\u884c\u4e3a\uff0c\u5e76\u7ed3\u5408\u6539\u8fdb\u7684\u635f\u5931\u51fd\u6570\u4f18\u5316\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u8868\u660eflowOE\u5728\u591a\u79cd\u5e02\u573a\u6761\u4ef6\u4e0b\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u57fa\u51c6\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u5229\u6da6\u548c\u66f4\u4f4e\u7684\u98ce\u9669\u3002", "conclusion": "flowOE\u5c55\u793a\u4e86\u5728\u52a8\u6001\u5e02\u573a\u4e2d\u63d0\u5347\u6700\u4f18\u6267\u884c\u7b56\u7565\u7684\u6f5c\u529b\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2506.05762", "pdf": "https://arxiv.org/pdf/2506.05762", "abs": "https://arxiv.org/abs/2506.05762", "authors": ["Yunpeng Qing", "Shuo Chen", "Yixiao Chi", "Shunyu Liu", "Sixu Lin", "Changqing Zou"], "title": "BiTrajDiff: Bidirectional Trajectory Generation with Diffusion Models for Offline Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "Recent advances in offline Reinforcement Learning (RL) have proven that\neffective policy learning can benefit from imposing conservative constraints on\npre-collected datasets. However, such static datasets often exhibit\ndistribution bias, resulting in limited generalizability. To address this\nlimitation, a straightforward solution is data augmentation (DA), which\nleverages generative models to enrich data distribution. Despite the promising\nresults, current DA techniques focus solely on reconstructing future\ntrajectories from given states, while ignoring the exploration of history\ntransitions that reach them. This single-direction paradigm inevitably hinders\nthe discovery of diverse behavior patterns, especially those leading to\ncritical states that may have yielded high-reward outcomes. In this work, we\nintroduce Bidirectional Trajectory Diffusion (BiTrajDiff), a novel DA framework\nfor offline RL that models both future and history trajectories from any\nintermediate states. Specifically, we decompose the trajectory generation task\ninto two independent yet complementary diffusion processes: one generating\nforward trajectories to predict future dynamics, and the other generating\nbackward trajectories to trace essential history transitions.BiTrajDiff can\nefficiently leverage critical states as anchors to expand into potentially\nvaluable yet underexplored regions of the state space, thereby facilitating\ndataset diversity. Extensive experiments on the D4RL benchmark suite\ndemonstrate that BiTrajDiff achieves superior performance compared to other\nadvanced DA methods across various offline RL backbones.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u5411\u8f68\u8ff9\u6269\u6563\uff08BiTrajDiff\uff09\u6846\u67b6\uff0c\u7528\u4e8e\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u6570\u636e\u589e\u5f3a\uff0c\u901a\u8fc7\u540c\u65f6\u751f\u6210\u672a\u6765\u548c\u5386\u53f2\u7684\u8f68\u8ff9\u6765\u63d0\u5347\u6570\u636e\u96c6\u591a\u6837\u6027\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u589e\u5f3a\u6280\u672f\u4ec5\u5173\u6ce8\u4ece\u7ed9\u5b9a\u72b6\u6001\u91cd\u6784\u672a\u6765\u8f68\u8ff9\uff0c\u5ffd\u7565\u4e86\u5386\u53f2\u8fc7\u6e21\u7684\u63a2\u7d22\uff0c\u5bfc\u81f4\u884c\u4e3a\u6a21\u5f0f\u591a\u6837\u6027\u4e0d\u8db3\uff0c\u5c24\u5176\u662f\u53ef\u80fd\u4ea7\u751f\u9ad8\u56de\u62a5\u7684\u5173\u952e\u72b6\u6001\u3002", "method": "BiTrajDiff\u901a\u8fc7\u4e24\u4e2a\u72ec\u7acb\u7684\u6269\u6563\u8fc7\u7a0b\u751f\u6210\u672a\u6765\u548c\u5386\u53f2\u7684\u8f68\u8ff9\uff0c\u5229\u7528\u5173\u952e\u72b6\u6001\u4f5c\u4e3a\u951a\u70b9\u6269\u5c55\u72b6\u6001\u7a7a\u95f4\u7684\u672a\u63a2\u7d22\u533a\u57df\u3002", "result": "\u5728D4RL\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cBiTrajDiff\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u5148\u8fdb\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u3002", "conclusion": "BiTrajDiff\u901a\u8fc7\u53cc\u5411\u8f68\u8ff9\u751f\u6210\u6709\u6548\u63d0\u5347\u4e86\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7684\u6027\u80fd\uff0c\u4e3a\u6570\u636e\u591a\u6837\u6027\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.05764", "pdf": "https://arxiv.org/pdf/2506.05764", "abs": "https://arxiv.org/abs/2506.05764", "authors": ["Haochuan", "Wang"], "title": "Exploring Microstructural Dynamics in Cryptocurrency Limit Order Books: Better Inputs Matter More Than Stacking Another Hidden Layer", "categories": ["cs.LG", "q-fin.TR"], "comment": null, "summary": "Cryptocurrency price dynamics are driven largely by microstructural supply\ndemand imbalances in the limit order book (LOB), yet the highly noisy nature of\nLOB data complicates the signal extraction process. Prior research has\ndemonstrated that deep-learning architectures can yield promising predictive\nperformance on pre-processed equity and futures LOB data, but they often treat\nmodel complexity as an unqualified virtue. In this paper, we aim to examine\nwhether adding extra hidden layers or parameters to \"blackbox ish\" neural\nnetworks genuinely enhances short term price forecasting, or if gains are\nprimarily attributable to data preprocessing and feature engineering. We\nbenchmark a spectrum of models from interpretable baselines, logistic\nregression, XGBoost to deep architectures (DeepLOB, Conv1D+LSTM) on BTC/USDT\nLOB snapshots sampled at 100 ms to multi second intervals using publicly\navailable Bybit data. We introduce two data filtering pipelines (Kalman,\nSavitzky Golay) and evaluate both binary (up/down) and ternary (up/flat/down)\nlabeling schemes. Our analysis compares models on out of sample accuracy,\nlatency, and robustness to noise. Results reveal that, with data preprocessing\nand hyperparameter tuning, simpler models can match and even exceed the\nperformance of more complex networks, offering faster inference and greater\ninterpretability.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u52a0\u5bc6\u8d27\u5e01\u4ef7\u683c\u9884\u6d4b\u4e2d\uff0c\u6570\u636e\u9884\u5904\u7406\u548c\u7279\u5f81\u5de5\u7a0b\u6bd4\u589e\u52a0\u795e\u7ecf\u7f51\u7edc\u590d\u6742\u5ea6\u66f4\u91cd\u8981\uff0c\u7b80\u5355\u6a21\u578b\u8868\u73b0\u4f18\u4e8e\u590d\u6742\u6a21\u578b\u3002", "motivation": "\u63a2\u8ba8\u5728\u52a0\u5bc6\u8d27\u5e01\u9650\u4ef7\u8ba2\u5355\u7c3f\uff08LOB\uff09\u6570\u636e\u4e2d\uff0c\u589e\u52a0\u795e\u7ecf\u7f51\u7edc\u590d\u6742\u5ea6\u662f\u5426\u771f\u7684\u80fd\u63d0\u5347\u77ed\u671f\u4ef7\u683c\u9884\u6d4b\u6027\u80fd\uff0c\u8fd8\u662f\u6570\u636e\u9884\u5904\u7406\u548c\u7279\u5f81\u5de5\u7a0b\u8d77\u4e3b\u8981\u4f5c\u7528\u3002", "method": "\u6bd4\u8f83\u4e86\u4ece\u903b\u8f91\u56de\u5f52\u3001XGBoost\u5230\u6df1\u5ea6\u67b6\u6784\uff08DeepLOB\u3001Conv1D+LSTM\uff09\u7684\u591a\u79cd\u6a21\u578b\uff0c\u4f7f\u7528BTC/USDT\u7684LOB\u6570\u636e\uff0c\u5e76\u5f15\u5165\u4e24\u79cd\u6570\u636e\u8fc7\u6ee4\u65b9\u6cd5\uff08\u5361\u5c14\u66fc\u6ee4\u6ce2\u3001Savitzky-Golay\u6ee4\u6ce2\uff09\u548c\u4e24\u79cd\u6807\u7b7e\u65b9\u6848\uff08\u4e8c\u5143\u548c\u4e09\u5143\uff09\u3002", "result": "\u7ecf\u8fc7\u6570\u636e\u9884\u5904\u7406\u548c\u8d85\u53c2\u6570\u8c03\u4f18\u540e\uff0c\u7b80\u5355\u6a21\u578b\u7684\u6027\u80fd\u53ef\u4ee5\u5339\u914d\u751a\u81f3\u8d85\u8fc7\u590d\u6742\u7f51\u7edc\uff0c\u540c\u65f6\u63d0\u4f9b\u66f4\u5feb\u7684\u63a8\u7406\u901f\u5ea6\u548c\u66f4\u9ad8\u7684\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u5728\u52a0\u5bc6\u8d27\u5e01\u4ef7\u683c\u9884\u6d4b\u4e2d\uff0c\u6570\u636e\u9884\u5904\u7406\u548c\u7279\u5f81\u5de5\u7a0b\u662f\u5173\u952e\uff0c\u7b80\u5355\u6a21\u578b\u5728\u6027\u80fd\u548c\u6548\u7387\u4e0a\u66f4\u5177\u4f18\u52bf\u3002"}}
{"id": "2506.05768", "pdf": "https://arxiv.org/pdf/2506.05768", "abs": "https://arxiv.org/abs/2506.05768", "authors": ["Wenyu Zhu", "Jianhui Wang", "Bowen Gao", "Yinjun Jia", "Haichuan Tan", "Ya-Qin Zhang", "Wei-Ying Ma", "Yanyan Lan"], "title": "AANet: Virtual Screening under Structural Uncertainty via Alignment and Aggregation", "categories": ["cs.LG", "q-bio.BM"], "comment": null, "summary": "Virtual screening (VS) is a critical component of modern drug discovery, yet\nmost existing methods--whether physics-based or deep learning-based--are\ndeveloped around holo protein structures with known ligand-bound pockets.\nConsequently, their performance degrades significantly on apo or predicted\nstructures such as those from AlphaFold2, which are more representative of\nreal-world early-stage drug discovery, where pocket information is often\nmissing. In this paper, we introduce an alignment-and-aggregation framework to\nenable accurate virtual screening under structural uncertainty. Our method\ncomprises two core components: (1) a tri-modal contrastive learning module that\naligns representations of the ligand, the holo pocket, and cavities detected\nfrom structures, thereby enhancing robustness to pocket localization error; and\n(2) a cross-attention based adapter for dynamically aggregating candidate\nbinding sites, enabling the model to learn from activity data even without\nprecise pocket annotations. We evaluated our method on a newly curated\nbenchmark of apo structures, where it significantly outperforms\nstate-of-the-art methods in blind apo setting, improving the early enrichment\nfactor (EF1%) from 11.75 to 37.19. Notably, it also maintains strong\nperformance on holo structures. These results demonstrate the promise of our\napproach in advancing first-in-class drug discovery, particularly in scenarios\nlacking experimentally resolved protein-ligand complexes.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5bf9\u9f50\u548c\u805a\u5408\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u7ed3\u6784\u4e0d\u786e\u5b9a\u6027\u4e0b\u5b9e\u73b0\u51c6\u786e\u7684\u865a\u62df\u7b5b\u9009\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5728apo\u7ed3\u6784\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u865a\u62df\u7b5b\u9009\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u5df2\u77e5\u914d\u4f53\u7ed3\u5408\u53e3\u888b\u7684holo\u86cb\u767d\u7ed3\u6784\uff0c\u800c\u5728apo\u6216\u9884\u6d4b\u7ed3\u6784\uff08\u5982AlphaFold2\u751f\u6210\uff09\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u9650\u5236\u4e86\u65e9\u671f\u836f\u7269\u53d1\u73b0\u7684\u5e94\u7528\u3002", "method": "\u65b9\u6cd5\u5305\u542b\u4e24\u90e8\u5206\uff1a(1) \u4e09\u6a21\u6001\u5bf9\u6bd4\u5b66\u4e60\u6a21\u5757\uff0c\u5bf9\u9f50\u914d\u4f53\u3001holo\u53e3\u888b\u548c\u68c0\u6d4b\u5230\u7684\u7a7a\u8154\u8868\u793a\uff1b(2) \u57fa\u4e8e\u4ea4\u53c9\u6ce8\u610f\u529b\u7684\u9002\u914d\u5668\uff0c\u52a8\u6001\u805a\u5408\u5019\u9009\u7ed3\u5408\u4f4d\u70b9\u3002", "result": "\u5728apo\u7ed3\u6784\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0cEF1%\u4ece11.75\u63d0\u5347\u81f337.19\uff0c\u540c\u65f6\u5728holo\u7ed3\u6784\u4e0a\u4fdd\u6301\u5f3a\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u7f3a\u4e4f\u5b9e\u9a8c\u89e3\u6790\u86cb\u767d-\u914d\u4f53\u590d\u5408\u7269\u7684\u573a\u666f\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u63a8\u52a8\u4e86\u9996\u521b\u836f\u7269\u7684\u53d1\u73b0\u3002"}}
{"id": "2506.05774", "pdf": "https://arxiv.org/pdf/2506.05774", "abs": "https://arxiv.org/abs/2506.05774", "authors": ["Tuomas Oikarinen", "Ge Yan", "Tsui-Wei Weng"], "title": "Evaluating Neuron Explanations: A Unified Framework with Sanity Checks", "categories": ["cs.LG"], "comment": "Published at ICML 2025", "summary": "Understanding the function of individual units in a neural network is an\nimportant building block for mechanistic interpretability. This is often done\nby generating a simple text explanation of the behavior of individual neurons\nor units. For these explanations to be useful, we must understand how reliable\nand truthful they are. In this work we unify many existing explanation\nevaluation methods under one mathematical framework. This allows us to compare\nexisting evaluation metrics, understand the evaluation pipeline with increased\nclarity and apply existing statistical methods on the evaluation. In addition,\nwe propose two simple sanity checks on the evaluation metrics and show that\nmany commonly used metrics fail these tests and do not change their score after\nmassive changes to the concept labels. Based on our experimental and\ntheoretical results, we propose guidelines that future evaluations should\nfollow and identify a set of reliable evaluation metrics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6570\u5b66\u6846\u67b6\u6765\u8bc4\u4f30\u795e\u7ecf\u7f51\u7edc\u5355\u5143\u7684\u89e3\u91ca\u65b9\u6cd5\uff0c\u5e76\u63d0\u51fa\u4e86\u4e24\u4e2a\u7b80\u5355\u7684\u5408\u7406\u6027\u68c0\u9a8c\uff0c\u53d1\u73b0\u8bb8\u591a\u5e38\u7528\u6307\u6807\u672a\u80fd\u901a\u8fc7\u8fd9\u4e9b\u68c0\u9a8c\u3002", "motivation": "\u7406\u89e3\u795e\u7ecf\u7f51\u7edc\u4e2d\u5355\u4e2a\u5355\u5143\u7684\u529f\u80fd\u662f\u673a\u5236\u53ef\u89e3\u91ca\u6027\u7684\u91cd\u8981\u57fa\u7840\uff0c\u4f46\u9700\u8981\u786e\u4fdd\u751f\u6210\u7684\u6587\u672c\u89e3\u91ca\u53ef\u9760\u4e14\u771f\u5b9e\u3002", "method": "\u7edf\u4e00\u73b0\u6709\u89e3\u91ca\u8bc4\u4f30\u65b9\u6cd5\u4e8e\u4e00\u4e2a\u6570\u5b66\u6846\u67b6\u4e0b\uff0c\u6bd4\u8f83\u8bc4\u4f30\u6307\u6807\uff0c\u5e76\u5e94\u7528\u7edf\u8ba1\u65b9\u6cd5\u3002\u63d0\u51fa\u4e24\u4e2a\u5408\u7406\u6027\u68c0\u9a8c\u3002", "result": "\u8bb8\u591a\u5e38\u7528\u8bc4\u4f30\u6307\u6807\u672a\u80fd\u901a\u8fc7\u5408\u7406\u6027\u68c0\u9a8c\uff0c\u4e14\u5728\u6982\u5ff5\u6807\u7b7e\u5927\u5e45\u6539\u53d8\u65f6\u5f97\u5206\u4e0d\u53d8\u3002", "conclusion": "\u63d0\u51fa\u4e86\u672a\u6765\u8bc4\u4f30\u5e94\u9075\u5faa\u7684\u6307\u5357\uff0c\u5e76\u786e\u5b9a\u4e86\u4e00\u7ec4\u53ef\u9760\u7684\u8bc4\u4f30\u6307\u6807\u3002"}}
{"id": "2506.05791", "pdf": "https://arxiv.org/pdf/2506.05791", "abs": "https://arxiv.org/abs/2506.05791", "authors": ["Yuki Takezawa", "Xiaowen Jiang", "Anton Rodomanov", "Sebastian U. Stich"], "title": "Exploiting Similarity for Computation and Communication-Efficient Decentralized Optimization", "categories": ["cs.LG", "math.OC"], "comment": "ICML 2025", "summary": "Reducing communication complexity is critical for efficient decentralized\noptimization. The proximal decentralized optimization (PDO) framework is\nparticularly appealing, as methods within this framework can exploit functional\nsimilarity among nodes to reduce communication rounds. Specifically, when local\nfunctions at different nodes are similar, these methods achieve faster\nconvergence with fewer communication steps. However, existing PDO methods often\nrequire highly accurate solutions to subproblems associated with the proximal\noperator, resulting in significant computational overhead. In this work, we\npropose the Stabilized Proximal Decentralized Optimization (SPDO) method, which\nachieves state-of-the-art communication and computational complexities within\nthe PDO framework. Additionally, we refine the analysis of existing PDO methods\nby relaxing subproblem accuracy requirements and leveraging average functional\nsimilarity. Experimental results demonstrate that SPDO significantly\noutperforms existing methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7a33\u5b9a\u8fd1\u7aef\u53bb\u4e2d\u5fc3\u5316\u4f18\u5316\u65b9\u6cd5\uff08SPDO\uff09\uff0c\u5728\u51cf\u5c11\u901a\u4fe1\u590d\u6742\u5ea6\u7684\u540c\u65f6\u964d\u4f4e\u4e86\u8ba1\u7b97\u5f00\u9500\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u53bb\u4e2d\u5fc3\u5316\u4f18\u5316\u4e2d\u901a\u4fe1\u590d\u6742\u5ea6\u662f\u5173\u952e\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u89e3\u51b3\u5b50\u95ee\u9898\u65f6\u8ba1\u7b97\u5f00\u9500\u5927\u3002", "method": "\u63d0\u51faSPDO\u65b9\u6cd5\uff0c\u653e\u5bbd\u5b50\u95ee\u9898\u7cbe\u5ea6\u8981\u6c42\u5e76\u5229\u7528\u5e73\u5747\u529f\u80fd\u76f8\u4f3c\u6027\u3002", "result": "SPDO\u5728\u901a\u4fe1\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u4e0a\u8fbe\u5230\u6700\u4f18\uff0c\u5b9e\u9a8c\u8868\u73b0\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "SPDO\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u53bb\u4e2d\u5fc3\u5316\u4f18\u5316\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u529f\u80fd\u76f8\u4f3c\u6027\u9ad8\u7684\u573a\u666f\u3002"}}
{"id": "2506.05797", "pdf": "https://arxiv.org/pdf/2506.05797", "abs": "https://arxiv.org/abs/2506.05797", "authors": ["Qianyi Chen", "Tianrun Gao", "Chenbo Jiang", "Tailin Wu"], "title": "EqCollide: Equivariant and Collision-Aware Deformable Objects Neural Simulator", "categories": ["cs.LG", "cs.CE", "cs.RO"], "comment": null, "summary": "Simulating collisions of deformable objects is a fundamental yet challenging\ntask due to the complexity of modeling solid mechanics and multi-body\ninteractions. Existing data-driven methods often suffer from lack of\nequivariance to physical symmetries, inadequate handling of collisions, and\nlimited scalability. Here we introduce EqCollide, the first end-to-end\nequivariant neural fields simulator for deformable objects and their\ncollisions. We propose an equivariant encoder to map object geometry and\nvelocity into latent control points. A subsequent equivariant Graph Neural\nNetwork-based Neural Ordinary Differential Equation models the interactions\namong control points via collision-aware message passing. To reconstruct\nvelocity fields, we query a neural field conditioned on control point features,\nenabling continuous and resolution-independent motion predictions. Experimental\nresults show that EqCollide achieves accurate, stable, and scalable simulations\nacross diverse object configurations, and our model achieves 24.34% to 35.82%\nlower rollout MSE even compared with the best-performing baseline model.\nFurthermore, our model could generalize to more colliding objects and extended\ntemporal horizons, and stay robust to input transformed with group action.", "AI": {"tldr": "EqCollide\u662f\u4e00\u79cd\u7aef\u5230\u7aef\u7684\u7b49\u53d8\u795e\u7ecf\u573a\u6a21\u62df\u5668\uff0c\u7528\u4e8e\u6a21\u62df\u53ef\u53d8\u5f62\u7269\u4f53\u53ca\u5176\u78b0\u649e\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u7269\u7406\u5bf9\u79f0\u6027\u3001\u78b0\u649e\u5904\u7406\u548c\u53ef\u6269\u5c55\u6027\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "\u6a21\u62df\u53ef\u53d8\u5f62\u7269\u4f53\u7684\u78b0\u649e\u662f\u4e00\u4e2a\u590d\u6742\u4e14\u5177\u6709\u6311\u6218\u6027\u7684\u4efb\u52a1\uff0c\u73b0\u6709\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u5728\u7269\u7406\u5bf9\u79f0\u6027\u3001\u78b0\u649e\u5904\u7406\u548c\u53ef\u6269\u5c55\u6027\u4e0a\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7b49\u53d8\u7f16\u7801\u5668\u5c06\u7269\u4f53\u51e0\u4f55\u548c\u901f\u5ea6\u6620\u5c04\u5230\u6f5c\u5728\u63a7\u5236\u70b9\uff0c\u5e76\u4f7f\u7528\u57fa\u4e8e\u7b49\u53d8\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u795e\u7ecf\u5e38\u5fae\u5206\u65b9\u7a0b\u901a\u8fc7\u78b0\u649e\u611f\u77e5\u6d88\u606f\u4f20\u9012\u5efa\u6a21\u63a7\u5236\u70b9\u95f4\u7684\u4ea4\u4e92\u3002\u901a\u8fc7\u67e5\u8be2\u795e\u7ecf\u573a\u91cd\u5efa\u901f\u5ea6\u573a\uff0c\u5b9e\u73b0\u8fde\u7eed\u4e14\u5206\u8fa8\u7387\u65e0\u5173\u7684\u8fd0\u52a8\u9884\u6d4b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cEqCollide\u5728\u591a\u79cd\u7269\u4f53\u914d\u7f6e\u4e0b\u5b9e\u73b0\u4e86\u51c6\u786e\u3001\u7a33\u5b9a\u4e14\u53ef\u6269\u5c55\u7684\u6a21\u62df\uff0c\u5176\u6eda\u52a8\u5747\u65b9\u8bef\u5dee\u6bd4\u6700\u4f73\u57fa\u7ebf\u6a21\u578b\u4f4e24.34%\u81f335.82%\u3002", "conclusion": "EqCollide\u80fd\u591f\u6cdb\u5316\u5230\u66f4\u591a\u78b0\u649e\u7269\u4f53\u548c\u66f4\u957f\u7684\u65f6\u95f4\u8303\u56f4\uff0c\u5e76\u5bf9\u7fa4\u4f5c\u7528\u53d8\u6362\u7684\u8f93\u5165\u4fdd\u6301\u9c81\u68d2\u6027\u3002"}}
{"id": "2506.05799", "pdf": "https://arxiv.org/pdf/2506.05799", "abs": "https://arxiv.org/abs/2506.05799", "authors": ["Zeyuan Li", "Qingdao Huang"], "title": "Option Pricing Using Ensemble Learning", "categories": ["cs.LG"], "comment": null, "summary": "Ensemble learning is characterized by flexibility, high precision, and\nrefined structure. As a critical component within computational finance, option\npricing with machine learning requires both high predictive accuracy and\nreduced structural complexity-features that align well with the inherent\nadvantages of ensemble learning. This paper investigates the application of\nensemble learning to option pricing, and conducts a comparative analysis with\nclassical machine learning models to assess their performance in terms of\naccuracy, local feature extraction, and robustness to noise. A novel\nexperimental strategy is introduced, leveraging parameter transfer across\nexperiments to improve robustness and realism in financial simulations.Building\nupon this strategy, an evaluation mechanism is developed that incorporates a\nscoring strategy and a weighted evaluation strategy explicitly emphasizing the\nfoundational role of financial theory. This mechanism embodies an orderly\nintegration of theoretical finance and computational methods. In addition, the\nstudy examines the interaction between sliding window technique and noise,\nrevealing nuanced patterns that suggest a potential connection relevant to\nongoing research in machine learning and data science.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u96c6\u6210\u5b66\u4e60\u5728\u671f\u6743\u5b9a\u4ef7\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u4e0e\u7ecf\u5178\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u4e86\u6bd4\u8f83\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5b9e\u9a8c\u7b56\u7565\u548c\u8bc4\u4f30\u673a\u5236\u3002", "motivation": "\u671f\u6743\u5b9a\u4ef7\u9700\u8981\u9ad8\u9884\u6d4b\u7cbe\u5ea6\u548c\u4f4e\u7ed3\u6784\u590d\u6742\u5ea6\uff0c\u96c6\u6210\u5b66\u4e60\u7684\u7075\u6d3b\u6027\u3001\u9ad8\u7cbe\u5ea6\u548c\u7cbe\u7ec6\u7ed3\u6784\u4e0e\u4e4b\u5951\u5408\u3002", "method": "\u91c7\u7528\u96c6\u6210\u5b66\u4e60\u65b9\u6cd5\uff0c\u5f15\u5165\u53c2\u6570\u4f20\u9012\u5b9e\u9a8c\u7b56\u7565\uff0c\u5f00\u53d1\u4e86\u7ed3\u5408\u8bc4\u5206\u548c\u52a0\u6743\u8bc4\u4f30\u7684\u673a\u5236\uff0c\u5e76\u7814\u7a76\u4e86\u6ed1\u52a8\u7a97\u53e3\u6280\u672f\u4e0e\u566a\u58f0\u7684\u4ea4\u4e92\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u96c6\u6210\u5b66\u4e60\u5728\u51c6\u786e\u6027\u3001\u5c40\u90e8\u7279\u5f81\u63d0\u53d6\u548c\u566a\u58f0\u9c81\u68d2\u6027\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u63ed\u793a\u4e86\u6ed1\u52a8\u7a97\u53e3\u4e0e\u566a\u58f0\u7684\u6f5c\u5728\u8054\u7cfb\u3002", "conclusion": "\u96c6\u6210\u5b66\u4e60\u5728\u671f\u6743\u5b9a\u4ef7\u4e2d\u5177\u6709\u4f18\u52bf\uff0c\u5b9e\u9a8c\u7b56\u7565\u548c\u8bc4\u4f30\u673a\u5236\u4e3a\u91d1\u878d\u7406\u8bba\u4e0e\u8ba1\u7b97\u65b9\u6cd5\u7684\u7ed3\u5408\u63d0\u4f9b\u4e86\u6709\u5e8f\u6846\u67b6\u3002"}}
{"id": "2506.05801", "pdf": "https://arxiv.org/pdf/2506.05801", "abs": "https://arxiv.org/abs/2506.05801", "authors": ["Chuang Ma", "Tomoyuki Obuchi", "Toshiyuki Tanaka"], "title": "Neural Collapse in Cumulative Link Models for Ordinal Regression: An Analysis with Unconstrained Feature Model", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "A phenomenon known as ''Neural Collapse (NC)'' in deep classification tasks,\nin which the penultimate-layer features and the final classifiers exhibit an\nextremely simple geometric structure, has recently attracted considerable\nattention, with the expectation that it can deepen our understanding of how\ndeep neural networks behave. The Unconstrained Feature Model (UFM) has been\nproposed to explain NC theoretically, and there emerges a growing body of work\nthat extends NC to tasks other than classification and leverages it for\npractical applications. In this study, we investigate whether a similar\nphenomenon arises in deep Ordinal Regression (OR) tasks, via combining the\ncumulative link model for OR and UFM. We show that a phenomenon we call Ordinal\nNeural Collapse (ONC) indeed emerges and is characterized by the following\nthree properties: (ONC1) all optimal features in the same class collapse to\ntheir within-class mean when regularization is applied; (ONC2) these class\nmeans align with the classifier, meaning that they collapse onto a\none-dimensional subspace; (ONC3) the optimal latent variables (corresponding to\nlogits or preactivations in classification tasks) are aligned according to the\nclass order, and in particular, in the zero-regularization limit, a highly\nlocal and simple geometric relationship emerges between the latent variables\nand the threshold values. We prove these properties analytically within the UFM\nframework with fixed threshold values and corroborate them empirically across a\nvariety of datasets. We also discuss how these insights can be leveraged in OR,\nhighlighting the use of fixed thresholds.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u6df1\u5ea6\u5e8f\u6570\u56de\u5f52\u4efb\u52a1\u4e2d\u4f1a\u51fa\u73b0\u4e00\u79cd\u79f0\u4e3a\u201c\u5e8f\u6570\u795e\u7ecf\u574d\u7f29\u201d\uff08ONC\uff09\u7684\u73b0\u8c61\uff0c\u5176\u7279\u5f81\u5305\u62ec\u7c7b\u5185\u7279\u5f81\u574d\u7f29\u3001\u7c7b\u5747\u503c\u4e0e\u5206\u7c7b\u5668\u5bf9\u9f50\u4ee5\u53ca\u6f5c\u5728\u53d8\u91cf\u6309\u7c7b\u987a\u5e8f\u6392\u5217\u3002", "motivation": "\u63a2\u7d22\u6df1\u5ea6\u5e8f\u6570\u56de\u5f52\u4efb\u52a1\u4e2d\u662f\u5426\u4f1a\u51fa\u73b0\u7c7b\u4f3c\u201c\u795e\u7ecf\u574d\u7f29\u201d\u7684\u73b0\u8c61\uff0c\u4ee5\u6df1\u5316\u5bf9\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u884c\u4e3a\u7684\u7406\u89e3\u3002", "method": "\u7ed3\u5408\u7d2f\u79ef\u94fe\u63a5\u6a21\u578b\u548c\u65e0\u7ea6\u675f\u7279\u5f81\u6a21\u578b\uff08UFM\uff09\uff0c\u7406\u8bba\u5206\u6790\u5e76\u5b9e\u8bc1\u9a8c\u8bc1ONC\u73b0\u8c61\u3002", "result": "ONC\u73b0\u8c61\u786e\u5b9e\u5b58\u5728\uff0c\u5e76\u8868\u73b0\u51fa\u4e09\u79cd\u7279\u6027\uff1a\u7c7b\u5185\u7279\u5f81\u574d\u7f29\u3001\u7c7b\u5747\u503c\u4e0e\u5206\u7c7b\u5668\u5bf9\u9f50\u3001\u6f5c\u5728\u53d8\u91cf\u6309\u7c7b\u987a\u5e8f\u6392\u5217\u3002", "conclusion": "ONC\u73b0\u8c61\u4e3a\u5e8f\u6570\u56de\u5f52\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u652f\u6301\uff0c\u5e76\u5c55\u793a\u4e86\u56fa\u5b9a\u9608\u503c\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.05814", "pdf": "https://arxiv.org/pdf/2506.05814", "abs": "https://arxiv.org/abs/2506.05814", "authors": ["Yogesh Verma", "Amauri H. Souza", "Vikas Garg"], "title": "Positional Encoding meets Persistent Homology on Graphs", "categories": ["cs.LG", "cs.AI", "cs.ET", "cs.SI"], "comment": "Accepted at ICML 2025", "summary": "The local inductive bias of message-passing graph neural networks (GNNs)\nhampers their ability to exploit key structural information (e.g., connectivity\nand cycles). Positional encoding (PE) and Persistent Homology (PH) have emerged\nas two promising approaches to mitigate this issue. PE schemes endow GNNs with\nlocation-aware features, while PH methods enhance GNNs with multiresolution\ntopological features. However, a rigorous theoretical characterization of the\nrelative merits and shortcomings of PE and PH has remained elusive. We bridge\nthis gap by establishing that neither paradigm is more expressive than the\nother, providing novel constructions where one approach fails but the other\nsucceeds. Our insights inform the design of a novel learnable method, PiPE\n(Persistence-informed Positional Encoding), which is provably more expressive\nthan both PH and PE. PiPE demonstrates strong performance across a variety of\ntasks (e.g., molecule property prediction, graph classification, and\nout-of-distribution generalization), thereby advancing the frontiers of graph\nrepresentation learning. Code is available at\nhttps://github.com/Aalto-QuML/PIPE.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u6d88\u606f\u4f20\u9012\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNNs\uff09\u7684\u5c40\u90e8\u5f52\u7eb3\u504f\u5dee\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4f4d\u7f6e\u7f16\u7801\uff08PE\uff09\u548c\u6301\u4e45\u540c\u8c03\uff08PH\uff09\u7684\u65b0\u65b9\u6cd5PiPE\uff0c\u8bc1\u660e\u5176\u6bd4\u4e24\u8005\u66f4\u5177\u8868\u8fbe\u529b\uff0c\u5e76\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u89e3\u51b3GNNs\u56e0\u5c40\u90e8\u5f52\u7eb3\u504f\u5dee\u800c\u65e0\u6cd5\u5145\u5206\u5229\u7528\u7ed3\u6784\u4fe1\u606f\uff08\u5982\u8fde\u901a\u6027\u548c\u5faa\u73af\uff09\u7684\u95ee\u9898\uff0c\u63a2\u7d22PE\u548cPH\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u6bd4\u8f83PE\u548cPH\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u8bbe\u8ba1\u4e86\u4e00\u79cd\u7ed3\u5408\u4e24\u8005\u7684\u65b0\u65b9\u6cd5PiPE\u3002", "result": "PiPE\u5728\u5206\u5b50\u6027\u8d28\u9884\u6d4b\u3001\u56fe\u5206\u7c7b\u548c\u5206\u5e03\u5916\u6cdb\u5316\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8ePE\u548cPH\u3002", "conclusion": "PiPE\u662f\u4e00\u79cd\u66f4\u5177\u8868\u8fbe\u529b\u7684\u65b9\u6cd5\uff0c\u4e3a\u56fe\u8868\u793a\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2506.05826", "pdf": "https://arxiv.org/pdf/2506.05826", "abs": "https://arxiv.org/abs/2506.05826", "authors": ["Ngoc Bui", "Menglin Yang", "Runjin Chen", "Leonardo Neves", "Mingxuan Ju", "Rex Ying", "Neil Shah", "Tong Zhao"], "title": "Learning Along the Arrow of Time: Hyperbolic Geometry for Backward-Compatible Representation Learning", "categories": ["cs.LG"], "comment": null, "summary": "Backward compatible representation learning enables updated models to\nintegrate seamlessly with existing ones, avoiding to reprocess stored data.\nDespite recent advances, existing compatibility approaches in Euclidean space\nneglect the uncertainty in the old embedding model and force the new model to\nreconstruct outdated representations regardless of their quality, thereby\nhindering the learning process of the new model. In this paper, we propose to\nswitch perspectives to hyperbolic geometry, where we treat time as a natural\naxis for capturing a model's confidence and evolution. By lifting embeddings\ninto hyperbolic space and constraining updated embeddings to lie within the\nentailment cone of the old ones, we maintain generational consistency across\nmodels while accounting for uncertainties in the representations. To further\nenhance compatibility, we introduce a robust contrastive alignment loss that\ndynamically adjusts alignment weights based on the uncertainty of the old\nembeddings. Experiments validate the superiority of the proposed method in\nachieving compatibility, paving the way for more resilient and adaptable\nmachine learning systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53cc\u66f2\u51e0\u4f55\u7684\u5411\u540e\u517c\u5bb9\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u5d4c\u5165\u63d0\u5347\u5230\u53cc\u66f2\u7a7a\u95f4\u5e76\u8003\u8651\u65e7\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5b9e\u73b0\u4e86\u6a21\u578b\u7684\u4ee3\u9645\u4e00\u81f4\u6027\u3002", "motivation": "\u73b0\u6709\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\u4e2d\u7684\u517c\u5bb9\u6027\u65b9\u6cd5\u5ffd\u7565\u4e86\u65e7\u5d4c\u5165\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5f3a\u5236\u65b0\u6a21\u578b\u91cd\u5efa\u8fc7\u65f6\u7684\u8868\u793a\uff0c\u963b\u788d\u4e86\u65b0\u6a21\u578b\u7684\u5b66\u4e60\u8fc7\u7a0b\u3002", "method": "\u5c06\u5d4c\u5165\u63d0\u5347\u5230\u53cc\u66f2\u7a7a\u95f4\uff0c\u7ea6\u675f\u66f4\u65b0\u540e\u7684\u5d4c\u5165\u4f4d\u4e8e\u65e7\u5d4c\u5165\u7684\u8574\u542b\u9525\u5185\uff0c\u5e76\u5f15\u5165\u52a8\u6001\u8c03\u6574\u5bf9\u9f50\u6743\u91cd\u7684\u5bf9\u6bd4\u5bf9\u9f50\u635f\u5931\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u5b9e\u73b0\u517c\u5bb9\u6027\u65b9\u9762\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6784\u5efa\u66f4\u5177\u5f39\u6027\u548c\u9002\u5e94\u6027\u7684\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.05831", "pdf": "https://arxiv.org/pdf/2506.05831", "abs": "https://arxiv.org/abs/2506.05831", "authors": ["Yihan Xie", "Sijing Li", "Tianwei Lin", "Zhuonan Wang", "Chenglin Yang", "Yu Zhong", "Wenqiao Zhang", "Haoyuan Li", "Hao Jiang", "Fengda Zhang", "Qishan Chen", "Jun Xiao", "Yueting Zhuang", "Beng Chin Ooi"], "title": "Heartcare Suite: Multi-dimensional Understanding of ECG with Raw Multi-lead Signal Modeling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We present Heartcare Suite, a multimodal comprehensive framework for\nfinegrained electrocardiogram (ECG) understanding. It comprises three key\ncomponents: (i) Heartcare-220K, a high-quality, structured, and comprehensive\nmultimodal ECG dataset covering essential tasks such as disease diagnosis,\nwaveform morphology analysis, and rhythm interpretation. (ii) Heartcare-Bench,\na systematic and multi-dimensional benchmark designed to evaluate diagnostic\nintelligence and guide the optimization of Medical Multimodal Large Language\nModels (Med-MLLMs) in ECG scenarios. and (iii) HeartcareGPT with a tailored\ntokenizer Bidirectional ECG Abstract Tokenization (Beat), which compresses raw\nmulti-lead signals into semantically rich discrete tokens via duallevel vector\nquantization and query-guided bidirectional diffusion mechanism. Built upon\nHeartcare-220K, HeartcareGPT achieves strong generalization and SoTA\nperformance across multiple clinically meaningful tasks. Extensive experiments\ndemonstrate that Heartcare Suite is highly effective in advancing ECGspecific\nmultimodal understanding and evaluation. Our project is available at\nhttps://github.com/DCDmllm/Heartcare-Suite .", "AI": {"tldr": "Heartcare Suite\u662f\u4e00\u4e2a\u591a\u6a21\u6001ECG\u7406\u89e3\u6846\u67b6\uff0c\u5305\u542b\u6570\u636e\u96c6\u3001\u57fa\u51c6\u6d4b\u8bd5\u548c\u6a21\u578bHeartcareGPT\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u5728ECG\u4efb\u52a1\u4e2d\u7684\u9ad8\u6548\u6027\u548c\u9886\u5148\u6027\u80fd\u3002", "motivation": "\u63d0\u5347ECG\u7684\u591a\u6a21\u6001\u7406\u89e3\u548c\u8bc4\u4f30\u80fd\u529b\uff0c\u4e3a\u533b\u5b66\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08Med-MLLMs\uff09\u5728ECG\u573a\u666f\u4e2d\u7684\u4f18\u5316\u63d0\u4f9b\u652f\u6301\u3002", "method": "\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u90e8\u5206\uff1a\u9ad8\u8d28\u91cf\u6570\u636e\u96c6Heartcare-220K\u3001\u7cfb\u7edf\u6027\u57fa\u51c6\u6d4b\u8bd5Heartcare-Bench\u548c\u6a21\u578bHeartcareGPT\uff08\u91c7\u7528\u5b9a\u5236\u5316\u5206\u8bcd\u5668Beat\uff09\u3002", "result": "HeartcareGPT\u5728\u591a\u4e2a\u4e34\u5e8a\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u548c\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "Heartcare Suite\u6709\u6548\u63a8\u52a8\u4e86ECG\u591a\u6a21\u6001\u7406\u89e3\u548c\u8bc4\u4f30\u7684\u8fdb\u5c55\uff0c\u9879\u76ee\u5df2\u5f00\u6e90\u3002"}}
{"id": "2506.05857", "pdf": "https://arxiv.org/pdf/2506.05857", "abs": "https://arxiv.org/abs/2506.05857", "authors": ["Junpeng Lin", "Tian Lan", "Bo Zhang", "Ke Lin", "Dandan Miao", "Huiru He", "Jiantao Ye", "Chen Zhang", "Yan-fu Li"], "title": "Wavelet-based Disentangled Adaptive Normalization for Non-stationary Times Series Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "Forecasting non-stationary time series is a challenging task because their\nstatistical properties often change over time, making it hard for deep models\nto generalize well. Instance-level normalization techniques can help address\nshifts in temporal distribution. However, most existing methods overlook the\nmulti-component nature of time series, where different components exhibit\ndistinct non-stationary behaviors. In this paper, we propose Wavelet-based\nDisentangled Adaptive Normalization (WDAN), a model-agnostic framework designed\nto address non-stationarity in time series forecasting. WDAN uses discrete\nwavelet transforms to break down the input into low-frequency trends and\nhigh-frequency fluctuations. It then applies tailored normalization strategies\nto each part. For trend components that exhibit strong non-stationarity, we\napply first-order differencing to extract stable features used for predicting\nnormalization parameters. Extensive experiments on multiple benchmarks\ndemonstrate that WDAN consistently improves forecasting accuracy across various\nbackbone model. Code is available at this repository:\nhttps://github.com/MonBG/WDAN.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5c0f\u6ce2\u7684\u89e3\u8026\u81ea\u9002\u5e94\u5f52\u4e00\u5316\uff08WDAN\uff09\u6846\u67b6\uff0c\u7528\u4e8e\u5904\u7406\u975e\u5e73\u7a33\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u591a\u7ec4\u5206\u7279\u6027\u3002", "motivation": "\u975e\u5e73\u7a33\u65f6\u95f4\u5e8f\u5217\u7684\u7edf\u8ba1\u7279\u6027\u968f\u65f6\u95f4\u53d8\u5316\uff0c\u73b0\u6709\u65b9\u6cd5\u5e38\u5ffd\u7565\u5176\u591a\u7ec4\u5206\u7279\u6027\uff0c\u5bfc\u81f4\u9884\u6d4b\u6027\u80fd\u4e0d\u4f73\u3002", "method": "\u4f7f\u7528\u79bb\u6563\u5c0f\u6ce2\u53d8\u6362\u5c06\u8f93\u5165\u5206\u89e3\u4e3a\u4f4e\u9891\u8d8b\u52bf\u548c\u9ad8\u9891\u6ce2\u52a8\uff0c\u5e76\u5206\u522b\u5e94\u7528\u5b9a\u5236\u5f52\u4e00\u5316\u7b56\u7565\u3002\u5bf9\u5f3a\u975e\u5e73\u7a33\u8d8b\u52bf\u90e8\u5206\uff0c\u91c7\u7528\u4e00\u9636\u5dee\u5206\u63d0\u53d6\u7a33\u5b9a\u7279\u5f81\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cWDAN\u663e\u8457\u63d0\u5347\u4e86\u4e0d\u540c\u4e3b\u5e72\u6a21\u578b\u7684\u9884\u6d4b\u51c6\u786e\u6027\u3002", "conclusion": "WDAN\u662f\u4e00\u79cd\u6a21\u578b\u65e0\u5173\u7684\u6846\u67b6\uff0c\u80fd\u6709\u6548\u5904\u7406\u65f6\u95f4\u5e8f\u5217\u7684\u975e\u5e73\u7a33\u6027\uff0c\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2506.05869", "pdf": "https://arxiv.org/pdf/2506.05869", "abs": "https://arxiv.org/abs/2506.05869", "authors": ["Han Ji", "Yuqi Feng", "Jiahao Fan", "Yanan Sun"], "title": "Loss Functions for Predictor-based Neural Architecture Search", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Evaluation is a critical but costly procedure in neural architecture search\n(NAS). Performance predictors have been widely adopted to reduce evaluation\ncosts by directly estimating architecture performance. The effectiveness of\npredictors is heavily influenced by the choice of loss functions. While\ntraditional predictors employ regression loss functions to evaluate the\nabsolute accuracy of architectures, recent approaches have explored various\nranking-based loss functions, such as pairwise and listwise ranking losses, to\nfocus on the ranking of architecture performance. Despite their success in NAS,\nthe effectiveness and characteristics of these loss functions have not been\nthoroughly investigated. In this paper, we conduct the first comprehensive\nstudy on loss functions in performance predictors, categorizing them into three\nmain types: regression, ranking, and weighted loss functions. Specifically, we\nassess eight loss functions using a range of NAS-relevant metrics on 13 tasks\nacross five search spaces. Our results reveal that specific categories of loss\nfunctions can be effectively combined to enhance predictor-based NAS.\nFurthermore, our findings could provide practical guidance for selecting\nappropriate loss functions for various tasks. We hope this work provides\nmeaningful insights to guide the development of loss functions for\npredictor-based methods in the NAS community.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5168\u9762\u7814\u7a76\u4e86\u6027\u80fd\u9884\u6d4b\u5668\u4e2d\u635f\u5931\u51fd\u6570\u7684\u4f5c\u7528\uff0c\u5c06\u5176\u5206\u4e3a\u56de\u5f52\u3001\u6392\u5e8f\u548c\u52a0\u6743\u4e09\u7c7b\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5b83\u4eec\u7684\u7ec4\u5408\u6548\u679c\u3002", "motivation": "\u795e\u7ecf\u67b6\u6784\u641c\u7d22\uff08NAS\uff09\u4e2d\u8bc4\u4f30\u6210\u672c\u9ad8\uff0c\u6027\u80fd\u9884\u6d4b\u5668\u901a\u8fc7\u635f\u5931\u51fd\u6570\u9009\u62e9\u76f4\u63a5\u5f71\u54cd\u6548\u679c\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u672a\u6df1\u5165\u63a2\u8ba8\u4e0d\u540c\u635f\u5931\u51fd\u6570\u7684\u7279\u6027\u4e0e\u6548\u679c\u3002", "method": "\u5c06\u635f\u5931\u51fd\u6570\u5206\u4e3a\u56de\u5f52\u3001\u6392\u5e8f\u548c\u52a0\u6743\u4e09\u7c7b\uff0c\u8bc4\u4f30\u4e86\u516b\u79cd\u635f\u5931\u51fd\u6570\u572813\u4e2a\u4efb\u52a1\u548c\u4e94\u4e2a\u641c\u7d22\u7a7a\u95f4\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u7279\u5b9a\u7c7b\u522b\u7684\u635f\u5931\u51fd\u6570\u7ec4\u5408\u53ef\u63d0\u5347\u9884\u6d4b\u5668\u6027\u80fd\uff0c\u5e76\u4e3a\u4e0d\u540c\u4efb\u52a1\u9009\u62e9\u635f\u5931\u51fd\u6570\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002", "conclusion": "\u672c\u6587\u4e3aNAS\u793e\u533a\u4e2d\u6027\u80fd\u9884\u6d4b\u5668\u7684\u635f\u5931\u51fd\u6570\u5f00\u53d1\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2506.05871", "pdf": "https://arxiv.org/pdf/2506.05871", "abs": "https://arxiv.org/abs/2506.05871", "authors": ["Xiannan Hu", "Tianyou Zeng", "Xiaoming Yuan", "Liwei Song", "Guangyuan Zhang", "Bangzheng He"], "title": "BestServe: Serving Strategies with Optimal Goodput in Collocation and Disaggregation Architectures", "categories": ["cs.LG", "cs.DC", "cs.PF"], "comment": null, "summary": "Serving large language models (LLMs) to millions of users requires efficient\nresource allocation and parallelism strategies. It is a labor intensive\ntrial-and-error process to find such a strategy. We present BestServe, a novel\nframework for ranking serving strategies by estimating goodput under various\noperating scenarios. Supporting both collocated and disaggregated\narchitectures, BestServe leverages an inference simulator built on an adapted\nroofline model and CPU-GPU dispatch dynamics. Our framework determines the\noptimal strategy in minutes on a single standard CPU, eliminating the need for\ncostly benchmarking, while achieving predictions within a $20\\%$ error margin.\nIt appeals to be practical for rapid deployment planning because of its\nlightweight design and strong extensibility.", "AI": {"tldr": "BestServe\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u62df\u63a8\u7406\u548c\u52a8\u6001\u8c03\u5ea6\u5feb\u901f\u8bc4\u4f30LLM\u670d\u52a1\u7b56\u7565\uff0c\u907f\u514d\u9ad8\u6210\u672c\u57fa\u51c6\u6d4b\u8bd5\u3002", "motivation": "\u4e3a\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u670d\u52a1\u8bbe\u8ba1\u9ad8\u6548\u8d44\u6e90\u5206\u914d\u548c\u5e76\u884c\u7b56\u7565\u662f\u4e00\u4e2a\u8017\u65f6\u4e14\u8bd5\u9519\u7684\u8fc7\u7a0b\uff0c\u9700\u8981\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "BestServe\u57fa\u4e8e\u6539\u8fdb\u7684\u5c4b\u9876\u6a21\u578b\u548cCPU-GPU\u8c03\u5ea6\u52a8\u6001\u6784\u5efa\u63a8\u7406\u6a21\u62df\u5668\uff0c\u652f\u6301\u591a\u79cd\u67b6\u6784\uff0c\u5feb\u901f\u8bc4\u4f30\u7b56\u7565\u3002", "result": "\u5728\u5355CPU\u4e0a\u51e0\u5206\u949f\u5185\u786e\u5b9a\u6700\u4f18\u7b56\u7565\uff0c\u9884\u6d4b\u8bef\u5dee\u572820%\u4ee5\u5185\uff0c\u9002\u7528\u4e8e\u5feb\u901f\u90e8\u7f72\u3002", "conclusion": "BestServe\u56e0\u5176\u8f7b\u91cf\u8bbe\u8ba1\u548c\u5f3a\u6269\u5c55\u6027\uff0c\u6210\u4e3aLLM\u670d\u52a1\u7b56\u7565\u8bc4\u4f30\u7684\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2506.05877", "pdf": "https://arxiv.org/pdf/2506.05877", "abs": "https://arxiv.org/abs/2506.05877", "authors": ["Hang Lv", "Lianyu Hu", "Mudi Jiang", "Xinying Liu", "Zengyou He"], "title": "Interpretable Clustering Ensemble", "categories": ["cs.LG"], "comment": null, "summary": "Clustering ensemble has emerged as an important research topic in the field\nof machine learning. Although numerous methods have been proposed to improve\nclustering quality, most existing approaches overlook the need for\ninterpretability in high-stakes applications. In domains such as medical\ndiagnosis and financial risk assessment, algorithms must not only be accurate\nbut also interpretable to ensure transparent and trustworthy decision-making.\nTherefore, to fill the gap of lack of interpretable algorithms in the field of\nclustering ensemble, we propose the first interpretable clustering ensemble\nalgorithm in the literature. By treating base partitions as categorical\nvariables, our method constructs a decision tree in the original feature space\nand use the statistical association test to guide the tree building process.\nExperimental results demonstrate that our algorithm achieves comparable\nperformance to state-of-the-art (SOTA) clustering ensemble methods while\nmaintaining an additional feature of interpretability. To the best of our\nknowledge, this is the first interpretable algorithm specifically designed for\nclustering ensemble, offering a new perspective for future research in\ninterpretable clustering.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u89e3\u91ca\u7684\u805a\u7c7b\u96c6\u6210\u7b97\u6cd5\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u7684\u7a7a\u767d\u3002", "motivation": "\u5728\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\uff08\u5982\u533b\u7597\u8bca\u65ad\u548c\u91d1\u878d\u98ce\u9669\u8bc4\u4f30\uff09\uff0c\u7b97\u6cd5\u4e0d\u4ec5\u9700\u8981\u51c6\u786e\uff0c\u8fd8\u9700\u5177\u5907\u53ef\u89e3\u91ca\u6027\u4ee5\u786e\u4fdd\u51b3\u7b56\u900f\u660e\u53ef\u4fe1\u3002", "method": "\u5c06\u57fa\u7840\u5206\u533a\u89c6\u4e3a\u5206\u7c7b\u53d8\u91cf\uff0c\u5728\u539f\u59cb\u7279\u5f81\u7a7a\u95f4\u4e2d\u6784\u5efa\u51b3\u7b56\u6811\uff0c\u5e76\u4f7f\u7528\u7edf\u8ba1\u5173\u8054\u6d4b\u8bd5\u6307\u5bfc\u6811\u7684\u6784\u5efa\u8fc7\u7a0b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u7b97\u6cd5\u6027\u80fd\u4e0e\u6700\u5148\u8fdb\u7684\u805a\u7c7b\u96c6\u6210\u65b9\u6cd5\u76f8\u5f53\uff0c\u540c\u65f6\u5177\u5907\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u4e13\u4e3a\u805a\u7c7b\u96c6\u6210\u8bbe\u8ba1\u7684\u53ef\u89e3\u91ca\u7b97\u6cd5\uff0c\u4e3a\u672a\u6765\u53ef\u89e3\u91ca\u805a\u7c7b\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2506.05878", "pdf": "https://arxiv.org/pdf/2506.05878", "abs": "https://arxiv.org/abs/2506.05878", "authors": ["Andreas Bergmeister", "Manish Krishan Lal", "Stefanie Jegelka", "Suvrit Sra"], "title": "A projection-based framework for gradient-free and parallel learning", "categories": ["cs.LG"], "comment": null, "summary": "We present a feasibility-seeking approach to neural network training. This\nmathematical optimization framework is distinct from conventional\ngradient-based loss minimization and uses projection operators and iterative\nprojection algorithms. We reformulate training as a large-scale feasibility\nproblem: finding network parameters and states that satisfy local constraints\nderived from its elementary operations. Training then involves projecting onto\nthese constraints, a local operation that can be parallelized across the\nnetwork. We introduce PJAX, a JAX-based software framework that enables this\nparadigm. PJAX composes projection operators for elementary operations,\nautomatically deriving the solution operators for the feasibility problems\n(akin to autodiff for derivatives). It inherently supports GPU/TPU\nacceleration, provides a familiar NumPy-like API, and is extensible. We train\ndiverse architectures (MLPs, CNNs, RNNs) on standard benchmarks using PJAX,\ndemonstrating its functionality and generality. Our results show that this\napproach is as a compelling alternative to gradient-based training, with clear\nadvantages in parallelism and the ability to handle non-differentiable\noperations.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53ef\u884c\u6027\u641c\u7d22\u7684\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u65b9\u6cd5\uff0c\u66ff\u4ee3\u4f20\u7edf\u7684\u68af\u5ea6\u4e0b\u964d\u635f\u5931\u6700\u5c0f\u5316\u6846\u67b6\uff0c\u5229\u7528\u6295\u5f71\u7b97\u5b50\u548c\u8fed\u4ee3\u6295\u5f71\u7b97\u6cd5\uff0c\u5c06\u8bad\u7ec3\u95ee\u9898\u8f6c\u5316\u4e3a\u5927\u89c4\u6a21\u53ef\u884c\u6027\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u68af\u5ea6\u4e0b\u964d\u65b9\u6cd5\u5728\u5904\u7406\u975e\u53ef\u5fae\u64cd\u4f5c\u548c\u5e76\u884c\u5316\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u8bad\u7ec3\u6846\u67b6\u3002", "method": "\u901a\u8fc7\u5c06\u8bad\u7ec3\u95ee\u9898\u8f6c\u5316\u4e3a\u53ef\u884c\u6027\u95ee\u9898\uff0c\u5229\u7528\u6295\u5f71\u7b97\u5b50\u548c\u8fed\u4ee3\u6295\u5f71\u7b97\u6cd5\u8fdb\u884c\u53c2\u6570\u4f18\u5316\uff0c\u5e76\u5f00\u53d1\u4e86\u57fa\u4e8eJAX\u7684\u8f6f\u4ef6\u6846\u67b6PJAX\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5e76\u884c\u5316\u548c\u5904\u7406\u975e\u53ef\u5fae\u64cd\u4f5c\u65b9\u9762\u5177\u6709\u4f18\u52bf\uff0c\u80fd\u591f\u8bad\u7ec3\u591a\u79cd\u7f51\u7edc\u67b6\u6784\uff08MLPs\u3001CNNs\u3001RNNs\uff09\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u884c\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5c24\u5176\u5728\u5e76\u884c\u5316\u548c\u975e\u53ef\u5fae\u64cd\u4f5c\u573a\u666f\u4e0b\u8868\u73b0\u7a81\u51fa\u3002"}}
{"id": "2506.05880", "pdf": "https://arxiv.org/pdf/2506.05880", "abs": "https://arxiv.org/abs/2506.05880", "authors": ["Adrien Petralia", "Philippe Charpentier", "Youssef Kadhi", "Themis Palpanas"], "title": "NILMFormer: Non-Intrusive Load Monitoring that Accounts for Non-Stationarity", "categories": ["cs.LG", "eess.SP"], "comment": "12 pages, 8 figures. This paper appeared in ACM SIGKDD 2025", "summary": "Millions of smart meters have been deployed worldwide, collecting the total\npower consumed by individual households. Based on these data, electricity\nsuppliers offer their clients energy monitoring solutions to provide feedback\non the consumption of their individual appliances. Historically, such estimates\nhave relied on statistical methods that use coarse-grained total monthly\nconsumption and static customer data, such as appliance ownership.\nNon-Intrusive Load Monitoring (NILM) is the problem of disaggregating a\nhousehold's collected total power consumption to retrieve the consumed power\nfor individual appliances. Current state-of-the-art (SotA) solutions for NILM\nare based on deep-learning (DL) and operate on subsequences of an entire\nhousehold consumption reading. However, the non-stationary nature of real-world\nsmart meter data leads to a drift in the data distribution within each\nsegmented window, which significantly affects model performance. This paper\nintroduces NILMFormer, a Transformer-based architecture that incorporates a new\nsubsequence stationarization/de-stationarization scheme to mitigate the\ndistribution drift and that uses a novel positional encoding that relies only\non the subsequence's timestamp information. Experiments with 4 real-world\ndatasets show that NILMFormer significantly outperforms the SotA approaches.\nOur solution has been deployed as the backbone algorithm for EDF's\n(Electricit\\'e De France) consumption monitoring service, delivering detailed\ninsights to millions of customers about their individual appliances' power\nconsumption. This paper appeared in KDD 2025.", "AI": {"tldr": "NILMFormer\u662f\u4e00\u79cd\u57fa\u4e8eTransformer\u7684\u67b6\u6784\uff0c\u901a\u8fc7\u5b50\u5e8f\u5217\u5e73\u7a33\u5316/\u53bb\u5e73\u7a33\u5316\u65b9\u6848\u548c\u65b0\u578b\u4f4d\u7f6e\u7f16\u7801\uff0c\u663e\u8457\u63d0\u5347\u4e86\u975e\u4fb5\u5165\u5f0f\u8d1f\u8f7d\u76d1\u6d4b\uff08NILM\uff09\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edfNILM\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u7edf\u8ba1\u6570\u636e\u548c\u9759\u6001\u5ba2\u6237\u4fe1\u606f\uff0c\u800c\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\u56e0\u6570\u636e\u5206\u5e03\u6f02\u79fb\u95ee\u9898\u5f71\u54cd\u6027\u80fd\u3002", "method": "\u63d0\u51faNILMFormer\uff0c\u7ed3\u5408\u5b50\u5e8f\u5217\u5e73\u7a33\u5316/\u53bb\u5e73\u7a33\u5316\u65b9\u6848\u548c\u57fa\u4e8e\u65f6\u95f4\u6233\u7684\u4f4d\u7f6e\u7f16\u7801\u3002", "result": "\u57284\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5df2\u90e8\u7f72\u4e3aEDF\u7684\u80fd\u8017\u76d1\u6d4b\u670d\u52a1\u6838\u5fc3\u7b97\u6cd5\u3002", "conclusion": "NILMFormer\u6709\u6548\u89e3\u51b3\u4e86\u6570\u636e\u5206\u5e03\u6f02\u79fb\u95ee\u9898\uff0c\u4e3aNILM\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.05895", "pdf": "https://arxiv.org/pdf/2506.05895", "abs": "https://arxiv.org/abs/2506.05895", "authors": ["Adrien Petralia", "Paul Boniol", "Philippe Charpentier", "Themis Palpanas"], "title": "Few Labels are all you need: A Weakly Supervised Framework for Appliance Localization in Smart-Meter Series", "categories": ["cs.LG"], "comment": "12 pages, 10 figures. This paper appeared in IEEE ICDE 2025", "summary": "Improving smart grid system management is crucial in the fight against\nclimate change, and enabling consumers to play an active role in this effort is\na significant challenge for electricity suppliers. In this regard, millions of\nsmart meters have been deployed worldwide in the last decade, recording the\nmain electricity power consumed in individual households. This data produces\nvaluable information that can help them reduce their electricity footprint;\nnevertheless, the collected signal aggregates the consumption of the different\nappliances running simultaneously in the house, making it difficult to\napprehend. Non-Intrusive Load Monitoring (NILM) refers to the challenge of\nestimating the power consumption, pattern, or on/off state activation of\nindividual appliances using the main smart meter signal. Recent methods\nproposed to tackle this task are based on a fully supervised deep-learning\napproach that requires both the aggregate signal and the ground truth of\nindividual appliance power. However, such labels are expensive to collect and\nextremely scarce in practice, as they require conducting intrusive surveys in\nhouseholds to monitor each appliance. In this paper, we introduce CamAL, a\nweakly supervised approach for appliance pattern localization that only\nrequires information on the presence of an appliance in a household to be\ntrained. CamAL merges an ensemble of deep-learning classifiers combined with an\nexplainable classification method to be able to localize appliance patterns.\nOur experimental evaluation, conducted on 4 real-world datasets, demonstrates\nthat CamAL significantly outperforms existing weakly supervised baselines and\nthat current SotA fully supervised NILM approaches require significantly more\nlabels to reach CamAL performances. The source of our experiments is available\nat: https://github.com/adrienpetralia/CamAL. This paper appeared in ICDE 2025.", "AI": {"tldr": "CamAL\u63d0\u51fa\u4e86\u4e00\u79cd\u5f31\u76d1\u7763\u65b9\u6cd5\uff0c\u7528\u4e8e\u5bb6\u7535\u6a21\u5f0f\u5b9a\u4f4d\uff0c\u4ec5\u9700\u5bb6\u7535\u5b58\u5728\u4fe1\u606f\u5373\u53ef\u8bad\u7ec3\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u667a\u80fd\u7535\u8868\u6570\u636e\u96be\u4ee5\u5206\u89e3\u4e3a\u5355\u4e2a\u5bb6\u7535\u7684\u7528\u7535\u6a21\u5f0f\uff0c\u73b0\u6709\u5168\u76d1\u7763\u65b9\u6cd5\u9700\u8981\u6602\u8d35\u4e14\u7a00\u7f3a\u7684\u6807\u7b7e\u6570\u636e\u3002", "method": "CamAL\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u5206\u7c7b\u5668\u548c\u53ef\u89e3\u91ca\u5206\u7c7b\u65b9\u6cd5\uff0c\u4ec5\u9700\u5bb6\u7535\u5b58\u5728\u4fe1\u606f\u5373\u53ef\u5b9a\u4f4d\u7528\u7535\u6a21\u5f0f\u3002", "result": "\u57284\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0cCamAL\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5f31\u76d1\u7763\u57fa\u7ebf\uff0c\u4e14\u6027\u80fd\u63a5\u8fd1\u5168\u76d1\u7763\u65b9\u6cd5\u3002", "conclusion": "CamAL\u4e3a\u667a\u80fd\u7535\u7f51\u7ba1\u7406\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u4f4e\u6210\u672c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u51cf\u5c11\u4e86\u5bf9\u6807\u7b7e\u6570\u636e\u7684\u4f9d\u8d56\u3002"}}
{"id": "2506.05902", "pdf": "https://arxiv.org/pdf/2506.05902", "abs": "https://arxiv.org/abs/2506.05902", "authors": ["Shirui Zhou", "Jiying Yan", "Junfang Tian", "Tao Wang", "Yongfu Li", "Shiquan Zhong"], "title": "A Driving Regime-Embedded Deep Learning Framework for Modeling Intra-Driver Heterogeneity in Multi-Scale Car-Following Dynamics", "categories": ["cs.LG", "physics.soc-ph"], "comment": null, "summary": "A fundamental challenge in car-following modeling lies in accurately\nrepresenting the multi-scale complexity of driving behaviors, particularly the\nintra-driver heterogeneity where a single driver's actions fluctuate\ndynamically under varying conditions. While existing models, both conventional\nand data-driven, address behavioral heterogeneity to some extent, they often\nemphasize inter-driver heterogeneity or rely on simplified assumptions,\nlimiting their ability to capture the dynamic heterogeneity of a single driver\nunder different driving conditions. To address this gap, we propose a novel\ndata-driven car-following framework that systematically embeds discrete driving\nregimes (e.g., steady-state following, acceleration, cruising) into vehicular\nmotion predictions. Leveraging high-resolution traffic trajectory datasets, the\nproposed hybrid deep learning architecture combines Gated Recurrent Units for\ndiscrete driving regime classification with Long Short-Term Memory networks for\ncontinuous kinematic prediction, unifying discrete decision-making processes\nand continuous vehicular dynamics to comprehensively represent inter- and\nintra-driver heterogeneity. Driving regimes are identified using a bottom-up\nsegmentation algorithm and Dynamic Time Warping, ensuring robust\ncharacterization of behavioral states across diverse traffic scenarios.\nComparative analyses demonstrate that the framework significantly reduces\nprediction errors for acceleration (maximum MSE improvement reached 58.47\\%),\nspeed, and spacing metrics while reproducing critical traffic phenomena, such\nas stop-and-go wave propagation and oscillatory dynamics.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6570\u636e\u9a71\u52a8\u8ddf\u8f66\u6a21\u578b\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u79bb\u6563\u9a7e\u9a76\u72b6\u6001\u5206\u7c7b\u548c\u8fde\u7eed\u8fd0\u52a8\u9884\u6d4b\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5bf9\u9a7e\u9a76\u5458\u52a8\u6001\u5f02\u8d28\u6027\u7684\u5efa\u6a21\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u96be\u4ee5\u51c6\u786e\u6355\u6349\u5355\u4e00\u9a7e\u9a76\u5458\u5728\u4e0d\u540c\u6761\u4ef6\u4e0b\u7684\u52a8\u6001\u5f02\u8d28\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u5168\u9762\u7684\u65b9\u6cd5\u6765\u8868\u5f81\u9a7e\u9a76\u884c\u4e3a\u7684\u590d\u6742\u6027\u3002", "method": "\u91c7\u7528\u6df7\u5408\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\uff0c\u7ed3\u5408GRU\u8fdb\u884c\u79bb\u6563\u9a7e\u9a76\u72b6\u6001\u5206\u7c7b\u548cLSTM\u8fdb\u884c\u8fde\u7eed\u8fd0\u52a8\u9884\u6d4b\uff0c\u5e76\u4f7f\u7528DTW\u548c\u5206\u6bb5\u7b97\u6cd5\u8bc6\u522b\u9a7e\u9a76\u72b6\u6001\u3002", "result": "\u6a21\u578b\u663e\u8457\u964d\u4f4e\u4e86\u52a0\u901f\u5ea6\u3001\u901f\u5ea6\u548c\u95f4\u8ddd\u7684\u9884\u6d4b\u8bef\u5dee\uff08\u6700\u5927MSE\u6539\u8fdb\u8fbe58.47%\uff09\uff0c\u5e76\u80fd\u91cd\u73b0\u5173\u952e\u4ea4\u901a\u73b0\u8c61\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u7edf\u4e00\u4e86\u79bb\u6563\u51b3\u7b56\u548c\u8fde\u7eed\u52a8\u6001\uff0c\u4e3a\u9a7e\u9a76\u5458\u5f02\u8d28\u6027\u5efa\u6a21\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.05912", "pdf": "https://arxiv.org/pdf/2506.05912", "abs": "https://arxiv.org/abs/2506.05912", "authors": ["Adrien Petralia", "Paul Boniol", "Philippe Charpentier", "Themis Palpanas"], "title": "DeviceScope: An Interactive App to Detect and Localize Appliance Patterns in Electricity Consumption Time Series", "categories": ["cs.LG", "eess.SP"], "comment": "4 pages, 5 figures. This paper appeared in ICDE 2025", "summary": "In recent years, electricity suppliers have installed millions of smart\nmeters worldwide to improve the management of the smart grid system. These\nmeters collect a large amount of electrical consumption data to produce\nvaluable information to help consumers reduce their electricity footprint.\nHowever, having non-expert users (e.g., consumers or sales advisors) understand\nthese data and derive usage patterns for different appliances has become a\nsignificant challenge for electricity suppliers because these data record the\naggregated behavior of all appliances. At the same time, ground-truth labels\n(which could train appliance detection and localization models) are expensive\nto collect and extremely scarce in practice. This paper introduces DeviceScope,\nan interactive tool designed to facilitate understanding smart meter data by\ndetecting and localizing individual appliance patterns within a given time\nperiod. Our system is based on CamAL (Class Activation Map-based Appliance\nLocalization), a novel weakly supervised approach for appliance localization\nthat only requires the knowledge of the existence of an appliance in a\nhousehold to be trained. This paper appeared in ICDE 2025.", "AI": {"tldr": "DeviceScope\u662f\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u5de5\u5177\uff0c\u5e2e\u52a9\u975e\u4e13\u4e1a\u7528\u6237\u7406\u89e3\u667a\u80fd\u7535\u8868\u6570\u636e\uff0c\u901a\u8fc7\u68c0\u6d4b\u548c\u5b9a\u4f4d\u5355\u4e2a\u7535\u5668\u6a21\u5f0f\u3002", "motivation": "\u667a\u80fd\u7535\u8868\u6570\u636e\u91cf\u5927\u4e14\u590d\u6742\uff0c\u975e\u4e13\u4e1a\u7528\u6237\u96be\u4ee5\u7406\u89e3\uff0c\u4e14\u7f3a\u4e4f\u6807\u6ce8\u6570\u636e\u8bad\u7ec3\u6a21\u578b\u3002", "method": "\u57fa\u4e8eCamAL\uff08\u7c7b\u6fc0\u6d3b\u6620\u5c04\u7535\u5668\u5b9a\u4f4d\uff09\u7684\u5f31\u76d1\u7763\u65b9\u6cd5\uff0c\u4ec5\u9700\u77e5\u9053\u7535\u5668\u5b58\u5728\u5373\u53ef\u8bad\u7ec3\u3002", "result": "DeviceScope\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u548c\u5b9a\u4f4d\u7535\u5668\u6a21\u5f0f\u3002", "conclusion": "DeviceScope\u4e3a\u667a\u80fd\u7535\u8868\u6570\u636e\u5206\u6790\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\uff0c\u89e3\u51b3\u4e86\u6570\u636e\u7406\u89e3\u548c\u6807\u6ce8\u7a00\u7f3a\u95ee\u9898\u3002"}}
{"id": "2506.05918", "pdf": "https://arxiv.org/pdf/2506.05918", "abs": "https://arxiv.org/abs/2506.05918", "authors": ["Wenxuan Huo", "Qiang He", "Gang Zhu", "Weifeng Huang"], "title": "Over-PINNs: Enhancing Physics-Informed Neural Networks via Higher-Order Partial Derivative Overdetermination of PDEs", "categories": ["cs.LG"], "comment": null, "summary": "Partial differential equations (PDEs) serve as the cornerstone of\nmathematical physics. In recent years, Physics-Informed Neural Networks (PINNs)\nhave significantly reduced the dependence on large datasets by embedding\nphysical laws directly into the training of neural networks. However, when\ndealing with complex problems, the accuracy of PINNs still has room for\nimprovement. To address this issue, we introduce the Over-PINNs framework,\nwhich leverages automatic differentiation (AD) to generate higher-order\nauxiliary equations that impose additional physical constraints. These\nequations are incorporated as extra loss terms in the training process,\neffectively enhancing the model's ability to capture physical information\nthrough an \"overdetermined\" approach. Numerical results illustrate that this\nmethod exhibits strong versatility in solving various types of PDEs. It\nachieves a significant improvement in solution accuracy without incurring\nsubstantial additional computational costs.", "AI": {"tldr": "Over-PINNs\u6846\u67b6\u901a\u8fc7\u81ea\u52a8\u5fae\u5206\u751f\u6210\u9ad8\u9636\u8f85\u52a9\u65b9\u7a0b\uff0c\u589e\u5f3aPINNs\u5728\u590d\u6742\u95ee\u9898\u4e2d\u7684\u51c6\u786e\u6027\uff0c\u663e\u8457\u63d0\u5347\u89e3\u7cbe\u5ea6\u4e14\u8ba1\u7b97\u6210\u672c\u589e\u52a0\u4e0d\u5927\u3002", "motivation": "\u89e3\u51b3PINNs\u5728\u5904\u7406\u590d\u6742\u95ee\u9898\u65f6\u7cbe\u5ea6\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u5229\u7528\u81ea\u52a8\u5fae\u5206\u751f\u6210\u9ad8\u9636\u8f85\u52a9\u65b9\u7a0b\uff0c\u4f5c\u4e3a\u989d\u5916\u635f\u5931\u9879\u5d4c\u5165\u8bad\u7ec3\u8fc7\u7a0b\u3002", "result": "\u5728\u591a\u79cdPDE\u6c42\u89e3\u4e2d\u8868\u73b0\u51fa\u5f3a\u901a\u7528\u6027\uff0c\u663e\u8457\u63d0\u5347\u7cbe\u5ea6\u4e14\u8ba1\u7b97\u6210\u672c\u53ef\u63a7\u3002", "conclusion": "Over-PINNs\u6846\u67b6\u901a\u8fc7\u8fc7\u5b9a\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86PINNs\u7684\u7269\u7406\u4fe1\u606f\u6355\u6349\u80fd\u529b\u3002"}}
{"id": "2506.05933", "pdf": "https://arxiv.org/pdf/2506.05933", "abs": "https://arxiv.org/abs/2506.05933", "authors": ["Robbert Bosch", "Wouter van Heeswijk", "Patricia Rogetzer", "Martijn Mes"], "title": "Machine Learning Predictions for Traffic Equilibria in Road Renovation Scheduling", "categories": ["cs.LG"], "comment": "15 pages, 2 figures, submitted as conference paper to ICCL 2025", "summary": "Accurately estimating the impact of road maintenance schedules on traffic\nconditions is important because maintenance operations can substantially worsen\ncongestion if not carefully planned. Reliable estimates allow planners to avoid\nexcessive delays during periods of roadwork. Since the exact increase in\ncongestion is difficult to predict analytically, traffic simulations are\ncommonly used to assess the redistribution of the flow of traffic. However,\nwhen applied to long-term maintenance planning involving many overlapping\nprojects and scheduling alternatives, these simulations must be run thousands\nof times, resulting in a significant computational burden. This paper\ninvestigates the use of machine learning-based surrogate models to predict\nnetwork-wide congestion caused by simultaneous road renovations. We frame the\nproblem as a supervised learning task, using one-hot encodings, engineered\ntraffic features, and heuristic approximations. A range of linear,\nensemble-based, probabilistic, and neural regression models is evaluated under\nan online learning framework in which data progressively becomes available. The\nexperimental results show that the Costliest Subset Heuristic provides a\nreasonable approximation when limited training data is available, and that most\nregression models fail to outperform it, with the exception of XGBoost, which\nachieves substantially better accuracy. In overall performance, XGBoost\nsignificantly outperforms alternatives in a range of metrics, most strikingly\nMean Absolute Percentage Error (MAPE) and Pinball loss, where it achieves a\nMAPE of 11% and outperforms the next-best model by 20% and 38% respectively.\nThis modeling approach has the potential to reduce the computational burden of\nlarge-scale traffic assignment problems in maintenance planning.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u66ff\u4ee3\u6a21\u578b\uff0c\u7528\u4e8e\u9884\u6d4b\u9053\u8def\u7ef4\u62a4\u8ba1\u5212\u5bf9\u4ea4\u901a\u62e5\u5835\u7684\u5f71\u54cd\uff0c\u4ee5\u51cf\u5c11\u4f20\u7edf\u6a21\u62df\u65b9\u6cd5\u7684\u9ad8\u8ba1\u7b97\u8d1f\u62c5\u3002XGBoost\u6a21\u578b\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u9053\u8def\u7ef4\u62a4\u8ba1\u5212\u5bf9\u4ea4\u901a\u62e5\u5835\u7684\u5f71\u54cd\u96be\u4ee5\u7cbe\u786e\u9884\u6d4b\uff0c\u4f20\u7edf\u6a21\u62df\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u9700\u5bfb\u627e\u66f4\u9ad8\u6548\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u5c06\u95ee\u9898\u5efa\u6a21\u4e3a\u76d1\u7763\u5b66\u4e60\u4efb\u52a1\uff0c\u4f7f\u7528\u72ec\u70ed\u7f16\u7801\u3001\u4ea4\u901a\u7279\u5f81\u5de5\u7a0b\u548c\u542f\u53d1\u5f0f\u8fd1\u4f3c\u65b9\u6cd5\uff0c\u8bc4\u4f30\u591a\u79cd\u56de\u5f52\u6a21\u578b\u3002", "result": "XGBoost\u6a21\u578b\u5728MAPE\u548cPinball\u635f\u5931\u4e0a\u8868\u73b0\u6700\u4f18\uff0c\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\u3002", "conclusion": "\u673a\u5668\u5b66\u4e60\u66ff\u4ee3\u6a21\u578b\u53ef\u6709\u6548\u964d\u4f4e\u5927\u89c4\u6a21\u4ea4\u901a\u5206\u914d\u95ee\u9898\u7684\u8ba1\u7b97\u8d1f\u62c5\uff0cXGBoost\u662f\u9996\u9009\u65b9\u6cd5\u3002"}}
{"id": "2506.05937", "pdf": "https://arxiv.org/pdf/2506.05937", "abs": "https://arxiv.org/abs/2506.05937", "authors": ["Charmaine Barker", "Daniel Bethell", "Simos Gerasimou"], "title": "Quantifying Adversarial Uncertainty in Evidential Deep Learning using Conflict Resolution", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reliability of deep learning models is critical for deployment in high-stakes\napplications, where out-of-distribution or adversarial inputs may lead to\ndetrimental outcomes. Evidential Deep Learning, an efficient paradigm for\nuncertainty quantification, models predictions as Dirichlet distributions of a\nsingle forward pass. However, EDL is particularly vulnerable to adversarially\nperturbed inputs, making overconfident errors. Conflict-aware Evidential Deep\nLearning (C-EDL) is a lightweight post-hoc uncertainty quantification approach\nthat mitigates these issues, enhancing adversarial and OOD robustness without\nretraining. C-EDL generates diverse, task-preserving transformations per input\nand quantifies representational disagreement to calibrate uncertainty estimates\nwhen needed. C-EDL's conflict-aware prediction adjustment improves detection of\nOOD and adversarial inputs, maintaining high in-distribution accuracy and low\ncomputational overhead. Our experimental evaluation shows that C-EDL\nsignificantly outperforms state-of-the-art EDL variants and competitive\nbaselines, achieving substantial reductions in coverage for OOD data (up to\n55%) and adversarial data (up to 90%), across a range of datasets, attack\ntypes, and uncertainty metrics.", "AI": {"tldr": "Conflict-aware Evidential Deep Learning (C-EDL) \u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u540e\u5904\u7406\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u751f\u6210\u591a\u6837\u5316\u7684\u4efb\u52a1\u4fdd\u7559\u53d8\u6362\u548c\u91cf\u5316\u8868\u793a\u5206\u6b67\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5bf9\u6297\u6027\u548c\u5206\u5e03\u5916\u8f93\u5165\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\u7684\u53ef\u9760\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\uff08\u5982 Evidential Deep Learning, EDL\uff09\u5bf9\u5bf9\u6297\u6027\u548c\u5206\u5e03\u5916\u8f93\u5165\u5bb9\u6613\u4ea7\u751f\u8fc7\u5ea6\u81ea\u4fe1\u7684\u9519\u8bef\u3002", "method": "C-EDL \u901a\u8fc7\u4e3a\u6bcf\u4e2a\u8f93\u5165\u751f\u6210\u591a\u6837\u5316\u7684\u4efb\u52a1\u4fdd\u7559\u53d8\u6362\uff0c\u5e76\u91cf\u5316\u8868\u793a\u5206\u6b67\u6765\u6821\u51c6\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cC-EDL \u5728\u591a\u79cd\u6570\u636e\u96c6\u3001\u653b\u51fb\u7c7b\u578b\u548c\u4e0d\u786e\u5b9a\u6027\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5bf9\u5206\u5e03\u5916\u6570\u636e\u548c\u5bf9\u6297\u6027\u6570\u636e\u7684\u8986\u76d6\u7387\u5206\u522b\u964d\u4f4e\u4e86 55% \u548c 90%\u3002", "conclusion": "C-EDL \u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u8f7b\u91cf\u7ea7\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u6a21\u578b\u5bf9\u5bf9\u6297\u6027\u548c\u5206\u5e03\u5916\u8f93\u5165\u7684\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2506.05940", "pdf": "https://arxiv.org/pdf/2506.05940", "abs": "https://arxiv.org/abs/2506.05940", "authors": ["Andr\u00e9s Guzm\u00e1n-Cordero", "Floor Eijkelboom", "Jan-Willem van de Meent"], "title": "Exponential Family Variational Flow Matching for Tabular Data Generation", "categories": ["cs.LG"], "comment": "14 pages, 1 figure, and 9 tables; To be published in the Proceedings\n  of the Forty-Second International Conference on Machine Learning", "summary": "While denoising diffusion and flow matching have driven major advances in\ngenerative modeling, their application to tabular data remains limited, despite\nits ubiquity in real-world applications. To this end, we develop TabbyFlow, a\nvariational Flow Matching (VFM) method for tabular data generation. To apply\nVFM to data with mixed continuous and discrete features, we introduce\nExponential Family Variational Flow Matching (EF-VFM), which represents\nheterogeneous data types using a general exponential family distribution. We\nhereby obtain an efficient, data-driven objective based on moment matching,\nenabling principled learning of probability paths over mixed continuous and\ndiscrete variables. We also establish a connection between variational flow\nmatching and generalized flow matching objectives based on Bregman divergences.\nEvaluation on tabular data benchmarks demonstrates state-of-the-art performance\ncompared to baselines.", "AI": {"tldr": "TabbyFlow\u662f\u4e00\u79cd\u57fa\u4e8e\u53d8\u5206\u6d41\u5339\u914d\uff08VFM\uff09\u7684\u8868\u683c\u6570\u636e\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u6307\u6570\u65cf\u53d8\u5206\u6d41\u5339\u914d\uff08EF-VFM\uff09\u5904\u7406\u6df7\u5408\u8fde\u7eed\u548c\u79bb\u6563\u7279\u5f81\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u6570\u636e\u9a71\u52a8\u76ee\u6807\u3002", "motivation": "\u5c3d\u7ba1\u53bb\u566a\u6269\u6563\u548c\u6d41\u5339\u914d\u5728\u751f\u6210\u5efa\u6a21\u4e2d\u53d6\u5f97\u4e86\u91cd\u5927\u8fdb\u5c55\uff0c\u4f46\u5728\u8868\u683c\u6570\u636e\u4e0a\u7684\u5e94\u7528\u4ecd\u7136\u6709\u9650\uff0c\u800c\u8868\u683c\u6570\u636e\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u975e\u5e38\u666e\u904d\u3002", "method": "\u63d0\u51fa\u4e86TabbyFlow\u65b9\u6cd5\uff0c\u5229\u7528\u6307\u6570\u65cf\u5206\u5e03\u8868\u793a\u5f02\u6784\u6570\u636e\u7c7b\u578b\uff0c\u5e76\u901a\u8fc7\u77e9\u5339\u914d\u5b9e\u73b0\u6982\u7387\u8def\u5f84\u7684\u5b66\u4e60\u3002", "result": "\u5728\u8868\u683c\u6570\u636e\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u4f18\u4e8e\u57fa\u7ebf\u7684\u6027\u80fd\u3002", "conclusion": "TabbyFlow\u901a\u8fc7EF-VFM\u65b9\u6cd5\uff0c\u4e3a\u6df7\u5408\u8fde\u7eed\u548c\u79bb\u6563\u7279\u5f81\u7684\u8868\u683c\u6570\u636e\u751f\u6210\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u5148\u8fdb\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.05941", "pdf": "https://arxiv.org/pdf/2506.05941", "abs": "https://arxiv.org/abs/2506.05941", "authors": ["Luka Hobor", "Mario Brcic", "Lidija Polutnik", "Ante Kapetanovic"], "title": "Comparative Analysis of Modern Machine Learning Models for Retail Sales Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": "20 total pages, 10 pages article, 10 pages appendix, 3 figures, 24\n  tables", "summary": "Accurate forecasting is key for all business planning. When estimated sales\nare too high, brick-and-mortar retailers may incur higher costs due to unsold\ninventories, higher labor and storage space costs, etc. On the other hand, when\nforecasts underestimate the level of sales, firms experience lost sales,\nshortages, and impact on the reputation of the retailer in their relevant\nmarket. Accurate forecasting presents a competitive advantage for companies. It\nfacilitates the achievement of revenue and profit goals and execution of\npricing strategy and tactics. In this study, we provide an exhaustive\nassessment of the forecasting models applied to a high-resolution\nbrick-and-mortar retail dataset. Our forecasting framework addresses the\nproblems found in retail environments, including intermittent demand, missing\nvalues, and frequent product turnover. We compare tree-based ensembles (such as\nXGBoost and LightGBM) and state-of-the-art neural network architectures\n(including N-BEATS, NHITS, and the Temporal Fusion Transformer) across various\nexperimental settings. Our results show that localized modeling strategies\nespecially those using tree-based models on individual groups with non-imputed\ndata, consistently deliver superior forecasting accuracy and computational\nefficiency. In contrast, neural models benefit from advanced imputation\nmethods, yet still fall short in handling the irregularities typical of\nphysical retail data. These results further practical understanding for model\nselection in retail environment and highlight the significance of data\npreprocessing to improve forecast performance.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u96f6\u552e\u4e1a\u4e2d\u51c6\u786e\u9884\u6d4b\u7684\u91cd\u8981\u6027\uff0c\u6bd4\u8f83\u4e86\u6811\u96c6\u6210\u6a21\u578b\u548c\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u5728\u96f6\u552e\u6570\u636e\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6811\u6a21\u578b\u5728\u5c40\u90e8\u5efa\u6a21\u7b56\u7565\u4e2d\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u51c6\u786e\u7684\u9500\u552e\u9884\u6d4b\u5bf9\u96f6\u552e\u4e1a\u81f3\u5173\u91cd\u8981\uff0c\u8fc7\u9ad8\u6216\u8fc7\u4f4e\u7684\u9884\u6d4b\u90fd\u4f1a\u5e26\u6765\u6210\u672c\u6216\u58f0\u8a89\u635f\u5931\u3002\u7814\u7a76\u65e8\u5728\u8bc4\u4f30\u4e0d\u540c\u9884\u6d4b\u6a21\u578b\u5728\u96f6\u552e\u73af\u5883\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u7814\u7a76\u6bd4\u8f83\u4e86\u6811\u96c6\u6210\u6a21\u578b\uff08\u5982XGBoost\u548cLightGBM\uff09\u548c\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff08\u5982N-BEATS\u3001NHITS\u548cTemporal Fusion Transformer\uff09\u5728\u9ad8\u5206\u8fa8\u7387\u96f6\u552e\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u8003\u8651\u4e86\u6570\u636e\u9884\u5904\u7406\u7684\u5f71\u54cd\u3002", "result": "\u6811\u96c6\u6210\u6a21\u578b\u5728\u5c40\u90e8\u5efa\u6a21\u7b56\u7565\u4e2d\u8868\u73b0\u66f4\u4f18\uff0c\u5c24\u5176\u662f\u5728\u975e\u63d2\u8865\u6570\u636e\u4e0a\u3002\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u867d\u53d7\u76ca\u4e8e\u9ad8\u7ea7\u63d2\u8865\u65b9\u6cd5\uff0c\u4f46\u4ecd\u96be\u4ee5\u5904\u7406\u96f6\u552e\u6570\u636e\u7684\u590d\u6742\u6027\u3002", "conclusion": "\u7814\u7a76\u4e3a\u96f6\u552e\u73af\u5883\u4e2d\u7684\u6a21\u578b\u9009\u62e9\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\uff0c\u5e76\u5f3a\u8c03\u4e86\u6570\u636e\u9884\u5904\u7406\u5bf9\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2506.05942", "pdf": "https://arxiv.org/pdf/2506.05942", "abs": "https://arxiv.org/abs/2506.05942", "authors": ["Samuele Salti", "Andrea Pinto", "Alessandro Lanza", "Serena Morigi"], "title": "Additive decomposition of one-dimensional signals using Transformers", "categories": ["cs.LG"], "comment": "Under consideration at Pattern Recognition Letters", "summary": "One-dimensional signal decomposition is a well-established and widely used\ntechnique across various scientific fields. It serves as a highly valuable\npre-processing step for data analysis. While traditional decomposition\ntechniques often rely on mathematical models, recent research suggests that\napplying the latest deep learning models to this problem presents an exciting,\nunexplored area with promising potential. This work presents a novel method for\nthe additive decomposition of one-dimensional signals. We leverage the\nTransformer architecture to decompose signals into their constituent\ncomponents: piece-wise constant, smooth (low-frequency oscillatory), textured\n(high-frequency oscillatory), and a noise component. Our model, trained on\nsynthetic data, achieves excellent accuracy in modeling and decomposing input\nsignals from the same distribution, as demonstrated by the experimental\nresults.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eTransformer\u67b6\u6784\u7684\u4e00\u7ef4\u4fe1\u53f7\u5206\u89e3\u65b0\u65b9\u6cd5\uff0c\u5c06\u4fe1\u53f7\u5206\u89e3\u4e3a\u5206\u6bb5\u5e38\u6570\u3001\u5e73\u6ed1\u3001\u7eb9\u7406\u548c\u566a\u58f0\u6210\u5206\uff0c\u5e76\u5728\u5408\u6210\u6570\u636e\u4e0a\u53d6\u5f97\u4e86\u9ad8\u7cbe\u5ea6\u3002", "motivation": "\u4f20\u7edf\u4fe1\u53f7\u5206\u89e3\u65b9\u6cd5\u4f9d\u8d56\u6570\u5b66\u6a21\u578b\uff0c\u800c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u6b64\u9886\u57df\u7684\u5e94\u7528\u5c1a\u672a\u5145\u5206\u63a2\u7d22\uff0c\u5177\u6709\u6f5c\u5728\u4f18\u52bf\u3002", "method": "\u5229\u7528Transformer\u67b6\u6784\u5bf9\u4e00\u7ef4\u4fe1\u53f7\u8fdb\u884c\u52a0\u6cd5\u5206\u89e3\uff0c\u5206\u89e3\u4e3a\u5206\u6bb5\u5e38\u6570\u3001\u5e73\u6ed1\u3001\u7eb9\u7406\u548c\u566a\u58f0\u6210\u5206\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u4e0a\u8bad\u7ec3\u540e\uff0c\u6a21\u578b\u5bf9\u540c\u5206\u5e03\u8f93\u5165\u4fe1\u53f7\u7684\u5efa\u6a21\u548c\u5206\u89e3\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5c55\u793a\u4e86\u6df1\u5ea6\u5b66\u4e60\u5728\u4fe1\u53f7\u5206\u89e3\u4e2d\u7684\u6f5c\u529b\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2506.05953", "pdf": "https://arxiv.org/pdf/2506.05953", "abs": "https://arxiv.org/abs/2506.05953", "authors": ["Alessandro Montenegro", "Leonardo Cesani", "Marco Mussi", "Matteo Papini", "Alberto Maria Metelli"], "title": "Learning Deterministic Policies with Policy Gradients in Constrained Markov Decision Processes", "categories": ["cs.LG"], "comment": "arXiv admin note: substantial text overlap with arXiv:2407.10775", "summary": "Constrained Reinforcement Learning (CRL) addresses sequential decision-making\nproblems where agents are required to achieve goals by maximizing the expected\nreturn while meeting domain-specific constraints. In this setting, policy-based\nmethods are widely used thanks to their advantages when dealing with\ncontinuous-control problems. These methods search in the policy space with an\naction-based or a parameter-based exploration strategy, depending on whether\nthey learn the parameters of a stochastic policy or those of a stochastic\nhyperpolicy. We introduce an exploration-agnostic algorithm, called C-PG, which\nenjoys global last-iterate convergence guarantees under gradient domination\nassumptions. Furthermore, under specific noise models where the (hyper)policy\nis expressed as a stochastic perturbation of the actions or of the parameters\nof an underlying deterministic policy, we additionally establish global\nlast-iterate convergence guarantees of C-PG to the optimal deterministic\npolicy. This holds when learning a stochastic (hyper)policy and subsequently\nswitching off the stochasticity at the end of training, thereby deploying a\ndeterministic policy. Finally, we empirically validate both the action-based\n(C-PGAE) and parameter-based (C-PGPE) variants of C-PG on constrained control\ntasks, and compare them against state-of-the-art baselines, demonstrating their\neffectiveness, in particular when deploying deterministic policies after\ntraining.", "AI": {"tldr": "C-PG\u662f\u4e00\u79cd\u63a2\u7d22\u65e0\u5173\u7684\u7b97\u6cd5\uff0c\u5728\u68af\u5ea6\u652f\u914d\u5047\u8bbe\u4e0b\u5177\u6709\u5168\u5c40\u6700\u540e\u8fed\u4ee3\u6536\u655b\u4fdd\u8bc1\uff0c\u9002\u7528\u4e8e\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\uff08CRL\uff09\u3002", "motivation": "\u89e3\u51b3\u5728\u6ee1\u8db3\u9886\u57df\u7279\u5b9a\u7ea6\u675f\u7684\u540c\u65f6\u6700\u5927\u5316\u9884\u671f\u56de\u62a5\u7684\u987a\u5e8f\u51b3\u7b56\u95ee\u9898\u3002", "method": "\u5f15\u5165C-PG\u7b97\u6cd5\uff0c\u652f\u6301\u57fa\u4e8e\u52a8\u4f5c\u6216\u53c2\u6570\u7684\u63a2\u7d22\u7b56\u7565\uff0c\u5e76\u5728\u7279\u5b9a\u566a\u58f0\u6a21\u578b\u4e0b\u8bc1\u660e\u5176\u5168\u5c40\u6536\u655b\u6027\u3002", "result": "C-PG\u5728\u7ea6\u675f\u63a7\u5236\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5c24\u5176\u5728\u8bad\u7ec3\u540e\u90e8\u7f72\u786e\u5b9a\u6027\u7b56\u7565\u65f6\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "conclusion": "C-PG\u7b97\u6cd5\u5728\u7406\u8bba\u548c\u5b9e\u8df5\u4e2d\u5747\u6709\u6548\uff0c\u7279\u522b\u9002\u5408\u9700\u8981\u786e\u5b9a\u6027\u7b56\u7565\u7684\u573a\u666f\u3002"}}
{"id": "2506.05957", "pdf": "https://arxiv.org/pdf/2506.05957", "abs": "https://arxiv.org/abs/2506.05957", "authors": ["Tianjun Yao", "Haoxuan Li", "Yongqiang Chen", "Tongliang Liu", "Le Song", "Eric Xing", "Zhiqiang Shen"], "title": "Pruning Spurious Subgraphs for Graph Out-of-Distribtuion Generalization", "categories": ["cs.LG", "I.2.6"], "comment": "Submission of ICML2025, with score 4/4/3/3", "summary": "Graph Neural Networks (GNNs) often encounter significant performance\ndegradation under distribution shifts between training and test data, hindering\ntheir applicability in real-world scenarios. Recent studies have proposed\nvarious methods to address the out-of-distribution generalization challenge,\nwith many methods in the graph domain focusing on directly identifying an\ninvariant subgraph that is predictive of the target label. However, we argue\nthat identifying the edges from the invariant subgraph directly is challenging\nand error-prone, especially when some spurious edges exhibit strong\ncorrelations with the targets. In this paper, we propose PrunE, the first\npruning-based graph OOD method that eliminates spurious edges to improve OOD\ngeneralizability. By pruning spurious edges, \\mine{} retains the invariant\nsubgraph more comprehensively, which is critical for OOD generalization.\nSpecifically, PrunE employs two regularization terms to prune spurious edges:\n1) graph size constraint to exclude uninformative spurious edges, and 2)\n$\\epsilon$-probability alignment to further suppress the occurrence of spurious\nedges. Through theoretical analysis and extensive experiments, we show that\nPrunE achieves superior OOD performance and outperforms previous\nstate-of-the-art methods significantly. Codes are available at:\n\\href{https://github.com/tianyao-aka/PrunE-GraphOOD}{https://github.com/tianyao-aka/PrunE-GraphOOD}.", "AI": {"tldr": "PrunE\u662f\u4e00\u79cd\u57fa\u4e8e\u526a\u679d\u7684\u56feOOD\u65b9\u6cd5\uff0c\u901a\u8fc7\u53bb\u9664\u865a\u5047\u8fb9\u6765\u63d0\u5347\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u5206\u5e03\u5916\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6570\u636e\u5206\u5e03\u504f\u79fb\u65f6\u6027\u80fd\u4e0b\u964d\u7684\u95ee\u9898\uff0c\u5c24\u5176\u662f\u865a\u5047\u8fb9\u4e0e\u76ee\u6807\u6807\u7b7e\u5f3a\u76f8\u5173\u7684\u60c5\u51b5\u3002", "method": "\u63d0\u51faPrunE\u65b9\u6cd5\uff0c\u4f7f\u7528\u4e24\u79cd\u6b63\u5219\u5316\u9879\u526a\u679d\u865a\u5047\u8fb9\uff1a\u56fe\u5927\u5c0f\u7ea6\u675f\u548c\u03b5-\u6982\u7387\u5bf9\u9f50\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u8868\u660e\uff0cPrunE\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u5206\u5e03\u5916\u6cdb\u5316\u6027\u80fd\u3002", "conclusion": "PrunE\u901a\u8fc7\u526a\u679d\u865a\u5047\u8fb9\uff0c\u66f4\u5168\u9762\u5730\u4fdd\u7559\u4e86\u4e0d\u53d8\u5b50\u56fe\uff0c\u4e3a\u56feOOD\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.05960", "pdf": "https://arxiv.org/pdf/2506.05960", "abs": "https://arxiv.org/abs/2506.05960", "authors": ["Adil Hasan", "Thomas Peyrin"], "title": "AQUATIC-Diff: Additive Quantization for Truly Tiny Compressed Diffusion Models", "categories": ["cs.LG"], "comment": null, "summary": "Significant investments have been made towards the commodification of\ndiffusion models for generation of diverse media. Their mass-market adoption is\nhowever still hobbled by the intense hardware resource requirements of\ndiffusion model inference. Model quantization strategies tailored specifically\ntowards diffusion models have been useful in easing this burden, yet have\ngenerally explored the Uniform Scalar Quantization (USQ) family of quantization\nmethods. In contrast, Vector Quantization (VQ) methods, which operate on groups\nof multiple related weights as the basic unit of compression, have seen\nsubstantial success in Large Language Model (LLM) quantization. In this work,\nwe apply codebook-based additive vector quantization to the problem of\ndiffusion model compression. Our resulting approach achieves a new Pareto\nfrontier for the extremely low-bit weight quantization on the standard\nclass-conditional benchmark of LDM-4 on ImageNet at 20 inference time steps.\nNotably, we report sFID 1.92 points lower than the full-precision model at W4A8\nand the best-reported results for FID, sFID and ISC at W2A8. We are also able\nto demonstrate FLOPs savings on arbitrary hardware via an efficient inference\nkernel, as opposed to savings resulting from small integer operations which may\nlack broad hardware support.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5411\u91cf\u91cf\u5316\u7684\u6269\u6563\u6a21\u578b\u538b\u7f29\u65b9\u6cd5\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u786c\u4ef6\u8d44\u6e90\u9700\u6c42\uff0c\u5e76\u5728\u4f4e\u6bd4\u7279\u91cf\u5316\u4e0b\u53d6\u5f97\u4e86\u4f18\u4e8e\u5168\u7cbe\u5ea6\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u7684\u5927\u89c4\u6a21\u5e94\u7528\u53d7\u9650\u4e8e\u9ad8\u786c\u4ef6\u8d44\u6e90\u9700\u6c42\uff0c\u73b0\u6709\u91cf\u5316\u65b9\u6cd5\u4e3b\u8981\u91c7\u7528\u5747\u5300\u6807\u91cf\u91cf\u5316\uff0c\u800c\u5411\u91cf\u91cf\u5316\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u7801\u672c\u7684\u52a0\u6cd5\u5411\u91cf\u91cf\u5316\u65b9\u6cd5\uff0c\u5bf9\u6269\u6563\u6a21\u578b\u8fdb\u884c\u538b\u7f29\uff0c\u5e76\u8bbe\u8ba1\u9ad8\u6548\u63a8\u7406\u5185\u6838\u4ee5\u5b9e\u73b0\u786c\u4ef6\u65e0\u5173\u7684FLOPs\u8282\u7701\u3002", "result": "\u5728LDM-4\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cW4A8\u91cf\u5316\u4e0bsFID\u6bd4\u5168\u7cbe\u5ea6\u6a21\u578b\u4f4e1.92\u5206\uff0cW2A8\u91cf\u5316\u4e0bFID\u3001sFID\u548cISC\u5747\u8fbe\u5230\u6700\u4f73\u7ed3\u679c\u3002", "conclusion": "\u5411\u91cf\u91cf\u5316\u65b9\u6cd5\u4e3a\u6269\u6563\u6a21\u578b\u538b\u7f29\u63d0\u4f9b\u4e86\u65b0\u7684\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4f4e\u6bd4\u7279\u91cf\u5316\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2506.05968", "pdf": "https://arxiv.org/pdf/2506.05968", "abs": "https://arxiv.org/abs/2506.05968", "authors": ["Motoki Omura", "Kazuki Ota", "Takayuki Osa", "Yusuke Mukuta", "Tatsuya Harada"], "title": "Gradual Transition from Bellman Optimality Operator to Bellman Operator in Online Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "Accepted at ICML 2025. Source code:\n  https://github.com/motokiomura/annealed-q-learning", "summary": "For continuous action spaces, actor-critic methods are widely used in online\nreinforcement learning (RL). However, unlike RL algorithms for discrete\nactions, which generally model the optimal value function using the Bellman\noptimality operator, RL algorithms for continuous actions typically model\nQ-values for the current policy using the Bellman operator. These algorithms\nfor continuous actions rely exclusively on policy updates for improvement,\nwhich often results in low sample efficiency. This study examines the\neffectiveness of incorporating the Bellman optimality operator into\nactor-critic frameworks. Experiments in a simple environment show that modeling\noptimal values accelerates learning but leads to overestimation bias. To\naddress this, we propose an annealing approach that gradually transitions from\nthe Bellman optimality operator to the Bellman operator, thereby accelerating\nlearning while mitigating bias. Our method, combined with TD3 and SAC,\nsignificantly outperforms existing approaches across various locomotion and\nmanipulation tasks, demonstrating improved performance and robustness to\nhyperparameters related to optimality.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4\u7684actor-critic\u6846\u67b6\u4e2d\u7ed3\u5408Bellman\u6700\u4f18\u7b97\u5b50\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u9000\u706b\u7b56\u7565\u7f13\u89e3\u8fc7\u4f30\u8ba1\u504f\u5dee\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5b66\u4e60\u6548\u7387\u548c\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4\u7684RL\u7b97\u6cd5\u4f9d\u8d56\u7b56\u7565\u66f4\u65b0\uff0c\u6837\u672c\u6548\u7387\u4f4e\uff0c\u800c\u7ed3\u5408Bellman\u6700\u4f18\u7b97\u5b50\u53ef\u80fd\u52a0\u901f\u5b66\u4e60\u4f46\u4f1a\u5f15\u5165\u8fc7\u4f30\u8ba1\u504f\u5dee\u3002", "method": "\u63d0\u51fa\u9000\u706b\u65b9\u6cd5\uff0c\u9010\u6b65\u4eceBellman\u6700\u4f18\u7b97\u5b50\u8fc7\u6e21\u5230Bellman\u7b97\u5b50\uff0c\u7ed3\u5408TD3\u548cSAC\u7b97\u6cd5\u3002", "result": "\u5728\u591a\u79cd\u8fd0\u52a8\u548c\u64cd\u4f5c\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u6027\u80fd\u548c\u8d85\u53c2\u6570\u9c81\u68d2\u6027\u3002", "conclusion": "\u7ed3\u5408Bellman\u6700\u4f18\u7b97\u5b50\u5e76\u901a\u8fc7\u9000\u706b\u7b56\u7565\u7f13\u89e3\u504f\u5dee\uff0c\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u9c81\u68d2\u7684\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4RL\u65b9\u6cd5\u3002"}}
{"id": "2506.05971", "pdf": "https://arxiv.org/pdf/2506.05971", "abs": "https://arxiv.org/abs/2506.05971", "authors": ["Jacob Bamberger", "Benjamin Gutteridge", "Scott le Roux", "Michael M. Bronstein", "Xiaowen Dong"], "title": "On Measuring Long-Range Interactions in Graph Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": "ICML 2025", "summary": "Long-range graph tasks -- those dependent on interactions between distant\nnodes -- are an open problem in graph neural network research. Real-world\nbenchmark tasks, especially the Long Range Graph Benchmark, have become popular\nfor validating the long-range capability of proposed architectures. However,\nthis is an empirical approach that lacks both robustness and theoretical\nunderpinning; a more principled characterization of the long-range problem is\nrequired. To bridge this gap, we formalize long-range interactions in graph\ntasks, introduce a range measure for operators on graphs, and validate it with\nsynthetic experiments. We then leverage our measure to examine commonly used\ntasks and architectures, and discuss to what extent they are, in fact,\nlong-range. We believe our work advances efforts to define and address the\nlong-range problem on graphs, and that our range measure will aid evaluation of\nnew datasets and architectures.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8861\u91cf\u56fe\u4efb\u52a1\u4e2d\u957f\u8ddd\u79bb\u4ea4\u4e92\u7684\u65b9\u6cd5\uff0c\u586b\u8865\u4e86\u73b0\u6709\u7ecf\u9a8c\u65b9\u6cd5\u7684\u4e0d\u8db3\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u56fe\u795e\u7ecf\u7f51\u7edc\u7814\u7a76\u4e2d\uff0c\u957f\u8ddd\u79bb\u56fe\u4efb\u52a1\u7f3a\u4e4f\u7406\u8bba\u652f\u6491\u548c\u9c81\u68d2\u6027\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u539f\u5219\u6027\u7684\u65b9\u6cd5\u6765\u5b9a\u4e49\u548c\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u4f5c\u8005\u5f62\u5f0f\u5316\u4e86\u56fe\u4efb\u52a1\u4e2d\u7684\u957f\u8ddd\u79bb\u4ea4\u4e92\uff0c\u5f15\u5165\u4e86\u4e00\u79cd\u56fe\u64cd\u4f5c\u7b26\u7684\u8303\u56f4\u5ea6\u91cf\uff0c\u5e76\u901a\u8fc7\u5408\u6210\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "result": "\u901a\u8fc7\u8be5\u5ea6\u91cf\u65b9\u6cd5\uff0c\u4f5c\u8005\u8bc4\u4f30\u4e86\u5e38\u7528\u4efb\u52a1\u548c\u67b6\u6784\u7684\u957f\u8ddd\u79bb\u7279\u6027\uff0c\u5e76\u8ba8\u8bba\u4e86\u5176\u5b9e\u9645\u8868\u73b0\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5b9a\u4e49\u548c\u89e3\u51b3\u56fe\u4e0a\u7684\u957f\u8ddd\u79bb\u95ee\u9898\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\uff0c\u5176\u8303\u56f4\u5ea6\u91cf\u65b9\u6cd5\u6709\u52a9\u4e8e\u8bc4\u4f30\u65b0\u6570\u636e\u96c6\u548c\u67b6\u6784\u3002"}}
{"id": "2506.05977", "pdf": "https://arxiv.org/pdf/2506.05977", "abs": "https://arxiv.org/abs/2506.05977", "authors": ["Yujia Huo", "Jianchun Liu", "Hongli Xu", "Zhenguo Ma", "Shilong Wang", "Liusheng Huang"], "title": "Mitigating Catastrophic Forgetting with Adaptive Transformer Block Expansion in Federated Fine-Tuning", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "Federated fine-tuning (FedFT) of large language models (LLMs) has emerged as\na promising solution for adapting models to distributed data environments while\nensuring data privacy.\n  Existing FedFT methods predominantly utilize parameter-efficient fine-tuning\n(PEFT) techniques to reduce communication and computation overhead.\n  However, they often fail to adequately address the catastrophic forgetting, a\ncritical challenge arising from continual adaptation in distributed\nenvironments. The traditional centralized fine-tuning methods, which are not\ndesigned for the heterogeneous and privacy-constrained nature of federated\nenvironments, struggle to mitigate this issue effectively. Moreover, the\nchallenge is further exacerbated by significant variation in data distributions\nand device capabilities across clients, which leads to intensified forgetting\nand degraded model generalization. To tackle these issues, we propose FedBE, a\nnovel FedFT framework that integrates an adaptive transformer block expansion\nmechanism with a dynamic trainable-block allocation strategy. Specifically,\nFedBE expands trainable blocks within the model architecture, structurally\nseparating newly learned task-specific knowledge from the original pre-trained\nrepresentations. Additionally, FedBE dynamically assigns these trainable blocks\nto clients based on their data distributions and computational capabilities.\nThis enables the framework to better accommodate heterogeneous federated\nenvironments and enhances the generalization ability of the model.Extensive\nexperiments show that compared with existing federated fine-tuning methods,\nFedBE achieves 12-74% higher accuracy retention on general tasks after\nfine-tuning and a model convergence acceleration ratio of 1.9-3.1x without\ndegrading the accuracy of downstream tasks.", "AI": {"tldr": "FedBE\u662f\u4e00\u79cd\u65b0\u7684\u8054\u90a6\u5fae\u8c03\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u6269\u5c55\u548c\u52a8\u6001\u5206\u914d\u7b56\u7565\u89e3\u51b3\u5206\u5e03\u5f0f\u73af\u5883\u4e2d\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u8054\u90a6\u5fae\u8c03\u65b9\u6cd5\u5728\u5206\u5e03\u5f0f\u73af\u5883\u4e2d\u96be\u4ee5\u6709\u6548\u5e94\u5bf9\u707e\u96be\u6027\u9057\u5fd8\uff0c\u4e14\u6570\u636e\u5206\u5e03\u548c\u8bbe\u5907\u80fd\u529b\u5dee\u5f02\u52a0\u5267\u4e86\u8fd9\u4e00\u95ee\u9898\u3002", "method": "FedBE\u7ed3\u5408\u81ea\u9002\u5e94Transformer\u5757\u6269\u5c55\u673a\u5236\u548c\u52a8\u6001\u53ef\u8bad\u7ec3\u5757\u5206\u914d\u7b56\u7565\uff0c\u5206\u79bb\u65b0\u5b66\u77e5\u8bc6\u4e0e\u9884\u8bad\u7ec3\u8868\u793a\uff0c\u5e76\u6839\u636e\u5ba2\u6237\u7aef\u6570\u636e\u5206\u5e03\u548c\u80fd\u529b\u52a8\u6001\u5206\u914d\u5757\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cFedBE\u5728\u901a\u7528\u4efb\u52a1\u4e0a\u51c6\u786e\u7387\u4fdd\u7559\u63d0\u9ad812-74%\uff0c\u6536\u655b\u901f\u5ea6\u52a0\u5feb1.9-3.1\u500d\uff0c\u4e14\u4e0d\u5f71\u54cd\u4e0b\u6e38\u4efb\u52a1\u51c6\u786e\u6027\u3002", "conclusion": "FedBE\u6709\u6548\u89e3\u51b3\u4e86\u8054\u90a6\u5fae\u8c03\u4e2d\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u5728\u5f02\u6784\u73af\u5883\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2506.05980", "pdf": "https://arxiv.org/pdf/2506.05980", "abs": "https://arxiv.org/abs/2506.05980", "authors": ["Geonwoo Cho", "Jaemoon Lee", "Jaegyun Im", "Subi Lee", "Jihwan Lee", "Sundong Kim"], "title": "AMPED: Adaptive Multi-objective Projection for balancing Exploration and skill Diversification", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Skill-based reinforcement learning (SBRL) enables rapid adaptation in\nenvironments with sparse rewards by pretraining a skill-conditioned policy.\nEffective skill learning requires jointly maximizing both exploration and skill\ndiversity. However, existing methods often face challenges in simultaneously\noptimizing for these two conflicting objectives. In this work, we propose a new\nmethod, Adaptive Multi-objective Projection for balancing Exploration and skill\nDiversification (AMPED), which explicitly addresses both exploration and skill\ndiversification. We begin by conducting extensive ablation studies to identify\nand define a set of objectives that effectively capture the aspects of\nexploration and skill diversity, respectively. During the skill pretraining\nphase, AMPED introduces a gradient surgery technique to balance the objectives\nof exploration and skill diversity, mitigating conflicts and reducing reliance\non heuristic tuning. In the subsequent fine-tuning phase, AMPED incorporates a\nskill selector module that dynamically selects suitable skills for downstream\ntasks, based on task-specific performance signals. Our approach achieves\nperformance that surpasses SBRL baselines across various benchmarks. These\nresults highlight the importance of explicitly harmonizing exploration and\ndiversity and demonstrate the effectiveness of AMPED in enabling robust and\ngeneralizable skill learning. Project Page: https://geonwoo.me/amped/", "AI": {"tldr": "AMPED\u662f\u4e00\u79cd\u65b0\u7684\u6280\u80fd\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u68af\u5ea6\u624b\u672f\u6280\u672f\u5e73\u8861\u63a2\u7d22\u4e0e\u6280\u80fd\u591a\u6837\u6027\uff0c\u5e76\u5728\u5fae\u8c03\u9636\u6bb5\u52a8\u6001\u9009\u62e9\u6280\u80fd\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u4f18\u5316\u63a2\u7d22\u4e0e\u6280\u80fd\u591a\u6837\u6027\u8fd9\u4e24\u4e2a\u51b2\u7a81\u76ee\u6807\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "AMPED\u901a\u8fc7\u68af\u5ea6\u624b\u672f\u6280\u672f\u5e73\u8861\u63a2\u7d22\u4e0e\u6280\u80fd\u591a\u6837\u6027\u76ee\u6807\uff0c\u5e76\u5728\u5fae\u8c03\u9636\u6bb5\u5f15\u5165\u52a8\u6001\u6280\u80fd\u9009\u62e9\u6a21\u5757\u3002", "result": "AMPED\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u6280\u80fd\u5f3a\u5316\u5b66\u4e60\u57fa\u7ebf\u3002", "conclusion": "AMPED\u901a\u8fc7\u663e\u5f0f\u534f\u8c03\u63a2\u7d22\u4e0e\u591a\u6837\u6027\uff0c\u5b9e\u73b0\u4e86\u9c81\u68d2\u4e14\u53ef\u6cdb\u5316\u7684\u6280\u80fd\u5b66\u4e60\u3002"}}
{"id": "2506.05985", "pdf": "https://arxiv.org/pdf/2506.05985", "abs": "https://arxiv.org/abs/2506.05985", "authors": ["Yuheng Lei", "Sitong Mao", "Shunbo Zhou", "Hongyuan Zhang", "Xuelong Li", "Ping Luo"], "title": "Dynamic Mixture of Progressive Parameter-Efficient Expert Library for Lifelong Robot Learning", "categories": ["cs.LG", "cs.RO"], "comment": null, "summary": "A generalist agent must continuously learn and adapt throughout its lifetime,\nachieving efficient forward transfer while minimizing catastrophic forgetting.\nPrevious work within the dominant pretrain-then-finetune paradigm has explored\nparameter-efficient fine-tuning for single-task adaptation, effectively\nsteering a frozen pretrained model with a small number of parameters. However,\nin the context of lifelong learning, these methods rely on the impractical\nassumption of a test-time task identifier and restrict knowledge sharing among\nisolated adapters. To address these limitations, we propose Dynamic Mixture of\nProgressive Parameter-Efficient Expert Library (DMPEL) for lifelong robot\nlearning. DMPEL progressively learn a low-rank expert library and employs a\nlightweight router to dynamically combine experts into an end-to-end policy,\nfacilitating flexible behavior during lifelong adaptation. Moreover, by\nleveraging the modular structure of the fine-tuned parameters, we introduce\ncoefficient replay to guide the router in accurately retrieving frozen experts\nfor previously encountered tasks, thereby mitigating catastrophic forgetting.\nThis method is significantly more storage- and computationally-efficient than\napplying demonstration replay to the entire policy. Extensive experiments on\nthe lifelong manipulation benchmark LIBERO demonstrate that our framework\noutperforms state-of-the-art lifelong learning methods in success rates across\ncontinual adaptation, while utilizing minimal trainable parameters and storage.", "AI": {"tldr": "\u63d0\u51faDMPEL\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u7ec4\u5408\u4f4e\u79e9\u4e13\u5bb6\u5e93\u548c\u8f7b\u91cf\u7ea7\u8def\u7531\u5668\uff0c\u5b9e\u73b0\u7ec8\u8eab\u673a\u5668\u4eba\u5b66\u4e60\u4e2d\u7684\u9ad8\u6548\u77e5\u8bc6\u8fc1\u79fb\u548c\u9057\u5fd8\u7f13\u89e3\u3002", "motivation": "\u89e3\u51b3\u7ec8\u8eab\u5b66\u4e60\u4e2d\u6d4b\u8bd5\u65f6\u4efb\u52a1\u6807\u8bc6\u4e0d\u5207\u5b9e\u9645\u548c\u77e5\u8bc6\u5171\u4eab\u53d7\u9650\u7684\u95ee\u9898\u3002", "method": "\u52a8\u6001\u6df7\u5408\u6e10\u8fdb\u53c2\u6570\u9ad8\u6548\u4e13\u5bb6\u5e93\uff08DMPEL\uff09\uff0c\u7ed3\u5408\u7cfb\u6570\u91cd\u653e\u6280\u672f\u3002", "result": "\u5728LIBERO\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u6210\u529f\u7387\u9ad8\u4e14\u8d44\u6e90\u5360\u7528\u4f4e\u3002", "conclusion": "DMPEL\u5728\u7ec8\u8eab\u5b66\u4e60\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u6548\u9002\u5e94\u548c\u9057\u5fd8\u7f13\u89e3\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.05994", "pdf": "https://arxiv.org/pdf/2506.05994", "abs": "https://arxiv.org/abs/2506.05994", "authors": ["Yi-Chun Liao", "Chieh-Lin Tsai", "Yuan-Hao Chang", "Cam\u00e9lia Slimani", "Jalil Boukhobza", "Tei-Wei Kuo"], "title": "RETENTION: Resource-Efficient Tree-Based Ensemble Model Acceleration with Content-Addressable Memory", "categories": ["cs.LG", "cs.AR", "cs.ET"], "comment": null, "summary": "Although deep learning has demonstrated remarkable capabilities in learning\nfrom unstructured data, modern tree-based ensemble models remain superior in\nextracting relevant information and learning from structured datasets. While\nseveral efforts have been made to accelerate tree-based models, the inherent\ncharacteristics of the models pose significant challenges for conventional\naccelerators. Recent research leveraging content-addressable memory (CAM)\noffers a promising solution for accelerating tree-based models, yet existing\ndesigns suffer from excessive memory consumption and low utilization. This work\naddresses these challenges by introducing RETENTION, an end-to-end framework\nthat significantly reduces CAM capacity requirement for tree-based model\ninference. We propose an iterative pruning algorithm with a novel pruning\ncriterion tailored for bagging-based models (e.g., Random Forest), which\nminimizes model complexity while ensuring controlled accuracy degradation.\nAdditionally, we present a tree mapping scheme that incorporates two innovative\ndata placement strategies to alleviate the memory redundancy caused by the\nwidespread use of don't care states in CAM. Experimental results show that\nimplementing the tree mapping scheme alone achieves $1.46\\times$ to $21.30\n\\times$ better space efficiency, while the full RETENTION framework yields\n$4.35\\times$ to $207.12\\times$ improvement with less than 3% accuracy loss.\nThese results demonstrate that RETENTION is highly effective in reducing CAM\ncapacity requirement, providing a resource-efficient direction for tree-based\nmodel acceleration.", "AI": {"tldr": "RETENTION\u6846\u67b6\u901a\u8fc7\u8fed\u4ee3\u526a\u679d\u7b97\u6cd5\u548c\u6811\u6620\u5c04\u65b9\u6848\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u57fa\u4e8e\u6811\u7684\u6a21\u578b\u63a8\u7406\u4e2dCAM\u7684\u5bb9\u91cf\u9700\u6c42\uff0c\u540c\u65f6\u4fdd\u6301\u7cbe\u5ea6\u635f\u5931\u57283%\u4ee5\u5185\u3002", "motivation": "\u5c3d\u7ba1\u6df1\u5ea6\u5b66\u4e60\u5728\u975e\u7ed3\u6784\u5316\u6570\u636e\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u57fa\u4e8e\u6811\u7684\u96c6\u6210\u6a21\u578b\u5728\u7ed3\u6784\u5316\u6570\u636e\u4e0a\u4ecd\u5360\u4f18\u52bf\u3002\u73b0\u6709CAM\u52a0\u901f\u65b9\u6848\u5b58\u5728\u5185\u5b58\u6d88\u8017\u9ad8\u548c\u5229\u7528\u7387\u4f4e\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faRETENTION\u6846\u67b6\uff0c\u5305\u62ec\u9488\u5bf9\u888b\u88c5\u6a21\u578b\u7684\u8fed\u4ee3\u526a\u679d\u7b97\u6cd5\u548c\u4e24\u79cd\u521b\u65b0\u7684\u6570\u636e\u653e\u7f6e\u7b56\u7565\u4ee5\u51cf\u5c11CAM\u4e2d\u7684\u5197\u4f59\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u6811\u6620\u5c04\u65b9\u6848\u5355\u72ec\u5b9e\u73b0\u7a7a\u95f4\u6548\u7387\u63d0\u53471.46\u00d7\u81f321.30\u00d7\uff0c\u5b8c\u6574\u6846\u67b6\u63d0\u53474.35\u00d7\u81f3207.12\u00d7\uff0c\u7cbe\u5ea6\u635f\u5931\u5c0f\u4e8e3%\u3002", "conclusion": "RETENTION\u6709\u6548\u51cf\u5c11CAM\u5bb9\u91cf\u9700\u6c42\uff0c\u4e3a\u57fa\u4e8e\u6811\u7684\u6a21\u578b\u52a0\u901f\u63d0\u4f9b\u4e86\u8d44\u6e90\u9ad8\u6548\u7684\u65b9\u5411\u3002"}}
{"id": "2506.05999", "pdf": "https://arxiv.org/pdf/2506.05999", "abs": "https://arxiv.org/abs/2506.05999", "authors": ["Sanna Jarl", "Jens Sj\u00f6lund", "Robert J. W. Frost", "Anders Holst", "Jonathan J. S. Scragg"], "title": "Machine learning for in-situ composition mapping in a self-driving magnetron sputtering system", "categories": ["cs.LG", "cond-mat.mtrl-sci", "I.2.1; J.2.8"], "comment": "24 pages, 10 figures. Submitted to the journal npj computational\n  materials", "summary": "Self-driving labs (SDLs), employing automation and machine learning (ML) to\naccelerate experimental procedures, have enormous potential in the discovery of\nnew materials. However, in thin film science, SDLs are mainly restricted to\nsolution-based synthetic methods which are easier to automate but cannot access\nthe broad chemical space of inorganic materials. This work presents an SDL\nbased on magnetron co-sputtering. We are using combinatorial frameworks,\nobtaining accurate composition maps on multi-element, compositionally graded\nthin films. This normally requires time-consuming ex-situ analysis prone to\nsystematic errors. We present a rapid and calibration-free in-situ, ML driven\napproach to produce composition maps for arbitrary source combinations and\nsputtering conditions. We develop a method to predict the composition\ndistribution in a multi-element combinatorial thin film, using in-situ\nmeasurements from quartz-crystal microbalance sensors placed in a sputter\nchamber. For a given source, the sensor readings are learned as a function of\nthe sputtering pressure and magnetron power, through active learning using\nGaussian processes (GPs). The final GPs are combined with a geometric model of\nthe deposition flux distribution in the chamber, which allows interpolation of\nthe deposition rates from each source, at any position across the sample. We\ninvestigate several acquisition functions for the ML procedure. A fully\nBayesian GP - BALM (Bayesian active learning MacKay) - achieved the best\nperformance, learning the deposition rates for a single source in 10\nexperiments. Prediction accuracy for co-sputtering composition distributions\nwas verified experimentally. Our framework dramatically increases throughput by\navoiding the need for extensive characterisation or calibration, thus\ndemonstrating the potential of ML-guided SDLs to accelerate materials\nexploration.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u78c1\u63a7\u5171\u6e85\u5c04\u7684\u81ea\u9a71\u52a8\u5b9e\u9a8c\u5ba4\uff08SDL\uff09\u65b9\u6cd5\uff0c\u7528\u4e8e\u5feb\u901f\u751f\u6210\u591a\u5143\u7d20\u7ec4\u5408\u8584\u819c\u7684\u6210\u5206\u5206\u5e03\u56fe\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u8017\u65f6\u4e14\u6613\u51fa\u9519\u7684\u5916\u90e8\u5206\u6790\u3002", "motivation": "\u5728\u8584\u819c\u79d1\u5b66\u4e2d\uff0c\u73b0\u6709\u7684SDL\u4e3b\u8981\u5c40\u9650\u4e8e\u6eb6\u6db2\u5408\u6210\u65b9\u6cd5\uff0c\u65e0\u6cd5\u8986\u76d6\u65e0\u673a\u6750\u6599\u7684\u5e7f\u6cdb\u5316\u5b66\u7a7a\u95f4\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u78c1\u63a7\u6e85\u5c04\u6280\u672f\u6269\u5c55SDL\u7684\u5e94\u7528\u8303\u56f4\u3002", "method": "\u7ed3\u5408\u7ec4\u5408\u6846\u67b6\u548c\u673a\u5668\u5b66\u4e60\uff08ML\uff09\uff0c\u5229\u7528\u77f3\u82f1\u6676\u4f53\u5fae\u5929\u5e73\u4f20\u611f\u5668\u8fdb\u884c\u539f\u4f4d\u6d4b\u91cf\uff0c\u901a\u8fc7\u9ad8\u65af\u8fc7\u7a0b\uff08GP\uff09\u548c\u4e3b\u52a8\u5b66\u4e60\u9884\u6d4b\u8584\u819c\u6210\u5206\u5206\u5e03\u3002", "result": "\u91c7\u7528\u8d1d\u53f6\u65af\u4e3b\u52a8\u5b66\u4e60\uff08BALM\uff09\u65b9\u6cd5\uff0c\u4ec5\u970010\u6b21\u5b9e\u9a8c\u5373\u53ef\u5b66\u4e60\u5355\u6e90\u7684\u6c89\u79ef\u901f\u7387\uff0c\u9a8c\u8bc1\u4e86\u5171\u6e85\u5c04\u6210\u5206\u5206\u5e03\u7684\u9884\u6d4b\u51c6\u786e\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u6750\u6599\u63a2\u7d22\u7684\u6548\u7387\uff0c\u5c55\u793a\u4e86ML\u5f15\u5bfc\u7684SDL\u5728\u52a0\u901f\u6750\u6599\u53d1\u73b0\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.06001", "pdf": "https://arxiv.org/pdf/2506.06001", "abs": "https://arxiv.org/abs/2506.06001", "authors": ["Shilong Tao", "Zhe Feng", "Haonan Sun", "Zhanxing Zhu", "Yunhuai Liu"], "title": "LaDEEP: A Deep Learning-based Surrogate Model for Large Deformation of Elastic-Plastic Solids", "categories": ["cs.LG"], "comment": "Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery\n  and Data Mining V.2 (KDD '25)", "summary": "Scientific computing for large deformation of elastic-plastic solids is\ncritical for numerous real-world applications. Classical numerical solvers rely\nprimarily on local discrete linear approximation and are constrained by an\ninherent trade-off between accuracy and efficiency. Recently, deep learning\nmodels have achieved impressive progress in solving the continuum mechanism.\nWhile previous models have explored various architectures and constructed\ncoefficient-solution mappings, they are designed for general instances without\nconsidering specific problem properties and hard to accurately handle with\ncomplex elastic-plastic solids involving contact, loading and unloading. In\nthis work, we take stretch bending, a popular metal fabrication technique, as\nour case study and introduce LaDEEP, a deep learning-based surrogate model for\n\\textbf{La}rge \\textbf{De}formation of \\textbf{E}lastic-\\textbf{P}lastic\nSolids. We encode the partitioned regions of the involved slender solids into a\ntoken sequence to maintain their essential order property. To characterize the\nphysical process of the solid deformation, a two-stage Transformer-based module\nis designed to predict the deformation with the sequence of tokens as input.\nEmpirically, LaDEEP achieves five magnitudes faster speed than finite element\nmethods with a comparable accuracy, and gains 20.47\\% relative improvement on\naverage compared to other deep learning baselines. We have also deployed our\nmodel into a real-world industrial production system, and it has shown\nremarkable performance in both accuracy and efficiency.", "AI": {"tldr": "LaDEEP\u662f\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u66ff\u4ee3\u6a21\u578b\uff0c\u7528\u4e8e\u89e3\u51b3\u5f39\u6027-\u5851\u6027\u56fa\u4f53\u7684\u5927\u53d8\u5f62\u95ee\u9898\uff0c\u901a\u8fc7\u5206\u533a\u7f16\u7801\u548cTransformer\u6a21\u5757\u5b9e\u73b0\u9ad8\u6548\u9884\u6d4b\uff0c\u901f\u5ea6\u548c\u51c6\u786e\u6027\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u6570\u503c\u6c42\u89e3\u5668\u5728\u7cbe\u5ea6\u548c\u6548\u7387\u4e4b\u95f4\u5b58\u5728\u56fa\u6709\u6743\u8861\uff0c\u800c\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u672a\u9488\u5bf9\u7279\u5b9a\u95ee\u9898\u7279\u6027\u8bbe\u8ba1\uff0c\u96be\u4ee5\u5904\u7406\u590d\u6742\u7684\u5f39\u6027-\u5851\u6027\u56fa\u4f53\u53d8\u5f62\u3002", "method": "\u91c7\u7528\u5206\u533a\u7f16\u7801\u5c06\u56fa\u4f53\u533a\u57df\u8f6c\u6362\u4e3a\u4ee4\u724c\u5e8f\u5217\uff0c\u8bbe\u8ba1\u57fa\u4e8eTransformer\u7684\u4e24\u9636\u6bb5\u6a21\u5757\u9884\u6d4b\u53d8\u5f62\u3002", "result": "LaDEEP\u6bd4\u6709\u9650\u5143\u65b9\u6cd5\u5feb\u4e94\u4e2a\u6570\u91cf\u7ea7\uff0c\u51c6\u786e\u6027\u76f8\u5f53\uff0c\u5e76\u6bd4\u5176\u4ed6\u6df1\u5ea6\u5b66\u4e60\u57fa\u7ebf\u5e73\u5747\u63d0\u534720.47%\u3002", "conclusion": "LaDEEP\u5728\u5b9e\u9645\u5de5\u4e1a\u751f\u4ea7\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u590d\u6742\u5f39\u6027-\u5851\u6027\u56fa\u4f53\u53d8\u5f62\u95ee\u9898\u4e2d\u7684\u9ad8\u6548\u6027\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2506.06003", "pdf": "https://arxiv.org/pdf/2506.06003", "abs": "https://arxiv.org/abs/2506.06003", "authors": ["Neal Mangaokar", "Ashish Hooda", "Zhuohang Li", "Bradley A. Malin", "Kassem Fawaz", "Somesh Jha", "Atul Prakash", "Amrita Roy Chowdhury"], "title": "What Really is a Member? Discrediting Membership Inference via Poisoning", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "Membership inference tests aim to determine whether a particular data point\nwas included in a language model's training set. However, recent works have\nshown that such tests often fail under the strict definition of membership\nbased on exact matching, and have suggested relaxing this definition to include\nsemantic neighbors as members as well. In this work, we show that membership\ninference tests are still unreliable under this relaxation - it is possible to\npoison the training dataset in a way that causes the test to produce incorrect\npredictions for a target point. We theoretically reveal a trade-off between a\ntest's accuracy and its robustness to poisoning. We also present a concrete\ninstantiation of this poisoning attack and empirically validate its\neffectiveness. Our results show that it can degrade the performance of existing\ntests to well below random.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u5373\u4f7f\u653e\u5bbd\u6210\u5458\u63a8\u65ad\u6d4b\u8bd5\u7684\u5b9a\u4e49\u4ee5\u5305\u542b\u8bed\u4e49\u90bb\u5c45\uff0c\u6d4b\u8bd5\u4ecd\u4e0d\u53ef\u9760\uff0c\u4e14\u53ef\u80fd\u901a\u8fc7\u6570\u636e\u6295\u6bd2\u653b\u51fb\u5bfc\u81f4\u9519\u8bef\u9884\u6d4b\u3002", "motivation": "\u63a2\u8ba8\u6210\u5458\u63a8\u65ad\u6d4b\u8bd5\u5728\u653e\u5bbd\u5b9a\u4e49\u540e\u7684\u53ef\u9760\u6027\uff0c\u63ed\u793a\u5176\u6613\u53d7\u6570\u636e\u6295\u6bd2\u653b\u51fb\u7684\u5f31\u70b9\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u6570\u636e\u6295\u6bd2\u653b\u51fb\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u9a8c\u8bc1\u5176\u6548\u679c\u3002", "result": "\u653b\u51fb\u80fd\u663e\u8457\u964d\u4f4e\u73b0\u6709\u6d4b\u8bd5\u7684\u6027\u80fd\uff0c\u751a\u81f3\u4f4e\u4e8e\u968f\u673a\u6c34\u5e73\u3002", "conclusion": "\u6210\u5458\u63a8\u65ad\u6d4b\u8bd5\u5728\u653e\u5bbd\u5b9a\u4e49\u540e\u4ecd\u4e0d\u53ef\u9760\uff0c\u4e14\u5b58\u5728\u51c6\u786e\u6027\u4e0e\u6297\u6295\u6bd2\u80fd\u529b\u4e4b\u95f4\u7684\u6743\u8861\u3002"}}
{"id": "2506.06005", "pdf": "https://arxiv.org/pdf/2506.06005", "abs": "https://arxiv.org/abs/2506.06005", "authors": ["Yihang Wang", "Yuying Qiu", "Peng Chen", "Yang Shu", "Zhongwen Rao", "Lujia Pan", "Bin Yang", "Chenjuan Guo"], "title": "LightGTS: A Lightweight General Time Series Forecasting Model", "categories": ["cs.LG"], "comment": "Accepted by the 42th International Conference on Machine Learning\n  (ICML 2025)", "summary": "Existing works on general time series forecasting build foundation models\nwith heavy model parameters through large-scale multi-source pre-training.\nThese models achieve superior generalization ability across various datasets at\nthe cost of significant computational burdens and limitations in\nresource-constrained scenarios. This paper introduces LightGTS, a lightweight\ngeneral time series forecasting model designed from the perspective of\nconsistent periodical modeling. To handle diverse scales and intrinsic periods\nin multi-source pre-training, we introduce Periodical Tokenization, which\nextracts consistent periodic patterns across different datasets with varying\nscales. To better utilize the periodicity in the decoding process, we further\nintroduce Periodical Parallel Decoding, which leverages historical tokens to\nimprove forecasting. Based on the two techniques above which fully leverage the\ninductive bias of periods inherent in time series, LightGTS uses a lightweight\nmodel to achieve outstanding performance on general time series forecasting. It\nachieves state-of-the-art forecasting performance on 9 real-world benchmarks in\nboth zero-shot and full-shot settings with much better efficiency compared with\nexisting time series foundation models.", "AI": {"tldr": "LightGTS\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u901a\u7528\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\uff0c\u901a\u8fc7\u5468\u671f\u6027\u5efa\u6a21\u548c\u9ad8\u6548\u89e3\u7801\u6280\u672f\uff0c\u5728\u591a\u79cd\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u9ad8\u6027\u80fd\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u8d1f\u62c5\u3002", "motivation": "\u73b0\u6709\u901a\u7528\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\u53c2\u6570\u5e9e\u5927\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u9650\u5236\u4e86\u5728\u8d44\u6e90\u53d7\u9650\u573a\u666f\u7684\u5e94\u7528\u3002\u672c\u6587\u65e8\u5728\u8bbe\u8ba1\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u6a21\u578b\uff0c\u901a\u8fc7\u5468\u671f\u6027\u5efa\u6a21\u63d0\u5347\u6548\u7387\u3002", "method": "\u63d0\u51faPeriodical Tokenization\u63d0\u53d6\u8de8\u6570\u636e\u96c6\u7684\u5468\u671f\u6027\u6a21\u5f0f\uff0c\u5e76\u5f15\u5165Periodical Parallel Decoding\u5229\u7528\u5386\u53f2\u6807\u8bb0\u6539\u8fdb\u9884\u6d4b\u3002", "result": "\u57289\u4e2a\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLightGTS\u5728\u96f6\u6837\u672c\u548c\u5168\u6837\u672c\u8bbe\u7f6e\u4e0b\u5747\u8fbe\u5230\u6700\u4f18\u6027\u80fd\uff0c\u4e14\u6548\u7387\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "conclusion": "LightGTS\u901a\u8fc7\u5468\u671f\u6027\u5efa\u6a21\u548c\u8f7b\u91cf\u5316\u8bbe\u8ba1\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\uff0c\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u573a\u666f\u3002"}}
{"id": "2506.06021", "pdf": "https://arxiv.org/pdf/2506.06021", "abs": "https://arxiv.org/abs/2506.06021", "authors": ["Shilong Tao", "Zhe Feng", "Haonan Sun", "Zhanxing Zhu", "Yunhuai Liu"], "title": "Unisoma: A Unified Transformer-based Solver for Multi-Solid Systems", "categories": ["cs.LG"], "comment": "Proceedings of the 42nd International Conference on Machine Learning", "summary": "Multi-solid systems are foundational to a wide range of real-world\napplications, yet modeling their complex interactions remains challenging.\nExisting deep learning methods predominantly rely on implicit modeling, where\nthe factors influencing solid deformation are not explicitly represented but\nare instead indirectly learned. However, as the number of solids increases,\nthese methods struggle to accurately capture intricate physical interactions.\nIn this paper, we introduce a novel explicit modeling paradigm that\nincorporates factors influencing solid deformation through structured modules.\nSpecifically, we present Unisoma, a unified and flexible Transformer-based\nmodel capable of handling variable numbers of solids. Unisoma directly captures\nphysical interactions using contact modules and adaptive interaction allocation\nmechanism, and learns the deformation through a triplet relationship. Compared\nto implicit modeling techniques, explicit modeling is more well-suited for\nmulti-solid systems with diverse coupling patterns, as it enables detailed\ntreatment of each solid while preventing information blending and confusion.\nExperimentally, Unisoma achieves consistent state-of-the-art performance across\nseven well-established datasets and two complex multi-solid tasks. Code is\navaiable at \\href{this link}{https://github.com/therontau0054/Unisoma}.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u663e\u5f0f\u5efa\u6a21\u65b9\u6cd5Unisoma\uff0c\u7528\u4e8e\u5904\u7406\u591a\u56fa\u4f53\u7cfb\u7edf\u7684\u590d\u6742\u76f8\u4e92\u4f5c\u7528\uff0c\u4f18\u4e8e\u73b0\u6709\u7684\u9690\u5f0f\u5efa\u6a21\u65b9\u6cd5\u3002", "motivation": "\u591a\u56fa\u4f53\u7cfb\u7edf\u7684\u590d\u6742\u76f8\u4e92\u4f5c\u7528\u5efa\u6a21\u5177\u6709\u6311\u6218\u6027\uff0c\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u7684\u9690\u5f0f\u5efa\u6a21\u65b9\u6cd5\u96be\u4ee5\u51c6\u786e\u6355\u6349\u7269\u7406\u4ea4\u4e92\u3002", "method": "\u63d0\u51fa\u4e86Unisoma\uff0c\u4e00\u79cd\u57fa\u4e8eTransformer\u7684\u663e\u5f0f\u5efa\u6a21\u65b9\u6cd5\uff0c\u901a\u8fc7\u63a5\u89e6\u6a21\u5757\u548c\u81ea\u9002\u5e94\u4ea4\u4e92\u5206\u914d\u673a\u5236\u76f4\u63a5\u6355\u6349\u7269\u7406\u4ea4\u4e92\uff0c\u5e76\u901a\u8fc7\u4e09\u5143\u5173\u7cfb\u5b66\u4e60\u53d8\u5f62\u3002", "result": "\u5728\u4e03\u4e2a\u6570\u636e\u96c6\u548c\u4e24\u4e2a\u590d\u6742\u4efb\u52a1\u4e0a\uff0cUnisoma\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u663e\u5f0f\u5efa\u6a21\u66f4\u9002\u5408\u591a\u56fa\u4f53\u7cfb\u7edf\uff0cUnisoma\u4e3a\u76f8\u5173\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.06039", "pdf": "https://arxiv.org/pdf/2506.06039", "abs": "https://arxiv.org/abs/2506.06039", "authors": ["Jake Robertson", "Arik Reuter", "Siyuan Guo", "Noah Hollmann", "Frank Hutter", "Bernhard Sch\u00f6lkopf"], "title": "Do-PFN: In-Context Learning for Causal Effect Estimation", "categories": ["cs.LG"], "comment": null, "summary": "Estimation of causal effects is critical to a range of scientific\ndisciplines. Existing methods for this task either require interventional data,\nknowledge about the ground truth causal graph, or rely on assumptions such as\nunconfoundedness, restricting their applicability in real-world settings. In\nthe domain of tabular machine learning, Prior-data fitted networks (PFNs) have\nachieved state-of-the-art predictive performance, having been pre-trained on\nsynthetic data to solve tabular prediction problems via in-context learning. To\nassess whether this can be transferred to the harder problem of causal effect\nestimation, we pre-train PFNs on synthetic data drawn from a wide variety of\ncausal structures, including interventions, to predict interventional outcomes\ngiven observational data. Through extensive experiments on synthetic case\nstudies, we show that our approach allows for the accurate estimation of causal\neffects without knowledge of the underlying causal graph. We also perform\nablation studies that elucidate Do-PFN's scalability and robustness across\ndatasets with a variety of causal characteristics.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9884\u8bad\u7ec3\u7f51\u7edc\uff08PFNs\uff09\u7684\u65b9\u6cd5\uff08Do-PFN\uff09\uff0c\u7528\u4e8e\u5728\u65e0\u9700\u771f\u5b9e\u56e0\u679c\u56fe\u7684\u60c5\u51b5\u4e0b\u51c6\u786e\u4f30\u8ba1\u56e0\u679c\u6548\u5e94\u3002", "motivation": "\u73b0\u6709\u56e0\u679c\u6548\u5e94\u4f30\u8ba1\u65b9\u6cd5\u4f9d\u8d56\u5e72\u9884\u6570\u636e\u6216\u771f\u5b9e\u56e0\u679c\u56fe\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002\u672c\u6587\u63a2\u7d22\u9884\u8bad\u7ec3\u7f51\u7edc\u5728\u56e0\u679c\u6548\u5e94\u4f30\u8ba1\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u9884\u8bad\u7ec3PFNs\u4e8e\u591a\u79cd\u56e0\u679c\u7ed3\u6784\u7684\u5408\u6210\u6570\u636e\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u9884\u6d4b\u5e72\u9884\u7ed3\u679c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cDo-PFN\u80fd\u5728\u672a\u77e5\u56e0\u679c\u56fe\u7684\u60c5\u51b5\u4e0b\u51c6\u786e\u4f30\u8ba1\u56e0\u679c\u6548\u5e94\uff0c\u4e14\u5177\u6709\u53ef\u6269\u5c55\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "Do-PFN\u4e3a\u56e0\u679c\u6548\u5e94\u4f30\u8ba1\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u771f\u5b9e\u56e0\u679c\u56fe\u7684\u65b0\u65b9\u6cd5\uff0c\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\u3002"}}
{"id": "2506.06045", "pdf": "https://arxiv.org/pdf/2506.06045", "abs": "https://arxiv.org/abs/2506.06045", "authors": ["Tobias W\u00fcrth", "Niklas Freymuth", "Gerhard Neumann", "Luise K\u00e4rger"], "title": "Diffusion-Based Hierarchical Graph Neural Networks for Simulating Nonlinear Solid Mechanics", "categories": ["cs.LG", "physics.comp-ph"], "comment": null, "summary": "Graph-based learned simulators have emerged as a promising approach for\nsimulating physical systems on unstructured meshes, offering speed and\ngeneralization across diverse geometries. However, they often struggle with\ncapturing global phenomena, such as bending or long-range correlations, and\nsuffer from error accumulation over long rollouts due to their reliance on\nlocal message passing and direct next-step prediction. We address these\nlimitations by introducing the Rolling Diffusion-Batched Inference Network\n(ROBIN), a novel learned simulator that integrates two key innovations: (i)\nRolling Diffusion, a parallelized inference scheme that amortizes the cost of\ndiffusion-based refinement across physical time steps by overlapping denoising\nsteps across a temporal window. (ii) A Hierarchical Graph Neural Network built\non algebraic multigrid coarsening, enabling multiscale message passing across\ndifferent mesh resolutions. This architecture, implemented via\nAlgebraic-hierarchical Message Passing Networks, captures both fine-scale local\ndynamics and global structural effects critical for phenomena like beam bending\nor multi-body contact. We validate ROBIN on challenging 2D and 3D solid\nmechanics benchmarks involving geometric, material, and contact nonlinearities.\nROBIN achieves state-of-the-art accuracy on all tasks, substantially\noutperforming existing next-step learned simulators while reducing inference\ntime by up to an order of magnitude compared to standard diffusion simulators.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aROBIN\u7684\u65b0\u578b\u5b66\u4e60\u6a21\u62df\u5668\uff0c\u901a\u8fc7\u7ed3\u5408\u6eda\u52a8\u6269\u6563\u548c\u5206\u5c42\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u56fe\u57fa\u5b66\u4e60\u6a21\u62df\u5668\u5728\u6355\u6349\u5168\u5c40\u73b0\u8c61\u548c\u957f\u671f\u8bef\u5dee\u79ef\u7d2f\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u56fe\u57fa\u5b66\u4e60\u6a21\u62df\u5668\u5728\u6a21\u62df\u7269\u7406\u7cfb\u7edf\u65f6\u96be\u4ee5\u6355\u6349\u5168\u5c40\u73b0\u8c61\uff08\u5982\u5f2f\u66f2\u6216\u957f\u7a0b\u76f8\u5173\u6027\uff09\uff0c\u4e14\u56e0\u4f9d\u8d56\u5c40\u90e8\u6d88\u606f\u4f20\u9012\u548c\u76f4\u63a5\u4e0b\u4e00\u6b65\u9884\u6d4b\u800c\u5bb9\u6613\u5728\u957f\u671f\u6a21\u62df\u4e2d\u79ef\u7d2f\u8bef\u5dee\u3002", "method": "ROBIN\u7ed3\u5408\u4e86\u6eda\u52a8\u6269\u6563\uff08\u4e00\u79cd\u5e76\u884c\u5316\u63a8\u7406\u65b9\u6848\uff09\u548c\u57fa\u4e8e\u4ee3\u6570\u591a\u91cd\u7f51\u683c\u7684\u5206\u5c42\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u5b9e\u73b0\u4e86\u591a\u5c3a\u5ea6\u6d88\u606f\u4f20\u9012\u3002", "result": "\u5728\u6d89\u53ca\u51e0\u4f55\u3001\u6750\u6599\u548c\u63a5\u89e6\u975e\u7ebf\u6027\u76842D\u548c3D\u56fa\u4f53\u529b\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cROBIN\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u51c6\u786e\u6027\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5c06\u63a8\u7406\u65f6\u95f4\u7f29\u77ed\u4e86\u4e00\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "ROBIN\u901a\u8fc7\u5176\u521b\u65b0\u7684\u67b6\u6784\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u590d\u6742\u7269\u7406\u7cfb\u7edf\u7684\u6a21\u62df\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.06048", "pdf": "https://arxiv.org/pdf/2506.06048", "abs": "https://arxiv.org/abs/2506.06048", "authors": ["Haripriya Harikumar", "Santu Rana"], "title": "TRUST: Test-time Resource Utilization for Superior Trustworthiness", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Standard uncertainty estimation techniques, such as dropout, often struggle\nto clearly distinguish reliable predictions from unreliable ones. We attribute\nthis limitation to noisy classifier weights, which, while not impairing overall\nclass-level predictions, render finer-level statistics less informative. To\naddress this, we propose a novel test-time optimization method that accounts\nfor the impact of such noise to produce more reliable confidence estimates.\nThis score defines a monotonic subset-selection function, where population\naccuracy consistently increases as samples with lower scores are removed, and\nit demonstrates superior performance in standard risk-based metrics such as\nAUSE and AURC. Additionally, our method effectively identifies discrepancies\nbetween training and test distributions, reliably differentiates\nin-distribution from out-of-distribution samples, and elucidates key\ndifferences between CNN and ViT classifiers across various vision datasets.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u6d4b\u8bd5\u65f6\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u51cf\u5c11\u5206\u7c7b\u5668\u6743\u91cd\u566a\u58f0\uff0c\u63d0\u5347\u9884\u6d4b\u7f6e\u4fe1\u5ea6\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u4f20\u7edf\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u65b9\u6cd5\uff08\u5982dropout\uff09\u96be\u4ee5\u6e05\u6670\u533a\u5206\u53ef\u9760\u4e0e\u4e0d\u53ef\u9760\u9884\u6d4b\uff0c\u539f\u56e0\u662f\u5206\u7c7b\u5668\u6743\u91cd\u566a\u58f0\u5f71\u54cd\u4e86\u7ec6\u7c92\u5ea6\u7edf\u8ba1\u4fe1\u606f\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u6d4b\u8bd5\u65f6\u4f18\u5316\u65b9\u6cd5\uff0c\u8003\u8651\u566a\u58f0\u5f71\u54cd\uff0c\u751f\u6210\u66f4\u53ef\u9760\u7684\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\uff0c\u5e76\u5b9a\u4e49\u5355\u8c03\u5b50\u96c6\u9009\u62e9\u51fd\u6570\u3002", "result": "\u5728AUSE\u548cAURC\u7b49\u6807\u51c6\u98ce\u9669\u6307\u6807\u4e0a\u8868\u73b0\u4f18\u8d8a\uff0c\u80fd\u6709\u6548\u8bc6\u522b\u8bad\u7ec3\u4e0e\u6d4b\u8bd5\u5206\u5e03\u5dee\u5f02\uff0c\u533a\u5206\u5206\u5e03\u5185\u5916\u6837\u672c\uff0c\u5e76\u63ed\u793aCNN\u4e0eViT\u5206\u7c7b\u5668\u7684\u5173\u952e\u5dee\u5f02\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u7684\u53ef\u9760\u6027\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u89c6\u89c9\u6570\u636e\u96c6\u3002"}}
{"id": "2506.06073", "pdf": "https://arxiv.org/pdf/2506.06073", "abs": "https://arxiv.org/abs/2506.06073", "authors": ["Linda Lu", "Ayush Sekhari", "Karthik Sridharan"], "title": "System-Aware Unlearning Algorithms: Use Lesser, Forget Faster", "categories": ["cs.LG"], "comment": "ICML 2025", "summary": "Machine unlearning addresses the problem of updating a machine learning\nmodel/system trained on a dataset $S$ so that the influence of a set of\ndeletion requests $U \\subseteq S$ on the unlearned model is minimized. The gold\nstandard definition of unlearning demands that the updated model, after\ndeletion, be nearly identical to the model obtained by retraining. This\ndefinition is designed for a worst-case attacker (one who can recover not only\nthe unlearned model but also the remaining data samples, i.e., $S \\setminus\nU$). Such a stringent definition has made developing efficient unlearning\nalgorithms challenging. However, such strong attackers are also unrealistic. In\nthis work, we propose a new definition, system-aware unlearning, which aims to\nprovide unlearning guarantees against an attacker that can at best only gain\naccess to the data stored in the system for learning/unlearning requests and\nnot all of $S\\setminus U$. With this new definition, we use the simple\nintuition that if a system can store less to make its learning/unlearning\nupdates, it can be more secure and update more efficiently against a\nsystem-aware attacker. Towards that end, we present an exact system-aware\nunlearning algorithm for linear classification using a selective sampling-based\napproach, and we generalize the method for classification with general function\nclasses. We theoretically analyze the tradeoffs between deletion capacity,\naccuracy, memory, and computation time.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u673a\u5668\u9057\u5fd8\u5b9a\u4e49\u2014\u2014\u7cfb\u7edf\u611f\u77e5\u9057\u5fd8\uff0c\u65e8\u5728\u9488\u5bf9\u4ec5\u80fd\u8bbf\u95ee\u7cfb\u7edf\u5b58\u50a8\u6570\u636e\u7684\u653b\u51fb\u8005\u63d0\u4f9b\u9057\u5fd8\u4fdd\u8bc1\uff0c\u5e76\u901a\u8fc7\u9009\u62e9\u6027\u91c7\u6837\u65b9\u6cd5\u5b9e\u73b0\u9ad8\u6548\u7684\u7ebf\u6027\u5206\u7c7b\u9057\u5fd8\u7b97\u6cd5\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u9057\u5fd8\u7684\u4e25\u683c\u5b9a\u4e49\uff08\u8981\u6c42\u9057\u5fd8\u540e\u6a21\u578b\u4e0e\u91cd\u65b0\u8bad\u7ec3\u7684\u6a21\u578b\u51e0\u4e4e\u76f8\u540c\uff09\u5bf9\u9ad8\u6548\u7b97\u6cd5\u5f00\u53d1\u6784\u6210\u6311\u6218\uff0c\u4e14\u5047\u8bbe\u7684\u653b\u51fb\u8005\u80fd\u529b\u8fc7\u4e8e\u5f3a\u5927\u3002\u56e0\u6b64\uff0c\u8bba\u6587\u63d0\u51fa\u66f4\u5b9e\u9645\u7684\u7cfb\u7edf\u611f\u77e5\u9057\u5fd8\u5b9a\u4e49\u3002", "method": "\u63d0\u51fa\u7cfb\u7edf\u611f\u77e5\u9057\u5fd8\u5b9a\u4e49\uff0c\u5e76\u57fa\u4e8e\u9009\u62e9\u6027\u91c7\u6837\u65b9\u6cd5\u8bbe\u8ba1\u4e86\u4e00\u79cd\u7cbe\u786e\u7684\u7ebf\u6027\u5206\u7c7b\u9057\u5fd8\u7b97\u6cd5\uff0c\u540c\u65f6\u63a8\u5e7f\u5230\u4e00\u822c\u51fd\u6570\u5206\u7c7b\u3002", "result": "\u7406\u8bba\u5206\u6790\u4e86\u5220\u9664\u5bb9\u91cf\u3001\u51c6\u786e\u6027\u3001\u5185\u5b58\u548c\u8ba1\u7b97\u65f6\u95f4\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\u3002", "conclusion": "\u7cfb\u7edf\u611f\u77e5\u9057\u5fd8\u5b9a\u4e49\u66f4\u5b9e\u9645\u4e14\u9ad8\u6548\uff0c\u4e3a\u673a\u5668\u9057\u5fd8\u7b97\u6cd5\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2506.06095", "pdf": "https://arxiv.org/pdf/2506.06095", "abs": "https://arxiv.org/abs/2506.06095", "authors": ["Wenhao Dai", "Haodong Deng", "Mengfei Rong", "Xinyu Yang", "Hongyu Liu", "Fangxin Liu", "Hailong Yang", "Weifeng Liu", "Qingxiao Sun"], "title": "Flexible Operator Fusion for Fast Sparse Transformer with Diverse Masking on GPU", "categories": ["cs.LG"], "comment": null, "summary": "Large language models are popular around the world due to their powerful\nunderstanding capabilities. As the core component of LLMs, accelerating\nTransformer through parallelization has gradually become a hot research topic.\nMask layers introduce sparsity into Transformer to reduce calculations.\nHowever, previous works rarely focus on the performance optimization of sparse\nTransformer. Moreover, rule-based mechanisms ignore the fusion opportunities of\nmixed-type operators and fail to adapt to various sequence lengths. To address\nthe above problems, we propose STOF, a framework that incorporates\noptimizations for Sparse Transformer via flexible masking and operator fusion\non GPU. We firstly unify the storage format and kernel implementation for the\nmulti-head attention. Then, we map fusion schemes to compilation templates and\ndetermine the optimal parameter setting through a two-stage search engine. The\nexperimental results show that compared to the state-of-the-art work, STOF\nachieves maximum speedups of 1.7x in MHA computation and 1.5x in end-to-end\ninference.", "AI": {"tldr": "STOF\u6846\u67b6\u901a\u8fc7\u7075\u6d3b\u7684\u63a9\u7801\u548cGPU\u4e0a\u7684\u7b97\u5b50\u878d\u5408\u4f18\u5316\u7a00\u758fTransformer\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7a00\u758fTransformer\u7814\u7a76\u8f83\u5c11\u5173\u6ce8\u6027\u80fd\u4f18\u5316\uff0c\u4e14\u57fa\u4e8e\u89c4\u5219\u7684\u673a\u5236\u65e0\u6cd5\u9002\u5e94\u4e0d\u540c\u5e8f\u5217\u957f\u5ea6\u548c\u6df7\u5408\u7c7b\u578b\u7b97\u5b50\u7684\u878d\u5408\u673a\u4f1a\u3002", "method": "STOF\u7edf\u4e00\u4e86\u591a\u5934\u6ce8\u610f\u529b\u7684\u5b58\u50a8\u683c\u5f0f\u548c\u5185\u6838\u5b9e\u73b0\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u641c\u7d22\u5f15\u64ce\u786e\u5b9a\u6700\u4f73\u53c2\u6570\u8bbe\u7f6e\uff0c\u5e76\u6620\u5c04\u878d\u5408\u65b9\u6848\u5230\u7f16\u8bd1\u6a21\u677f\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSTOF\u5728MHA\u8ba1\u7b97\u548c\u7aef\u5230\u7aef\u63a8\u7406\u4e2d\u5206\u522b\u5b9e\u73b0\u4e861.7\u500d\u548c1.5\u500d\u7684\u6700\u5927\u52a0\u901f\u3002", "conclusion": "STOF\u901a\u8fc7\u4f18\u5316\u7a00\u758fTransformer\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002"}}
{"id": "2506.06105", "pdf": "https://arxiv.org/pdf/2506.06105", "abs": "https://arxiv.org/abs/2506.06105", "authors": ["Rujikorn Charakorn", "Edoardo Cetin", "Yujin Tang", "Robert Tjarko Lange"], "title": "Text-to-LoRA: Instant Transformer Adaption", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at ICML 2025", "summary": "While Foundation Models provide a general tool for rapid content creation,\nthey regularly require task-specific adaptation. Traditionally, this exercise\ninvolves careful curation of datasets and repeated fine-tuning of the\nunderlying model. Fine-tuning techniques enable practitioners to adapt\nfoundation models for many new applications but require expensive and lengthy\ntraining while being notably sensitive to hyperparameter choices. To overcome\nthese limitations, we introduce Text-to-LoRA (T2L), a model capable of adapting\nlarge language models (LLMs) on the fly solely based on a natural language\ndescription of the target task. T2L is a hypernetwork trained to construct\nLoRAs in a single inexpensive forward pass. After training T2L on a suite of 9\npre-trained LoRA adapters (GSM8K, Arc, etc.), we show that the ad-hoc\nreconstructed LoRA instances match the performance of task-specific adapters\nacross the corresponding test sets. Furthermore, T2L can compress hundreds of\nLoRA instances and zero-shot generalize to entirely unseen tasks. This approach\nprovides a significant step towards democratizing the specialization of\nfoundation models and enables language-based adaptation with minimal compute\nrequirements.\n  Our code is available at https://github.com/SakanaAI/text-to-lora", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faText-to-LoRA (T2L)\uff0c\u4e00\u79cd\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u52a8\u6001\u8c03\u6574\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u65b9\u6cd5\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u5fae\u8c03\u7684\u9ad8\u6210\u672c\u548c\u590d\u6742\u6027\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u7cbe\u5fc3\u8bbe\u8ba1\u6570\u636e\u96c6\u548c\u53cd\u590d\u5fae\u8c03\uff0c\u6210\u672c\u9ad8\u4e14\u5bf9\u8d85\u53c2\u6570\u654f\u611f\u3002T2L\u65e8\u5728\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u5b9e\u73b0\u5feb\u901f\u3001\u4f4e\u6210\u672c\u7684\u6a21\u578b\u9002\u914d\u3002", "method": "T2L\u662f\u4e00\u79cd\u8d85\u7f51\u7edc\uff0c\u901a\u8fc7\u5355\u6b21\u524d\u5411\u4f20\u64ad\u751f\u6210LoRA\u9002\u914d\u5668\uff0c\u8bad\u7ec3\u57fa\u4e8e9\u4e2a\u9884\u8bad\u7ec3LoRA\u9002\u914d\u5668\uff08\u5982GSM8K\u3001Arc\u7b49\uff09\u3002", "result": "T2L\u751f\u6210\u7684LoRA\u5b9e\u4f8b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u8868\u73b0\u4e0e\u4efb\u52a1\u4e13\u7528\u9002\u914d\u5668\u76f8\u5f53\uff0c\u5e76\u80fd\u538b\u7f29\u6570\u767e\u4e2aLoRA\u5b9e\u4f8b\uff0c\u96f6\u6837\u672c\u6cdb\u5316\u5230\u65b0\u4efb\u52a1\u3002", "conclusion": "T2L\u4e3a\u5927\u89c4\u6a21\u6a21\u578b\u9002\u914d\u63d0\u4f9b\u4e86\u4e00\u79cd\u4f4e\u6210\u672c\u3001\u9ad8\u6548\u7684\u65b9\u6cd5\uff0c\u63a8\u52a8\u4e86\u57fa\u7840\u6a21\u578b\u7684\u6c11\u4e3b\u5316\u5e94\u7528\u3002"}}
{"id": "2506.06108", "pdf": "https://arxiv.org/pdf/2506.06108", "abs": "https://arxiv.org/abs/2506.06108", "authors": ["Graham Cormode", "Samuel Maddock", "Enayat Ullah", "Shripad Gade"], "title": "Synthetic Tabular Data: Methods, Attacks and Defenses", "categories": ["cs.LG", "cs.CR"], "comment": "Survey paper for accepted lecture-style tutorial at ACM KDD 2025", "summary": "Synthetic data is often positioned as a solution to replace sensitive\nfixed-size datasets with a source of unlimited matching data, freed from\nprivacy concerns. There has been much progress in synthetic data generation\nover the last decade, leveraging corresponding advances in machine learning and\ndata analytics. In this survey, we cover the key developments and the main\nconcepts in tabular synthetic data generation, including paradigms based on\nprobabilistic graphical models and on deep learning. We provide background and\nmotivation, before giving a technical deep-dive into the methodologies. We also\naddress the limitations of synthetic data, by studying attacks that seek to\nretrieve information about the original sensitive data. Finally, we present\nextensions and open problems in this area.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u8868\u683c\u5408\u6210\u6570\u636e\u751f\u6210\u7684\u5173\u952e\u8fdb\u5c55\u548c\u4e3b\u8981\u6982\u5ff5\uff0c\u5305\u62ec\u57fa\u4e8e\u6982\u7387\u56fe\u6a21\u578b\u548c\u6df1\u5ea6\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u5e76\u63a2\u8ba8\u4e86\u5408\u6210\u6570\u636e\u7684\u5c40\u9650\u6027\u53ca\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u5408\u6210\u6570\u636e\u88ab\u89c6\u4e3a\u89e3\u51b3\u9690\u79c1\u95ee\u9898\u7684\u6f5c\u5728\u65b9\u6848\uff0c\u672c\u6587\u65e8\u5728\u603b\u7ed3\u8be5\u9886\u57df\u7684\u6280\u672f\u8fdb\u5c55\u548c\u6311\u6218\u3002", "method": "\u7efc\u8ff0\u4e86\u6982\u7387\u56fe\u6a21\u578b\u548c\u6df1\u5ea6\u5b66\u4e60\u5728\u5408\u6210\u6570\u636e\u751f\u6210\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u5206\u6790\u4e86\u653b\u51fb\u539f\u59cb\u6570\u636e\u7684\u65b9\u6cd5\u3002", "result": "\u603b\u7ed3\u4e86\u5408\u6210\u6570\u636e\u751f\u6210\u7684\u6280\u672f\u8fdb\u5c55\uff0c\u540c\u65f6\u6307\u51fa\u5176\u9690\u79c1\u4fdd\u62a4\u5c40\u9650\u6027\u3002", "conclusion": "\u5408\u6210\u6570\u636e\u751f\u6210\u9886\u57df\u4ecd\u6709\u5f85\u89e3\u51b3\u7684\u95ee\u9898\u548c\u6269\u5c55\u65b9\u5411\u3002"}}
{"id": "2506.06112", "pdf": "https://arxiv.org/pdf/2506.06112", "abs": "https://arxiv.org/abs/2506.06112", "authors": ["Cheng-Long Wang", "Qi Li", "Zihang Xiang", "Yinzhi Cao", "Di Wang"], "title": "Towards Lifecycle Unlearning Commitment Management: Measuring Sample-level Unlearning Completeness", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": "To appear in the Proceedings of USENIX Security Symposium, 2025", "summary": "Growing concerns over data privacy and security highlight the importance of\nmachine unlearning--removing specific data influences from trained models\nwithout full retraining. Techniques like Membership Inference Attacks (MIAs)\nare widely used to externally assess successful unlearning. However, existing\nmethods face two key limitations: (1) maximizing MIA effectiveness (e.g., via\nonline attacks) requires prohibitive computational resources, often exceeding\nretraining costs; (2) MIAs, designed for binary inclusion tests, struggle to\ncapture granular changes in approximate unlearning. To address these\nchallenges, we propose the Interpolated Approximate Measurement (IAM), a\nframework natively designed for unlearning inference. IAM quantifies\nsample-level unlearning completeness by interpolating the model's\ngeneralization-fitting behavior gap on queried samples. IAM achieves strong\nperformance in binary inclusion tests for exact unlearning and high correlation\nfor approximate unlearning--scalable to LLMs using just one pre-trained shadow\nmodel. We theoretically analyze how IAM's scoring mechanism maintains\nperformance efficiently. We then apply IAM to recent approximate unlearning\nalgorithms, revealing general risks of both over-unlearning and\nunder-unlearning, underscoring the need for stronger safeguards in approximate\nunlearning systems. The code is available at\nhttps://github.com/Happy2Git/Unlearning_Inference_IAM.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aIAM\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u91cf\u5316\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e2d\u7684\u6570\u636e\u9057\u5fd8\u6548\u679c\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u8ba1\u7b97\u8d44\u6e90\u548c\u7c92\u5ea6\u4e0a\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u6570\u636e\u9690\u79c1\u548c\u5b89\u5168\u95ee\u9898\u65e5\u76ca\u7a81\u51fa\uff0c\u9700\u8981\u9ad8\u6548\u8bc4\u4f30\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e2d\u7684\u6570\u636e\u9057\u5fd8\u6548\u679c\uff0c\u73b0\u6709\u65b9\u6cd5\u5982MIA\u5728\u8ba1\u7b97\u8d44\u6e90\u548c\u7c92\u5ea6\u4e0a\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u63d0\u51faIAM\u6846\u67b6\uff0c\u901a\u8fc7\u63d2\u503c\u6a21\u578b\u7684\u6cdb\u5316-\u62df\u5408\u884c\u4e3a\u95f4\u9699\u6765\u91cf\u5316\u6837\u672c\u7ea7\u9057\u5fd8\u6548\u679c\uff0c\u9002\u7528\u4e8e\u7cbe\u786e\u548c\u8fd1\u4f3c\u9057\u5fd8\u3002", "result": "IAM\u5728\u4e8c\u5143\u5305\u542b\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u9002\u7528\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4e14\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u4f4e\u3002\u7406\u8bba\u5206\u6790\u8868\u660e\u5176\u8bc4\u5206\u673a\u5236\u9ad8\u6548\u3002", "conclusion": "IAM\u4e3a\u6570\u636e\u9057\u5fd8\u63d0\u4f9b\u4e86\u9ad8\u6548\u8bc4\u4f30\u5de5\u5177\uff0c\u63ed\u793a\u4e86\u8fd1\u4f3c\u9057\u5fd8\u7b97\u6cd5\u4e2d\u7684\u8fc7\u5ea6\u9057\u5fd8\u548c\u4e0d\u8db3\u9057\u5fd8\u98ce\u9669\uff0c\u5f3a\u8c03\u4e86\u66f4\u5f3a\u7684\u5b89\u5168\u4fdd\u969c\u9700\u6c42\u3002"}}
{"id": "2506.06114", "pdf": "https://arxiv.org/pdf/2506.06114", "abs": "https://arxiv.org/abs/2506.06114", "authors": ["Xudong Zhang", "Renato Cordeiro de Amorim"], "title": "Scalable unsupervised feature selection via weight stability", "categories": ["cs.LG"], "comment": null, "summary": "Unsupervised feature selection is critical for improving clustering\nperformance in high-dimensional data, where irrelevant features can obscure\nmeaningful structure. In this work, we introduce the Minkowski weighted\n$k$-means++, a novel initialisation strategy for the Minkowski Weighted\n$k$-means. Our initialisation selects centroids probabilistically using feature\nrelevance estimates derived from the data itself. Building on this, we propose\ntwo new feature selection algorithms, FS-MWK++, which aggregates feature\nweights across a range of Minkowski exponents to identify stable and\ninformative features, and SFS-MWK++, a scalable variant based on subsampling.\nWe support our approach with a theoretical guarantee under mild assumptions and\nextensive experiments showing that our methods consistently outperform existing\nalternatives.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eMinkowski\u52a0\u6743k-means++\u7684\u65b0\u521d\u59cb\u5316\u7b56\u7565\uff0c\u5e76\u5f00\u53d1\u4e86\u4e24\u79cd\u7279\u5f81\u9009\u62e9\u7b97\u6cd5FS-MWK++\u548cSFS-MWK++\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9ad8\u7ef4\u6570\u636e\u805a\u7c7b\u6027\u80fd\u3002", "motivation": "\u9ad8\u7ef4\u6570\u636e\u4e2d\u65e0\u5173\u7279\u5f81\u4f1a\u63a9\u76d6\u6709\u610f\u4e49\u7684\u7ed3\u6784\uff0c\u65e0\u76d1\u7763\u7279\u5f81\u9009\u62e9\u5bf9\u63d0\u5347\u805a\u7c7b\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51faMinkowski\u52a0\u6743k-means++\u521d\u59cb\u5316\u7b56\u7565\uff0c\u57fa\u4e8e\u6570\u636e\u7279\u5f81\u76f8\u5173\u6027\u6982\u7387\u9009\u62e9\u4e2d\u5fc3\u70b9\uff0c\u5e76\u5f00\u53d1FS-MWK++\u548cSFS-MWK++\u4e24\u79cd\u7279\u5f81\u9009\u62e9\u7b97\u6cd5\u3002", "result": "\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u9a8c\u8868\u660e\uff0c\u65b0\u65b9\u6cd5\u5728\u591a\u79cd\u60c5\u51b5\u4e0b\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u65b0\u65b9\u6cd5\u5728\u65e0\u76d1\u7763\u7279\u5f81\u9009\u62e9\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u663e\u8457\u63d0\u5347\u4e86\u805a\u7c7b\u6027\u80fd\u3002"}}
{"id": "2506.06122", "pdf": "https://arxiv.org/pdf/2506.06122", "abs": "https://arxiv.org/abs/2506.06122", "authors": ["Weixun Wang", "Shaopan Xiong", "Gengru Chen", "Wei Gao", "Sheng Guo", "Yancheng He", "Ju Huang", "Jiaheng Liu", "Zhendong Li", "Xiaoyang Li", "Zichen Liu", "Haizhou Zhao", "Dakai An", "Lunxi Cao", "Qiyang Cao", "Wanxi Deng", "Feilei Du", "Yiliang Gu", "Jiahe Li", "Xiang Li", "Mingjie Liu", "Yijia Luo", "Zihe Liu", "Yadao Wang", "Pei Wang", "Tianyuan Wu", "Yanan Wu", "Yuheng Zhao", "Shuaibing Zhao", "Jin Yang", "Siran Yang", "Yingshui Tan", "Huimin Yi", "Yuchi Xu", "Yujin Yuan", "Xingyao Zhang", "Lin Qu", "Wenbo Su", "Wei Wang", "Jiamang Wang", "Bo Zheng"], "title": "Reinforcement Learning Optimization for Large-Scale Learning: An Efficient and User-Friendly Scaling Library", "categories": ["cs.LG", "cs.DC"], "comment": "16 pages", "summary": "We introduce ROLL, an efficient, scalable, and user-friendly library designed\nfor Reinforcement Learning Optimization for Large-scale Learning. ROLL caters\nto three primary user groups: tech pioneers aiming for cost-effective,\nfault-tolerant large-scale training, developers requiring flexible control over\ntraining workflows, and researchers seeking agile experimentation. ROLL is\nbuilt upon several key modules to serve these user groups effectively. First, a\nsingle-controller architecture combined with an abstraction of the parallel\nworker simplifies the development of the training pipeline. Second, the\nparallel strategy and data transfer modules enable efficient and scalable\ntraining. Third, the rollout scheduler offers fine-grained management of each\nsample's lifecycle during the rollout stage. Fourth, the environment worker and\nreward worker support rapid and flexible experimentation with agentic RL\nalgorithms and reward designs. Finally, AutoDeviceMapping allows users to\nassign resources to different models flexibly across various stages.", "AI": {"tldr": "ROLL\u662f\u4e00\u4e2a\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u4e14\u7528\u6237\u53cb\u597d\u7684\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u5e93\uff0c\u9488\u5bf9\u5927\u89c4\u6a21\u5b66\u4e60\u573a\u666f\u8bbe\u8ba1\uff0c\u6ee1\u8db3\u6280\u672f\u5148\u9a71\u3001\u5f00\u53d1\u8005\u548c\u7814\u7a76\u8005\u7684\u9700\u6c42\u3002", "motivation": "\u4e3a\u4e0d\u540c\u7528\u6237\u7fa4\u4f53\uff08\u6280\u672f\u5148\u9a71\u3001\u5f00\u53d1\u8005\u548c\u7814\u7a76\u8005\uff09\u63d0\u4f9b\u6210\u672c\u6548\u76ca\u9ad8\u3001\u5bb9\u9519\u6027\u5f3a\u7684\u5927\u89c4\u6a21\u8bad\u7ec3\u5de5\u5177\uff0c\u540c\u65f6\u652f\u6301\u7075\u6d3b\u7684\u5b9e\u9a8c\u548c\u5f00\u53d1\u3002", "method": "\u91c7\u7528\u5355\u63a7\u5236\u5668\u67b6\u6784\u3001\u5e76\u884c\u7b56\u7565\u548c\u6570\u636e\u4f20\u8f93\u6a21\u5757\u3001\u7ec6\u7c92\u5ea6\u751f\u547d\u5468\u671f\u7ba1\u7406\u7684rollout\u8c03\u5ea6\u5668\u3001\u73af\u5883\u4e0e\u5956\u52b1\u5de5\u4f5c\u5668\uff0c\u4ee5\u53ca\u7075\u6d3b\u7684AutoDeviceMapping\u8d44\u6e90\u5206\u914d\u3002", "result": "\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u4e14\u7075\u6d3b\u7684\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\uff0c\u652f\u6301\u5927\u89c4\u6a21\u8bad\u7ec3\u548c\u5feb\u901f\u5b9e\u9a8c\u3002", "conclusion": "ROLL\u901a\u8fc7\u6a21\u5757\u5316\u8bbe\u8ba1\u548c\u7075\u6d3b\u7684\u8d44\u6e90\u7ba1\u7406\uff0c\u6210\u529f\u6ee1\u8db3\u4e86\u4e0d\u540c\u7528\u6237\u7fa4\u4f53\u7684\u9700\u6c42\uff0c\u4e3a\u5927\u89c4\u6a21\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2506.06127", "pdf": "https://arxiv.org/pdf/2506.06127", "abs": "https://arxiv.org/abs/2506.06127", "authors": ["Pascal Plettenberg", "Dominik K\u00f6hler", "Bernhard Sick", "Josephine M. Thomas"], "title": "Flow-Attentional Graph Neural Networks", "categories": ["cs.LG"], "comment": null, "summary": "Graph Neural Networks (GNNs) have become essential for learning from\ngraph-structured data. However, existing GNNs do not consider the conservation\nlaw inherent in graphs associated with a flow of physical resources, such as\nelectrical current in power grids or traffic in transportation networks, which\ncan lead to reduced model performance. To address this, we propose flow\nattention, which adapts existing graph attention mechanisms to satisfy\nKirchhoff\\'s first law. Furthermore, we discuss how this modification\ninfluences the expressivity and identify sets of non-isomorphic graphs that can\nbe discriminated by flow attention but not by standard attention. Through\nextensive experiments on two flow graph datasets (electronic circuits and power\ngrids), we demonstrate that flow attention enhances the performance of\nattention-based GNNs on both graph-level classification and regression tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u57fa\u5c14\u970d\u592b\u7b2c\u4e00\u5b9a\u5f8b\u7684\u6d41\u6ce8\u610f\u529b\u673a\u5236\uff0c\u63d0\u5347\u4e86\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u6d41\u56fe\u6570\u636e\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u56fe\u795e\u7ecf\u7f51\u7edc\u672a\u8003\u8651\u6d41\u56fe\u6570\u636e\u4e2d\u7684\u5b88\u6052\u5b9a\u5f8b\uff08\u5982\u7535\u6d41\u3001\u4ea4\u901a\u6d41\u91cf\uff09\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u63d0\u51fa\u6d41\u6ce8\u610f\u529b\u673a\u5236\uff0c\u6539\u8fdb\u73b0\u6709\u56fe\u6ce8\u610f\u529b\u673a\u5236\u4ee5\u6ee1\u8db3\u57fa\u5c14\u970d\u592b\u7b2c\u4e00\u5b9a\u5f8b\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u6d41\u6ce8\u610f\u529b\u5728\u7535\u8def\u548c\u7535\u7f51\u6570\u636e\u96c6\u4e0a\u63d0\u5347\u4e86\u56fe\u5206\u7c7b\u548c\u56de\u5f52\u4efb\u52a1\u7684\u6027\u80fd\u3002", "conclusion": "\u6d41\u6ce8\u610f\u529b\u673a\u5236\u80fd\u6709\u6548\u6355\u6349\u6d41\u56fe\u6570\u636e\u7684\u5b88\u6052\u7279\u6027\uff0c\u63d0\u5347\u6a21\u578b\u8868\u73b0\u3002"}}
{"id": "2506.06130", "pdf": "https://arxiv.org/pdf/2506.06130", "abs": "https://arxiv.org/abs/2506.06130", "authors": ["Thomas Borsani", "Andrea Rosani", "Giuseppe Nicosia", "Giuseppe Di Fatta"], "title": "Gradient Similarity Surgery in Multi-Task Deep Learning", "categories": ["cs.LG", "cs.CV"], "comment": "Paper accepted at ECMLPKDD 2025", "summary": "The multi-task learning ($MTL$) paradigm aims to simultaneously learn\nmultiple tasks within a single model capturing higher-level, more general\nhidden patterns that are shared by the tasks. In deep learning, a significant\nchallenge in the backpropagation training process is the design of advanced\noptimisers to improve the convergence speed and stability of the gradient\ndescent learning rule. In particular, in multi-task deep learning ($MTDL$) the\nmultitude of tasks may generate potentially conflicting gradients that would\nhinder the concurrent convergence of the diverse loss functions. This challenge\narises when the gradients of the task objectives have either different\nmagnitudes or opposite directions, causing one or a few to dominate or to\ninterfere with each other, thus degrading the training process. Gradient\nsurgery methods address the problem explicitly dealing with conflicting\ngradients by adjusting the overall gradient trajectory. This work introduces a\nnovel gradient surgery method, the Similarity-Aware Momentum Gradient Surgery\n(SAM-GS), which provides an effective and scalable approach based on a gradient\nmagnitude similarity measure to guide the optimisation process. The SAM-GS\nsurgery adopts gradient equalisation and modulation of the first-order\nmomentum. A series of experimental tests have shown the effectiveness of SAM-GS\non synthetic problems and $MTL$ benchmarks. Gradient magnitude similarity plays\na crucial role in regularising gradient aggregation in $MTDL$ for the\noptimisation of the learning process.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u68af\u5ea6\u624b\u672f\u65b9\u6cd5SAM-GS\uff0c\u901a\u8fc7\u68af\u5ea6\u76f8\u4f3c\u6027\u5ea6\u91cf\u4f18\u5316\u591a\u4efb\u52a1\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u68af\u5ea6\u51b2\u7a81\u95ee\u9898\u3002", "motivation": "\u591a\u4efb\u52a1\u6df1\u5ea6\u5b66\u4e60\uff08MTDL\uff09\u4e2d\uff0c\u4efb\u52a1\u68af\u5ea6\u53ef\u80fd\u56e0\u65b9\u5411\u6216\u5927\u5c0f\u4e0d\u540c\u800c\u4ea7\u751f\u51b2\u7a81\uff0c\u5f71\u54cd\u6536\u655b\u901f\u5ea6\u548c\u7a33\u5b9a\u6027\u3002", "method": "\u63d0\u51faSAM-GS\u65b9\u6cd5\uff0c\u57fa\u4e8e\u68af\u5ea6\u76f8\u4f3c\u6027\u5ea6\u91cf\u8c03\u6574\u68af\u5ea6\u8f68\u8ff9\uff0c\u7ed3\u5408\u68af\u5ea6\u5747\u8861\u548c\u4e00\u9636\u52a8\u91cf\u8c03\u5236\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eSAM-GS\u5728\u5408\u6210\u95ee\u9898\u548cMTL\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6709\u6548\u3002", "conclusion": "\u68af\u5ea6\u76f8\u4f3c\u6027\u5728MTDL\u4e2d\u5bf9\u68af\u5ea6\u805a\u5408\u548c\u4f18\u5316\u5b66\u4e60\u8fc7\u7a0b\u8d77\u5173\u952e\u4f5c\u7528\u3002"}}
{"id": "2506.06137", "pdf": "https://arxiv.org/pdf/2506.06137", "abs": "https://arxiv.org/abs/2506.06137", "authors": ["Rihui Jin", "Zheyu Xin", "Xing Xie", "Zuoyi Li", "Guilin Qi", "Yongrui Chen", "Xinbang Dai", "Tongtong Wu", "Gholamreza Haffari"], "title": "Table-r1: Self-supervised and Reinforcement Learning for Program-based Table Reasoning in Small Language Models", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Table reasoning (TR) requires structured reasoning over semi-structured\ntabular data and remains challenging, particularly for small language models\n(SLMs, e.g., LLaMA-8B) due to their limited capacity compared to large LMs\n(LLMs, e.g., GPT-4o). To narrow this gap, we explore program-based TR (P-TR),\nwhich circumvents key limitations of text-based TR (T-TR), notably in numerical\nreasoning, by generating executable programs. However, applying P-TR to SLMs\nintroduces two challenges: (i) vulnerability to heterogeneity in table layouts,\nand (ii) inconsistency in reasoning due to limited code generation capability.\nWe propose Table-r1, a two-stage P-TR method designed for SLMs. Stage 1\nintroduces an innovative self-supervised learning task, Layout Transformation\nInference, to improve tabular layout generalization from a programmatic view.\nStage 2 adopts a mix-paradigm variant of Group Relative Policy Optimization,\nenhancing P-TR consistency while allowing dynamic fallback to T-TR when needed.\nExperiments on four TR benchmarks demonstrate that Table-r1 outperforms all\nSLM-based methods, achieving at least a 15% accuracy improvement over the base\nmodel (LLaMA-8B) across all datasets and reaching performance competitive with\nLLMs.", "AI": {"tldr": "Table-r1\u662f\u4e00\u79cd\u9488\u5bf9\u5c0f\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\u7684\u4e24\u9636\u6bb5\u7a0b\u5e8f\u5316\u8868\u683c\u63a8\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u5e03\u5c40\u8f6c\u6362\u63a8\u7406\u548c\u6df7\u5408\u8303\u5f0f\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8868\u683c\u63a8\u7406\u7684\u51c6\u786e\u6027\u548c\u4e00\u81f4\u6027\u3002", "motivation": "\u5c0f\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\u5728\u8868\u683c\u63a8\u7406\uff08TR\uff09\u4e2d\u8868\u73b0\u53d7\u9650\uff0c\u5c24\u5176\u662f\u5728\u6570\u503c\u63a8\u7406\u548c\u5e03\u5c40\u6cdb\u5316\u65b9\u9762\u3002\u7a0b\u5e8f\u5316TR\uff08P-TR\uff09\u867d\u80fd\u90e8\u5206\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u4f46SLMs\u5728\u4ee3\u7801\u751f\u6210\u548c\u5e03\u5c40\u9002\u5e94\u4e0a\u4ecd\u5b58\u5728\u4e0d\u8db3\u3002", "method": "Table-r1\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a\u7b2c\u4e00\u9636\u6bb5\u901a\u8fc7\u81ea\u76d1\u7763\u5b66\u4e60\u4efb\u52a1\uff08\u5e03\u5c40\u8f6c\u6362\u63a8\u7406\uff09\u63d0\u5347\u8868\u683c\u5e03\u5c40\u6cdb\u5316\u80fd\u529b\uff1b\u7b2c\u4e8c\u9636\u6bb5\u91c7\u7528\u6df7\u5408\u8303\u5f0f\u4f18\u5316\uff08Group Relative Policy Optimization\uff09\uff0c\u589e\u5f3a\u63a8\u7406\u4e00\u81f4\u6027\u5e76\u652f\u6301\u52a8\u6001\u56de\u9000\u5230\u6587\u672cTR\uff08T-TR\uff09\u3002", "result": "\u5728\u56db\u4e2aTR\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cTable-r1\u663e\u8457\u4f18\u4e8e\u5176\u4ed6SLM\u65b9\u6cd5\uff0c\u51c6\u786e\u7387\u6bd4\u57fa\u7840\u6a21\u578b\uff08LLaMA-8B\uff09\u63d0\u5347\u81f3\u5c1115%\uff0c\u4e14\u6027\u80fd\u63a5\u8fd1\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u3002", "conclusion": "Table-r1\u4e3aSLMs\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u8868\u683c\u63a8\u7406\u89e3\u51b3\u65b9\u6848\uff0c\u7f29\u5c0f\u4e86\u4e0eLLMs\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u540c\u65f6\u89e3\u51b3\u4e86\u5e03\u5c40\u9002\u5e94\u548c\u63a8\u7406\u4e00\u81f4\u6027\u95ee\u9898\u3002"}}
{"id": "2506.06143", "pdf": "https://arxiv.org/pdf/2506.06143", "abs": "https://arxiv.org/abs/2506.06143", "authors": ["Carolin Benjamins", "Helena Graf", "Sarah Segel", "Difan Deng", "Tim Ruhkopf", "Leona Hennig", "Soham Basu", "Neeratyoy Mallik", "Edward Bergman", "Deyao Chen", "Fran\u00e7ois Cl\u00e9ment", "Matthias Feurer", "Katharina Eggensperger", "Frank Hutter", "Carola Doerr", "Marius Lindauer"], "title": "carps: A Framework for Comparing N Hyperparameter Optimizers on M Benchmarks", "categories": ["cs.LG"], "comment": null, "summary": "Hyperparameter Optimization (HPO) is crucial to develop well-performing\nmachine learning models. In order to ease prototyping and benchmarking of HPO\nmethods, we propose carps, a benchmark framework for Comprehensive Automated\nResearch Performance Studies allowing to evaluate N optimizers on M benchmark\ntasks. In this first release of carps, we focus on the four most important\ntypes of HPO task types: blackbox, multi-fidelity, multi-objective and\nmulti-fidelity-multi-objective. With 3 336 tasks from 5 community benchmark\ncollections and 28 variants of 9 optimizer families, we offer the biggest go-to\nlibrary to date to evaluate and compare HPO methods. The carps framework relies\non a purpose-built, lightweight interface, gluing together optimizers and\nbenchmark tasks. It also features an analysis pipeline, facilitating the\nevaluation of optimizers on benchmarks. However, navigating a huge number of\ntasks while developing and comparing methods can be computationally infeasible.\nTo address this, we obtain a subset of representative tasks by minimizing the\nstar discrepancy of the subset, in the space spanned by the full set. As a\nresult, we propose an initial subset of 10 to 30 diverse tasks for each task\ntype, and include functionality to re-compute subsets as more benchmarks become\navailable, enabling efficient evaluations. We also establish a first set of\nbaseline results on these tasks as a measure for future comparisons. With carps\n(https://www.github.com/automl/CARP-S), we make an important step in the\nstandardization of HPO evaluation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3acarps\u7684\u57fa\u51c6\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u8d85\u53c2\u6570\u4f18\u5316\uff08HPO\uff09\u65b9\u6cd5\uff0c\u652f\u6301\u591a\u79cd\u4efb\u52a1\u7c7b\u578b\uff0c\u5e76\u63d0\u4f9b\u4ee3\u8868\u6027\u4efb\u52a1\u5b50\u96c6\u4ee5\u63d0\u5347\u6548\u7387\u3002", "motivation": "\u4e3a\u4e86\u7b80\u5316\u548c\u6807\u51c6\u5316HPO\u65b9\u6cd5\u7684\u539f\u578b\u8bbe\u8ba1\u548c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5f00\u53d1\u4e86carps\u6846\u67b6\u3002", "method": "carps\u6846\u67b6\u6574\u5408\u4e86\u591a\u79cd\u4f18\u5316\u5668\u548c\u57fa\u51c6\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7\u6700\u5c0f\u5316\u5b50\u96c6\u7684\u661f\u5dee\u5f02\u6765\u9009\u53d6\u4ee3\u8868\u6027\u4efb\u52a1\u3002", "result": "\u63d0\u4f9b\u4e86\u5305\u542b3,336\u4e2a\u4efb\u52a1\u7684\u5e93\uff0c\u5e76\u4e3a\u6bcf\u79cd\u4efb\u52a1\u7c7b\u578b\u63a8\u8350\u4e8610\u523030\u4e2a\u4ee3\u8868\u6027\u4efb\u52a1\uff0c\u540c\u65f6\u5efa\u7acb\u4e86\u57fa\u7ebf\u7ed3\u679c\u3002", "conclusion": "carps\u6846\u67b6\u63a8\u52a8\u4e86HPO\u8bc4\u4f30\u7684\u6807\u51c6\u5316\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u5de5\u5177\u548c\u57fa\u51c6\u3002"}}
{"id": "2506.06158", "pdf": "https://arxiv.org/pdf/2506.06158", "abs": "https://arxiv.org/abs/2506.06158", "authors": ["Armand Kassa\u00ef Koupa\u00ef", "Lise Le Boudec", "Louis Serrano", "Patrick Gallinari"], "title": "ENMA: Tokenwise Autoregression for Generative Neural PDE Operators", "categories": ["cs.LG"], "comment": null, "summary": "Solving time-dependent parametric partial differential equations (PDEs)\nremains a fundamental challenge for neural solvers, particularly when\ngeneralizing across a wide range of physical parameters and dynamics. When data\nis uncertain or incomplete-as is often the case-a natural approach is to turn\nto generative models. We introduce ENMA, a generative neural operator designed\nto model spatio-temporal dynamics arising from physical phenomena. ENMA\npredicts future dynamics in a compressed latent space using a generative masked\nautoregressive transformer trained with flow matching loss, enabling tokenwise\ngeneration. Irregularly sampled spatial observations are encoded into uniform\nlatent representations via attention mechanisms and further compressed through\na spatio-temporal convolutional encoder. This allows ENMA to perform in-context\nlearning at inference time by conditioning on either past states of the target\ntrajectory or auxiliary context trajectories with similar dynamics. The result\nis a robust and adaptable framework that generalizes to new PDE regimes and\nsupports one-shot surrogate modeling of time-dependent parametric PDEs.", "AI": {"tldr": "ENMA\u662f\u4e00\u79cd\u751f\u6210\u795e\u7ecf\u7b97\u5b50\uff0c\u7528\u4e8e\u89e3\u51b3\u65f6\u95f4\u4f9d\u8d56\u53c2\u6570\u504f\u5fae\u5206\u65b9\u7a0b\uff08PDEs\uff09\u7684\u6311\u6218\uff0c\u901a\u8fc7\u751f\u6210\u63a9\u7801\u81ea\u56de\u5f52\u53d8\u6362\u5668\u548c\u6d41\u5339\u914d\u635f\u5931\u5728\u6f5c\u5728\u7a7a\u95f4\u9884\u6d4b\u672a\u6765\u52a8\u6001\u3002", "motivation": "\u89e3\u51b3\u65f6\u95f4\u4f9d\u8d56\u53c2\u6570PDEs\u7684\u6cdb\u5316\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u6570\u636e\u4e0d\u786e\u5b9a\u6216\u4e0d\u5b8c\u6574\u7684\u60c5\u51b5\u4e0b\uff0c\u9700\u8981\u4e00\u79cd\u751f\u6210\u6a21\u578b\u6765\u5efa\u6a21\u65f6\u7a7a\u52a8\u6001\u3002", "method": "ENMA\u4f7f\u7528\u751f\u6210\u63a9\u7801\u81ea\u56de\u5f52\u53d8\u6362\u5668\u548c\u6d41\u5339\u914d\u635f\u5931\u5728\u538b\u7f29\u6f5c\u5728\u7a7a\u95f4\u9884\u6d4b\u52a8\u6001\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u548c\u65f6\u7a7a\u5377\u79ef\u7f16\u7801\u5668\u5904\u7406\u4e0d\u89c4\u5219\u91c7\u6837\u6570\u636e\u3002", "result": "ENMA\u80fd\u591f\u6cdb\u5316\u5230\u65b0\u7684PDE\u4f53\u7cfb\uff0c\u652f\u6301\u65f6\u95f4\u4f9d\u8d56\u53c2\u6570PDEs\u7684\u4e00\u6b21\u6027\u4ee3\u7406\u5efa\u6a21\u3002", "conclusion": "ENMA\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9c81\u68d2\u4e14\u9002\u5e94\u6027\u5f3a\u7684\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u590d\u6742PDE\u95ee\u9898\u7684\u6c42\u89e3\u3002"}}
{"id": "2506.06166", "pdf": "https://arxiv.org/pdf/2506.06166", "abs": "https://arxiv.org/abs/2506.06166", "authors": ["Tianyi Alex Qiu", "Zhonghao He", "Tejasveer Chugh", "Max Kleiman-Weiner"], "title": "The Lock-in Hypothesis: Stagnation by Algorithm", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CY", "cs.HC"], "comment": "ICML 2025, 46 pages", "summary": "The training and deployment of large language models (LLMs) create a feedback\nloop with human users: models learn human beliefs from data, reinforce these\nbeliefs with generated content, reabsorb the reinforced beliefs, and feed them\nback to users again and again. This dynamic resembles an echo chamber. We\nhypothesize that this feedback loop entrenches the existing values and beliefs\nof users, leading to a loss of diversity and potentially the lock-in of false\nbeliefs. We formalize this hypothesis and test it empirically with agent-based\nLLM simulations and real-world GPT usage data. Analysis reveals sudden but\nsustained drops in diversity after the release of new GPT iterations,\nconsistent with the hypothesized human-AI feedback loop. Code and data\navailable at https://thelockinhypothesis.com", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e0e\u4eba\u7c7b\u7528\u6237\u7684\u53cd\u9988\u5faa\u73af\uff0c\u53d1\u73b0\u8fd9\u79cd\u5faa\u73af\u53ef\u80fd\u5bfc\u81f4\u591a\u6837\u6027\u7684\u4e27\u5931\u548c\u9519\u8bef\u4fe1\u5ff5\u7684\u56fa\u5316\u3002", "motivation": "\u63a2\u8ba8LLMs\u4e0e\u4eba\u7c7b\u7528\u6237\u7684\u4e92\u52a8\u5982\u4f55\u5f62\u6210\u7c7b\u4f3c\u56de\u97f3\u5ba4\u7684\u53cd\u9988\u5faa\u73af\uff0c\u8fdb\u800c\u5f71\u54cd\u4fe1\u5ff5\u591a\u6837\u6027\u548c\u6b63\u786e\u6027\u3002", "method": "\u901a\u8fc7\u57fa\u4e8e\u4ee3\u7406\u7684LLM\u6a21\u62df\u548c\u771f\u5b9eGPT\u4f7f\u7528\u6570\u636e\uff0c\u5f62\u5f0f\u5316\u5e76\u9a8c\u8bc1\u5047\u8bbe\u3002", "result": "\u5206\u6790\u663e\u793a\uff0c\u65b0GPT\u7248\u672c\u53d1\u5e03\u540e\uff0c\u591a\u6837\u6027\u51fa\u73b0\u7a81\u7136\u4e14\u6301\u7eed\u7684\u4e0b\u964d\uff0c\u652f\u6301\u53cd\u9988\u5faa\u73af\u5047\u8bf4\u3002", "conclusion": "\u4eba\u7c7b-AI\u53cd\u9988\u5faa\u73af\u53ef\u80fd\u52a0\u5267\u4fe1\u5ff5\u56fa\u5316\uff0c\u9700\u8b66\u60d5\u5176\u5bf9\u591a\u6837\u6027\u548c\u771f\u7406\u6027\u7684\u6f5c\u5728\u8d1f\u9762\u5f71\u54cd\u3002"}}
{"id": "2506.06178", "pdf": "https://arxiv.org/pdf/2506.06178", "abs": "https://arxiv.org/abs/2506.06178", "authors": ["Alessandro Montenegro", "Federico Mansutti", "Marco Mussi", "Matteo Papini", "Alberto Maria Metelli"], "title": "Reusing Trajectories in Policy Gradients Enables Fast Convergence", "categories": ["cs.LG"], "comment": null, "summary": "Policy gradient (PG) methods are a class of effective reinforcement learning\nalgorithms, particularly when dealing with continuous control problems. These\nmethods learn the parameters of parametric policies via stochastic gradient\nascent, typically using on-policy trajectory data to estimate the policy\ngradient. However, such reliance on fresh data makes them sample-inefficient.\nIndeed, vanilla PG methods require $O(\\epsilon^{-2})$ trajectories to reach an\n$\\epsilon$-approximate stationary point. A common strategy to improve\nefficiency is to reuse off-policy information from past iterations, such as\nprevious gradients or trajectories. While gradient reuse has received\nsubstantial theoretical attention, leading to improved rates of\n$O(\\epsilon^{-3/2})$, the reuse of past trajectories remains largely unexplored\nfrom a theoretical perspective. In this work, we provide the first rigorous\ntheoretical evidence that extensive reuse of past off-policy trajectories can\nsignificantly accelerate convergence in PG methods. We introduce a power mean\ncorrection to the multiple importance weighting estimator and propose RPG\n(Retrospective Policy Gradient), a PG algorithm that combines old and new\ntrajectories for policy updates. Through a novel analysis, we show that, under\nestablished assumptions, RPG achieves a sample complexity of\n$\\widetilde{O}(\\epsilon^{-1})$, the best known rate in the literature. We\nfurther validate empirically our approach against PG methods with\nstate-of-the-art rates.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\uff08RPG\uff09\uff0c\u901a\u8fc7\u91cd\u7528\u8fc7\u53bb\u7684\u79bb\u7b56\u7565\u8f68\u8ff9\u52a0\u901f\u6536\u655b\uff0c\u7406\u8bba\u8bc1\u660e\u5176\u6837\u672c\u590d\u6742\u5ea6\u8fbe\u5230\u6700\u4f18\u3002", "motivation": "\u4f20\u7edf\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u4f9d\u8d56\u65b0\u6570\u636e\uff0c\u6837\u672c\u6548\u7387\u4f4e\uff0c\u800c\u91cd\u7528\u8fc7\u53bb\u8f68\u8ff9\u7684\u7406\u8bba\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u5f15\u5165\u5e42\u5747\u503c\u6821\u6b63\u7684\u591a\u91cd\u8981\u6027\u52a0\u6743\u4f30\u8ba1\u5668\uff0c\u63d0\u51faRPG\u7b97\u6cd5\u7ed3\u5408\u65b0\u65e7\u8f68\u8ff9\u66f4\u65b0\u7b56\u7565\u3002", "result": "\u7406\u8bba\u8bc1\u660eRPG\u7684\u6837\u672c\u590d\u6742\u5ea6\u4e3a$\\widetilde{O}(\\epsilon^{-1})$\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "RPG\u901a\u8fc7\u91cd\u7528\u8f68\u8ff9\u663e\u8457\u63d0\u5347\u6548\u7387\uff0c\u7406\u8bba\u548c\u5b9e\u9a8c\u5747\u9a8c\u8bc1\u5176\u4f18\u8d8a\u6027\u3002"}}
{"id": "2506.06179", "pdf": "https://arxiv.org/pdf/2506.06179", "abs": "https://arxiv.org/abs/2506.06179", "authors": ["Muhammed Ustaomeroglu", "Guannan Qu"], "title": "A Theoretical Study of (Hyper) Self-Attention through the Lens of Interactions: Representation, Training, Generalization", "categories": ["cs.LG", "stat.ML", "68T07, 90C26, 68Q32"], "comment": "Accepted to ICML 2025", "summary": "Self-attention has emerged as a core component of modern neural\narchitectures, yet its theoretical underpinnings remain elusive. In this paper,\nwe study self-attention through the lens of interacting entities, ranging from\nagents in multi-agent reinforcement learning to alleles in genetic sequences,\nand show that a single layer linear self-attention can efficiently represent,\nlearn, and generalize functions capturing pairwise interactions, including\nout-of-distribution scenarios. Our analysis reveals that self-attention acts as\na mutual interaction learner under minimal assumptions on the diversity of\ninteraction patterns observed during training, thereby encompassing a wide\nvariety of real-world domains. In addition, we validate our theoretical\ninsights through experiments demonstrating that self-attention learns\ninteraction functions and generalizes across both population distributions and\nout-of-distribution scenarios. Building on our theories, we introduce\nHyperFeatureAttention, a novel neural network module designed to learn\ncouplings of different feature-level interactions between entities.\nFurthermore, we propose HyperAttention, a new module that extends beyond\npairwise interactions to capture multi-entity dependencies, such as three-way,\nfour-way, or general n-way interactions.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u81ea\u6ce8\u610f\u529b\u673a\u5236\u7684\u7406\u8bba\u57fa\u7840\uff0c\u8868\u660e\u5355\u5c42\u7ebf\u6027\u81ea\u6ce8\u610f\u529b\u80fd\u9ad8\u6548\u8868\u793a\u3001\u5b66\u4e60\u548c\u6cdb\u5316\u6355\u6349\u6210\u5bf9\u4ea4\u4e92\u7684\u51fd\u6570\uff0c\u5305\u62ec\u5206\u5e03\u5916\u573a\u666f\u3002", "motivation": "\u63a2\u7d22\u81ea\u6ce8\u610f\u529b\u673a\u5236\u7684\u7406\u8bba\u57fa\u7840\uff0c\u63ed\u793a\u5176\u5728\u591a\u9886\u57df\u4e2d\u7684\u901a\u7528\u6027\u3002", "method": "\u901a\u8fc7\u5206\u6790\u81ea\u6ce8\u610f\u529b\u4f5c\u4e3a\u4ea4\u4e92\u5b66\u4e60\u5668\u7684\u4f5c\u7528\uff0c\u63d0\u51fa\u65b0\u6a21\u5757HyperFeatureAttention\u548cHyperAttention\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\u81ea\u6ce8\u610f\u529b\u80fd\u5b66\u4e60\u4ea4\u4e92\u51fd\u6570\u5e76\u6cdb\u5316\u5230\u5206\u5e03\u5916\u573a\u666f\u3002", "conclusion": "\u81ea\u6ce8\u610f\u529b\u662f\u4e00\u79cd\u901a\u7528\u7684\u4ea4\u4e92\u5b66\u4e60\u5668\uff0c\u65b0\u6a21\u5757\u80fd\u6269\u5c55\u5176\u80fd\u529b\u4ee5\u6355\u6349\u591a\u5b9e\u4f53\u4f9d\u8d56\u5173\u7cfb\u3002"}}
{"id": "2506.06185", "pdf": "https://arxiv.org/pdf/2506.06185", "abs": "https://arxiv.org/abs/2506.06185", "authors": ["Jing Jia", "Sifan Liu", "Bowen Song", "Wei Yuan", "Liyue Shen", "Guanyang Wang"], "title": "Antithetic Noise in Diffusion Models", "categories": ["cs.LG", "cs.NA", "math.NA", "stat.CO", "stat.ML"], "comment": "43 pages, 20 figures, 9 tables", "summary": "We initiate a systematic study of antithetic initial noise in diffusion\nmodels. Across unconditional models trained on diverse datasets,\ntext-conditioned latent-diffusion models, and diffusion-posterior samplers, we\nfind that pairing each initial noise with its negation consistently yields\nstrongly negatively correlated samples. To explain this phenomenon, we combine\nexperiments and theoretical analysis, leading to a symmetry conjecture that the\nlearned score function is approximately affine antisymmetric (odd symmetry up\nto a constant shift), and provide evidence supporting it. Leveraging this\nnegative correlation, we enable two applications: (1) enhancing image diversity\nin models like Stable Diffusion without quality loss, and (2) sharpening\nuncertainty quantification (e.g., up to 90% narrower confidence intervals) when\nestimating downstream statistics. Building on these gains, we extend the\ntwo-point pairing to a randomized quasi-Monte Carlo estimator, which further\nimproves estimation accuracy. Our framework is training-free, model-agnostic,\nand adds no runtime overhead.", "AI": {"tldr": "\u7814\u7a76\u4e86\u6269\u6563\u6a21\u578b\u4e2d\u521d\u59cb\u566a\u58f0\u7684\u5bf9\u79f0\u6027\u53ca\u5176\u5e94\u7528\uff0c\u53d1\u73b0\u521d\u59cb\u566a\u58f0\u4e0e\u5176\u5426\u5b9a\u914d\u5bf9\u53ef\u4ea7\u751f\u5f3a\u8d1f\u76f8\u5173\u6837\u672c\uff0c\u5e76\u57fa\u4e8e\u6b64\u63d0\u51fa\u4e86\u63d0\u5347\u56fe\u50cf\u591a\u6837\u6027\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u65b9\u6cd5\u3002", "motivation": "\u63a2\u7d22\u6269\u6563\u6a21\u578b\u4e2d\u521d\u59cb\u566a\u58f0\u7684\u5bf9\u79f0\u6027\u53ca\u5176\u6f5c\u5728\u5e94\u7528\uff0c\u4ee5\u63d0\u5347\u6a21\u578b\u6027\u80fd\u548c\u591a\u6837\u6027\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\u548c\u7406\u8bba\u5206\u6790\u9a8c\u8bc1\u521d\u59cb\u566a\u58f0\u4e0e\u5176\u5426\u5b9a\u914d\u5bf9\u7684\u8d1f\u76f8\u5173\u6027\uff0c\u63d0\u51fa\u5bf9\u79f0\u6027\u731c\u60f3\uff0c\u5e76\u57fa\u4e8e\u6b64\u5f00\u53d1\u4e86\u4e24\u79cd\u5e94\u7528\u65b9\u6cd5\u3002", "result": "\u5b9e\u73b0\u4e86\u56fe\u50cf\u591a\u6837\u6027\u7684\u63d0\u5347\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u4f18\u5316\uff08\u5982\u7f6e\u4fe1\u533a\u95f4\u7f29\u5c0f90%\uff09\uff0c\u5e76\u901a\u8fc7\u968f\u673a\u5316\u51c6\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\u5668\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u65e0\u9700\u8bad\u7ec3\u3001\u6a21\u578b\u65e0\u5173\u4e14\u65e0\u8fd0\u884c\u65f6\u5f00\u9500\uff0c\u4e3a\u6269\u6563\u6a21\u578b\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2506.06188", "pdf": "https://arxiv.org/pdf/2506.06188", "abs": "https://arxiv.org/abs/2506.06188", "authors": ["Luis Kin Miyatake", "Eduardo Camponogara", "Eric Aislan Antonelo", "Alexey Pavlov"], "title": "Physics-Informed Neural Networks for Control of Single-Phase Flow Systems Governed by Partial Differential Equations", "categories": ["cs.LG"], "comment": "62 pages, 14 figures", "summary": "The modeling and control of single-phase flow systems governed by Partial\nDifferential Equations (PDEs) present challenges, especially under transient\nconditions. In this work, we extend the Physics-Informed Neural Nets for\nControl (PINC) framework, originally proposed to modeling and control of\nOrdinary Differential Equations (ODE) without the need of any labeled data, to\nthe PDE case, particularly to single-phase incompressible and compressible\nflows, integrating neural networks with physical conservation laws. The PINC\nmodel for PDEs is structured into two stages: a steady-state network, which\nlearns equilibrium solutions for a wide range of control inputs, and a\ntransient network, which captures dynamic responses under time-varying boundary\nconditions. We propose a simplifying assumption that reduces the dimensionality\nof the spatial coordinate regarding the initial condition, allowing the\nefficient training of the PINC network. This simplification enables the\nderivation of optimal control policies using Model Predictive Control (MPC). We\nvalidate our approach through numerical experiments, demonstrating that the\nPINC model, which is trained exclusively using physical laws, i.e., without\nlabeled data, accurately represents flow dynamics and enables real-time control\napplications. The results highlight the PINC's capability to efficiently\napproximate PDE solutions without requiring iterative solvers, making it a\npromising alternative for fluid flow monitoring and optimization in engineering\napplications.", "AI": {"tldr": "\u8bba\u6587\u6269\u5c55\u4e86PINC\u6846\u67b6\uff0c\u5c06\u5176\u4eceODE\u63a7\u5236\u6269\u5c55\u5230PDE\u63a7\u5236\uff0c\u901a\u8fc7\u7ed3\u5408\u795e\u7ecf\u7f51\u7edc\u4e0e\u7269\u7406\u5b88\u6052\u5b9a\u5f8b\uff0c\u5b9e\u73b0\u4e86\u65e0\u9700\u6807\u8bb0\u6570\u636e\u7684\u5355\u76f8\u6d41\u5efa\u6a21\u4e0e\u63a7\u5236\u3002", "motivation": "\u89e3\u51b3PDE\u63a7\u5236\u7684\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u77ac\u6001\u6761\u4ef6\u4e0b\uff0c\u4e3a\u5de5\u7a0b\u5e94\u7528\u63d0\u4f9b\u9ad8\u6548\u4e14\u65e0\u9700\u6807\u8bb0\u6570\u636e\u7684\u6d41\u4f53\u6d41\u76d1\u63a7\u4e0e\u4f18\u5316\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u7f51\u7edc\u7ed3\u6784\uff1a\u7a33\u6001\u7f51\u7edc\u5b66\u4e60\u5e73\u8861\u89e3\uff0c\u77ac\u6001\u7f51\u7edc\u6355\u6349\u52a8\u6001\u54cd\u5e94\uff1b\u901a\u8fc7\u7b80\u5316\u5047\u8bbe\u964d\u4f4e\u7a7a\u95f4\u7ef4\u5ea6\uff0c\u7ed3\u5408MPC\u63a8\u5bfc\u6700\u4f18\u63a7\u5236\u7b56\u7565\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86PINC\u6a21\u578b\u80fd\u51c6\u786e\u8868\u793a\u6d41\u52a8\u529b\u5b66\u5e76\u5b9e\u73b0\u5b9e\u65f6\u63a7\u5236\uff0c\u65e0\u9700\u8fed\u4ee3\u6c42\u89e3\u5668\u3002", "conclusion": "PINC\u6846\u67b6\u4e3a\u6d41\u4f53\u6d41\u76d1\u63a7\u4e0e\u4f18\u5316\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u65e0\u9700\u6807\u8bb0\u6570\u636e\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u5de5\u7a0b\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.06192", "pdf": "https://arxiv.org/pdf/2506.06192", "abs": "https://arxiv.org/abs/2506.06192", "authors": ["Dimitrios Proios", "Alban Bornet", "Anthony Yazdani", "Jose F Rodrigues Jr", "Douglas Teodoro"], "title": "ICU-TSB: A Benchmark for Temporal Patient Representation Learning for Unsupervised Stratification into Patient Cohorts", "categories": ["cs.LG"], "comment": "6 pages 1 table 6 figures", "summary": "Patient stratification identifying clinically meaningful subgroups is\nessential for advancing personalized medicine through improved diagnostics and\ntreatment strategies. Electronic health records (EHRs), particularly those from\nintensive care units (ICUs), contain rich temporal clinical data that can be\nleveraged for this purpose. In this work, we introduce ICU-TSB (Temporal\nStratification Benchmark), the first comprehensive benchmark for evaluating\npatient stratification based on temporal patient representation learning using\nthree publicly available ICU EHR datasets. A key contribution of our benchmark\nis a novel hierarchical evaluation framework utilizing disease taxonomies to\nmeasure the alignment of discovered clusters with clinically validated disease\ngroupings. In our experiments with ICU-TSB, we compared statistical methods and\nseveral recurrent neural networks, including LSTM and GRU, for their ability to\ngenerate effective patient representations for subsequent clustering of patient\ntrajectories. Our results demonstrate that temporal representation learning can\nrediscover clinically meaningful patient cohorts; nevertheless, it remains a\nchallenging task, with v-measuring varying from up to 0.46 at the top level of\nthe taxonomy to up to 0.40 at the lowest level. To further enhance the\npractical utility of our findings, we also evaluate multiple strategies for\nassigning interpretable labels to the identified clusters. The experiments and\nbenchmark are fully reproducible and available at\nhttps://github.com/ds4dh/CBMS2025stratification.", "AI": {"tldr": "ICU-TSB\u662f\u4e00\u4e2a\u57fa\u4e8eICU\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHR\uff09\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u60a3\u8005\u5206\u5c42\u65b9\u6cd5\uff0c\u901a\u8fc7\u65f6\u95f4\u8868\u793a\u5b66\u4e60\u548c\u805a\u7c7b\u5206\u6790\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u53d1\u73b0\u4e34\u5e8a\u76f8\u5173\u60a3\u8005\u7fa4\u4f53\u65b9\u9762\u7684\u6f5c\u529b\u3002", "motivation": "\u60a3\u8005\u5206\u5c42\u5bf9\u4e2a\u6027\u5316\u533b\u7597\u81f3\u5173\u91cd\u8981\uff0cICU\u7684EHR\u6570\u636e\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u65f6\u95f4\u4e34\u5e8a\u4fe1\u606f\uff0c\u53ef\u7528\u4e8e\u6b64\u76ee\u7684\u3002", "method": "\u63d0\u51fa\u4e86ICU-TSB\u57fa\u51c6\uff0c\u91c7\u7528\u5c42\u6b21\u5316\u8bc4\u4f30\u6846\u67b6\uff0c\u7ed3\u5408\u75be\u75c5\u5206\u7c7b\u6cd5\uff0c\u6bd4\u8f83\u4e86\u7edf\u8ba1\u65b9\u6cd5\u548cRNN\uff08\u5982LSTM\u548cGRU\uff09\u5728\u60a3\u8005\u8868\u793a\u5b66\u4e60\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u65f6\u95f4\u8868\u793a\u5b66\u4e60\u80fd\u591f\u53d1\u73b0\u4e34\u5e8a\u76f8\u5173\u7684\u60a3\u8005\u7fa4\u4f53\uff0c\u4f46\u4efb\u52a1\u4ecd\u5177\u6311\u6218\u6027\uff0cv-measure\u5728\u5206\u7c7b\u6cd5\u4e0d\u540c\u5c42\u7ea7\u4e0a\u4ecb\u4e8e0.40\u81f30.46\u4e4b\u95f4\u3002", "conclusion": "ICU-TSB\u4e3a\u60a3\u8005\u5206\u5c42\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u7684\u8bc4\u4f30\u5de5\u5177\uff0c\u5e76\u63a2\u7d22\u4e86\u4e3a\u805a\u7c7b\u5206\u914d\u53ef\u89e3\u91ca\u6807\u7b7e\u7684\u7b56\u7565\uff0c\u63a8\u52a8\u4e86\u8be5\u9886\u57df\u7684\u5b9e\u7528\u5316\u3002"}}
{"id": "2506.06194", "pdf": "https://arxiv.org/pdf/2506.06194", "abs": "https://arxiv.org/abs/2506.06194", "authors": ["Sibylle Marcotte", "R\u00e9mi Gribonval", "Gabriel Peyr\u00e9"], "title": "Transformative or Conservative? Conservation laws for ResNets and Transformers", "categories": ["cs.LG"], "comment": "Accepted to ICML 2025", "summary": "While conservation laws in gradient flow training dynamics are well\nunderstood for (mostly shallow) ReLU and linear networks, their study remains\nlargely unexplored for more practical architectures. This paper bridges this\ngap by deriving and analyzing conservation laws for modern architectures, with\na focus on convolutional ResNets and Transformer networks. For this, we first\nshow that basic building blocks such as ReLU (or linear) shallow networks, with\nor without convolution, have easily expressed conservation laws, and no more\nthan the known ones. In the case of a single attention layer, we also\ncompletely describe all conservation laws, and we show that residual blocks\nhave the same conservation laws as the same block without a skip connection. We\nthen introduce the notion of conservation laws that depend only on a subset of\nparameters (corresponding e.g. to a pair of consecutive layers, to a residual\nblock, or to an attention layer). We demonstrate that the characterization of\nsuch laws can be reduced to the analysis of the corresponding building block in\nisolation. Finally, we examine how these newly discovered conservation\nprinciples, initially established in the continuous gradient flow regime,\npersist under discrete optimization dynamics, particularly in the context of\nStochastic Gradient Descent (SGD).", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u73b0\u4ee3\u67b6\u6784\uff08\u5982\u5377\u79efResNets\u548cTransformer\u7f51\u7edc\uff09\u4e2d\u7684\u5b88\u6052\u5b9a\u5f8b\uff0c\u586b\u8865\u4e86\u73b0\u6709\u7814\u7a76\u7684\u7a7a\u767d\u3002", "motivation": "\u7814\u7a76\u73b0\u4ee3\u67b6\u6784\u4e2d\u7684\u5b88\u6052\u5b9a\u5f8b\uff0c\u4ee5\u8865\u5145\u76ee\u524d\u5bf9\u6d45\u5c42ReLU\u548c\u7ebf\u6027\u7f51\u7edc\u7684\u7406\u89e3\u3002", "method": "\u901a\u8fc7\u5206\u6790\u57fa\u672c\u6784\u5efa\u5757\uff08\u5982ReLU\u6216\u7ebf\u6027\u7f51\u7edc\u3001\u6ce8\u610f\u529b\u5c42\u548c\u6b8b\u5dee\u5757\uff09\u7684\u5b88\u6052\u5b9a\u5f8b\uff0c\u5e76\u5c06\u5176\u6269\u5c55\u5230\u73b0\u4ee3\u67b6\u6784\u3002", "result": "\u53d1\u73b0\u73b0\u4ee3\u67b6\u6784\u4e2d\u7684\u5b88\u6052\u5b9a\u5f8b\u53ef\u4ee5\u901a\u8fc7\u5206\u6790\u72ec\u7acb\u6784\u5efa\u5757\u6765\u8868\u5f81\uff0c\u5e76\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u5b9a\u5f8b\u5728\u79bb\u6563\u4f18\u5316\uff08\u5982SGD\uff09\u4e2d\u7684\u6301\u7eed\u6027\u3002", "conclusion": "\u8bba\u6587\u4e3a\u73b0\u4ee3\u67b6\u6784\u4e2d\u7684\u5b88\u6052\u5b9a\u5f8b\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5206\u6790\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u79bb\u6563\u4f18\u5316\u4e2d\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2506.06204", "pdf": "https://arxiv.org/pdf/2506.06204", "abs": "https://arxiv.org/abs/2506.06204", "authors": ["Elie Kadoche", "Pascal Bianchi", "Florence Carton", "Philippe Ciblat", "Damien Ernst"], "title": "How to craft a deep reinforcement learning policy for wind farm flow control", "categories": ["cs.LG"], "comment": null, "summary": "Within wind farms, wake effects between turbines can significantly reduce\noverall energy production. Wind farm flow control encompasses methods designed\nto mitigate these effects through coordinated turbine control. Wake steering,\nfor example, consists in intentionally misaligning certain turbines with the\nwind to optimize airflow and increase power output. However, designing a robust\nwake steering controller remains challenging, and existing machine learning\napproaches are limited to quasi-static wind conditions or small wind farms.\nThis work presents a new deep reinforcement learning methodology to develop a\nwake steering policy that overcomes these limitations. Our approach introduces\na novel architecture that combines graph attention networks and multi-head\nself-attention blocks, alongside a novel reward function and training strategy.\nThe resulting model computes the yaw angles of each turbine, optimizing energy\nproduction in time-varying wind conditions. An empirical study conducted on\nsteady-state, low-fidelity simulation, shows that our model requires\napproximately 10 times fewer training steps than a fully connected neural\nnetwork and achieves more robust performance compared to a strong optimization\nbaseline, increasing energy production by up to 14 %. To the best of our\nknowledge, this is the first deep reinforcement learning-based wake steering\ncontroller to generalize effectively across any time-varying wind conditions in\na low-fidelity, steady-state numerical simulation setting.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bbe\u8ba1\u98ce\u7535\u573a\u4e2d\u7684\u5c3e\u6d41\u8f6c\u5411\u63a7\u5236\u5668\uff0c\u4ee5\u4f18\u5316\u80fd\u91cf\u751f\u4ea7\u3002", "motivation": "\u98ce\u7535\u573a\u4e2d\u6da1\u8f6e\u673a\u4e4b\u95f4\u7684\u5c3e\u6d41\u6548\u5e94\u4f1a\u663e\u8457\u964d\u4f4e\u6574\u4f53\u80fd\u91cf\u751f\u4ea7\uff0c\u73b0\u6709\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u4ec5\u9002\u7528\u4e8e\u51c6\u9759\u6001\u98ce\u51b5\u6216\u5c0f\u578b\u98ce\u7535\u573a\u3002", "method": "\u7ed3\u5408\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\u548c\u591a\u5934\u81ea\u6ce8\u610f\u529b\u5757\u7684\u65b0\u67b6\u6784\uff0c\u4ee5\u53ca\u65b0\u7684\u5956\u52b1\u51fd\u6570\u548c\u8bad\u7ec3\u7b56\u7565\uff0c\u8ba1\u7b97\u6bcf\u4e2a\u6da1\u8f6e\u7684\u504f\u822a\u89d2\u3002", "result": "\u6a21\u578b\u5728\u4f4e\u7cbe\u5ea6\u7a33\u6001\u6a21\u62df\u4e2d\uff0c\u8bad\u7ec3\u6b65\u9aa4\u51cf\u5c1110\u500d\uff0c\u80fd\u91cf\u751f\u4ea7\u63d0\u5347\u9ad8\u8fbe14%\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u80fd\u5728\u65f6\u53d8\u98ce\u51b5\u4e0b\u6709\u6548\u6cdb\u5316\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u5c3e\u6d41\u8f6c\u5411\u63a7\u5236\u5668\u3002"}}
{"id": "2506.06212", "pdf": "https://arxiv.org/pdf/2506.06212", "abs": "https://arxiv.org/abs/2506.06212", "authors": ["Ali Azizpour", "Nicolas Zilberstein", "Santiago Segarra"], "title": "Model-Driven Graph Contrastive Learning", "categories": ["cs.LG"], "comment": null, "summary": "We propose $\\textbf{MGCL}$, a model-driven graph contrastive learning (GCL)\nframework that leverages graphons (probabilistic generative models for graphs)\nto guide contrastive learning by accounting for the data's underlying\ngenerative process. GCL has emerged as a powerful self-supervised framework for\nlearning expressive node or graph representations without relying on annotated\nlabels, which are often scarce in real-world data. By contrasting augmented\nviews of graph data, GCL has demonstrated strong performance across various\ndownstream tasks, such as node and graph classification. However, existing\nmethods typically rely on manually designed or heuristic augmentation\nstrategies that are not tailored to the underlying data distribution and\noperate at the individual graph level, ignoring similarities among graphs\ngenerated from the same model. Conversely, in our proposed approach, MGCL first\nestimates the graphon associated with the observed data and then defines a\ngraphon-informed augmentation process, enabling data-adaptive and principled\naugmentations. Additionally, for graph-level tasks, MGCL clusters the dataset\nand estimates a graphon per group, enabling contrastive pairs to reflect shared\nsemantics and structure. Extensive experiments on benchmark datasets\ndemonstrate that MGCL achieves state-of-the-art performance, highlighting the\nadvantages of incorporating generative models into GCL.", "AI": {"tldr": "MGCL\u662f\u4e00\u79cd\u57fa\u4e8e\u6a21\u578b\u9a71\u52a8\u7684\u56fe\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528\u56fe\u751f\u6210\u6a21\u578b\uff08graphons\uff09\u6307\u5bfc\u5bf9\u6bd4\u5b66\u4e60\uff0c\u901a\u8fc7\u6570\u636e\u751f\u6210\u8fc7\u7a0b\u4f18\u5316\u8868\u793a\u5b66\u4e60\u3002", "motivation": "\u73b0\u6709GCL\u65b9\u6cd5\u4f9d\u8d56\u624b\u52a8\u8bbe\u8ba1\u7684\u542f\u53d1\u5f0f\u589e\u5f3a\u7b56\u7565\uff0c\u672a\u8003\u8651\u6570\u636e\u5206\u5e03\uff0c\u4e14\u5ffd\u7565\u540c\u6a21\u578b\u751f\u6210\u56fe\u95f4\u7684\u76f8\u4f3c\u6027\u3002MGCL\u65e8\u5728\u901a\u8fc7\u56fe\u751f\u6210\u6a21\u578b\u5b9e\u73b0\u6570\u636e\u81ea\u9002\u5e94\u548c\u539f\u5219\u6027\u589e\u5f3a\u3002", "method": "MGCL\u9996\u5148\u4f30\u8ba1\u89c2\u6d4b\u6570\u636e\u7684\u56fe\u751f\u6210\u6a21\u578b\uff0c\u5b9a\u4e49\u57fa\u4e8e\u56fe\u751f\u6210\u6a21\u578b\u7684\u589e\u5f3a\u8fc7\u7a0b\u3002\u5bf9\u4e8e\u56fe\u7ea7\u4efb\u52a1\uff0cMGCL\u5bf9\u6570\u636e\u96c6\u805a\u7c7b\u5e76\u4e3a\u6bcf\u7ec4\u4f30\u8ba1\u56fe\u751f\u6210\u6a21\u578b\uff0c\u4ee5\u53cd\u6620\u5171\u4eab\u8bed\u4e49\u548c\u7ed3\u6784\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMGCL\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "MGCL\u901a\u8fc7\u5c06\u751f\u6210\u6a21\u578b\u878d\u5165GCL\uff0c\u5c55\u793a\u4e86\u6570\u636e\u81ea\u9002\u5e94\u589e\u5f3a\u7684\u4f18\u52bf\u3002"}}
{"id": "2506.06215", "pdf": "https://arxiv.org/pdf/2506.06215", "abs": "https://arxiv.org/abs/2506.06215", "authors": ["Itai Gat", "Neta Shaul", "Uriel Singer", "Yaron Lipman"], "title": "Corrector Sampling in Language Models", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Autoregressive language models accumulate errors due to their fixed,\nirrevocable left-to-right token generation. To address this, we propose a new\nsampling method called Resample-Previous-Tokens (RPT). RPT mitigates error\naccumulation by iteratively revisiting and potentially replacing tokens in a\nwindow of previously generated text. This method can be integrated into\nexisting autoregressive models, preserving their next-token-prediction quality\nand speed. Fine-tuning a pretrained 8B parameter model with RPT for only 100B\nresulted in ~10% relative improvements on reasoning and coding benchmarks\ncompared to the standard sampling.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRPT\u7684\u65b0\u91c7\u6837\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fed\u4ee3\u91cd\u65b0\u8bbf\u95ee\u548c\u66ff\u6362\u5148\u524d\u751f\u6210\u7684\u6587\u672c\u6765\u51cf\u5c11\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u9519\u8bef\u7d2f\u79ef\u3002", "motivation": "\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u56e0\u5176\u56fa\u5b9a\u7684\u4ece\u5de6\u5230\u53f3\u7684\u6807\u8bb0\u751f\u6210\u65b9\u5f0f\u4f1a\u5bfc\u81f4\u9519\u8bef\u7d2f\u79ef\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u7f13\u89e3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51faRPT\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fed\u4ee3\u91cd\u65b0\u8bbf\u95ee\u548c\u66ff\u6362\u5148\u524d\u751f\u6210\u7684\u6587\u672c\u6765\u51cf\u5c11\u9519\u8bef\u7d2f\u79ef\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7684\u9884\u6d4b\u8d28\u91cf\u548c\u901f\u5ea6\u3002", "result": "\u57288B\u53c2\u6570\u6a21\u578b\u4e0a\u4ec5\u7528100B\u6570\u636e\u8fdb\u884c\u5fae\u8c03\u540e\uff0cRPT\u5728\u63a8\u7406\u548c\u7f16\u7801\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u7ea610%\u7684\u76f8\u5bf9\u6539\u8fdb\u3002", "conclusion": "RPT\u662f\u4e00\u79cd\u6709\u6548\u7684\u91c7\u6837\u65b9\u6cd5\uff0c\u80fd\u591f\u663e\u8457\u51cf\u5c11\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u9519\u8bef\u7d2f\u79ef\uff0c\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2506.06231", "pdf": "https://arxiv.org/pdf/2506.06231", "abs": "https://arxiv.org/abs/2506.06231", "authors": ["Mohammad Jalali", "Bahar Dibaei Nia", "Farzan Farnia"], "title": "Towards an Explainable Comparison and Alignment of Feature Embeddings", "categories": ["cs.LG", "cs.AI", "cs.CV", "math.SP"], "comment": null, "summary": "While several feature embedding models have been developed in the literature,\ncomparisons of these embeddings have largely focused on their numerical\nperformance in classification-related downstream applications. However, an\ninterpretable comparison of different embeddings requires identifying and\nanalyzing mismatches between sample groups clustered within the embedding\nspaces. In this work, we propose the \\emph{Spectral Pairwise Embedding\nComparison (SPEC)} framework to compare embeddings and identify their\ndifferences in clustering a reference dataset. Our approach examines the kernel\nmatrices derived from two embeddings and leverages the eigendecomposition of\nthe difference kernel matrix to detect sample clusters that are captured\ndifferently by the two embeddings. We present a scalable implementation of this\nkernel-based approach, with computational complexity that grows linearly with\nthe sample size. Furthermore, we introduce an optimization problem using this\nframework to align two embeddings, ensuring that clusters identified in one\nembedding are also captured in the other model. We provide numerical results\ndemonstrating the SPEC's application to compare and align embeddings on\nlarge-scale datasets such as ImageNet and MS-COCO. The code is available at\n[https://github.com/mjalali/embedding-comparison](github.com/mjalali/embedding-comparison).", "AI": {"tldr": "\u63d0\u51fa\u4e86SPEC\u6846\u67b6\uff0c\u7528\u4e8e\u6bd4\u8f83\u548c\u8c03\u6574\u5d4c\u5165\u6a21\u578b\uff0c\u901a\u8fc7\u6838\u77e9\u9635\u5dee\u5f02\u5206\u6790\u805a\u7c7b\u5dee\u5f02\uff0c\u5e76\u5b9e\u73b0\u7ebf\u6027\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "motivation": "\u73b0\u6709\u5d4c\u5165\u6a21\u578b\u7684\u6bd4\u8f83\u4e3b\u8981\u5173\u6ce8\u6570\u503c\u6027\u80fd\uff0c\u7f3a\u4e4f\u5bf9\u805a\u7c7b\u5dee\u5f02\u7684\u53ef\u89e3\u91ca\u6027\u5206\u6790\u3002", "method": "\u5229\u7528\u6838\u77e9\u9635\u7684\u8c31\u5206\u89e3\u68c0\u6d4b\u5d4c\u5165\u95f4\u7684\u805a\u7c7b\u5dee\u5f02\uff0c\u5e76\u63d0\u51fa\u4f18\u5316\u95ee\u9898\u8c03\u6574\u5d4c\u5165\u5bf9\u9f50\u3002", "result": "\u5728ImageNet\u548cMS-COCO\u7b49\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86SPEC\u7684\u6709\u6548\u6027\u3002", "conclusion": "SPEC\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u53ef\u89e3\u91ca\u7684\u65b9\u6cd5\u6765\u6bd4\u8f83\u548c\u8c03\u6574\u5d4c\u5165\u6a21\u578b\u3002"}}
{"id": "2506.06244", "pdf": "https://arxiv.org/pdf/2506.06244", "abs": "https://arxiv.org/abs/2506.06244", "authors": ["Aditya Kommineni", "Woojae Jeong", "Kleanthis Avramidis", "Colin McDaniel", "Myzelle Hughes", "Thomas McGee", "Elsi Kaiser", "Kristina Lerman", "Idan A. Blank", "Dani Byrd", "Assal Habibi", "B. Rael Cahn", "Sudarsana Kadiri", "Takfarinas Medani", "Richard M. Leahy", "Shrikanth Narayanan"], "title": "Neural Responses to Affective Sentences Reveal Signatures of Depression", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Major Depressive Disorder (MDD) is a highly prevalent mental health\ncondition, and a deeper understanding of its neurocognitive foundations is\nessential for identifying how core functions such as emotional and\nself-referential processing are affected. We investigate how depression alters\nthe temporal dynamics of emotional processing by measuring neural responses to\nself-referential affective sentences using surface electroencephalography (EEG)\nin healthy and depressed individuals. Our results reveal significant\ngroup-level differences in neural activity during sentence viewing, suggesting\ndisrupted integration of emotional and self-referential information in\ndepression. Deep learning model trained on these responses achieves an area\nunder the receiver operating curve (AUC) of 0.707 in distinguishing healthy\nfrom depressed participants, and 0.624 in differentiating depressed subgroups\nwith and without suicidal ideation. Spatial ablations highlight anterior\nelectrodes associated with semantic and affective processing as key\ncontributors. These findings suggest stable, stimulus-driven neural signatures\nof depression that may inform future diagnostic tools.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7EEG\u6d4b\u91cf\u5065\u5eb7\u4e0e\u6291\u90c1\u4e2a\u4f53\u5bf9\u81ea\u6211\u53c2\u7167\u60c5\u611f\u53e5\u5b50\u7684\u795e\u7ecf\u53cd\u5e94\uff0c\u53d1\u73b0\u6291\u90c1\u60c5\u7eea\u5904\u7406\u7684\u65f6\u95f4\u52a8\u6001\u53d8\u5316\uff0c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u80fd\u533a\u5206\u5065\u5eb7\u4e0e\u6291\u90c1\u4e2a\u4f53\u53ca\u6291\u90c1\u4e9a\u7ec4\u3002", "motivation": "\u6df1\u5165\u4e86\u89e3\u6291\u90c1\u75c7\u7684\u795e\u7ecf\u8ba4\u77e5\u57fa\u7840\uff0c\u5c24\u5176\u662f\u60c5\u611f\u548c\u81ea\u6211\u53c2\u7167\u5904\u7406\u529f\u80fd\u7684\u53d8\u5316\u3002", "method": "\u4f7f\u7528\u8868\u9762EEG\u6d4b\u91cf\u5065\u5eb7\u4e0e\u6291\u90c1\u4e2a\u4f53\u5bf9\u81ea\u6211\u53c2\u7167\u60c5\u611f\u53e5\u5b50\u7684\u795e\u7ecf\u53cd\u5e94\uff0c\u5e76\u8bad\u7ec3\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5206\u6790\u6570\u636e\u3002", "result": "\u53d1\u73b0\u6291\u90c1\u4e2a\u4f53\u5728\u53e5\u5b50\u89c2\u770b\u65f6\u7684\u795e\u7ecf\u6d3b\u52a8\u663e\u8457\u4e0d\u540c\uff0c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u533a\u5206\u5065\u5eb7\u4e0e\u6291\u90c1\u7684AUC\u4e3a0.707\uff0c\u533a\u5206\u6291\u90c1\u4e9a\u7ec4\u7684AUC\u4e3a0.624\u3002", "conclusion": "\u6291\u90c1\u5177\u6709\u7a33\u5b9a\u7684\u795e\u7ecf\u7279\u5f81\uff0c\u53ef\u80fd\u4e3a\u672a\u6765\u8bca\u65ad\u5de5\u5177\u63d0\u4f9b\u4f9d\u636e\u3002"}}
{"id": "2506.06248", "pdf": "https://arxiv.org/pdf/2506.06248", "abs": "https://arxiv.org/abs/2506.06248", "authors": ["Guillaume Pourcel", "Debabrota Basu", "Maxence Ernoult", "Aditya Gilra"], "title": "Lagrangian-based Equilibrium Propagation: generalisation to arbitrary boundary conditions & equivalence with Hamiltonian Echo Learning", "categories": ["cs.LG"], "comment": null, "summary": "Equilibrium Propagation (EP) is a learning algorithm for training\nEnergy-based Models (EBMs) on static inputs which leverages the variational\ndescription of their fixed points. Extending EP to time-varying inputs is a\nchallenging problem, as the variational description must apply to the entire\nsystem trajectory rather than just fixed points, and careful consideration of\nboundary conditions becomes essential. In this work, we present Generalized\nLagrangian Equilibrium Propagation (GLEP), which extends the variational\nformulation of EP to time-varying inputs. We demonstrate that GLEP yields\ndifferent learning algorithms depending on the boundary conditions of the\nsystem, many of which are impractical for implementation. We then show that\nHamiltonian Echo Learning (HEL) -- which includes the recently proposed\nRecurrent HEL (RHEL) and the earlier known Hamiltonian Echo Backpropagation\n(HEB) algorithms -- can be derived as a special case of GLEP. Notably, HEL is\nthe only instance of GLEP we found that inherits the properties that make EP a\ndesirable alternative to backpropagation for hardware implementations: it\noperates in a \"forward-only\" manner (i.e. using the same system for both\ninference and learning), it scales efficiently (requiring only two or more\npasses through the system regardless of model size), and enables local\nlearning.", "AI": {"tldr": "GLEP\u6269\u5c55\u4e86EP\u7b97\u6cd5\uff0c\u9002\u7528\u4e8e\u65f6\u53d8\u8f93\u5165\uff0c\u5e76\u5c55\u793a\u4e86\u4e0d\u540c\u8fb9\u754c\u6761\u4ef6\u4e0b\u7684\u5b66\u4e60\u7b97\u6cd5\u3002HEL\u662fGLEP\u7684\u7279\u4f8b\uff0c\u7ee7\u627f\u4e86EP\u7684\u786c\u4ef6\u53cb\u597d\u7279\u6027\u3002", "motivation": "\u5c06EP\u7b97\u6cd5\u6269\u5c55\u5230\u65f6\u53d8\u8f93\u5165\uff0c\u89e3\u51b3\u53d8\u5206\u63cf\u8ff0\u548c\u8fb9\u754c\u6761\u4ef6\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faGLEP\uff0c\u6269\u5c55EP\u7684\u53d8\u5206\u6846\u67b6\uff0c\u5206\u6790\u4e0d\u540c\u8fb9\u754c\u6761\u4ef6\u4e0b\u7684\u5b66\u4e60\u7b97\u6cd5\u3002", "result": "GLEP\u751f\u6210\u591a\u79cd\u7b97\u6cd5\uff0cHEL\u662f\u552f\u4e00\u5177\u5907EP\u786c\u4ef6\u53cb\u597d\u7279\u6027\u7684\u7279\u4f8b\u3002", "conclusion": "GLEP\u4e3a\u65f6\u53d8\u8f93\u5165\u63d0\u4f9b\u901a\u7528\u6846\u67b6\uff0cHEL\u662f\u5176\u5b9e\u7528\u4e14\u9ad8\u6548\u7684\u5b9e\u73b0\u3002"}}
{"id": "2506.06278", "pdf": "https://arxiv.org/pdf/2506.06278", "abs": "https://arxiv.org/abs/2506.06278", "authors": ["Bruce W. Lee", "Addie Foote", "Alex Infanger", "Leni Shor", "Harish Kamath", "Jacob Goldman-Wetzler", "Bryce Woodworth", "Alex Cloud", "Alexander Matt Turner"], "title": "Distillation Robustifies Unlearning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Current LLM unlearning methods are not robust: they can be reverted easily\nwith a few steps of finetuning. This is true even for the idealized unlearning\nmethod of training to imitate an oracle model that was never exposed to\nunwanted information, suggesting that output-based finetuning is insufficient\nto achieve robust unlearning. In a similar vein, we find that training a\nrandomly initialized student to imitate an unlearned model transfers desired\nbehaviors while leaving undesired capabilities behind. In other words,\ndistillation robustifies unlearning. Building on this insight, we propose\nUnlearn-Noise-Distill-on-Outputs (UNDO), a scalable method that distills an\nunlearned model into a partially noised copy of itself. UNDO introduces a\ntunable tradeoff between compute cost and robustness, establishing a new Pareto\nfrontier on synthetic language and arithmetic tasks. At its strongest setting,\nUNDO matches the robustness of a model retrained from scratch with perfect data\nfiltering while using only 60-80% of the compute and requiring only 0.01% of\nthe pretraining data to be labeled. We also show that UNDO robustifies\nunlearning on the more realistic Weapons of Mass Destruction Proxy (WMDP)\nbenchmark. Since distillation is widely used in practice, incorporating an\nunlearning step beforehand offers a convenient path to robust capability\nremoval.", "AI": {"tldr": "\u5f53\u524dLLM\u9057\u5fd8\u65b9\u6cd5\u4e0d\u591f\u9c81\u68d2\uff0c\u5bb9\u6613\u88ab\u5fae\u8c03\u6062\u590d\u3002\u63d0\u51faUNDO\u65b9\u6cd5\uff0c\u901a\u8fc7\u84b8\u998f\u589e\u5f3a\u9057\u5fd8\u9c81\u68d2\u6027\uff0c\u8ba1\u7b97\u6210\u672c\u4f4e\u4e14\u6548\u679c\u597d\u3002", "motivation": "\u73b0\u6709LLM\u9057\u5fd8\u65b9\u6cd5\u6613\u88ab\u5fae\u8c03\u6062\u590d\uff0c\u8f93\u51fa\u5fae\u8c03\u4e0d\u8db3\u4ee5\u5b9e\u73b0\u9c81\u68d2\u9057\u5fd8\uff0c\u9700\u63a2\u7d22\u66f4\u6709\u6548\u65b9\u6cd5\u3002", "method": "\u63d0\u51faUNDO\u65b9\u6cd5\uff0c\u901a\u8fc7\u84b8\u998f\u672a\u5b66\u4e60\u6a21\u578b\u5230\u90e8\u5206\u566a\u58f0\u7248\u672c\uff0c\u5e73\u8861\u8ba1\u7b97\u6210\u672c\u4e0e\u9c81\u68d2\u6027\u3002", "result": "UNDO\u5728\u5408\u6210\u4efb\u52a1\u4e2d\u63a5\u8fd1\u4ece\u5934\u8bad\u7ec3\u7684\u9c81\u68d2\u6027\uff0c\u8ba1\u7b97\u6210\u672c\u4f4e\uff0c\u4ec5\u9700\u5c11\u91cf\u6807\u6ce8\u6570\u636e\uff1b\u5728WMDP\u57fa\u51c6\u4e0a\u4e5f\u8868\u73b0\u826f\u597d\u3002", "conclusion": "UNDO\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u9c81\u68d2\u7684\u9057\u5fd8\u65b9\u6cd5\uff0c\u7ed3\u5408\u84b8\u998f\u53ef\u65b9\u4fbf\u5b9e\u73b0\u80fd\u529b\u79fb\u9664\u3002"}}
{"id": "2506.06280", "pdf": "https://arxiv.org/pdf/2506.06280", "abs": "https://arxiv.org/abs/2506.06280", "authors": ["Yuanzhe Hu", "Kinshuk Goel", "Vlad Killiakov", "Yaoqing Yang"], "title": "Eigenspectrum Analysis of Neural Networks without Aspect Ratio Bias", "categories": ["cs.LG", "cs.AI"], "comment": "30 pages, 14 figures, published to ICML 2025", "summary": "Diagnosing deep neural networks (DNNs) through the eigenspectrum of weight\nmatrices has been an active area of research in recent years. At a high level,\neigenspectrum analysis of DNNs involves measuring the heavytailness of the\nempirical spectral densities (ESD) of weight matrices. It provides insight into\nhow well a model is trained and can guide decisions on assigning better\nlayer-wise training hyperparameters. In this paper, we address a challenge\nassociated with such eigenspectrum methods: the impact of the aspect ratio of\nweight matrices on estimated heavytailness metrics. We demonstrate that\nmatrices of varying sizes (and aspect ratios) introduce a non-negligible bias\nin estimating heavytailness metrics, leading to inaccurate model diagnosis and\nlayer-wise hyperparameter assignment. To overcome this challenge, we propose\nFARMS (Fixed-Aspect-Ratio Matrix Subsampling), a method that normalizes the\nweight matrices by subsampling submatrices with a fixed aspect ratio. Instead\nof measuring the heavytailness of the original ESD, we measure the average ESD\nof these subsampled submatrices. We show that measuring the heavytailness of\nthese submatrices with the fixed aspect ratio can effectively mitigate the\naspect ratio bias. We validate our approach across various optimization\ntechniques and application domains that involve eigenspectrum analysis of\nweights, including image classification in computer vision (CV) models,\nscientific machine learning (SciML) model training, and large language model\n(LLM) pruning. Our results show that despite its simplicity, FARMS uniformly\nimproves the accuracy of eigenspectrum analysis while enabling more effective\nlayer-wise hyperparameter assignment in these application domains. In one of\nthe LLM pruning experiments, FARMS reduces the perplexity of the LLaMA-7B model\nby 17.3% when compared with the state-of-the-art method.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faFARMS\u65b9\u6cd5\uff0c\u901a\u8fc7\u56fa\u5b9a\u7eb5\u6a2a\u6bd4\u7684\u5b50\u77e9\u9635\u91c7\u6837\u89e3\u51b3\u6743\u91cd\u77e9\u9635\u7eb5\u6a2a\u6bd4\u5bf9\u91cd\u5c3e\u6027\u5ea6\u91cf\u7684\u504f\u5dee\u95ee\u9898\uff0c\u63d0\u5347\u6a21\u578b\u8bca\u65ad\u548c\u8d85\u53c2\u6570\u5206\u914d\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u6743\u91cd\u77e9\u9635\u7684\u7eb5\u6a2a\u6bd4\u4f1a\u5f71\u54cd\u91cd\u5c3e\u6027\u5ea6\u91cf\u7684\u51c6\u786e\u6027\uff0c\u5bfc\u81f4\u6a21\u578b\u8bca\u65ad\u548c\u5c42\u95f4\u8d85\u53c2\u6570\u5206\u914d\u4e0d\u51c6\u786e\u3002", "method": "\u63d0\u51faFARMS\u65b9\u6cd5\uff0c\u901a\u8fc7\u56fa\u5b9a\u7eb5\u6a2a\u6bd4\u7684\u5b50\u77e9\u9635\u91c7\u6837\uff0c\u6d4b\u91cf\u5b50\u77e9\u9635\u7684\u5e73\u5747\u8c31\u5bc6\u5ea6\u91cd\u5c3e\u6027\uff0c\u6d88\u9664\u7eb5\u6a2a\u6bd4\u504f\u5dee\u3002", "result": "FARMS\u5728\u591a\u79cd\u5e94\u7528\u9886\u57df\uff08CV\u3001SciML\u3001LLM\uff09\u4e2d\u63d0\u5347\u4e86\u8c31\u5206\u6790\u7684\u51c6\u786e\u6027\uff0c\u5e76\u5728LLM\u526a\u679d\u5b9e\u9a8c\u4e2d\u964d\u4f4e\u4e8617.3%\u7684\u56f0\u60d1\u5ea6\u3002", "conclusion": "FARMS\u662f\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u6d88\u9664\u7eb5\u6a2a\u6bd4\u504f\u5dee\uff0c\u63d0\u5347\u6a21\u578b\u8bca\u65ad\u548c\u8d85\u53c2\u6570\u5206\u914d\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2406.03674", "pdf": "https://arxiv.org/pdf/2406.03674", "abs": "https://arxiv.org/abs/2406.03674", "authors": ["Negin Golrezaei", "Sourav Sahoo"], "title": "Learning Safe Strategies for Value Maximizing Buyers in Uniform Price Auctions", "categories": ["cs.DS", "cs.GT", "cs.LG"], "comment": "61 pages, 4 figures. To appear at ICML 2025", "summary": "We study the bidding problem in repeated uniform price multi-unit auctions\nfrom the perspective of a single value-maximizing buyer who aims to maximize\ntheir cumulative value over $T$ rounds while adhering to return-on-investment\n(RoI) constraints in each round. Buyers adopt $m$-uniform bidding format, where\nthey submit $m$ bid-quantity pairs $(b_i, q_i)$ to demand $q_i$ units at bid\n$b_i$. We introduce safe bidding strategies as those that satisfy RoI\nconstraints in every auction, regardless of competing bids. We show that these\nstrategies depend only on the valuation curve of the bidder, and the bidder can\nfocus on a finite subset of this class without loss of generality. While the\nnumber of strategies in this subset is exponential in $m$, we develop a\npolynomial-time algorithm to learn the optimal safe strategy that achieves\nsublinear regret in the online setting, where regret is measured against a\nclairvoyant benchmark that knows the competing bids a priori and selects a\nfixed hindsight optimal safe strategy. We then evaluate the performance of safe\nstrategies against a clairvoyant that selects the optimal strategy from a\nricher class of strategies in the online setting. In this scenario, we compute\nthe richness ratio, $\\alpha\\in(0, 1]$ for the class of strategies chosen by the\nclairvoyant and show that our algorithm, designed to learn safe strategies,\nachieves $\\alpha$-approximate sublinear regret against these stronger\nbenchmarks. Experiments on semi-synthetic data from real-world auctions show\nthat safe strategies substantially outperform the derived theoretical bounds,\nmaking them quite appealing in practice.", "AI": {"tldr": "\u7814\u7a76\u91cd\u590d\u7edf\u4e00\u4ef7\u683c\u591a\u5355\u4f4d\u62cd\u5356\u4e2d\u7684\u6295\u6807\u95ee\u9898\uff0c\u63d0\u51fa\u4e00\u79cd\u5b89\u5168\u6295\u6807\u7b56\u7565\uff0c\u786e\u4fdd\u6bcf\u8f6e\u6ee1\u8db3RoI\u7ea6\u675f\uff0c\u5e76\u5f00\u53d1\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u5b66\u4e60\u6700\u4f18\u7b56\u7565\u3002", "motivation": "\u89e3\u51b3\u6295\u6807\u8005\u5728\u591a\u8f6e\u62cd\u5356\u4e2d\u5982\u4f55\u6700\u5927\u5316\u7d2f\u79ef\u4ef7\u503c\u540c\u65f6\u6ee1\u8db3\u6bcf\u8f6eRoI\u7ea6\u675f\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165$m$-uniform\u6295\u6807\u683c\u5f0f\u548c\u5b89\u5168\u6295\u6807\u7b56\u7565\uff0c\u5f00\u53d1\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u5b66\u4e60\u6700\u4f18\u7b56\u7565\u3002", "result": "\u7b97\u6cd5\u5728\u5728\u7ebf\u8bbe\u7f6e\u4e2d\u5b9e\u73b0\u4e9a\u7ebf\u6027\u9057\u61be\uff0c\u5b9e\u9a8c\u663e\u793a\u5b89\u5168\u7b56\u7565\u8868\u73b0\u4f18\u4e8e\u7406\u8bba\u754c\u9650\u3002", "conclusion": "\u5b89\u5168\u7b56\u7565\u5728\u5b9e\u8df5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u9002\u5408\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2506.05351", "pdf": "https://arxiv.org/pdf/2506.05351", "abs": "https://arxiv.org/abs/2506.05351", "authors": ["Rukmal Weerawarana", "Maxwell Braun"], "title": "Infinite Time Turing Machines and their Applications", "categories": ["cs.CC", "cs.AI", "cs.FL", "cs.LG"], "comment": "Published by Ren XYZ Inc", "summary": "This work establishes a rigorous theoretical foundation for analyzing deep\nlearning systems by leveraging Infinite Time Turing Machines (ITTMs), which\nextend classical computation into transfinite ordinal steps. Using ITTMs, we\nreinterpret modern architectures like Transformers, revealing fundamental\nlimitations in scalability, efficiency, and interpretability. Building on these\ninsights, we propose the Universal State Machine (USM), a novel computational\nparadigm designed from first principles. The USM employs a dynamic, queryable\ncomputation graph that evolves in real time, enabling modular, interpretable,\nand resource-efficient computation. This framework not only overcomes the\ninefficiencies and rigidity of current models but also lays the groundwork for\nscalable, generalizable artificial intelligence systems.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u65e0\u9650\u65f6\u95f4\u56fe\u7075\u673a\uff08ITTMs\uff09\u4e3a\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\u5efa\u7acb\u4e86\u4e25\u683c\u7684\u7406\u8bba\u57fa\u7840\uff0c\u63ed\u793a\u4e86Transformer\u7b49\u73b0\u4ee3\u67b6\u6784\u5728\u53ef\u6269\u5c55\u6027\u3001\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\u4e0a\u7684\u6839\u672c\u9650\u5236\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8ba1\u7b97\u8303\u5f0f\u2014\u2014\u901a\u7528\u72b6\u6001\u673a\uff08USM\uff09\u3002", "motivation": "\u4e3a\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\u63d0\u4f9b\u7406\u8bba\u652f\u6301\uff0c\u89e3\u51b3\u73b0\u6709\u6a21\u578b\u5728\u53ef\u6269\u5c55\u6027\u3001\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\u4e0a\u7684\u4e0d\u8db3\u3002", "method": "\u5229\u7528\u65e0\u9650\u65f6\u95f4\u56fe\u7075\u673a\uff08ITTMs\uff09\u5206\u6790\u73b0\u4ee3\u67b6\u6784\uff0c\u63d0\u51fa\u52a8\u6001\u53ef\u67e5\u8be2\u8ba1\u7b97\u56fe\u7684\u901a\u7528\u72b6\u6001\u673a\uff08USM\uff09\u3002", "result": "USM\u514b\u670d\u4e86\u73b0\u6709\u6a21\u578b\u7684\u4f4e\u6548\u6027\u548c\u521a\u6027\uff0c\u4e3a\u53ef\u6269\u5c55\u3001\u901a\u7528\u7684AI\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "USM\u662f\u4e00\u79cd\u521b\u65b0\u7684\u8ba1\u7b97\u8303\u5f0f\uff0c\u5177\u6709\u6a21\u5757\u5316\u3001\u53ef\u89e3\u91ca\u548c\u8d44\u6e90\u9ad8\u6548\u7684\u7279\u70b9\uff0c\u4e3a\u672a\u6765AI\u7cfb\u7edf\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2506.05354", "pdf": "https://arxiv.org/pdf/2506.05354", "abs": "https://arxiv.org/abs/2506.05354", "authors": ["Jarek Duda"], "title": "Adaptive stable distribution and Hurst exponent by method of moments moving estimator for nonstationary time series", "categories": ["stat.ME", "cs.LG", "econ.EM", "stat.ML"], "comment": "5 pages, 7 figures. arXiv admin note: text overlap with\n  arXiv:2304.03069", "summary": "Nonstationarity of real-life time series requires model adaptation. In\nclassical approaches like ARMA-ARCH there is assumed some arbitrarily chosen\ndependence type. To avoid their bias, we will focus on novel more agnostic\napproach: moving estimator, which estimates parameters separately for every\ntime $t$: optimizing $F_t=\\sum_{\\tau<t} (1-\\eta)^{t-\\tau} \\ln(\\rho_\\theta\n(x_\\tau))$ local log-likelihood with exponentially weakening weights of the old\nvalues. In practice such moving estimates can be found by EMA (exponential\nmoving average) of some parameters, like $m_p=E[|x-\\mu|^p]$ absolute central\nmoments, updated by $m_{p,t+1} = m_{p,t} + \\eta (|x_t-\\mu_t|^p-m_{p,t})$. We\nwill focus here on its applications for alpha-Stable distribution, which also\ninfluences Hurst exponent, hence can be used for its adaptive estimation. Its\napplication will be shown on financial data as DJIA time series - beside\nstandard estimation of evolution of center $\\mu$ and scale parameter $\\sigma$,\nthere is also estimated evolution of $\\alpha$ parameter allowing to\ncontinuously evaluate market stability - tails having $\\rho(x) \\sim\n1/|x|^{\\alpha+1}$ behavior, controlling probability of potentially dangerous\nextreme events.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u79fb\u52a8\u4f30\u8ba1\u5668\u7684\u975e\u53c2\u6570\u65b9\u6cd5\uff0c\u7528\u4e8e\u9002\u5e94\u975e\u5e73\u7a33\u65f6\u95f4\u5e8f\u5217\uff0c\u901a\u8fc7\u6307\u6570\u52a0\u6743\u5c40\u90e8\u5bf9\u6570\u4f3c\u7136\u4f18\u5316\u53c2\u6570\u4f30\u8ba1\uff0c\u5e76\u5e94\u7528\u4e8e\u91d1\u878d\u6570\u636e\u4e2d\u7684alpha-Stable\u5206\u5e03\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\uff08\u5982ARMA-ARCH\uff09\u5047\u8bbe\u56fa\u5b9a\u7684\u4f9d\u8d56\u7c7b\u578b\uff0c\u53ef\u80fd\u5f15\u5165\u504f\u5dee\u3002\u8bba\u6587\u65e8\u5728\u901a\u8fc7\u66f4\u7075\u6d3b\u7684\u65b9\u6cd5\u9002\u5e94\u975e\u5e73\u7a33\u65f6\u95f4\u5e8f\u5217\u7684\u52a8\u6001\u53d8\u5316\u3002", "method": "\u4f7f\u7528\u79fb\u52a8\u4f30\u8ba1\u5668\uff0c\u901a\u8fc7\u6307\u6570\u52a0\u6743\u5c40\u90e8\u5bf9\u6570\u4f3c\u7136\u4f18\u5316\u53c2\u6570\u4f30\u8ba1\uff0c\u5e76\u5229\u7528EMA\u66f4\u65b0\u7edd\u5bf9\u4e2d\u5fc3\u77e9\u7b49\u53c2\u6570\u3002\u7279\u522b\u5173\u6ce8alpha-Stable\u5206\u5e03\u7684\u5e94\u7528\u3002", "result": "\u65b9\u6cd5\u6210\u529f\u5e94\u7528\u4e8eDJIA\u91d1\u878d\u6570\u636e\uff0c\u52a8\u6001\u4f30\u8ba1\u4e86\u4e2d\u5fc3\u3001\u5c3a\u5ea6\u53c2\u6570\u548c\u03b1\u53c2\u6570\uff0c\u7528\u4e8e\u8bc4\u4f30\u5e02\u573a\u7a33\u5b9a\u6027\u548c\u6781\u7aef\u4e8b\u4ef6\u6982\u7387\u3002", "conclusion": "\u79fb\u52a8\u4f30\u8ba1\u5668\u63d0\u4f9b\u4e86\u4e00\u79cd\u7075\u6d3b\u4e14\u65e0\u504f\u7684\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u975e\u5e73\u7a33\u65f6\u95f4\u5e8f\u5217\u5206\u6790\uff0c\u5c24\u5176\u5728\u91d1\u878d\u6570\u636e\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2506.05390", "pdf": "https://arxiv.org/pdf/2506.05390", "abs": "https://arxiv.org/abs/2506.05390", "authors": ["Markelle Kelly", "Mohammad Tahaei", "Padhraic Smyth", "Lauren Wilcox"], "title": "Understanding Gender Bias in AI-Generated Product Descriptions", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted to FAccT 2025", "summary": "While gender bias in large language models (LLMs) has been extensively\nstudied in many domains, uses of LLMs in e-commerce remain largely unexamined\nand may reveal novel forms of algorithmic bias and harm. Our work investigates\nthis space, developing data-driven taxonomic categories of gender bias in the\ncontext of product description generation, which we situate with respect to\nexisting general purpose harms taxonomies. We illustrate how AI-generated\nproduct descriptions can uniquely surface gender biases in ways that require\nspecialized detection and mitigation approaches. Further, we quantitatively\nanalyze issues corresponding to our taxonomic categories in two models used for\nthis task -- GPT-3.5 and an e-commerce-specific LLM -- demonstrating that these\nforms of bias commonly occur in practice. Our results illuminate unique,\nunder-explored dimensions of gender bias, such as assumptions about clothing\nsize, stereotypical bias in which features of a product are advertised, and\ndifferences in the use of persuasive language. These insights contribute to our\nunderstanding of three types of AI harms identified by current frameworks:\nexclusionary norms, stereotyping, and performance disparities, particularly for\nthe context of e-commerce.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u7535\u5b50\u5546\u52a1\u4e2d\u751f\u6210\u4ea7\u54c1\u63cf\u8ff0\u65f6\u7684\u6027\u522b\u504f\u89c1\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u5206\u7c7b\u65b9\u6cd5\uff0c\u5e76\u5206\u6790\u4e86GPT-3.5\u548c\u7535\u5546\u4e13\u7528LLM\u4e2d\u7684\u504f\u89c1\u8868\u73b0\u3002", "motivation": "\u5c3d\u7ba1LLM\u7684\u6027\u522b\u504f\u89c1\u5728\u8bb8\u591a\u9886\u57df\u5df2\u88ab\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u5728\u7535\u5b50\u5546\u52a1\u4e2d\u7684\u5e94\u7528\u5c1a\u672a\u6df1\u5165\u63a2\u8ba8\uff0c\u53ef\u80fd\u63ed\u793a\u65b0\u7684\u7b97\u6cd5\u504f\u89c1\u548c\u5371\u5bb3\u3002", "method": "\u5f00\u53d1\u4e86\u6570\u636e\u9a71\u52a8\u7684\u6027\u522b\u504f\u89c1\u5206\u7c7b\u65b9\u6cd5\uff0c\u5e76\u5b9a\u91cf\u5206\u6790\u4e86GPT-3.5\u548c\u7535\u5546\u4e13\u7528LLM\u4e2d\u7684\u504f\u89c1\u8868\u73b0\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u7535\u5546\u573a\u666f\u4e2d\u5b58\u5728\u72ec\u7279\u7684\u6027\u522b\u504f\u89c1\uff0c\u5982\u5bf9\u670d\u88c5\u5c3a\u5bf8\u7684\u5047\u8bbe\u3001\u4ea7\u54c1\u7279\u5f81\u5e7f\u544a\u4e2d\u7684\u523b\u677f\u5370\u8c61\u4ee5\u53ca\u8bf4\u670d\u6027\u8bed\u8a00\u7684\u4f7f\u7528\u5dee\u5f02\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u7535\u5b50\u5546\u52a1\u4e2d\u672a\u5145\u5206\u63a2\u7d22\u7684\u6027\u522b\u504f\u89c1\u7ef4\u5ea6\uff0c\u8865\u5145\u4e86\u73b0\u6709AI\u5371\u5bb3\u6846\u67b6\u4e2d\u7684\u6392\u65a5\u6027\u89c4\u8303\u3001\u523b\u677f\u5370\u8c61\u548c\u6027\u80fd\u5dee\u5f02\u95ee\u9898\u3002"}}
{"id": "2506.05391", "pdf": "https://arxiv.org/pdf/2506.05391", "abs": "https://arxiv.org/abs/2506.05391", "authors": ["Ambrose Emmett-Iwaniw", "Nathan Kirk"], "title": "Enhancing Neural Autoregressive Distribution Estimators for Image Reconstruction", "categories": ["eess.IV", "cs.CV", "cs.LG", "stat.AP"], "comment": "Accepted for publication in conference proceedings, MCQMC 2024", "summary": "Autoregressive models are often employed to learn distributions of image data\nby decomposing the $D$-dimensional density function into a product of\none-dimensional conditional distributions. Each conditional depends on\npreceding variables (pixels, in the case of image data), making the order in\nwhich variables are processed fundamental to the model performance. In this\npaper, we study the problem of observing a small subset of image pixels\n(referred to as a pixel patch) to predict the unobserved parts of the image. As\nour prediction mechanism, we propose a generalized and computationally\nefficient version of the convolutional neural autoregressive distribution\nestimator (ConvNADE) model adapted for real-valued and color images. Moreover,\nwe investigate the quality of image reconstruction when observing both random\npixel patches and low-discrepancy pixel patches inspired by quasi-Monte Carlo\ntheory. Experiments on benchmark datasets demonstrate that choosing the pixels\nakin to a low-discrepancy sequence reduces test loss and produces more\nrealistic reconstructed images.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u901a\u8fc7\u89c2\u5bdf\u56fe\u50cf\u50cf\u7d20\u5b50\u96c6\u9884\u6d4b\u672a\u89c2\u6d4b\u90e8\u5206\u7684\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684ConvNADE\u6a21\u578b\uff0c\u5e76\u63a2\u8ba8\u4e86\u4e0d\u540c\u50cf\u7d20\u9009\u62e9\u7b56\u7565\u5bf9\u91cd\u5efa\u8d28\u91cf\u7684\u5f71\u54cd\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u5c11\u91cf\u50cf\u7d20\u9884\u6d4b\u56fe\u50cf\u672a\u89c2\u6d4b\u90e8\u5206\uff0c\u63d0\u5347\u81ea\u56de\u5f52\u6a21\u578b\u5728\u56fe\u50cf\u6570\u636e\u5206\u5e03\u5b66\u4e60\u4e2d\u7684\u6548\u7387\u548c\u8d28\u91cf\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684ConvNADE\u6a21\u578b\uff0c\u9002\u7528\u4e8e\u5b9e\u503c\u548c\u5f69\u8272\u56fe\u50cf\uff0c\u5e76\u6bd4\u8f83\u4e86\u968f\u673a\u50cf\u7d20\u5757\u548c\u4f4e\u5dee\u5f02\u50cf\u7d20\u5757\u5bf9\u91cd\u5efa\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528\u4f4e\u5dee\u5f02\u5e8f\u5217\u9009\u62e9\u7684\u50cf\u7d20\u80fd\u964d\u4f4e\u6d4b\u8bd5\u635f\u5931\u5e76\u751f\u6210\u66f4\u771f\u5b9e\u7684\u56fe\u50cf\u91cd\u5efa\u3002", "conclusion": "\u4f4e\u5dee\u5f02\u50cf\u7d20\u9009\u62e9\u7b56\u7565\u80fd\u6709\u6548\u63d0\u5347\u56fe\u50cf\u91cd\u5efa\u8d28\u91cf\uff0c\u6539\u8fdb\u7684ConvNADE\u6a21\u578b\u5728\u6548\u7387\u548c\u6027\u80fd\u4e0a\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2506.05393", "pdf": "https://arxiv.org/pdf/2506.05393", "abs": "https://arxiv.org/abs/2506.05393", "authors": ["Shenyang Huang", "Ali Parviz", "Emma Kondrup", "Zachary Yang", "Zifeng Ding", "Michael Bronstein", "Reihaneh Rabbany", "Guillaume Rabusseau"], "title": "Are Large Language Models Good Temporal Graph Learners?", "categories": ["cs.CL", "cs.LG"], "comment": "9 pages, 9 tables, 4 figures", "summary": "Large Language Models (LLMs) have recently driven significant advancements in\nNatural Language Processing and various other applications. While a broad range\nof literature has explored the graph-reasoning capabilities of LLMs, including\ntheir use of predictors on graphs, the application of LLMs to dynamic graphs --\nreal world evolving networks -- remains relatively unexplored. Recent work\nstudies synthetic temporal graphs generated by random graph models, but\napplying LLMs to real-world temporal graphs remains an open question. To\naddress this gap, we introduce Temporal Graph Talker (TGTalker), a novel\ntemporal graph learning framework designed for LLMs. TGTalker utilizes the\nrecency bias in temporal graphs to extract relevant structural information,\nconverted to natural language for LLMs, while leveraging temporal neighbors as\nadditional information for prediction. TGTalker demonstrates competitive link\nprediction capabilities compared to existing Temporal Graph Neural Network\n(TGNN) models. Across five real-world networks, TGTalker performs competitively\nwith state-of-the-art temporal graph methods while consistently outperforming\npopular models such as TGN and HTGN. Furthermore, TGTalker generates textual\nexplanations for each prediction, thus opening up exciting new directions in\nexplainability and interpretability for temporal link prediction. The code is\npublicly available at https://github.com/shenyangHuang/TGTalker.", "AI": {"tldr": "TGTalker\u662f\u4e00\u79cd\u65b0\u9896\u7684\u65f6\u5e8f\u56fe\u5b66\u4e60\u6846\u67b6\uff0c\u4e13\u4e3aLLMs\u8bbe\u8ba1\uff0c\u7528\u4e8e\u52a8\u6001\u56fe\u7684\u94fe\u63a5\u9884\u6d4b\uff0c\u5e76\u5728\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5c3d\u7ba1LLMs\u5728\u56fe\u63a8\u7406\u80fd\u529b\u4e0a\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u5176\u5728\u52a8\u6001\u56fe\uff08\u771f\u5b9e\u4e16\u754c\u6f14\u5316\u7f51\u7edc\uff09\u4e2d\u7684\u5e94\u7528\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002", "method": "TGTalker\u5229\u7528\u65f6\u5e8f\u56fe\u4e2d\u7684\u8fd1\u671f\u504f\u7f6e\u63d0\u53d6\u7ed3\u6784\u4fe1\u606f\uff0c\u5e76\u5c06\u5176\u8f6c\u6362\u4e3a\u81ea\u7136\u8bed\u8a00\u4f9bLLMs\u4f7f\u7528\uff0c\u540c\u65f6\u5229\u7528\u65f6\u5e8f\u90bb\u5c45\u4f5c\u4e3a\u9884\u6d4b\u7684\u989d\u5916\u4fe1\u606f\u3002", "result": "\u5728\u4e94\u4e2a\u771f\u5b9e\u4e16\u754c\u7f51\u7edc\u4e2d\uff0cTGTalker\u4e0e\u73b0\u6709TGNN\u6a21\u578b\u7ade\u4e89\uff0c\u5e76\u4f18\u4e8eTGN\u548cHTGN\uff0c\u540c\u65f6\u4e3a\u9884\u6d4b\u63d0\u4f9b\u6587\u672c\u89e3\u91ca\u3002", "conclusion": "TGTalker\u4e0d\u4ec5\u63d0\u5347\u4e86\u52a8\u6001\u56fe\u7684\u94fe\u63a5\u9884\u6d4b\u6027\u80fd\uff0c\u8fd8\u4e3a\u65f6\u5e8f\u94fe\u63a5\u9884\u6d4b\u7684\u53ef\u89e3\u91ca\u6027\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2506.05394", "pdf": "https://arxiv.org/pdf/2506.05394", "abs": "https://arxiv.org/abs/2506.05394", "authors": ["Hondamunige Prasanna Silva", "Federico Becattini", "Lorenzo Seidenari"], "title": "Attacking Attention of Foundation Models Disrupts Downstream Tasks", "categories": ["cs.CR", "cs.LG"], "comment": "Paper published at CVPR 2025 Workshop Advml", "summary": "Foundation models represent the most prominent and recent paradigm shift in\nartificial intelligence. Foundation models are large models, trained on broad\ndata that deliver high accuracy in many downstream tasks, often without\nfine-tuning. For this reason, models such as CLIP , DINO or Vision Transfomers\n(ViT), are becoming the bedrock of many industrial AI-powered applications.\nHowever, the reliance on pre-trained foundation models also introduces\nsignificant security concerns, as these models are vulnerable to adversarial\nattacks. Such attacks involve deliberately crafted inputs designed to deceive\nAI systems, jeopardizing their reliability. This paper studies the\nvulnerabilities of vision foundation models, focusing specifically on CLIP and\nViTs, and explores the transferability of adversarial attacks to downstream\ntasks. We introduce a novel attack, targeting the structure of\ntransformer-based architectures in a task-agnostic fashion. We demonstrate the\neffectiveness of our attack on several downstream tasks: classification,\ncaptioning, image/text retrieval, segmentation and depth estimation. Code\navailable at:https://github.com/HondamunigePrasannaSilva/attack-attention", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u89c6\u89c9\u57fa\u7840\u6a21\u578b\uff08\u5982CLIP\u548cViT\uff09\u7684\u5bf9\u6297\u653b\u51fb\u6f0f\u6d1e\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9Transformer\u67b6\u6784\u7684\u65b0\u578b\u653b\u51fb\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u5176\u5728\u591a\u79cd\u4e0b\u6e38\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002", "motivation": "\u57fa\u7840\u6a21\u578b\u5728AI\u5e94\u7528\u4e2d\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u5176\u5bf9\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u4f9d\u8d56\u5f15\u5165\u4e86\u5b89\u5168\u98ce\u9669\uff0c\u5c24\u5176\u662f\u5bf9\u6297\u653b\u51fb\u7684\u5a01\u80c1\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9Transformer\u67b6\u6784\u7684\u4efb\u52a1\u65e0\u5173\u653b\u51fb\u65b9\u6cd5\uff0c\u5e76\u6d4b\u8bd5\u4e86\u5176\u5728\u5206\u7c7b\u3001\u63cf\u8ff0\u3001\u68c0\u7d22\u3001\u5206\u5272\u548c\u6df1\u5ea6\u4f30\u8ba1\u7b49\u4efb\u52a1\u4e2d\u7684\u6548\u679c\u3002", "result": "\u653b\u51fb\u65b9\u6cd5\u5728\u591a\u79cd\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u9ad8\u6548\u6027\uff0c\u9a8c\u8bc1\u4e86\u57fa\u7840\u6a21\u578b\u7684\u8106\u5f31\u6027\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u57fa\u7840\u6a21\u578b\u7684\u5b89\u5168\u9690\u60a3\uff0c\u5f3a\u8c03\u4e86\u5bf9\u6297\u653b\u51fb\u7684\u6f5c\u5728\u5a01\u80c1\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u9632\u5fa1\u7b56\u7565\u63d0\u4f9b\u4e86\u53c2\u8003\u3002"}}
{"id": "2506.05402", "pdf": "https://arxiv.org/pdf/2506.05402", "abs": "https://arxiv.org/abs/2506.05402", "authors": ["Tianyu Qi", "Lei Xue", "Yufeng Zhan", "Xiaobo Ma"], "title": "Sylva: Tailoring Personalized Adversarial Defense in Pre-trained Models via Collaborative Fine-tuning", "categories": ["cs.CR", "cs.LG"], "comment": "Accepted by the ACM Conference on Computer and Communications\n  Security (CCS) 2025", "summary": "The growing adoption of large pre-trained models in edge computing has made\ndeploying model inference on mobile clients both practical and popular. These\ndevices are inherently vulnerable to direct adversarial attacks, which pose a\nsubstantial threat to the robustness and security of deployed models. Federated\nadversarial training (FAT) has emerged as an effective solution to enhance\nmodel robustness while preserving client privacy. However, FAT frequently\nproduces a generalized global model, which struggles to address the diverse and\nheterogeneous data distributions across clients, resulting in insufficiently\npersonalized performance, while also encountering substantial communication\nchallenges during the training process. In this paper, we propose\n\\textit{Sylva}, a personalized collaborative adversarial training framework\ndesigned to deliver customized defense models for each client through a\ntwo-phase process. In Phase 1, \\textit{Sylva} employs LoRA for local\nadversarial fine-tuning, enabling clients to personalize model robustness while\ndrastically reducing communication costs by uploading only LoRA parameters\nduring federated aggregation. In Phase 2, a game-based layer selection strategy\nis introduced to enhance accuracy on benign data, further refining the\npersonalized model. This approach ensures that each client receives a tailored\ndefense model that balances robustness and accuracy effectively. Extensive\nexperiments on benchmark datasets demonstrate that \\textit{Sylva} can achieve\nup to 50$\\times$ improvements in communication efficiency compared to\nstate-of-the-art algorithms, while achieving up to 29.5\\% and 50.4\\%\nenhancements in adversarial robustness and benign accuracy, respectively.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSylva\u7684\u4e2a\u6027\u5316\u534f\u4f5c\u5bf9\u6297\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8fc7\u7a0b\u4e3a\u6bcf\u4e2a\u5ba2\u6237\u7aef\u63d0\u4f9b\u5b9a\u5236\u5316\u7684\u9632\u5fa1\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u901a\u4fe1\u6548\u7387\u548c\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u8fb9\u7f18\u8ba1\u7b97\u4e2d\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u90e8\u7f72\u9762\u4e34\u5bf9\u6297\u653b\u51fb\u5a01\u80c1\uff0c\u73b0\u6709\u8054\u90a6\u5bf9\u6297\u8bad\u7ec3\uff08FAT\uff09\u65b9\u6cd5\u5728\u4e2a\u6027\u5316\u6027\u80fd\u548c\u901a\u4fe1\u6548\u7387\u4e0a\u5b58\u5728\u4e0d\u8db3\u3002", "method": "Sylva\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a1\uff09\u4f7f\u7528LoRA\u8fdb\u884c\u672c\u5730\u5bf9\u6297\u5fae\u8c03\u4ee5\u51cf\u5c11\u901a\u4fe1\u6210\u672c\uff1b2\uff09\u5f15\u5165\u57fa\u4e8e\u535a\u5f08\u8bba\u7684\u5c42\u9009\u62e9\u7b56\u7565\u4f18\u5316\u826f\u6027\u6570\u636e\u51c6\u786e\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSylva\u5728\u901a\u4fe1\u6548\u7387\u4e0a\u63d0\u534750\u500d\uff0c\u5bf9\u6297\u9c81\u68d2\u6027\u548c\u826f\u6027\u6570\u636e\u51c6\u786e\u6027\u5206\u522b\u63d0\u534729.5%\u548c50.4%\u3002", "conclusion": "Sylva\u6709\u6548\u5e73\u8861\u4e86\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u51c6\u786e\u6027\uff0c\u4e3a\u4e2a\u6027\u5316\u9632\u5fa1\u6a21\u578b\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.05408", "pdf": "https://arxiv.org/pdf/2506.05408", "abs": "https://arxiv.org/abs/2506.05408", "authors": ["Jonathan Scott", "Christoph H. Lampert", "David Saulpic"], "title": "Differentially Private Federated $k$-Means Clustering with Server-Side Data", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "Clustering is a cornerstone of data analysis that is particularly suited to\nidentifying coherent subgroups or substructures in unlabeled data, as are\ngenerated continuously in large amounts these days. However, in many cases\ntraditional clustering methods are not applicable, because data are\nincreasingly being produced and stored in a distributed way, e.g. on edge\ndevices, and privacy concerns prevent it from being transferred to a central\nserver. To address this challenge, we present \\acronym, a new algorithm for\n$k$-means clustering that is fully-federated as well as differentially private.\nOur approach leverages (potentially small and out-of-distribution) server-side\ndata to overcome the primary challenge of differentially private clustering\nmethods: the need for a good initialization. Combining our initialization with\na simple federated DP-Lloyds algorithm we obtain an algorithm that achieves\nexcellent results on synthetic and real-world benchmark tasks. We also provide\na theoretical analysis of our method that provides bounds on the convergence\nspeed and cluster identification success.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\\acronym\u7684\u8054\u90a6\u5dee\u5206\u9690\u79c1k\u5747\u503c\u805a\u7c7b\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e86\u5206\u5e03\u5f0f\u6570\u636e\u9690\u79c1\u4fdd\u62a4\u4e0b\u7684\u805a\u7c7b\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u805a\u7c7b\u65b9\u6cd5\u4e0d\u9002\u7528\u4e8e\u5206\u5e03\u5f0f\u6570\u636e\uff08\u5982\u8fb9\u7f18\u8bbe\u5907\u751f\u6210\u7684\u6570\u636e\uff09\uff0c\u4e14\u9690\u79c1\u95ee\u9898\u9650\u5236\u4e86\u6570\u636e\u96c6\u4e2d\u5904\u7406\u3002", "method": "\u7ed3\u5408\u670d\u52a1\u5668\u7aef\u6570\u636e\u521d\u59cb\u5316\uff0c\u91c7\u7528\u7b80\u5355\u7684\u8054\u90a6DP-Lloyds\u7b97\u6cd5\uff0c\u5b9e\u73b0\u9ad8\u6548\u805a\u7c7b\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u57fa\u51c6\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u63d0\u4f9b\u4e86\u6536\u655b\u901f\u5ea6\u548c\u805a\u7c7b\u6210\u529f\u7387\u7684\u7406\u8bba\u5206\u6790\u3002", "conclusion": "\\acronym\u7b97\u6cd5\u5728\u8054\u90a6\u548c\u9690\u79c1\u4fdd\u62a4\u73af\u5883\u4e0b\u6709\u6548\u89e3\u51b3\u4e86k\u5747\u503c\u805a\u7c7b\u95ee\u9898\u3002"}}
{"id": "2506.05409", "pdf": "https://arxiv.org/pdf/2506.05409", "abs": "https://arxiv.org/abs/2506.05409", "authors": ["\u00c7a\u011flar H\u0131zl\u0131", "\u00c7a\u011fatay Y\u0131ld\u0131z", "Pekka Marttinen"], "title": "Object-level Self-Distillation for Vision Pretraining", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "State-of-the-art vision pretraining methods rely on image-level\nself-distillation from object-centric datasets such as ImageNet, implicitly\nassuming each image contains a single object. This assumption does not always\nhold: many ImageNet images already contain multiple objects. Further, it limits\nscalability to scene-centric datasets that better mirror real-world complexity.\nWe address these challenges by introducing Object-level Self-DIStillation\n(ODIS), a pretraining approach that shifts the self-distillation granularity\nfrom whole images to individual objects. Using object-aware cropping and masked\nattention, ODIS isolates object-specific regions, guiding the transformer\ntoward semantically meaningful content and transforming a noisy, scene-level\ntask into simpler object-level sub-tasks. We show that this approach improves\nvisual representations both at the image and patch levels. Using masks at\ninference time, our method achieves an impressive $82.6\\%$ $k$-NN accuracy on\nImageNet1k with ViT-Large.", "AI": {"tldr": "ODIS\u662f\u4e00\u79cd\u9884\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u8c61\u7ea7\u81ea\u84b8\u998f\u6539\u8fdb\u89c6\u89c9\u8868\u793a\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5047\u8bbe\u56fe\u50cf\u4ec5\u542b\u5355\u4e00\u5bf9\u8c61\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u89c6\u89c9\u9884\u8bad\u7ec3\u65b9\u6cd5\u5047\u8bbe\u56fe\u50cf\u4ec5\u542b\u5355\u4e00\u5bf9\u8c61\uff0c\u9650\u5236\u4e86\u5176\u5728\u590d\u6742\u573a\u666f\u6570\u636e\u96c6\u4e0a\u7684\u6269\u5c55\u6027\u3002ODIS\u901a\u8fc7\u5bf9\u8c61\u7ea7\u81ea\u84b8\u998f\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "ODIS\u91c7\u7528\u5bf9\u8c61\u611f\u77e5\u88c1\u526a\u548c\u63a9\u7801\u6ce8\u610f\u529b\uff0c\u9694\u79bb\u5bf9\u8c61\u7279\u5b9a\u533a\u57df\uff0c\u5c06\u566a\u58f0\u573a\u666f\u4efb\u52a1\u8f6c\u5316\u4e3a\u7b80\u5355\u5bf9\u8c61\u7ea7\u5b50\u4efb\u52a1\u3002", "result": "ODIS\u5728ViT-Large\u4e0a\u5b9e\u73b0\u4e8682.6%\u7684k-NN\u51c6\u786e\u7387\u3002", "conclusion": "ODIS\u901a\u8fc7\u5bf9\u8c61\u7ea7\u81ea\u84b8\u998f\u663e\u8457\u63d0\u5347\u4e86\u89c6\u89c9\u8868\u793a\u80fd\u529b\uff0c\u9002\u7528\u4e8e\u590d\u6742\u573a\u666f\u6570\u636e\u3002"}}
{"id": "2506.05413", "pdf": "https://arxiv.org/pdf/2506.05413", "abs": "https://arxiv.org/abs/2506.05413", "authors": ["Patrik Czak\u00f3", "G\u00e1bor Kert\u00e9sz", "S\u00e1ndor Sz\u00e9n\u00e1si"], "title": "SmoothRot: Combining Channel-Wise Scaling and Rotation for Quantization-Friendly LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "6 pages, 3 figures, 5 tables. Submitted to the IEEE SMC 2025\n  conference", "summary": "We present SmoothRot, a novel post-training quantization technique to enhance\nthe efficiency of 4-bit quantization in Large Language Models (LLMs). SmoothRot\naddresses the critical challenge of massive activation outliers, by integrating\nchannel-wise scaling with Hadamard transformations. Our technique effectively\ntransforms extreme outliers into quantization-friendly activations,\nsignificantly improving quantization accuracy. Experiments conducted on popular\nLLMs (LLaMA2 7B, LLaMA3.1 8B, and Mistral 7B) demonstrate that SmoothRot\nconsistently reduces the performance gap between quantized and FP16 models by\napproximately 10-30\\% across language generation and zero-shot reasoning tasks,\nwithout introducing additional inference latency. Code is available at\nhttps://github.com/czakop/smoothrot.", "AI": {"tldr": "SmoothRot\u662f\u4e00\u79cd\u65b0\u9896\u7684\u540e\u8bad\u7ec3\u91cf\u5316\u6280\u672f\uff0c\u901a\u8fc7\u7ed3\u5408\u901a\u9053\u7ea7\u7f29\u653e\u548cHadamard\u53d8\u6362\uff0c\u663e\u8457\u63d0\u53474\u4f4d\u91cf\u5316\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u6548\u7387\u3002", "motivation": "\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u5927\u89c4\u6a21\u6fc0\u6d3b\u5f02\u5e38\u503c\u7684\u5173\u952e\u6311\u6218\uff0c\u4ee5\u63d0\u9ad8\u91cf\u5316\u7cbe\u5ea6\u3002", "method": "\u96c6\u6210\u901a\u9053\u7ea7\u7f29\u653e\u4e0eHadamard\u53d8\u6362\uff0c\u5c06\u6781\u7aef\u5f02\u5e38\u503c\u8f6c\u5316\u4e3a\u9002\u5408\u91cf\u5316\u7684\u6fc0\u6d3b\u3002", "result": "\u5728LLaMA2 7B\u3001LLaMA3.1 8B\u548cMistral 7B\u7b49\u6a21\u578b\u4e0a\uff0c\u91cf\u5316\u4e0eFP16\u6a21\u578b\u7684\u6027\u80fd\u5dee\u8ddd\u7f29\u5c0f\u4e8610-30%\uff0c\u4e14\u4e0d\u589e\u52a0\u63a8\u7406\u5ef6\u8fdf\u3002", "conclusion": "SmoothRot\u6709\u6548\u63d0\u5347\u4e864\u4f4d\u91cf\u5316\u7684\u51c6\u786e\u6027\uff0c\u9002\u7528\u4e8e\u8bed\u8a00\u751f\u6210\u548c\u96f6\u6837\u672c\u63a8\u7406\u4efb\u52a1\u3002"}}
{"id": "2506.05414", "pdf": "https://arxiv.org/pdf/2506.05414", "abs": "https://arxiv.org/abs/2506.05414", "authors": ["Mingfei Chen", "Zijun Cui", "Xiulong Liu", "Jinlin Xiang", "Caleb Zheng", "Jingyuan Li", "Eli Shlizerman"], "title": "SAVVY: Spatial Awareness via Audio-Visual LLMs through Seeing and Hearing", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM", "cs.SD", "eess.AS"], "comment": "Project website with demo videos: https://zijuncui02.github.io/SAVVY/", "summary": "3D spatial reasoning in dynamic, audio-visual environments is a cornerstone\nof human cognition yet remains largely unexplored by existing Audio-Visual\nLarge Language Models (AV-LLMs) and benchmarks, which predominantly focus on\nstatic or 2D scenes. We introduce SAVVY-Bench, the first benchmark for 3D\nspatial reasoning in dynamic scenes with synchronized spatial audio.\nSAVVY-Bench is comprised of thousands of relationships involving static and\nmoving objects, and requires fine-grained temporal grounding, consistent 3D\nlocalization, and multi-modal annotation. To tackle this challenge, we propose\nSAVVY, a novel training-free reasoning pipeline that consists of two stages:\n(i) Egocentric Spatial Tracks Estimation, which leverages AV-LLMs as well as\nother audio-visual methods to track the trajectories of key objects related to\nthe query using both visual and spatial audio cues, and (ii) Dynamic Global Map\nConstruction, which aggregates multi-modal queried object trajectories and\nconverts them into a unified global dynamic map. Using the constructed map, a\nfinal QA answer is obtained through a coordinate transformation that aligns the\nglobal map with the queried viewpoint. Empirical evaluation demonstrates that\nSAVVY substantially enhances performance of state-of-the-art AV-LLMs, setting a\nnew standard and stage for approaching dynamic 3D spatial reasoning in AV-LLMs.", "AI": {"tldr": "SAVVY-Bench\u662f\u9996\u4e2a\u9488\u5bf9\u52a8\u60013D\u573a\u666f\u4e2d\u7a7a\u95f4\u63a8\u7406\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7ed3\u5408\u4e86\u540c\u6b65\u7a7a\u95f4\u97f3\u9891\u3002SAVVY\u662f\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u4e24\u9636\u6bb5\u63a8\u7406\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u73b0\u6709AV-LLMs\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709AV-LLMs\u548c\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u5173\u6ce8\u9759\u6001\u62162D\u573a\u666f\uff0c\u7f3a\u4e4f\u5bf9\u52a8\u60013D\u7a7a\u95f4\u63a8\u7406\u7684\u7814\u7a76\u3002", "method": "SAVVY\u5206\u4e3a\u4e24\u9636\u6bb5\uff1a1) \u5229\u7528AV-LLMs\u548c\u5176\u4ed6\u89c6\u542c\u65b9\u6cd5\u8ddf\u8e2a\u5173\u952e\u5bf9\u8c61\u8f68\u8ff9\uff1b2) \u6784\u5efa\u5168\u5c40\u52a8\u6001\u5730\u56fe\u5e76\u901a\u8fc7\u5750\u6807\u53d8\u6362\u751f\u6210\u6700\u7ec8\u7b54\u6848\u3002", "result": "SAVVY\u663e\u8457\u63d0\u5347\u4e86\u73b0\u6709AV-LLMs\u7684\u6027\u80fd\uff0c\u4e3a\u52a8\u60013D\u7a7a\u95f4\u63a8\u7406\u8bbe\u5b9a\u4e86\u65b0\u6807\u51c6\u3002", "conclusion": "SAVVY-Bench\u548cSAVVY\u65b9\u6cd5\u586b\u8865\u4e86\u52a8\u60013D\u7a7a\u95f4\u63a8\u7406\u7684\u7a7a\u767d\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2506.05416", "pdf": "https://arxiv.org/pdf/2506.05416", "abs": "https://arxiv.org/abs/2506.05416", "authors": ["David Zagardo"], "title": "FERRET: Private Deep Learning Faster And Better Than DPSGD", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": "28 pages, 6 figures", "summary": "We revisit 1-bit gradient compression through the lens of mutual-information\ndifferential privacy (MI-DP). Building on signSGD, we propose FERRET--Fast and\nEffective Restricted Release for Ethical Training--which transmits at most one\nsign bit per parameter group with Bernoulli masking.\n  Theory: We prove each fired group leaks at most ln 2 nats; after subsampling\nwith rate s, the total privacy loss of G groups trained for T steps with firing\nprobability p is epsilon = G * T * s * p * ln 2. Thus FERRET achieves MI-DP for\nepsilon in [0.1, 2] without additive noise.\n  Practice: We evaluate three granularities--FERRET-MAX (finest), FERRET-EIGHTH\n(medium), and FERRET-2 (coarsest)--on five LLMs (137M-1.8B parameters) against\nDPSGD and Non-DP baselines. All methods trained for 1, 3, and 5 epochs.\n  Utility: Across all settings, FERRET-MAX/EIGHTH beat DPSGD's perplexity. At\nepsilon=0.5, 5 epochs: FERRET-EIGHTH achieves 3.98 perplexity vs DPSGD's 11.61\n(2.9x better), within 23% of Non-DP (3.25).\n  Privacy: MI-AUC stays at chance for FERRET-MAX/EIGHTH (~0.51), matching DPSGD\nvs Non-DP's 0.76-0.99. FERRET-2 shows higher leakage (~0.55) due to lower\nheadroom.\n  Efficiency: Stricter budgets fire fewer signs, so FERRET uses 19-33% of\nDPSGD's training time and only 34-36% of Non-DP training time.\n  Take-away: Sign-based MI-DP gets closer to achieving all three qualities of\nthe privacy, utility, performance trilemma: FERRET trains up to 5x faster,\nachieves 3x lower perplexity compared to DPSGD and 1.2x greater than Non-DP,\nall while providing formal, mathematically provable privacy guarantees using\nzero additive noise. The results also show that, in certain instances, masked\n1-bit updates can match non-private training utility while safeguarding data.", "AI": {"tldr": "FERRET\u662f\u4e00\u79cd\u57fa\u4e8e1\u4f4d\u68af\u5ea6\u538b\u7f29\u548c\u4e92\u4fe1\u606f\u5dee\u5206\u9690\u79c1\uff08MI-DP\uff09\u7684\u5feb\u901f\u6709\u6548\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7Bernoulli\u63a9\u7801\u4f20\u8f93\u7b26\u53f7\u4f4d\uff0c\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\u3001\u9ad8\u6548\u6027\u548c\u6027\u80fd\u7684\u5e73\u8861\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u5dee\u5206\u9690\u79c1\u65b9\u6cd5\uff08\u5982DPSGD\uff09\u5728\u9690\u79c1\u4fdd\u62a4\u3001\u6a21\u578b\u6027\u80fd\u548c\u8bad\u7ec3\u6548\u7387\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\uff0c\u63d0\u51fa\u4e00\u79cd\u65e0\u9700\u52a0\u6027\u566a\u58f0\u7684\u9690\u79c1\u4fdd\u62a4\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8esignSGD\uff0c\u63d0\u51faFERRET\u65b9\u6cd5\uff0c\u901a\u8fc7Bernoulli\u63a9\u7801\u4f20\u8f93\u7b26\u53f7\u4f4d\uff0c\u5206\u7ec4\u5904\u7406\u53c2\u6570\uff0c\u5e76\u7406\u8bba\u8bc1\u660e\u5176\u9690\u79c1\u635f\u5931\u4e0a\u9650\u3002", "result": "FERRET\u5728\u591a\u4e2a\u7c92\u5ea6\u4e0b\u5747\u4f18\u4e8eDPSGD\uff0c\u8bad\u7ec3\u901f\u5ea6\u66f4\u5feb\uff0819-33%\u65f6\u95f4\uff09\uff0c\u56f0\u60d1\u5ea6\u66f4\u4f4e\uff083x\uff09\uff0c\u4e14\u9690\u79c1\u4fdd\u62a4\u6548\u679c\u4e0eDPSGD\u76f8\u5f53\u3002", "conclusion": "FERRET\u5728\u9690\u79c1\u3001\u6027\u80fd\u548c\u6548\u7387\u4e09\u65b9\u9762\u53d6\u5f97\u5e73\u8861\uff0c\u8bc1\u660e\u4e861\u4f4d\u68af\u5ea6\u538b\u7f29\u5728\u9690\u79c1\u4fdd\u62a4\u8bad\u7ec3\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.05418", "pdf": "https://arxiv.org/pdf/2506.05418", "abs": "https://arxiv.org/abs/2506.05418", "authors": ["Kyungsoo Kim", "Jeongsoo Ha", "Yusung Kim"], "title": "Self-Predictive Dynamics for Generalization of Vision-based Reinforcement Learning", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "IJCAI 2022", "summary": "Vision-based reinforcement learning requires efficient and robust\nrepresentations of image-based observations, especially when the images contain\ndistracting (task-irrelevant) elements such as shadows, clouds, and light. It\nbecomes more important if those distractions are not exposed during training.\nWe design a Self-Predictive Dynamics (SPD) method to extract task-relevant\nfeatures efficiently, even in unseen observations after training. SPD uses weak\nand strong augmentations in parallel, and learns representations by predicting\ninverse and forward transitions across the two-way augmented versions. In a set\nof MuJoCo visual control tasks and an autonomous driving task (CARLA), SPD\noutperforms previous studies in complex observations, and significantly\nimproves the generalization performance for unseen observations. Our code is\navailable at https://github.com/unigary/SPD.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9884\u6d4b\u52a8\u6001\uff08SPD\uff09\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u672a\u89c1\u8fc7\u7684\u89c2\u5bdf\u4e2d\u9ad8\u6548\u63d0\u53d6\u4efb\u52a1\u76f8\u5173\u7279\u5f81\uff0c\u663e\u8457\u63d0\u5347\u6cdb\u5316\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u89c6\u89c9\u5f3a\u5316\u5b66\u4e60\u4e2d\u56fe\u50cf\u89c2\u5bdf\u4e2d\u7684\u5e72\u6270\u5143\u7d20\uff08\u5982\u9634\u5f71\u3001\u4e91\u3001\u5149\u7ebf\uff09\u5bf9\u4efb\u52a1\u65e0\u5173\u7279\u5f81\u7684\u5f71\u54cd\uff0c\u5c24\u5176\u662f\u5728\u8bad\u7ec3\u4e2d\u672a\u66b4\u9732\u8fd9\u4e9b\u5e72\u6270\u65f6\u3002", "method": "SPD\u91c7\u7528\u5f31\u589e\u5f3a\u548c\u5f3a\u589e\u5f3a\u5e76\u884c\u5904\u7406\uff0c\u901a\u8fc7\u5b66\u4e60\u53cc\u5411\u589e\u5f3a\u7248\u672c\u7684\u9006\u548c\u6b63\u5411\u8f6c\u6362\u6765\u63d0\u53d6\u7279\u5f81\u3002", "result": "\u5728MuJoCo\u89c6\u89c9\u63a7\u5236\u4efb\u52a1\u548cCARLA\u81ea\u52a8\u9a7e\u9a76\u4efb\u52a1\u4e2d\uff0cSPD\u5728\u590d\u6742\u89c2\u5bdf\u4e2d\u8868\u73b0\u4f18\u4e8e\u5148\u524d\u7814\u7a76\uff0c\u663e\u8457\u63d0\u5347\u4e86\u672a\u89c1\u89c2\u5bdf\u7684\u6cdb\u5316\u6027\u80fd\u3002", "conclusion": "SPD\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u53d6\u4efb\u52a1\u76f8\u5173\u7279\u5f81\uff0c\u63d0\u5347\u6a21\u578b\u5728\u590d\u6742\u548c\u672a\u89c1\u89c2\u5bdf\u4e2d\u7684\u6027\u80fd\u3002"}}
{"id": "2506.05422", "pdf": "https://arxiv.org/pdf/2506.05422", "abs": "https://arxiv.org/abs/2506.05422", "authors": ["Andrei T. Patrascu"], "title": "Constructive Symbolic Reinforcement Learning via Intuitionistic Logic and Goal-Chaining Inference", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "We introduce a novel learning and planning framework that replaces\ntraditional reward-based optimisation with constructive logical inference. In\nour model, actions, transitions, and goals are represented as logical\npropositions, and decision-making proceeds by building constructive proofs\nunder intuitionistic logic. This method ensures that state transitions and\npolicies are accepted only when supported by verifiable preconditions --\neschewing probabilistic trial-and-error in favour of guaranteed logical\nvalidity. We implement a symbolic agent operating in a structured gridworld,\nwhere reaching a goal requires satisfying a chain of intermediate subgoals\n(e.g., collecting keys to open doors), each governed by logical constraints.\nUnlike conventional reinforcement learning agents, which require extensive\nexploration and suffer from unsafe or invalid transitions, our constructive\nagent builds a provably correct plan through goal chaining, condition tracking,\nand knowledge accumulation. Empirical comparison with Q-learning demonstrates\nthat our method achieves perfect safety, interpretable behaviour, and efficient\nconvergence with no invalid actions, highlighting its potential for safe\nplanning, symbolic cognition, and trustworthy AI. This work presents a new\ndirection for reinforcement learning grounded not in numeric optimisation, but\nin constructive logic and proof theory.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u903b\u8f91\u63a8\u7406\u7684\u5b66\u4e60\u4e0e\u89c4\u5212\u6846\u67b6\uff0c\u66ff\u4ee3\u4f20\u7edf\u7684\u57fa\u4e8e\u5956\u52b1\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u5efa\u76f4\u89c9\u903b\u8f91\u7684\u8bc1\u660e\u5b9e\u73b0\u51b3\u7b56\uff0c\u786e\u4fdd\u72b6\u6001\u8f6c\u6362\u548c\u7b56\u7565\u7684\u903b\u8f91\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u4f9d\u8d56\u6982\u7387\u8bd5\u9519\uff0c\u53ef\u80fd\u5bfc\u81f4\u4e0d\u5b89\u5168\u6216\u65e0\u6548\u7684\u8f6c\u6362\uff0c\u800c\u672c\u6587\u65e8\u5728\u901a\u8fc7\u903b\u8f91\u63a8\u7406\u5b9e\u73b0\u5b89\u5168\u3001\u53ef\u89e3\u91ca\u4e14\u9ad8\u6548\u7684\u89c4\u5212\u3002", "method": "\u5c06\u52a8\u4f5c\u3001\u72b6\u6001\u8f6c\u6362\u548c\u76ee\u6807\u8868\u793a\u4e3a\u903b\u8f91\u547d\u9898\uff0c\u5229\u7528\u76f4\u89c9\u903b\u8f91\u6784\u5efa\u6784\u9020\u6027\u8bc1\u660e\uff0c\u786e\u4fdd\u6bcf\u4e00\u6b65\u90fd\u6709\u53ef\u9a8c\u8bc1\u7684\u524d\u63d0\u6761\u4ef6\u3002", "result": "\u5728\u7ed3\u6784\u5316\u7f51\u683c\u4e16\u754c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u96f6\u65e0\u6548\u52a8\u4f5c\u3001\u5b8c\u7f8e\u5b89\u5168\u6027\u548c\u9ad8\u6548\u6536\u655b\uff0c\u4f18\u4e8e\u4f20\u7edfQ\u5b66\u4e60\u3002", "conclusion": "\u672c\u6587\u4e3a\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u57fa\u4e8e\u6784\u9020\u903b\u8f91\u548c\u8bc1\u660e\u7406\u8bba\u7684\u65b0\u65b9\u5411\uff0c\u9002\u7528\u4e8e\u5b89\u5168\u89c4\u5212\u548c\u53ef\u4fe1AI\u3002"}}
{"id": "2506.05429", "pdf": "https://arxiv.org/pdf/2506.05429", "abs": "https://arxiv.org/abs/2506.05429", "authors": ["Ashwin Ramesh Babu", "Sajad Mousavi", "Vineet Gundecha", "Sahand Ghorbanpour", "Avisek Naug", "Antonio Guillen", "Ricardo Luna Gutierrez", "Soumyendu Sarkar"], "title": "Coordinated Robustness Evaluation Framework for Vision-Language Models", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": "Accepted: IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition Workshops (CVPRW) 2025", "summary": "Vision-language models, which integrate computer vision and natural language\nprocessing capabilities, have demonstrated significant advancements in tasks\nsuch as image captioning and visual question and answering. However, similar to\ntraditional models, they are susceptible to small perturbations, posing a\nchallenge to their robustness, particularly in deployment scenarios. Evaluating\nthe robustness of these models requires perturbations in both the vision and\nlanguage modalities to learn their inter-modal dependencies. In this work, we\ntrain a generic surrogate model that can take both image and text as input and\ngenerate joint representation which is further used to generate adversarial\nperturbations for both the text and image modalities. This coordinated attack\nstrategy is evaluated on the visual question and answering and visual reasoning\ndatasets using various state-of-the-art vision-language models. Our results\nindicate that the proposed strategy outperforms other multi-modal attacks and\nsingle-modality attacks from the recent literature. Our results demonstrate\ntheir effectiveness in compromising the robustness of several state-of-the-art\npre-trained multi-modal models such as instruct-BLIP, ViLT and others.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u7684\u66ff\u4ee3\u6a21\u578b\uff0c\u7528\u4e8e\u751f\u6210\u9488\u5bf9\u89c6\u89c9\u548c\u8bed\u8a00\u6a21\u6001\u7684\u5bf9\u6297\u6027\u6270\u52a8\uff0c\u8bc4\u4f30\u5176\u5728\u89c6\u89c9\u95ee\u7b54\u548c\u89c6\u89c9\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6548\u679c\uff0c\u7ed3\u679c\u8868\u660e\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u56fe\u50cf\u63cf\u8ff0\u548c\u89c6\u89c9\u95ee\u7b54\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u5bf9\u5fae\u5c0f\u6270\u52a8\u7684\u654f\u611f\u6027\u9650\u5236\u4e86\u5176\u9c81\u68d2\u6027\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u8054\u5408\u6270\u52a8\u8bc4\u4f30\u6a21\u578b\u7684\u8de8\u6a21\u6001\u4f9d\u8d56\u6027\u3002", "method": "\u8bad\u7ec3\u4e00\u4e2a\u901a\u7528\u7684\u66ff\u4ee3\u6a21\u578b\uff0c\u63a5\u53d7\u56fe\u50cf\u548c\u6587\u672c\u8f93\u5165\uff0c\u751f\u6210\u8054\u5408\u8868\u793a\uff0c\u5e76\u8fdb\u4e00\u6b65\u751f\u6210\u9488\u5bf9\u6587\u672c\u548c\u56fe\u50cf\u7684\u5bf9\u6297\u6027\u6270\u52a8\u3002", "result": "\u63d0\u51fa\u7684\u534f\u8c03\u653b\u51fb\u7b56\u7565\u5728\u591a\u4e2a\u5148\u8fdb\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e0a\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u591a\u6a21\u6001\u548c\u5355\u6a21\u6001\u653b\u51fb\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u63ed\u793a\u4e86\u73b0\u6709\u9884\u8bad\u7ec3\u591a\u6a21\u6001\u6a21\u578b\u7684\u9c81\u68d2\u6027\u7f3a\u9677\uff0c\u4e3a\u6a21\u578b\u6539\u8fdb\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2506.05431", "pdf": "https://arxiv.org/pdf/2506.05431", "abs": "https://arxiv.org/abs/2506.05431", "authors": ["Ashwin Ramesh Babu", "Sajad Mousavi", "Vineet Gundecha", "Sahand Ghorbanpour", "Avisek Naug", "Antonio Guillen", "Ricardo Luna Gutierrez", "Soumyendu Sarkar"], "title": "Robustness Evaluation for Video Models with Reinforcement Learning", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted at the IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition Workshops (CVPRW) 2025", "summary": "Evaluating the robustness of Video classification models is very challenging,\nspecifically when compared to image-based models. With their increased temporal\ndimension, there is a significant increase in complexity and computational\ncost. One of the key challenges is to keep the perturbations to a minimum to\ninduce misclassification. In this work, we propose a multi-agent reinforcement\nlearning approach (spatial and temporal) that cooperatively learns to identify\nthe given video's sensitive spatial and temporal regions. The agents consider\ntemporal coherence in generating fine perturbations, leading to a more\neffective and visually imperceptible attack. Our method outperforms the\nstate-of-the-art solutions on the Lp metric and the average queries. Our method\nenables custom distortion types, making the robustness evaluation more relevant\nto the use case. We extensively evaluate 4 popular models for video action\nrecognition on two popular datasets, HMDB-51 and UCF-101.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u89c6\u9891\u5206\u7c7b\u6a21\u578b\u7684\u9c81\u68d2\u6027\uff0c\u901a\u8fc7\u7a7a\u95f4\u548c\u65f6\u95f4\u6270\u52a8\u751f\u6210\u66f4\u6709\u6548\u7684\u653b\u51fb\u3002", "motivation": "\u89c6\u9891\u5206\u7c7b\u6a21\u578b\u7684\u9c81\u68d2\u6027\u8bc4\u4f30\u6bd4\u56fe\u50cf\u6a21\u578b\u66f4\u5177\u6311\u6218\u6027\uff0c\u56e0\u5176\u65f6\u95f4\u7ef4\u5ea6\u548c\u8ba1\u7b97\u590d\u6742\u6027\u589e\u52a0\uff0c\u9700\u6700\u5c0f\u5316\u6270\u52a8\u4ee5\u8bf1\u5bfc\u8bef\u5206\u7c7b\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff08\u7a7a\u95f4\u548c\u65f6\u95f4\uff09\uff0c\u534f\u540c\u5b66\u4e60\u8bc6\u522b\u89c6\u9891\u7684\u654f\u611f\u533a\u57df\uff0c\u751f\u6210\u89c6\u89c9\u4e0d\u53ef\u5bdf\u89c9\u7684\u7cbe\u7ec6\u6270\u52a8\u3002", "result": "\u5728Lp\u6307\u6807\u548c\u5e73\u5747\u67e5\u8be2\u6b21\u6570\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u652f\u6301\u81ea\u5b9a\u4e49\u5931\u771f\u7c7b\u578b\uff0c\u5e76\u5728HMDB-51\u548cUCF-101\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u4e864\u79cd\u6d41\u884c\u6a21\u578b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u89c6\u9891\u5206\u7c7b\u6a21\u578b\u9c81\u68d2\u6027\u8bc4\u4f30\u7684\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2506.05441", "pdf": "https://arxiv.org/pdf/2506.05441", "abs": "https://arxiv.org/abs/2506.05441", "authors": ["Kimberley M. Bird", "Xujiong Ye", "Alan M. Race", "James M. Brown"], "title": "Deep histological synthesis from mass spectrometry imaging for multimodal registration", "categories": ["eess.IV", "cs.CV", "cs.LG", "I.2; I.4"], "comment": "Medical Image Understanding and Analysis (MIUA) 2025 Extended\n  Abstract Submission", "summary": "Registration of histological and mass spectrometry imaging (MSI) allows for\nmore precise identification of structural changes and chemical interactions in\ntissue. With histology and MSI having entirely different image formation\nprocesses and dimensionalities, registration of the two modalities remains an\nongoing challenge. This work proposes a solution that synthesises histological\nimages from MSI, using a pix2pix model, to effectively enable unimodal\nregistration. Preliminary results show promising synthetic histology images\nwith limited artifacts, achieving increases in mutual information (MI) and\nstructural similarity index measures (SSIM) of +0.924 and +0.419, respectively,\ncompared to a baseline U-Net model. Our source code is available on GitHub:\nhttps://github.com/kimberley/MIUA2025.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8epix2pix\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u5c06\u8d28\u8c31\u6210\u50cf\uff08MSI\uff09\u5408\u6210\u4e3a\u7ec4\u7ec7\u5b66\u56fe\u50cf\uff0c\u4ee5\u5b9e\u73b0\u5355\u6a21\u6001\u914d\u51c6\uff0c\u521d\u6b65\u7ed3\u679c\u663e\u793a\u5408\u6210\u56fe\u50cf\u8d28\u91cf\u8f83\u9ad8\u3002", "motivation": "\u7ec4\u7ec7\u5b66\u548cMSI\u7684\u56fe\u50cf\u5f62\u6210\u8fc7\u7a0b\u548c\u7ef4\u5ea6\u4e0d\u540c\uff0c\u5bfc\u81f4\u4e24\u8005\u914d\u51c6\u56f0\u96be\uff0c\u9700\u8981\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528pix2pix\u6a21\u578b\u4eceMSI\u6570\u636e\u5408\u6210\u7ec4\u7ec7\u5b66\u56fe\u50cf\uff0c\u4ee5\u5b9e\u73b0\u5355\u6a21\u6001\u914d\u51c6\u3002", "result": "\u5408\u6210\u56fe\u50cf\u8d28\u91cf\u8f83\u597d\uff0c\u4e92\u4fe1\u606f\uff08MI\uff09\u548c\u7ed3\u6784\u76f8\u4f3c\u6027\u6307\u6570\uff08SSIM\uff09\u5206\u522b\u63d0\u9ad8\u4e86+0.924\u548c+0.419\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u7ec4\u7ec7\u5b66\u548cMSI\u914d\u51c6\u4e2d\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2506.05444", "pdf": "https://arxiv.org/pdf/2506.05444", "abs": "https://arxiv.org/abs/2506.05444", "authors": ["Marwane Kzadri", "Franco Alberto Cardillo", "Nan\u00e9e Chahinian", "Carole Delenne", "Renaud Hostache", "Jamal Riffi"], "title": "U-NetMN and SegNetMN: Modified U-Net and SegNet models for bimodal SAR image segmentation", "categories": ["cs.CV", "cs.LG", "eess.IV"], "comment": null, "summary": "Segmenting Synthetic Aperture Radar (SAR) images is crucial for many remote\nsensing applications, particularly water body detection. However, deep\nlearning-based segmentation models often face challenges related to convergence\nspeed and stability, mainly due to the complex statistical distribution of this\ntype of data. In this study, we evaluate the impact of mode normalization on\ntwo widely used semantic segmentation models, U-Net and SegNet. Specifically,\nwe integrate mode normalization, to reduce convergence time while maintaining\nthe performance of the baseline models. Experimental results demonstrate that\nmode normalization significantly accelerates convergence. Furthermore,\ncross-validation results indicate that normalized models exhibit increased\nstability in different zones. These findings highlight the effectiveness of\nnormalization in improving computational efficiency and generalization in SAR\nimage segmentation.", "AI": {"tldr": "\u7814\u7a76\u4e86\u6a21\u5f0f\u5f52\u4e00\u5316\u5bf9SAR\u56fe\u50cf\u5206\u5272\u6a21\u578b\uff08U-Net\u548cSegNet\uff09\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5176\u80fd\u663e\u8457\u52a0\u901f\u6536\u655b\u5e76\u63d0\u9ad8\u7a33\u5b9a\u6027\u3002", "motivation": "SAR\u56fe\u50cf\u5206\u5272\u5728\u9065\u611f\u5e94\u7528\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u56e0\u6570\u636e\u590d\u6742\u7edf\u8ba1\u5206\u5e03\u800c\u9762\u4e34\u6536\u655b\u901f\u5ea6\u548c\u7a33\u5b9a\u6027\u95ee\u9898\u3002", "method": "\u5728U-Net\u548cSegNet\u4e2d\u96c6\u6210\u6a21\u5f0f\u5f52\u4e00\u5316\uff0c\u8bc4\u4f30\u5176\u5bf9\u6536\u655b\u65f6\u95f4\u548c\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u6a21\u5f0f\u5f52\u4e00\u5316\u663e\u8457\u52a0\u901f\u6536\u655b\uff0c\u4e14\u5f52\u4e00\u5316\u6a21\u578b\u5728\u4e0d\u540c\u533a\u57df\u8868\u73b0\u66f4\u7a33\u5b9a\u3002", "conclusion": "\u5f52\u4e00\u5316\u6709\u6548\u63d0\u5347\u4e86SAR\u56fe\u50cf\u5206\u5272\u7684\u8ba1\u7b97\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2506.05449", "pdf": "https://arxiv.org/pdf/2506.05449", "abs": "https://arxiv.org/abs/2506.05449", "authors": ["Miguel Silva", "Alexandre Valle de Carvalho"], "title": "AI-powered Contextual 3D Environment Generation: A Systematic Review", "categories": ["cs.GR", "cs.CV", "cs.LG"], "comment": null, "summary": "The generation of high-quality 3D environments is crucial for industries such\nas gaming, virtual reality, and cinema, yet remains resource-intensive due to\nthe reliance on manual processes. This study performs a systematic review of\nexisting generative AI techniques for 3D scene generation, analyzing their\ncharacteristics, strengths, limitations, and potential for improvement. By\nexamining state-of-the-art approaches, it presents key challenges such as scene\nauthenticity and the influence of textual inputs. Special attention is given to\nhow AI can blend different stylistic domains while maintaining coherence, the\nimpact of training data on output quality, and the limitations of current\nmodels. In addition, this review surveys existing evaluation metrics for\nassessing realism and explores how industry professionals incorporate AI into\ntheir workflows. The findings of this study aim to provide a comprehensive\nunderstanding of the current landscape and serve as a foundation for future\nresearch on AI-driven 3D content generation. Key findings include that advanced\ngenerative architectures enable high-quality 3D content creation at a high\ncomputational cost, effective multi-modal integration techniques like\ncross-attention and latent space alignment facilitate text-to-3D tasks, and the\nquality and diversity of training data combined with comprehensive evaluation\nmetrics are critical to achieving scalable, robust 3D scene generation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u7efc\u8ff0\u4e86\u751f\u6210\u5f0fAI\u57283D\u573a\u666f\u751f\u6210\u4e2d\u7684\u5e94\u7528\uff0c\u5206\u6790\u4e86\u73b0\u6709\u6280\u672f\u7684\u4f18\u7f3a\u70b9\uff0c\u5e76\u63a2\u8ba8\u4e86\u672a\u6765\u6539\u8fdb\u65b9\u5411\u3002", "motivation": "\u9ad8\u8d28\u91cf3D\u73af\u5883\u751f\u6210\u5728\u6e38\u620f\u3001\u865a\u62df\u73b0\u5b9e\u548c\u7535\u5f71\u7b49\u884c\u4e1a\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u76ee\u524d\u4f9d\u8d56\u624b\u52a8\u6d41\u7a0b\uff0c\u8d44\u6e90\u6d88\u8017\u5927\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u56de\u987e\u73b0\u6709\u751f\u6210\u5f0fAI\u6280\u672f\uff0c\u5206\u6790\u5176\u7279\u70b9\u3001\u4f18\u52bf\u548c\u5c40\u9650\u6027\uff0c\u5e76\u63a2\u8ba8\u6539\u8fdb\u6f5c\u529b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5148\u8fdb\u751f\u6210\u67b6\u6784\u80fd\u4ee5\u9ad8\u8ba1\u7b97\u6210\u672c\u751f\u6210\u9ad8\u8d28\u91cf3D\u5185\u5bb9\uff0c\u591a\u6a21\u6001\u96c6\u6210\u6280\u672f\uff08\u5982\u4ea4\u53c9\u6ce8\u610f\u529b\u548c\u6f5c\u5728\u7a7a\u95f4\u5bf9\u9f50\uff09\u6709\u52a9\u4e8e\u6587\u672c\u52303D\u4efb\u52a1\u3002", "conclusion": "\u7814\u7a76\u4e3aAI\u9a71\u52a8\u76843D\u5185\u5bb9\u751f\u6210\u63d0\u4f9b\u4e86\u5168\u9762\u7406\u89e3\uff0c\u5e76\u6307\u51fa\u8bad\u7ec3\u6570\u636e\u8d28\u91cf\u548c\u591a\u6837\u6027\u4ee5\u53ca\u8bc4\u4f30\u6307\u6807\u5bf9\u5b9e\u73b0\u53ef\u6269\u5c55\u3001\u7a33\u5065\u76843D\u573a\u666f\u751f\u6210\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2506.05480", "pdf": "https://arxiv.org/pdf/2506.05480", "abs": "https://arxiv.org/abs/2506.05480", "authors": ["Daniel Wang", "Patrick Rim", "Tian Tian", "Alex Wong", "Ganesh Sundaramoorthi"], "title": "ODE-GS: Latent ODEs for Dynamic Scene Extrapolation with 3D Gaussian Splatting", "categories": ["cs.GR", "cs.CV", "cs.LG"], "comment": null, "summary": "We present ODE-GS, a novel method that unifies 3D Gaussian Splatting with\nlatent neural ordinary differential equations (ODEs) to forecast dynamic 3D\nscenes far beyond the time span seen during training. Existing neural rendering\nsystems - whether NeRF- or 3DGS-based - embed time directly in a deformation\nnetwork and therefore excel at interpolation but collapse when asked to predict\nthe future, where timestamps are strictly out-of-distribution. ODE-GS\neliminates this dependency: after learning a high-fidelity, time-conditioned\ndeformation model for the training window, we freeze it and train a Transformer\nencoder that summarizes past Gaussian trajectories into a latent state whose\ncontinuous evolution is governed by a neural ODE. Numerical integration of this\nlatent flow yields smooth, physically plausible Gaussian trajectories that can\nbe queried at any future instant and rendered in real time. Coupled with a\nvariational objective and a lightweight second-derivative regularizer, ODE-GS\nattains state-of-the-art extrapolation on D-NeRF and NVFI benchmarks, improving\nPSNR by up to 10 dB and halving perceptual error (LPIPS) relative to the\nstrongest baselines. Our results demonstrate that continuous-time latent\ndynamics are a powerful, practical route to photorealistic prediction of\ncomplex 3D scenes.", "AI": {"tldr": "ODE-GS\u7ed3\u54083D\u9ad8\u65af\u6cfc\u6e85\u4e0e\u6f5c\u5728\u795e\u7ecfODE\uff0c\u9884\u6d4b\u52a8\u60013D\u573a\u666f\uff0c\u8d85\u8d8a\u8bad\u7ec3\u65f6\u95f4\u8303\u56f4\uff0c\u5b9e\u73b0\u9ad8\u4fdd\u771f\u5916\u63a8\u3002", "motivation": "\u73b0\u6709\u795e\u7ecf\u6e32\u67d3\u7cfb\u7edf\uff08\u5982NeRF\u62163DGS\uff09\u5728\u65f6\u95f4\u9884\u6d4b\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0cODE-GS\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u51bb\u7ed3\u65f6\u95f4\u6761\u4ef6\u53d8\u5f62\u6a21\u578b\uff0c\u8bad\u7ec3Transformer\u7f16\u7801\u5668\u603b\u7ed3\u9ad8\u65af\u8f68\u8ff9\uff0c\u5229\u7528\u795e\u7ecfODE\u63a7\u5236\u6f5c\u5728\u72b6\u6001\u6f14\u5316\u3002", "result": "\u5728D-NeRF\u548cNVFI\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cPSNR\u63d0\u5347\u8fbe10 dB\uff0cLPIPS\u51cf\u534a\uff0c\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u3002", "conclusion": "ODE-GS\u8bc1\u660e\u8fde\u7eed\u65f6\u95f4\u6f5c\u5728\u52a8\u529b\u5b66\u662f\u9884\u6d4b\u590d\u67423D\u573a\u666f\u7684\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2506.05490", "pdf": "https://arxiv.org/pdf/2506.05490", "abs": "https://arxiv.org/abs/2506.05490", "authors": ["Mohammed Almutairi"], "title": "Sentiment Analysis in Learning Management Systems Understanding Student Feedback at Scale", "categories": ["cs.HC", "cs.AI", "cs.LG"], "comment": "10 pages, 10 figures", "summary": "During the wake of the Covid-19 pandemic, the educational paradigm has\nexperienced a major change from in person learning traditional to online\nplatforms. The change of learning convention has impacted the teacher-student\nespecially in non-verbal communication. The absent of non-verbal communication\nhas led to a reliance on verbal feedback which diminished the efficacy of the\neducational experience. This paper explores the integration of sentiment\nanalysis into learning management systems (LMS) to bridge the student-teacher's\ngap by offering an alternative approach to interpreting student feedback beyond\nits verbal context. The research involves data preparation, feature selection,\nand the development of a deep neural network model encompassing word embedding,\nLSTM, and attention mechanisms. This model is compared against a logistic\nregression baseline to evaluate its efficacy in understanding student feedback.\nThe study aims to bridge the communication gap between instructors and students\nin online learning environments, offering insights into the emotional context\nof student feedback and ultimately improving the quality of online education.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u65b0\u51a0\u75ab\u60c5\u540e\u6559\u80b2\u8f6c\u5411\u5728\u7ebf\u5e73\u53f0\u65f6\uff0c\u5982\u4f55\u901a\u8fc7\u60c5\u611f\u5206\u6790\u5f25\u8865\u5e08\u751f\u975e\u8bed\u8a00\u6c9f\u901a\u7684\u7f3a\u5931\uff0c\u63d0\u5347\u6559\u80b2\u4f53\u9a8c\u3002", "motivation": "\u75ab\u60c5\u5bfc\u81f4\u6559\u80b2\u8f6c\u5411\u5728\u7ebf\u5e73\u53f0\uff0c\u975e\u8bed\u8a00\u6c9f\u901a\u7f3a\u5931\uff0c\u4f9d\u8d56\u8bed\u8a00\u53cd\u9988\u964d\u4f4e\u4e86\u6559\u80b2\u6548\u679c\u3002", "method": "\u7814\u7a76\u7ed3\u5408\u6570\u636e\u51c6\u5907\u3001\u7279\u5f81\u9009\u62e9\u548c\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff08\u542b\u8bcd\u5d4c\u5165\u3001LSTM\u548c\u6ce8\u610f\u529b\u673a\u5236\uff09\uff0c\u5e76\u4e0e\u903b\u8f91\u56de\u5f52\u57fa\u7ebf\u6a21\u578b\u5bf9\u6bd4\u3002", "result": "\u6a21\u578b\u65e8\u5728\u901a\u8fc7\u60c5\u611f\u5206\u6790\u7406\u89e3\u5b66\u751f\u53cd\u9988\u7684\u60c5\u611f\u80cc\u666f\uff0c\u5f25\u8865\u5e08\u751f\u6c9f\u901a\u5dee\u8ddd\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5728\u7ebf\u6559\u80b2\u63d0\u4f9b\u4e86\u6539\u8fdb\u5e08\u751f\u6c9f\u901a\u7684\u65b0\u65b9\u6cd5\uff0c\u63d0\u5347\u6559\u80b2\u8d28\u91cf\u3002"}}
{"id": "2506.05495", "pdf": "https://arxiv.org/pdf/2506.05495", "abs": "https://arxiv.org/abs/2506.05495", "authors": ["Vladimir Braverman", "Jon C. Ergun", "Chen Wang", "Samson Zhou"], "title": "Learning-Augmented Hierarchical Clustering", "categories": ["cs.DS", "cs.LG"], "comment": "ICML 2025; abstract shortened for arxiv requirements", "summary": "Hierarchical clustering (HC) is an important data analysis technique in which\nthe goal is to recursively partition a dataset into a tree-like structure while\ngrouping together similar data points at each level of granularity.\nUnfortunately, for many of the proposed HC objectives, there exist strong\nbarriers to approximation algorithms with the hardness of approximation. Thus,\nwe consider the problem of hierarchical clustering given auxiliary information\nfrom natural oracles. Specifically, we focus on a *splitting oracle* which,\nwhen provided with a triplet of vertices $(u,v,w)$, answers (possibly\nerroneously) the pairs of vertices whose lowest common ancestor includes all\nthree vertices in an optimal tree, i.e., identifying which vertex ``splits\naway'' from the others. Using such an oracle, we obtain the following results:\n  - A polynomial-time algorithm that outputs a hierarchical clustering tree\nwith $O(1)$-approximation to the Dasgupta objective (Dasgupta [STOC'16]).\n  - A near-linear time algorithm that outputs a hierarchical clustering tree\nwith $(1-o(1))$-approximation to the Moseley-Wang objective (Moseley and Wang\n[NeurIPS'17]).\n  Under the plausible Small Set Expansion Hypothesis, no polynomial-time\nalgorithm can achieve any constant approximation for Dasgupta's objective or\n$(1-C)$-approximation for the Moseley-Wang objective for some constant $C>0$.\nAs such, our results demonstrate that the splitting oracle enables algorithms\nto outperform standard HC approaches and overcome hardness constraints.\nFurthermore, our approaches extend to sublinear settings, in which we show new\nstreaming and PRAM algorithms for HC with improved guarantees.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5206\u88c2\u9884\u8a00\u673a\u8f85\u52a9\u7684\u5c42\u6b21\u805a\u7c7b\u7b97\u6cd5\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u8fd1\u4f3c\u56f0\u96be\uff0c\u5e76\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u548c\u8fd1\u7ebf\u6027\u65f6\u95f4\u5185\u5b9e\u73b0\u4e86\u5bf9Dasgupta\u548cMoseley-Wang\u76ee\u6807\u7684\u8fd1\u4f3c\u4f18\u5316\u3002", "motivation": "\u4f20\u7edf\u5c42\u6b21\u805a\u7c7b\u76ee\u6807\u5b58\u5728\u8fd1\u4f3c\u7b97\u6cd5\u7684\u786c\u6027\u9650\u5236\uff0c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u5f15\u5165\u5206\u88c2\u9884\u8a00\u673a\u8f85\u52a9\uff0c\u7a81\u7834\u8fd9\u4e9b\u9650\u5236\u3002", "method": "\u5229\u7528\u5206\u88c2\u9884\u8a00\u673a\u63d0\u4f9b\u7684\u8f85\u52a9\u4fe1\u606f\uff0c\u8bbe\u8ba1\u591a\u9879\u5f0f\u65f6\u95f4\u548c\u8fd1\u7ebf\u6027\u65f6\u95f4\u7b97\u6cd5\uff0c\u5206\u522b\u4f18\u5316Dasgupta\u548cMoseley-Wang\u76ee\u6807\u3002", "result": "\u7b97\u6cd5\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u5b9e\u73b0\u4e86Dasgupta\u76ee\u6807\u7684O(1)\u8fd1\u4f3c\uff0c\u5728\u8fd1\u7ebf\u6027\u65f6\u95f4\u5185\u5b9e\u73b0\u4e86Moseley-Wang\u76ee\u6807\u7684(1-o(1))\u8fd1\u4f3c\u3002", "conclusion": "\u5206\u88c2\u9884\u8a00\u673a\u80fd\u591f\u5e2e\u52a9\u7b97\u6cd5\u8d85\u8d8a\u4f20\u7edf\u5c42\u6b21\u805a\u7c7b\u65b9\u6cd5\u7684\u9650\u5236\uff0c\u5e76\u5728\u5b50\u7ebf\u6027\u8bbe\u7f6e\u4e0b\u6269\u5c55\u5e94\u7528\u3002"}}
{"id": "2506.05498", "pdf": "https://arxiv.org/pdf/2506.05498", "abs": "https://arxiv.org/abs/2506.05498", "authors": ["Niruthiha Selvanayagam"], "title": "Multidimensional Analysis of Specific Language Impairment Using Unsupervised Learning Through PCA and Clustering", "categories": ["cs.CL", "cs.LG", "62H30, 62P10", "I.2.7; J.3"], "comment": "14 pages, 3 figures, 16 tables", "summary": "Specific Language Impairment (SLI) affects approximately 7 percent of\nchildren, presenting as isolated language deficits despite normal cognitive\nabilities, sensory systems, and supportive environments. Traditional diagnostic\napproaches often rely on standardized assessments, which may overlook subtle\ndevelopmental patterns. This study aims to identify natural language\ndevelopment trajectories in children with and without SLI using unsupervised\nmachine learning techniques, providing insights for early identification and\ntargeted interventions. Narrative samples from 1,163 children aged 4-16 years\nacross three corpora (Conti-Ramsden 4, ENNI, and Gillam) were analyzed using\nPrincipal Component Analysis (PCA) and clustering. A total of 64 linguistic\nfeatures were evaluated to uncover developmental trajectories and distinguish\nlinguistic profiles. Two primary clusters emerged: (1) high language production\nwith low SLI prevalence, and (2) limited production but higher syntactic\ncomplexity with higher SLI prevalence. Additionally, boundary cases exhibited\nintermediate traits, supporting a continuum model of language abilities.\nFindings suggest SLI manifests primarily through reduced production capacity\nrather than syntactic complexity deficits. The results challenge categorical\ndiagnostic frameworks and highlight the potential of unsupervised learning\ntechniques for refining diagnostic criteria and intervention strategies.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u7528\u65e0\u76d1\u7763\u673a\u5668\u5b66\u4e60\u6280\u672f\u5206\u6790\u7279\u5b9a\u8bed\u8a00\u969c\u788d\uff08SLI\uff09\u513f\u7ae5\u7684\u81ea\u7136\u8bed\u8a00\u53d1\u5c55\u8f68\u8ff9\uff0c\u53d1\u73b0SLI\u4e3b\u8981\u8868\u73b0\u4e3a\u8bed\u8a00\u4ea7\u51fa\u80fd\u529b\u964d\u4f4e\u800c\u975e\u53e5\u6cd5\u590d\u6742\u6027\u7f3a\u9677\u3002", "motivation": "\u4f20\u7edf\u6807\u51c6\u5316\u8bc4\u4f30\u53ef\u80fd\u5ffd\u7565SLI\u7684\u7ec6\u5fae\u53d1\u5c55\u6a21\u5f0f\uff0c\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u65e0\u76d1\u7763\u5b66\u4e60\u6280\u672f\u63d0\u4f9b\u65e9\u671f\u8bc6\u522b\u548c\u5e72\u9884\u7684\u89c1\u89e3\u3002", "method": "\u5206\u67901,163\u540d4-16\u5c81\u513f\u7ae5\u7684\u53d9\u4e8b\u6837\u672c\uff0c\u4f7f\u7528\u4e3b\u6210\u5206\u5206\u6790\uff08PCA\uff09\u548c\u805a\u7c7b\u6280\u672f\u8bc4\u4f3064\u79cd\u8bed\u8a00\u7279\u5f81\u3002", "result": "\u53d1\u73b0\u4e24\u4e2a\u4e3b\u8981\u805a\u7c7b\uff1a\u9ad8\u8bed\u8a00\u4ea7\u51fa\u4f4eSLI\u60a3\u75c5\u7387\u7ec4\u548c\u4f4e\u4ea7\u51fa\u9ad8\u53e5\u6cd5\u590d\u6742\u6027\u9ad8SLI\u60a3\u75c5\u7387\u7ec4\uff0c\u652f\u6301\u8bed\u8a00\u80fd\u529b\u7684\u8fde\u7eed\u6a21\u578b\u3002", "conclusion": "\u7814\u7a76\u6311\u6218\u4e86\u5206\u7c7b\u8bca\u65ad\u6846\u67b6\uff0c\u5f3a\u8c03\u65e0\u76d1\u7763\u5b66\u4e60\u6280\u672f\u5728\u4f18\u5316\u8bca\u65ad\u6807\u51c6\u548c\u5e72\u9884\u7b56\u7565\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.05516", "pdf": "https://arxiv.org/pdf/2506.05516", "abs": "https://arxiv.org/abs/2506.05516", "authors": ["Boyuan Deng", "Luca Rossini", "Jin Wang", "Weijie Wang", "Nikolaos Tsagarakis"], "title": "Learning to Recover: Dynamic Reward Shaping with Wheel-Leg Coordination for Fallen Robots", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "Adaptive recovery from fall incidents are essential skills for the practical\ndeployment of wheeled-legged robots, which uniquely combine the agility of legs\nwith the speed of wheels for rapid recovery. However, traditional methods\nrelying on preplanned recovery motions, simplified dynamics or sparse rewards\noften fail to produce robust recovery policies. This paper presents a\nlearning-based framework integrating Episode-based Dynamic Reward Shaping and\ncurriculum learning, which dynamically balances exploration of diverse recovery\nmaneuvers with precise posture refinement. An asymmetric actor-critic\narchitecture accelerates training by leveraging privileged information in\nsimulation, while noise-injected observations enhance robustness against\nuncertainties. We further demonstrate that synergistic wheel-leg coordination\nreduces joint torque consumption by 15.8% and 26.2% and improves stabilization\nthrough energy transfer mechanisms. Extensive evaluations on two distinct\nquadruped platforms achieve recovery success rates up to 99.1% and 97.8%\nwithout platform-specific tuning. The supplementary material is available at\nhttps://boyuandeng.github.io/L2R-WheelLegCoordination/", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u7ed3\u5408\u52a8\u6001\u5956\u52b1\u8c03\u6574\u548c\u8bfe\u7a0b\u5b66\u4e60\uff0c\u7528\u4e8e\u8f6e\u817f\u673a\u5668\u4eba\u7684\u81ea\u9002\u5e94\u8dcc\u5012\u6062\u590d\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6062\u590d\u6210\u529f\u7387\u548c\u80fd\u6548\u3002", "motivation": "\u8f6e\u817f\u673a\u5668\u4eba\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u9700\u8981\u5177\u5907\u81ea\u9002\u5e94\u8dcc\u5012\u6062\u590d\u80fd\u529b\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u56e0\u4f9d\u8d56\u9884\u89c4\u5212\u52a8\u4f5c\u6216\u7b80\u5316\u52a8\u529b\u5b66\u800c\u96be\u4ee5\u751f\u6210\u9c81\u68d2\u7684\u6062\u590d\u7b56\u7565\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u60c5\u8282\u7684\u52a8\u6001\u5956\u52b1\u8c03\u6574\u548c\u8bfe\u7a0b\u5b66\u4e60\uff0c\u7ed3\u5408\u975e\u5bf9\u79f0\u6f14\u5458-\u8bc4\u8bba\u5bb6\u67b6\u6784\u548c\u566a\u58f0\u6ce8\u5165\u89c2\u6d4b\uff0c\u4ee5\u52a0\u901f\u8bad\u7ec3\u5e76\u589e\u5f3a\u9c81\u68d2\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4e24\u79cd\u56db\u8db3\u5e73\u53f0\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u8fbe99.1%\u548c97.8%\u7684\u6062\u590d\u6210\u529f\u7387\uff0c\u540c\u65f6\u964d\u4f4e\u4e86\u5173\u8282\u626d\u77e9\u6d88\u8017\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u8f6e\u817f\u534f\u540c\u548c\u80fd\u91cf\u8f6c\u79fb\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6062\u590d\u6027\u80fd\u548c\u80fd\u6548\uff0c\u9002\u7528\u4e8e\u4e0d\u540c\u5e73\u53f0\u4e14\u65e0\u9700\u7279\u5b9a\u8c03\u4f18\u3002"}}
{"id": "2506.05523", "pdf": "https://arxiv.org/pdf/2506.05523", "abs": "https://arxiv.org/abs/2506.05523", "authors": ["Zikui Cai", "Andrew Wang", "Anirudh Satheesh", "Ankit Nakhawa", "Hyunwoo Jae", "Keenan Powell", "Minghui Liu", "Neel Jay", "Sungbin Oh", "Xiyao Wang", "Yongyuan Liang", "Tom Goldstein", "Furong Huang"], "title": "MORSE-500: A Programmatically Controllable Video Benchmark to Stress-Test Multimodal Reasoning", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Despite rapid advances in vision-language models (VLMs), current benchmarks\nfor multimodal reasoning fall short in three key dimensions. First, they\noverwhelmingly rely on static images, failing to capture the temporal\ncomplexity of real-world environments. Second, they narrowly focus on\nmathematical problem-solving, neglecting the broader spectrum of reasoning\nskills -- including abstract, physical, planning, spatial, and temporal\ncapabilities -- required for robust multimodal intelligence. Third, many\nbenchmarks quickly saturate, offering limited headroom for diagnosing failure\nmodes or measuring continued progress. We introduce MORSE-500 (Multimodal\nReasoning Stress-test Environment), a video benchmark composed of 500 fully\nscripted clips with embedded questions spanning six complementary reasoning\ncategories. Each instance is programmatically generated using deterministic\nPython scripts (via Manim, Matplotlib, MoviePy), generative video models, and\ncurated real footage. This script-driven design allows fine-grained control\nover visual complexity, distractor density, and temporal dynamics -- enabling\ndifficulty to be scaled systematically as models improve. Unlike static\nbenchmarks that become obsolete once saturated, MORSE-500 is built to evolve:\nits controllable generation pipeline supports the creation of arbitrarily\nchallenging new instances, making it ideally suited for stress-testing\nnext-generation models. Initial experiments with state-of-the-art systems --\nincluding various Gemini 2.5 Pro and OpenAI o3 which represent the strongest\navailable at the time, alongside strong open-source models -- reveal\nsubstantial performance gaps across all categories, with particularly large\ndeficits in abstract and planning tasks. We release the full dataset,\ngeneration scripts, and evaluation harness to support transparent,\nreproducible, and forward-looking multimodal reasoning research.", "AI": {"tldr": "MORSE-500\u662f\u4e00\u4e2a\u65b0\u7684\u89c6\u9891\u57fa\u51c6\u6d4b\u8bd5\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u8bc4\u6d4b\u5728\u65f6\u95f4\u590d\u6742\u6027\u3001\u591a\u7ef4\u5ea6\u63a8\u7406\u80fd\u529b\u548c\u53ef\u6269\u5c55\u6027\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u8bc4\u6d4b\u57fa\u51c6\u8fc7\u4e8e\u4f9d\u8d56\u9759\u6001\u56fe\u50cf\uff0c\u5c40\u9650\u4e8e\u6570\u5b66\u95ee\u9898\u89e3\u51b3\uff0c\u4e14\u5bb9\u6613\u9971\u548c\uff0c\u65e0\u6cd5\u5168\u9762\u8bc4\u4f30\u591a\u6a21\u6001\u63a8\u7406\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u7a0b\u5e8f\u5316\u751f\u6210500\u4e2a\u811a\u672c\u89c6\u9891\u7247\u6bb5\uff0c\u6db5\u76d6\u516d\u7c7b\u63a8\u7406\u95ee\u9898\uff0c\u5229\u7528Python\u811a\u672c\u3001\u751f\u6210\u89c6\u9891\u6a21\u578b\u548c\u771f\u5b9e\u7d20\u6750\uff0c\u5b9e\u73b0\u96be\u5ea6\u53ef\u63a7\u7684\u52a8\u6001\u8bc4\u6d4b\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u5f53\u524d\u6700\u5148\u8fdb\u6a21\u578b\u5728\u62bd\u8c61\u548c\u89c4\u5212\u4efb\u52a1\u4e0a\u8868\u73b0\u663e\u8457\u4e0d\u8db3\u3002", "conclusion": "MORSE-500\u4e3a\u591a\u6a21\u6001\u63a8\u7406\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u900f\u660e\u7684\u8bc4\u6d4b\u5de5\u5177\uff0c\u652f\u6301\u672a\u6765\u6a21\u578b\u7684\u6301\u7eed\u6539\u8fdb\u3002"}}
{"id": "2506.05529", "pdf": "https://arxiv.org/pdf/2506.05529", "abs": "https://arxiv.org/abs/2506.05529", "authors": ["Rodney Sanchez", "Ferat Sahin", "Alexander Ororbia", "Jamison Heard"], "title": "Avoiding Death through Fear Intrinsic Conditioning", "categories": ["cs.AI", "cs.LG", "I.2.0; I.2.8"], "comment": null, "summary": "Biological and psychological concepts have inspired reinforcement learning\nalgorithms to create new complex behaviors that expand agents' capacity. These\nbehaviors can be seen in the rise of techniques like goal decomposition,\ncurriculum, and intrinsic rewards, which have paved the way for these complex\nbehaviors. One limitation in evaluating these methods is the requirement for\nengineered extrinsic for realistic environments. A central challenge in\nengineering the necessary reward function(s) comes from these environments\ncontaining states that carry high negative rewards, but provide no feedback to\nthe agent. Death is one such stimuli that fails to provide direct feedback to\nthe agent. In this work, we introduce an intrinsic reward function inspired by\nearly amygdala development and produce this intrinsic reward through a novel\nmemory-augmented neural network (MANN) architecture. We show how this intrinsic\nmotivation serves to deter exploration of terminal states and results in\navoidance behavior similar to fear conditioning observed in animals.\nFurthermore, we demonstrate how modifying a threshold where the fear response\nis active produces a range of behaviors that are described under the paradigm\nof general anxiety disorders (GADs). We demonstrate this behavior in the\nMiniworld Sidewalk environment, which provides a partially observable Markov\ndecision process (POMDP) and a sparse reward with a non-descriptive terminal\ncondition, i.e., death. In effect, this study results in a\nbiologically-inspired neural architecture and framework for fear conditioning\nparadigms; we empirically demonstrate avoidance behavior in a constructed agent\nthat is able to solve environments with non-descriptive terminal conditions.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53d7\u65e9\u671f\u674f\u4ec1\u6838\u53d1\u80b2\u542f\u53d1\u7684\u5185\u5728\u5956\u52b1\u51fd\u6570\uff0c\u901a\u8fc7\u65b0\u578b\u8bb0\u5fc6\u589e\u5f3a\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u5b9e\u73b0\uff0c\u7528\u4e8e\u907f\u514d\u7ec8\u7aef\u72b6\u6001\uff08\u5982\u6b7b\u4ea1\uff09\u7684\u63a2\u7d22\uff0c\u5e76\u5728Miniworld Sidewalk\u73af\u5883\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u8bc4\u4f30\u65f6\u9700\u8981\u8bbe\u8ba1\u5916\u90e8\u5956\u52b1\u51fd\u6570\uff0c\u4f46\u67d0\u4e9b\u73af\u5883\uff08\u5982\u5305\u542b\u6b7b\u4ea1\u72b6\u6001\uff09\u65e0\u6cd5\u63d0\u4f9b\u76f4\u63a5\u53cd\u9988\uff0c\u9650\u5236\u4e86\u7b97\u6cd5\u7684\u9002\u7528\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u674f\u4ec1\u6838\u53d1\u80b2\u542f\u53d1\u7684\u5185\u5728\u5956\u52b1\u51fd\u6570\uff0c\u5e76\u901a\u8fc7\u8bb0\u5fc6\u589e\u5f3a\u795e\u7ecf\u7f51\u7edc\uff08MANN\uff09\u67b6\u6784\u5b9e\u73b0\uff0c\u8c03\u6574\u6050\u60e7\u53cd\u5e94\u7684\u9608\u503c\u4ee5\u6a21\u62df\u5e7f\u6cdb\u6027\u7126\u8651\u969c\u788d\uff08GADs\uff09\u884c\u4e3a\u3002", "result": "\u5728Miniworld Sidewalk\u73af\u5883\u4e2d\uff0c\u8be5\u65b9\u6cd5\u6210\u529f\u5b9e\u73b0\u4e86\u7c7b\u4f3c\u52a8\u7269\u6050\u60e7\u6761\u4ef6\u7684\u56de\u907f\u884c\u4e3a\uff0c\u5e76\u80fd\u89e3\u51b3\u975e\u63cf\u8ff0\u6027\u7ec8\u7aef\u6761\u4ef6\u7684\u73af\u5883\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u79cd\u751f\u7269\u542f\u53d1\u7684\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u548c\u6050\u60e7\u6761\u4ef6\u8303\u5f0f\u6846\u67b6\uff0c\u4e3a\u5904\u7406\u975e\u63cf\u8ff0\u6027\u7ec8\u7aef\u72b6\u6001\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.05544", "pdf": "https://arxiv.org/pdf/2506.05544", "abs": "https://arxiv.org/abs/2506.05544", "authors": ["Shibo Li", "Yao Zheng"], "title": "Online Conformal Model Selection for Nonstationary Time Series", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "This paper introduces the MPS (Model Prediction Set), a novel framework for\nonline model selection for nonstationary time series. Classical model selection\nmethods, such as information criteria and cross-validation, rely heavily on the\nstationarity assumption and often fail in dynamic environments which undergo\ngradual or abrupt changes over time. Yet real-world data are rarely stationary,\nand model selection under nonstationarity remains a largely open problem. To\ntackle this challenge, we combine conformal inference with model confidence\nsets to develop a procedure that adaptively selects models best suited to the\nevolving dynamics at any given time. Concretely, the MPS updates in real time a\nconfidence set of candidate models that covers the best model for the next time\nperiod with a specified long-run probability, while adapting to nonstationarity\nof unknown forms. Through simulations and real-world data analysis, we\ndemonstrate that MPS reliably and efficiently identifies optimal models under\nnonstationarity, an essential capability lacking in offline methods. Moreover,\nMPS frequently produces high-quality sets with small cardinality, whose\nevolution offers deeper insights into changing dynamics. As a generic\nframework, MPS accommodates any data-generating process, data structure, model\nclass, training method, and evaluation metric, making it broadly applicable\nacross diverse problem settings.", "AI": {"tldr": "MPS\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u5171\u5f62\u63a8\u65ad\u548c\u6a21\u578b\u7f6e\u4fe1\u96c6\uff0c\u5b9e\u73b0\u5728\u7ebf\u975e\u5e73\u7a33\u65f6\u95f4\u5e8f\u5217\u7684\u6a21\u578b\u9009\u62e9\uff0c\u9002\u5e94\u52a8\u6001\u53d8\u5316\u3002", "motivation": "\u4f20\u7edf\u6a21\u578b\u9009\u62e9\u65b9\u6cd5\u4f9d\u8d56\u5e73\u7a33\u6027\u5047\u8bbe\uff0c\u65e0\u6cd5\u9002\u5e94\u975e\u5e73\u7a33\u6570\u636e\uff0c\u800c\u73b0\u5b9e\u6570\u636e\u591a\u4e3a\u975e\u5e73\u7a33\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408\u5171\u5f62\u63a8\u65ad\u548c\u6a21\u578b\u7f6e\u4fe1\u96c6\uff0c\u5b9e\u65f6\u66f4\u65b0\u5019\u9009\u6a21\u578b\u96c6\uff0c\u786e\u4fdd\u8986\u76d6\u6700\u4f18\u6a21\u578b\u3002", "result": "MPS\u5728\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u4e2d\u53ef\u9760\u9ad8\u6548\u5730\u8bc6\u522b\u6700\u4f18\u6a21\u578b\uff0c\u4e14\u751f\u6210\u9ad8\u8d28\u91cf\u5c0f\u89c4\u6a21\u6a21\u578b\u96c6\u3002", "conclusion": "MPS\u662f\u4e00\u79cd\u901a\u7528\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u6570\u636e\u7ed3\u6784\u548c\u6a21\u578b\uff0c\u4e3a\u975e\u5e73\u7a33\u73af\u5883\u63d0\u4f9b\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.05556", "pdf": "https://arxiv.org/pdf/2506.05556", "abs": "https://arxiv.org/abs/2506.05556", "authors": ["Stefano Fiscale", "Laura Inno", "Alessandra Rotundi", "Angelo Ciaramella", "Alessio Ferone", "Christian Magliano", "Luca Cacciapuoti", "Veselin Kostov", "Elisa Quintana", "Giovanni Covone", "Maria Teresa Muscari Tomajoli", "Vito Saggese", "Luca Tonietti", "Antonio Vanzanella", "Vincenzo Della Corte"], "title": "DART-Vetter: A Deep LeARning Tool for automatic triage of exoplanet candidates", "categories": ["astro-ph.EP", "astro-ph.IM", "cs.LG"], "comment": "Number of pages: 24, Number of figures: 8, Article accepted for\n  publication in The Astronomical Journal on 2025-05-30", "summary": "In the identification of new planetary candidates in transit surveys, the\nemployment of Deep Learning models proved to be essential to efficiently\nanalyse a continuously growing volume of photometric observations. To further\nimprove the robustness of these models, it is necessary to exploit the\ncomplementarity of data collected from different transit surveys such as NASA's\nKepler, Transiting Exoplanet Survey Satellite (TESS), and, in the near future,\nthe ESA PLAnetary Transits and Oscillation of stars (PLATO) mission. In this\nwork, we present a Deep Learning model, named DART-Vetter, able to distinguish\nplanetary candidates (PC) from false positives signals (NPC) detected by any\npotential transiting survey. DART-Vetter is a Convolutional Neural Network that\nprocesses only the light curves folded on the period of the relative signal,\nfeaturing a simpler and more compact architecture with respect to other\ntriaging and/or vetting models available in the literature. We trained and\ntested DART-Vetter on several dataset of publicly available and homogeneously\nlabelled TESS and Kepler light curves in order to prove the effectiveness of\nour model. Despite its simplicity, DART-Vetter achieves highly competitive\ntriaging performance, with a recall rate of 91% on an ensemble of TESS and\nKepler data, when compared to Exominer and Astronet-Triage. Its compact, open\nsource and easy to replicate architecture makes DART-Vetter a particularly\nuseful tool for automatizing triaging procedures or assisting human vetters,\nshowing a discrete generalization on TCEs with Multiple Event Statistic (MES) >\n20 and orbital period < 50 days.", "AI": {"tldr": "DART-Vetter\u662f\u4e00\u79cd\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u7528\u4e8e\u533a\u5206\u884c\u661f\u5019\u9009\u4fe1\u53f7\u548c\u5047\u9633\u6027\u4fe1\u53f7\uff0c\u5177\u6709\u7b80\u5355\u7d27\u51d1\u7684\u67b6\u6784\uff0c\u5e76\u5728TESS\u548cKepler\u6570\u636e\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u63d0\u9ad8\u4ece\u4e0d\u540c\u51cc\u661f\u5de1\u5929\u6570\u636e\u4e2d\u8bc6\u522b\u884c\u661f\u5019\u9009\u4fe1\u53f7\u7684\u9c81\u68d2\u6027\u3002", "method": "\u4f7f\u7528\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5904\u7406\u6298\u53e0\u540e\u7684\u5149\u53d8\u66f2\u7ebf\uff0c\u7b80\u5316\u67b6\u6784\u5e76\u516c\u5f00\u6e90\u4ee3\u7801\u3002", "result": "\u5728TESS\u548cKepler\u6570\u636e\u4e0a\u53ec\u56de\u7387\u8fbe91%\uff0c\u4f18\u4e8eExominer\u548cAstronet-Triage\u3002", "conclusion": "DART-Vetter\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u6613\u4e8e\u590d\u5236\u7684\u5de5\u5177\uff0c\u9002\u7528\u4e8e\u81ea\u52a8\u5316\u7b5b\u9009\u6216\u8f85\u52a9\u4eba\u5de5\u9a8c\u8bc1\u3002"}}
{"id": "2506.05565", "pdf": "https://arxiv.org/pdf/2506.05565", "abs": "https://arxiv.org/abs/2506.05565", "authors": ["Feliks Ba\u0144ka", "Jaros\u0142aw A. Chudziak"], "title": "Applying Informer for Option Pricing: A Transformer-Based Approach", "categories": ["cs.CE", "cs.AI", "cs.LG", "q-fin.CP", "91G60, 68T07", "I.2.6; J.4"], "comment": "8 pages, 3 tables, 7 figures. Accepted at the 17th International\n  Conference on Agents and Artificial Intelligence (ICAART 2025). Final version\n  published in Proceedings of ICAART 2025 (Vol. 3), pages 1270-1277", "summary": "Accurate option pricing is essential for effective trading and risk\nmanagement in financial markets, yet it remains challenging due to market\nvolatility and the limitations of traditional models like Black-Scholes. In\nthis paper, we investigate the application of the Informer neural network for\noption pricing, leveraging its ability to capture long-term dependencies and\ndynamically adjust to market fluctuations. This research contributes to the\nfield of financial forecasting by introducing Informer's efficient architecture\nto enhance prediction accuracy and provide a more adaptable and resilient\nframework compared to existing methods. Our results demonstrate that Informer\noutperforms traditional approaches in option pricing, advancing the\ncapabilities of data-driven financial forecasting in this domain.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86Informer\u795e\u7ecf\u7f51\u7edc\u5728\u671f\u6743\u5b9a\u4ef7\u4e2d\u7684\u5e94\u7528\uff0c\u5c55\u793a\u4e86\u5176\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u671f\u6743\u5b9a\u4ef7\u6a21\u578b\uff08\u5982Black-Scholes\uff09\u53d7\u9650\u4e8e\u5e02\u573a\u6ce2\u52a8\u6027\uff0c\u9700\u8981\u66f4\u51c6\u786e\u4e14\u9002\u5e94\u6027\u5f3a\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528Informer\u795e\u7ecf\u7f51\u7edc\uff0c\u5229\u7528\u5176\u6355\u6349\u957f\u671f\u4f9d\u8d56\u5173\u7cfb\u548c\u52a8\u6001\u9002\u5e94\u5e02\u573a\u6ce2\u52a8\u7684\u80fd\u529b\u3002", "result": "Informer\u5728\u671f\u6743\u5b9a\u4ef7\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u3002", "conclusion": "Informer\u4e3a\u6570\u636e\u9a71\u52a8\u7684\u91d1\u878d\u9884\u6d4b\u63d0\u4f9b\u4e86\u66f4\u9002\u5e94\u6027\u5f3a\u4e14\u7a33\u5065\u7684\u6846\u67b6\u3002"}}
{"id": "2506.05567", "pdf": "https://arxiv.org/pdf/2506.05567", "abs": "https://arxiv.org/abs/2506.05567", "authors": ["Fuat Can Beylunioglu", "Mehrdad Pirnia", "P. Robert Duimering"], "title": "Partially-Supervised Neural Network Model For Quadratic Multiparametric Programming", "categories": ["math.OC", "cs.LG", "14J60 (Primary) 14F05, 14J26 (Secondary)"], "comment": "36 pages including references and appendix", "summary": "Neural Networks (NN) with ReLU activation functions are used to model\nmultiparametric quadratic optimization problems (mp-QP) in diverse engineering\napplications. Researchers have suggested leveraging the piecewise affine\nproperty of deep NN models to solve mp-QP with linear constraints, which also\nexhibit piecewise affine behaviour. However, traditional deep NN applications\nto mp-QP fall short of providing optimal and feasible predictions, even when\ntrained on large datasets. This study proposes a partially-supervised NN (PSNN)\narchitecture that directly represents the mathematical structure of the global\nsolution function. In contrast to generic NN training approaches, the proposed\nPSNN method derives a large proportion of model weights directly from the\nmathematical properties of the optimization problem, producing more accurate\nsolutions despite significantly smaller training data sets. Many energy\nmanagement problems are formulated as QP, so we apply the proposed approach to\nenergy systems (specifically DC optimal power flow) to demonstrate proof of\nconcept. Model performance in terms of solution accuracy and speed of\npredictions was compared against a commercial solver and a generic Deep NN\nmodel based on classical training. Results show KKT sufficient conditions for\nPSNN consistently outperform generic NN architectures with classical training\nusing far less data, including when tested on extreme, out-of-training\ndistribution test data. Given its speed advantages over traditional solvers,\nthe PSNN model can quickly produce optimal and feasible solutions within a\nsecond for millions of input parameters sampled from a distribution of\nstochastic demands and renewable generator dispatches, which can be used for\nsimulations and long term planning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u90e8\u5206\u76d1\u7763\u795e\u7ecf\u7f51\u7edc\uff08PSNN\uff09\u67b6\u6784\uff0c\u7528\u4e8e\u89e3\u51b3\u591a\u53c2\u6570\u4e8c\u6b21\u4f18\u5316\u95ee\u9898\uff08mp-QP\uff09\uff0c\u901a\u8fc7\u76f4\u63a5\u5229\u7528\u4f18\u5316\u95ee\u9898\u7684\u6570\u5b66\u7ed3\u6784\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u8bad\u7ec3\u6570\u636e\u9700\u6c42\u5e76\u63d0\u5347\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u4f20\u7edf\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5728\u89e3\u51b3mp-QP\u65f6\u65e0\u6cd5\u63d0\u4f9b\u6700\u4f18\u4e14\u53ef\u884c\u7684\u9884\u6d4b\uff0c\u5373\u4f7f\u5728\u5927\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faPSNN\u67b6\u6784\uff0c\u76f4\u63a5\u4ece\u4f18\u5316\u95ee\u9898\u7684\u6570\u5b66\u6027\u8d28\u4e2d\u63a8\u5bfc\u5927\u90e8\u5206\u6a21\u578b\u6743\u91cd\uff0c\u51cf\u5c11\u5bf9\u8bad\u7ec3\u6570\u636e\u7684\u4f9d\u8d56\u3002", "result": "PSNN\u5728\u89e3\u7cbe\u5ea6\u548c\u9884\u6d4b\u901f\u5ea6\u4e0a\u4f18\u4e8e\u4f20\u7edf\u5546\u4e1a\u6c42\u89e3\u5668\u548c\u901a\u7528\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff0c\u4e14\u5bf9\u6781\u7aef\u6d4b\u8bd5\u6570\u636e\u8868\u73b0\u826f\u597d\u3002", "conclusion": "PSNN\u80fd\u591f\u5feb\u901f\u751f\u6210\u6700\u4f18\u89e3\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u6a21\u62df\u548c\u957f\u671f\u89c4\u5212\uff0c\u5c24\u5176\u5728\u80fd\u6e90\u7ba1\u7406\u95ee\u9898\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2506.05587", "pdf": "https://arxiv.org/pdf/2506.05587", "abs": "https://arxiv.org/abs/2506.05587", "authors": ["Junjie Xing", "Yeye He", "Mengyu Zhou", "Haoyu Dong", "Shi Han", "Lingjiao Chen", "Dongmei Zhang", "Surajit Chaudhuri", "H. V. Jagadish"], "title": "MMTU: A Massive Multi-Task Table Understanding and Reasoning Benchmark", "categories": ["cs.AI", "cs.CL", "cs.DB", "cs.LG"], "comment": null, "summary": "Tables and table-based use cases play a crucial role in many important\nreal-world applications, such as spreadsheets, databases, and computational\nnotebooks, which traditionally require expert-level users like data engineers,\ndata analysts, and database administrators to operate. Although LLMs have shown\nremarkable progress in working with tables (e.g., in spreadsheet and database\ncopilot scenarios), comprehensive benchmarking of such capabilities remains\nlimited. In contrast to an extensive and growing list of NLP benchmarks,\nevaluations of table-related tasks are scarce, and narrowly focus on tasks like\nNL-to-SQL and Table-QA, overlooking the broader spectrum of real-world tasks\nthat professional users face. This gap limits our understanding and model\nprogress in this important area.\n  In this work, we introduce MMTU, a large-scale benchmark with over 30K\nquestions across 25 real-world table tasks, designed to comprehensively\nevaluate models ability to understand, reason, and manipulate real tables at\nthe expert-level. These tasks are drawn from decades' worth of computer science\nresearch on tabular data, with a focus on complex table tasks faced by\nprofessional users. We show that MMTU require a combination of skills --\nincluding table understanding, reasoning, and coding -- that remain challenging\nfor today's frontier models, where even frontier reasoning models like OpenAI\no4-mini and DeepSeek R1 score only around 60%, suggesting significant room for\nimprovement. We highlight key findings in our evaluation using MMTU and hope\nthat this benchmark drives further advances in understanding and developing\nfoundation models for structured data processing and analysis. Our code and\ndata are available at https://github.com/MMTU-Benchmark/MMTU and\nhttps://huggingface.co/datasets/MMTU-benchmark/MMTU.", "AI": {"tldr": "MMTU\u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b25\u4e2a\u73b0\u5b9e\u4e16\u754c\u8868\u683c\u4efb\u52a1\u768430K\u95ee\u9898\uff0c\u65e8\u5728\u5168\u9762\u8bc4\u4f30\u6a21\u578b\u5728\u4e13\u5bb6\u7ea7\u522b\u4e0a\u7406\u89e3\u3001\u63a8\u7406\u548c\u64cd\u4f5c\u8868\u683c\u7684\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u4e3b\u8981\u5c40\u9650\u4e8eNL-to-SQL\u548cTable-QA\u7b49\u4efb\u52a1\uff0c\u5ffd\u7565\u4e86\u4e13\u4e1a\u7528\u6237\u9762\u4e34\u7684\u66f4\u5e7f\u6cdb\u4efb\u52a1\uff0c\u9650\u5236\u4e86\u6a21\u578b\u5728\u8fd9\u4e00\u9886\u57df\u7684\u53d1\u5c55\u3002", "method": "MMTU\u57fa\u4e8e\u6570\u5341\u5e74\u7684\u8868\u683c\u6570\u636e\u7814\u7a76\uff0c\u8bbe\u8ba1\u4e8625\u4e2a\u590d\u6742\u4efb\u52a1\uff0c\u6db5\u76d6\u8868\u683c\u7406\u89e3\u3001\u63a8\u7406\u548c\u7f16\u7801\u7b49\u6280\u80fd\u3002", "result": "\u524d\u6cbf\u6a21\u578b\uff08\u5982OpenAI o4-mini\u548cDeepSeek R1\uff09\u5728MMTU\u4e0a\u7684\u8868\u73b0\u4ec5\u4e3a60%\uff0c\u8868\u660e\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\u3002", "conclusion": "MMTU\u4e3a\u7ed3\u6784\u5316\u6570\u636e\u5904\u7406\u548c\u5206\u6790\u7684\u57fa\u7840\u6a21\u578b\u53d1\u5c55\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u51c6\uff0c\u63a8\u52a8\u4e86\u8be5\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2506.05590", "pdf": "https://arxiv.org/pdf/2506.05590", "abs": "https://arxiv.org/abs/2506.05590", "authors": ["Stella Huang", "Qing Zhou"], "title": "Nonlinear Causal Discovery through a Sequential Edge Orientation Approach", "categories": ["stat.ML", "cs.LG"], "comment": "42 Pages, 13 figures, 3 tables", "summary": "Recent advances have established the identifiability of a directed acyclic\ngraph (DAG) under additive noise models (ANMs), spurring the development of\nvarious causal discovery methods. However, most existing methods make\nrestrictive model assumptions, rely heavily on general independence tests, or\nrequire substantial computational time. To address these limitations, we\npropose a sequential procedure to orient undirected edges in a completed\npartial DAG (CPDAG), representing an equivalence class of DAGs, by leveraging\nthe pairwise additive noise model (PANM) to identify their causal directions.\nWe prove that this procedure can recover the true causal DAG assuming a\nrestricted ANM. Building on this result, we develop a novel constraint-based\nalgorithm for learning causal DAGs under nonlinear ANMs. Given an estimated\nCPDAG, we develop a ranking procedure that sorts undirected edges by their\nadherence to the PANM, which defines an evaluation order of the edges. To\ndetermine the edge direction, we devise a statistical test that compares the\nlog-likelihood values, evaluated with respect to the competing directions, of a\nsub-graph comprising just the candidate nodes and their identified parents in\nthe partial DAG. We further establish the structural learning consistency of\nour algorithm in the large-sample limit. Extensive experiments on synthetic and\nreal-world datasets demonstrate that our method is computationally efficient,\nrobust to model misspecification, and consistently outperforms many existing\nnonlinear DAG learning methods.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6210\u5bf9\u52a0\u6027\u566a\u58f0\u6a21\u578b\uff08PANM\uff09\u7684\u987a\u5e8f\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u90e8\u5206\u6709\u5411\u65e0\u73af\u56fe\uff08CPDAG\uff09\u4e2d\u5b9a\u5411\u65e0\u5411\u8fb9\uff0c\u4ee5\u6062\u590d\u771f\u5b9e\u7684\u56e0\u679cDAG\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u7684\u7ea6\u675f\u7b97\u6cd5\u3002", "motivation": "\u73b0\u6709\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\u5b58\u5728\u6a21\u578b\u5047\u8bbe\u4e25\u683c\u3001\u4f9d\u8d56\u72ec\u7acb\u6027\u68c0\u9a8c\u6216\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u5c40\u9650\u6027\u3002", "method": "\u5229\u7528PANM\u5bf9CPDAG\u4e2d\u7684\u65e0\u5411\u8fb9\u8fdb\u884c\u6392\u5e8f\u548c\u5b9a\u5411\uff0c\u901a\u8fc7\u7edf\u8ba1\u68c0\u9a8c\u6bd4\u8f83\u5bf9\u6570\u4f3c\u7136\u503c\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u7ea6\u675f\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u8ba1\u7b97\u9ad8\u6548\uff0c\u5bf9\u6a21\u578b\u8bef\u8bbe\u9c81\u68d2\uff0c\u4e14\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u975e\u7ebf\u6027DAG\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u975e\u7ebf\u6027\u52a0\u6027\u566a\u58f0\u6a21\u578b\u4e0b\u5177\u6709\u7ed3\u6784\u5b66\u4e60\u4e00\u81f4\u6027\uff0c\u5e76\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2506.05619", "pdf": "https://arxiv.org/pdf/2506.05619", "abs": "https://arxiv.org/abs/2506.05619", "authors": ["Kihyun Kim", "Jiawei Zhang", "Asuman Ozdaglar", "Pablo A. Parrilo"], "title": "Population-Proportional Preference Learning from Human Feedback: An Axiomatic Approach", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Conventional preference learning methods often prioritize opinions held more\nwidely when aggregating preferences from multiple evaluators. This may result\nin policies that are biased in favor of some types of opinions or groups. The\nobjective of this paper is to develop a novel preference learning framework\ncapable of aligning aggregate opinions and policies proportionally with the\ntrue population distribution of evaluator preferences. Our approach infers the\nfeasible set of evaluator population distributions directly from pairwise\ncomparison data. Using these estimates, the algorithm constructs a policy that\nsatisfies foundational axioms from social choice theory, namely monotonicity\nand Pareto efficiency, as well as our newly-introduced axioms of\npopulation-proportional representation and population-bounded robustness. We\npropose a soft-max relaxation method that smoothly trade-offs\npopulation-proportional representation with the selection of the Condorcet\nwinner (which beats all other options in pairwise comparisons). Finally, we\nvalidate the effectiveness and scalability of our approach through experiments\non both tabular recommendation tasks and large-scale language model alignment.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u504f\u597d\u5b66\u4e60\u6846\u67b6\uff0c\u65e8\u5728\u901a\u8fc7\u6210\u5bf9\u6bd4\u8f83\u6570\u636e\u63a8\u65ad\u8bc4\u4f30\u8005\u504f\u597d\u5206\u5e03\uff0c\u751f\u6210\u7b26\u5408\u793e\u4f1a\u9009\u62e9\u7406\u8bba\u516c\u7406\u7684\u653f\u7b56\uff0c\u5e76\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u4f20\u7edf\u504f\u597d\u5b66\u4e60\u65b9\u6cd5\u53ef\u80fd\u504f\u5411\u5e7f\u6cdb\u6301\u6709\u7684\u610f\u89c1\uff0c\u5bfc\u81f4\u653f\u7b56\u5bf9\u67d0\u4e9b\u7fa4\u4f53\u6216\u610f\u89c1\u7c7b\u578b\u4e0d\u516c\u5e73\u3002\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u80fd\u6309\u771f\u5b9e\u8bc4\u4f30\u8005\u504f\u597d\u6bd4\u4f8b\u5bf9\u9f50\u96c6\u4f53\u610f\u89c1\u548c\u653f\u7b56\u7684\u65b0\u6846\u67b6\u3002", "method": "\u901a\u8fc7\u6210\u5bf9\u6bd4\u8f83\u6570\u636e\u63a8\u65ad\u8bc4\u4f30\u8005\u7fa4\u4f53\u5206\u5e03\uff0c\u6784\u5efa\u6ee1\u8db3\u5355\u8c03\u6027\u3001\u5e15\u7d2f\u6258\u6548\u7387\u3001\u4eba\u53e3\u6bd4\u4f8b\u4ee3\u8868\u6027\u548c\u4eba\u53e3\u8fb9\u754c\u9c81\u68d2\u6027\u516c\u7406\u7684\u653f\u7b56\uff0c\u5e76\u91c7\u7528\u8f6f\u6700\u5927\u677e\u5f1b\u65b9\u6cd5\u5e73\u8861\u4eba\u53e3\u6bd4\u4f8b\u4ee3\u8868\u6027\u548cCondorcet\u80dc\u8005\u7684\u9009\u62e9\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u8868\u683c\u63a8\u8350\u4efb\u52a1\u548c\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u4e2d\u7684\u6709\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u65b0\u6846\u67b6\u80fd\u591f\u751f\u6210\u66f4\u516c\u5e73\u4e14\u7b26\u5408\u8bc4\u4f30\u8005\u771f\u5b9e\u504f\u597d\u7684\u653f\u7b56\uff0c\u540c\u65f6\u6ee1\u8db3\u793e\u4f1a\u9009\u62e9\u7406\u8bba\u7684\u6838\u5fc3\u516c\u7406\u3002"}}
{"id": "2506.05625", "pdf": "https://arxiv.org/pdf/2506.05625", "abs": "https://arxiv.org/abs/2506.05625", "authors": ["Anushka Tiwari", "Haimonti Dutta", "Shahrzad Khanizadeh"], "title": "Heterogeneous Sequel-Aware Graph Neural Networks for Sequential Learning", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "Graph-based recommendation systems use higher-order user and item embeddings\nfor next-item predictions. Dynamically adding collaborative signals from\nneighbors helps to use similar users' preferences during learning. While\nitem-item correlations and their impact on recommendations have been studied,\nthe efficacy of temporal item sequences for recommendations is much less\nexplored. In this paper, we examine temporal item sequence (sequel-aware)\nembeddings along with higher-order user embeddings and show that sequel-aware\nGraph Neural Networks have better (or comparable) recommendation performance\nthan graph-based recommendation systems that do not consider sequel\ninformation. Extensive empirical results comparing Heterogeneous Sequel-aware\nGraph Neural Networks (HSAL-GNNs) to other algorithms for sequential learning\n(such as transformers, graph neural networks, auto-encoders) are presented on\nthree synthetic and three real-world datasets. Our results indicate that the\nincorporation of sequence information from items greatly enhances\nrecommendations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u63a8\u8350\u7cfb\u7edf\uff0c\u901a\u8fc7\u5f15\u5165\u65f6\u95f4\u5e8f\u5217\u4fe1\u606f\uff08sequel-aware\uff09\u63d0\u5347\u63a8\u8350\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u7528\u6237\u548c\u7269\u54c1\u7684\u9ad8\u9636\u5d4c\u5165\u53ca\u7269\u54c1\u95f4\u76f8\u5173\u6027\uff0c\u4f46\u65f6\u95f4\u5e8f\u5217\u4fe1\u606f\u5bf9\u63a8\u8350\u7684\u5f71\u54cd\u8f83\u5c11\u88ab\u63a2\u7d22\u3002", "method": "\u63d0\u51fa\u5f02\u6784\u65f6\u95f4\u5e8f\u5217\u611f\u77e5\u56fe\u795e\u7ecf\u7f51\u7edc\uff08HSAL-GNNs\uff09\uff0c\u7ed3\u5408\u65f6\u95f4\u5e8f\u5217\u548c\u9ad8\u9636\u7528\u6237\u5d4c\u5165\uff0c\u5e76\u4e0e\u591a\u79cd\u7b97\u6cd5\uff08\u5982Transformer\u3001\u56fe\u795e\u7ecf\u7f51\u7edc\u3001\u81ea\u7f16\u7801\u5668\uff09\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5f15\u5165\u65f6\u95f4\u5e8f\u5217\u4fe1\u606f\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u6027\u80fd\u3002", "conclusion": "\u65f6\u95f4\u5e8f\u5217\u4fe1\u606f\u5bf9\u63a8\u8350\u7cfb\u7edf\u6709\u91cd\u8981\u4ef7\u503c\uff0cHSAL-GNNs\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u6216\u5ab2\u7f8e\u4e0d\u8003\u8651\u5e8f\u5217\u4fe1\u606f\u7684\u56fe\u63a8\u8350\u7cfb\u7edf\u3002"}}
{"id": "2506.05631", "pdf": "https://arxiv.org/pdf/2506.05631", "abs": "https://arxiv.org/abs/2506.05631", "authors": ["Veselin B. Kostov", "Brian P. Powell", "Aline U. Fornear", "Marco Z. Di Fraia", "Robert Gagliano", "Thomas L. Jacobs", "Julien S. de Lambilly", "Hugo A. Durantini Luca", "Steven R. Majewski", "Mark Omohundro", "Jerome Orosz", "Saul A. Rappaport", "Ryan Salik", "Donald Short", "William Welsh", "Svetoslav Alexandrov", "Cledison Marcos da Silva", "Erika Dunning", "Gerd Guhne", "Marc Huten", "Michiharu Hyogo", "Davide Iannone", "Sam Lee", "Christian Magliano", "Manya Sharma", "Allan Tarr", "John Yablonsky", "Sovan Acharya", "Fred Adams", "Thomas Barclay", "Benjamin T. Montet", "Susan Mullally", "Greg Olmschenk", "Andrej Prsa", "Elisa Quintana", "Robert Wilson", "Hasret Balcioglu", "Ethan Kruse", "the Eclipsing Binary Patrol Collaboration"], "title": "The TESS Ten Thousand Catalog: 10,001 uniformly-vetted and -validated Eclipsing Binary Stars detected in Full-Frame Image data by machine learning and analyzed by citizen scientists", "categories": ["astro-ph.SR", "astro-ph.EP", "astro-ph.IM", "cs.LG"], "comment": "40 pages, 39 figures, 4 tables", "summary": "The Transiting Exoplanet Survey Satellite (TESS) has surveyed nearly the\nentire sky in Full-Frame Image mode with a time resolution of 200 seconds to 30\nminutes and a temporal baseline of at least 27 days. In addition to the primary\ngoal of discovering new exoplanets, TESS is exceptionally capable at detecting\nvariable stars, and in particular short-period eclipsing binaries which are\nrelatively common, making up a few percent of all stars, and represent powerful\nastrophysical laboratories for deep investigations of stellar formation and\nevolution. We combed Sectors 1-82 of TESS Full-Frame Image data searching for\neclipsing binary stars using a neural network that identified ~1.2 million\nstars with eclipse-like features. Of these, we have performed an in-depth\nanalysis on ~60,000 targets using automated methods and manual inspection by\ncitizen scientists. Here we present a catalog of 10001 uniformly-vetted and\n-validated eclipsing binary stars that passed all our ephemeris and photocenter\ntests, as well as complementary visual inspection. Of these, 7936 are new\neclipsing binaries while the remaining 2065 are known systems for which we\nupdate the published ephemerides. We outline the detection and analysis of the\ntargets, discuss the properties of the sample, and highlight potentially\ninteresting systems. Finally, we also provide a list of ~900,000 unvetted and\nunvalidated targets for which the neural network found eclipse-like features\nwith a score higher than 0.9, and for which there are no known eclipsing\nbinaries within a sky-projected separation of a TESS pixel (~21 arcsec).", "AI": {"tldr": "TESS\u536b\u661f\u901a\u8fc7\u5168\u5e27\u56fe\u50cf\u6a21\u5f0f\u89c2\u6d4b\u5929\u7a7a\uff0c\u53d1\u73b0\u5e76\u9a8c\u8bc1\u4e8610001\u4e2a\u98df\u53cc\u661f\u7cfb\u7edf\uff0c\u5176\u4e2d7936\u4e2a\u4e3a\u65b0\u53d1\u73b0\uff0c2065\u4e2a\u4e3a\u5df2\u77e5\u7cfb\u7edf\u7684\u66f4\u65b0\u3002", "motivation": "\u7814\u7a76\u98df\u53cc\u661f\u7cfb\u7edf\u5bf9\u6052\u661f\u5f62\u6210\u548c\u6f14\u5316\u7684\u6df1\u5165\u7406\u89e3\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0cTESS\u6570\u636e\u4e3a\u6b64\u63d0\u4f9b\u4e86\u4e30\u5bcc\u8d44\u6e90\u3002", "method": "\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u7b5b\u9009TESS\u5168\u5e27\u56fe\u50cf\u6570\u636e\uff0c\u7ed3\u5408\u81ea\u52a8\u5316\u65b9\u6cd5\u548c\u516c\u6c11\u79d1\u5b66\u5bb6\u7684\u624b\u52a8\u68c0\u67e5\uff0c\u9a8c\u8bc1\u98df\u53cc\u661f\u7cfb\u7edf\u3002", "result": "\u751f\u6210\u5305\u542b10001\u4e2a\u98df\u53cc\u661f\u7684\u76ee\u5f55\uff0c\u5176\u4e2d7936\u4e2a\u4e3a\u65b0\u53d1\u73b0\uff0c2065\u4e2a\u4e3a\u5df2\u77e5\u7cfb\u7edf\u7684\u66f4\u65b0\u3002", "conclusion": "TESS\u6570\u636e\u4e3a\u98df\u53cc\u661f\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9d\u8d35\u8d44\u6e90\uff0c\u672a\u6765\u53ef\u8fdb\u4e00\u6b65\u63a2\u7d22\u672a\u9a8c\u8bc1\u76ee\u6807\u3002"}}
{"id": "2506.05639", "pdf": "https://arxiv.org/pdf/2506.05639", "abs": "https://arxiv.org/abs/2506.05639", "authors": ["John Kirchenbauer", "Janny Mongkolsupawan", "Yuxin Wen", "Tom Goldstein", "Daphne Ippolito"], "title": "A Fictional Q&A Dataset for Studying Memorization and Knowledge Acquisition", "categories": ["cs.CL", "cs.LG"], "comment": "10 pages and 8 figures in the main body", "summary": "When language models are trained on textual data, they acquire both knowledge\nabout the structure of language as well as knowledge of facts about the world.\nAt inference time, their knowledge of facts can be leveraged to solve\ninteresting problems and perform useful knowledge work for users. It is well\nknown that language models can verbatim memorize long sequences from their\ntraining data. However, it is much less well understood how language models\nmemorize facts seen during training. In this work, we propose a new dataset to\nspecifically empower researchers to study the dual processes of fact\nmemorization and verbatim sequence memorization. The dataset consists of\nsynthetically-generated, webtext-like documents about fictional events, as well\nas question-answer pairs about the events. We conduct training experiments\nshowing how synthetic data about fictional events can be effective in teasing\napart different forms of memorization. We also document the challenges in\neffectively building realistic, fictional synthetic data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u7814\u7a76\u8bed\u8a00\u6a21\u578b\u5bf9\u4e8b\u5b9e\u8bb0\u5fc6\u548c\u9010\u5b57\u5e8f\u5217\u8bb0\u5fc6\u7684\u53cc\u91cd\u8fc7\u7a0b\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u5c55\u793a\u4e86\u5408\u6210\u6570\u636e\u5728\u533a\u5206\u4e0d\u540c\u8bb0\u5fc6\u5f62\u5f0f\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u5728\u8bad\u7ec3\u65f6\u4f1a\u5b66\u4e60\u8bed\u8a00\u7ed3\u6784\u548c\u4e16\u754c\u4e8b\u5b9e\uff0c\u4f46\u5176\u5bf9\u4e8b\u5b9e\u7684\u8bb0\u5fc6\u673a\u5236\u5c1a\u4e0d\u660e\u786e\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u5408\u6210\u6570\u636e\u7814\u7a76\u8fd9\u4e00\u8fc7\u7a0b\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u865a\u6784\u4e8b\u4ef6\u7684\u5408\u6210\u6570\u636e\u96c6\uff0c\u5305\u62ec\u7c7b\u4f3c\u7f51\u7edc\u6587\u672c\u7684\u6587\u6863\u548c\u76f8\u5173\u95ee\u7b54\u5bf9\uff0c\u5e76\u8fdb\u884c\u4e86\u8bad\u7ec3\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5408\u6210\u6570\u636e\u80fd\u6709\u6548\u533a\u5206\u8bed\u8a00\u6a21\u578b\u7684\u4e0d\u540c\u8bb0\u5fc6\u5f62\u5f0f\uff0c\u540c\u65f6\u4e5f\u63ed\u793a\u4e86\u6784\u5efa\u771f\u5b9e\u865a\u6784\u6570\u636e\u7684\u6311\u6218\u3002", "conclusion": "\u5408\u6210\u6570\u636e\u4e3a\u7814\u7a76\u8bed\u8a00\u6a21\u578b\u7684\u8bb0\u5fc6\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\uff0c\u4f46\u6784\u5efa\u9ad8\u8d28\u91cf\u6570\u636e\u4ecd\u9700\u514b\u670d\u6311\u6218\u3002"}}
{"id": "2506.05657", "pdf": "https://arxiv.org/pdf/2506.05657", "abs": "https://arxiv.org/abs/2506.05657", "authors": ["Anarya Ray"], "title": "Emulating compact binary population synthesis simulations with robust uncertainty quantification and model comparison: Bayesian normalizing flows", "categories": ["astro-ph.HE", "cs.LG", "gr-qc"], "comment": "16 pages, 4 figures", "summary": "Population synthesis simulations of compact binary coalescences~(CBCs) play a\ncrucial role in extracting astrophysical insights from an ensemble of\ngravitational wave~(GW) observations. However, realistic simulations are costly\nto implement for a dense grid of initial conditions. Normalizing flows can\nemulate the distribution functions of a simulated population of binary\nparameters and thereby enable empirical constraints on the astrophysical\ninitial conditions and branching fractions of various formation channels given\ndata from a catalog of GW observations. They can also be used for data\namplification in sparse regions of the CBC parameter space to guide the\ndevelopment of phenomenological population models for rarely synthesizable\nsystems with components in theorized mass gaps, without having to simulate a\nprohibitively large number of binaries. But flow predictions are wrought with\nuncertainties, especially for sparse training sets. In this work I develop a\nmethod for quantifying and marginalizing uncertainties in the emulators by\nintroducing the Bayesian Normalizing flow, a conditional density estimator\nconstructed from Bayesian neural networks. Using the exact likelihood function\nassociated with density estimators I sample the posterior distribution of flow\nparameters with suitably chosen priors to quantify and marginalize over flow\nuncertainties. I demonstrate the accuracy, calibration, and data-amplification\nimpacts of the estimated uncertainties for simulations of binary black hole\npopulations formed through common envelope evolution. I outline applications of\nthe methodology in simulation-based inference from growing GW catalogs and\nsketch other uses for general simulation-based approaches in GW astronomy.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8d1d\u53f6\u65af\u5f52\u4e00\u5316\u6d41\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u91cf\u5316\u5e76\u8fb9\u7f18\u5316\u6a21\u62df\u7d27\u51d1\u53cc\u661f\u5e76\u5408\uff08CBCs\uff09\u53c2\u6570\u5206\u5e03\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u4ee5\u652f\u6301\u5f15\u529b\u6ce2\u89c2\u6d4b\u6570\u636e\u7684\u5206\u6790\u3002", "motivation": "\u73b0\u5b9e\u6a21\u62df\u6210\u672c\u9ad8\u6602\uff0c\u4e14\u7a00\u758f\u8bad\u7ec3\u96c6\u4f1a\u5bfc\u81f4\u6d41\u9884\u6d4b\u7684\u4e0d\u786e\u5b9a\u6027\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u4ee5\u66f4\u51c6\u786e\u5730\u7ea6\u675f\u5929\u4f53\u7269\u7406\u521d\u59cb\u6761\u4ef6\u548c\u5f62\u6210\u901a\u9053\u3002", "method": "\u901a\u8fc7\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\u6784\u5efa\u6761\u4ef6\u5bc6\u5ea6\u4f30\u8ba1\u5668\uff08\u8d1d\u53f6\u65af\u5f52\u4e00\u5316\u6d41\uff09\uff0c\u5229\u7528\u7cbe\u786e\u4f3c\u7136\u51fd\u6570\u5bf9\u540e\u9a8c\u5206\u5e03\u8fdb\u884c\u91c7\u6837\uff0c\u91cf\u5316\u5e76\u8fb9\u7f18\u5316\u6d41\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u5728\u5171\u540c\u5305\u5c42\u6f14\u5316\u5f62\u6210\u7684\u53cc\u9ed1\u6d1e\u7fa4\u4f53\u6a21\u62df\u4e2d\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u51c6\u786e\u6027\u3001\u6821\u51c6\u6027\u548c\u6570\u636e\u653e\u5927\u6548\u679c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u9002\u7528\u4e8e\u5f15\u529b\u6ce2\u76ee\u5f55\u7684\u6a21\u62df\u63a8\u65ad\uff0c\u5e76\u53ef\u63a8\u5e7f\u5230\u5176\u4ed6\u5f15\u529b\u6ce2\u5929\u6587\u5b66\u7684\u6a21\u62df\u65b9\u6cd5\u4e2d\u3002"}}
{"id": "2506.05688", "pdf": "https://arxiv.org/pdf/2506.05688", "abs": "https://arxiv.org/abs/2506.05688", "authors": ["Keinichi Fujita", "Shota Horiguchi", "Yusuke Ijima"], "title": "Voice Impression Control in Zero-Shot TTS", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "comment": "5 pages,5 figures, Accepted to INTERSPEECH 2025", "summary": "Para-/non-linguistic information in speech is pivotal in shaping the\nlisteners' impression. Although zero-shot text-to-speech (TTS) has achieved\nhigh speaker fidelity, modulating subtle para-/non-linguistic information to\ncontrol perceived voice characteristics, i.e., impressions, remains\nchallenging. We have therefore developed a voice impression control method in\nzero-shot TTS that utilizes a low-dimensional vector to represent the\nintensities of various voice impression pairs (e.g., dark-bright). The results\nof both objective and subjective evaluations have demonstrated our method's\neffectiveness in impression control. Furthermore, generating this vector via a\nlarge language model enables target-impression generation from a natural\nlanguage description of the desired impression, thus eliminating the need for\nmanual optimization.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u96f6\u6837\u672cTTS\u4e2d\u901a\u8fc7\u4f4e\u7ef4\u5411\u91cf\u63a7\u5236\u8bed\u97f3\u5370\u8c61\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u76ee\u6807\u5370\u8c61\u5411\u91cf\u3002", "motivation": "\u5c3d\u7ba1\u96f6\u6837\u672cTTS\u5728\u8bf4\u8bdd\u4eba\u4fdd\u771f\u5ea6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5982\u4f55\u901a\u8fc7\u8c03\u8282\u526f/\u975e\u8bed\u8a00\u4fe1\u606f\u63a7\u5236\u8bed\u97f3\u5370\u8c61\u4ecd\u5177\u6311\u6218\u6027\u3002", "method": "\u4f7f\u7528\u4f4e\u7ef4\u5411\u91cf\u8868\u793a\u8bed\u97f3\u5370\u8c61\u5bf9\u7684\u5f3a\u5ea6\uff08\u5982\u6697-\u4eae\uff09\uff0c\u5e76\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u751f\u6210\u76ee\u6807\u5370\u8c61\u5411\u91cf\u3002", "result": "\u4e3b\u5ba2\u89c2\u8bc4\u4f30\u5747\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u5370\u8c61\u63a7\u5236\u4e0a\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u65e0\u9700\u624b\u52a8\u4f18\u5316\u5373\u53ef\u5b9e\u73b0\u76ee\u6807\u5370\u8c61\u751f\u6210\u3002"}}
{"id": "2506.05695", "pdf": "https://arxiv.org/pdf/2506.05695", "abs": "https://arxiv.org/abs/2506.05695", "authors": ["Lingyuan Liu", "Mengxiang Zhang"], "title": "Being Strong Progressively! Enhancing Knowledge Distillation of Large Language Models through a Curriculum Learning Framework", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Knowledge Distillation (KD) compresses large language models (LLMs) by\ntransferring the teacher model's capabilities to a smaller student model,\nreducing inference cost and memory usage while maintaining performance.\nHowever, existing KD methods for LLMs often fail to prevent significant shifts\nin the student model's distribution during training, leading to issues such as\ncatastrophic forgetting, mode collapse, and training-inference mismatch. To\naddress these challenges, we propose a novel, plug-in curriculum learning\nframework inspired by the strength training principle of \"progressive overload\"\n(POCL), which can be seamlessly integrated into existing white-box KD\napproaches with minimal computational overhead. The framework comprises two\ncore components: (1) a difficulty measurer that ranks and partitions training\nsamples from easy to hard, and (2) a training scheduler that incrementally\nintroduces these subsets into the distillation process at fixed intervals while\napplying loss functions with progressively rising temperatures. By starting\nwith the easiest samples and progressively increasing the difficulty, the\napproach enhances both the stability and efficiency of learning. Extensive\nexperiments in instruction-following settings demonstrate that POCL\nconsistently improves the performance of distilled student models across\nvarious white-box KD methods and model families. Our findings highlight the\neffectiveness of sorted training samples in KD for LLMs. More generally, our\nwork demonstrates how to structure training data within the KD process to\nenhance the stability and performance of distilled LLMs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6e10\u8fdb\u5f0f\u8fc7\u8f7d\u539f\u5219\uff08POCL\uff09\u7684\u8bfe\u7a0b\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u6539\u8fdb\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u77e5\u8bc6\u84b8\u998f\uff08KD\uff09\u8fc7\u7a0b\uff0c\u901a\u8fc7\u9010\u6b65\u589e\u52a0\u8bad\u7ec3\u6837\u672c\u96be\u5ea6\u63d0\u5347\u5b66\u751f\u6a21\u578b\u7684\u7a33\u5b9a\u6027\u548c\u6027\u80fd\u3002", "motivation": "\u73b0\u6709KD\u65b9\u6cd5\u5728\u8bad\u7ec3\u5b66\u751f\u6a21\u578b\u65f6\u5bb9\u6613\u5bfc\u81f4\u5206\u5e03\u504f\u79fb\uff0c\u5f15\u53d1\u707e\u96be\u6027\u9057\u5fd8\u3001\u6a21\u5f0f\u5d29\u6e83\u7b49\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u7a33\u5b9a\u7684\u8bad\u7ec3\u6846\u67b6\u3002", "method": "POCL\u6846\u67b6\u5305\u542b\u4e24\u90e8\u5206\uff1a\u96be\u5ea6\u6d4b\u91cf\u5668\uff08\u5bf9\u6837\u672c\u4ece\u6613\u5230\u96be\u6392\u5e8f\uff09\u548c\u8bad\u7ec3\u8c03\u5ea6\u5668\uff08\u9010\u6b65\u5f15\u5165\u6837\u672c\u5e76\u8c03\u6574\u635f\u5931\u51fd\u6570\u6e29\u5ea6\uff09\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cPOCL\u80fd\u663e\u8457\u63d0\u5347\u84b8\u998f\u540e\u5b66\u751f\u6a21\u578b\u7684\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u767d\u76d2KD\u65b9\u6cd5\u548c\u6a21\u578b\u5bb6\u65cf\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u6784\u5316\u8bad\u7ec3\u6570\u636e\uff0cPOCL\u589e\u5f3a\u4e86KD\u8fc7\u7a0b\u7684\u7a33\u5b9a\u6027\u4e0e\u6027\u80fd\uff0c\u4e3aLLM\u7684\u538b\u7f29\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.05725", "pdf": "https://arxiv.org/pdf/2506.05725", "abs": "https://arxiv.org/abs/2506.05725", "authors": ["Fang Wu", "Vijay Prakash Dwivedi", "Jure Leskovec"], "title": "Large Language Models are Good Relational Learners", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) have demonstrated remarkable capabilities across\nvarious domains, yet their application to relational deep learning (RDL)\nremains underexplored. Existing approaches adapt LLMs by traversing relational\nlinks between entities in a database and converting the structured data into\nflat text documents. Still, this text-based serialization disregards critical\nrelational structures, introduces redundancy, and often exceeds standard LLM\ncontext lengths. We introduce Rel-LLM, a novel architecture that utilizes a\ngraph neural network (GNN)- based encoder to generate structured relational\nprompts for LLMs within a retrieval-augmented generation (RAG) framework.\nUnlike traditional text-based serialization approaches, our method preserves\nthe inherent relational structure of databases while enabling LLMs to\neffectively process and reason over complex entity relationships. Specifically,\nthe GNN encoder extracts a local subgraph around an entity to build feature\nrepresentations that contain relevant entity relationships and temporal\ndependencies. These representations are transformed into structured prompts\nusing a denormalization process, effectively allowing the LLM to reason over\nrelational structures. Through extensive experiments, we demonstrate that\nRel-LLM outperforms existing methods on key RDL tasks, offering a scalable and\nefficient approach to integrating LLMs with structured data sources. Code is\navailable at https://github.com/smiles724/Rel-LLM.", "AI": {"tldr": "Rel-LLM\u662f\u4e00\u79cd\u65b0\u9896\u67b6\u6784\uff0c\u7ed3\u5408\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6846\u67b6\uff0c\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u7ed3\u6784\u5316\u5173\u7cfb\u63d0\u793a\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u6587\u672c\u5e8f\u5217\u5316\u65b9\u6cd5\u5728\u5173\u7cfb\u6df1\u5ea6\u5b66\u4e60\uff08RDL\uff09\u4e2d\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u901a\u8fc7\u5c06\u7ed3\u6784\u5316\u6570\u636e\u8f6c\u6362\u4e3a\u6241\u5e73\u6587\u672c\u5e8f\u5217\u6765\u9002\u5e94LLM\uff0c\u4f46\u5ffd\u89c6\u4e86\u5173\u952e\u5173\u7cfb\u7ed3\u6784\uff0c\u5bfc\u81f4\u5197\u4f59\u548c\u4e0a\u4e0b\u6587\u957f\u5ea6\u95ee\u9898\u3002", "method": "Rel-LLM\u4f7f\u7528GNN\u7f16\u7801\u5668\u63d0\u53d6\u5b9e\u4f53\u5468\u56f4\u7684\u5c40\u90e8\u5b50\u56fe\uff0c\u751f\u6210\u5305\u542b\u5173\u7cfb\u548c\u65f6\u95f4\u4f9d\u8d56\u7684\u7279\u5f81\u8868\u793a\uff0c\u5e76\u901a\u8fc7\u53cd\u89c4\u8303\u5316\u8fc7\u7a0b\u5c06\u5176\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u63d0\u793a\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cRel-LLM\u5728\u5173\u952eRDL\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684LLM\u4e0e\u7ed3\u6784\u5316\u6570\u636e\u96c6\u6210\u65b9\u6848\u3002", "conclusion": "Rel-LLM\u901a\u8fc7\u4fdd\u7559\u6570\u636e\u5e93\u7684\u5173\u7cfb\u7ed3\u6784\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u5904\u7406\u590d\u6742\u5b9e\u4f53\u5173\u7cfb\u7684\u80fd\u529b\u3002"}}
{"id": "2506.05735", "pdf": "https://arxiv.org/pdf/2506.05735", "abs": "https://arxiv.org/abs/2506.05735", "authors": ["Rongzhe Wei", "Peizhi Niu", "Hans Hao-Hsun Hsu", "Ruihan Wu", "Haoteng Yin", "Mohsen Ghassemi", "Yifan Li", "Vamsi K. Potluru", "Eli Chien", "Kamalika Chaudhuri", "Olgica Milenkovic", "Pan Li"], "title": "Do LLMs Really Forget? Evaluating Unlearning with Knowledge Correlation and Confidence Awareness", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Machine unlearning techniques aim to mitigate unintended memorization in\nlarge language models (LLMs). However, existing approaches predominantly focus\non the explicit removal of isolated facts, often overlooking latent inferential\ndependencies and the non-deterministic nature of knowledge within LLMs.\nConsequently, facts presumed forgotten may persist implicitly through\ncorrelated information. To address these challenges, we propose a knowledge\nunlearning evaluation framework that more accurately captures the implicit\nstructure of real-world knowledge by representing relevant factual contexts as\nknowledge graphs with associated confidence scores. We further develop an\ninference-based evaluation protocol leveraging powerful LLMs as judges; these\njudges reason over the extracted knowledge subgraph to determine unlearning\nsuccess. Our LLM judges utilize carefully designed prompts and are calibrated\nagainst human evaluations to ensure their trustworthiness and stability.\nExtensive experiments on our newly constructed benchmark demonstrate that our\nframework provides a more realistic and rigorous assessment of unlearning\nperformance. Moreover, our findings reveal that current evaluation strategies\ntend to overestimate unlearning effectiveness. Our code is publicly available\nat https://github.com/Graph-COM/Knowledge_Unlearning.git.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u77e5\u8bc6\u9057\u5fd8\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u77e5\u8bc6\u56fe\u8c31\u548c\u7f6e\u4fe1\u5ea6\u8bc4\u5206\u66f4\u51c6\u786e\u5730\u6355\u6349\u73b0\u5b9e\u4e16\u754c\u77e5\u8bc6\u7684\u9690\u5f0f\u7ed3\u6784\uff0c\u5e76\u5229\u7528LLM\u4f5c\u4e3a\u8bc4\u4f30\u8005\u6765\u9a8c\u8bc1\u9057\u5fd8\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u663e\u5f0f\u79fb\u9664\u5b64\u7acb\u4e8b\u5b9e\uff0c\u5ffd\u7565\u4e86\u9690\u5f0f\u63a8\u7406\u4f9d\u8d56\u548cLLM\u4e2d\u77e5\u8bc6\u7684\u975e\u786e\u5b9a\u6027\uff0c\u5bfc\u81f4\u9057\u5fd8\u6548\u679c\u88ab\u9ad8\u4f30\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u8bbe\u8ba1\u63a8\u7406\u8bc4\u4f30\u534f\u8bae\uff0c\u5229\u7528LLM\u4f5c\u4e3a\u8bc4\u4f30\u8005\uff0c\u5e76\u901a\u8fc7\u4eba\u7c7b\u8bc4\u4f30\u6821\u51c6\u5176\u53ef\u4fe1\u5ea6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u80fd\u66f4\u771f\u5b9e\u3001\u4e25\u683c\u5730\u8bc4\u4f30\u9057\u5fd8\u6027\u80fd\uff0c\u5e76\u53d1\u73b0\u73b0\u6709\u7b56\u7565\u9ad8\u4f30\u4e86\u9057\u5fd8\u6548\u679c\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u77e5\u8bc6\u9057\u5fd8\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2506.05745", "pdf": "https://arxiv.org/pdf/2506.05745", "abs": "https://arxiv.org/abs/2506.05745", "authors": ["Emil Biju", "Shayan Talaei", "Zhemin Huang", "Mohammadreza Pourreza", "Azalia Mirhoseini", "Amin Saberi"], "title": "SPRINT: Enabling Interleaved Planning and Parallelized Execution in Reasoning Models", "categories": ["cs.AI", "cs.LG"], "comment": "Emil Biju, Shayan Talaei, and Zhemin Huang contributed equally to\n  this work", "summary": "Large reasoning models (LRMs) excel at complex reasoning tasks but typically\ngenerate lengthy sequential chains-of-thought, resulting in long inference\ntimes before arriving at the final answer. To address this challenge, we\nintroduce SPRINT, a novel post-training and inference-time framework designed\nto enable LRMs to dynamically identify and exploit opportunities for\nparallelization during their reasoning process. SPRINT incorporates an\ninnovative data curation pipeline that reorganizes natural language reasoning\ntrajectories into structured rounds of long-horizon planning and parallel\nexecution. By fine-tuning LRMs on a small amount of such curated data, the\nmodels learn to dynamically identify independent subtasks within extended\nreasoning processes and effectively execute them in parallel. Through extensive\nevaluations, we show that the models fine-tuned with the SPRINT framework match\nthe performance of reasoning models on complex domains such as mathematics\nwhile generating up to ~39% fewer sequential tokens on problems requiring more\nthan 8000 output tokens. Finally, we observe consistent results transferred to\ntwo out-of-distribution tasks of GPQA and Countdown with up to 45% and 65%\nreduction in average sequential tokens for longer reasoning trajectories, while\nachieving the performance of the fine-tuned reasoning model.", "AI": {"tldr": "SPRINT\u6846\u67b6\u901a\u8fc7\u5e76\u884c\u5316\u63a8\u7406\u8fc7\u7a0b\u51cf\u5c11\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u7684\u63a8\u7406\u65f6\u95f4\uff0c\u540c\u65f6\u4fdd\u6301\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5927\u578b\u63a8\u7406\u6a21\u578b\u56e0\u751f\u6210\u5197\u957f\u7684\u94fe\u5f0f\u63a8\u7406\u800c\u5bfc\u81f4\u7684\u63a8\u7406\u65f6\u95f4\u8fc7\u957f\u95ee\u9898\u3002", "method": "\u5f15\u5165SPRINT\u6846\u67b6\uff0c\u901a\u8fc7\u6570\u636e\u91cd\u7ec4\u548c\u5fae\u8c03\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u52a8\u6001\u8bc6\u522b\u5e76\u884c\u6267\u884c\u7684\u5b50\u4efb\u52a1\u3002", "result": "\u5728\u6570\u5b66\u7b49\u9886\u57df\u6027\u80fd\u76f8\u5f53\uff0c\u540c\u65f6\u51cf\u5c11\u9ad8\u8fbe39%\u7684\u5e8f\u5217\u6807\u8bb0\uff1b\u5728GPQA\u548cCountdown\u4efb\u52a1\u4e2d\u5206\u522b\u51cf\u5c1145%\u548c65%\u7684\u5e8f\u5217\u6807\u8bb0\u3002", "conclusion": "SPRINT\u6709\u6548\u51cf\u5c11\u4e86\u63a8\u7406\u65f6\u95f4\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2506.05754", "pdf": "https://arxiv.org/pdf/2506.05754", "abs": "https://arxiv.org/abs/2506.05754", "authors": ["Emmanuel Anaya Gonzalez", "Sairam Vaidya", "Kanghee Park", "Ruyi Ji", "Taylor Berg-Kirkpatrick", "Loris D'Antoni"], "title": "Constrained Sampling for Language Models Should Be Easy: An MCMC Perspective", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Constrained decoding enables Language Models (LMs) to produce samples that\nprovably satisfy hard constraints. However, existing constrained-decoding\napproaches often distort the underlying model distribution, a limitation that\nis especially problematic in applications like program fuzzing, where one wants\nto generate diverse and valid program inputs for testing purposes. We propose a\nnew constrained sampling framework based on Markov Chain Monte Carlo (MCMC)\nthat simultaneously satisfies three core desiderata: constraint satisfying\n(every sample satisfies the constraint), monotonically converging (the sampling\nprocess converges to the true conditional distribution), and efficient\n(high-quality samples emerge in few steps). Our method constructs a proposal\ndistribution over valid outputs and applies a Metropolis-Hastings acceptance\ncriterion based on the LM's likelihood, ensuring principled and efficient\nexploration of the constrained space. Empirically, our sampler outperforms\nexisting methods on both synthetic benchmarks and real-world program fuzzing\ntasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eMCMC\u7684\u7ea6\u675f\u91c7\u6837\u6846\u67b6\uff0c\u6ee1\u8db3\u7ea6\u675f\u6761\u4ef6\u3001\u5355\u8c03\u6536\u655b\u548c\u9ad8\u6548\u6027\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7ea6\u675f\u89e3\u7801\u65b9\u6cd5\u4f1a\u626d\u66f2\u6a21\u578b\u5206\u5e03\uff0c\u5f71\u54cd\u751f\u6210\u6837\u672c\u7684\u591a\u6837\u6027\uff0c\u5c24\u5176\u5728\u7a0b\u5e8f\u6a21\u7cca\u6d4b\u8bd5\u7b49\u5e94\u7528\u4e2d\u3002", "method": "\u6784\u5efa\u6709\u6548\u8f93\u51fa\u7684\u63d0\u8bae\u5206\u5e03\uff0c\u5e76\u57fa\u4e8eLM\u4f3c\u7136\u5e94\u7528Metropolis-Hastings\u63a5\u53d7\u51c6\u5219\u3002", "result": "\u5728\u5408\u6210\u57fa\u51c6\u548c\u5b9e\u9645\u7a0b\u5e8f\u6a21\u7cca\u6d4b\u8bd5\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u65b0\u6846\u67b6\u5728\u6ee1\u8db3\u7ea6\u675f\u7684\u540c\u65f6\u9ad8\u6548\u63a2\u7d22\u7ea6\u675f\u7a7a\u95f4\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2506.05758", "pdf": "https://arxiv.org/pdf/2506.05758", "abs": "https://arxiv.org/abs/2506.05758", "authors": ["Guang-Xing Li"], "title": "Mapping correlations and coherence: adjacency-based approach to data visualization and regularity discovery", "categories": ["physics.comp-ph", "astro-ph.IM", "cs.LG", "math.DS"], "comment": "Code is avaliable at\n  https://github.com/gxli/Adjacent-Correlation-Analysis", "summary": "The development of science has been transforming man's view towards nature\nfor centuries. Observing structures and patterns in an effective approach to\ndiscover regularities from data is a key step toward theory-building. With\nincreasingly complex data being obtained, revealing regularities systematically\nhas become a challenge. Correlation is a most commonly-used and effective\napproach to describe regularities in data, yet for complex patterns, spatial\ninhomogeneity and complexity can often undermine the correlations. We present\nan algorithm to derive maps representing the type and degree of correlations,\nby taking the two-fold symmetry of the correlation vector into full account\nusing the Stokes parameter. The method allows for a spatially resolved view of\nthe nature and strength of correlations between physical quantities. In the\ncorrelation view, a region can often be separated into different subregions\nwith different types of correlations. Subregions correspond to physical regimes\nfor physical systems, or climate zones for climate maps. The simplicity of the\nmethod makes it widely applicable to a variety of data, where the\ncorrelation-based approach makes the map particularly useful in revealing\nregularities in physical systems and alike. As a new and efficient approach to\nrepresent data, the method should facilitate the development of new\ncomputational approaches to regularity discovery.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u65af\u6258\u514b\u65af\u53c2\u6570\u7684\u7b97\u6cd5\uff0c\u7528\u4e8e\u751f\u6210\u8868\u793a\u76f8\u5173\u6027\u7684\u7c7b\u578b\u548c\u7a0b\u5ea6\u7684\u5730\u56fe\uff0c\u9002\u7528\u4e8e\u590d\u6742\u6570\u636e\u4e2d\u7684\u89c4\u5f8b\u53d1\u73b0\u3002", "motivation": "\u968f\u7740\u6570\u636e\u590d\u6742\u6027\u589e\u52a0\uff0c\u7cfb\u7edf\u6027\u63ed\u793a\u89c4\u5f8b\u6210\u4e3a\u6311\u6218\uff0c\u4f20\u7edf\u76f8\u5173\u6027\u65b9\u6cd5\u5728\u590d\u6742\u6a21\u5f0f\u4e2d\u53ef\u80fd\u5931\u6548\u3002", "method": "\u5229\u7528\u65af\u6258\u514b\u65af\u53c2\u6570\u8003\u8651\u76f8\u5173\u6027\u5411\u91cf\u7684\u53cc\u91cd\u5bf9\u79f0\u6027\uff0c\u751f\u6210\u7a7a\u95f4\u5206\u8fa8\u7387\u7684\u76f8\u5173\u6027\u5730\u56fe\u3002", "result": "\u65b9\u6cd5\u80fd\u591f\u533a\u5206\u4e0d\u540c\u5b50\u533a\u57df\u7684\u76f8\u5173\u6027\u7c7b\u578b\uff0c\u9002\u7528\u4e8e\u7269\u7406\u7cfb\u7edf\u548c\u6c14\u5019\u5730\u56fe\u7b49\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u89c4\u5f8b\u53d1\u73b0\u63d0\u4f9b\u4e86\u65b0\u7684\u9ad8\u6548\u6570\u636e\u8868\u793a\u65b9\u5f0f\uff0c\u6709\u671b\u63a8\u52a8\u65b0\u8ba1\u7b97\u65b9\u6cd5\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.05779", "pdf": "https://arxiv.org/pdf/2506.05779", "abs": "https://arxiv.org/abs/2506.05779", "authors": ["Yinchao Zhang", "Su Yao", "Yong Feng", "Kang Chen", "Tong Li", "Zhuotao Liu", "Yi Zhao", "Lexuan Zhang", "Xiangyu Gao", "Feng Xiong", "Qi Li", "Ke Xu"], "title": "Pegasus: A Universal Framework for Scalable Deep Learning Inference on the Dataplane", "categories": ["cs.NI", "cs.LG"], "comment": "to be published in Sigcomm 2025", "summary": "The paradigm of Intelligent DataPlane (IDP) embeds deep learning (DL) models\non the network dataplane to enable intelligent traffic analysis at line-speed.\nHowever, the current use of the match-action table (MAT) abstraction on the\ndataplane is misaligned with DL inference, leading to several key limitations,\nincluding accuracy degradation, limited scale, and lack of generality. This\npaper proposes Pegasus to address these limitations. Pegasus translates DL\noperations into three dataplane-oriented primitives to achieve generality:\nPartition, Map, and SumReduce. Specifically, Partition \"divides\"\nhigh-dimensional features into multiple low-dimensional vectors, making them\nmore suitable for the dataplane; Map \"conquers\" computations on the\nlow-dimensional vectors in parallel with the technique of fuzzy matching, while\nSumReduce \"combines\" the computation results. Additionally, Pegasus employs\nPrimitive Fusion to merge computations, improving scalability. Finally, Pegasus\nadopts full precision weights with fixed-point activations to improve accuracy.\nOur implementation on a P4 switch demonstrates that Pegasus can effectively\nsupport various types of DL models, including Multi-Layer Perceptron (MLP),\nRecurrent Neural Network (RNN), Convolutional Neural Network (CNN), and\nAutoEncoder models on the dataplane. Meanwhile, Pegasus outperforms\nstate-of-the-art approaches with an average accuracy improvement of up to\n22.8%, along with up to 248x larger model size and 212x larger input scale.", "AI": {"tldr": "Pegasus\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6570\u636e\u5e73\u9762\u62bd\u8c61\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u6df1\u5ea6\u5b66\u4e60\u64cd\u4f5c\u8f6c\u5316\u4e3a\u4e09\u79cd\u6570\u636e\u5e73\u9762\u539f\u8bed\uff08Partition\u3001Map\u3001SumReduce\uff09\u548cPrimitive Fusion\u6280\u672f\uff0c\u89e3\u51b3\u4e86\u73b0\u6709MAT\u62bd\u8c61\u4e0eDL\u63a8\u7406\u4e0d\u5339\u914d\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u51c6\u786e\u6027\u3001\u89c4\u6a21\u548c\u901a\u7528\u6027\u3002", "motivation": "\u5f53\u524d\u6570\u636e\u5e73\u9762\u4e0a\u7684MAT\u62bd\u8c61\u4e0eDL\u63a8\u7406\u4e0d\u5339\u914d\uff0c\u5bfc\u81f4\u51c6\u786e\u6027\u4e0b\u964d\u3001\u89c4\u6a21\u53d7\u9650\u548c\u7f3a\u4e4f\u901a\u7528\u6027\u3002", "method": "Pegasus\u5c06DL\u64cd\u4f5c\u8f6c\u5316\u4e3a\u4e09\u79cd\u6570\u636e\u5e73\u9762\u539f\u8bed\uff08Partition\u3001Map\u3001SumReduce\uff09\uff0c\u5e76\u91c7\u7528Primitive Fusion\u6280\u672f\u5408\u5e76\u8ba1\u7b97\uff0c\u540c\u65f6\u4f7f\u7528\u5168\u7cbe\u5ea6\u6743\u91cd\u548c\u5b9a\u70b9\u6fc0\u6d3b\u6765\u63d0\u9ad8\u51c6\u786e\u6027\u3002", "result": "\u5728P4\u4ea4\u6362\u673a\u4e0a\u7684\u5b9e\u73b0\u8868\u660e\uff0cPegasus\u80fd\u6709\u6548\u652f\u6301\u591a\u79cdDL\u6a21\u578b\uff08\u5982MLP\u3001RNN\u3001CNN\u3001AutoEncoder\uff09\uff0c\u5e73\u5747\u51c6\u786e\u6027\u63d0\u5347\u8fbe22.8%\uff0c\u6a21\u578b\u89c4\u6a21\u548c\u8f93\u5165\u89c4\u6a21\u5206\u522b\u63d0\u5347248\u500d\u548c212\u500d\u3002", "conclusion": "Pegasus\u901a\u8fc7\u521b\u65b0\u7684\u6570\u636e\u5e73\u9762\u62bd\u8c61\u548c\u4f18\u5316\u6280\u672f\uff0c\u663e\u8457\u63d0\u5347\u4e86DL\u6a21\u578b\u5728\u6570\u636e\u5e73\u9762\u4e0a\u7684\u6027\u80fd\u548c\u901a\u7528\u6027\u3002"}}
{"id": "2506.05780", "pdf": "https://arxiv.org/pdf/2506.05780", "abs": "https://arxiv.org/abs/2506.05780", "authors": ["Meng Fan", "Yifan Zuo", "Patrick Blaes", "Harley Montgomery", "Subhasis Das"], "title": "Robust sensor fusion against on-vehicle sensor staleness", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "comment": "This paper has been accepted by CVPR 2025 Precognition Workshop", "summary": "Sensor fusion is crucial for a performant and robust Perception system in\nautonomous vehicles, but sensor staleness, where data from different sensors\narrives with varying delays, poses significant challenges. Temporal\nmisalignment between sensor modalities leads to inconsistent object state\nestimates, severely degrading the quality of trajectory predictions that are\ncritical for safety. We present a novel and model-agnostic approach to address\nthis problem via (1) a per-point timestamp offset feature (for LiDAR and radar\nboth relative to camera) that enables fine-grained temporal awareness in sensor\nfusion, and (2) a data augmentation strategy that simulates realistic sensor\nstaleness patterns observed in deployed vehicles. Our method is integrated into\na perspective-view detection model that consumes sensor data from multiple\nLiDARs, radars and cameras. We demonstrate that while a conventional model\nshows significant regressions when one sensor modality is stale, our approach\nreaches consistently good performance across both synchronized and stale\nconditions.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u89e3\u51b3\u81ea\u52a8\u9a7e\u9a76\u4e2d\u4f20\u611f\u5668\u6570\u636e\u5ef6\u8fdf\u95ee\u9898\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u65f6\u95f4\u6233\u504f\u79fb\u7279\u5f81\u548c\u6570\u636e\u589e\u5f3a\u7b56\u7565\uff0c\u63d0\u5347\u4e86\u4f20\u611f\u5668\u878d\u5408\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u611f\u5668\u6570\u636e\u5ef6\u8fdf\uff08staleness\uff09\u4f1a\u5bfc\u81f4\u591a\u6a21\u6001\u6570\u636e\u65f6\u95f4\u4e0d\u4e00\u81f4\uff0c\u4ece\u800c\u5f71\u54cd\u76ee\u6807\u72b6\u6001\u4f30\u8ba1\u548c\u8f68\u8ff9\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u8fd9\u5bf9\u81ea\u52a8\u9a7e\u9a76\u7684\u5b89\u5168\u6027\u81f3\u5173\u91cd\u8981\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\uff1a\uff081\uff09\u4e3aLiDAR\u548c\u96f7\u8fbe\u6570\u636e\u5f15\u5165\u76f8\u5bf9\u4e8e\u76f8\u673a\u7684\u65f6\u95f4\u6233\u504f\u79fb\u7279\u5f81\uff1b\uff082\uff09\u6a21\u62df\u5b9e\u9645\u8f66\u8f86\u4e2d\u4f20\u611f\u5668\u5ef6\u8fdf\u6a21\u5f0f\u7684\u6570\u636e\u589e\u5f3a\u7b56\u7565\u3002\u8be5\u65b9\u6cd5\u96c6\u6210\u5230\u4e00\u4e2a\u591a\u4f20\u611f\u5668\u68c0\u6d4b\u6a21\u578b\u4e2d\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4f20\u7edf\u65b9\u6cd5\u5728\u4f20\u611f\u5668\u6570\u636e\u5ef6\u8fdf\u65f6\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u800c\u65b0\u65b9\u6cd5\u5728\u540c\u6b65\u548c\u5ef6\u8fdf\u6761\u4ef6\u4e0b\u5747\u8868\u73b0\u826f\u597d\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u4f20\u611f\u5668\u6570\u636e\u5ef6\u8fdf\u95ee\u9898\uff0c\u63d0\u5347\u81ea\u52a8\u9a7e\u9a76\u611f\u77e5\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u548c\u6027\u80fd\u3002"}}
{"id": "2506.05834", "pdf": "https://arxiv.org/pdf/2506.05834", "abs": "https://arxiv.org/abs/2506.05834", "authors": ["Sandro Preto", "Marcelo Finger"], "title": "Regional, Lattice and Logical Representations of Neural Networks", "categories": ["cs.LO", "cs.AI", "cs.LG"], "comment": "In Proceedings LSFA 2024, arXiv:2506.05219", "summary": "A possible path to the interpretability of neural networks is to\n(approximately) represent them in the regional format of piecewise linear\nfunctions, where regions of inputs are associated to linear functions computing\nthe network outputs. We present an algorithm for the translation of feedforward\nneural networks with ReLU activation functions in hidden layers and truncated\nidentity activation functions in the output layer. We also empirically\ninvestigate the complexity of regional representations outputted by our method\nfor neural networks with varying sizes. Lattice and logical representations of\nneural networks are straightforward from regional representations as long as\nthey satisfy a specific property. So we empirically investigate to what extent\nthe translations by our algorithm satisfy such property.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06ReLU\u6fc0\u6d3b\u7684\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u8f6c\u6362\u4e3a\u5206\u6bb5\u7ebf\u6027\u51fd\u6570\u533a\u57df\u8868\u793a\u7684\u65b9\u6cd5\uff0c\u5e76\u7814\u7a76\u4e86\u5176\u590d\u6742\u6027\u548c\u9002\u7528\u6027\u3002", "motivation": "\u63a2\u7d22\u795e\u7ecf\u7f51\u7edc\u53ef\u89e3\u91ca\u6027\u7684\u4e00\u79cd\u53ef\u80fd\u8def\u5f84\uff0c\u5373\u901a\u8fc7\u5206\u6bb5\u7ebf\u6027\u51fd\u6570\u8fd1\u4f3c\u8868\u793a\u7f51\u7edc\u884c\u4e3a\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u7b97\u6cd5\uff0c\u5c06\u9690\u85cf\u5c42\u4f7f\u7528ReLU\u6fc0\u6d3b\u3001\u8f93\u51fa\u5c42\u4f7f\u7528\u622a\u65ad\u6052\u7b49\u6fc0\u6d3b\u7684\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u8f6c\u6362\u4e3a\u533a\u57df\u8868\u793a\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u7814\u7a76\u4e86\u4e0d\u540c\u89c4\u6a21\u795e\u7ecf\u7f51\u7edc\u7684\u533a\u57df\u8868\u793a\u590d\u6742\u6027\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u6ee1\u8db3\u7279\u5b9a\u6027\u8d28\u7684\u7a0b\u5ea6\u3002", "conclusion": "\u533a\u57df\u8868\u793a\u4e3a\u795e\u7ecf\u7f51\u7edc\u7684\u53ef\u89e3\u91ca\u6027\u63d0\u4f9b\u4e86\u6f5c\u5728\u8def\u5f84\uff0c\u4e14\u5176\u6ee1\u8db3\u7279\u5b9a\u6027\u8d28\u7684\u80fd\u529b\u4e3a\u540e\u7eed\u903b\u8f91\u548c\u683c\u8868\u793a\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.05853", "pdf": "https://arxiv.org/pdf/2506.05853", "abs": "https://arxiv.org/abs/2506.05853", "authors": ["Nikita Vasilenko", "Alexander Demin", "Vladimir Boorlakov"], "title": "Training-Free Query Optimization via LLM-Based Plan Similarity", "categories": ["cs.DB", "cs.LG"], "comment": "18 pages, 5 figures", "summary": "Large language model (LLM) embeddings offer a promising new avenue for\ndatabase query optimization. In this paper, we explore how pre-trained\nexecution plan embeddings can guide SQL query execution without the need for\nadditional model training. We introduce LLM-PM (LLM-based Plan Mapping), a\nframework that embeds the default execution plan of a query, finds its k\nnearest neighbors among previously executed plans, and recommends database\nhintsets based on neighborhood voting. A lightweight consistency check\nvalidates the selected hint, while a fallback mechanism searches the full hint\nspace when needed. Evaluated on the JOB-CEB benchmark using OpenGauss, LLM-PM\nachieves an average speed-up of 21% query latency reduction. This work\nhighlights the potential of LLM-powered embeddings to deliver practical\nimprovements in query performance and opens new directions for training-free,\nembedding-based optimizer guidance systems.", "AI": {"tldr": "LLM-PM\u5229\u7528\u9884\u8bad\u7ec3\u7684\u6267\u884c\u8ba1\u5212\u5d4c\u5165\u6307\u5bfcSQL\u67e5\u8be2\u6267\u884c\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\uff0c\u901a\u8fc7\u90bb\u5c45\u6295\u7968\u63a8\u8350\u6570\u636e\u5e93\u63d0\u793a\u96c6\uff0c\u5b9e\u73b021%\u7684\u67e5\u8be2\u5ef6\u8fdf\u964d\u4f4e\u3002", "motivation": "\u63a2\u7d22\u9884\u8bad\u7ec3LLM\u5d4c\u5165\u5728\u6570\u636e\u5e93\u67e5\u8be2\u4f18\u5316\u4e2d\u7684\u6f5c\u529b\uff0c\u51cf\u5c11\u6a21\u578b\u8bad\u7ec3\u9700\u6c42\u3002", "method": "\u63d0\u51faLLM-PM\u6846\u67b6\uff0c\u5d4c\u5165\u67e5\u8be2\u9ed8\u8ba4\u6267\u884c\u8ba1\u5212\uff0c\u901a\u8fc7k\u8fd1\u90bb\u548c\u6295\u7968\u63a8\u8350\u63d0\u793a\u96c6\uff0c\u8f85\u4ee5\u4e00\u81f4\u6027\u68c0\u67e5\u548c\u56de\u9000\u673a\u5236\u3002", "result": "\u5728JOB-CEB\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5e73\u5747\u51cf\u5c1121%\u67e5\u8be2\u5ef6\u8fdf\u3002", "conclusion": "LLM\u5d4c\u5165\u4e3a\u67e5\u8be2\u4f18\u5316\u63d0\u4f9b\u4e86\u5b9e\u7528\u6539\u8fdb\uff0c\u5f00\u8f9f\u4e86\u65e0\u8bad\u7ec3\u5d4c\u5165\u4f18\u5316\u7cfb\u7edf\u7684\u65b0\u65b9\u5411\u3002"}}
{"id": "2506.05862", "pdf": "https://arxiv.org/pdf/2506.05862", "abs": "https://arxiv.org/abs/2506.05862", "authors": ["Rembert Daems", "Sven Seys", "Val\u00e9rie Hox", "Adam Chaker", "Glynnis De Greve", "Winde Lemmens", "Anne-Lise Poirrier", "Eline Beckers", "Zuzana Diamant", "Carmen Dierickx", "Peter W. Hellings", "Caroline Huart", "Claudia Jerin", "Mark Jorissen", "Hanne Osc\u00e9", "Karolien Roux", "Mark Thompson", "Sophie Tombu", "Saartje Uyttebroek", "Andrzej Zarowski", "Senne Gorris", "Laura Van Gerven", "Dirk Loeckx", "Thomas Demeester"], "title": "Improved Allergy Wheal Detection for the Skin Prick Automated Test Device", "categories": ["cs.CV", "cs.LG"], "comment": "This work is presented at Artificial Intelligence in Medicine 2025,\n  this is the longer (10 pages) version", "summary": "Background: The skin prick test (SPT) is the gold standard for diagnosing\nsensitization to inhalant allergies. The Skin Prick Automated Test (SPAT)\ndevice was designed for increased consistency in test results, and captures 32\nimages to be jointly used for allergy wheal detection and delineation, which\nleads to a diagnosis.\n  Materials and Methods: Using SPAT data from $868$ patients with suspected\ninhalant allergies, we designed an automated method to detect and delineate\nwheals on these images. To this end, $10,416$ wheals were manually annotated by\ndrawing detailed polygons along the edges. The unique data-modality of the SPAT\ndevice, with $32$ images taken under distinct lighting conditions, requires a\ncustom-made approach. Our proposed method consists of two parts: a neural\nnetwork component that segments the wheals on the pixel level, followed by an\nalgorithmic and interpretable approach for detecting and delineating the\nwheals.\n  Results: We evaluate the performance of our method on a hold-out validation\nset of $217$ patients. As a baseline we use a single conventionally lighted\nimage per SPT as input to our method.\n  Conclusion: Using the $32$ SPAT images under various lighting conditions\noffers a considerably higher accuracy than a single image in conventional,\nuniform light.", "AI": {"tldr": "SPAT\u8bbe\u5907\u901a\u8fc7\u591a\u5149\u7167\u6761\u4ef6\u56fe\u50cf\u63d0\u9ad8\u8fc7\u654f\u68c0\u6d4b\u51c6\u786e\u6027\uff0c\u7ed3\u5408\u795e\u7ecf\u7f51\u7edc\u548c\u7b97\u6cd5\u5b9e\u73b0\u81ea\u52a8\u5316\u68c0\u6d4b\u3002", "motivation": "\u63d0\u9ad8\u76ae\u80a4\u70b9\u523a\u8bd5\u9a8c\uff08SPT\uff09\u7684\u68c0\u6d4b\u4e00\u81f4\u6027\u548c\u51c6\u786e\u6027\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u5355\u4e00\u5149\u7167\u56fe\u50cf\u7684\u5c40\u9650\u6027\u3002", "method": "\u4f7f\u7528SPAT\u8bbe\u5907\u768432\u5f20\u591a\u5149\u7167\u56fe\u50cf\uff0c\u7ed3\u5408\u795e\u7ecf\u7f51\u7edc\u5206\u5272\u548c\u7b97\u6cd5\u68c0\u6d4b\uff0c\u624b\u52a8\u6807\u6ce810,416\u4e2a\u98ce\u56e2\u3002", "result": "\u5728217\u540d\u60a3\u8005\u7684\u9a8c\u8bc1\u96c6\u4e0a\uff0c\u591a\u5149\u7167\u56fe\u50cf\u6bd4\u5355\u5149\u7167\u56fe\u50cf\u663e\u8457\u63d0\u9ad8\u4e86\u68c0\u6d4b\u51c6\u786e\u6027\u3002", "conclusion": "\u591a\u5149\u7167\u6761\u4ef6\u4e0b\u7684SPAT\u56fe\u50cf\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u5355\u5149\u7167\u56fe\u50cf\uff0c\u4e3a\u8fc7\u654f\u8bca\u65ad\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u5de5\u5177\u3002"}}
{"id": "2506.05867", "pdf": "https://arxiv.org/pdf/2506.05867", "abs": "https://arxiv.org/abs/2506.05867", "authors": ["Zhixiong Zhuang", "Hui-Po Wang", "Maria-Irina Nicolae", "Mario Fritz"], "title": "Stealix: Model Stealing via Prompt Evolution", "categories": ["cs.CR", "cs.LG"], "comment": "Accepted at ICML 2025. The project page is at\n  https://zhixiongzh.github.io/stealix/", "summary": "Model stealing poses a significant security risk in machine learning by\nenabling attackers to replicate a black-box model without access to its\ntraining data, thus jeopardizing intellectual property and exposing sensitive\ninformation. Recent methods that use pre-trained diffusion models for data\nsynthesis improve efficiency and performance but rely heavily on manually\ncrafted prompts, limiting automation and scalability, especially for attackers\nwith little expertise. To assess the risks posed by open-source pre-trained\nmodels, we propose a more realistic threat model that eliminates the need for\nprompt design skills or knowledge of class names. In this context, we introduce\nStealix, the first approach to perform model stealing without predefined\nprompts. Stealix uses two open-source pre-trained models to infer the victim\nmodel's data distribution, and iteratively refines prompts through a genetic\nalgorithm, progressively improving the precision and diversity of synthetic\nimages. Our experimental results demonstrate that Stealix significantly\noutperforms other methods, even those with access to class names or\nfine-grained prompts, while operating under the same query budget. These\nfindings highlight the scalability of our approach and suggest that the risks\nposed by pre-trained generative models in model stealing may be greater than\npreviously recognized.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faStealix\u65b9\u6cd5\uff0c\u9996\u6b21\u5b9e\u73b0\u65e0\u9700\u9884\u5b9a\u4e49\u63d0\u793a\u7684\u6a21\u578b\u7a83\u53d6\uff0c\u5229\u7528\u9057\u4f20\u7b97\u6cd5\u4f18\u5316\u63d0\u793a\uff0c\u663e\u8457\u63d0\u5347\u5408\u6210\u56fe\u50cf\u7684\u7cbe\u5ea6\u548c\u591a\u6837\u6027\u3002", "motivation": "\u6a21\u578b\u7a83\u53d6\u5bf9\u673a\u5668\u5b66\u4e60\u5b89\u5168\u6784\u6210\u5a01\u80c1\uff0c\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u8bbe\u8ba1\u63d0\u793a\uff0c\u9650\u5236\u4e86\u81ea\u52a8\u5316\u548c\u53ef\u6269\u5c55\u6027\u3002", "method": "Stealix\u7ed3\u5408\u4e24\u4e2a\u5f00\u6e90\u9884\u8bad\u7ec3\u6a21\u578b\u63a8\u65ad\u53d7\u5bb3\u8005\u6a21\u578b\u7684\u6570\u636e\u5206\u5e03\uff0c\u901a\u8fc7\u9057\u4f20\u7b97\u6cd5\u8fed\u4ee3\u4f18\u5316\u63d0\u793a\u3002", "result": "\u5b9e\u9a8c\u663e\u793aStealix\u5728\u76f8\u540c\u67e5\u8be2\u9884\u7b97\u4e0b\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u5373\u4f7f\u5bf9\u624b\u5177\u5907\u7c7b\u522b\u540d\u6216\u7cbe\u7ec6\u63d0\u793a\u3002", "conclusion": "\u9884\u8bad\u7ec3\u751f\u6210\u6a21\u578b\u5728\u6a21\u578b\u7a83\u53d6\u4e2d\u7684\u98ce\u9669\u53ef\u80fd\u88ab\u4f4e\u4f30\uff0cStealix\u5c55\u793a\u4e86\u5176\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2506.05888", "pdf": "https://arxiv.org/pdf/2506.05888", "abs": "https://arxiv.org/abs/2506.05888", "authors": ["Luca Nepote", "Alix Lh\u00e9ritier", "Nicolas Bondoux", "Marios Kountouris", "Maurizio Filippone"], "title": "Variational Inference for Quantum HyperNetworks", "categories": ["quant-ph", "cs.LG", "stat.ML", "68Q12"], "comment": "This work has been accepted for publication in 2025 International\n  Joint Conference on Neural Networks (IJCNN 2025) and will be published on\n  IEEE Xplore", "summary": "Binary Neural Networks (BiNNs), which employ single-bit precision weights,\nhave emerged as a promising solution to reduce memory usage and power\nconsumption while maintaining competitive performance in large-scale systems.\nHowever, training BiNNs remains a significant challenge due to the limitations\nof conventional training algorithms. Quantum HyperNetworks offer a novel\nparadigm for enhancing the optimization of BiNN by leveraging quantum\ncomputing. Specifically, a Variational Quantum Algorithm is employed to\ngenerate binary weights through quantum circuit measurements, while key quantum\nphenomena such as superposition and entanglement facilitate the exploration of\na broader solution space. In this work, we establish a connection between this\napproach and Bayesian inference by deriving the Evidence Lower Bound (ELBO),\nwhen direct access to the output distribution is available (i.e., in\nsimulations), and introducing a surrogate ELBO based on the Maximum Mean\nDiscrepancy (MMD) metric for scenarios involving implicit distributions, as\ncommonly encountered in practice. Our experimental results demonstrate that the\nproposed methods outperform standard Maximum Likelihood Estimation (MLE),\nimproving trainability and generalization.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u91cf\u5b50\u8d85\u7f51\u7edc\u4f18\u5316\u4e8c\u8fdb\u5236\u795e\u7ecf\u7f51\u7edc\uff08BiNNs\uff09\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cf\u5b50\u8ba1\u7b97\u751f\u6210\u4e8c\u8fdb\u5236\u6743\u91cd\uff0c\u5e76\u63a2\u7d22\u66f4\u5e7f\u7684\u89e3\u7a7a\u95f4\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u4f18\u4e8e\u4f20\u7edf\u7684\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u3002", "motivation": "\u4e8c\u8fdb\u5236\u795e\u7ecf\u7f51\u7edc\uff08BiNNs\uff09\u5728\u51cf\u5c11\u5185\u5b58\u548c\u529f\u8017\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u4f20\u7edf\u8bad\u7ec3\u7b97\u6cd5\u5b58\u5728\u5c40\u9650\u6027\u3002\u91cf\u5b50\u8ba1\u7b97\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u4f18\u5316\u9014\u5f84\u3002", "method": "\u91c7\u7528\u53d8\u5206\u91cf\u5b50\u7b97\u6cd5\u751f\u6210\u4e8c\u8fdb\u5236\u6743\u91cd\uff0c\u5229\u7528\u91cf\u5b50\u53e0\u52a0\u548c\u7ea0\u7f20\u63a2\u7d22\u89e3\u7a7a\u95f4\u3002\u901a\u8fc7\u63a8\u5bfc\u8bc1\u636e\u4e0b\u754c\uff08ELBO\uff09\u548c\u5f15\u5165\u57fa\u4e8e\u6700\u5927\u5747\u503c\u5dee\u5f02\uff08MMD\uff09\u7684\u66ff\u4ee3ELBO\uff0c\u4f18\u5316\u8bad\u7ec3\u8fc7\u7a0b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u53ef\u8bad\u7ec3\u6027\u548c\u6cdb\u5316\u80fd\u529b\u4e0a\u4f18\u4e8e\u4f20\u7edf\u7684\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\uff08MLE\uff09\u3002", "conclusion": "\u91cf\u5b50\u8d85\u7f51\u7edc\u4e3aBiNNs\u7684\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u65b0\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002"}}
{"id": "2506.05894", "pdf": "https://arxiv.org/pdf/2506.05894", "abs": "https://arxiv.org/abs/2506.05894", "authors": ["Philipp Plank", "Yufei Zhang"], "title": "Policy Optimization for Continuous-time Linear-Quadratic Graphon Mean Field Games", "categories": ["math.OC", "cs.LG", "math.PR", "68Q25, 91A15, 49N80, 91A07, 91A43, 49N10"], "comment": null, "summary": "Multi-agent reinforcement learning, despite its popularity and empirical\nsuccess, faces significant scalability challenges in large-population dynamic\ngames. Graphon mean field games (GMFGs) offer a principled framework for\napproximating such games while capturing heterogeneity among players. In this\npaper, we propose and analyze a policy optimization framework for\ncontinuous-time, finite-horizon linear-quadratic GMFGs. Exploiting the\nstructural properties of GMFGs, we design an efficient policy parameterization\nin which each player's policy is represented as an affine function of their\nprivate state, with a shared slope function and player-specific intercepts. We\ndevelop a bilevel optimization algorithm that alternates between policy\ngradient updates for best-response computation under a fixed population\ndistribution, and distribution updates using the resulting policies. We prove\nlinear convergence of the policy gradient steps to best-response policies and\nestablish global convergence of the overall algorithm to the Nash equilibrium.\nThe analysis relies on novel landscape characterizations over\ninfinite-dimensional policy spaces. Numerical experiments demonstrate the\nconvergence and robustness of the proposed algorithm under varying graphon\nstructures, noise levels, and action frequencies.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u8fde\u7eed\u65f6\u95f4\u6709\u9650\u89c6\u91ce\u7ebf\u6027\u4e8c\u6b21\u56fe\u5e73\u5747\u573a\u6e38\u620f\uff08GMFGs\uff09\u7684\u7b56\u7565\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u5c42\u4f18\u5316\u7b97\u6cd5\u5b9e\u73b0\u7eb3\u4ec0\u5747\u8861\u7684\u5168\u5c40\u6536\u655b\u3002", "motivation": "\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u5728\u5927\u89c4\u6a21\u52a8\u6001\u6e38\u620f\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u540c\u65f6\u6355\u6349\u73a9\u5bb6\u95f4\u7684\u5f02\u8d28\u6027\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u7b56\u7565\u53c2\u6570\u5316\u65b9\u6cd5\uff0c\u5c06\u6bcf\u4e2a\u73a9\u5bb6\u7684\u7b56\u7565\u8868\u793a\u4e3a\u79c1\u6709\u72b6\u6001\u7684\u4eff\u5c04\u51fd\u6570\uff0c\u5e76\u5f00\u53d1\u4e86\u53cc\u5c42\u4f18\u5316\u7b97\u6cd5\uff0c\u4ea4\u66ff\u8fdb\u884c\u7b56\u7565\u68af\u5ea6\u66f4\u65b0\u548c\u5206\u5e03\u66f4\u65b0\u3002", "result": "\u8bc1\u660e\u4e86\u7b56\u7565\u68af\u5ea6\u6b65\u9aa4\u5bf9\u6700\u4f73\u54cd\u5e94\u7b56\u7565\u7684\u7ebf\u6027\u6536\u655b\u6027\uff0c\u5e76\u5efa\u7acb\u4e86\u7b97\u6cd5\u5bf9\u7eb3\u4ec0\u5747\u8861\u7684\u5168\u5c40\u6536\u655b\u6027\u3002", "conclusion": "\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u5728\u4e0d\u540c\u56fe\u7ed3\u6784\u3001\u566a\u58f0\u6c34\u5e73\u548c\u52a8\u4f5c\u9891\u7387\u4e0b\u7684\u6536\u655b\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2506.05917", "pdf": "https://arxiv.org/pdf/2506.05917", "abs": "https://arxiv.org/abs/2506.05917", "authors": ["Steven Landgraf", "Markus Hillemann", "Markus Ulrich"], "title": "Rethinking Semi-supervised Segmentation Beyond Accuracy: Reliability and Robustness", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Semantic segmentation is critical for scene understanding but demands costly\npixel-wise annotations, attracting increasing attention to semi-supervised\napproaches to leverage abundant unlabeled data. While semi-supervised\nsegmentation is often promoted as a path toward scalable, real-world\ndeployment, it is astonishing that current evaluation protocols exclusively\nfocus on segmentation accuracy, entirely overlooking reliability and\nrobustness. These qualities, which ensure consistent performance under diverse\nconditions (robustness) and well-calibrated model confidences as well as\nmeaningful uncertainties (reliability), are essential for safety-critical\napplications like autonomous driving, where models must handle unpredictable\nenvironments and avoid sudden failures at all costs. To address this gap, we\nintroduce the Reliable Segmentation Score (RSS), a novel metric that combines\npredictive accuracy, calibration, and uncertainty quality measures via a\nharmonic mean. RSS penalizes deficiencies in any of its components, providing\nan easy and intuitive way of holistically judging segmentation models.\nComprehensive evaluations of UniMatchV2 against its predecessor and a\nsupervised baseline show that semi-supervised methods often trade reliability\nfor accuracy. While out-of-domain evaluations demonstrate UniMatchV2's\nrobustness, they further expose persistent reliability shortcomings. We\nadvocate for a shift in evaluation protocols toward more holistic metrics like\nRSS to better align semi-supervised learning research with real-world\ndeployment needs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8bc4\u4f30\u6307\u6807RSS\uff0c\u7528\u4e8e\u7efc\u5408\u8861\u91cf\u534a\u76d1\u7763\u8bed\u4e49\u5206\u5272\u6a21\u578b\u7684\u51c6\u786e\u6027\u3001\u53ef\u9760\u6027\u548c\u9c81\u68d2\u6027\uff0c\u586b\u8865\u4e86\u5f53\u524d\u8bc4\u4f30\u534f\u8bae\u7684\u4e0d\u8db3\u3002", "motivation": "\u5f53\u524d\u534a\u76d1\u7763\u5206\u5272\u8bc4\u4f30\u4ec5\u5173\u6ce8\u51c6\u786e\u6027\uff0c\u5ffd\u7565\u4e86\u53ef\u9760\u6027\u548c\u9c81\u68d2\u6027\uff0c\u800c\u8fd9\u4e9b\u5bf9\u5b89\u5168\u5173\u952e\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5f15\u5165Reliable Segmentation Score (RSS)\uff0c\u901a\u8fc7\u8c03\u548c\u5e73\u5747\u503c\u7ed3\u5408\u9884\u6d4b\u51c6\u786e\u6027\u3001\u6821\u51c6\u548c\u4e0d\u786e\u5b9a\u6027\u8d28\u91cf\u3002", "result": "\u534a\u76d1\u7763\u65b9\u6cd5\u5e38\u4ee5\u727a\u7272\u53ef\u9760\u6027\u6362\u53d6\u51c6\u786e\u6027\uff0cUniMatchV2\u5728\u9c81\u68d2\u6027\u4e0a\u8868\u73b0\u826f\u597d\u4f46\u53ef\u9760\u6027\u4ecd\u6709\u4e0d\u8db3\u3002", "conclusion": "\u5efa\u8bae\u91c7\u7528RSS\u7b49\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u6307\u6807\uff0c\u4ee5\u66f4\u597d\u5730\u6ee1\u8db3\u5b9e\u9645\u90e8\u7f72\u9700\u6c42\u3002"}}
{"id": "2506.05958", "pdf": "https://arxiv.org/pdf/2506.05958", "abs": "https://arxiv.org/abs/2506.05958", "authors": ["Alicia Beneyto-Rodriguez", "Gregorio I. Sainz-Palmero", "Marta Galende-Hern\u00e1ndez", "Mar\u00eda J. Fuente", "Jos\u00e9 M. Cuenca"], "title": "Applying XAI based unsupervised knowledge discovering for Operation modes in a WWTP. A real case: AQUAVALL WWTP", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": null, "summary": "Water reuse is a key point when fresh water is a commodity in ever greater\ndemand, but which is also becoming ever more available. Furthermore, the return\nof clean water to its natural environment is also mandatory. Therefore,\nwastewater treatment plants (WWTPs) are essential in any policy focused on\nthese serious challenges.\n  WWTPs are complex facilities which need to operate at their best to achieve\ntheir goals. Nowadays, they are largely monitored, generating large databases\nof historical data concerning their functioning over time. All this implies a\nlarge amount of embedded information which is not usually easy for plant\nmanagers to assimilate, correlate and understand; in other words, for them to\nknow the global operation of the plant at any given time. At this point, the\nintelligent and Machine Learning (ML) approaches can give support for that\nneed, managing all the data and translating them into manageable, interpretable\nand explainable knowledge about how the WWTP plant is operating at a glance.\n  Here, an eXplainable Artificial Intelligence (XAI) based methodology is\nproposed and tested for a real WWTP, in order to extract explainable service\nknowledge concerning the operation modes of the WWTP managed by AQUAVALL, which\nis the public service in charge of the integral water cycle in the City Council\nof Valladolid (Castilla y Le\\'on, Spain). By applying well-known approaches of\nXAI and ML focused on the challenge of WWTP, it has been possible to summarize\na large number of historical databases through a few explained operation modes\nof the plant in a low-dimensional data space, showing the variables and\nfacility units involved in each case.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\uff08XAI\uff09\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u4ece\u6c61\u6c34\u5904\u7406\u5382\uff08WWTP\uff09\u7684\u5386\u53f2\u6570\u636e\u4e2d\u63d0\u53d6\u53ef\u89e3\u91ca\u7684\u64cd\u4f5c\u6a21\u5f0f\uff0c\u5e2e\u52a9\u7ba1\u7406\u8005\u5feb\u901f\u7406\u89e3\u5de5\u5382\u8fd0\u884c\u72b6\u6001\u3002", "motivation": "\u968f\u7740\u6de1\u6c34\u9700\u6c42\u589e\u52a0\uff0c\u5e9f\u6c34\u5904\u7406\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u6c61\u6c34\u5904\u7406\u5382\uff08WWTP\uff09\u751f\u6210\u5927\u91cf\u6570\u636e\uff0c\u4f46\u7ba1\u7406\u8005\u96be\u4ee5\u4ece\u4e2d\u63d0\u53d6\u6709\u7528\u4fe1\u606f\u3002XAI\u548c\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u53ef\u4ee5\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u91c7\u7528XAI\u548cML\u65b9\u6cd5\uff0c\u5bf9\u897f\u73ed\u7259Valladolid\u5e02AQUAVALL\u7ba1\u7406\u7684WWTP\u5386\u53f2\u6570\u636e\u8fdb\u884c\u5206\u6790\uff0c\u63d0\u53d6\u4f4e\u7ef4\u6570\u636e\u7a7a\u95f4\u4e2d\u7684\u53ef\u89e3\u91ca\u64cd\u4f5c\u6a21\u5f0f\u3002", "result": "\u6210\u529f\u4ece\u5927\u91cf\u5386\u53f2\u6570\u636e\u4e2d\u603b\u7ed3\u51fa\u5c11\u6570\u53ef\u89e3\u91ca\u7684\u64cd\u4f5c\u6a21\u5f0f\uff0c\u5e76\u8bc6\u522b\u51fa\u76f8\u5173\u53d8\u91cf\u548c\u8bbe\u65bd\u5355\u5143\u3002", "conclusion": "XAI\u65b9\u6cd5\u80fd\u6709\u6548\u5e2e\u52a9\u6c61\u6c34\u5904\u7406\u5382\u7ba1\u7406\u8005\u5feb\u901f\u7406\u89e3\u8fd0\u884c\u72b6\u6001\uff0c\u4e3a\u51b3\u7b56\u63d0\u4f9b\u652f\u6301\u3002"}}
{"id": "2506.05967", "pdf": "https://arxiv.org/pdf/2506.05967", "abs": "https://arxiv.org/abs/2506.05967", "authors": ["Katarzyna Kobalczyk", "Mihaela van der Schaar"], "title": "Preference Learning for AI Alignment: a Causal Perspective", "categories": ["cs.AI", "cs.LG", "stat.ML"], "comment": null, "summary": "Reward modelling from preference data is a crucial step in aligning large\nlanguage models (LLMs) with human values, requiring robust generalisation to\nnovel prompt-response pairs. In this work, we propose to frame this problem in\na causal paradigm, providing the rich toolbox of causality to identify the\npersistent challenges, such as causal misidentification, preference\nheterogeneity, and confounding due to user-specific factors. Inheriting from\nthe literature of causal inference, we identify key assumptions necessary for\nreliable generalisation and contrast them with common data collection\npractices. We illustrate failure modes of naive reward models and demonstrate\nhow causally-inspired approaches can improve model robustness. Finally, we\noutline desiderata for future research and practices, advocating targeted\ninterventions to address inherent limitations of observational data.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u7528\u56e0\u679c\u8303\u5f0f\u89e3\u51b3\u5956\u52b1\u5efa\u6a21\u95ee\u9898\uff0c\u4ee5\u5e94\u5bf9\u56e0\u679c\u8bef\u8bc6\u522b\u3001\u504f\u597d\u5f02\u8d28\u6027\u548c\u7528\u6237\u7279\u5b9a\u56e0\u7d20\u7b49\u6311\u6218\u3002", "motivation": "\u5956\u52b1\u5efa\u6a21\u662f\u4f7f\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u5bf9\u9f50\u7684\u5173\u952e\u6b65\u9aa4\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u6cdb\u5316\u6027\u4e0a\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u91c7\u7528\u56e0\u679c\u63a8\u65ad\u7684\u5de5\u5177\uff0c\u8bc6\u522b\u53ef\u9760\u6cdb\u5316\u7684\u5173\u952e\u5047\u8bbe\uff0c\u5e76\u4e0e\u5e38\u89c1\u6570\u636e\u6536\u96c6\u5b9e\u8df5\u5bf9\u6bd4\u3002", "result": "\u5c55\u793a\u4e86\u6734\u7d20\u5956\u52b1\u6a21\u578b\u7684\u5931\u8d25\u6a21\u5f0f\uff0c\u5e76\u8bc1\u660e\u56e0\u679c\u542f\u53d1\u65b9\u6cd5\u80fd\u63d0\u5347\u6a21\u578b\u9c81\u68d2\u6027\u3002", "conclusion": "\u63d0\u51fa\u672a\u6765\u7814\u7a76\u7684\u7406\u60f3\u76ee\u6807\uff0c\u5efa\u8bae\u901a\u8fc7\u9488\u5bf9\u6027\u5e72\u9884\u89e3\u51b3\u89c2\u6d4b\u6570\u636e\u7684\u56fa\u6709\u5c40\u9650\u6027\u3002"}}
{"id": "2506.06024", "pdf": "https://arxiv.org/pdf/2506.06024", "abs": "https://arxiv.org/abs/2506.06024", "authors": ["Deborah Pereg"], "title": "On Inverse Problems, Parameter Estimation, and Domain Generalization", "categories": ["cs.IT", "cs.LG", "math.IT"], "comment": null, "summary": "Signal restoration and inverse problems are key elements in most real-world\ndata science applications. In the past decades, with the emergence of machine\nlearning methods, inversion of measurements has become a popular step in almost\nall physical applications, which is normally executed prior to downstream tasks\nthat often involve parameter estimation. In this work, we analyze the general\nproblem of parameter estimation in an inverse problem setting. First, we\naddress the domain-shift problem by re-formulating it in direct relation with\nthe discrete parameter estimation analysis. We analyze a significant\nvulnerability in current attempts to enforce domain generalization, which we\ndubbed the Double Meaning Theorem. Our theoretical findings are experimentally\nillustrated for domain shift examples in image deblurring and speckle\nsuppression in medical imaging. We then proceed to a theoretical analysis of\nparameter estimation given observed measurements before and after data\nprocessing involving an inversion of the observations. We compare this setting\nfor invertible and non-invertible (degradation) processes. We distinguish\nbetween continuous and discrete parameter estimation, corresponding with\nregression and classification problems, respectively. Our theoretical findings\nalign with the well-known information-theoretic data processing inequality, and\nto a certain degree question the common misconception that data-processing for\ninversion, based on modern generative models that may often produce outstanding\nperceptual quality, will necessarily improve the following parameter estimation\nobjective. It is our hope that this paper will provide practitioners with\ndeeper insights that may be leveraged in the future for the development of more\nefficient and informed strategic system planning, critical in safety-sensitive\napplications.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u9006\u95ee\u9898\u4e2d\u7684\u53c2\u6570\u4f30\u8ba1\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u57df\u504f\u79fb\u95ee\u9898\u7684\u91cd\u65b0\u8868\u8ff0\uff0c\u5e76\u63ed\u793a\u4e86\u5f53\u524d\u57df\u6cdb\u5316\u65b9\u6cd5\u7684\u8106\u5f31\u6027\uff08\u53cc\u4e49\u5b9a\u7406\uff09\u3002\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u53d1\u73b0\uff0c\u5e76\u6bd4\u8f83\u4e86\u53ef\u9006\u4e0e\u4e0d\u53ef\u9006\u8fc7\u7a0b\u4e2d\u7684\u53c2\u6570\u4f30\u8ba1\u3002", "motivation": "\u7814\u7a76\u9006\u95ee\u9898\u4e2d\u7684\u53c2\u6570\u4f30\u8ba1\uff0c\u89e3\u51b3\u57df\u504f\u79fb\u95ee\u9898\uff0c\u5e76\u63a2\u8ba8\u6570\u636e\u9884\u5904\u7406\u5bf9\u53c2\u6570\u4f30\u8ba1\u7684\u5f71\u54cd\u3002", "method": "\u91cd\u65b0\u8868\u8ff0\u57df\u504f\u79fb\u95ee\u9898\uff0c\u5206\u6790\u53cc\u4e49\u5b9a\u7406\uff0c\u5e76\u901a\u8fc7\u56fe\u50cf\u53bb\u6a21\u7cca\u548c\u533b\u5b66\u56fe\u50cf\u53bb\u566a\u5b9e\u9a8c\u9a8c\u8bc1\u7406\u8bba\u3002\u6bd4\u8f83\u53ef\u9006\u4e0e\u4e0d\u53ef\u9006\u8fc7\u7a0b\u7684\u53c2\u6570\u4f30\u8ba1\u3002", "result": "\u53d1\u73b0\u6570\u636e\u9884\u5904\u7406\uff08\u5982\u57fa\u4e8e\u751f\u6210\u6a21\u578b\u7684\u9006\u95ee\u9898\u6c42\u89e3\uff09\u672a\u5fc5\u80fd\u6539\u5584\u53c2\u6570\u4f30\u8ba1\u6027\u80fd\uff0c\u4e0e\u4fe1\u606f\u8bba\u6570\u636e\u5904\u7406\u4e0d\u7b49\u5f0f\u4e00\u81f4\u3002", "conclusion": "\u672c\u6587\u4e3a\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u66f4\u6df1\u5165\u7684\u89c1\u89e3\uff0c\u6709\u52a9\u4e8e\u5728\u5b89\u5168\u654f\u611f\u5e94\u7528\u4e2d\u5236\u5b9a\u66f4\u9ad8\u6548\u7684\u7cfb\u7edf\u7b56\u7565\u3002"}}
{"id": "2506.06027", "pdf": "https://arxiv.org/pdf/2506.06027", "abs": "https://arxiv.org/abs/2506.06027", "authors": ["Yuhao Sun", "Jiacheng Zhang", "Zesheng Ye", "Chaowei Xiao", "Feng Liu"], "title": "Sample-Specific Noise Injection For Diffusion-Based Adversarial Purification", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Diffusion-based purification (DBP) methods aim to remove adversarial noise\nfrom the input sample by first injecting Gaussian noise through a forward\ndiffusion process, and then recovering the clean example through a reverse\ngenerative process. In the above process, how much Gaussian noise is injected\nto the input sample is key to the success of DBP methods, which is controlled\nby a constant noise level $t^*$ for all samples in existing methods. In this\npaper, we discover that an optimal $t^*$ for each sample indeed could be\ndifferent. Intuitively, the cleaner a sample is, the less the noise it should\nbe injected, and vice versa. Motivated by this finding, we propose a new\nframework, called Sample-specific Score-aware Noise Injection (SSNI).\nSpecifically, SSNI uses a pre-trained score network to estimate how much a data\npoint deviates from the clean data distribution (i.e., score norms). Then,\nbased on the magnitude of score norms, SSNI applies a reweighting function to\nadaptively adjust $t^*$ for each sample, achieving sample-specific noise\ninjections. Empirically, incorporating our framework with existing DBP methods\nresults in a notable improvement in both accuracy and robustness on CIFAR-10\nand ImageNet-1K, highlighting the necessity to allocate distinct noise levels\nto different samples in DBP methods. Our code is available at:\nhttps://github.com/tmlr-group/SSNI.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSSNI\u7684\u6837\u672c\u7279\u5f02\u6027\u566a\u58f0\u6ce8\u5165\u6846\u67b6\uff0c\u901a\u8fc7\u9884\u8bad\u7ec3\u7684\u8bc4\u5206\u7f51\u7edc\u52a8\u6001\u8c03\u6574\u566a\u58f0\u6c34\u5e73\uff0c\u663e\u8457\u63d0\u5347\u4e86DBP\u65b9\u6cd5\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709DBP\u65b9\u6cd5\u5bf9\u6240\u6709\u6837\u672c\u4f7f\u7528\u56fa\u5b9a\u566a\u58f0\u6c34\u5e73$t^*$\uff0c\u800c\u7814\u7a76\u53d1\u73b0\u4e0d\u540c\u6837\u672c\u7684\u6700\u4f18$t^*$\u53ef\u80fd\u4e0d\u540c\uff0c\u56e0\u6b64\u63d0\u51fa\u52a8\u6001\u8c03\u6574\u566a\u58f0\u6c34\u5e73\u7684\u5fc5\u8981\u6027\u3002", "method": "SSNI\u5229\u7528\u9884\u8bad\u7ec3\u7684\u8bc4\u5206\u7f51\u7edc\u4f30\u8ba1\u6837\u672c\u504f\u79bb\u5e72\u51c0\u6570\u636e\u5206\u5e03\u7684\u7a0b\u5ea6\uff08\u8bc4\u5206\u8303\u6570\uff09\uff0c\u5e76\u57fa\u4e8e\u8bc4\u5206\u8303\u6570\u52a8\u6001\u8c03\u6574\u566a\u58f0\u6c34\u5e73$t^*$\u3002", "result": "\u5728CIFAR-10\u548cImageNet-1K\u6570\u636e\u96c6\u4e0a\uff0cSSNI\u663e\u8457\u63d0\u5347\u4e86DBP\u65b9\u6cd5\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u4e3a\u4e0d\u540c\u6837\u672c\u5206\u914d\u4e0d\u540c\u7684\u566a\u58f0\u6c34\u5e73\u662fDBP\u65b9\u6cd5\u7684\u5173\u952e\u6539\u8fdb\u65b9\u5411\u3002"}}
{"id": "2506.06041", "pdf": "https://arxiv.org/pdf/2506.06041", "abs": "https://arxiv.org/abs/2506.06041", "authors": ["Joscha Diehl", "Rasheed Ibraheem", "Leonard Schmitz", "Yue Wu"], "title": "Tensor-to-Tensor Models with Fast Iterated Sum Features", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Data in the form of images or higher-order tensors is ubiquitous in modern\ndeep learning applications. Owing to their inherent high dimensionality, the\nneed for subquadratic layers processing such data is even more pressing than\nfor sequence data. We propose a novel tensor-to-tensor layer with linear cost\nin the input size, utilizing the mathematical gadget of ``corner trees'' from\nthe field of permutation counting. In particular, for order-two tensors, we\nprovide an image-to-image layer that can be plugged into image processing\npipelines. On the one hand, our method can be seen as a higher-order\ngeneralization of state-space models. On the other hand, it is based on a\nmultiparameter generalization of the signature of iterated integrals (or sums).\nThe proposed tensor-to-tensor concept is used to build a neural network layer\ncalled the Fast Iterated Sums (FIS) layer which integrates seamlessly with\nother layer types. We demonstrate the usability of the FIS layer with both\nclassification and anomaly detection tasks. By replacing some layers of a\nsmaller ResNet architecture with FIS, a similar accuracy (with a difference of\nonly 0.1\\%) was achieved in comparison to a larger ResNet while reducing the\nnumber of trainable parameters and multi-add operations. The FIS layer was also\nused to build an anomaly detection model that achieved an average AUROC of\n97.3\\% on the texture images of the popular MVTec AD dataset. The processing\nand modelling codes are publicly available at\nhttps://github.com/diehlj/fast-iterated-sums.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u201c\u89d2\u6811\u201d\u6570\u5b66\u5de5\u5177\u7684\u65b0\u578b\u5f20\u91cf\u5230\u5f20\u91cf\u5c42\uff08FIS\u5c42\uff09\uff0c\u5177\u6709\u7ebf\u6027\u8ba1\u7b97\u6210\u672c\uff0c\u9002\u7528\u4e8e\u56fe\u50cf\u548c\u9ad8\u9636\u5f20\u91cf\u6570\u636e\u5904\u7406\u3002", "motivation": "\u73b0\u4ee3\u6df1\u5ea6\u5b66\u4e60\u5e94\u7528\u4e2d\uff0c\u56fe\u50cf\u548c\u9ad8\u9636\u5f20\u91cf\u6570\u636e\u7684\u9ad8\u7ef4\u5ea6\u7279\u6027\u9700\u8981\u6b21\u4e8c\u6b21\u8ba1\u7b97\u590d\u6742\u5ea6\u7684\u5c42\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u6ee1\u8db3\u9700\u6c42\u3002", "method": "\u5229\u7528\u201c\u89d2\u6811\u201d\u548c\u591a\u91cd\u53c2\u6570\u5316\u7684\u8fed\u4ee3\u79ef\u5206\uff08\u6216\u6c42\u548c\uff09\u7b7e\u540d\uff0c\u6784\u5efa\u4e86FIS\u5c42\uff0c\u53ef\u65e0\u7f1d\u96c6\u6210\u5230\u795e\u7ecf\u7f51\u7edc\u4e2d\u3002", "result": "\u5728\u5206\u7c7b\u548c\u5f02\u5e38\u68c0\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u66ff\u6362ResNet\u90e8\u5206\u5c42\u540e\uff0c\u53c2\u6570\u91cf\u548c\u8ba1\u7b97\u91cf\u51cf\u5c11\uff0c\u7cbe\u5ea6\u4ec5\u4e0b\u964d0.1%\uff1b\u5f02\u5e38\u68c0\u6d4b\u6a21\u578b\u5728MVTec AD\u6570\u636e\u96c6\u4e0aAUROC\u8fbe97.3%\u3002", "conclusion": "FIS\u5c42\u4e3a\u9ad8\u7ef4\u6570\u636e\u5904\u7406\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u517c\u5177\u8ba1\u7b97\u6548\u7387\u548c\u6027\u80fd\u4f18\u52bf\u3002"}}
{"id": "2506.06042", "pdf": "https://arxiv.org/pdf/2506.06042", "abs": "https://arxiv.org/abs/2506.06042", "authors": ["Taoran Yue", "Xiaojin Lu", "Jiaxi Cai", "Yuanping Chen", "Shibing Chu"], "title": "SDS-Net: Shallow-Deep Synergism-detection Network for infrared small target detection", "categories": ["cs.CV", "cs.LG"], "comment": "13 pages,9 figures, Submitted IEEE Transactions on Geoscience and\n  Remote Sensing", "summary": "Current CNN-based infrared small target detection(IRSTD) methods generally\noverlook the heterogeneity between shallow and deep features, leading to\ninefficient collaboration between shallow fine grained structural information\nand deep high-level semantic representations. Additionally, the dependency\nrelationships and fusion mechanisms across different feature hierarchies lack\nsystematic modeling, which fails to fully exploit the complementarity of\nmultilevel features. These limitations hinder IRSTD performance while incurring\nsubstantial computational costs. To address these challenges, this paper\nproposes a shallow-deep synergistic detection network (SDS-Net) that\nefficiently models multilevel feature representations to increase both the\ndetection accuracy and computational efficiency in IRSTD tasks. SDS-Net\nintroduces a dual-branch architecture that separately models the structural\ncharacteristics and semantic properties of features, effectively preserving\nshallow spatial details while capturing deep semantic representations, thereby\nachieving high-precision detection with significantly improved inference speed.\nFurthermore, the network incorporates an adaptive feature fusion module to\ndynamically model cross-layer feature correlations, enhancing overall feature\ncollaboration and representation capability. Comprehensive experiments on three\npublic datasets (NUAA-SIRST, NUDT-SIRST, and IRSTD-1K) demonstrate that SDS-Net\noutperforms state-of-the-art IRSTD methods while maintaining low computational\ncomplexity and high inference efficiency, showing superior detection\nperformance and broad application prospects. Our code will be made public at\nhttps://github.com/PhysiLearn/SDS-Net.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6d45\u5c42-\u6df1\u5c42\u534f\u540c\u68c0\u6d4b\u7f51\u7edc\uff08SDS-Net\uff09\uff0c\u901a\u8fc7\u53cc\u5206\u652f\u67b6\u6784\u548c\u81ea\u9002\u5e94\u7279\u5f81\u878d\u5408\u6a21\u5757\uff0c\u63d0\u5347\u7ea2\u5916\u5c0f\u76ee\u6807\u68c0\u6d4b\u7684\u7cbe\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u73b0\u6709CNN\u65b9\u6cd5\u5ffd\u89c6\u4e86\u6d45\u5c42\u548c\u6df1\u5c42\u7279\u5f81\u7684\u5f02\u8d28\u6027\uff0c\u5bfc\u81f4\u7279\u5f81\u534f\u4f5c\u4e0d\u8db3\uff0c\u5f71\u54cd\u68c0\u6d4b\u6027\u80fd\u548c\u8ba1\u7b97\u6548\u7387\u3002", "method": "\u91c7\u7528\u53cc\u5206\u652f\u67b6\u6784\u5206\u522b\u5efa\u6a21\u7ed3\u6784\u7279\u5f81\u548c\u8bed\u4e49\u7279\u5f81\uff0c\u5e76\u5f15\u5165\u81ea\u9002\u5e94\u7279\u5f81\u878d\u5408\u6a21\u5757\u52a8\u6001\u5efa\u6a21\u8de8\u5c42\u7279\u5f81\u76f8\u5173\u6027\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u4f4e\u8ba1\u7b97\u590d\u6742\u6027\u548c\u9ad8\u63a8\u7406\u6548\u7387\u3002", "conclusion": "SDS-Net\u5728\u68c0\u6d4b\u6027\u80fd\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u5747\u8868\u73b0\u51fa\u8272\uff0c\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2506.06069", "pdf": "https://arxiv.org/pdf/2506.06069", "abs": "https://arxiv.org/abs/2506.06069", "authors": ["Maor Ashkenazi", "Ofir Brenner", "Tal Furman Shohet", "Eran Treister"], "title": "Zero-Shot Detection of LLM-Generated Code via Approximated Task Conditioning", "categories": ["cs.CL", "cs.LG"], "comment": "To appear in the Proceedings of ECML-PKDD 2025, Springer Lecture\n  Notes in Computer Science (LNCS)", "summary": "Detecting Large Language Model (LLM)-generated code is a growing challenge\nwith implications for security, intellectual property, and academic integrity.\nWe investigate the role of conditional probability distributions in improving\nzero-shot LLM-generated code detection, when considering both the code and the\ncorresponding task prompt that generated it. Our key insight is that when\nevaluating the probability distribution of code tokens using an LLM, there is\nlittle difference between LLM-generated and human-written code. However,\nconditioning on the task reveals notable differences. This contrasts with\nnatural language text, where differences exist even in the unconditional\ndistributions. Leveraging this, we propose a novel zero-shot detection approach\nthat approximates the original task used to generate a given code snippet and\nthen evaluates token-level entropy under the approximated task conditioning\n(ATC). We further provide a mathematical intuition, contextualizing our method\nrelative to previous approaches. ATC requires neither access to the generator\nLLM nor the original task prompts, making it practical for real-world\napplications. To the best of our knowledge, it achieves state-of-the-art\nresults across benchmarks and generalizes across programming languages,\nincluding Python, CPP, and Java. Our findings highlight the importance of\ntask-level conditioning for LLM-generated code detection. The supplementary\nmaterials and code are available at https://github.com/maorash/ATC, including\nthe dataset gathering implementation, to foster further research in this area.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6761\u4ef6\u6982\u7387\u5206\u5e03\u7684\u65b0\u65b9\u6cd5\uff08ATC\uff09\uff0c\u7528\u4e8e\u96f6\u6837\u672c\u68c0\u6d4bLLM\u751f\u6210\u7684\u4ee3\u7801\uff0c\u65e0\u9700\u8bbf\u95ee\u751f\u6210\u6a21\u578b\u6216\u539f\u59cb\u4efb\u52a1\u63d0\u793a\uff0c\u5728\u591a\u79cd\u7f16\u7a0b\u8bed\u8a00\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "LLM\u751f\u6210\u7684\u4ee3\u7801\u68c0\u6d4b\u5bf9\u5b89\u5168\u3001\u77e5\u8bc6\u4ea7\u6743\u548c\u5b66\u672f\u8bda\u4fe1\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u533a\u5206LLM\u751f\u6210\u548c\u4eba\u7c7b\u7f16\u5199\u4ee3\u7801\u65f6\u6548\u679c\u6709\u9650\u3002", "method": "\u901a\u8fc7\u8fd1\u4f3c\u751f\u6210\u4ee3\u7801\u7684\u4efb\u52a1\u6761\u4ef6\uff08ATC\uff09\uff0c\u8bc4\u4f30\u4ee3\u7801\u6807\u8bb0\u7684\u71b5\u5dee\u5f02\uff0c\u5229\u7528\u4efb\u52a1\u7ea7\u6761\u4ef6\u6982\u7387\u5206\u5e03\u63d0\u9ad8\u68c0\u6d4b\u6548\u679c\u3002", "result": "ATC\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u4f18\u6027\u80fd\uff0c\u5e76\u652f\u6301\u591a\u79cd\u7f16\u7a0b\u8bed\u8a00\uff08\u5982Python\u3001CPP\u3001Java\uff09\u3002", "conclusion": "\u4efb\u52a1\u7ea7\u6761\u4ef6\u5bf9LLM\u751f\u6210\u4ee3\u7801\u68c0\u6d4b\u81f3\u5173\u91cd\u8981\uff0cATC\u65b9\u6cd5\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u76f8\u5173\u4ee3\u7801\u548c\u6570\u636e\u5df2\u5f00\u6e90\u3002"}}
{"id": "2506.06072", "pdf": "https://arxiv.org/pdf/2506.06072", "abs": "https://arxiv.org/abs/2506.06072", "authors": ["Hongyi Zhou", "Weiran Liao", "Xi Huang", "Yucheng Tang", "Fabian Otto", "Xiaogang Jia", "Xinkai Jiang", "Simon Hilber", "Ge Li", "Qian Wang", "\u00d6mer Erdin\u00e7 Ya\u011fmurlu", "Nils Blank", "Moritz Reuss", "Rudolf Lioutikov"], "title": "BEAST: Efficient Tokenization of B-Splines Encoded Action Sequences for Imitation Learning", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "We present the B-spline Encoded Action Sequence Tokenizer (BEAST), a novel\naction tokenizer that encodes action sequences into compact discrete or\ncontinuous tokens using B-splines. In contrast to existing action tokenizers\nbased on vector quantization or byte pair encoding, BEAST requires no separate\ntokenizer training and consistently produces tokens of uniform length, enabling\nfast action sequence generation via parallel decoding. Leveraging our B-spline\nformulation, BEAST inherently ensures generating smooth trajectories without\ndiscontinuities between adjacent segments. We extensively evaluate BEAST by\nintegrating it with three distinct model architectures: a Variational\nAutoencoder (VAE) with continuous tokens, a decoder-only Transformer with\ndiscrete tokens, and Florence-2, a pretrained Vision-Language Model with an\nencoder-decoder architecture, demonstrating BEAST's compatibility and\nscalability with large pretrained models. We evaluate BEAST across three\nestablished benchmarks consisting of 166 simulated tasks and on three distinct\nrobot settings with a total of 8 real-world tasks. Experimental results\ndemonstrate that BEAST (i) significantly reduces both training and inference\ncomputational costs, and (ii) consistently generates smooth, high-frequency\ncontrol signals suitable for continuous control tasks while (iii) reliably\nachieves competitive task success rates compared to state-of-the-art methods.", "AI": {"tldr": "BEAST\u662f\u4e00\u79cd\u57fa\u4e8eB\u6837\u6761\u7684\u52a8\u4f5c\u5e8f\u5217\u6807\u8bb0\u5668\uff0c\u65e0\u9700\u5355\u72ec\u8bad\u7ec3\uff0c\u652f\u6301\u5e76\u884c\u89e3\u7801\uff0c\u751f\u6210\u5e73\u6ed1\u8f68\u8ff9\uff0c\u5e76\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u9ad8\u6548\u548c\u7ade\u4e89\u529b\u3002", "motivation": "\u73b0\u6709\u52a8\u4f5c\u6807\u8bb0\u5668\uff08\u5982\u5411\u91cf\u91cf\u5316\u6216\u5b57\u8282\u5bf9\u7f16\u7801\uff09\u9700\u8981\u5355\u72ec\u8bad\u7ec3\u4e14\u751f\u6210\u7684\u6807\u8bb0\u957f\u5ea6\u4e0d\u4e00\u81f4\uff0cBEAST\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u5229\u7528B\u6837\u6761\u7f16\u7801\u52a8\u4f5c\u5e8f\u5217\u4e3a\u7d27\u51d1\u7684\u79bb\u6563\u6216\u8fde\u7eed\u6807\u8bb0\uff0c\u652f\u6301\u4e09\u79cd\u6a21\u578b\u67b6\u6784\uff08VAE\u3001Transformer\u3001Florence-2\uff09\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u5728166\u4e2a\u6a21\u62df\u4efb\u52a1\u548c8\u4e2a\u771f\u5b9e\u4efb\u52a1\u4e2d\uff0cBEAST\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u751f\u6210\u5e73\u6ed1\u63a7\u5236\u4fe1\u53f7\uff0c\u5e76\u4fdd\u6301\u9ad8\u4efb\u52a1\u6210\u529f\u7387\u3002", "conclusion": "BEAST\u662f\u4e00\u79cd\u9ad8\u6548\u3001\u517c\u5bb9\u6027\u5f3a\u7684\u52a8\u4f5c\u6807\u8bb0\u5668\uff0c\u9002\u7528\u4e8e\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2506.06083", "pdf": "https://arxiv.org/pdf/2506.06083", "abs": "https://arxiv.org/abs/2506.06083", "authors": ["Lama Alqazlan", "Zheng Fang", "Michael Castelle", "Rob Procter"], "title": "A Novel, Human-in-the-Loop Computational Grounded Theory Framework for Big Social Data", "categories": ["cs.HC", "cs.IR", "cs.LG", "H.4; I.7; J.4"], "comment": "24 pages, 2 figures, 15 tables", "summary": "The availability of big data has significantly influenced the possibilities\nand methodological choices for conducting large-scale behavioural and social\nscience research. In the context of qualitative data analysis, a major\nchallenge is that conventional methods require intensive manual labour and are\noften impractical to apply to large datasets. One effective way to address this\nissue is by integrating emerging computational methods to overcome scalability\nlimitations. However, a critical concern for researchers is the trustworthiness\nof results when Machine Learning (ML) and Natural Language Processing (NLP)\ntools are used to analyse such data. We argue that confidence in the\ncredibility and robustness of results depends on adopting a 'human-in-the-loop'\nmethodology that is able to provide researchers with control over the\nanalytical process, while retaining the benefits of using ML and NLP. With this\nin mind, we propose a novel methodological framework for Computational Grounded\nTheory (CGT) that supports the analysis of large qualitative datasets, while\nmaintaining the rigour of established Grounded Theory (GT) methodologies. To\nillustrate the framework's value, we present the results of testing it on a\ndataset collected from Reddit in a study aimed at understanding tutors'\nexperiences in the gig economy.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4eba\u7c7b\u53c2\u4e0e\u7684\u8ba1\u7b97\u624e\u6839\u7406\u8bba\uff08CGT\uff09\u6846\u67b6\uff0c\u7528\u4e8e\u5927\u89c4\u6a21\u5b9a\u6027\u6570\u636e\u5206\u6790\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u6269\u5c55\u7684\u95ee\u9898\uff0c\u5e76\u901a\u8fc7Reddit\u6570\u636e\u96c6\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5927\u6570\u636e\u65f6\u4ee3\u4e0b\uff0c\u4f20\u7edf\u5b9a\u6027\u5206\u6790\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u4e14\u673a\u5668\u5b66\u4e60\u5de5\u5177\u7684\u53ef\u4fe1\u5ea6\u95ee\u9898\u4e9f\u5f85\u89e3\u51b3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u2018\u4eba\u7c7b\u53c2\u4e0e\u5faa\u73af\u2019\u7684\u8ba1\u7b97\u624e\u6839\u7406\u8bba\u6846\u67b6\uff0c\u7ed3\u5408ML\u548cNLP\u5de5\u5177\uff0c\u540c\u65f6\u4fdd\u6301\u7814\u7a76\u8005\u5bf9\u5206\u6790\u8fc7\u7a0b\u7684\u63a7\u5236\u3002", "result": "\u5728Reddit\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\u4e86\u8be5\u6846\u67b6\uff0c\u6210\u529f\u5206\u6790\u4e86\u96f6\u5de5\u7ecf\u6d4e\u4e2d\u5bfc\u5e08\u7684\u7ecf\u9a8c\u3002", "conclusion": "CGT\u6846\u67b6\u65e2\u4fdd\u7559\u4e86\u624e\u6839\u7406\u8bba\u7684\u4e25\u8c28\u6027\uff0c\u53c8\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u5b9a\u6027\u6570\u636e\u5206\u6790\u7684\u6269\u5c55\u6027\u95ee\u9898\uff0c\u589e\u5f3a\u4e86\u7ed3\u679c\u7684\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2506.06087", "pdf": "https://arxiv.org/pdf/2506.06087", "abs": "https://arxiv.org/abs/2506.06087", "authors": ["Yuga Hikida", "Ayush Bharti", "Niall Jeffrey", "Fran\u00e7ois-Xavier Briol"], "title": "Multilevel neural simulation-based inference", "categories": ["stat.ML", "astro-ph.CO", "astro-ph.IM", "cs.LG", "stat.CO"], "comment": null, "summary": "Neural simulation-based inference (SBI) is a popular set of methods for\nBayesian inference when models are only available in the form of a simulator.\nThese methods are widely used in the sciences and engineering, where writing\ndown a likelihood can be significantly more challenging than constructing a\nsimulator. However, the performance of neural SBI can suffer when simulators\nare computationally expensive, thereby limiting the number of simulations that\ncan be performed. In this paper, we propose a novel approach to neural SBI\nwhich leverages multilevel Monte Carlo techniques for settings where several\nsimulators of varying cost and fidelity are available. We demonstrate through\nboth theoretical analysis and extensive experiments that our method can\nsignificantly enhance the accuracy of SBI methods given a fixed computational\nbudget.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u7ea7\u8499\u7279\u5361\u7f57\u6280\u672f\u7684\u65b0\u578b\u795e\u7ecfSBI\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u6a21\u62df\u5668\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u56fa\u5b9a\u8ba1\u7b97\u9884\u7b97\u4e0b\u7684\u63a8\u7406\u51c6\u786e\u6027\u3002", "motivation": "\u5728\u79d1\u5b66\u548c\u5de5\u7a0b\u4e2d\uff0c\u6784\u5efa\u6a21\u62df\u5668\u6bd4\u5199\u51fa\u4f3c\u7136\u51fd\u6570\u66f4\u5bb9\u6613\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u6a21\u62df\u5668\u9650\u5236\u4e86\u795e\u7ecfSBI\u7684\u6027\u80fd\u3002", "method": "\u5229\u7528\u591a\u7ea7\u8499\u7279\u5361\u7f57\u6280\u672f\uff0c\u7ed3\u5408\u591a\u4e2a\u4e0d\u540c\u6210\u672c\u548c\u4fdd\u771f\u5ea6\u7684\u6a21\u62df\u5668\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u56fa\u5b9a\u8ba1\u7b97\u9884\u7b97\u4e0b\u663e\u8457\u63d0\u9ad8\u4e86SBI\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u6a21\u62df\u5668\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u795e\u7ecfSBI\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.06092", "pdf": "https://arxiv.org/pdf/2506.06092", "abs": "https://arxiv.org/abs/2506.06092", "authors": ["Nadine Garibli", "Mayank Patwari", "Bence Csiba", "Yi Wei", "Kostas Sidiropoulos"], "title": "LinGuinE: Longitudinal Guidance Estimation for Volumetric Lung Tumour Segmentation", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": "10 pages, 3 figures", "summary": "Segmentation of lung gross tumour volumes is an important first step in\nradiotherapy and surgical intervention, and is starting to play a role in\nassessing chemotherapy response. Response to a drug is measured by tracking the\ntumour volumes over a series of CT scans over a time period i.e. a longitudinal\nstudy. However, there currently exist few solutions for automated or\nsemi-automated longitudinal tumour segmentation. This paper introduces\nLinGuinE, an automated method to segment a longitudinal series of lung tumours.\nA radiologist must provide an initial input, indicating the location of the\ntumour in a CT scan at an arbitrary time point. LinGuinE samples points inside\nthis tumour and propagates them to another time point using rigid registration.\nA click validity classifier selects points which still fall within the tumour;\nthese are used to automatically create a segmentation in the new time point. We\ntest LinGuinE on a dataset acquired from a phase 3 clinical trial for lung\ntumours and the publicly available 4-D lung CBCT dataset. We find that LinGuinE\nimproves the Dice on both test sets by over 20% (p< 0.05) across 63\nlongitudinal studies. We show that any time point can be used as a starting\npoint, conduct ablation experiments, and find that our LinGuinE setup yields\nthe best results on both test datasets.", "AI": {"tldr": "LinGuinE\u662f\u4e00\u79cd\u81ea\u52a8\u5206\u5272\u80ba\u90e8\u80bf\u7624\u7eb5\u5411CT\u626b\u63cf\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u521d\u59cb\u8f93\u5165\u548c\u70b9\u4f20\u64ad\u5b9e\u73b0\u9ad8\u6548\u5206\u5272\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5206\u5272\u51c6\u786e\u6027\u3002", "motivation": "\u76ee\u524d\u7f3a\u4e4f\u81ea\u52a8\u5316\u6216\u534a\u81ea\u52a8\u5316\u7684\u7eb5\u5411\u80bf\u7624\u5206\u5272\u65b9\u6cd5\uff0c\u800c\u8fd9\u5bf9\u653e\u7597\u3001\u624b\u672f\u548c\u5316\u7597\u8bc4\u4f30\u81f3\u5173\u91cd\u8981\u3002", "method": "LinGuinE\u901a\u8fc7\u521a\u6027\u914d\u51c6\u5c06\u521d\u59cb\u80bf\u7624\u70b9\u4f20\u64ad\u5230\u5176\u4ed6\u65f6\u95f4\u70b9\uff0c\u5e76\u4f7f\u7528\u70b9\u51fb\u6709\u6548\u6027\u5206\u7c7b\u5668\u7b5b\u9009\u6709\u6548\u70b9\u4ee5\u751f\u6210\u65b0\u5206\u5272\u3002", "result": "\u5728\u4e24\u4e2a\u6d4b\u8bd5\u6570\u636e\u96c6\u4e0a\uff0cLinGuinE\u7684Dice\u5206\u6570\u63d0\u9ad8\u4e8620%\u4ee5\u4e0a\uff08p<0.05\uff09\uff0c\u9002\u7528\u4e8e\u4efb\u610f\u8d77\u59cb\u65f6\u95f4\u70b9\u3002", "conclusion": "LinGuinE\u5728\u7eb5\u5411\u80bf\u7624\u5206\u5272\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u4e34\u5e8a\u5b9e\u8df5\u63d0\u4f9b\u4e86\u9ad8\u6548\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.06094", "pdf": "https://arxiv.org/pdf/2506.06094", "abs": "https://arxiv.org/abs/2506.06094", "authors": ["Elim Kwan", "Rehman Qureshi", "Liam Fletcher", "Colin Laganier", "Victoria Nockles", "Richard Walters"], "title": "On-board Mission Replanning for Adaptive Cooperative Multi-Robot Systems", "categories": ["cs.RO", "cs.LG"], "comment": "9 pages, 5 figures, 1 table", "summary": "Cooperative autonomous robotic systems have significant potential for\nexecuting complex multi-task missions across space, air, ground, and maritime\ndomains. But they commonly operate in remote, dynamic and hazardous\nenvironments, requiring rapid in-mission adaptation without reliance on fragile\nor slow communication links to centralised compute. Fast, on-board replanning\nalgorithms are therefore needed to enhance resilience. Reinforcement Learning\nshows strong promise for efficiently solving mission planning tasks when\nformulated as Travelling Salesperson Problems (TSPs), but existing methods: 1)\nare unsuitable for replanning, where agents do not start at a single location;\n2) do not allow cooperation between agents; 3) are unable to model tasks with\nvariable durations; or 4) lack practical considerations for on-board\ndeployment. Here we define the Cooperative Mission Replanning Problem as a\nnovel variant of multiple TSP with adaptations to overcome these issues, and\ndevelop a new encoder/decoder-based model using Graph Attention Networks and\nAttention Models to solve it effectively and efficiently. Using a simple\nexample of cooperative drones, we show our replanner consistently (90% of the\ntime) maintains performance within 10% of the state-of-the-art LKH3 heuristic\nsolver, whilst running 85-370 times faster on a Raspberry Pi. This work paves\nthe way for increased resilience in autonomous multi-agent systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u5feb\u901f\u91cd\u89c4\u5212\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u534f\u540c\u4efb\u52a1\u4e2d\u7684\u52a8\u6001\u73af\u5883\u9002\u5e94\u95ee\u9898\uff0c\u6027\u80fd\u63a5\u8fd1\u6700\u4f18\u89e3\u4e14\u8ba1\u7b97\u901f\u5ea6\u5feb\u3002", "motivation": "\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u5728\u8fdc\u7a0b\u3001\u52a8\u6001\u548c\u5371\u9669\u73af\u5883\u4e2d\u5feb\u901f\u91cd\u89c4\u5212\u7684\u9700\u6c42\uff0c\u514b\u670d\u73b0\u6709\u65b9\u6cd5\u5728\u91cd\u89c4\u5212\u3001\u534f\u4f5c\u3001\u4efb\u52a1\u65f6\u957f\u5efa\u6a21\u548c\u5b9e\u9645\u90e8\u7f72\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u65c5\u884c\u5546\u95ee\u9898\u53d8\u4f53\uff0c\u5e76\u5f00\u53d1\u4e86\u57fa\u4e8e\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\u548c\u6ce8\u610f\u529b\u6a21\u578b\u7684\u7f16\u7801\u5668/\u89e3\u7801\u5668\u6a21\u578b\u3002", "result": "\u5728\u6811\u8393\u6d3e\u4e0a\u8fd0\u884c\u65f6\uff0c\u6027\u80fd\u63a5\u8fd1\u6700\u4f18\u89e3\uff0890%\u60c5\u51b5\u4e0b\u8bef\u5dee\u572810%\u4ee5\u5185\uff09\uff0c\u4e14\u901f\u5ea6\u5feb85-370\u500d\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u81ea\u4e3b\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.06096", "pdf": "https://arxiv.org/pdf/2506.06096", "abs": "https://arxiv.org/abs/2506.06096", "authors": ["Zijian Yang", "Minh-Nghia Phan", "Ralf Schl\u00fcter", "Hermann Ney"], "title": "Label-Context-Dependent Internal Language Model Estimation for CTC", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "comment": "accepted to Interspeech 2025", "summary": "Although connectionist temporal classification (CTC) has the label context\nindependence assumption, it can still implicitly learn a context-dependent\ninternal language model (ILM) due to modern powerful encoders. In this work, we\ninvestigate the implicit context dependency modeled in the ILM of CTC. To this\nend, we propose novel context-dependent ILM estimation methods for CTC based on\nknowledge distillation (KD) with theoretical justifications. Furthermore, we\nintroduce two regularization methods for KD. We conduct experiments on\nLibrispeech and TED-LIUM Release 2 datasets for in-domain and cross-domain\nevaluation, respectively. Experimental results show that context-dependent ILMs\noutperform the context-independent priors in cross-domain evaluation,\nindicating that CTC learns a context-dependent ILM. The proposed label-level KD\nwith smoothing method surpasses other ILM estimation approaches, with more than\n13% relative improvement in word error rate compared to shallow fusion.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86CTC\u6a21\u578b\u4e2d\u9690\u542b\u7684\u4e0a\u4e0b\u6587\u4f9d\u8d56\u6027\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u77e5\u8bc6\u84b8\u998f\u7684\u4e0a\u4e0b\u6587\u4f9d\u8d56ILM\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u5c3d\u7ba1CTC\u6a21\u578b\u5047\u8bbe\u6807\u7b7e\u4e0a\u4e0b\u6587\u72ec\u7acb\uff0c\u4f46\u7531\u4e8e\u73b0\u4ee3\u5f3a\u5927\u7f16\u7801\u5668\uff0c\u5b83\u4ecd\u80fd\u9690\u5f0f\u5b66\u4e60\u4e0a\u4e0b\u6587\u4f9d\u8d56\u7684\u5185\u90e8\u8bed\u8a00\u6a21\u578b\uff08ILM\uff09\u3002\u672c\u6587\u65e8\u5728\u63a2\u7a76CTC\u4e2dILM\u7684\u9690\u542b\u4e0a\u4e0b\u6587\u4f9d\u8d56\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u77e5\u8bc6\u84b8\u998f\uff08KD\uff09\u7684\u4e0a\u4e0b\u6587\u4f9d\u8d56ILM\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5e76\u5f15\u5165\u4e24\u79cd\u6b63\u5219\u5316\u65b9\u6cd5\u3002\u5b9e\u9a8c\u5728Librispeech\u548cTED-LIUM Release 2\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0a\u4e0b\u6587\u4f9d\u8d56\u7684ILM\u5728\u8de8\u57df\u8bc4\u4f30\u4e2d\u4f18\u4e8e\u4e0a\u4e0b\u6587\u72ec\u7acb\u7684\u5148\u9a8c\u6a21\u578b\uff0c\u4e14\u63d0\u51fa\u7684\u6807\u7b7e\u7ea7KD\u5e73\u6ed1\u65b9\u6cd5\u8868\u73b0\u6700\u4f73\uff0c\u8bcd\u9519\u8bef\u7387\u76f8\u5bf9\u964d\u4f4e\u4e8613%\u4ee5\u4e0a\u3002", "conclusion": "CTC\u786e\u5b9e\u5b66\u4e60\u5230\u4e86\u4e0a\u4e0b\u6587\u4f9d\u8d56\u7684ILM\uff0c\u4e14\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u6027\u80fd\u4e0a\u663e\u8457\u4f18\u4e8e\u5176\u4ed6ILM\u4f30\u8ba1\u65b9\u6cd5\u3002"}}
{"id": "2506.06125", "pdf": "https://arxiv.org/pdf/2506.06125", "abs": "https://arxiv.org/abs/2506.06125", "authors": ["Hamza Fawzi", "Omar Fawzi"], "title": "Convergence of linear programming hierarchies for Gibbs states of spin systems", "categories": ["math.OC", "cs.IT", "cs.LG", "math.IT", "math.PR"], "comment": "11 pages", "summary": "We consider the problem of computing expectation values of local functions\nunder the Gibbs distribution of a spin system. In particular, we study two\nfamilies of linear programming hierarchies for this problem. The first\nhierarchy imposes local spin flip equalities and has been considered in the\nbootstrap literature in high energy physics. For this hierarchy, we prove fast\nconvergence under a spatial mixing (decay of correlations) condition. This\ncondition is satisfied for example above the critical temperature for Ising\nmodels on a $d$-dimensional grid. The second hierarchy is based on a Markov\nchain having the Gibbs state as a fixed point and has been studied in the\noptimization literature and more recently in the bootstrap literature. For this\nhierarchy, we prove fast convergence provided the Markov chain mixes rapidly.\nBoth hierarchies lead to an $\\varepsilon$-approximation for local expectation\nvalues using a linear program of size quasi-polynomial in $n/\\varepsilon$,\nwhere $n$ is the total number of sites, provided the interactions can be\nembedded in a $d$-dimensional grid with constant $d$. Compared to standard\nMonte Carlo methods, an advantage of this approach is that it always (i.e., for\nany system) outputs rigorous upper and lower bounds on the expectation value of\ninterest, without needing an a priori analysis of the convergence speed.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5728\u81ea\u65cb\u7cfb\u7edf\u7684Gibbs\u5206\u5e03\u4e0b\u8ba1\u7b97\u5c40\u90e8\u51fd\u6570\u671f\u671b\u503c\u7684\u4e24\u79cd\u7ebf\u6027\u89c4\u5212\u5c42\u6b21\u65b9\u6cd5\uff0c\u5206\u522b\u57fa\u4e8e\u5c40\u90e8\u81ea\u65cb\u7ffb\u8f6c\u7b49\u5f0f\u548c\u9a6c\u5c14\u53ef\u592b\u94fe\uff0c\u8bc1\u660e\u4e86\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u7684\u5feb\u901f\u6536\u655b\u6027\u3002", "motivation": "\u89e3\u51b3\u5728\u81ea\u65cb\u7cfb\u7edf\u4e2d\u8ba1\u7b97\u5c40\u90e8\u51fd\u6570\u671f\u671b\u503c\u7684\u95ee\u9898\uff0c\u63d0\u4f9b\u4e00\u79cd\u65e0\u9700\u5148\u9a8c\u6536\u655b\u5206\u6790\u7684\u4e25\u683c\u4e0a\u4e0b\u754c\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u7ebf\u6027\u89c4\u5212\u5c42\u6b21\u65b9\u6cd5\uff1a\u4e00\u662f\u57fa\u4e8e\u5c40\u90e8\u81ea\u65cb\u7ffb\u8f6c\u7b49\u5f0f\uff0c\u4e8c\u662f\u57fa\u4e8e\u9a6c\u5c14\u53ef\u592b\u94fe\u3002\u8bc1\u660e\u4e86\u5728\u7a7a\u95f4\u6df7\u5408\u6216\u9a6c\u5c14\u53ef\u592b\u94fe\u5feb\u901f\u6df7\u5408\u6761\u4ef6\u4e0b\u7684\u6536\u655b\u6027\u3002", "result": "\u4e24\u79cd\u65b9\u6cd5\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u80fd\u5feb\u901f\u6536\u655b\uff0c\u4e14\u80fd\u63d0\u4f9b\u4e25\u683c\u7684\u4e0a\u4e0b\u754c\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u4e3a\u62df\u591a\u9879\u5f0f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u76f8\u6bd4\u8499\u7279\u5361\u6d1b\u65b9\u6cd5\u5177\u6709\u4f18\u52bf\uff0c\u9002\u7528\u4e8e\u4efb\u4f55\u7cfb\u7edf\u4e14\u65e0\u9700\u5148\u9a8c\u6536\u655b\u5206\u6790\u3002"}}
{"id": "2506.06134", "pdf": "https://arxiv.org/pdf/2506.06134", "abs": "https://arxiv.org/abs/2506.06134", "authors": ["Veronica Centorrino", "Francesco Bullo", "Giovanni Russo"], "title": "Similarity Matching Networks: Hebbian Learning and Convergence Over Multiple Time Scales", "categories": ["q-bio.NC", "cs.LG", "math.OC"], "comment": "28 pages, 9 figures", "summary": "A recent breakthrough in biologically-plausible normative frameworks for\ndimensionality reduction is based upon the similarity matching cost function\nand the low-rank matrix approximation problem. Despite clear biological\ninterpretation, successful application in several domains, and experimental\nvalidation, a formal complete convergence analysis remains elusive. Building on\nthis framework, we consider and analyze a continuous-time neural network, the\n\\emph{similarity matching network}, for principal subspace projection. Derived\nfrom a min-max-min objective, this biologically-plausible network consists of\nthree coupled dynamics evolving at different time scales: neural dynamics,\nlateral synaptic dynamics, and feedforward synaptic dynamics at the fast,\nintermediate, and slow time scales, respectively. The feedforward and lateral\nsynaptic dynamics consist of Hebbian and anti-Hebbian learning rules,\nrespectively. By leveraging a multilevel optimization framework, we prove\nconvergence of the dynamics in the offline setting. Specifically, at the first\nlevel (fast time scale), we show strong convexity of the cost function and\nglobal exponential convergence of the corresponding gradient-flow dynamics. At\nthe second level (intermediate time scale), we prove strong concavity of the\ncost function and exponential convergence of the corresponding gradient-flow\ndynamics within the space of positive definite matrices. At the third and final\nlevel (slow time scale), we study a non-convex and non-smooth cost function,\nprovide explicit expressions for its global minima, and prove almost sure\nconvergence of the corresponding gradient-flow dynamics to the global minima.\nThese results rely on two empirically motivated conjectures that are supported\nby thorough numerical experiments. Finally, we validate the effectiveness of\nour approach via a numerical example.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u76f8\u4f3c\u6027\u5339\u914d\u7684\u8fde\u7eed\u65f6\u95f4\u795e\u7ecf\u7f51\u7edc\uff0c\u7528\u4e8e\u4e3b\u6210\u5206\u5b50\u7a7a\u95f4\u6295\u5f71\uff0c\u901a\u8fc7\u591a\u7ea7\u4f18\u5316\u6846\u67b6\u8bc1\u660e\u4e86\u5176\u6536\u655b\u6027\u3002", "motivation": "\u5c3d\u7ba1\u76f8\u4f3c\u6027\u5339\u914d\u6210\u672c\u51fd\u6570\u5728\u751f\u7269\u5b66\u4e0a\u6709\u660e\u786e\u89e3\u91ca\u4e14\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u5176\u6536\u655b\u6027\u5206\u6790\u5c1a\u672a\u5b8c\u5168\u89e3\u51b3\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u4e09\u9636\u6bb5\u52a8\u6001\u7f51\u7edc\uff08\u795e\u7ecf\u3001\u4fa7\u5411\u7a81\u89e6\u3001\u524d\u9988\u7a81\u89e6\uff09\uff0c\u5206\u522b\u5bf9\u5e94\u5feb\u3001\u4e2d\u3001\u6162\u65f6\u95f4\u5c3a\u5ea6\uff0c\u5e76\u91c7\u7528Hebbian\u548c\u53cdHebbian\u5b66\u4e60\u89c4\u5219\u3002", "result": "\u901a\u8fc7\u591a\u7ea7\u4f18\u5316\u6846\u67b6\uff0c\u8bc1\u660e\u4e86\u5feb\u65f6\u95f4\u5c3a\u5ea6\u7684\u5168\u5c40\u6307\u6570\u6536\u655b\u3001\u4e2d\u65f6\u95f4\u5c3a\u5ea6\u7684\u6b63\u5b9a\u77e9\u9635\u7a7a\u95f4\u5185\u6536\u655b\uff0c\u4ee5\u53ca\u6162\u65f6\u95f4\u5c3a\u5ea6\u7684\u5168\u5c40\u6700\u5c0f\u503c\u6536\u655b\u3002", "conclusion": "\u6570\u503c\u5b9e\u9a8c\u652f\u6301\u4e86\u7406\u8bba\u5206\u6790\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2506.06155", "pdf": "https://arxiv.org/pdf/2506.06155", "abs": "https://arxiv.org/abs/2506.06155", "authors": ["Wenyuan Li", "Shunlin Liang", "Yuxiang Zhang", "Liqin Liu", "Keyan Chen", "Yongzhe Chen", "Han Ma", "Jianglei Xu", "Yichuan Ma", "Shikang Guan", "Zhenwei Shi"], "title": "Fine-grained Hierarchical Crop Type Classification from Integrated Hyperspectral EnMAP Data and Multispectral Sentinel-2 Time Series: A Large-scale Dataset and Dual-stream Transformer Method", "categories": ["cs.CV", "cs.LG"], "comment": "27 pages, 12 figures", "summary": "Fine-grained crop type classification serves as the fundamental basis for\nlarge-scale crop mapping and plays a vital role in ensuring food security. It\nrequires simultaneous capture of both phenological dynamics (obtained from\nmulti-temporal satellite data like Sentinel-2) and subtle spectral variations\n(demanding nanometer-scale spectral resolution from hyperspectral imagery).\nResearch combining these two modalities remains scarce currently due to\nchallenges in hyperspectral data acquisition and crop types annotation costs.\nTo address these issues, we construct a hierarchical hyperspectral crop dataset\n(H2Crop) by integrating 30m-resolution EnMAP hyperspectral data with Sentinel-2\ntime series. With over one million annotated field parcels organized in a\nfour-tier crop taxonomy, H2Crop establishes a vital benchmark for fine-grained\nagricultural crop classification and hyperspectral image processing. We propose\na dual-stream Transformer architecture that synergistically processes these\nmodalities. It coordinates two specialized pathways: a spectral-spatial\nTransformer extracts fine-grained signatures from hyperspectral EnMAP data,\nwhile a temporal Swin Transformer extracts crop growth patterns from Sentinel-2\ntime series. The designed hierarchical classification head with hierarchical\nfusion then simultaneously delivers multi-level crop type classification across\nall taxonomic tiers. Experiments demonstrate that adding hyperspectral EnMAP\ndata to Sentinel-2 time series yields a 4.2% average F1-scores improvement\n(peaking at 6.3%). Extensive comparisons also confirm our method's higher\naccuracy over existing deep learning approaches for crop type classification\nand the consistent benefits of hyperspectral data across varying temporal\nwindows and crop change scenarios. Codes and dataset are available at\nhttps://github.com/flyakon/H2Crop.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u6d41Transformer\u67b6\u6784\uff0c\u7ed3\u5408\u9ad8\u5149\u8c31EnMAP\u6570\u636e\u4e0eSentinel-2\u65f6\u95f4\u5e8f\u5217\uff0c\u7528\u4e8e\u7ec6\u7c92\u5ea6\u4f5c\u7269\u5206\u7c7b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5206\u7c7b\u6027\u80fd\u3002", "motivation": "\u7ec6\u7c92\u5ea6\u4f5c\u7269\u5206\u7c7b\u5bf9\u5927\u89c4\u6a21\u4f5c\u7269\u5236\u56fe\u548c\u7cae\u98df\u5b89\u5168\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u56e0\u9ad8\u5149\u8c31\u6570\u636e\u83b7\u53d6\u548c\u6807\u6ce8\u6210\u672c\u9ad8\u800c\u7a00\u7f3a\u3002", "method": "\u6784\u5efa\u4e86H2Crop\u6570\u636e\u96c6\uff0c\u5e76\u63d0\u51fa\u53cc\u6d41Transformer\u67b6\u6784\uff0c\u5206\u522b\u5904\u7406\u9ad8\u5149\u8c31\u6570\u636e\u7684\u7cbe\u7ec6\u5149\u8c31\u7279\u5f81\u548cSentinel-2\u65f6\u95f4\u5e8f\u5217\u7684\u7269\u5019\u52a8\u6001\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u52a0\u5165\u9ad8\u5149\u8c31\u6570\u636e\u540e\uff0cF1\u5206\u6570\u5e73\u5747\u63d0\u53474.2%\uff0c\u6700\u9ad8\u8fbe6.3%\uff0c\u4e14\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u3002", "conclusion": "\u9ad8\u5149\u8c31\u6570\u636e\u5728\u4e0d\u540c\u65f6\u95f4\u7a97\u53e3\u548c\u4f5c\u7269\u53d8\u5316\u573a\u666f\u4e2d\u5747\u5177\u4f18\u52bf\uff0cH2Crop\u6570\u636e\u96c6\u548c\u65b9\u6cd5\u4e3a\u519c\u4e1a\u5206\u7c7b\u548c\u9ad8\u5149\u8c31\u5904\u7406\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u51c6\u3002"}}
{"id": "2506.06202", "pdf": "https://arxiv.org/pdf/2506.06202", "abs": "https://arxiv.org/abs/2506.06202", "authors": ["Renato Cordeiro Ferreira", "Rowanne Trapmann", "Willem-Jan van den Heuvel"], "title": "MLOps with Microservices: A Case Study on the Maritime Domain", "categories": ["cs.SE", "cs.AI", "cs.LG", "D.2.11; D.2.9; I.2.m; I.5.0"], "comment": "13 pages, 3 figures, to be published in SummerSOC 2025", "summary": "This case study describes challenges and lessons learned on building Ocean\nGuard: a Machine Learning-Enabled System (MLES) for anomaly detection in the\nmaritime domain. First, the paper presents the system's specification, and\narchitecture. Ocean Guard was designed with a microservices' architecture to\nenable multiple teams to work on the project in parallel. Then, the paper\ndiscusses how the developers adapted contract-based design to MLOps for\nachieving that goal. As a MLES, Ocean Guard employs code, model, and data\ncontracts to establish guidelines between its services. This case study hopes\nto inspire software engineers, machine learning engineers, and data scientists\nto leverage similar approaches for their systems.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u6784\u5efa\u6d77\u6d0b\u76d1\u6d4b\u7cfb\u7edfOcean Guard\u7684\u6311\u6218\u4e0e\u7ecf\u9a8c\uff0c\u91cd\u70b9\u662f\u5176\u5fae\u670d\u52a1\u67b6\u6784\u548c\u57fa\u4e8e\u5408\u540c\u7684\u8bbe\u8ba1\u65b9\u6cd5\u5728MLOps\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u4e3a\u6d77\u4e8b\u9886\u57df\u7684\u5f02\u5e38\u68c0\u6d4b\u5f00\u53d1\u4e00\u4e2a\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\uff08MLES\uff09\uff0c\u5e76\u901a\u8fc7\u5fae\u670d\u52a1\u67b6\u6784\u548c\u5408\u540c\u8bbe\u8ba1\u5b9e\u73b0\u56e2\u961f\u534f\u4f5c\u3002", "method": "\u91c7\u7528\u5fae\u670d\u52a1\u67b6\u6784\u548c\u57fa\u4e8e\u5408\u540c\u7684\u8bbe\u8ba1\uff08\u4ee3\u7801\u3001\u6a21\u578b\u548c\u6570\u636e\u5408\u540c\uff09\u6765\u534f\u8c03\u591a\u56e2\u961f\u5e76\u884c\u5f00\u53d1\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86Ocean Guard\u7cfb\u7edf\uff0c\u5c55\u793a\u4e86\u5408\u540c\u8bbe\u8ba1\u5728MLOps\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u6848\u4f8b\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u3001\u673a\u5668\u5b66\u4e60\u5de5\u7a0b\u5e08\u548c\u6570\u636e\u79d1\u5b66\u5bb6\u63d0\u4f9b\u4e86\u53ef\u501f\u9274\u7684\u7cfb\u7edf\u8bbe\u8ba1\u65b9\u6cd5\u3002"}}
{"id": "2506.06221", "pdf": "https://arxiv.org/pdf/2506.06221", "abs": "https://arxiv.org/abs/2506.06221", "authors": ["Yan Shen", "Ruihai Wu", "Yubin Ke", "Xinyuan Song", "Zeyi Li", "Xiaoqi Li", "Hongwei Fan", "Haoran Lu", "Hao dong"], "title": "BiAssemble: Learning Collaborative Affordance for Bimanual Geometric Assembly", "categories": ["cs.RO", "cs.LG"], "comment": "ICML 2025", "summary": "Shape assembly, the process of combining parts into a complete whole, is a\ncrucial robotic skill with broad real-world applications. Among various\nassembly tasks, geometric assembly--where broken parts are reassembled into\ntheir original form (e.g., reconstructing a shattered bowl)--is particularly\nchallenging. This requires the robot to recognize geometric cues for grasping,\nassembly, and subsequent bimanual collaborative manipulation on varied\nfragments. In this paper, we exploit the geometric generalization of\npoint-level affordance, learning affordance aware of bimanual collaboration in\ngeometric assembly with long-horizon action sequences. To address the\nevaluation ambiguity caused by geometry diversity of broken parts, we introduce\na real-world benchmark featuring geometric variety and global reproducibility.\nExtensive experiments demonstrate the superiority of our approach over both\nprevious affordance-based and imitation-based methods. Project page:\nhttps://sites.google.com/view/biassembly/.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u70b9\u7ea7\u529f\u80fd\u611f\u77e5\u7684\u53cc\u81c2\u534f\u4f5c\u51e0\u4f55\u88c5\u914d\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u788e\u7247\u51e0\u4f55\u591a\u6837\u6027\u5e26\u6765\u7684\u8bc4\u4f30\u6a21\u7cca\u6027\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u51e0\u4f55\u88c5\u914d\uff08\u5982\u4fee\u590d\u7834\u788e\u7684\u7897\uff09\u662f\u673a\u5668\u4eba\u6280\u672f\u4e2d\u7684\u91cd\u8981\u6311\u6218\uff0c\u9700\u8981\u8bc6\u522b\u51e0\u4f55\u7ebf\u7d22\u4ee5\u5b9e\u73b0\u6293\u53d6\u3001\u88c5\u914d\u548c\u53cc\u81c2\u534f\u4f5c\u64cd\u4f5c\u3002", "method": "\u5229\u7528\u70b9\u7ea7\u529f\u80fd\u611f\u77e5\u7684\u51e0\u4f55\u6cdb\u5316\u80fd\u529b\uff0c\u5b66\u4e60\u652f\u6301\u53cc\u81c2\u534f\u4f5c\u7684\u957f\u65f6\u7a0b\u52a8\u4f5c\u5e8f\u5217\uff0c\u5e76\u5f15\u5165\u5177\u6709\u51e0\u4f55\u591a\u6837\u6027\u548c\u5168\u5c40\u53ef\u91cd\u590d\u6027\u7684\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u529f\u80fd\u611f\u77e5\u548c\u6a21\u4eff\u5b66\u4e60\u65b9\u6cd5\u4e2d\u5747\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u51e0\u4f55\u88c5\u914d\u4efb\u52a1\u4e2d\u6709\u6548\u89e3\u51b3\u4e86\u8bc4\u4f30\u6a21\u7cca\u6027\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u53cc\u81c2\u534f\u4f5c\u7684\u88c5\u914d\u80fd\u529b\u3002"}}
{"id": "2506.06243", "pdf": "https://arxiv.org/pdf/2506.06243", "abs": "https://arxiv.org/abs/2506.06243", "authors": ["Benjamin Smith", "Jianhui Gao", "Jessica Gronsbell"], "title": "fairmetrics: An R package for group fairness evaluation", "categories": ["stat.CO", "cs.LG", "stat.ML", "G.3; G.4"], "comment": "6 pages, 1 figure, 1 table", "summary": "Fairness is a growing area of machine learning (ML) that focuses on ensuring\nmodels do not produce systematically biased outcomes for specific groups,\nparticularly those defined by protected attributes such as race, gender, or\nage. Evaluating fairness is a critical aspect of ML model development, as\nbiased models can perpetuate structural inequalities. The {fairmetrics} R\npackage offers a user-friendly framework for rigorously evaluating numerous\ngroup-based fairness criteria, including metrics based on independence (e.g.,\nstatistical parity), separation (e.g., equalized odds), and sufficiency (e.g.,\npredictive parity). Group-based fairness criteria assess whether a model is\nequally accurate or well-calibrated across a set of predefined groups so that\nappropriate bias mitigation strategies can be implemented. {fairmetrics}\nprovides both point and interval estimates for multiple metrics through a\nconvenient wrapper function and includes an example dataset derived from the\nMedical Information Mart for Intensive Care, version II (MIMIC-II) database\n(Goldberger et al., 2000; Raffa, 2016).", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86{fairmetrics} R\u5305\uff0c\u7528\u4e8e\u8bc4\u4f30\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u516c\u5e73\u6027\uff0c\u786e\u4fdd\u6a21\u578b\u4e0d\u4f1a\u5bf9\u7279\u5b9a\u7fa4\u4f53\u4ea7\u751f\u7cfb\u7edf\u6027\u504f\u89c1\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u6a21\u578b\u53ef\u80fd\u5bf9\u7279\u5b9a\u7fa4\u4f53\u4ea7\u751f\u504f\u89c1\uff0c\u5bfc\u81f4\u7ed3\u6784\u6027\u4e0d\u5e73\u7b49\uff0c\u56e0\u6b64\u9700\u8981\u5de5\u5177\u6765\u8bc4\u4f30\u548c\u786e\u4fdd\u516c\u5e73\u6027\u3002", "method": "{fairmetrics} R\u5305\u63d0\u4f9b\u4e86\u4e00\u5957\u7528\u6237\u53cb\u597d\u7684\u6846\u67b6\uff0c\u652f\u6301\u591a\u79cd\u57fa\u4e8e\u7fa4\u4f53\u7684\u516c\u5e73\u6027\u6807\u51c6\u8bc4\u4f30\uff0c\u5305\u62ec\u72ec\u7acb\u6027\u3001\u5206\u79bb\u6027\u548c\u5145\u5206\u6027\u7b49\u6307\u6807\u3002", "result": "\u8be5\u5de5\u5177\u63d0\u4f9b\u4e86\u70b9\u4f30\u8ba1\u548c\u533a\u95f4\u4f30\u8ba1\uff0c\u5e76\u5305\u542b\u4e86\u4e00\u4e2a\u6765\u81eaMIMIC-II\u6570\u636e\u5e93\u7684\u793a\u4f8b\u6570\u636e\u96c6\u3002", "conclusion": "{fairmetrics} R\u5305\u4e3a\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u516c\u5e73\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u52a9\u4e8e\u5b9e\u65bd\u9002\u5f53\u7684\u504f\u89c1\u7f13\u89e3\u7b56\u7565\u3002"}}
{"id": "2506.06254", "pdf": "https://arxiv.org/pdf/2506.06254", "abs": "https://arxiv.org/abs/2506.06254", "authors": ["Weizhi Zhang", "Xinyang Zhang", "Chenwei Zhang", "Liangwei Yang", "Jingbo Shang", "Zhepei Wei", "Henry Peng Zou", "Zijie Huang", "Zhengyang Wang", "Yifan Gao", "Xiaoman Pan", "Lian Xiong", "Jingguo Liu", "Philip S. Yu", "Xian Li"], "title": "PersonaAgent: When Large Language Model Agents Meet Personalization at Test Time", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Large Language Model (LLM) empowered agents have recently emerged as advanced\nparadigms that exhibit impressive capabilities in a wide range of domains and\ntasks. Despite their potential, current LLM agents often adopt a\none-size-fits-all approach, lacking the flexibility to respond to users'\nvarying needs and preferences. This limitation motivates us to develop\nPersonaAgent, the first personalized LLM agent framework designed to address\nversatile personalization tasks. Specifically, PersonaAgent integrates two\ncomplementary components - a personalized memory module that includes episodic\nand semantic memory mechanisms; a personalized action module that enables the\nagent to perform tool actions tailored to the user. At the core, the persona\n(defined as unique system prompt for each user) functions as an intermediary:\nit leverages insights from personalized memory to control agent actions, while\nthe outcomes of these actions in turn refine the memory. Based on the\nframework, we propose a test-time user-preference alignment strategy that\nsimulate the latest n interactions to optimize the persona prompt, ensuring\nreal-time user preference alignment through textual loss feedback between\nsimulated and ground-truth responses. Experimental evaluations demonstrate that\nPersonaAgent significantly outperforms other baseline methods by not only\npersonalizing the action space effectively but also scaling during test-time\nreal-world applications. These results underscore the feasibility and potential\nof our approach in delivering tailored, dynamic user experiences.", "AI": {"tldr": "PersonaAgent\u662f\u4e00\u4e2a\u4e2a\u6027\u5316\u7684LLM\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u4e2a\u6027\u5316\u8bb0\u5fc6\u548c\u52a8\u4f5c\u6a21\u5757\uff0c\u7ed3\u5408\u7528\u6237\u504f\u597d\u4f18\u5316\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524dLLM\u4ee3\u7406\u7f3a\u4e4f\u7075\u6d3b\u6027\uff0c\u65e0\u6cd5\u6ee1\u8db3\u7528\u6237\u591a\u6837\u5316\u7684\u9700\u6c42\u548c\u504f\u597d\uff0c\u56e0\u6b64\u5f00\u53d1\u4e86PersonaAgent\u3002", "method": "PersonaAgent\u5305\u542b\u4e2a\u6027\u5316\u8bb0\u5fc6\u6a21\u5757\uff08\u60c5\u666f\u548c\u8bed\u4e49\u8bb0\u5fc6\uff09\u548c\u52a8\u4f5c\u6a21\u5757\uff0c\u901a\u8fc7\u7528\u6237\u504f\u597d\u5bf9\u9f50\u7b56\u7565\u4f18\u5316\u7cfb\u7edf\u63d0\u793a\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cPersonaAgent\u5728\u4e2a\u6027\u5316\u52a8\u4f5c\u7a7a\u95f4\u548c\u5b9e\u65f6\u5e94\u7528\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "PersonaAgent\u5c55\u793a\u4e86\u63d0\u4f9b\u52a8\u6001\u4e2a\u6027\u5316\u7528\u6237\u4f53\u9a8c\u7684\u53ef\u884c\u6027\u548c\u6f5c\u529b\u3002"}}
{"id": "2506.06261", "pdf": "https://arxiv.org/pdf/2506.06261", "abs": "https://arxiv.org/abs/2506.06261", "authors": ["Jihwan Jeong", "Xiaoyu Wang", "Jingmin Wang", "Scott Sanner", "Pascal Poupart"], "title": "Reflect-then-Plan: Offline Model-Based Planning through a Doubly Bayesian Lens", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Offline reinforcement learning (RL) is crucial when online exploration is\ncostly or unsafe but often struggles with high epistemic uncertainty due to\nlimited data. Existing methods rely on fixed conservative policies, restricting\nadaptivity and generalization. To address this, we propose Reflect-then-Plan\n(RefPlan), a novel doubly Bayesian offline model-based (MB) planning approach.\nRefPlan unifies uncertainty modeling and MB planning by recasting planning as\nBayesian posterior estimation. At deployment, it updates a belief over\nenvironment dynamics using real-time observations, incorporating uncertainty\ninto MB planning via marginalization. Empirical results on standard benchmarks\nshow that RefPlan significantly improves the performance of conservative\noffline RL policies. In particular, RefPlan maintains robust performance under\nhigh epistemic uncertainty and limited data, while demonstrating resilience to\nchanging environment dynamics, improving the flexibility, generalizability, and\nrobustness of offline-learned policies.", "AI": {"tldr": "RefPlan\u662f\u4e00\u79cd\u57fa\u4e8e\u53cc\u91cd\u8d1d\u53f6\u65af\u7684\u79bb\u7ebf\u6a21\u578b\u89c4\u5212\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u89c4\u5212\u91cd\u65b0\u5b9a\u4e49\u4e3a\u8d1d\u53f6\u65af\u540e\u9a8c\u4f30\u8ba1\uff0c\u7edf\u4e00\u4e86\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u548c\u6a21\u578b\u89c4\u5212\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4fdd\u5b88\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u7684\u6027\u80fd\u3002", "motivation": "\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u5728\u5728\u7ebf\u63a2\u7d22\u6210\u672c\u9ad8\u6216\u4e0d\u5b89\u5168\u65f6\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5e38\u56e0\u6570\u636e\u6709\u9650\u5bfc\u81f4\u9ad8\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff0c\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u56fa\u5b9a\u4fdd\u5b88\u7b56\u7565\uff0c\u9650\u5236\u4e86\u9002\u5e94\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51faReflect-then-Plan (RefPlan)\uff0c\u901a\u8fc7\u5b9e\u65f6\u89c2\u6d4b\u66f4\u65b0\u73af\u5883\u52a8\u6001\u7684\u4fe1\u5ff5\uff0c\u5e76\u5c06\u4e0d\u786e\u5b9a\u6027\u901a\u8fc7\u8fb9\u7f18\u5316\u7eb3\u5165\u6a21\u578b\u89c4\u5212\u3002", "result": "\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRefPlan\u663e\u8457\u63d0\u5347\u4e86\u4fdd\u5b88\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u7684\u6027\u80fd\uff0c\u5c24\u5176\u5728\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u9ad8\u548c\u6570\u636e\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u7a33\u5065\u3002", "conclusion": "RefPlan\u63d0\u9ad8\u4e86\u79bb\u7ebf\u5b66\u4e60\u7b56\u7565\u7684\u7075\u6d3b\u6027\u3001\u6cdb\u5316\u80fd\u529b\u548c\u9c81\u68d2\u6027\uff0c\u9002\u5e94\u52a8\u6001\u53d8\u5316\u7684\u73af\u5883\u3002"}}
{"id": "2506.06266", "pdf": "https://arxiv.org/pdf/2506.06266", "abs": "https://arxiv.org/abs/2506.06266", "authors": ["Sabri Eyuboglu", "Ryan Ehrlich", "Simran Arora", "Neel Guha", "Dylan Zinsley", "Emily Liu", "Will Tennien", "Atri Rudra", "James Zou", "Azalia Mirhoseini", "Christopher Re"], "title": "Cartridges: Lightweight and general-purpose long context representations via self-study", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large language models are often used to answer queries grounded in large text\ncorpora (e.g. codebases, legal documents, or chat histories) by placing the\nentire corpus in the context window and leveraging in-context learning (ICL).\nAlthough current models support contexts of 100K-1M tokens, this setup is\ncostly to serve because the memory consumption of the KV cache scales with\ninput length. We explore an alternative: training a smaller KV cache offline on\neach corpus. At inference time, we load this trained KV cache, which we call a\nCartridge, and decode a response. Critically, the cost of training a Cartridge\ncan be amortized across all the queries referencing the same corpus. However,\nwe find that the naive approach of training the Cartridge with next-token\nprediction on the corpus is not competitive with ICL. Instead, we propose\nself-study, a training recipe in which we generate synthetic conversations\nabout the corpus and train the Cartridge with a context-distillation objective.\nWe find that Cartridges trained with self-study replicate the functionality of\nICL, while being significantly cheaper to serve. On challenging long-context\nbenchmarks, Cartridges trained with self-study match ICL performance while\nusing 38.6x less memory and enabling 26.4x higher throughput. Self-study also\nextends the model's effective context length (e.g. from 128k to 484k tokens on\nMTOB) and surprisingly, leads to Cartridges that can be composed at inference\ntime without retraining.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCartridge\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u79bb\u7ebf\u8bad\u7ec3\u5c0f\u578bKV\u7f13\u5b58\u6765\u66ff\u4ee3\u4f20\u7edf\u7684\u5927\u89c4\u6a21\u4e0a\u4e0b\u6587\u7a97\u53e3\u65b9\u6cd5\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5185\u5b58\u6d88\u8017\u548c\u63a8\u7406\u6210\u672c\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u5927\u89c4\u6a21\u6587\u672c\u8bed\u6599\u65f6\uff0c\u5185\u5b58\u6d88\u8017\u9ad8\u4e14\u6210\u672c\u6602\u8d35\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faCartridge\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u5b66\u4e60\u8bad\u7ec3\u5c0f\u578bKV\u7f13\u5b58\uff0c\u751f\u6210\u5408\u6210\u5bf9\u8bdd\u5e76\u4f7f\u7528\u4e0a\u4e0b\u6587\u84b8\u998f\u76ee\u6807\u4f18\u5316\u3002", "result": "Cartridge\u5728\u6027\u80fd\u4e0a\u4e0eICL\u76f8\u5f53\uff0c\u4f46\u5185\u5b58\u6d88\u8017\u964d\u4f4e38.6\u500d\uff0c\u541e\u5410\u91cf\u63d0\u9ad826.4\u500d\uff0c\u5e76\u6269\u5c55\u4e86\u6709\u6548\u4e0a\u4e0b\u6587\u957f\u5ea6\u3002", "conclusion": "Cartridge\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u7ecf\u6d4e\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u4e0d\u91cd\u65b0\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u7ec4\u5408\u4f7f\u7528\u3002"}}
{"id": "2506.06275", "pdf": "https://arxiv.org/pdf/2506.06275", "abs": "https://arxiv.org/abs/2506.06275", "authors": ["Emmanouil Zaranis", "Ant\u00f3nio Farinhas", "Saul Santos", "Beatriz Canaverde", "Miguel Moura Ramos", "Aditya K Surikuchi", "Andr\u00e9 Viveiros", "Baohao Liao", "Elena Bueno-Benito", "Nithin Sivakumaran", "Pavlo Vasylenko", "Shoubin Yu", "Sonal Sannigrahi", "Wafaa Mohammed", "Ben Peters", "Danae S\u00e1nchez Villegas", "Elias Stengel-Eskin", "Giuseppe Attanasio", "Jaehong Yoon", "Stella Frank", "Alessandro Suglia", "Chrysoula Zerva", "Desmond Elliott", "Mariella Dimiccoli", "Mohit Bansal", "Oswald Lanz", "Raffaella Bernardi", "Raquel Fern\u00e1ndez", "Sandro Pezzelle", "Vlad Niculae", "Andr\u00e9 F. T. Martins"], "title": "Movie Facts and Fibs (MF$^2$): A Benchmark for Long Movie Understanding", "categories": ["cs.CV", "cs.CL", "cs.LG"], "comment": "Under Review", "summary": "Despite recent progress in vision-language models (VLMs), holistic\nunderstanding of long-form video content remains a significant challenge,\npartly due to limitations in current benchmarks. Many focus on peripheral,\n``needle-in-a-haystack'' details, encouraging context-insensitive retrieval\nover deep comprehension. Others rely on large-scale, semi-automatically\ngenerated questions (often produced by language models themselves) that are\neasier for models to answer but fail to reflect genuine understanding. In this\npaper, we introduce MF$^2$, a new benchmark for evaluating whether models can\ncomprehend, consolidate, and recall key narrative information from full-length\nmovies (50-170 minutes long). MF$^2$ includes over 50 full-length,\nopen-licensed movies, each paired with manually constructed sets of claim pairs\n-- one true (fact) and one plausible but false (fib), totalling over 850 pairs.\nThese claims target core narrative elements such as character motivations and\nemotions, causal chains, and event order, and refer to memorable moments that\nhumans can recall without rewatching the movie. Instead of multiple-choice\nformats, we adopt a binary claim evaluation protocol: for each pair, models\nmust correctly identify both the true and false claims. This reduces biases\nlike answer ordering and enables a more precise assessment of reasoning. Our\nexperiments demonstrate that both open-weight and closed state-of-the-art\nmodels fall well short of human performance, underscoring the relative ease of\nthe task for humans and their superior ability to retain and reason over\ncritical narrative information -- an ability current VLMs lack.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86MF$^2$\uff0c\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u6a21\u578b\u5bf9\u957f\u89c6\u9891\u5185\u5bb9\u7406\u89e3\u80fd\u529b\u7684\u65b0\u57fa\u51c6\uff0c\u91cd\u70b9\u5173\u6ce8\u6838\u5fc3\u53d9\u4e8b\u5143\u7d20\uff0c\u800c\u975e\u8868\u9762\u7ec6\u8282\u3002", "motivation": "\u5f53\u524d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u5728\u957f\u89c6\u9891\u5185\u5bb9\u7406\u89e3\u4e0a\u5b58\u5728\u5c40\u9650\uff0c\u73b0\u6709\u57fa\u51c6\u591a\u5173\u6ce8\u8868\u9762\u7ec6\u8282\u6216\u4f9d\u8d56\u534a\u81ea\u52a8\u751f\u6210\u7684\u95ee\u9898\uff0c\u65e0\u6cd5\u53cd\u6620\u771f\u5b9e\u7406\u89e3\u3002", "method": "MF$^2$\u5305\u542b50\u591a\u90e8\u5b8c\u6574\u7535\u5f71\uff0c\u6bcf\u90e8\u7535\u5f71\u914d\u5bf9\u624b\u5de5\u6784\u5efa\u7684\u771f\u5b9e\u4e0e\u865a\u5047\u58f0\u660e\u5bf9\uff0c\u5171850\u591a\u5bf9\uff0c\u8bc4\u4f30\u6a21\u578b\u5bf9\u6838\u5fc3\u53d9\u4e8b\u7684\u7406\u89e3\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u73b0\u6709\u6a21\u578b\u5728\u8bc6\u522b\u771f\u5b9e\u4e0e\u865a\u5047\u58f0\u660e\u4e0a\u7684\u8868\u73b0\u8fdc\u4f4e\u4e8e\u4eba\u7c7b\uff0c\u7a81\u663e\u5176\u5728\u5173\u952e\u53d9\u4e8b\u4fe1\u606f\u4fdd\u7559\u548c\u63a8\u7406\u4e0a\u7684\u4e0d\u8db3\u3002", "conclusion": "MF$^2$\u63ed\u793a\u4e86\u5f53\u524dVLMs\u5728\u957f\u89c6\u9891\u5185\u5bb9\u7406\u89e3\u4e0a\u7684\u77ed\u677f\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u66f4\u7cbe\u51c6\u7684\u8bc4\u4f30\u5de5\u5177\u3002"}}
{"id": "2506.05426", "pdf": "https://arxiv.org/pdf/2506.05426", "abs": "https://arxiv.org/abs/2506.05426", "authors": ["Wenhao Wu", "Fuhong Liu", "Haoru Li", "Zican Hu", "Daoyi Dong", "Chunlin Chen", "Zhi Wang"], "title": "Mixture-of-Experts Meets In-Context Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "26 pages, 13 figures", "summary": "In-context reinforcement learning (ICRL) has emerged as a promising paradigm\nfor adapting RL agents to downstream tasks through prompt conditioning.\nHowever, two notable challenges remain in fully harnessing in-context learning\nwithin RL domains: the intrinsic multi-modality of the state-action-reward data\nand the diverse, heterogeneous nature of decision tasks. To tackle these\nchallenges, we propose \\textbf{T2MIR} (\\textbf{T}oken- and \\textbf{T}ask-wise\n\\textbf{M}oE for \\textbf{I}n-context \\textbf{R}L), an innovative framework that\nintroduces architectural advances of mixture-of-experts (MoE) into\ntransformer-based decision models. T2MIR substitutes the feedforward layer with\ntwo parallel layers: a token-wise MoE that captures distinct semantics of input\ntokens across multiple modalities, and a task-wise MoE that routes diverse\ntasks to specialized experts for managing a broad task distribution with\nalleviated gradient conflicts. To enhance task-wise routing, we introduce a\ncontrastive learning method that maximizes the mutual information between the\ntask and its router representation, enabling more precise capture of\ntask-relevant information. The outputs of two MoE components are concatenated\nand fed into the next layer. Comprehensive experiments show that T2MIR\nsignificantly facilitates in-context learning capacity and outperforms various\ntypes of baselines. We bring the potential and promise of MoE to ICRL, offering\na simple and scalable architectural enhancement to advance ICRL one step closer\ntoward achievements in language and vision communities. Our code is available\nat https://github.com/NJU-RL/T2MIR.", "AI": {"tldr": "T2MIR\u662f\u4e00\u79cd\u57fa\u4e8e\u6df7\u5408\u4e13\u5bb6\uff08MoE\uff09\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u4ee4\u724c\u548c\u4efb\u52a1\u7ea7MoE\u63d0\u5347\u4e0a\u4e0b\u6587\u5f3a\u5316\u5b66\u4e60\uff08ICRL\uff09\u7684\u6027\u80fd\uff0c\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u6570\u636e\u548c\u4efb\u52a1\u591a\u6837\u6027\u7684\u6311\u6218\u3002", "motivation": "ICRL\u5728\u9002\u5e94\u4e0b\u6e38\u4efb\u52a1\u65f6\u9762\u4e34\u591a\u6a21\u6001\u6570\u636e\u548c\u4efb\u52a1\u5f02\u8d28\u6027\u7684\u6311\u6218\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u67b6\u6784\u6765\u63d0\u5347\u6027\u80fd\u3002", "method": "T2MIR\u91c7\u7528\u4ee4\u724c\u7ea7\u548c\u4efb\u52a1\u7ea7MoE\uff0c\u7ed3\u5408\u5bf9\u6bd4\u5b66\u4e60\u4f18\u5316\u4efb\u52a1\u8def\u7531\uff0c\u589e\u5f3a\u6a21\u578b\u5bf9\u591a\u6a21\u6001\u548c\u4efb\u52a1\u591a\u6837\u6027\u7684\u5904\u7406\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8868\u660eT2MIR\u663e\u8457\u63d0\u5347\u4e86\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\uff0c\u4f18\u4e8e\u591a\u79cd\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "T2MIR\u4e3aICRL\u63d0\u4f9b\u4e86\u7b80\u5355\u53ef\u6269\u5c55\u7684\u67b6\u6784\u6539\u8fdb\uff0c\u63a8\u52a8\u4e86\u5176\u5728\u8bed\u8a00\u548c\u89c6\u89c9\u9886\u57df\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.05427", "pdf": "https://arxiv.org/pdf/2506.05427", "abs": "https://arxiv.org/abs/2506.05427", "authors": ["Zishan Shu", "Yufan Deng", "Hongyu Zhang", "Zhiwei Nie", "Jie Chen"], "title": "MTPNet: Multi-Grained Target Perception for Unified Activity Cliff Prediction", "categories": ["cs.LG", "cs.AI", "cs.CE"], "comment": null, "summary": "Activity cliff prediction is a critical task in drug discovery and material\ndesign. Existing computational methods are limited to handling single binding\ntargets, which restricts the applicability of these prediction models. In this\npaper, we present the Multi-Grained Target Perception network (MTPNet) to\nincorporate the prior knowledge of interactions between the molecules and their\ntarget proteins. Specifically, MTPNet is a unified framework for activity cliff\nprediction, which consists of two components: Macro-level Target Semantic (MTS)\nguidance and Micro-level Pocket Semantic (MPS) guidance. By this way, MTPNet\ndynamically optimizes molecular representations through multi-grained protein\nsemantic conditions. To our knowledge, it is the first time to employ the\nreceptor proteins as guiding information to effectively capture critical\ninteraction details. Extensive experiments on 30 representative activity cliff\ndatasets demonstrate that MTPNet significantly outperforms previous approaches,\nachieving an average RMSE improvement of 18.95% on top of several mainstream\nGNN architectures. Overall, MTPNet internalizes interaction patterns through\nconditional deep learning to achieve unified predictions of activity cliffs,\nhelping to accelerate compound optimization and design. Codes are available at:\nhttps://github.com/ZishanShu/MTPNet.", "AI": {"tldr": "MTPNet\u662f\u4e00\u79cd\u7528\u4e8e\u6d3b\u6027\u60ac\u5d16\u9884\u6d4b\u7684\u591a\u7c92\u5ea6\u76ee\u6807\u611f\u77e5\u7f51\u7edc\uff0c\u901a\u8fc7\u7ed3\u5408\u5206\u5b50\u4e0e\u9776\u86cb\u767d\u7684\u76f8\u4e92\u4f5c\u7528\u5148\u9a8c\u77e5\u8bc6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u8ba1\u7b97\u65b9\u6cd5\u4ec5\u80fd\u5904\u7406\u5355\u4e00\u7ed3\u5408\u76ee\u6807\uff0c\u9650\u5236\u4e86\u9884\u6d4b\u6a21\u578b\u7684\u9002\u7528\u6027\u3002MTPNet\u65e8\u5728\u901a\u8fc7\u591a\u7c92\u5ea6\u86cb\u767d\u8d28\u8bed\u4e49\u6761\u4ef6\u52a8\u6001\u4f18\u5316\u5206\u5b50\u8868\u5f81\u3002", "method": "MTPNet\u7531\u5b8f\u89c2\u76ee\u6807\u8bed\u4e49\uff08MTS\uff09\u548c\u5fae\u89c2\u53e3\u888b\u8bed\u4e49\uff08MPS\uff09\u4e24\u90e8\u5206\u7ec4\u6210\uff0c\u5229\u7528\u53d7\u4f53\u86cb\u767d\u4f5c\u4e3a\u6307\u5bfc\u4fe1\u606f\u6355\u83b7\u5173\u952e\u76f8\u4e92\u4f5c\u7528\u7ec6\u8282\u3002", "result": "\u572830\u4e2a\u4ee3\u8868\u6027\u6d3b\u6027\u60ac\u5d16\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMTPNet\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e73\u5747RMSE\u63d0\u5347\u4e8618.95%\u3002", "conclusion": "MTPNet\u901a\u8fc7\u6761\u4ef6\u6df1\u5ea6\u5b66\u4e60\u5185\u5316\u76f8\u4e92\u4f5c\u7528\u6a21\u5f0f\uff0c\u5b9e\u73b0\u4e86\u6d3b\u6027\u60ac\u5d16\u7684\u7edf\u4e00\u9884\u6d4b\uff0c\u6709\u52a9\u4e8e\u52a0\u901f\u5316\u5408\u7269\u4f18\u5316\u4e0e\u8bbe\u8ba1\u3002"}}
{"id": "2506.05428", "pdf": "https://arxiv.org/pdf/2506.05428", "abs": "https://arxiv.org/abs/2506.05428", "authors": ["Zhihao Tang", "Chaozhuo Li", "Litian Zhang", "Xi Zhang"], "title": "Diffusion with a Linguistic Compass: Steering the Generation of Clinically Plausible Future sMRI Representations for Early MCI Conversion Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Early prediction of Mild Cognitive Impairment (MCI) conversion is hampered by\na trade-off between immediacy--making fast predictions from a single baseline\nsMRI--and accuracy--leveraging longitudinal scans to capture disease\nprogression. We propose MCI-Diff, a diffusion-based framework that synthesizes\nclinically plausible future sMRI representations directly from baseline data,\nachieving both real-time risk assessment and high predictive performance.\nFirst, a multi-task sequence reconstruction strategy trains a shared denoising\nnetwork on interpolation and extrapolation tasks to handle irregular follow-up\nsampling and learn robust latent trajectories. Second, an LLM-driven\n\"linguistic compass\" is introduced for clinical plausibility sampling:\ngenerated feature candidates are quantized, tokenized, and scored by a\nfine-tuned language model conditioned on expected structural biomarkers,\nguiding autoregressive generation toward realistic disease patterns.\nExperiments on ADNI and AIBL cohorts show that MCI-Diff outperforms\nstate-of-the-art baselines, improving early conversion accuracy by 5-12%.", "AI": {"tldr": "MCI-Diff\u662f\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u4ece\u57fa\u7ebf\u6570\u636e\u5408\u6210\u672a\u6765sMRI\u8868\u793a\uff0c\u5b9e\u73b0\u5b9e\u65f6\u98ce\u9669\u8bc4\u4f30\u548c\u9ad8\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u65e9\u671f\u9884\u6d4b\u8f7b\u5ea6\u8ba4\u77e5\u969c\u788d\uff08MCI\uff09\u8f6c\u5316\u5b58\u5728\u5373\u65f6\u6027\uff08\u4ece\u5355\u6b21\u57fa\u7ebfsMRI\u5feb\u901f\u9884\u6d4b\uff09\u4e0e\u51c6\u786e\u6027\uff08\u5229\u7528\u7eb5\u5411\u626b\u63cf\u6355\u6349\u75be\u75c5\u8fdb\u5c55\uff09\u4e4b\u95f4\u7684\u6743\u8861\u3002", "method": "1. \u591a\u4efb\u52a1\u5e8f\u5217\u91cd\u5efa\u7b56\u7565\u8bad\u7ec3\u5171\u4eab\u53bb\u566a\u7f51\u7edc\u5904\u7406\u4e0d\u89c4\u5219\u968f\u8bbf\u91c7\u6837\uff1b2. \u5f15\u5165LLM\u9a71\u52a8\u7684\u201c\u8bed\u8a00\u6307\u5357\u201d\u8fdb\u884c\u4e34\u5e8a\u5408\u7406\u6027\u91c7\u6837\u3002", "result": "\u5728ADNI\u548cAIBL\u961f\u5217\u4e2d\uff0cMCI-Diff\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u65e9\u671f\u8f6c\u5316\u51c6\u786e\u6027\u63d0\u9ad85-12%\u3002", "conclusion": "MCI-Diff\u5728\u5b9e\u65f6\u6027\u548c\u51c6\u786e\u6027\u4e0a\u53d6\u5f97\u5e73\u8861\uff0c\u663e\u8457\u63d0\u5347\u4e86MCI\u65e9\u671f\u8f6c\u5316\u7684\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2506.05432", "pdf": "https://arxiv.org/pdf/2506.05432", "abs": "https://arxiv.org/abs/2506.05432", "authors": ["Yuxuan Yue", "Zukang Xu", "Zhihang Yuan", "Dawei Yang", "Jianglong Wu", "Liqiang Nie"], "title": "PCDVQ: Enhancing Vector Quantization for Large Language Models via Polar Coordinate Decoupling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) face significant challenges in edge deployment\ndue to their massive parameter scale. Vector Quantization (VQ), a\nclustering-based quantization method, serves as a prevalent solution to this\nissue for its extremely low-bit (even at 2-bit) and considerable accuracy.\nSince a vector is a quantity in mathematics and physics that has both direction\nand magnitude, existing VQ works typically quantize them in a coupled manner.\nHowever, we find that direction exhibits significantly greater sensitivity to\nquantization compared to the magnitude. For instance, when separately\nclustering the directions and magnitudes of weight vectors in LLaMA-2-7B, the\naccuracy drop of zero-shot tasks are 46.5\\% and 2.3\\%, respectively. This gap\neven increases with the reduction of clustering centers. Further, Euclidean\ndistance, a common metric to access vector similarities in current VQ works,\nplaces greater emphasis on reducing the magnitude error. This property is\ncontrary to the above finding, unavoidably leading to larger quantization\nerrors. To these ends, this paper proposes Polar Coordinate Decoupled Vector\nQuantization (PCDVQ), an effective and efficient VQ framework consisting of two\nkey modules: 1) Polar Coordinate Decoupling (PCD), which transforms vectors\ninto their polar coordinate representations and perform independent\nquantization of the direction and magnitude parameters.2) Distribution Aligned\nCodebook Construction (DACC), which optimizes the direction and magnitude\ncodebooks in accordance with the source distribution. Experimental results show\nthat PCDVQ outperforms baseline methods at 2-bit level by at least 1.5\\%\nzero-shot accuracy, establishing a novel paradigm for accurate and highly\ncompressed LLMs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faPCDVQ\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u8026\u5411\u91cf\u7684\u65b9\u5411\u548c\u5e45\u5ea6\u8fdb\u884c\u91cf\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4f4e\u6bd4\u7279\u91cf\u5316\u4e0bLLMs\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u5411\u91cf\u91cf\u5316\u65b9\u6cd5\u901a\u5e38\u8026\u5408\u91cf\u5316\u5411\u91cf\u7684\u65b9\u5411\u548c\u5e45\u5ea6\uff0c\u4f46\u7814\u7a76\u53d1\u73b0\u65b9\u5411\u5bf9\u91cf\u5316\u66f4\u654f\u611f\uff0c\u73b0\u6709\u65b9\u6cd5\u56e0\u6b27\u6c0f\u8ddd\u79bb\u7684\u5c40\u9650\u6027\u5bfc\u81f4\u91cf\u5316\u8bef\u5dee\u8f83\u5927\u3002", "method": "\u63d0\u51faPolar Coordinate Decoupled Vector Quantization (PCDVQ)\uff0c\u5305\u62ec\u4e24\u4e2a\u6a21\u5757\uff1a1) \u6781\u5750\u6807\u89e3\u8026\uff08PCD\uff09\uff0c\u72ec\u7acb\u91cf\u5316\u65b9\u5411\u548c\u5e45\u5ea6\uff1b2) \u5206\u5e03\u5bf9\u9f50\u7801\u672c\u6784\u5efa\uff08DACC\uff09\uff0c\u4f18\u5316\u7801\u672c\u4ee5\u5339\u914d\u6e90\u5206\u5e03\u3002", "result": "\u5b9e\u9a8c\u663e\u793aPCDVQ\u57282\u6bd4\u7279\u91cf\u5316\u4e0b\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u81f3\u5c11\u63d0\u53471.5%\u7684\u96f6\u6837\u672c\u51c6\u786e\u7387\u3002", "conclusion": "PCDVQ\u4e3a\u9ad8\u538b\u7f29LLMs\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u8303\u5f0f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u91cf\u5316\u7cbe\u5ea6\u3002"}}
{"id": "2506.05433", "pdf": "https://arxiv.org/pdf/2506.05433", "abs": "https://arxiv.org/abs/2506.05433", "authors": ["Zikang Liu", "Tongtian Yue", "Yepeng Tang", "Longteng Guo", "Junxian Cai", "Qingbin Liu", "Xi Chen", "Jing Liu"], "title": "Prefix Grouper: Efficient GRPO Training through Shared-Prefix Forward", "categories": ["cs.LG", "cs.AI"], "comment": "10 pages, technical report", "summary": "Group Relative Policy Optimization (GRPO) enhances policy learning by\ncomputing gradients from relative comparisons among candidate outputs that\nshare a common input prefix. Despite its effectiveness, GRPO introduces\nsubstantial computational overhead when processing long shared prefixes, which\nmust be redundantly encoded for each group member. This inefficiency becomes a\nmajor scalability bottleneck in long-context learning scenarios. We propose\nPrefix Grouper, an efficient GRPO training algorithm that eliminates redundant\nprefix computation via a Shared-Prefix Forward strategy. In particular, by\nrestructuring self-attention into two parts, our method enables the shared\nprefix to be encoded only once, while preserving full differentiability and\ncompatibility with end-to-end training. We provide both theoretical and\nempirical evidence that Prefix Grouper is training-equivalent to standard GRPO:\nit yields identical forward outputs and backward gradients, ensuring that the\noptimization dynamics and final policy performance remain unchanged.\nEmpirically, our experiments confirm that Prefix Grouper achieves consistent\nresults while significantly reducing the computational cost of training,\nparticularly in long-prefix scenarios. The proposed method is fully\nplug-and-play: it is compatible with existing GRPO-based architectures and can\nbe seamlessly integrated into current training pipelines as a drop-in\nreplacement, requiring no structural modifications and only minimal changes to\ninput construction and attention computation. Prefix Grouper enables the use of\nlarger group sizes under the same computational budget, thereby improving the\nscalability of GRPO to more complex tasks and larger models. Code is now\navailable at https://github.com/johncaged/PrefixGrouper", "AI": {"tldr": "Prefix Grouper\u662f\u4e00\u79cd\u9ad8\u6548\u7684GRPO\u8bad\u7ec3\u7b97\u6cd5\uff0c\u901a\u8fc7\u5171\u4eab\u524d\u7f00\u8ba1\u7b97\u51cf\u5c11\u5197\u4f59\uff0c\u63d0\u5347\u957f\u4e0a\u4e0b\u6587\u5b66\u4e60\u573a\u666f\u4e0b\u7684\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "GRPO\u5728\u5904\u7406\u957f\u5171\u4eab\u524d\u7f00\u65f6\u5b58\u5728\u8ba1\u7b97\u5197\u4f59\u95ee\u9898\uff0c\u6210\u4e3a\u6269\u5c55\u6027\u7684\u74f6\u9888\u3002", "method": "\u91c7\u7528Shared-Prefix Forward\u7b56\u7565\uff0c\u5c06\u81ea\u6ce8\u610f\u529b\u5206\u4e3a\u4e24\u90e8\u5206\uff0c\u5171\u4eab\u524d\u7f00\u4ec5\u7f16\u7801\u4e00\u6b21\uff0c\u4fdd\u6301\u7aef\u5230\u7aef\u8bad\u7ec3\u517c\u5bb9\u6027\u3002", "result": "\u7406\u8bba\u548c\u5b9e\u9a8c\u8bc1\u660ePrefix Grouper\u4e0e\u6807\u51c6GRPO\u8bad\u7ec3\u7b49\u6548\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "Prefix Grouper\u53ef\u65e0\u7f1d\u96c6\u6210\u73b0\u6709GRPO\u67b6\u6784\uff0c\u63d0\u5347\u4efb\u52a1\u590d\u6742\u6027\u548c\u6a21\u578b\u89c4\u6a21\u7684\u6269\u5c55\u6027\u3002"}}
{"id": "2506.05434", "pdf": "https://arxiv.org/pdf/2506.05434", "abs": "https://arxiv.org/abs/2506.05434", "authors": ["Thomas Massena", "L\u00e9o and\u00e9ol", "Thibaut Boissin", "Franck Mamalet", "Corentin Friedrich", "Mathieu Serrurier", "S\u00e9bastien Gerchinovitz"], "title": "Efficient Robust Conformal Prediction via Lipschitz-Bounded Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Conformal Prediction (CP) has proven to be an effective post-hoc method for\nimproving the trustworthiness of neural networks by providing prediction sets\nwith finite-sample guarantees. However, under adversarial attacks, classical\nconformal guarantees do not hold anymore: this problem is addressed in the\nfield of Robust Conformal Prediction. Several methods have been proposed to\nprovide robust CP sets with guarantees under adversarial perturbations, but,\nfor large scale problems, these sets are either too large or the methods are\ntoo computationally demanding to be deployed in real life scenarios. In this\nwork, we propose a new method that leverages Lipschitz-bounded networks to\nprecisely and efficiently estimate robust CP sets. When combined with a\n1-Lipschitz robust network, we demonstrate that our lip-rcp method outperforms\nstate-of-the-art results in both the size of the robust CP sets and\ncomputational efficiency in medium and large-scale scenarios such as ImageNet.\nTaking a different angle, we also study vanilla CP under attack, and derive new\nworst-case coverage bounds of vanilla CP sets, which are valid simultaneously\nfor all adversarial attack levels. Our lip-rcp method makes this second\napproach as efficient as vanilla CP while also allowing robustness guarantees.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLipschitz\u7ea6\u675f\u7f51\u7edc\u7684\u65b0\u65b9\u6cd5\uff08lip-rcp\uff09\uff0c\u7528\u4e8e\u9ad8\u6548\u7cbe\u786e\u5730\u4f30\u8ba1\u9c81\u68d2\u5171\u5f62\u9884\u6d4b\u96c6\uff0c\u5e76\u5728\u4e2d\u5927\u89c4\u6a21\u573a\u666f\uff08\u5982ImageNet\uff09\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u5171\u5f62\u9884\u6d4b\uff08CP\uff09\u5728\u5bf9\u6297\u653b\u51fb\u4e0b\u65e0\u6cd5\u4fdd\u8bc1\u9884\u6d4b\u96c6\u7684\u53ef\u9760\u6027\uff0c\u800c\u73b0\u6709\u9c81\u68d2CP\u65b9\u6cd5\u5728\u5927\u89c4\u6a21\u95ee\u9898\u4e2d\u8ba1\u7b97\u6210\u672c\u9ad8\u6216\u9884\u6d4b\u96c6\u8fc7\u5927\uff0c\u96be\u4ee5\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u5229\u7528Lipschitz\u7ea6\u675f\u7f51\u7edc\u8bbe\u8ba1lip-rcp\u65b9\u6cd5\uff0c\u7ed3\u54081-Lipschitz\u9c81\u68d2\u7f51\u7edc\uff0c\u9ad8\u6548\u751f\u6210\u9c81\u68d2CP\u96c6\u3002", "result": "lip-rcp\u5728\u4e2d\u5927\u89c4\u6a21\u573a\u666f\uff08\u5982ImageNet\uff09\u4e2d\uff0c\u9884\u6d4b\u96c6\u5927\u5c0f\u548c\u8ba1\u7b97\u6548\u7387\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002\u540c\u65f6\uff0c\u8fd8\u5206\u6790\u4e86\u4f20\u7edfCP\u5728\u653b\u51fb\u4e0b\u7684\u6700\u574f\u8986\u76d6\u8fb9\u754c\u3002", "conclusion": "lip-rcp\u65b9\u6cd5\u5728\u4fdd\u8bc1\u9c81\u68d2\u6027\u7684\u540c\u65f6\uff0c\u8ba1\u7b97\u6548\u7387\u4e0e\u4f20\u7edfCP\u76f8\u5f53\uff0c\u4e3a\u5927\u89c4\u6a21\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2506.05435", "pdf": "https://arxiv.org/pdf/2506.05435", "abs": "https://arxiv.org/abs/2506.05435", "authors": ["Manon Renault", "Hamoud Younes", "Hugo Tessier", "Ronan Le Roy", "Bastien Pasdeloup", "Mathieu L\u00e9onardon"], "title": "Event Classification of Accelerometer Data for Industrial Package Monitoring with Embedded Deep Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Package monitoring is an important topic in industrial applications, with\nsignificant implications for operational efficiency and ecological\nsustainability. In this study, we propose an approach that employs an embedded\nsystem, placed on reusable packages, to detect their state (on a Forklift, in a\nTruck, or in an undetermined location). We aim to design a system with a\nlifespan of several years, corresponding to the lifespan of reusable packages.\nOur analysis demonstrates that maximizing device lifespan requires minimizing\nwake time. We propose a pipeline that includes data processing, training, and\nevaluation of the deep learning model designed for imbalanced, multiclass time\nseries data collected from an embedded sensor. The method uses a\none-dimensional Convolutional Neural Network architecture to classify\naccelerometer data from the IoT device. Before training, two data augmentation\ntechniques are tested to solve the imbalance problem of the dataset: the\nSynthetic Minority Oversampling TEchnique and the ADAptive SYNthetic sampling\napproach. After training, compression techniques are implemented to have a\nsmall model size. On the considered twoclass problem, the methodology yields a\nprecision of 94.54% for the first class and 95.83% for the second class, while\ncompression techniques reduce the model size by a factor of four. The trained\nmodel is deployed on the IoT device, where it operates with a power consumption\nof 316 mW during inference.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5d4c\u5165\u5f0f\u7cfb\u7edf\u7684\u5305\u88c5\u72b6\u6001\u76d1\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5206\u7c7b\u52a0\u901f\u5ea6\u8ba1\u6570\u636e\uff0c\u4f18\u5316\u8bbe\u5907\u5bff\u547d\u548c\u6a21\u578b\u5927\u5c0f\u3002", "motivation": "\u5de5\u4e1a\u5e94\u7528\u4e2d\u5305\u88c5\u76d1\u6d4b\u5bf9\u6548\u7387\u548c\u53ef\u6301\u7eed\u6027\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8bbe\u8ba1\u957f\u5bff\u547d\u7cfb\u7edf\u4ee5\u5339\u914d\u53ef\u91cd\u590d\u4f7f\u7528\u5305\u88c5\u7684\u751f\u547d\u5468\u671f\u3002", "method": "\u4f7f\u7528\u4e00\u7ef4\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5904\u7406\u4e0d\u5e73\u8861\u591a\u7c7b\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u6d4b\u8bd5\u4e24\u79cd\u6570\u636e\u589e\u5f3a\u6280\u672f\uff08SMOTE\u548cADASYN\uff09\uff0c\u5e76\u5e94\u7528\u6a21\u578b\u538b\u7f29\u6280\u672f\u3002", "result": "\u6a21\u578b\u5728\u4e24\u5206\u7c7b\u95ee\u9898\u4e2d\u7cbe\u5ea6\u8fbe94.54%\u548c95.83%\uff0c\u6a21\u578b\u5927\u5c0f\u51cf\u5c11\u56db\u500d\uff0c\u63a8\u7406\u529f\u8017\u4e3a316 mW\u3002", "conclusion": "\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u5305\u88c5\u72b6\u6001\u76d1\u6d4b\u95ee\u9898\uff0c\u540c\u65f6\u4f18\u5316\u4e86\u8bbe\u5907\u5bff\u547d\u548c\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2506.05438", "pdf": "https://arxiv.org/pdf/2506.05438", "abs": "https://arxiv.org/abs/2506.05438", "authors": ["Tongda Sun", "Chen Yin", "Huailiang Zheng", "Yining Dong"], "title": "An Unsupervised Framework for Dynamic Health Indicator Construction and Its Application in Rolling Bearing Prognostics", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Health indicator (HI) plays a key role in degradation assessment and\nprognostics of rolling bearings. Although various HI construction methods have\nbeen investigated, most of them rely on expert knowledge for feature extraction\nand overlook capturing dynamic information hidden in sequential degradation\nprocesses, which limits the ability of the constructed HI for degradation trend\nrepresentation and prognostics. To address these concerns, a novel dynamic HI\nthat considers HI-level temporal dependence is constructed through an\nunsupervised framework. Specifically, a degradation feature learning module\ncomposed of a skip-connection-based autoencoder first maps raw signals to a\nrepresentative degradation feature space (DFS) to automatically extract\nessential degradation features without the need for expert knowledge.\nSubsequently, in this DFS, a new HI-generating module embedded with an inner\nHI-prediction block is proposed for dynamic HI construction, where the temporal\ndependence between past and current HI states is guaranteed and modeled\nexplicitly. On this basis, the dynamic HI captures the inherent dynamic\ncontents of the degradation process, ensuring its effectiveness for degradation\ntendency modeling and future degradation prognostics. The experiment results on\ntwo bearing lifecycle datasets demonstrate that the proposed HI construction\nmethod outperforms comparison methods, and the constructed dynamic HI is\nsuperior for prognostic tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u52a8\u6001\u5065\u5eb7\u6307\u6807\uff08HI\uff09\u6784\u5efa\u65b9\u6cd5\uff0c\u901a\u8fc7\u65e0\u76d1\u7763\u6846\u67b6\u81ea\u52a8\u63d0\u53d6\u9000\u5316\u7279\u5f81\u5e76\u5efa\u6a21\u65f6\u5e8f\u4f9d\u8d56\u5173\u7cfb\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u5065\u5eb7\u6307\u6807\u6784\u5efa\u65b9\u6cd5\u4f9d\u8d56\u4e13\u5bb6\u77e5\u8bc6\u4e14\u5ffd\u7565\u52a8\u6001\u4fe1\u606f\uff0c\u9650\u5236\u4e86\u9000\u5316\u8d8b\u52bf\u8868\u5f81\u548c\u9884\u6d4b\u80fd\u529b\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u8df3\u8dc3\u8fde\u63a5\u7684\u81ea\u7f16\u7801\u5668\u63d0\u53d6\u9000\u5316\u7279\u5f81\uff0c\u5e76\u5d4c\u5165HI\u9884\u6d4b\u5757\u6784\u5efa\u52a8\u6001HI\uff0c\u5efa\u6a21\u65f6\u5e8f\u4f9d\u8d56\u3002", "result": "\u5728\u4e24\u4e2a\u8f74\u627f\u751f\u547d\u5468\u671f\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u6240\u63d0\u65b9\u6cd5\u4f18\u4e8e\u5bf9\u6bd4\u65b9\u6cd5\uff0c\u52a8\u6001HI\u5728\u9884\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u52a8\u6001HI\u80fd\u6709\u6548\u6355\u6349\u9000\u5316\u8fc7\u7a0b\u7684\u52a8\u6001\u5185\u5bb9\uff0c\u63d0\u5347\u9000\u5316\u8d8b\u52bf\u5efa\u6a21\u548c\u9884\u6d4b\u80fd\u529b\u3002"}}
{"id": "2506.05443", "pdf": "https://arxiv.org/pdf/2506.05443", "abs": "https://arxiv.org/abs/2506.05443", "authors": ["Yiyu Lin", "Yan Wang", "You Zhou", "Xinye Ni", "Jiahui Wu", "Sen Yang"], "title": "UniPTMs: The First Unified Multi-type PTM Site Prediction Model via Master-Slave Architecture-Based Multi-Stage Fusion Strategy and Hierarchical Contrastive Loss", "categories": ["cs.LG", "cs.AI", "q-bio.GN"], "comment": null, "summary": "As a core mechanism of epigenetic regulation in eukaryotes, protein\npost-translational modifications (PTMs) require precise prediction to decipher\ndynamic life activity networks. To address the limitations of existing deep\nlearning models in cross-modal feature fusion, domain generalization, and\narchitectural optimization, this study proposes UniPTMs: the first unified\nframework for multi-type PTM prediction. The framework innovatively establishes\na \"Master-Slave\" dual-path collaborative architecture: The master path\ndynamically integrates high-dimensional representations of protein sequences,\nstructures, and evolutionary information through a Bidirectional Gated\nCross-Attention (BGCA) module, while the slave path optimizes feature\ndiscrepancies and recalibration between structural and traditional features\nusing a Low-Dimensional Fusion Network (LDFN). Complemented by a Multi-scale\nAdaptive convolutional Pyramid (MACP) for capturing local feature patterns and\na Bidirectional Hierarchical Gated Fusion Network (BHGFN) enabling multi-level\nfeature integration across paths, the framework employs a Hierarchical Dynamic\nWeighting Fusion (HDWF) mechanism to intelligently aggregate multimodal\nfeatures. Enhanced by a novel Hierarchical Contrastive loss function for\nfeature consistency optimization, UniPTMs demonstrates significant performance\nimprovements (3.2%-11.4% MCC and 4.2%-14.3% AP increases) over state-of-the-art\nmodels across five modification types and transcends the Single-Type Prediction\nParadigm. To strike a balance between model complexity and performance, we have\nalso developed a lightweight variant named UniPTMs-mini.", "AI": {"tldr": "UniPTMs\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u591a\u7c7b\u578b\u86cb\u767d\u8d28\u7ffb\u8bd1\u540e\u4fee\u9970\uff08PTM\uff09\u9884\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u53cc\u8def\u5f84\u534f\u4f5c\u67b6\u6784\u548c\u52a8\u6001\u7279\u5f81\u878d\u5408\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u8de8\u6a21\u6001\u7279\u5f81\u878d\u5408\u3001\u9886\u57df\u6cdb\u5316\u548c\u67b6\u6784\u4f18\u5316\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684PTM\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u63d0\u51faUniPTMs\u6846\u67b6\uff0c\u91c7\u7528\u4e3b\u4ece\u53cc\u8def\u5f84\u534f\u4f5c\u67b6\u6784\uff0c\u7ed3\u5408BGCA\u6a21\u5757\u3001LDFN\u7f51\u7edc\u3001MACP\u91d1\u5b57\u5854\u548cBHGFN\u7f51\u7edc\uff0c\u5e76\u5f15\u5165HDWF\u673a\u5236\u548c\u5bf9\u6bd4\u635f\u5931\u51fd\u6570\u3002", "result": "\u5728\u4e94\u79cd\u4fee\u9970\u7c7b\u578b\u4e0a\uff0cUniPTMs\u7684\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff08MCC\u63d0\u53473.2%-11.4%\uff0cAP\u63d0\u53474.2%-14.3%\uff09\u3002", "conclusion": "UniPTMs\u4e0d\u4ec5\u7a81\u7834\u4e86\u5355\u7c7b\u578b\u9884\u6d4b\u8303\u5f0f\uff0c\u8fd8\u901a\u8fc7\u8f7b\u91cf\u7ea7\u53d8\u4f53UniPTMs-mini\u5e73\u8861\u4e86\u6a21\u578b\u590d\u6742\u6027\u4e0e\u6027\u80fd\u3002"}}
{"id": "2506.05445", "pdf": "https://arxiv.org/pdf/2506.05445", "abs": "https://arxiv.org/abs/2506.05445", "authors": ["Thanh Vinh Vo", "Young Lee", "Haozhe Ma", "Chien Lu", "Tze-Yun Leong"], "title": "Causal Policy Learning in Reinforcement Learning: Backdoor-Adjusted Soft Actor-Critic", "categories": ["cs.LG", "cs.AI"], "comment": "Preprint", "summary": "Hidden confounders that influence both states and actions can bias policy\nlearning in reinforcement learning (RL), leading to suboptimal or\nnon-generalizable behavior. Most RL algorithms ignore this issue, learning\npolicies from observational trajectories based solely on statistical\nassociations rather than causal effects. We propose DoSAC (Do-Calculus Soft\nActor-Critic with Backdoor Adjustment), a principled extension of the SAC\nalgorithm that corrects for hidden confounding via causal intervention\nestimation. DoSAC estimates the interventional policy $\\pi(a | \\mathrm{do}(s))$\nusing the backdoor criterion, without requiring access to true confounders or\ncausal labels. To achieve this, we introduce a learnable Backdoor Reconstructor\nthat infers pseudo-past variables (previous state and action) from the current\nstate to enable backdoor adjustment from observational data. This module is\nintegrated into a soft actor-critic framework to compute both the\ninterventional policy and its entropy. Empirical results on continuous control\nbenchmarks show that DoSAC outperforms baselines under confounded settings,\nwith improved robustness, generalization, and policy reliability.", "AI": {"tldr": "DoSAC\u662f\u4e00\u79cd\u57fa\u4e8e\u56e0\u679c\u5e72\u9884\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u540e\u95e8\u8c03\u6574\u89e3\u51b3\u9690\u85cf\u6df7\u6742\u56e0\u7d20\u95ee\u9898\uff0c\u63d0\u5347\u7b56\u7565\u5b66\u4e60\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u9690\u85cf\u6df7\u6742\u56e0\u7d20\u4f1a\u5f71\u54cd\u72b6\u6001\u548c\u52a8\u4f5c\uff0c\u5bfc\u81f4\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u5b66\u4e60\u51fa\u73b0\u504f\u5dee\uff0c\u4f20\u7edfRL\u7b97\u6cd5\u5ffd\u7565\u6b64\u95ee\u9898\u3002", "method": "\u63d0\u51faDoSAC\u7b97\u6cd5\uff0c\u7ed3\u5408\u540e\u95e8\u8c03\u6574\u548c\u8f6f\u6f14\u5458-\u8bc4\u8bba\u5bb6\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u540e\u95e8\u91cd\u6784\u5668\u63a8\u65ad\u4f2a\u8fc7\u53bb\u53d8\u91cf\uff0c\u5b9e\u73b0\u56e0\u679c\u5e72\u9884\u3002", "result": "\u5728\u8fde\u7eed\u63a7\u5236\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDoSAC\u5728\u6df7\u6742\u73af\u5883\u4e0b\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5177\u6709\u66f4\u597d\u7684\u9c81\u68d2\u6027\u3001\u6cdb\u5316\u80fd\u529b\u548c\u7b56\u7565\u53ef\u9760\u6027\u3002", "conclusion": "DoSAC\u901a\u8fc7\u56e0\u679c\u5e72\u9884\u6709\u6548\u89e3\u51b3\u4e86\u9690\u85cf\u6df7\u6742\u56e0\u7d20\u95ee\u9898\uff0c\u4e3a\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u53ef\u9760\u7684\u7b56\u7565\u5b66\u4e60\u65b9\u6cd5\u3002"}}
{"id": "2506.05447", "pdf": "https://arxiv.org/pdf/2506.05447", "abs": "https://arxiv.org/abs/2506.05447", "authors": ["Andrei Mircea", "Supriyo Chakraborty", "Nima Chitsazan", "Irina Rish", "Ekaterina Lobacheva"], "title": "Training Dynamics Underlying Language Model Scaling Laws: Loss Deceleration and Zero-Sum Learning", "categories": ["cs.LG", "cs.AI", "I.2.7"], "comment": "Published as a conference paper at ACL 2025", "summary": "This work aims to understand how scaling improves language models,\nspecifically in terms of training dynamics. We find that language models\nundergo loss deceleration early in training; an abrupt slowdown in the rate of\nloss improvement, resulting in piecewise linear behaviour of the loss curve in\nlog-log space. Scaling up the model mitigates this transition by (1) decreasing\nthe loss at which deceleration occurs, and (2) improving the log-log rate of\nloss improvement after deceleration. We attribute loss deceleration to a type\nof degenerate training dynamics we term zero-sum learning (ZSL). In ZSL,\nper-example gradients become systematically opposed, leading to destructive\ninterference in per-example changes in loss. As a result, improving loss on one\nsubset of examples degrades it on another, bottlenecking overall progress. Loss\ndeceleration and ZSL provide new insights into the training dynamics underlying\nlanguage model scaling laws, and could potentially be targeted directly to\nimprove language models independent of scale. We make our code and artefacts\navailable at: https://github.com/mirandrom/zsl", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u8bed\u8a00\u6a21\u578b\u5728\u8bad\u7ec3\u65e9\u671f\u4f1a\u51fa\u73b0\u635f\u5931\u51cf\u901f\u73b0\u8c61\uff0c\u6a21\u578b\u89c4\u6a21\u7684\u6269\u5927\u53ef\u4ee5\u7f13\u89e3\u8fd9\u4e00\u73b0\u8c61\u3002", "motivation": "\u7406\u89e3\u6a21\u578b\u89c4\u6a21\u5982\u4f55\u901a\u8fc7\u8bad\u7ec3\u52a8\u6001\u5f71\u54cd\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u3002", "method": "\u5206\u6790\u635f\u5931\u66f2\u7ebf\u7684\u5bf9\u6570-\u5bf9\u6570\u7a7a\u95f4\u884c\u4e3a\uff0c\u63d0\u51fa\u96f6\u548c\u5b66\u4e60\uff08ZSL\uff09\u6982\u5ff5\u89e3\u91ca\u635f\u5931\u51cf\u901f\u3002", "result": "\u6a21\u578b\u89c4\u6a21\u6269\u5927\u80fd\u964d\u4f4e\u635f\u5931\u51cf\u901f\u53d1\u751f\u7684\u635f\u5931\u503c\uff0c\u5e76\u6539\u5584\u51cf\u901f\u540e\u7684\u635f\u5931\u6539\u8fdb\u901f\u7387\u3002", "conclusion": "\u635f\u5931\u51cf\u901f\u548cZSL\u4e3a\u8bed\u8a00\u6a21\u578b\u89c4\u6a21\u5b9a\u5f8b\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\uff0c\u53ef\u80fd\u76f4\u63a5\u4f18\u5316\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2506.05454", "pdf": "https://arxiv.org/pdf/2506.05454", "abs": "https://arxiv.org/abs/2506.05454", "authors": ["Liang Zhang", "Bingcong Li", "Kiran Koshy Thekumparampil", "Sewoong Oh", "Michael Muehlebach", "Niao He"], "title": "Zeroth-Order Optimization Finds Flat Minima", "categories": ["cs.LG", "cs.AI", "math.OC", "stat.ML"], "comment": null, "summary": "Zeroth-order methods are extensively used in machine learning applications\nwhere gradients are infeasible or expensive to compute, such as black-box\nattacks, reinforcement learning, and language model fine-tuning. Existing\noptimization theory focuses on convergence to an arbitrary stationary point,\nbut less is known on the implicit regularization that provides a fine-grained\ncharacterization on which particular solutions are finally reached. We show\nthat zeroth-order optimization with the standard two-point estimator favors\nsolutions with small trace of Hessian, which is widely used in previous work to\ndistinguish between sharp and flat minima. We further provide convergence rates\nof zeroth-order optimization to approximate flat minima for convex and\nsufficiently smooth functions, where flat minima are defined as the minimizers\nthat achieve the smallest trace of Hessian among all optimal solutions.\nExperiments on binary classification tasks with convex losses and language\nmodel fine-tuning support our theoretical findings.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u96f6\u9636\u4f18\u5316\u65b9\u6cd5\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u9690\u5f0f\u6b63\u5219\u5316\u7279\u6027\uff0c\u53d1\u73b0\u6807\u51c6\u4e24\u70b9\u4f30\u8ba1\u5668\u503e\u5411\u4e8e\u9009\u62e9Hessian\u77e9\u9635\u8ff9\u8f83\u5c0f\u7684\u89e3\uff08\u5373\u5e73\u5766\u6700\u5c0f\u503c\uff09\uff0c\u5e76\u63d0\u4f9b\u4e86\u6536\u655b\u901f\u7387\u7684\u7406\u8bba\u5206\u6790\u3002", "motivation": "\u96f6\u9636\u65b9\u6cd5\u5728\u68af\u5ea6\u96be\u4ee5\u8ba1\u7b97\u6216\u4e0d\u53ef\u884c\u7684\u60c5\u51b5\u4e0b\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u73b0\u6709\u7406\u8bba\u4e3b\u8981\u5173\u6ce8\u6536\u655b\u6027\uff0c\u5bf9\u9690\u5f0f\u6b63\u5219\u5316\u7684\u7814\u7a76\u8f83\u5c11\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u4f7f\u7528\u6807\u51c6\u4e24\u70b9\u4f30\u8ba1\u5668\u7684\u96f6\u9636\u4f18\u5316\u65b9\u6cd5\uff0c\u5206\u6790\u5176\u5bf9Hessian\u77e9\u9635\u8ff9\u7684\u5f71\u54cd\uff0c\u5e76\u5b9a\u4e49\u5e73\u5766\u6700\u5c0f\u503c\u4e3aHessian\u8ff9\u6700\u5c0f\u7684\u6700\u4f18\u89e3\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u96f6\u9636\u4f18\u5316\u503e\u5411\u4e8e\u9009\u62e9\u5e73\u5766\u6700\u5c0f\u503c\uff0c\u5e76\u5728\u51f8\u4e14\u5145\u5206\u5149\u6ed1\u7684\u51fd\u6570\u4e0a\u63d0\u4f9b\u4e86\u6536\u655b\u901f\u7387\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u679c\u3002", "conclusion": "\u96f6\u9636\u4f18\u5316\u65b9\u6cd5\u9690\u5f0f\u504f\u597d\u5e73\u5766\u6700\u5c0f\u503c\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2506.05479", "pdf": "https://arxiv.org/pdf/2506.05479", "abs": "https://arxiv.org/abs/2506.05479", "authors": ["Matei Gabriel Co\u015fa", "Marek Eli\u00e1\u0161"], "title": "Learning-Augmented Algorithms for MTS with Bandit Access to Multiple Predictors", "categories": ["cs.LG", "cs.DS", "68W40 (Primary), 68T05 (Secondary)"], "comment": "Accepted to ICML 2025", "summary": "We consider the following problem: We are given $\\ell$ heuristics for\nMetrical Task Systems (MTS), where each might be tailored to a different type\nof input instances. While processing an input instance received online, we are\nallowed to query the action of only one of the heuristics at each time step.\nOur goal is to achieve performance comparable to the best of the given\nheuristics. The main difficulty of our setting comes from the fact that the\ncost paid by a heuristic at time $t$ cannot be estimated unless the same\nheuristic was also queried at time $t-1$. This is related to Bandit Learning\nagainst memory bounded adversaries (Arora et al., 2012). We show how to achieve\nregret of $O(\\text{OPT}^{2/3})$ and prove a tight lower bound based on the\nconstruction of Dekel et al. (2013).", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728Metrical Task Systems\uff08MTS\uff09\u4e2d\uff0c\u7ed9\u5b9a\u591a\u4e2a\u542f\u53d1\u5f0f\u65b9\u6cd5\u65f6\uff0c\u5982\u4f55\u5728\u5728\u7ebf\u5904\u7406\u8f93\u5165\u5b9e\u4f8b\u65f6\u4ec5\u67e5\u8be2\u4e00\u4e2a\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u4ee5\u5b9e\u73b0\u4e0e\u6700\u4f73\u542f\u53d1\u5f0f\u65b9\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5728MTS\u4e2d\uff0c\u7531\u4e8e\u542f\u53d1\u5f0f\u65b9\u6cd5\u7684\u6210\u672c\u65e0\u6cd5\u76f4\u63a5\u4f30\u8ba1\uff0c\u5bfc\u81f4\u96be\u4ee5\u9009\u62e9\u6700\u4f73\u542f\u53d1\u5f0f\u65b9\u6cd5\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b9\u6cd5\uff0c\u901a\u8fc7\u9650\u5236\u6bcf\u6b65\u4ec5\u67e5\u8be2\u4e00\u4e2a\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u5e76\u5229\u7528Bandit Learning\u5bf9\u6297\u5185\u5b58\u53d7\u9650\u7684\u5bf9\u624b\u3002", "result": "\u5b9e\u73b0\u4e86$O(\\text{OPT}^{2/3})$\u7684\u9057\u61be\u503c\uff0c\u5e76\u57fa\u4e8eDekel\u7b49\u4eba\u7684\u6784\u9020\u8bc1\u660e\u4e86\u7d27\u4e0b\u754c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728MTS\u4e2d\u6709\u6548\u5b9e\u73b0\u4e86\u4e0e\u6700\u4f73\u542f\u53d1\u5f0f\u65b9\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u5e76\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u3002"}}
{"id": "2506.05484", "pdf": "https://arxiv.org/pdf/2506.05484", "abs": "https://arxiv.org/abs/2506.05484", "authors": ["Ruihua Chen", "Bangyu Wu", "Meng Li", "Kai Yang"], "title": "Initial Model Incorporation for Deep Learning FWI: Pretraining or Denormalization?", "categories": ["cs.LG", "physics.geo-ph"], "comment": null, "summary": "Subsurface property neural network reparameterized full waveform inversion\n(FWI) has emerged as an effective unsupervised learning framework, which can\ninvert stably with an inaccurate starting model. It updates the trainable\nneural network parameters instead of fine-tuning on the subsurface model\ndirectly. There are primarily two ways to embed the prior knowledge of the\ninitial model into neural networks, that is, pretraining and denormalization.\nPretraining first regulates the neural networks' parameters by fitting the\ninitial velocity model; Denormalization directly adds the outputs of the\nnetwork into the initial models without pretraining. In this letter, we\nsystematically investigate the influence of the two ways of initial model\nincorporation for the neural network reparameterized FWI. We demonstrate that\npretraining requires inverting the model perturbation based on a constant\nvelocity value (mean) with a two-stage implementation. It leads to a complex\nworkflow and inconsistency of objective functions in the two-stage process,\ncausing the network parameters to become inactive and lose plasticity.\nExperimental results demonstrate that denormalization can simplify workflows,\naccelerate convergence, and enhance inversion accuracy compared with\npretraining.", "AI": {"tldr": "\u8bba\u6587\u6bd4\u8f83\u4e86\u4e24\u79cd\u5c06\u521d\u59cb\u6a21\u578b\u77e5\u8bc6\u5d4c\u5165\u795e\u7ecf\u7f51\u7edc\u7684\u65b9\u6cd5\uff08\u9884\u8bad\u7ec3\u548c\u53bb\u5f52\u4e00\u5316\uff09\u5bf9\u5168\u6ce2\u5f62\u53cd\u6f14\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u53bb\u5f52\u4e00\u5316\u65b9\u6cd5\u66f4\u4f18\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u66f4\u6709\u6548\u5730\u5c06\u521d\u59cb\u6a21\u578b\u77e5\u8bc6\u5d4c\u5165\u795e\u7ecf\u7f51\u7edc\uff0c\u4ee5\u63d0\u5347\u5168\u6ce2\u5f62\u53cd\u6f14\u7684\u7a33\u5b9a\u6027\u548c\u51c6\u786e\u6027\u3002", "method": "\u901a\u8fc7\u9884\u8bad\u7ec3\u548c\u53bb\u5f52\u4e00\u5316\u4e24\u79cd\u65b9\u5f0f\u5d4c\u5165\u521d\u59cb\u6a21\u578b\u77e5\u8bc6\uff0c\u5e76\u6bd4\u8f83\u5176\u5bf9\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\u5316\u7684\u5168\u6ce2\u5f62\u53cd\u6f14\u7684\u5f71\u54cd\u3002", "result": "\u53bb\u5f52\u4e00\u5316\u65b9\u6cd5\u7b80\u5316\u4e86\u5de5\u4f5c\u6d41\u7a0b\uff0c\u52a0\u901f\u4e86\u6536\u655b\uff0c\u5e76\u63d0\u9ad8\u4e86\u53cd\u6f14\u7cbe\u5ea6\uff0c\u4f18\u4e8e\u9884\u8bad\u7ec3\u65b9\u6cd5\u3002", "conclusion": "\u53bb\u5f52\u4e00\u5316\u662f\u4e00\u79cd\u66f4\u4f18\u7684\u521d\u59cb\u6a21\u578b\u5d4c\u5165\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\u5316\u7684\u5168\u6ce2\u5f62\u53cd\u6f14\u3002"}}
{"id": "2506.05497", "pdf": "https://arxiv.org/pdf/2506.05497", "abs": "https://arxiv.org/abs/2506.05497", "authors": ["Sima Noorani", "Shayan Kiyani", "George Pappas", "Hamed Hassani"], "title": "Conformal Prediction Beyond the Seen: A Missing Mass Perspective for Uncertainty Quantification in Generative Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Uncertainty quantification (UQ) is essential for safe deployment of\ngenerative AI models such as large language models (LLMs), especially in high\nstakes applications. Conformal prediction (CP) offers a principled uncertainty\nquantification framework, but classical methods focus on regression and\nclassification, relying on geometric distances or softmax scores: tools that\npresuppose structured outputs. We depart from this paradigm by studying CP in a\nquery only setting, where prediction sets must be constructed solely from\nfinite queries to a black box generative model, introducing a new trade off\nbetween coverage, test time query budget, and informativeness. We introduce\nConformal Prediction with Query Oracle (CPQ), a framework characterizing the\noptimal interplay between these objectives. Our finite sample algorithm is\nbuilt on two core principles: one governs the optimal query policy, and the\nother defines the optimal mapping from queried samples to prediction sets.\nRemarkably, both are rooted in the classical missing mass problem in\nstatistics. Specifically, the optimal query policy depends on the rate of\ndecay, or the derivative, of the missing mass, for which we develop a novel\nestimator. Meanwhile, the optimal mapping hinges on the missing mass itself,\nwhich we estimate using Good Turing estimators. We then turn our focus to\nimplementing our method for language models, where outputs are vast, variable,\nand often under specified. Fine grained experiments on three real world open\nended tasks and two LLMs, show CPQ applicability to any black box LLM and\nhighlight: (1) individual contribution of each principle to CPQ performance,\nand (2) CPQ ability to yield significantly more informative prediction sets\nthan existing conformal methods for language uncertainty quantification.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCPQ\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u4ec5\u67e5\u8be2\u9ed1\u76d2\u751f\u6210\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u89e3\u51b3\u4e86\u8986\u76d6\u7387\u3001\u67e5\u8be2\u9884\u7b97\u548c\u4fe1\u606f\u91cf\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\u3002", "motivation": "\u751f\u6210\u5f0fAI\u6a21\u578b\uff08\u5982\u5927\u8bed\u8a00\u6a21\u578b\uff09\u5728\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\u9700\u8981\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\uff0c\u800c\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u7ed3\u6784\u5316\u8f93\u51fa\uff0c\u65e0\u6cd5\u76f4\u63a5\u9002\u7528\u4e8e\u751f\u6210\u5f0f\u6a21\u578b\u3002", "method": "\u57fa\u4e8e\u7edf\u8ba1\u4e2d\u7684\u7f3a\u5931\u8d28\u91cf\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u6838\u5fc3\u539f\u5219\uff1a\u6700\u4f18\u67e5\u8be2\u7b56\u7565\u548c\u6700\u4f18\u6620\u5c04\u65b9\u6cd5\uff0c\u5e76\u5f00\u53d1\u4e86\u65b0\u7684\u4f30\u8ba1\u5668\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cCPQ\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u9884\u6d4b\u96c6\u7684\u4fe1\u606f\u91cf\uff0c\u9002\u7528\u4e8e\u4efb\u4f55\u9ed1\u76d2\u5927\u8bed\u8a00\u6a21\u578b\u3002", "conclusion": "CPQ\u4e3a\u751f\u6210\u5f0f\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u4e14\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.05500", "pdf": "https://arxiv.org/pdf/2506.05500", "abs": "https://arxiv.org/abs/2506.05500", "authors": ["Alex Damian", "Jason D. Lee", "Joan Bruna"], "title": "The Generative Leap: Sharp Sample Complexity for Efficiently Learning Gaussian Multi-Index Models", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "In this work we consider generic Gaussian Multi-index models, in which the\nlabels only depend on the (Gaussian) $d$-dimensional inputs through their\nprojection onto a low-dimensional $r = O_d(1)$ subspace, and we study efficient\nagnostic estimation procedures for this hidden subspace. We introduce the\n\\emph{generative leap} exponent $k^\\star$, a natural extension of the\ngenerative exponent from [Damian et al.'24] to the multi-index setting. We\nfirst show that a sample complexity of $n=\\Theta(d^{1 \\vee \\k/2})$ is necessary\nin the class of algorithms captured by the Low-Degree-Polynomial framework. We\nthen establish that this sample complexity is also sufficient, by giving an\nagnostic sequential estimation procedure (that is, requiring no prior knowledge\nof the multi-index model) based on a spectral U-statistic over appropriate\nHermite tensors. We further compute the generative leap exponent for several\nexamples including piecewise linear functions (deep ReLU networks with bias),\nand general deep neural networks (with $r$-dimensional first hidden layer).", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u9ad8\u65af\u591a\u6307\u6570\u6a21\u578b\u7684\u9ad8\u6548\u65e0\u504f\u4f30\u8ba1\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u751f\u6210\u8df3\u8dc3\u6307\u6570k*\uff0c\u5e76\u8bc1\u660e\u4e86\u6837\u672c\u590d\u6742\u5ea6n=\u0398(d^(1\u2228k/2))\u7684\u5fc5\u8981\u6027\u548c\u5145\u5206\u6027\u3002", "motivation": "\u7814\u7a76\u9ad8\u65af\u591a\u6307\u6570\u6a21\u578b\u4e2d\u9690\u85cf\u5b50\u7a7a\u95f4\u7684\u9ad8\u6548\u65e0\u504f\u4f30\u8ba1\u65b9\u6cd5\uff0c\u6269\u5c55\u4e86\u751f\u6210\u6307\u6570\u7684\u6982\u5ff5\u3002", "method": "\u63d0\u51fa\u751f\u6210\u8df3\u8dc3\u6307\u6570k*\uff0c\u5e76\u901a\u8fc7\u57fa\u4e8eHermite\u5f20\u91cf\u7684\u8c31U\u7edf\u8ba1\u91cf\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65e0\u504f\u5e8f\u8d2f\u4f30\u8ba1\u65b9\u6cd5\u3002", "result": "\u8bc1\u660e\u4e86\u6837\u672c\u590d\u6742\u5ea6n=\u0398(d^(1\u2228k/2))\u7684\u5fc5\u8981\u6027\u548c\u5145\u5206\u6027\uff0c\u5e76\u8ba1\u7b97\u4e86\u751f\u6210\u8df3\u8dc3\u6307\u6570\u5728\u591a\u4e2a\u4f8b\u5b50\u4e2d\u7684\u503c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u9002\u7528\u4e8e\u9ad8\u65af\u591a\u6307\u6570\u6a21\u578b\uff0c\u4e3a\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7b49\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2506.05513", "pdf": "https://arxiv.org/pdf/2506.05513", "abs": "https://arxiv.org/abs/2506.05513", "authors": ["Yunfei Huang", "David S. Greenberg"], "title": "Geometric and Physical Constraints Synergistically Enhance Neural PDE Surrogates", "categories": ["cs.LG", "physics.flu-dyn"], "comment": null, "summary": "Neural PDE surrogates can improve the cost-accuracy tradeoff of classical\nsolvers, but often generalize poorly to new initial conditions and accumulate\nerrors over time. Physical and symmetry constraints have shown promise in\nclosing this performance gap, but existing techniques for imposing these\ninductive biases are incompatible with the staggered grids commonly used in\ncomputational fluid dynamics. Here we introduce novel input and output layers\nthat respect physical laws and symmetries on the staggered grids, and for the\nfirst time systematically investigate how these constraints, individually and\nin combination, affect the accuracy of PDE surrogates. We focus on two\nchallenging problems: shallow water equations with closed boundaries and\ndecaying incompressible turbulence. Compared to strong baselines, symmetries\nand physical constraints consistently improve performance across tasks,\narchitectures, autoregressive prediction steps, accuracy measures, and network\nsizes. Symmetries are more effective than physical constraints, but surrogates\nwith both performed best, even compared to baselines with data augmentation or\npushforward training, while themselves benefiting from the pushforward trick.\nDoubly-constrained surrogates also generalize better to initial conditions and\ndurations beyond the range of the training data, and more accurately predict\nreal-world ocean currents.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8f93\u5165\u548c\u8f93\u51fa\u5c42\u8bbe\u8ba1\uff0c\u7528\u4e8e\u5728\u4ea4\u9519\u7f51\u683c\u4e0a\u4fdd\u6301\u7269\u7406\u5b9a\u5f8b\u548c\u5bf9\u79f0\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86PDE\u4ee3\u7406\u6a21\u578b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u4ea4\u9519\u7f51\u683c\u4e0a\u96be\u4ee5\u65bd\u52a0\u7269\u7406\u548c\u5bf9\u79f0\u7ea6\u675f\uff0c\u5bfc\u81f4PDE\u4ee3\u7406\u6a21\u578b\u5728\u65b0\u521d\u59cb\u6761\u4ef6\u548c\u957f\u65f6\u95f4\u9884\u6d4b\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u8bbe\u8ba1\u4e86\u65b0\u9896\u7684\u8f93\u5165\u548c\u8f93\u51fa\u5c42\uff0c\u786e\u4fdd\u5728\u4ea4\u9519\u7f51\u683c\u4e0a\u6ee1\u8db3\u7269\u7406\u5b9a\u5f8b\u548c\u5bf9\u79f0\u6027\uff0c\u5e76\u7cfb\u7edf\u7814\u7a76\u4e86\u8fd9\u4e9b\u7ea6\u675f\u5bf9PDE\u4ee3\u7406\u6a21\u578b\u7684\u5f71\u54cd\u3002", "result": "\u5bf9\u79f0\u6027\u548c\u7269\u7406\u7ea6\u675f\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u5c24\u5176\u5728\u521d\u59cb\u6761\u4ef6\u548c\u957f\u65f6\u95f4\u9884\u6d4b\u7684\u6cdb\u5316\u80fd\u529b\u4e0a\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "\u7ed3\u5408\u5bf9\u79f0\u6027\u548c\u7269\u7406\u7ea6\u675f\u7684\u4ee3\u7406\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0c\u4f18\u4e8e\u6570\u636e\u589e\u5f3a\u548c\u63a8\u524d\u8bad\u7ec3\u7b49\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e14\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u4e2d\u66f4\u5177\u9884\u6d4b\u51c6\u786e\u6027\u3002"}}
{"id": "2506.05515", "pdf": "https://arxiv.org/pdf/2506.05515", "abs": "https://arxiv.org/abs/2506.05515", "authors": ["Adrien Cort\u00e9s", "R\u00e9mi Rehm", "Victor Letzelter"], "title": "Winner-takes-all for Multivariate Probabilistic Time Series Forecasting", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "ICML 2025", "summary": "We introduce TimeMCL, a method leveraging the Multiple Choice Learning (MCL)\nparadigm to forecast multiple plausible time series futures. Our approach\nemploys a neural network with multiple heads and utilizes the Winner-Takes-All\n(WTA) loss to promote diversity among predictions. MCL has recently gained\nattention due to its simplicity and ability to address ill-posed and ambiguous\ntasks. We propose an adaptation of this framework for time-series forecasting,\npresenting it as an efficient method to predict diverse futures, which we\nrelate to its implicit quantization objective. We provide insights into our\napproach using synthetic data and evaluate it on real-world time series,\ndemonstrating its promising performance at a light computational cost.", "AI": {"tldr": "TimeMCL\u662f\u4e00\u79cd\u57fa\u4e8e\u591a\u9009\u62e9\u5b66\u4e60\uff08MCL\uff09\u8303\u5f0f\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u9884\u6d4b\u65f6\u95f4\u5e8f\u5217\u7684\u591a\u79cd\u53ef\u80fd\u672a\u6765\u3002\u5b83\u901a\u8fc7\u591a\u5934\u90e8\u795e\u7ecf\u7f51\u7edc\u548cWinner-Takes-All\uff08WTA\uff09\u635f\u5931\u51fd\u6570\u63d0\u5347\u9884\u6d4b\u591a\u6837\u6027\uff0c\u5e76\u5728\u8ba1\u7b97\u6210\u672c\u8f83\u4f4e\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u5e38\u9762\u4e34\u6a21\u7cca\u6027\u548c\u4e0d\u786e\u5b9a\u6027\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u591a\u79cd\u53ef\u80fd\u7684\u672a\u6765\u3002MCL\u56e0\u5176\u7b80\u5355\u6027\u548c\u5904\u7406\u6a21\u7cca\u4efb\u52a1\u7684\u80fd\u529b\u53d7\u5230\u5173\u6ce8\uff0c\u56e0\u6b64\u4f5c\u8005\u5c06\u5176\u5e94\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u3002", "method": "\u91c7\u7528\u591a\u5934\u90e8\u795e\u7ecf\u7f51\u7edc\u548cWTA\u635f\u5931\u51fd\u6570\uff0c\u901a\u8fc7MCL\u6846\u67b6\u9884\u6d4b\u591a\u6837\u5316\u7684\u65f6\u95f4\u5e8f\u5217\u672a\u6765\uff0c\u5e76\u9690\u542b\u5730\u5b9e\u73b0\u91cf\u5316\u76ee\u6807\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u548c\u771f\u5b9e\u65f6\u95f4\u5e8f\u5217\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cTimeMCL\u80fd\u4ee5\u8f83\u4f4e\u8ba1\u7b97\u6210\u672c\u5b9e\u73b0\u591a\u6837\u4e14\u51c6\u786e\u7684\u9884\u6d4b\u3002", "conclusion": "TimeMCL\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u591a\u6837\u5316\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u6a21\u7cca\u6027\u4efb\u52a1\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.05526", "pdf": "https://arxiv.org/pdf/2506.05526", "abs": "https://arxiv.org/abs/2506.05526", "authors": ["Michal Klein", "Alireza Mousavi-Hosseini", "Stephen Zhang", "Marco Cuturi"], "title": "On Fitting Flow Models with Large Sinkhorn Couplings", "categories": ["cs.LG", "stat.ML"], "comment": "20 pages, 14 figures", "summary": "Flow models transform data gradually from one modality (e.g. noise) onto\nanother (e.g. images). Such models are parameterized by a time-dependent\nvelocity field, trained to fit segments connecting pairs of source and target\npoints. When the pairing between source and target points is given, training\nflow models boils down to a supervised regression problem. When no such pairing\nexists, as is the case when generating data from noise, training flows is much\nharder. A popular approach lies in picking source and target points\nindependently. This can, however, lead to velocity fields that are slow to\ntrain, but also costly to integrate at inference time. In theory, one would\ngreatly benefit from training flow models by sampling pairs from an optimal\ntransport (OT) measure coupling source and target, since this would lead to a\nhighly efficient flow solving the Benamou and Brenier dynamical OT problem. In\npractice, recent works have proposed to sample mini-batches of $n$ source and\n$n$ target points and reorder them using an OT solver to form better pairs.\nThese works have advocated using batches of size $n\\approx 256$, and considered\nOT solvers that return couplings that are either sharp (using e.g. the\nHungarian algorithm) or blurred (using e.g. entropic regularization, a.k.a.\nSinkhorn). We follow in the footsteps of these works by exploring the benefits\nof increasing $n$ by three to four orders of magnitude, and look more carefully\non the effect of the entropic regularization $\\varepsilon$ used in the Sinkhorn\nalgorithm. Our analysis is facilitated by new scale invariant quantities to\nreport the sharpness of a coupling, while our sharded computations across\nmultiple GPU or GPU nodes allow scaling up $n$. We show that in both synthetic\nand image generation tasks, flow models greatly benefit when fitted with large\nSinkhorn couplings, with a low entropic regularization $\\varepsilon$.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u901a\u8fc7\u589e\u52a0\u6279\u91cf\u5927\u5c0f\u548c\u4f18\u5316Sinkhorn\u7b97\u6cd5\u7684\u71b5\u6b63\u5219\u5316\u53c2\u6570\uff0c\u63d0\u5347\u6d41\u6a21\u578b\u5728\u6570\u636e\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u6548\u7387\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u5728\u6ca1\u6709\u6e90-\u76ee\u6807\u70b9\u914d\u5bf9\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7\u4f18\u5316\u4f20\u8f93\uff08OT\uff09\u65b9\u6cd5\u8bad\u7ec3\u6d41\u6a21\u578b\uff0c\u4ee5\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u548c\u63a8\u7406\u901f\u5ea6\u3002", "method": "\u91c7\u7528\u5927\u89c4\u6a21\u6279\u91cf\uff08n\u589e\u52a03-4\u4e2a\u6570\u91cf\u7ea7\uff09\u548cSinkhorn\u7b97\u6cd5\uff08\u4f4e\u71b5\u6b63\u5219\u5316\u53c2\u6570\u03b5\uff09\u4f18\u5316\u6d41\u6a21\u578b\u7684\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u5408\u6210\u548c\u56fe\u50cf\u751f\u6210\u4efb\u52a1\u4e2d\uff0c\u4f7f\u7528\u5927\u89c4\u6a21Sinkhorn\u8026\u5408\u548c\u4f4e\u71b5\u6b63\u5219\u5316\u663e\u8457\u63d0\u5347\u4e86\u6d41\u6a21\u578b\u7684\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u4f18\u5316\u6279\u91cf\u5927\u5c0f\u548c\u71b5\u6b63\u5219\u5316\u53c2\u6570\uff0c\u6d41\u6a21\u578b\u5728\u6570\u636e\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u9ad8\u6548\u3002"}}
{"id": "2506.05530", "pdf": "https://arxiv.org/pdf/2506.05530", "abs": "https://arxiv.org/abs/2506.05530", "authors": ["Snir Hordan", "Maya Bechler-Speicher", "Gur Lifshitz", "Nadav Dym"], "title": "Spectral Graph Neural Networks are Incomplete on Graphs with a Simple Spectrum", "categories": ["cs.LG"], "comment": "9 pages main text", "summary": "Spectral features are widely incorporated within Graph Neural Networks (GNNs)\nto improve their expressive power, or their ability to distinguish among\nnon-isomorphic graphs. One popular example is the usage of graph Laplacian\neigenvectors for positional encoding in MPNNs and Graph Transformers. The\nexpressive power of such Spectrally-enhanced GNNs (SGNNs) is usually evaluated\nvia the k-WL graph isomorphism test hierarchy and homomorphism counting. Yet,\nthese frameworks align poorly with the graph spectra, yielding limited insight\ninto SGNNs' expressive power. We leverage a well-studied paradigm of\nclassifying graphs by their largest eigenvalue multiplicity to introduce an\nexpressivity hierarchy for SGNNs. We then prove that many SGNNs are incomplete\neven on graphs with distinct eigenvalues. To mitigate this deficiency, we adapt\nrotation equivariant neural networks to the graph spectra setting to propose a\nmethod to provably improve SGNNs' expressivity on simple spectrum graphs. We\nempirically verify our theoretical claims via an image classification\nexperiment on the MNIST Superpixel dataset and eigenvector canonicalization on\ngraphs from ZINC.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u8c31\u7684SGNN\u8868\u8fbe\u80fd\u529b\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5e76\u8bc1\u660e\u4e86\u73b0\u6709SGNN\u5728\u7b80\u5355\u8c31\u56fe\u4e0a\u7684\u5c40\u9650\u6027\uff0c\u540c\u65f6\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30SGNN\u8868\u8fbe\u80fd\u529b\u7684\u6846\u67b6\uff08\u5982k-WL\u548c\u540c\u6001\u8ba1\u6570\uff09\u4e0e\u56fe\u8c31\u5173\u8054\u6027\u5dee\uff0c\u65e0\u6cd5\u6df1\u5165\u7406\u89e3SGNN\u7684\u8868\u8fbe\u80fd\u529b\u3002", "method": "\u5229\u7528\u56fe\u7684\u6700\u5927\u7279\u5f81\u503c\u591a\u91cd\u6027\u5206\u7c7b\u8303\u5f0f\uff0c\u63d0\u51faSGNN\u7684\u8868\u8fbe\u80fd\u529b\u5c42\u6b21\u7ed3\u6784\uff0c\u5e76\u57fa\u4e8e\u65cb\u8f6c\u7b49\u53d8\u795e\u7ecf\u7f51\u7edc\u63d0\u51fa\u6539\u8fdb\u65b9\u6cd5\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u8bb8\u591aSGNN\u5728\u7279\u5f81\u503c\u4e0d\u540c\u7684\u56fe\u4e0a\u4ecd\u4e0d\u5b8c\u5168\uff0c\u6539\u8fdb\u65b9\u6cd5\u5728\u7b80\u5355\u8c31\u56fe\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u8868\u8fbe\u80fd\u529b\u3002", "conclusion": "\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u679c\uff0c\u4e3aSGNN\u7684\u8868\u8fbe\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u7684\u8bc4\u4f30\u548c\u6539\u8fdb\u65b9\u5411\u3002"}}
{"id": "2506.05538", "pdf": "https://arxiv.org/pdf/2506.05538", "abs": "https://arxiv.org/abs/2506.05538", "authors": ["Arnesh Batra", "Anushk Kumar", "Jashn Khemani", "Arush Gumber", "Arhan Jain", "Somil Gupta"], "title": "SocialDF: Benchmark Dataset and Detection Model for Mitigating Harmful Deepfake Content on Social Media Platforms", "categories": ["cs.LG", "cs.MM"], "comment": null, "summary": "The rapid advancement of deep generative models has significantly improved\nthe realism of synthetic media, presenting both opportunities and security\nchallenges. While deepfake technology has valuable applications in\nentertainment and accessibility, it has emerged as a potent vector for\nmisinformation campaigns, particularly on social media. Existing detection\nframeworks struggle to distinguish between benign and adversarially generated\ndeepfakes engineered to manipulate public perception. To address this\nchallenge, we introduce SocialDF, a curated dataset reflecting real-world\ndeepfake challenges on social media platforms. This dataset encompasses\nhigh-fidelity deepfakes sourced from various online ecosystems, ensuring broad\ncoverage of manipulative techniques. We propose a novel LLM-based multi-factor\ndetection approach that combines facial recognition, automated speech\ntranscription, and a multi-agent LLM pipeline to cross-verify audio-visual\ncues. Our methodology emphasizes robust, multi-modal verification techniques\nthat incorporate linguistic, behavioral, and contextual analysis to effectively\ndiscern synthetic media from authentic content.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faSocialDF\u6570\u636e\u96c6\u548c\u57fa\u4e8eLLM\u7684\u591a\u56e0\u7d20\u68c0\u6d4b\u65b9\u6cd5\uff0c\u4ee5\u5e94\u5bf9\u793e\u4ea4\u5a92\u4f53\u4e0a\u6df1\u5ea6\u4f2a\u9020\u7684\u6311\u6218\u3002", "motivation": "\u6df1\u5ea6\u4f2a\u9020\u6280\u672f\u7684\u5feb\u901f\u53d1\u5c55\u5e26\u6765\u4e86\u5b89\u5168\u6311\u6218\uff0c\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u96be\u4ee5\u533a\u5206\u826f\u6027\u548c\u6076\u610f\u751f\u6210\u7684\u6df1\u5ea6\u4f2a\u9020\u5185\u5bb9\u3002", "method": "\u63d0\u51faSocialDF\u6570\u636e\u96c6\uff0c\u5e76\u8bbe\u8ba1\u57fa\u4e8eLLM\u7684\u591a\u56e0\u7d20\u68c0\u6d4b\u65b9\u6cd5\uff0c\u7ed3\u5408\u9762\u90e8\u8bc6\u522b\u3001\u8bed\u97f3\u8f6c\u5f55\u548c\u591a\u4ee3\u7406LLM\u7ba1\u9053\u8fdb\u884c\u4ea4\u53c9\u9a8c\u8bc1\u3002", "result": "\u65b9\u6cd5\u901a\u8fc7\u591a\u6a21\u6001\u9a8c\u8bc1\u6280\u672f\uff08\u8bed\u8a00\u3001\u884c\u4e3a\u548c\u4e0a\u4e0b\u6587\u5206\u6790\uff09\u6709\u6548\u533a\u5206\u5408\u6210\u5a92\u4f53\u4e0e\u771f\u5b9e\u5185\u5bb9\u3002", "conclusion": "SocialDF\u548cLLM\u591a\u56e0\u7d20\u68c0\u6d4b\u65b9\u6cd5\u4e3a\u89e3\u51b3\u793e\u4ea4\u5a92\u4f53\u4e0a\u7684\u6df1\u5ea6\u4f2a\u9020\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2506.05542", "pdf": "https://arxiv.org/pdf/2506.05542", "abs": "https://arxiv.org/abs/2506.05542", "authors": ["Vlastimil Martinek", "Andrea Gariboldi", "Dimosthenis Tzimotoudis", "Aitor Alberdi Escudero", "Edward Blake", "David Cechak", "Luke Cassar", "Alessandro Balestrucci", "Panagiotis Alexiou"], "title": "Agentomics-ML: Autonomous Machine Learning Experimentation Agent for Genomic and Transcriptomic Data", "categories": ["cs.LG", "cs.MA"], "comment": null, "summary": "The adoption of machine learning (ML) and deep learning methods has\nrevolutionized molecular medicine by driving breakthroughs in genomics,\ntranscriptomics, drug discovery, and biological systems modeling. The\nincreasing quantity, multimodality, and heterogeneity of biological datasets\ndemand automated methods that can produce generalizable predictive models.\nRecent developments in large language model-based agents have shown promise for\nautomating end-to-end ML experimentation on structured benchmarks. However,\nwhen applied to heterogeneous computational biology datasets, these methods\nstruggle with generalization and success rates. Here, we introduce\nAgentomics-ML, a fully autonomous agent-based system designed to produce a\nclassification model and the necessary files for reproducible training and\ninference. Our method follows predefined steps of an ML experimentation\nprocess, repeatedly interacting with the file system through Bash to complete\nindividual steps. Once an ML model is produced, training and validation metrics\nprovide scalar feedback to a reflection step to identify issues such as\noverfitting. This step then creates verbal feedback for future iterations,\nsuggesting adjustments to steps such as data representation, model\narchitecture, and hyperparameter choices. We have evaluated Agentomics-ML on\nseveral established genomic and transcriptomic benchmark datasets and show that\nit outperforms existing state-of-the-art agent-based methods in both\ngeneralization and success rates. While state-of-the-art models built by domain\nexperts still lead in absolute performance on the majority of the computational\nbiology datasets used in this work, Agentomics-ML narrows the gap for fully\nautonomous systems and achieves state-of-the-art performance on one of the used\nbenchmark datasets. The code is available at\nhttps://github.com/BioGeMT/Agentomics-ML.", "AI": {"tldr": "Agentomics-ML\u662f\u4e00\u4e2a\u5168\u81ea\u4e3b\u7684\u57fa\u4e8e\u4ee3\u7406\u7684\u7cfb\u7edf\uff0c\u7528\u4e8e\u751f\u6210\u5206\u7c7b\u6a21\u578b\u548c\u53ef\u91cd\u590d\u8bad\u7ec3\u4e0e\u63a8\u7406\u7684\u6587\u4ef6\uff0c\u5728\u8ba1\u7b97\u751f\u7269\u5b66\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u751f\u7269\u6570\u636e\u96c6\u7684\u590d\u6742\u6027\u8981\u6c42\u81ea\u52a8\u5316\u65b9\u6cd5\u751f\u6210\u901a\u7528\u9884\u6d4b\u6a21\u578b\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u5f02\u6784\u6570\u636e\u96c6\u4e0a\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u3002", "method": "\u7cfb\u7edf\u901a\u8fc7Bash\u4e0e\u6587\u4ef6\u7cfb\u7edf\u4ea4\u4e92\uff0c\u9075\u5faaML\u5b9e\u9a8c\u6b65\u9aa4\uff0c\u901a\u8fc7\u53cd\u9988\u8c03\u6574\u6570\u636e\u8868\u793a\u3001\u6a21\u578b\u67b6\u6784\u548c\u8d85\u53c2\u6570\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cAgentomics-ML\u5728\u6cdb\u5316\u80fd\u529b\u548c\u6210\u529f\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5728\u4e00\u4e2a\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u6700\u4f18\u6027\u80fd\u3002", "conclusion": "Agentomics-ML\u7f29\u5c0f\u4e86\u5168\u81ea\u4e3b\u7cfb\u7edf\u4e0e\u4e13\u5bb6\u6784\u5efa\u6a21\u578b\u7684\u5dee\u8ddd\uff0c\u4e3a\u8ba1\u7b97\u751f\u7269\u5b66\u63d0\u4f9b\u4e86\u9ad8\u6548\u5de5\u5177\u3002"}}
{"id": "2506.05568", "pdf": "https://arxiv.org/pdf/2506.05568", "abs": "https://arxiv.org/abs/2506.05568", "authors": ["Arian Raje", "Baris Askin", "Divyansh Jhunjhunwala", "Gauri Joshi"], "title": "Ravan: Multi-Head Low-Rank Adaptation for Federated Fine-Tuning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have not yet effectively leveraged the vast\namounts of edge-device data, and federated learning (FL) offers a promising\nparadigm to collaboratively fine-tune LLMs without transferring private edge\ndata to the cloud. To operate within the computation and communication\nconstraints of edge devices, recent literature on federated fine-tuning of LLMs\nproposes the use of low-rank adaptation (LoRA) and similar parameter-efficient\nmethods. However, LoRA-based methods suffer from accuracy degradation in FL\nsettings, primarily because of data and computational heterogeneity across\nclients. We propose \\textsc{Ravan}, an adaptive multi-head LoRA method that\nbalances parameter efficiency and model expressivity by reparameterizing the\nweight updates as the sum of multiple LoRA heads\n$s_i\\textbf{B}_i\\textbf{H}_i\\textbf{A}_i$ in which only the core matrices\n$\\textbf{H}_i$ and their lightweight scaling factors $s_i$ are trained. These\ntrainable scaling factors let the optimization focus on the most useful heads,\nrecovering a higher-rank approximation of the full update without increasing\nthe number of communicated parameters since clients upload $s_i\\textbf{H}_i$\ndirectly. Experiments on vision and language benchmarks show that\n\\textsc{Ravan} improves test accuracy by 2-8\\% over prior parameter-efficient\nbaselines, making it a robust and scalable solution for federated fine-tuning\nof LLMs.", "AI": {"tldr": "\u63d0\u51fa\u4e86Ravan\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u5934LoRA\u81ea\u9002\u5e94\u8c03\u6574\u53c2\u6570\uff0c\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u4e2d\u6570\u636e\u5f02\u6784\u6027\u95ee\u9898\uff0c\u63d0\u5347LLMs\u7684\u5fae\u8c03\u6548\u679c\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709LoRA\u65b9\u6cd5\u5728\u8054\u90a6\u5b66\u4e60\u4e2d\u56e0\u6570\u636e\u548c\u8ba1\u7b97\u5f02\u6784\u6027\u5bfc\u81f4\u7684\u7cbe\u5ea6\u4e0b\u964d\u95ee\u9898\u3002", "method": "\u63d0\u51faRavan\u65b9\u6cd5\uff0c\u5c06\u6743\u91cd\u66f4\u65b0\u91cd\u65b0\u53c2\u6570\u5316\u4e3a\u591a\u4e2aLoRA\u5934\u7684\u52a0\u6743\u548c\uff0c\u4ec5\u8bad\u7ec3\u6838\u5fc3\u77e9\u9635\u548c\u8f7b\u91cf\u7ea7\u7f29\u653e\u56e0\u5b50\u3002", "result": "\u5728\u89c6\u89c9\u548c\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRavan\u6bd4\u73b0\u6709\u53c2\u6570\u9ad8\u6548\u65b9\u6cd5\u63d0\u5347\u4e862-8%\u7684\u6d4b\u8bd5\u51c6\u786e\u7387\u3002", "conclusion": "Ravan\u662f\u4e00\u79cd\u9c81\u68d2\u4e14\u53ef\u6269\u5c55\u7684\u8054\u90a6\u5b66\u4e60LLMs\u5fae\u8c03\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.05574", "pdf": "https://arxiv.org/pdf/2506.05574", "abs": "https://arxiv.org/abs/2506.05574", "authors": ["Chase Goddard", "Lindsay M. Smith", "Vudtiwat Ngampruetikorn", "David J. Schwab"], "title": "When can in-context learning generalize out of task distribution?", "categories": ["cs.LG", "cond-mat.dis-nn", "cond-mat.stat-mech", "q-bio.NC", "stat.ML"], "comment": null, "summary": "In-context learning (ICL) is a remarkable capability of pretrained\ntransformers that allows models to generalize to unseen tasks after seeing only\na few examples. We investigate empirically the conditions necessary on the\npretraining distribution for ICL to emerge and generalize\n\\emph{out-of-distribution}. Previous work has focused on the number of distinct\ntasks necessary in the pretraining dataset. Here, we use a different notion of\ntask diversity to study the emergence of ICL in transformers trained on linear\nfunctions. We find that as task diversity increases, transformers undergo a\ntransition from a specialized solution, which exhibits ICL only within the\npretraining task distribution, to a solution which generalizes out of\ndistribution to the entire task space. We also investigate the nature of the\nsolutions learned by the transformer on both sides of the transition, and\nobserve similar transitions in nonlinear regression problems. We construct a\nphase diagram to characterize how our concept of task diversity interacts with\nthe number of pretraining tasks. In addition, we explore how factors such as\nthe depth of the model and the dimensionality of the regression problem\ninfluence the transition.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u9884\u8bad\u7ec3\u5206\u5e03\u5bf9\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\u80fd\u529b\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u4efb\u52a1\u591a\u6837\u6027\u589e\u52a0\u65f6\uff0c\u6a21\u578b\u4f1a\u4ece\u4ec5\u9002\u7528\u4e8e\u9884\u8bad\u7ec3\u4efb\u52a1\u7684\u89e3\u51b3\u65b9\u6848\u8fc7\u6e21\u5230\u6cdb\u5316\u5230\u6574\u4e2a\u4efb\u52a1\u7a7a\u95f4\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u63a2\u7d22\u9884\u8bad\u7ec3\u5206\u5e03\u4e2d\u4efb\u52a1\u591a\u6837\u6027\u5bf9ICL\u80fd\u529b\u7684\u5f71\u54cd\uff0c\u4ee5\u53ca\u6a21\u578b\u5728\u4e0d\u540c\u4efb\u52a1\u591a\u6837\u6027\u4e0b\u7684\u8868\u73b0\u3002", "method": "\u4f7f\u7528\u7ebf\u6027\u51fd\u6570\u8bad\u7ec3\u7684\u53d8\u6362\u5668\uff0c\u7814\u7a76\u4efb\u52a1\u591a\u6837\u6027\u5bf9ICL\u80fd\u529b\u7684\u5f71\u54cd\uff0c\u5e76\u6784\u5efa\u76f8\u56fe\u5206\u6790\u6a21\u578b\u884c\u4e3a\u3002", "result": "\u4efb\u52a1\u591a\u6837\u6027\u589e\u52a0\u65f6\uff0c\u6a21\u578b\u4ece\u4ec5\u9002\u7528\u4e8e\u9884\u8bad\u7ec3\u4efb\u52a1\u7684\u89e3\u51b3\u65b9\u6848\u8fc7\u6e21\u5230\u6cdb\u5316\u5230\u6574\u4e2a\u4efb\u52a1\u7a7a\u95f4\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u4efb\u52a1\u591a\u6837\u6027\u662fICL\u80fd\u529b\u6cdb\u5316\u7684\u5173\u952e\u56e0\u7d20\uff0c\u6a21\u578b\u6df1\u5ea6\u548c\u95ee\u9898\u7ef4\u5ea6\u4e5f\u4f1a\u5f71\u54cd\u8fd9\u4e00\u8fc7\u6e21\u3002"}}
{"id": "2506.05577", "pdf": "https://arxiv.org/pdf/2506.05577", "abs": "https://arxiv.org/abs/2506.05577", "authors": ["Saptarshi Nath", "Christos Peridis", "Eseoghene Benjamin", "Xinran Liu", "Soheil Kolouri", "Peter Kinnell", "Zexin Li", "Cong Liu", "Shirin Dora", "Andrea Soltoggio"], "title": "Collaborative Learning in Agentic Systems: A Collective AI is Greater Than the Sum of Its Parts", "categories": ["cs.LG", "cs.AI", "cs.MA", "I.2.6; I.2.11"], "comment": "36 pages, 21 figures, 6 tables. Preprint", "summary": "Agentic AI has gained significant interest as a research paradigm focused on\nautonomy, self-directed learning, and long-term reliability of decision making.\nReal-world agentic systems operate in decentralized settings on a large set of\ntasks or data distributions with constraints such as limited bandwidth,\nasynchronous execution, and the absence of a centralized model or even common\nobjectives. We posit that exploiting previously learned skills, task\nsimilarities, and communication capabilities in a collective of agentic AI are\nchallenging but essential elements to enabling scalability, open-endedness, and\nbeneficial collaborative learning dynamics. In this paper, we introduce Modular\nSharing and Composition in Collective Learning (MOSAIC), an agentic algorithm\nthat allows multiple agents to independently solve different tasks while also\nidentifying, sharing, and reusing useful machine-learned knowledge, without\ncoordination, synchronization, or centralized control. MOSAIC combines three\nmechanisms: (1) modular policy composition via neural network masks, (2) cosine\nsimilarity estimation using Wasserstein embeddings for knowledge selection, and\n(3) asynchronous communication and policy integration. Results on a set of RL\nbenchmarks show that MOSAIC has a greater sample efficiency than isolated\nlearners, i.e., it learns significantly faster, and in some cases, finds\nsolutions to tasks that cannot be solved by isolated learners. The\ncollaborative learning and sharing dynamics are also observed to result in the\nemergence of ideal curricula of tasks, from easy to hard. These findings\nsupport the case for collaborative learning in agentic systems to achieve\nbetter and continuously evolving performance both at the individual and\ncollective levels.", "AI": {"tldr": "MOSAIC\u662f\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u7b97\u6cd5\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u5171\u4eab\u548c\u7ec4\u5408\u5b66\u4e60\uff0c\u5b9e\u73b0\u65e0\u534f\u8c03\u3001\u5f02\u6b65\u7684\u77e5\u8bc6\u5171\u4eab\u4e0e\u91cd\u7528\uff0c\u63d0\u9ad8\u6837\u672c\u6548\u7387\u5e76\u89e3\u51b3\u5b64\u7acb\u5b66\u4e60\u8005\u65e0\u6cd5\u5b8c\u6210\u7684\u4efb\u52a1\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u5728\u53bb\u4e2d\u5fc3\u5316\u73af\u5883\u4e2d\u5b9e\u73b0\u667a\u80fd\u4f53\u7684\u81ea\u4e3b\u5b66\u4e60\u548c\u534f\u4f5c\uff0c\u4ee5\u89e3\u51b3\u5e26\u5bbd\u9650\u5236\u3001\u5f02\u6b65\u6267\u884c\u548c\u7f3a\u4e4f\u96c6\u4e2d\u63a7\u5236\u7b49\u95ee\u9898\u3002", "method": "\u7ed3\u5408\u6a21\u5757\u5316\u7b56\u7565\u7ec4\u5408\u3001Wasserstein\u5d4c\u5165\u7684\u4f59\u5f26\u76f8\u4f3c\u6027\u4f30\u8ba1\u548c\u5f02\u6b65\u901a\u4fe1\u4e0e\u7b56\u7565\u96c6\u6210\u3002", "result": "MOSAIC\u5728RL\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u6837\u672c\u6548\u7387\uff0c\u80fd\u89e3\u51b3\u5b64\u7acb\u5b66\u4e60\u8005\u65e0\u6cd5\u5b8c\u6210\u7684\u4efb\u52a1\uff0c\u5e76\u89c2\u5bdf\u5230\u4efb\u52a1\u7406\u60f3\u8bfe\u7a0b\u7684\u51fa\u73b0\u3002", "conclusion": "\u534f\u4f5c\u5b66\u4e60\u5728\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u80fd\u5b9e\u73b0\u4e2a\u4f53\u548c\u96c6\u4f53\u6027\u80fd\u7684\u6301\u7eed\u63d0\u5347\u3002"}}
{"id": "2506.05583", "pdf": "https://arxiv.org/pdf/2506.05583", "abs": "https://arxiv.org/abs/2506.05583", "authors": ["Nien-Shao Wang", "Duygu Nur Yaldiz", "Yavuz Faruk Bakman", "Sai Praneeth Karimireddy"], "title": "Conformal Prediction Adaptive to Unknown Subpopulation Shifts", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "20 pages, 6 figures, 5 tables, submitted to NeurIPS 2025", "summary": "Conformal prediction is widely used to equip black-box machine learning\nmodels with uncertainty quantification enjoying formal coverage guarantees.\nHowever, these guarantees typically break down in the presence of distribution\nshifts, where the data distribution at test time differs from the training (or\ncalibration-time) distribution. In this work, we address subpopulation shifts,\nwhere the test environment exhibits an unknown and differing mixture of\nsubpopulations compared to the calibration data. We propose new methods that\nprovably adapt conformal prediction to such shifts, ensuring valid coverage\nwithout requiring explicit knowledge of subpopulation structure. Our algorithms\nscale to high-dimensional settings and perform effectively in realistic machine\nlearning tasks. Extensive experiments on vision (with vision transformers) and\nlanguage (with large language models) benchmarks demonstrate that our methods\nreliably maintain coverage and controls risk in scenarios where standard\nconformal prediction fails.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65b0\u65b9\u6cd5\uff0c\u89e3\u51b3\u5206\u5e03\u504f\u79fb\u4e0b\u4fdd\u5f62\u9884\u6d4b\u7684\u8986\u76d6\u95ee\u9898\uff0c\u786e\u4fdd\u6709\u6548\u8986\u76d6\u4e14\u65e0\u9700\u5b50\u7fa4\u7ed3\u6784\u77e5\u8bc6\u3002", "motivation": "\u4fdd\u5f62\u9884\u6d4b\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u8986\u76d6\u4fdd\u8bc1\u5931\u6548\uff0c\u5c24\u5176\u662f\u5b50\u7fa4\u504f\u79fb\u65f6\uff0c\u6d4b\u8bd5\u6570\u636e\u4e0e\u6821\u51c6\u6570\u636e\u5206\u5e03\u4e0d\u540c\u3002", "method": "\u63d0\u51fa\u65b0\u7b97\u6cd5\uff0c\u9002\u5e94\u5b50\u7fa4\u504f\u79fb\uff0c\u786e\u4fdd\u8986\u76d6\u6709\u6548\u6027\uff0c\u9002\u7528\u4e8e\u9ad8\u7ef4\u573a\u666f\u3002", "result": "\u5728\u89c6\u89c9\u548c\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u65b0\u65b9\u6cd5\u5728\u6807\u51c6\u4fdd\u5f62\u9884\u6d4b\u5931\u6548\u65f6\u4ecd\u4fdd\u6301\u8986\u76d6\u548c\u98ce\u9669\u63a7\u5236\u3002", "conclusion": "\u65b0\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u5b50\u7fa4\u504f\u79fb\u4e0b\u7684\u4fdd\u5f62\u9884\u6d4b\u95ee\u9898\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2506.05584", "pdf": "https://arxiv.org/pdf/2506.05584", "abs": "https://arxiv.org/abs/2506.05584", "authors": ["Yuchen Zeng", "Tuan Dinh", "Wonjun Kang", "Andreas C Mueller"], "title": "TabFlex: Scaling Tabular Learning to Millions with Linear Attention", "categories": ["cs.LG"], "comment": "30 pages, ICML 2025", "summary": "Leveraging the in-context learning (ICL) capability of Large Language Models\n(LLMs) for tabular classification has gained significant attention for its\ntraining-free adaptability across diverse datasets. Recent advancements, like\nTabPFN, excel in small-scale tabular datasets but struggle to scale for large\nand complex datasets. Our work enhances the efficiency and scalability of\nTabPFN for larger datasets by incorporating linear attention mechanisms as a\nscalable alternative to complexity-quadratic self-attention. Our model,\nTabFlex, efficiently handles tabular datasets with thousands of features and\nhundreds of classes, scaling seamlessly to millions of samples. For instance,\nTabFlex processes the poker-hand dataset with over a million samples in just 5\nseconds. Our extensive evaluations demonstrate that TabFlex can achieve over a\n2x speedup compared to TabPFN and a 1.5x speedup over XGBoost, outperforming 25\ntested baselines in terms of efficiency across a diverse range of datasets.\nFurthermore, TabFlex remains highly effective on large-scale datasets,\ndelivering strong performance with significantly reduced computational costs,\nespecially when combined with data-efficient techniques such as dimensionality\nreduction and data sampling.", "AI": {"tldr": "TabFlex\u901a\u8fc7\u5f15\u5165\u7ebf\u6027\u6ce8\u610f\u529b\u673a\u5236\u63d0\u5347TabPFN\u7684\u6548\u7387\u4e0e\u6269\u5c55\u6027\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u8868\u683c\u6570\u636e\u96c6\uff0c\u6027\u80fd\u4f18\u4e8e25\u79cd\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5982TabPFN\u5728\u5c0f\u89c4\u6a21\u8868\u683c\u6570\u636e\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u96be\u4ee5\u6269\u5c55\u5230\u5927\u89c4\u6a21\u590d\u6742\u6570\u636e\u96c6\u3002", "method": "\u91c7\u7528\u7ebf\u6027\u6ce8\u610f\u529b\u673a\u5236\u66ff\u4ee3\u590d\u6742\u5ea6\u4e8c\u6b21\u7684\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff0c\u63d0\u5347\u6a21\u578b\u6548\u7387\u4e0e\u6269\u5c55\u6027\u3002", "result": "TabFlex\u5728\u5904\u7406\u767e\u4e07\u7ea7\u6837\u672c\u65f6\u4ec5\u97005\u79d2\uff0c\u901f\u5ea6\u6bd4TabPFN\u5feb2\u500d\uff0c\u6bd4XGBoost\u5feb1.5\u500d\u3002", "conclusion": "TabFlex\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u9ad8\u6548\u4e14\u6027\u80fd\u4f18\u5f02\uff0c\u7ed3\u5408\u964d\u7ef4\u548c\u91c7\u6837\u6280\u672f\u53ef\u8fdb\u4e00\u6b65\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2506.05586", "pdf": "https://arxiv.org/pdf/2506.05586", "abs": "https://arxiv.org/abs/2506.05586", "authors": ["Isha Puri", "Amit Dhurandhar", "Tejaswini Pedapati", "Kartikeyan Shanmugam", "Dennis Wei", "Kush R. Varshney"], "title": "CoFrNets: Interpretable Neural Architecture Inspired by Continued Fractions", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In recent years there has been a considerable amount of research on local\npost hoc explanations for neural networks. However, work on building\ninterpretable neural architectures has been relatively sparse. In this paper,\nwe present a novel neural architecture, CoFrNet, inspired by the form of\ncontinued fractions which are known to have many attractive properties in\nnumber theory, such as fast convergence of approximations to real numbers. We\nshow that CoFrNets can be efficiently trained as well as interpreted leveraging\ntheir particular functional form. Moreover, we prove that such architectures\nare universal approximators based on a proof strategy that is different than\nthe typical strategy used to prove universal approximation results for neural\nnetworks based on infinite width (or depth), which is likely to be of\nindependent interest. We experiment on nonlinear synthetic functions and are\nable to accurately model as well as estimate feature attributions and even\nhigher order terms in some cases, which is a testament to the representational\npower as well as interpretability of such architectures. To further showcase\nthe power of CoFrNets, we experiment on seven real datasets spanning tabular,\ntext and image modalities, and show that they are either comparable or\nsignificantly better than other interpretable models and multilayer\nperceptrons, sometimes approaching the accuracies of state-of-the-art models.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u795e\u7ecf\u7f51\u7edc\u67b6\u6784CoFrNet\uff0c\u53d7\u8fde\u5206\u6570\u542f\u53d1\uff0c\u5177\u6709\u9ad8\u6548\u8bad\u7ec3\u548c\u89e3\u91ca\u6027\uff0c\u5e76\u5728\u7406\u8bba\u548c\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u8fd1\u5e74\u6765\uff0c\u5c40\u90e8\u4e8b\u540e\u89e3\u91ca\u795e\u7ecf\u7f51\u7edc\u7684\u7814\u7a76\u8f83\u591a\uff0c\u4f46\u6784\u5efa\u53ef\u89e3\u91ca\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u7684\u5de5\u4f5c\u8f83\u5c11\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u8fde\u5206\u6570\u7684CoFrNet\u67b6\u6784\uff0c\u5229\u7528\u5176\u7279\u6b8a\u51fd\u6570\u5f62\u5f0f\u5b9e\u73b0\u9ad8\u6548\u8bad\u7ec3\u548c\u89e3\u91ca\uff0c\u5e76\u8bc1\u660e\u5176\u901a\u7528\u903c\u8fd1\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cCoFrNet\u5728\u5408\u6210\u51fd\u6570\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u63a5\u8fd1\u6216\u8d85\u8d8a\u5176\u4ed6\u53ef\u89e3\u91ca\u6a21\u578b\u53ca\u591a\u5c42\u611f\u77e5\u673a\u3002", "conclusion": "CoFrNet\u517c\u5177\u5f3a\u5927\u8868\u793a\u80fd\u529b\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u6784\u5efa\u9ad8\u6548\u4e14\u900f\u660e\u7684\u795e\u7ecf\u7f51\u7edc\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.05596", "pdf": "https://arxiv.org/pdf/2506.05596", "abs": "https://arxiv.org/abs/2506.05596", "authors": ["Jes Frellsen", "Maher M. Kassem", "Tone Bengtsen", "Lars Olsen", "Kresten Lindorff-Larsen", "Jesper Ferkinghoff-Borg", "Wouter Boomsma"], "title": "Zero-shot protein stability prediction by inverse folding models: a free energy interpretation", "categories": ["cs.LG", "cs.AI", "q-bio.BM", "stat.ML"], "comment": null, "summary": "Inverse folding models have proven to be highly effective zero-shot\npredictors of protein stability. Despite this success, the link between the\namino acid preferences of an inverse folding model and the free-energy\nconsiderations underlying thermodynamic stability remains incompletely\nunderstood. A better understanding would be of interest not only from a\ntheoretical perspective, but also potentially provide the basis for stronger\nzero-shot stability prediction. In this paper, we take steps to clarify the\nfree-energy foundations of inverse folding models. Our derivation reveals the\nstandard practice of likelihood ratios as a simplistic approximation and\nsuggests several paths towards better estimates of the relative stability. We\nempirically assess these approaches and demonstrate that considerable gains in\nzero-shot performance can be achieved with fairly simple means.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u9006\u6298\u53e0\u6a21\u578b\u4e0e\u86cb\u767d\u8d28\u7a33\u5b9a\u6027\u4e4b\u95f4\u7684\u81ea\u7531\u80fd\u57fa\u7840\u5173\u7cfb\uff0c\u63d0\u51fa\u4e86\u6539\u8fdb\u96f6-shot\u7a33\u5b9a\u6027\u9884\u6d4b\u7684\u65b9\u6cd5\u3002", "motivation": "\u7406\u89e3\u9006\u6298\u53e0\u6a21\u578b\u7684\u6c28\u57fa\u9178\u504f\u597d\u4e0e\u70ed\u529b\u5b66\u7a33\u5b9a\u6027\u4e4b\u95f4\u7684\u81ea\u7531\u80fd\u5173\u7cfb\uff0c\u4ee5\u63d0\u5347\u96f6-shot\u7a33\u5b9a\u6027\u9884\u6d4b\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u63a8\u5bfc\u63ed\u793a\u4e86\u4f3c\u7136\u6bd4\u6807\u51c6\u7684\u7b80\u5316\u8fd1\u4f3c\uff0c\u5e76\u63d0\u51fa\u6539\u8fdb\u76f8\u5bf9\u7a33\u5b9a\u6027\u4f30\u8ba1\u7684\u65b9\u6cd5\uff0c\u968f\u540e\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u7b80\u5355\u65b9\u6cd5\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u96f6-shot\u6027\u80fd\u3002", "conclusion": "\u672c\u6587\u4e3a\u9006\u6298\u53e0\u6a21\u578b\u7684\u81ea\u7531\u80fd\u57fa\u7840\u63d0\u4f9b\u4e86\u66f4\u6e05\u6670\u7684\u7406\u89e3\uff0c\u5e76\u5c55\u793a\u4e86\u6539\u8fdb\u96f6-shot\u7a33\u5b9a\u6027\u9884\u6d4b\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.05597", "pdf": "https://arxiv.org/pdf/2506.05597", "abs": "https://arxiv.org/abs/2506.05597", "authors": ["Yash Vijay", "Harini Subramanyan"], "title": "FaCTR: Factorized Channel-Temporal Representation Transformers for Efficient Time Series Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "While Transformers excel in language and vision-where inputs are semantically\nrich and exhibit univariate dependency structures-their architectural\ncomplexity leads to diminishing returns in time series forecasting. Time series\ndata is characterized by low per-timestep information density and complex\ndependencies across channels and covariates, requiring conditioning on\nstructured variable interactions. To address this mismatch and\noverparameterization, we propose FaCTR, a lightweight spatiotemporal\nTransformer with an explicitly structural design. FaCTR injects dynamic,\nsymmetric cross-channel interactions-modeled via a low-rank Factorization\nMachine into temporally contextualized patch embeddings through a learnable\ngating mechanism. It further encodes static and dynamic covariates for\nmultivariate conditioning. Despite its compact design, FaCTR achieves\nstate-of-the-art performance on eleven public forecasting benchmarks spanning\nboth short-term and long-term horizons, with its largest variant using close to\nonly 400K parameters-on average 50x smaller than competitive spatiotemporal\ntransformer baselines. In addition, its structured design enables\ninterpretability through cross-channel influence scores-an essential\nrequirement for real-world decision-making. Finally, FaCTR supports\nself-supervised pretraining, positioning it as a compact yet versatile\nfoundation for downstream time series tasks.", "AI": {"tldr": "FaCTR\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u65f6\u7a7aTransformer\uff0c\u901a\u8fc7\u4f4e\u79e9\u56e0\u5b50\u5206\u89e3\u673a\u548c\u53ef\u5b66\u4e60\u95e8\u63a7\u673a\u5236\u4f18\u5316\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u4e14\u53c2\u6570\u66f4\u5c11\u3002", "motivation": "Transformer\u5728\u8bed\u8a00\u548c\u89c6\u89c9\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u56e0\u6570\u636e\u4fe1\u606f\u5bc6\u5ea6\u4f4e\u548c\u590d\u6742\u4f9d\u8d56\u5173\u7cfb\u800c\u6548\u679c\u4e0d\u4f73\u3002", "method": "FaCTR\u901a\u8fc7\u52a8\u6001\u5bf9\u79f0\u8de8\u901a\u9053\u4ea4\u4e92\u548c\u4f4e\u79e9\u56e0\u5b50\u5206\u89e3\u673a\u8bbe\u8ba1\uff0c\u7ed3\u5408\u9759\u6001\u548c\u52a8\u6001\u534f\u53d8\u91cf\u7f16\u7801\uff0c\u5b9e\u73b0\u9ad8\u6548\u9884\u6d4b\u3002", "result": "\u572811\u4e2a\u516c\u5171\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u6700\u4f18\uff0c\u53c2\u6570\u89c4\u6a21\u4ec5\u4e3a\u7ade\u4e89\u65b9\u6cd5\u76841/50\uff0c\u4e14\u652f\u6301\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "FaCTR\u662f\u4e00\u79cd\u7d27\u51d1\u4e14\u591a\u529f\u80fd\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u57fa\u7840\u6a21\u578b\uff0c\u652f\u6301\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u3002"}}
{"id": "2506.05615", "pdf": "https://arxiv.org/pdf/2506.05615", "abs": "https://arxiv.org/abs/2506.05615", "authors": ["Ruipeng Zhang", "Ya-Chien Chang", "Sicun Gao"], "title": "When Maximum Entropy Misleads Policy Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The Maximum Entropy Reinforcement Learning (MaxEnt RL) framework is a leading\napproach for achieving efficient learning and robust performance across many RL\ntasks. However, MaxEnt methods have also been shown to struggle with\nperformance-critical control problems in practice, where non-MaxEnt algorithms\ncan successfully learn. In this work, we analyze how the trade-off between\nrobustness and optimality affects the performance of MaxEnt algorithms in\ncomplex control tasks: while entropy maximization enhances exploration and\nrobustness, it can also mislead policy optimization, leading to failure in\ntasks that require precise, low-entropy policies. Through experiments on a\nvariety of control problems, we concretely demonstrate this misleading effect.\nOur analysis leads to better understanding of how to balance reward design and\nentropy maximization in challenging control problems.", "AI": {"tldr": "MaxEnt RL\u6846\u67b6\u5728\u590d\u6742\u63a7\u5236\u4efb\u52a1\u4e2d\u9762\u4e34\u9c81\u68d2\u6027\u4e0e\u6700\u4f18\u6027\u7684\u6743\u8861\u95ee\u9898\uff0c\u71b5\u6700\u5927\u5316\u53ef\u80fd\u8bef\u5bfc\u7b56\u7565\u4f18\u5316\u3002", "motivation": "\u5206\u6790MaxEnt RL\u5728\u6027\u80fd\u5173\u952e\u63a7\u5236\u95ee\u9898\u4e2d\u7684\u8868\u73b0\uff0c\u63a2\u7a76\u5176\u9c81\u68d2\u6027\u4e0e\u6700\u4f18\u6027\u7684\u6743\u8861\u3002", "method": "\u901a\u8fc7\u591a\u79cd\u63a7\u5236\u95ee\u9898\u7684\u5b9e\u9a8c\uff0c\u5c55\u793a\u71b5\u6700\u5927\u5316\u5bf9\u7b56\u7565\u4f18\u5316\u7684\u8bef\u5bfc\u6548\u5e94\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u71b5\u6700\u5927\u5316\u53ef\u80fd\u5bfc\u81f4\u4efb\u52a1\u5931\u8d25\uff0c\u5c24\u5176\u662f\u5728\u9700\u8981\u7cbe\u786e\u3001\u4f4e\u71b5\u7b56\u7565\u7684\u4efb\u52a1\u4e2d\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5e73\u8861\u5956\u52b1\u8bbe\u8ba1\u4e0e\u71b5\u6700\u5927\u5316\u63d0\u4f9b\u4e86\u66f4\u6df1\u5165\u7684\u7406\u89e3\u3002"}}
{"id": "2506.05617", "pdf": "https://arxiv.org/pdf/2506.05617", "abs": "https://arxiv.org/abs/2506.05617", "authors": ["Antonia van Betteray", "Matthias Rottmann", "Karsten Kahl"], "title": "LFA applied to CNNs: Efficient Singular Value Decomposition of Convolutional Mappings by Local Fourier Analysis", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The singular values of convolutional mappings encode interesting spectral\nproperties, which can be used, e.g., to improve generalization and robustness\nof convolutional neural networks as well as to facilitate model compression.\nHowever, the computation of singular values is typically very\nresource-intensive. The naive approach involves unrolling the convolutional\nmapping along the input and channel dimensions into a large and sparse\ntwo-dimensional matrix, making the exact calculation of all singular values\ninfeasible due to hardware limitations. In particular, this is true for\nmatrices that represent convolutional mappings with large inputs and a high\nnumber of channels. Existing efficient methods leverage the Fast Fourier\ntransformation (FFT) to transform convolutional mappings into the frequency\ndomain, enabling the computation of singular values for matrices representing\nconvolutions with larger input and channel dimensions. For a constant number of\nchannels in a given convolution, an FFT can compute N singular values in O(N\nlog N) complexity. In this work, we propose an approach of complexity O(N)\nbased on local Fourier analysis, which additionally exploits the shift\ninvariance of convolutional operators. We provide a theoretical analysis of our\nalgorithm's runtime and validate its efficiency through numerical experiments.\nOur results demonstrate that our proposed method is scalable and offers a\npractical solution to calculate the entire set of singular values - along with\nthe corresponding singular vectors if needed - for high-dimensional\nconvolutional mappings.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5c40\u90e8\u5085\u91cc\u53f6\u5206\u6790\u7684\u4f4e\u590d\u6742\u5ea6\u65b9\u6cd5\uff0c\u7528\u4e8e\u9ad8\u6548\u8ba1\u7b97\u5377\u79ef\u6620\u5c04\u7684\u5947\u5f02\u503c\u3002", "motivation": "\u5377\u79ef\u6620\u5c04\u7684\u5947\u5f02\u503c\u5177\u6709\u91cd\u8981\u7684\u8c31\u7279\u6027\uff0c\u4f46\u4f20\u7edf\u8ba1\u7b97\u65b9\u6cd5\u8d44\u6e90\u6d88\u8017\u5927\uff0c\u96be\u4ee5\u5904\u7406\u9ad8\u7ef4\u8f93\u5165\u548c\u591a\u901a\u9053\u60c5\u51b5\u3002", "method": "\u5229\u7528\u5c40\u90e8\u5085\u91cc\u53f6\u5206\u6790\u548c\u5377\u79ef\u7b97\u5b50\u7684\u5e73\u79fb\u4e0d\u53d8\u6027\uff0c\u63d0\u51fa\u590d\u6742\u5ea6\u4e3aO(N)\u7684\u7b97\u6cd5\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6548\u7387\uff0c\u80fd\u591f\u8ba1\u7b97\u9ad8\u7ef4\u5377\u79ef\u6620\u5c04\u7684\u5168\u90e8\u5947\u5f02\u503c\u53ca\u5bf9\u5e94\u5947\u5f02\u5411\u91cf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u9ad8\u7ef4\u5377\u79ef\u6620\u5c04\u7684\u5947\u5f02\u503c\u8ba1\u7b97\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.05626", "pdf": "https://arxiv.org/pdf/2506.05626", "abs": "https://arxiv.org/abs/2506.05626", "authors": ["Xiaohua Lu", "Liubov Tupikina", "Mehwish Alam"], "title": "Two-dimensional Taxonomy for N-ary Knowledge Representation Learning Methods", "categories": ["cs.LG"], "comment": null, "summary": "Real-world knowledge can take various forms, including structured,\nsemi-structured, and unstructured data. Among these, knowledge graphs are a\nform of structured human knowledge that integrate heterogeneous data sources\ninto structured representations but typically reduce complex n-ary relations to\nsimple triples, thereby losing higher-order relational details. In contrast,\nhypergraphs naturally represent n-ary relations with hyperedges, which directly\nconnect multiple entities together. Yet hypergraph representation learning\noften overlooks entity roles in hyperedges, limiting the fine-grained semantic\nmodelling. To address these issues, knowledge hypergraphs and hyper-relational\nknowledge graphs combine the advantages of knowledge graphs and hypergraphs to\nbetter capture the complex structures and role-specific semantics of real-world\nknowledge. This survey provides a comprehensive review of methods handling\nn-ary relational data, covering both knowledge hypergraphs and hyper-relational\nknowledge graphs literatures. We propose a two-dimensional taxonomy: the first\ndimension categorises models based on their methodology, i.e.,\ntranslation-based models, tensor factorisation-based models, deep neural\nnetwork-based models, logic rules-based models, and hyperedge expansion-based\nmodels. The second dimension classifies models according to their awareness of\nentity roles and positions in n-ary relations, dividing them into aware-less,\nposition-aware, and role-aware approaches. Finally, we discuss existing\ndatasets, negative sampling strategies, and outline open challenges to inspire\nfuture research.", "AI": {"tldr": "\u8be5\u7efc\u8ff0\u63a2\u8ba8\u4e86\u77e5\u8bc6\u8d85\u56fe\u548c\u8d85\u5173\u7cfb\u77e5\u8bc6\u56fe\u5982\u4f55\u7ed3\u5408\u77e5\u8bc6\u56fe\u548c\u8d85\u56fe\u7684\u4f18\u52bf\uff0c\u4ee5\u66f4\u597d\u5730\u5efa\u6a21\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u590d\u6742\u5173\u7cfb\u548c\u5b9e\u4f53\u89d2\u8272\u3002", "motivation": "\u89e3\u51b3\u77e5\u8bc6\u56fe\u7b80\u5316\u9ad8\u9636\u5173\u7cfb\u4e22\u5931\u7ec6\u8282\u4ee5\u53ca\u8d85\u56fe\u5ffd\u89c6\u5b9e\u4f53\u89d2\u8272\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e8c\u7ef4\u5206\u7c7b\u6cd5\uff1a\u6309\u65b9\u6cd5\u8bba\uff08\u5982\u7ffb\u8bd1\u3001\u5f20\u91cf\u5206\u89e3\u3001\u6df1\u5ea6\u5b66\u4e60\u7b49\uff09\u548c\u5b9e\u4f53\u89d2\u8272\u610f\u8bc6\uff08\u65e0\u610f\u8bc6\u3001\u4f4d\u7f6e\u610f\u8bc6\u3001\u89d2\u8272\u610f\u8bc6\uff09\u5206\u7c7b\u6a21\u578b\u3002", "result": "\u7efc\u8ff0\u4e86\u5904\u7406n\u5143\u5173\u7cfb\u6570\u636e\u7684\u65b9\u6cd5\uff0c\u5305\u62ec\u73b0\u6709\u6570\u636e\u96c6\u548c\u8d1f\u91c7\u6837\u7b56\u7565\u3002", "conclusion": "\u603b\u7ed3\u4e86\u5f53\u524d\u6311\u6218\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u65b9\u5411\u3002"}}
{"id": "2506.05628", "pdf": "https://arxiv.org/pdf/2506.05628", "abs": "https://arxiv.org/abs/2506.05628", "authors": ["Jiri Navratil", "Jarret Ross", "Payel Das", "Youssef Mroueh", "Samuel C Hoffman", "Vijil Chenthamarakshan", "Brian Belgodere"], "title": "GP-MoLFormer-Sim: Test Time Molecular Optimization through Contextual Similarity Guidance", "categories": ["cs.LG", "cs.AI"], "comment": "12 pages main article, 21 pages total", "summary": "The ability to design molecules while preserving similarity to a target\nmolecule and/or property is crucial for various applications in drug discovery,\nchemical design, and biology. We introduce in this paper an efficient\ntraining-free method for navigating and sampling from the molecular space with\na generative Chemical Language Model (CLM), while using the molecular\nsimilarity to the target as a guide. Our method leverages the contextual\nrepresentations learned from the CLM itself to estimate the molecular\nsimilarity, which is then used to adjust the autoregressive sampling strategy\nof the CLM. At each step of the decoding process, the method tracks the\ndistance of the current generations from the target and updates the logits to\nencourage the preservation of similarity in generations. We implement the\nmethod using a recently proposed $\\sim$47M parameter SMILES-based CLM,\nGP-MoLFormer, and therefore refer to the method as GP-MoLFormer-Sim, which\nenables a test-time update of the deep generative policy to reflect the\ncontextual similarity to a set of guide molecules. The method is further\nintegrated into a genetic algorithm (GA) and tested on a set of standard\nmolecular optimization benchmarks involving property optimization, molecular\nrediscovery, and structure-based drug design. Results show that,\nGP-MoLFormer-Sim, combined with GA (GP-MoLFormer-Sim+GA) outperforms existing\ntraining-free baseline methods, when the oracle remains black-box. The findings\nin this work are a step forward in understanding and guiding the generative\nmechanisms of CLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u65b9\u6cd5\uff08GP-MoLFormer-Sim\uff09\uff0c\u5229\u7528\u5316\u5b66\u8bed\u8a00\u6a21\u578b\uff08CLM\uff09\u751f\u6210\u5206\u5b50\uff0c\u5e76\u901a\u8fc7\u5206\u5b50\u76f8\u4f3c\u6027\u5f15\u5bfc\u91c7\u6837\u7b56\u7565\uff0c\u7ed3\u5408\u9057\u4f20\u7b97\u6cd5\uff08GA\uff09\u5728\u5206\u5b50\u4f18\u5316\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5728\u836f\u7269\u53d1\u73b0\u548c\u5316\u5b66\u8bbe\u8ba1\u4e2d\uff0c\u8bbe\u8ba1\u5206\u5b50\u65f6\u9700\u4fdd\u6301\u4e0e\u76ee\u6807\u5206\u5b50\u7684\u76f8\u4f3c\u6027\u6216\u7279\u5b9a\u6027\u8d28\uff0c\u73b0\u6709\u65b9\u6cd5\u6548\u7387\u4e0d\u8db3\uff0c\u9700\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u65e0\u8bad\u7ec3\u65b9\u6cd5\u3002", "method": "\u5229\u7528CLM\u7684\u4e0a\u4e0b\u6587\u8868\u793a\u4f30\u8ba1\u5206\u5b50\u76f8\u4f3c\u6027\uff0c\u8c03\u6574\u81ea\u56de\u5f52\u91c7\u6837\u7b56\u7565\uff0c\u7ed3\u5408\u9057\u4f20\u7b97\u6cd5\uff08GA\uff09\u4f18\u5316\u5206\u5b50\u751f\u6210\u3002", "result": "GP-MoLFormer-Sim+GA\u5728\u5206\u5b50\u4f18\u5316\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u65e0\u8bad\u7ec3\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u9ed1\u76d2\u6761\u4ef6\u4e0b\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u7406\u89e3\u548c\u5f15\u5bfcCLM\u751f\u6210\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u63a8\u52a8\u4e86\u5206\u5b50\u8bbe\u8ba1\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.05632", "pdf": "https://arxiv.org/pdf/2506.05632", "abs": "https://arxiv.org/abs/2506.05632", "authors": ["Joseph Rowan", "Buu Phan", "Ashish Khisti"], "title": "List-Level Distribution Coupling with Applications to Speculative Decoding and Lossy Compression", "categories": ["cs.LG"], "comment": "Submitted to NeurIPS 2025", "summary": "We study a relaxation of the problem of coupling probability distributions --\na list of samples is generated from one distribution and an accept is declared\nif any one of these samples is identical to the sample generated from the other\ndistribution. We propose a novel method for generating samples, which extends\nthe Gumbel-max sampling suggested in Daliri et al. (arXiv:2408.07978) for\ncoupling probability distributions. We also establish a corresponding lower\nbound on the acceptance probability, which we call the list matching lemma. We\nnext discuss two applications of our setup. First, we develop a new mechanism\nfor multi-draft speculative sampling that is simple to implement and achieves\nperformance competitive with baselines such as SpecTr and SpecInfer across a\nrange of language tasks. Our method also guarantees a certain degree of drafter\ninvariance with respect to the output tokens which is not supported by existing\nschemes. We also provide a theoretical lower bound on the token level\nacceptance probability. As our second application, we consider distributed\nlossy compression with side information in a setting where a source sample is\ncompressed and available to multiple decoders, each with independent side\ninformation. We propose a compression technique that is based on our\ngeneralization of Gumbel-max sampling and show that it provides significant\ngains in experiments involving synthetic Gaussian sources and the MNIST image\ndataset.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6982\u7387\u5206\u5e03\u8026\u5408\u65b9\u6cd5\uff0c\u6269\u5c55\u4e86Gumbel-max\u91c7\u6837\uff0c\u5e76\u5efa\u7acb\u4e86\u63a5\u53d7\u6982\u7387\u7684\u4e0b\u754c\uff08\u5217\u8868\u5339\u914d\u5f15\u7406\uff09\u3002\u8be5\u65b9\u6cd5\u5e94\u7528\u4e8e\u591a\u8349\u7a3f\u63a8\u6d4b\u91c7\u6837\u548c\u5206\u5e03\u5f0f\u6709\u635f\u538b\u7f29\uff0c\u8868\u73b0\u51fa\u7ade\u4e89\u6027\u80fd\u3002", "motivation": "\u7814\u7a76\u6982\u7387\u5206\u5e03\u8026\u5408\u95ee\u9898\u7684\u677e\u5f1b\u5f62\u5f0f\uff0c\u63d0\u51fa\u66f4\u9ad8\u6548\u7684\u91c7\u6837\u65b9\u6cd5\uff0c\u5e76\u63a2\u7d22\u5176\u5728\u5b9e\u9645\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u6269\u5c55Gumbel-max\u91c7\u6837\uff0c\u63d0\u51fa\u65b0\u65b9\u6cd5\u751f\u6210\u6837\u672c\uff0c\u5e76\u5efa\u7acb\u63a5\u53d7\u6982\u7387\u4e0b\u754c\uff08\u5217\u8868\u5339\u914d\u5f15\u7406\uff09\u3002\u5e94\u7528\u4e8e\u591a\u8349\u7a3f\u63a8\u6d4b\u91c7\u6837\u548c\u5206\u5e03\u5f0f\u6709\u635f\u538b\u7f29\u3002", "result": "\u5728\u591a\u8349\u7a3f\u63a8\u6d4b\u91c7\u6837\u4e2d\u8868\u73b0\u4e0e\u57fa\u7ebf\u65b9\u6cd5\u7ade\u4e89\uff0c\u4e14\u652f\u6301\u8349\u7a3f\u4e0d\u53d8\u6027\uff1b\u5728\u5206\u5e03\u5f0f\u6709\u635f\u538b\u7f29\u4e2d\uff0c\u5bf9\u5408\u6210\u9ad8\u65af\u6e90\u548cMNIST\u6570\u636e\u96c6\u6709\u663e\u8457\u589e\u76ca\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u7406\u8bba\u548c\u5b9e\u9a8c\u4e2d\u5747\u8868\u73b0\u51fa\u8272\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u5b9e\u9645\u4efb\u52a1\u3002"}}
{"id": "2506.05634", "pdf": "https://arxiv.org/pdf/2506.05634", "abs": "https://arxiv.org/abs/2506.05634", "authors": ["Saeed Hedayatian", "Stefanos Nikolaidis"], "title": "AutoQD: Automatic Discovery of Diverse Behaviors with Quality-Diversity Optimization", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": "22 pages, 5 figures", "summary": "Quality-Diversity (QD) algorithms have shown remarkable success in\ndiscovering diverse, high-performing solutions, but rely heavily on\nhand-crafted behavioral descriptors that constrain exploration to predefined\nnotions of diversity. Leveraging the equivalence between policies and occupancy\nmeasures, we present a theoretically grounded approach to automatically\ngenerate behavioral descriptors by embedding the occupancy measures of policies\nin Markov Decision Processes. Our method, AutoQD, leverages random Fourier\nfeatures to approximate the Maximum Mean Discrepancy (MMD) between policy\noccupancy measures, creating embeddings whose distances reflect meaningful\nbehavioral differences. A low-dimensional projection of these embeddings that\ncaptures the most behaviorally significant dimensions is then used as\nbehavioral descriptors for off-the-shelf QD methods. We prove that our\nembeddings converge to true MMD distances between occupancy measures as the\nnumber of sampled trajectories and embedding dimensions increase. Through\nexperiments in multiple continuous control tasks we demonstrate AutoQD's\nability in discovering diverse policies without predefined behavioral\ndescriptors, presenting a well-motivated alternative to prior methods in\nunsupervised Reinforcement Learning and QD optimization. Our approach opens new\npossibilities for open-ended learning and automated behavior discovery in\nsequential decision making settings without requiring domain-specific\nknowledge.", "AI": {"tldr": "AutoQD\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u751f\u6210\u884c\u4e3a\u63cf\u8ff0\u7b26\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5d4c\u5165\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u7684\u7b56\u7565\u5360\u7528\u5ea6\u91cf\uff0c\u907f\u514d\u4e86\u4f9d\u8d56\u9884\u5b9a\u4e49\u591a\u6837\u6027\u63cf\u8ff0\u7b26\u7684\u9650\u5236\u3002", "motivation": "\u4f20\u7edfQD\u7b97\u6cd5\u4f9d\u8d56\u624b\u5de5\u8bbe\u8ba1\u7684\u884c\u4e3a\u63cf\u8ff0\u7b26\uff0c\u9650\u5236\u4e86\u63a2\u7d22\u7684\u591a\u6837\u6027\u3002AutoQD\u65e8\u5728\u81ea\u52a8\u751f\u6210\u63cf\u8ff0\u7b26\uff0c\u5b9e\u73b0\u66f4\u5f00\u653e\u7684\u63a2\u7d22\u3002", "method": "\u5229\u7528\u968f\u673a\u5085\u91cc\u53f6\u7279\u5f81\u8fd1\u4f3c\u7b56\u7565\u5360\u7528\u5ea6\u91cf\u7684\u6700\u5927\u5747\u503c\u5dee\u5f02\uff08MMD\uff09\uff0c\u751f\u6210\u53cd\u6620\u884c\u4e3a\u5dee\u5f02\u7684\u4f4e\u7ef4\u5d4c\u5165\uff0c\u4f5c\u4e3aQD\u7b97\u6cd5\u7684\u8f93\u5165\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eAutoQD\u80fd\u5728\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e2d\u53d1\u73b0\u591a\u6837\u7b56\u7565\uff0c\u4e14\u5d4c\u5165\u8ddd\u79bb\u968f\u6837\u672c\u548c\u7ef4\u5ea6\u589e\u52a0\u6536\u655b\u4e8e\u771f\u5b9eMMD\u8ddd\u79bb\u3002", "conclusion": "AutoQD\u4e3a\u65e0\u76d1\u7763\u5f3a\u5316\u5b66\u4e60\u548cQD\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u652f\u6301\u65e0\u9700\u9886\u57df\u77e5\u8bc6\u7684\u81ea\u52a8\u5316\u884c\u4e3a\u53d1\u73b0\u3002"}}
{"id": "2506.05636", "pdf": "https://arxiv.org/pdf/2506.05636", "abs": "https://arxiv.org/abs/2506.05636", "authors": ["Markelle Kelly", "Alex Boyd", "Sam Showalter", "Mark Steyvers", "Padhraic Smyth"], "title": "Bayesian Inference for Correlated Human Experts and Classifiers", "categories": ["cs.LG", "cs.AI"], "comment": "accepted to ICML 2025", "summary": "Applications of machine learning often involve making predictions based on\nboth model outputs and the opinions of human experts. In this context, we\ninvestigate the problem of querying experts for class label predictions, using\nas few human queries as possible, and leveraging the class probability\nestimates of pre-trained classifiers. We develop a general Bayesian framework\nfor this problem, modeling expert correlation via a joint latent\nrepresentation, enabling simulation-based inference about the utility of\nadditional expert queries, as well as inference of posterior distributions over\nunobserved expert labels. We apply our approach to two real-world medical\nclassification problems, as well as to CIFAR-10H and ImageNet-16H,\ndemonstrating substantial reductions relative to baselines in the cost of\nquerying human experts while maintaining high prediction accuracy.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8d1d\u53f6\u65af\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u7ed3\u5408\u4eba\u7c7b\u4e13\u5bb6\u610f\u89c1\u548c\u6a21\u578b\u9884\u6d4b\uff0c\u4ee5\u51cf\u5c11\u4e13\u5bb6\u67e5\u8be2\u6b21\u6570\u5e76\u4fdd\u6301\u9ad8\u51c6\u786e\u6027\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u9ad8\u6548\u5229\u7528\u4eba\u7c7b\u4e13\u5bb6\u7684\u6807\u7b7e\u9884\u6d4b\uff0c\u51cf\u5c11\u67e5\u8be2\u6b21\u6570\u5e76\u63d0\u5347\u9884\u6d4b\u6548\u679c\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u8d1d\u53f6\u65af\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u5408\u6f5c\u5728\u8868\u793a\u5efa\u6a21\u4e13\u5bb6\u76f8\u5173\u6027\uff0c\u652f\u6301\u6a21\u62df\u63a8\u7406\u548c\u672a\u89c2\u5bdf\u4e13\u5bb6\u6807\u7b7e\u7684\u540e\u9a8c\u63a8\u65ad\u3002", "result": "\u5728\u771f\u5b9e\u533b\u5b66\u5206\u7c7b\u95ee\u9898\u548c\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u4e13\u5bb6\u67e5\u8be2\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u548c\u4eba\u7c7b\u4e13\u5bb6\u610f\u89c1\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u5b9e\u7528\u7684\u65b9\u6cd5\u3002"}}
{"id": "2506.05641", "pdf": "https://arxiv.org/pdf/2506.05641", "abs": "https://arxiv.org/abs/2506.05641", "authors": ["Andrey Zhmoginov", "Jihwan Lee", "Mark Sandler"], "title": "Projectable Models: One-Shot Generation of Small Specialized Transformers from Large Ones", "categories": ["cs.LG", "cs.CL"], "comment": "Presented at ES-FoMo II: 2nd Workshop on Efficient Systems for\n  Foundation Models (ICML 2024)", "summary": "Modern Foundation Models (FMs) are typically trained on corpora spanning a\nwide range of different data modalities, topics and downstream tasks. Utilizing\nthese models can be very computationally expensive and is out of reach for most\nconsumer devices. Furthermore, most of the broad FM knowledge may actually be\nirrelevant for a specific task at hand. Here we explore a technique for mapping\nparameters of a large Transformer to parameters of a smaller specialized model.\nBy making this transformation task-specific, we aim to capture a narrower scope\nof the knowledge needed for performing a specific task by a smaller model. We\nstudy our method on image modeling tasks, showing that performance of generated\nmodels exceeds that of universal conditional models.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5c06\u5927\u578bTransformer\u53c2\u6570\u6620\u5c04\u5230\u5c0f\u578b\u4e13\u7528\u6a21\u578b\u7684\u6280\u672f\uff0c\u4ee5\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u5e76\u63d0\u9ad8\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u73b0\u4ee3\u57fa\u7840\u6a21\u578b\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u77e5\u8bc6\u5e7f\u6cdb\uff0c\u4f46\u7279\u5b9a\u4efb\u52a1\u53ef\u80fd\u53ea\u9700\u90e8\u5206\u77e5\u8bc6\uff0c\u56e0\u6b64\u63a2\u7d22\u5982\u4f55\u7f29\u5c0f\u6a21\u578b\u89c4\u6a21\u4ee5\u9002\u5e94\u7279\u5b9a\u4efb\u52a1\u3002", "method": "\u901a\u8fc7\u4efb\u52a1\u7279\u5b9a\u7684\u53c2\u6570\u6620\u5c04\u6280\u672f\uff0c\u5c06\u5927\u578bTransformer\u53c2\u6570\u8f6c\u5316\u4e3a\u5c0f\u578b\u4e13\u7528\u6a21\u578b\u53c2\u6570\u3002", "result": "\u5728\u56fe\u50cf\u5efa\u6a21\u4efb\u52a1\u4e2d\uff0c\u751f\u6210\u7684\u5c0f\u578b\u6a21\u578b\u6027\u80fd\u4f18\u4e8e\u901a\u7528\u6761\u4ef6\u6a21\u578b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u7f29\u5c0f\u6a21\u578b\u89c4\u6a21\u5e76\u63d0\u5347\u7279\u5b9a\u4efb\u52a1\u6027\u80fd\u3002"}}
{"id": "2506.05647", "pdf": "https://arxiv.org/pdf/2506.05647", "abs": "https://arxiv.org/abs/2506.05647", "authors": ["Shuangqi Li", "Hieu Le", "Jingyi Xu", "Mathieu Salzmann"], "title": "Learning to Weight Parameters for Data Attribution", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "We study data attribution in generative models, aiming to identify which\ntraining examples most influence a given output. Existing methods achieve this\nby tracing gradients back to training data. However, they typically treat all\nnetwork parameters uniformly, ignoring the fact that different layers encode\ndifferent types of information and may thus draw information differently from\nthe training set. We propose a method that models this by learning parameter\nimportance weights tailored for attribution, without requiring labeled data.\nThis allows the attribution process to adapt to the structure of the model,\ncapturing which training examples contribute to specific semantic aspects of an\noutput, such as subject, style, or background. Our method improves attribution\naccuracy across diffusion models and enables fine-grained insights into how\noutputs borrow from training data.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u751f\u6210\u6a21\u578b\u4e2d\u6570\u636e\u5f52\u5c5e\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b66\u4e60\u53c2\u6570\u91cd\u8981\u6027\u6743\u91cd\u6765\u6539\u8fdb\u5f52\u5c5e\u51c6\u786e\u6027\uff0c\u65e0\u9700\u6807\u6ce8\u6570\u636e\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u8ffd\u8e2a\u68af\u5ea6\u65f6\u901a\u5e38\u5ffd\u7565\u7f51\u7edc\u53c2\u6570\u7684\u4e0d\u540c\u5c42\u6b21\u5bf9\u4fe1\u606f\u7f16\u7801\u7684\u5dee\u5f02\uff0c\u5bfc\u81f4\u5f52\u5c5e\u4e0d\u51c6\u786e\u3002", "method": "\u901a\u8fc7\u5b66\u4e60\u53c2\u6570\u91cd\u8981\u6027\u6743\u91cd\uff0c\u9002\u5e94\u6a21\u578b\u7ed3\u6784\uff0c\u6355\u6349\u8bad\u7ec3\u6570\u636e\u5bf9\u8f93\u51fa\u4e0d\u540c\u8bed\u4e49\u65b9\u9762\uff08\u5982\u4e3b\u9898\u3001\u98ce\u683c\u6216\u80cc\u666f\uff09\u7684\u8d21\u732e\u3002", "result": "\u65b9\u6cd5\u5728\u6269\u6563\u6a21\u578b\u4e2d\u63d0\u9ad8\u4e86\u5f52\u5c5e\u51c6\u786e\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u5bf9\u8f93\u51fa\u5982\u4f55\u4ece\u8bad\u7ec3\u6570\u636e\u4e2d\u501f\u9274\u7684\u7ec6\u7c92\u5ea6\u89c1\u89e3\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u5efa\u6a21\u53c2\u6570\u91cd\u8981\u6027\u6743\u91cd\uff0c\u6539\u8fdb\u4e86\u751f\u6210\u6a21\u578b\u4e2d\u7684\u6570\u636e\u5f52\u5c5e\uff0c\u4e3a\u7406\u89e3\u6a21\u578b\u884c\u4e3a\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2506.05664", "pdf": "https://arxiv.org/pdf/2506.05664", "abs": "https://arxiv.org/abs/2506.05664", "authors": ["Chao Zhang", "Li Wang", "Samson Lasaulce", "Merouane Debbah"], "title": "BAQ: Efficient Bit Allocation Quantization for Large Language Models", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Post-training model quantization is a widely adopted technique for reducing\nthe memory and computational costs of large language models (LLMs). However,\nmost existing methods rely on uniform or heuristic bitwidth assignments,\nfailing to account for the nonuniform sensitivity of weights to quantization\nnoise. In this paper, we propose a novel framework for allocating quantization\nbitwidths based on sensitivity metrics derived from a Hessian proxy. We make\nkey assumptions, which allow the layer/component-wise loss function to be\nexpressed as an explicit function of the bitwidths. This enables a neat\nformulation of the bit allocation problem as a convex optimization task, whose\nclosed-form solution adapts precision across weights to minimize the layer-wise\nquantization loss. Inspecting the solution provides several insights (such as\nthe equal-loss structure), which are then exploited to design the proposed\n\\textbf{BAQ} (Bit Allocation Quantization) algorithm. The proposed algorithm\nachieves a good trade-off between loss minimization and complexity and allows\nBAQ to be integrated into standard quantization pipelines with minimal\noverhead. Experimental results show that BAQ consistently outperforms GPTQ,\nachieving up to 56$\\times$ lower perplexity at the same bitwidth on large\nlanguage models ranging from 125M to 30B parameters. Leveraging our analytical\nresults derived from solving the optimal bit allocation problem, we also\nprovide a theoretical explanation for the observed gains. All codes of this\npaper are available at https://github.com/CSU-ModelCompression/BAQ.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eHessian\u4ee3\u7406\u7684\u91cf\u5316\u4f4d\u5bbd\u5206\u914d\u6846\u67b6BAQ\uff0c\u901a\u8fc7\u51f8\u4f18\u5316\u4efb\u52a1\u81ea\u9002\u5e94\u5206\u914d\u4f4d\u5bbd\uff0c\u663e\u8457\u964d\u4f4e\u91cf\u5316\u635f\u5931\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u4f18\u4e8eGPTQ\u3002", "motivation": "\u73b0\u6709\u91cf\u5316\u65b9\u6cd5\u4f9d\u8d56\u5747\u5300\u6216\u542f\u53d1\u5f0f\u4f4d\u5bbd\u5206\u914d\uff0c\u672a\u80fd\u8003\u8651\u6743\u91cd\u5bf9\u91cf\u5316\u566a\u58f0\u7684\u975e\u5747\u5300\u654f\u611f\u6027\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u57fa\u4e8eHessian\u4ee3\u7406\u7684\u7075\u654f\u5ea6\u5ea6\u91cf\uff0c\u5c06\u4f4d\u5bbd\u5206\u914d\u95ee\u9898\u8f6c\u5316\u4e3a\u51f8\u4f18\u5316\u4efb\u52a1\uff0c\u8bbe\u8ba1BAQ\u7b97\u6cd5\u5b9e\u73b0\u81ea\u9002\u5e94\u4f4d\u5bbd\u5206\u914d\u3002", "result": "BAQ\u5728125M\u81f330B\u53c2\u6570\u7684LLMs\u4e0a\u8868\u73b0\u4f18\u4e8eGPTQ\uff0c\u76f8\u540c\u4f4d\u5bbd\u4e0b\u56f0\u60d1\u5ea6\u964d\u4f4e56\u500d\u3002", "conclusion": "BAQ\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u5b9e\u73b0\u4e86\u91cf\u5316\u635f\u5931\u6700\u5c0f\u5316\u4e0e\u590d\u6742\u5ea6\u7684\u826f\u597d\u6743\u8861\uff0c\u4e3aLLM\u91cf\u5316\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.05668", "pdf": "https://arxiv.org/pdf/2506.05668", "abs": "https://arxiv.org/abs/2506.05668", "authors": ["Jiajun He", "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato", "Yuanqi Du", "Francisco Vargas"], "title": "RNE: a plug-and-play framework for diffusion density estimation and inference-time control", "categories": ["cs.LG", "stat.ML"], "comment": "39 pages; 10 figures", "summary": "In this paper, we introduce the Radon-Nikodym Estimator (RNE), a flexible,\nplug-and-play framework for diffusion inference-time density estimation and\ncontrol, based on the concept of the density ratio between path distributions.\nRNE connects and unifies a variety of existing density estimation and\ninference-time control methods under a single and intuitive perspective,\nstemming from basic variational inference and probabilistic principles\ntherefore offering both theoretical clarity and practical versatility.\nExperiments demonstrate that RNE achieves promising performances in diffusion\ndensity estimation and inference-time control tasks, including annealing,\ncomposition of diffusion models, and reward-tilting.", "AI": {"tldr": "Radon-Nikodym Estimator\uff08RNE\uff09\u662f\u4e00\u79cd\u57fa\u4e8e\u8def\u5f84\u5206\u5e03\u5bc6\u5ea6\u6bd4\u7684\u7075\u6d3b\u6846\u67b6\uff0c\u7528\u4e8e\u6269\u6563\u63a8\u65ad\u65f6\u7684\u5bc6\u5ea6\u4f30\u8ba1\u548c\u63a7\u5236\uff0c\u7edf\u4e00\u4e86\u591a\u79cd\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u63d0\u51faRNE\u662f\u4e3a\u4e86\u901a\u8fc7\u5bc6\u5ea6\u6bd4\u7684\u6982\u5ff5\uff0c\u7edf\u4e00\u548c\u7b80\u5316\u6269\u6563\u63a8\u65ad\u65f6\u7684\u5bc6\u5ea6\u4f30\u8ba1\u4e0e\u63a7\u5236\u65b9\u6cd5\uff0c\u540c\u65f6\u63d0\u4f9b\u7406\u8bba\u6e05\u6670\u6027\u548c\u5b9e\u8df5\u7075\u6d3b\u6027\u3002", "method": "RNE\u57fa\u4e8e\u53d8\u5206\u63a8\u65ad\u548c\u6982\u7387\u539f\u7406\uff0c\u901a\u8fc7\u8def\u5f84\u5206\u5e03\u7684\u5bc6\u5ea6\u6bd4\u5b9e\u73b0\u6269\u6563\u6a21\u578b\u7684\u5bc6\u5ea6\u4f30\u8ba1\u4e0e\u63a7\u5236\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cRNE\u5728\u6269\u6563\u5bc6\u5ea6\u4f30\u8ba1\u548c\u63a8\u65ad\u63a7\u5236\u4efb\u52a1\uff08\u5982\u9000\u706b\u3001\u6a21\u578b\u7ec4\u5408\u548c\u5956\u52b1\u503e\u659c\uff09\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "RNE\u4e3a\u6269\u6563\u63a8\u65ad\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u4e14\u76f4\u89c2\u7684\u6846\u67b6\uff0c\u517c\u5177\u7406\u8bba\u6df1\u5ea6\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2506.05672", "pdf": "https://arxiv.org/pdf/2506.05672", "abs": "https://arxiv.org/abs/2506.05672", "authors": ["Andrey Zhmoginov", "Jihwan Lee", "Max Vladymyrov", "Mark Sandler"], "title": "Contextually Guided Transformers via Low-Rank Adaptation", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) based on Transformers excel at text processing,\nbut their reliance on prompts for specialized behavior introduces computational\noverhead. We propose a modification to a Transformer architecture that\neliminates the need for explicit prompts by learning to encode context into the\nmodel's weights. Our Contextually Guided Transformer (CGT) model maintains a\ncontextual summary at each sequence position, allowing it to update the weights\non the fly based on the preceding context. This approach enables the model to\nself-specialize, effectively creating a tailored model for processing\ninformation following a given prefix. We demonstrate the effectiveness of our\nmethod on synthetic in-context learning tasks and language modeling benchmarks.\nFurthermore, we introduce techniques for enhancing the interpretability of the\nlearned contextual representations, drawing connections to Variational\nAutoencoders and promoting smoother, more consistent context encoding. This\nwork offers a novel direction for efficient and adaptable language modeling by\nintegrating context directly into the model's architecture.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u663e\u5f0f\u63d0\u793a\u7684Transformer\u6539\u8fdb\u6a21\u578bCGT\uff0c\u901a\u8fc7\u52a8\u6001\u6743\u91cd\u8c03\u6574\u5b9e\u73b0\u4e0a\u4e0b\u6587\u81ea\u9002\u5e94\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edfLLMs\u4f9d\u8d56\u663e\u5f0f\u63d0\u793a\u5e26\u6765\u7684\u8ba1\u7b97\u5f00\u9500\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1CGT\u6a21\u578b\uff0c\u52a8\u6001\u7f16\u7801\u4e0a\u4e0b\u6587\u5230\u6743\u91cd\u4e2d\uff0c\u652f\u6301\u81ea\u9002\u5e94\u6027\u3002", "result": "\u5728\u5408\u6210\u4efb\u52a1\u548c\u8bed\u8a00\u5efa\u6a21\u57fa\u51c6\u4e0a\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\uff0c\u5e76\u63d0\u5347\u4e86\u8868\u793a\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u4e3a\u9ad8\u6548\u3001\u81ea\u9002\u5e94\u7684\u8bed\u8a00\u5efa\u6a21\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2506.05673", "pdf": "https://arxiv.org/pdf/2506.05673", "abs": "https://arxiv.org/abs/2506.05673", "authors": ["Sajjad Abdoli", "Freeman Lewin", "Gediminas Vasiliauskas", "Fabian Schonholz"], "title": "Peer-Ranked Precision: Creating a Foundational Dataset for Fine-Tuning Vision Models from DataSeeds' Annotated Imagery", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "28 pages, 12 figures", "summary": "The development of modern Artificial Intelligence (AI) models, particularly\ndiffusion-based models employed in computer vision and image generation tasks,\nis undergoing a paradigmatic shift in development methodologies. Traditionally\ndominated by a \"Model Centric\" approach, in which performance gains were\nprimarily pursued through increasingly complex model architectures and\nhyperparameter optimization, the field is now recognizing a more nuanced\n\"Data-Centric\" approach. This emergent framework foregrounds the quality,\nstructure, and relevance of training data as the principal driver of model\nperformance. To operationalize this paradigm shift, we introduce the\nDataSeeds.AI sample dataset (the \"DSD\"), initially comprised of approximately\n10,610 high-quality human peer-ranked photography images accompanied by\nextensive multi-tier annotations. The DSD is a foundational computer vision\ndataset designed to usher in a new standard for commercial image datasets.\nRepresenting a small fraction of DataSeeds.AI's 100 million-plus image catalog,\nthe DSD provides a scalable foundation necessary for robust commercial and\nmultimodal AI development. Through this in-depth exploratory analysis, we\ndocument the quantitative improvements generated by the DSD on specific models\nagainst known benchmarks and make the code and the trained models used in our\nevaluation publicly available.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86AI\u6a21\u578b\u5f00\u53d1\u4ece\u2018\u6a21\u578b\u4e2d\u5fc3\u2019\u5411\u2018\u6570\u636e\u4e2d\u5fc3\u2019\u7684\u8303\u5f0f\u8f6c\u53d8\uff0c\u5e76\u4ecb\u7ecd\u4e86\u9ad8\u8d28\u91cf\u6570\u636e\u96c6DSD\u53ca\u5176\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u63d0\u5347\u3002", "motivation": "\u4f20\u7edfAI\u5f00\u53d1\u8fc7\u4e8e\u4f9d\u8d56\u590d\u6742\u6a21\u578b\u67b6\u6784\uff0c\u800c\u5ffd\u89c6\u4e86\u6570\u636e\u8d28\u91cf\u7684\u91cd\u8981\u6027\u3002\u8bba\u6587\u65e8\u5728\u63a8\u52a8\u2018\u6570\u636e\u4e3a\u4e2d\u5fc3\u2019\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "method": "\u5f15\u5165DSD\u6570\u636e\u96c6\uff0810,610\u5f20\u9ad8\u8d28\u91cf\u56fe\u50cf\u53ca\u591a\u5c42\u7ea7\u6807\u6ce8\uff09\uff0c\u5e76\u8bc4\u4f30\u5176\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5b9a\u91cf\u6539\u8fdb\u3002", "result": "DSD\u663e\u8457\u63d0\u5347\u4e86\u7279\u5b9a\u6a21\u578b\u7684\u6027\u80fd\uff0c\u4ee3\u7801\u548c\u8bad\u7ec3\u6a21\u578b\u5df2\u516c\u5f00\u3002", "conclusion": "\u6570\u636e\u4e2d\u5fc3\u65b9\u6cd5\u662fAI\u53d1\u5c55\u7684\u5173\u952e\uff0cDSD\u4e3a\u5546\u4e1a\u548c\u591a\u6a21\u6001AI\u5f00\u53d1\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u57fa\u7840\u3002"}}
{"id": "2506.05676", "pdf": "https://arxiv.org/pdf/2506.05676", "abs": "https://arxiv.org/abs/2506.05676", "authors": ["Haoyang Jiang", "Jindong Wang", "Xingquan Zhu", "Yi He"], "title": "Topology-aware Neural Flux Prediction Guided by Physics", "categories": ["cs.LG"], "comment": null, "summary": "Graph Neural Networks (GNNs) often struggle in preserving high-frequency\ncomponents of nodal signals when dealing with directed graphs. Such components\nare crucial for modeling flow dynamics, without which a traditional GNN tends\nto treat a graph with forward and reverse topologies equal.To make GNNs\nsensitive to those high-frequency components thereby being capable to capture\ndetailed topological differences, this paper proposes a novel framework that\ncombines 1) explicit difference matrices that model directional gradients and\n2) implicit physical constraints that enforce messages passing within GNNs to\nbe consistent with natural laws. Evaluations on two real-world directed graph\ndata, namely, water flux network and urban traffic flow network, demonstrate\nthe effectiveness of our proposal.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u6846\u67b6\uff0c\u7ed3\u5408\u663e\u5f0f\u5dee\u5f02\u77e9\u9635\u548c\u9690\u5f0f\u7269\u7406\u7ea6\u675f\uff0c\u4ee5\u63d0\u5347GNN\u5728\u5b9a\u5411\u56fe\u4e2d\u5bf9\u9ad8\u9891\u4fe1\u53f7\u7684\u6355\u6349\u80fd\u529b\u3002", "motivation": "\u4f20\u7edfGNN\u5728\u5904\u7406\u5b9a\u5411\u56fe\u65f6\u96be\u4ee5\u4fdd\u7559\u8282\u70b9\u4fe1\u53f7\u7684\u9ad8\u9891\u6210\u5206\uff0c\u800c\u8fd9\u4e9b\u6210\u5206\u5bf9\u5efa\u6a21\u6d41\u52a8\u6001\u81f3\u5173\u91cd\u8981\u3002", "method": "\u7ed3\u5408\u663e\u5f0f\u5dee\u5f02\u77e9\u9635\uff08\u5efa\u6a21\u65b9\u5411\u68af\u5ea6\uff09\u548c\u9690\u5f0f\u7269\u7406\u7ea6\u675f\uff08\u786e\u4fdd\u6d88\u606f\u4f20\u9012\u7b26\u5408\u81ea\u7136\u89c4\u5f8b\uff09\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u7684\u6c34\u901a\u91cf\u7f51\u7edc\u548c\u57ce\u5e02\u4ea4\u901a\u6d41\u7f51\u7edc\u4e2d\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u65b0\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86GNN\u5728\u5b9a\u5411\u56fe\u4e2d\u6355\u6349\u9ad8\u9891\u4fe1\u53f7\u548c\u62d3\u6251\u5dee\u5f02\u7684\u80fd\u529b\u3002"}}
{"id": "2506.05678", "pdf": "https://arxiv.org/pdf/2506.05678", "abs": "https://arxiv.org/abs/2506.05678", "authors": ["Haotian Jiang", "Zeyu Bao", "Shida Wang", "Qianxiao Li"], "title": "Numerical Investigation of Sequence Modeling Theory using Controllable Memory Functions", "categories": ["cs.LG"], "comment": null, "summary": "The evolution of sequence modeling architectures, from recurrent neural\nnetworks and convolutional models to Transformers and structured state-space\nmodels, reflects ongoing efforts to address the diverse temporal dependencies\ninherent in sequential data. Despite this progress, systematically\ncharacterizing the strengths and limitations of these architectures remains a\nfundamental challenge. In this work, we propose a synthetic benchmarking\nframework to evaluate how effectively different sequence models capture\ndistinct temporal structures. The core of this approach is to generate\nsynthetic targets, each characterized by a memory function and a parameter that\ndetermines the strength of temporal dependence. This setup allows us to produce\na continuum of tasks that vary in temporal complexity, enabling fine-grained\nanalysis of model behavior concerning specific memory properties. We focus on\nfour representative memory functions, each corresponding to a distinct class of\ntemporal structures. Experiments on several sequence modeling architectures\nconfirm existing theoretical insights and reveal new findings. These results\ndemonstrate the effectiveness of the proposed method in advancing theoretical\nunderstanding and highlight the importance of using controllable targets with\nclearly defined structures for evaluating sequence modeling architectures.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5408\u6210\u57fa\u51c6\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u4e0d\u540c\u5e8f\u5217\u6a21\u578b\u6355\u6349\u4e0d\u540c\u65f6\u95f4\u7ed3\u6784\u7684\u80fd\u529b\uff0c\u901a\u8fc7\u751f\u6210\u5177\u6709\u660e\u786e\u65f6\u95f4\u4f9d\u8d56\u6027\u7684\u5408\u6210\u76ee\u6807\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u7684\u4f18\u7f3a\u70b9\u3002", "motivation": "\u7cfb\u7edf\u5730\u8bc4\u4f30\u5e8f\u5217\u6a21\u578b\u5728\u4e0d\u540c\u65f6\u95f4\u4f9d\u8d56\u6027\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u586b\u8865\u73b0\u6709\u7814\u7a76\u4e2d\u5bf9\u6a21\u578b\u80fd\u529b\u7cfb\u7edf\u5316\u5206\u6790\u7684\u7a7a\u767d\u3002", "method": "\u8bbe\u8ba1\u4e86\u5408\u6210\u57fa\u51c6\u6846\u67b6\uff0c\u751f\u6210\u5177\u6709\u4e0d\u540c\u65f6\u95f4\u590d\u6742\u5ea6\u7684\u4efb\u52a1\uff0c\u901a\u8fc7\u56db\u79cd\u4ee3\u8868\u6027\u8bb0\u5fc6\u51fd\u6570\u5206\u6790\u6a21\u578b\u884c\u4e3a\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u73b0\u6709\u7406\u8bba\u89c1\u89e3\u5e76\u63ed\u793a\u4e86\u65b0\u53d1\u73b0\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u52a9\u4e8e\u7406\u8bba\u7406\u89e3\uff0c\u5e76\u5f3a\u8c03\u4e86\u4f7f\u7528\u660e\u786e\u7ed3\u6784\u7684\u53ef\u63a7\u76ee\u6807\u5bf9\u8bc4\u4f30\u5e8f\u5217\u6a21\u578b\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2506.05680", "pdf": "https://arxiv.org/pdf/2506.05680", "abs": "https://arxiv.org/abs/2506.05680", "authors": ["Tailin Zhou", "Zhilin Chen", "Wenlong Lyu", "Zhitang Chen", "Danny H. K. Tsang", "Jun Zhang"], "title": "Learning Design-Score Manifold to Guide Diffusion Models for Offline Optimization", "categories": ["cs.LG", "cs.AI"], "comment": "This manuscript is submitted and under review", "summary": "Optimizing complex systems, from discovering therapeutic drugs to designing\nhigh-performance materials, remains a fundamental challenge across science and\nengineering, as the underlying rules are often unknown and costly to evaluate.\nOffline optimization aims to optimize designs for target scores using\npre-collected datasets without system interaction. However, conventional\napproaches may fail beyond training data, predicting inaccurate scores and\ngenerating inferior designs. This paper introduces ManGO, a diffusion-based\nframework that learns the design-score manifold, capturing the design-score\ninterdependencies holistically. Unlike existing methods that treat design and\nscore spaces in isolation, ManGO unifies forward prediction and backward\ngeneration, attaining generalization beyond training data. Key to this is its\nderivative-free guidance for conditional generation, coupled with adaptive\ninference-time scaling that dynamically optimizes denoising paths. Extensive\nevaluations demonstrate that ManGO outperforms 24 single- and 10\nmulti-objective optimization methods across diverse domains, including\nsynthetic tasks, robot control, material design, DNA sequence, and real-world\nengineering optimization.", "AI": {"tldr": "ManGO\u662f\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5b66\u4e60\u8bbe\u8ba1-\u8bc4\u5206\u6d41\u5f62\uff0c\u7edf\u4e00\u524d\u5411\u9884\u6d4b\u548c\u540e\u5411\u751f\u6210\uff0c\u5b9e\u73b0\u8d85\u8d8a\u8bad\u7ec3\u6570\u636e\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u590d\u6742\u7cfb\u7edf\u7684\u4f18\u5316\u662f\u79d1\u5b66\u548c\u5de5\u7a0b\u4e2d\u7684\u57fa\u672c\u6311\u6218\uff0c\u4f20\u7edf\u65b9\u6cd5\u5728\u8bad\u7ec3\u6570\u636e\u5916\u8868\u73b0\u4e0d\u4f73\u3002", "method": "ManGO\u91c7\u7528\u65e0\u5bfc\u6570\u5f15\u5bfc\u7684\u6761\u4ef6\u751f\u6210\u548c\u81ea\u9002\u5e94\u63a8\u7406\u65f6\u95f4\u7f29\u653e\uff0c\u52a8\u6001\u4f18\u5316\u53bb\u566a\u8def\u5f84\u3002", "result": "\u5728\u591a\u4e2a\u9886\u57df\uff08\u5982\u673a\u5668\u4eba\u63a7\u5236\u3001\u6750\u6599\u8bbe\u8ba1\u7b49\uff09\u4e2d\uff0cManGO\u4f18\u4e8e24\u79cd\u5355\u76ee\u6807\u548c10\u79cd\u591a\u76ee\u6807\u4f18\u5316\u65b9\u6cd5\u3002", "conclusion": "ManGO\u901a\u8fc7\u7edf\u4e00\u8bbe\u8ba1-\u8bc4\u5206\u7a7a\u95f4\uff0c\u663e\u8457\u63d0\u5347\u4e86\u79bb\u7ebf\u4f18\u5316\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2506.05683", "pdf": "https://arxiv.org/pdf/2506.05683", "abs": "https://arxiv.org/abs/2506.05683", "authors": ["Fardis Nadimi", "Payam Abdisarabshali", "Kasra Borazjani", "Jacob Chakareski", "Seyyedali Hosseinalipour"], "title": "Multi-Modal Multi-Task Federated Foundation Models for Next-Generation Extended Reality Systems: Towards Privacy-Preserving Distributed Intelligence in AR/VR/MR", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.MM"], "comment": "16 pages, 4 Figures, 8 Tables", "summary": "Extended reality (XR) systems, which consist of virtual reality (VR),\naugmented reality (AR), and mixed reality (XR), offer a transformative\ninterface for immersive, multi-modal, and embodied human-computer interaction.\nIn this paper, we envision that multi-modal multi-task (M3T) federated\nfoundation models (FedFMs) can offer transformative capabilities for XR systems\nthrough integrating the representational strength of M3T foundation models\n(FMs) with the privacy-preserving model training principles of federated\nlearning (FL). We present a modular architecture for FedFMs, which entails\ndifferent coordination paradigms for model training and aggregations. Central\nto our vision is the codification of XR challenges that affect the\nimplementation of FedFMs under the SHIFT dimensions: (1) Sensor and modality\ndiversity, (2) Hardware heterogeneity and system-level constraints, (3)\nInteractivity and embodied personalization, (4) Functional/task variability,\nand (5) Temporality and environmental variability. We illustrate the\nmanifestation of these dimensions across a set of emerging and anticipated\napplications of XR systems. Finally, we propose evaluation metrics, dataset\nrequirements, and design tradeoffs necessary for the development of\nresource-aware FedFMs in XR. This perspective aims to chart the technical and\nconceptual foundations for context-aware privacy-preserving intelligence in the\nnext generation of XR systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6a21\u6001\u591a\u4efb\u52a1\u8054\u90a6\u57fa\u7840\u6a21\u578b\uff08FedFMs\uff09\u67b6\u6784\uff0c\u7528\u4e8e\u6269\u5c55\u73b0\u5b9e\uff08XR\uff09\u7cfb\u7edf\uff0c\u7ed3\u5408\u4e86\u57fa\u7840\u6a21\u578b\u7684\u8868\u5f81\u80fd\u529b\u548c\u8054\u90a6\u5b66\u4e60\u7684\u9690\u79c1\u4fdd\u62a4\u8bad\u7ec3\u539f\u5219\u3002", "motivation": "\u901a\u8fc7\u6574\u5408\u591a\u6a21\u6001\u591a\u4efb\u52a1\u57fa\u7840\u6a21\u578b\u548c\u8054\u90a6\u5b66\u4e60\uff0c\u89e3\u51b3XR\u7cfb\u7edf\u5728\u9690\u79c1\u4fdd\u62a4\u548c\u591a\u6a21\u6001\u4ea4\u4e92\u4e2d\u7684\u6311\u6218\u3002", "method": "\u63d0\u51fa\u6a21\u5757\u5316\u67b6\u6784\uff0c\u652f\u6301\u4e0d\u540c\u534f\u8c03\u8303\u5f0f\u7684\u6a21\u578b\u8bad\u7ec3\u548c\u805a\u5408\uff0c\u5e76\u5b9a\u4e49\u4e86\u5f71\u54cdFedFMs\u5b9e\u73b0\u7684SHIFT\u7ef4\u5ea6\u3002", "result": "\u5c55\u793a\u4e86SHIFT\u7ef4\u5ea6\u5728XR\u5e94\u7528\u4e2d\u7684\u5177\u4f53\u8868\u73b0\uff0c\u5e76\u63d0\u51fa\u4e86\u8bc4\u4f30\u6307\u6807\u3001\u6570\u636e\u96c6\u9700\u6c42\u548c\u8bbe\u8ba1\u6743\u8861\u3002", "conclusion": "\u4e3a\u4e0b\u4e00\u4ee3XR\u7cfb\u7edf\u4e2d\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u9690\u79c1\u4fdd\u62a4\u667a\u80fd\u5960\u5b9a\u4e86\u6280\u672f\u548c\u6982\u5ff5\u57fa\u7840\u3002"}}
{"id": "2506.05701", "pdf": "https://arxiv.org/pdf/2506.05701", "abs": "https://arxiv.org/abs/2506.05701", "authors": ["Pavel Dolin", "Weizhi Li", "Gautam Dasarathy", "Visar Berisha"], "title": "Statistically Valid Post-Deployment Monitoring Should Be Standard for AI-Based Digital Health", "categories": ["cs.LG"], "comment": null, "summary": "This position paper argues that post-deployment monitoring in clinical AI is\nunderdeveloped and proposes statistically valid and label-efficient testing\nframeworks as a principled foundation for ensuring reliability and safety in\nreal-world deployment. A recent review found that only 9% of FDA-registered\nAI-based healthcare tools include a post-deployment surveillance plan. Existing\nmonitoring approaches are often manual, sporadic, and reactive, making them\nill-suited for the dynamic environments in which clinical models operate. We\ncontend that post-deployment monitoring should be grounded in label-efficient\nand statistically valid testing frameworks, offering a principled alternative\nto current practices. We use the term \"statistically valid\" to refer to methods\nthat provide explicit guarantees on error rates (e.g., Type I/II error), enable\nformal inference under pre-defined assumptions, and support\nreproducibility--features that align with regulatory requirements.\nSpecifically, we propose that the detection of changes in the data and model\nperformance degradation should be framed as distinct statistical hypothesis\ntesting problems. Grounding monitoring in statistical rigor ensures a\nreproducible and scientifically sound basis for maintaining the reliability of\nclinical AI systems. Importantly, it also opens new research directions for the\ntechnical community--spanning theory, methods, and tools for statistically\nprincipled detection, attribution, and mitigation of post-deployment model\nfailures in real-world settings.", "AI": {"tldr": "\u672c\u6587\u4e3b\u5f20\u4e34\u5e8aAI\u7684\u90e8\u7f72\u540e\u76d1\u6d4b\u4e0d\u8db3\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u7edf\u8ba1\u6709\u6548\u6027\u548c\u6807\u7b7e\u6548\u7387\u7684\u6d4b\u8bd5\u6846\u67b6\uff0c\u4ee5\u786e\u4fdd\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u53ef\u9760\u6027\u548c\u5b89\u5168\u6027\u3002", "motivation": "\u5f53\u524d\u4e34\u5e8aAI\u7684\u90e8\u7f72\u540e\u76d1\u6d4b\u8ba1\u5212\u4e0d\u8db3\uff08\u4ec59%\u7684FDA\u6ce8\u518c\u5de5\u5177\u5305\u542b\u6b64\u7c7b\u8ba1\u5212\uff09\uff0c\u4e14\u73b0\u6709\u65b9\u6cd5\u591a\u4e3a\u624b\u52a8\u3001\u96f6\u661f\u548c\u53cd\u5e94\u5f0f\uff0c\u65e0\u6cd5\u9002\u5e94\u52a8\u6001\u73af\u5883\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u7edf\u8ba1\u5047\u8bbe\u68c0\u9a8c\u7684\u6846\u67b6\uff0c\u5c06\u6570\u636e\u53d8\u5316\u548c\u6a21\u578b\u6027\u80fd\u9000\u5316\u4f5c\u4e3a\u72ec\u7acb\u7684\u7edf\u8ba1\u95ee\u9898\u5904\u7406\uff0c\u786e\u4fdd\u79d1\u5b66\u6027\u548c\u53ef\u91cd\u590d\u6027\u3002", "result": "\u8be5\u65b9\u6cd5\u4e3a\u4e34\u5e8aAI\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u79d1\u5b66\u57fa\u7840\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u7edf\u8ba1\u4e25\u8c28\u7684\u76d1\u6d4b\u6846\u67b6\u662f\u786e\u4fdd\u4e34\u5e8aAI\u7cfb\u7edf\u53ef\u9760\u6027\u7684\u5173\u952e\uff0c\u5e76\u4e3a\u6280\u672f\u793e\u533a\u63d0\u4f9b\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2506.05702", "pdf": "https://arxiv.org/pdf/2506.05702", "abs": "https://arxiv.org/abs/2506.05702", "authors": ["Chaofan Pan", "Jiafen Liu", "Yanhua Li", "Linbo Xiong", "Fan Min", "Wei Wei", "Xin Yang"], "title": "Action-Adaptive Continual Learning: Enabling Policy Generalization under Dynamic Action Spaces", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Continual Learning (CL) is a powerful tool that enables agents to learn a\nsequence of tasks, accumulating knowledge learned in the past and using it for\nproblem-solving or future task learning. However, existing CL methods often\nassume that the agent's capabilities remain static within dynamic environments,\nwhich doesn't reflect real-world scenarios where capabilities dynamically\nchange. This paper introduces a new and realistic problem: Continual Learning\nwith Dynamic Capabilities (CL-DC), posing a significant challenge for CL\nagents: How can policy generalization across different action spaces be\nachieved? Inspired by the cortical functions, we propose an Action-Adaptive\nContinual Learning framework (AACL) to address this challenge. Our framework\ndecouples the agent's policy from the specific action space by building an\naction representation space. For a new action space, the encoder-decoder of\naction representations is adaptively fine-tuned to maintain a balance between\nstability and plasticity. Furthermore, we release a benchmark based on three\nenvironments to validate the effectiveness of methods for CL-DC. Experimental\nresults demonstrate that our framework outperforms popular methods by\ngeneralizing the policy across action spaces.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u95ee\u9898CL-DC\uff08\u52a8\u6001\u80fd\u529b\u7684\u6301\u7eed\u5b66\u4e60\uff09\uff0c\u5e76\u63d0\u51fa\u4e86AACL\u6846\u67b6\u6765\u89e3\u51b3\u7b56\u7565\u5728\u4e0d\u540c\u52a8\u4f5c\u7a7a\u95f4\u4e2d\u7684\u6cdb\u5316\u95ee\u9898\u3002", "motivation": "\u73b0\u6709CL\u65b9\u6cd5\u5047\u8bbe\u667a\u80fd\u4f53\u80fd\u529b\u5728\u52a8\u6001\u73af\u5883\u4e2d\u4e0d\u53d8\uff0c\u4e0d\u7b26\u5408\u73b0\u5b9e\u573a\u666f\u3002", "method": "\u63d0\u51faAACL\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u52a8\u4f5c\u8868\u793a\u7a7a\u95f4\u89e3\u8026\u7b56\u7565\u4e0e\u5177\u4f53\u52a8\u4f5c\u7a7a\u95f4\uff0c\u5e76\u81ea\u9002\u5e94\u8c03\u6574\u7f16\u7801\u5668-\u89e3\u7801\u5668\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eAACL\u5728\u4e09\u4e2a\u73af\u5883\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u7b56\u7565\u7684\u8de8\u52a8\u4f5c\u7a7a\u95f4\u6cdb\u5316\u3002", "conclusion": "AACL\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86CL-DC\u95ee\u9898\uff0c\u5e73\u8861\u4e86\u7a33\u5b9a\u6027\u548c\u53ef\u5851\u6027\u3002"}}
{"id": "2506.05710", "pdf": "https://arxiv.org/pdf/2506.05710", "abs": "https://arxiv.org/abs/2506.05710", "authors": ["Xiucheng Wang", "Honggang Jia", "Nan Cheng", "Dusit Niyato"], "title": "Latent Diffusion Model Based Denoising Receiver for 6G Semantic Communication: From Stochastic Differential Theory to Application", "categories": ["cs.LG", "cs.IT", "cs.SY", "eess.SY", "math.IT"], "comment": null, "summary": "In this paper, a novel semantic communication framework empowered by\ngenerative artificial intelligence (GAI) is proposed, specifically leveraging\nthe capabilities of diffusion models (DMs). A rigorous theoretical foundation\nis established based on stochastic differential equations (SDEs), which\nelucidates the denoising properties of DMs in mitigating additive white\nGaussian noise (AWGN) in latent semantic representations. Crucially, a\nclosed-form analytical relationship between the signal-to-noise ratio (SNR) and\nthe denoising timestep is derived, enabling the optimal selection of diffusion\nparameters for any given channel condition. To address the distribution\nmismatch between the received signal and the DM's training data, a\nmathematically principled scaling mechanism is introduced, ensuring robust\nperformance across a wide range of SNRs without requiring model fine-tuning.\nBuilt upon this theoretical insight, we develop a latent diffusion model\n(LDM)-based semantic transceiver, wherein a variational autoencoder (VAE) is\nemployed for efficient semantic compression, and a pretrained DM serves as a\nuniversal denoiser. Notably, the proposed architecture is fully training-free\nat inference time, offering high modularity and compatibility with large-scale\npretrained LDMs. This design inherently supports zero-shot generalization and\nmitigates the challenges posed by out-of-distribution inputs. Extensive\nexperimental evaluations demonstrate that the proposed framework significantly\noutperforms conventional neural-network-based semantic communication baselines,\nparticularly under low SNR conditions and distributional shifts, thereby\nestablishing a promising direction for GAI-driven robust semantic transmission\nin future 6G systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\uff08GAI\uff09\u548c\u6269\u6563\u6a21\u578b\uff08DMs\uff09\u7684\u65b0\u578b\u8bed\u4e49\u901a\u4fe1\u6846\u67b6\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u5728\u9ad8\u566a\u58f0\u548c\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u8bed\u4e49\u901a\u4fe1\u65b9\u6cd5\u5728\u9ad8\u566a\u58f0\u548c\u5206\u5e03\u4e0d\u5339\u914d\u6761\u4ef6\u4e0b\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9c81\u68d2\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u57fa\u4e8e\u968f\u673a\u5fae\u5206\u65b9\u7a0b\uff08SDEs\uff09\u5efa\u7acb\u7406\u8bba\u6846\u67b6\uff0c\u63a8\u5bfcSNR\u4e0e\u53bb\u566a\u6b65\u957f\u7684\u5173\u7cfb\uff0c\u63d0\u51fa\u65e0\u9700\u5fae\u8c03\u7684\u7f29\u653e\u673a\u5236\uff0c\u5e76\u8bbe\u8ba1\u57fa\u4e8e\u6f5c\u5728\u6269\u6563\u6a21\u578b\uff08LDM\uff09\u7684\u8bed\u4e49\u6536\u53d1\u5668\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u4f4eSNR\u548c\u5206\u5e03\u504f\u79fb\u4e0b\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u795e\u7ecf\u7f51\u7edc\u57fa\u7ebf\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u672a\u67656G\u7cfb\u7edf\u4e2dGAI\u9a71\u52a8\u7684\u9c81\u68d2\u8bed\u4e49\u4f20\u8f93\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2506.05713", "pdf": "https://arxiv.org/pdf/2506.05713", "abs": "https://arxiv.org/abs/2506.05713", "authors": ["Zhan Zhuang", "Xiequn Wang", "Wei Li", "Yulong Zhang", "Qiushi Huang", "Shuhao Chen", "Xuehao Wang", "Yanbin Wei", "Yuhe Nie", "Kede Ma", "Yu Zhang", "Ying Wei"], "title": "Come Together, But Not Right Now: A Progressive Strategy to Boost Low-Rank Adaptation", "categories": ["cs.LG"], "comment": "Accepted by ICML 2025. Code link: https://github.com/zwebzone/coto", "summary": "Low-rank adaptation (LoRA) has emerged as a leading parameter-efficient\nfine-tuning technique for adapting large foundation models, yet it often locks\nadapters into suboptimal minima near their initialization. This hampers model\ngeneralization and limits downstream operators such as adapter merging and\npruning. Here, we propose CoTo, a progressive training strategy that gradually\nincreases adapters' activation probability over the course of fine-tuning. By\nstochastically deactivating adapters, CoTo encourages more balanced\noptimization and broader exploration of the loss landscape. We provide a\ntheoretical analysis showing that CoTo promotes layer-wise dropout stability\nand linear mode connectivity, and we adopt a cooperative-game approach to\nquantify each adapter's marginal contribution. Extensive experiments\ndemonstrate that CoTo consistently boosts single-task performance, enhances\nmulti-task merging accuracy, improves pruning robustness, and reduces training\noverhead, all while remaining compatible with diverse LoRA variants. Code is\navailable at https://github.com/zwebzone/coto.", "AI": {"tldr": "CoTo\u662f\u4e00\u79cd\u6e10\u8fdb\u5f0f\u8bad\u7ec3\u7b56\u7565\uff0c\u901a\u8fc7\u9010\u6b65\u589e\u52a0\u9002\u914d\u5668\u7684\u6fc0\u6d3b\u6982\u7387\uff0c\u4f18\u5316LoRA\u7684\u5fae\u8c03\u6548\u679c\uff0c\u63d0\u5347\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u548c\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "LoRA\u5728\u5fae\u8c03\u5927\u578b\u57fa\u7840\u6a21\u578b\u65f6\u5bb9\u6613\u9677\u5165\u6b21\u4f18\u89e3\uff0c\u9650\u5236\u4e86\u6a21\u578b\u6cdb\u5316\u548c\u4e0b\u6e38\u64cd\u4f5c\uff08\u5982\u9002\u914d\u5668\u5408\u5e76\u548c\u526a\u679d\uff09\u7684\u6548\u679c\u3002", "method": "\u63d0\u51faCoTo\u7b56\u7565\uff0c\u901a\u8fc7\u968f\u673a\u505c\u7528\u9002\u914d\u5668\uff0c\u4fc3\u8fdb\u66f4\u5e73\u8861\u7684\u4f18\u5316\u548c\u66f4\u5e7f\u6cdb\u7684\u635f\u5931\u7a7a\u95f4\u63a2\u7d22\u3002\u7406\u8bba\u5206\u6790\u8868\u660e\uff0cCoTo\u80fd\u63d0\u5347\u5c42\u95f4dropout\u7a33\u5b9a\u6027\u548c\u7ebf\u6027\u6a21\u5f0f\u8fde\u901a\u6027\uff0c\u5e76\u901a\u8fc7\u5408\u4f5c\u535a\u5f08\u91cf\u5316\u9002\u914d\u5668\u7684\u8fb9\u9645\u8d21\u732e\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cCoTo\u663e\u8457\u63d0\u5347\u4e86\u5355\u4efb\u52a1\u6027\u80fd\u3001\u591a\u4efb\u52a1\u5408\u5e76\u51c6\u786e\u6027\u3001\u526a\u679d\u9c81\u68d2\u6027\uff0c\u5e76\u51cf\u5c11\u4e86\u8bad\u7ec3\u5f00\u9500\u3002", "conclusion": "CoTo\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u517c\u5bb9\u6027\u5f3a\u7684LoRA\u6539\u8fdb\u7b56\u7565\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u53d8\u4f53\u3002"}}
{"id": "2506.05716", "pdf": "https://arxiv.org/pdf/2506.05716", "abs": "https://arxiv.org/abs/2506.05716", "authors": ["Adrian Ly", "Richard Dazeley", "Peter Vamplew", "Francisco Cruz", "Sunil Aryal"], "title": "Ensemble Elastic DQN: A novel multi-step ensemble approach to address overestimation in deep value-based reinforcement learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "While many algorithmic extensions to Deep Q-Networks (DQN) have been\nproposed, there remains limited understanding of how different improvements\ninteract. In particular, multi-step and ensemble style extensions have shown\npromise in reducing overestimation bias, thereby improving sample efficiency\nand algorithmic stability. In this paper, we introduce a novel algorithm called\nEnsemble Elastic Step DQN (EEDQN), which unifies ensembles with elastic step\nupdates to stabilise algorithmic performance. EEDQN is designed to address two\nmajor challenges in deep reinforcement learning: overestimation bias and sample\nefficiency. We evaluated EEDQN against standard and ensemble DQN variants\nacross the MinAtar benchmark, a set of environments that emphasise behavioral\nlearning while reducing representational complexity. Our results show that\nEEDQN achieves consistently robust performance across all tested environments,\noutperforming baseline DQN methods and matching or exceeding state-of-the-art\nensemble DQNs in final returns on most of the MinAtar environments. These\nfindings highlight the potential of systematically combining algorithmic\nimprovements and provide evidence that ensemble and multi-step methods, when\ncarefully integrated, can yield substantial gains.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aEEDQN\u7684\u65b0\u7b97\u6cd5\uff0c\u7ed3\u5408\u4e86\u96c6\u6210\u5b66\u4e60\u548c\u5f39\u6027\u6b65\u957f\u66f4\u65b0\uff0c\u4ee5\u89e3\u51b3\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u9ad8\u4f30\u504f\u5dee\u548c\u6837\u672c\u6548\u7387\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u5bf9DQN\u7684\u4e0d\u540c\u6539\u8fdb\u65b9\u6cd5\u4e4b\u95f4\u7684\u4ea4\u4e92\u7406\u89e3\u6709\u9650\uff0c\u5c24\u5176\u662f\u591a\u6b65\u548c\u96c6\u6210\u65b9\u6cd5\u5728\u51cf\u5c11\u9ad8\u4f30\u504f\u5dee\u65b9\u9762\u8868\u73b0\u51fa\u6f5c\u529b\u3002", "method": "EEDQN\u901a\u8fc7\u7ed3\u5408\u96c6\u6210\u5b66\u4e60\u548c\u5f39\u6027\u6b65\u957f\u66f4\u65b0\u6765\u7a33\u5b9a\u7b97\u6cd5\u6027\u80fd\uff0c\u5e76\u5728MinAtar\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8bc4\u4f30\u5176\u6548\u679c\u3002", "result": "EEDQN\u5728\u6240\u6709\u6d4b\u8bd5\u73af\u5883\u4e2d\u8868\u73b0\u7a33\u5065\uff0c\u4f18\u4e8e\u57fa\u7ebfDQN\u65b9\u6cd5\uff0c\u5e76\u5728\u5927\u591a\u6570MinAtar\u73af\u5883\u4e2d\u8fbe\u5230\u6216\u8d85\u8fc7\u6700\u5148\u8fdb\u7684\u96c6\u6210DQN\u3002", "conclusion": "\u7cfb\u7edf\u7ed3\u5408\u7b97\u6cd5\u6539\u8fdb\u5177\u6709\u6f5c\u529b\uff0c\u96c6\u6210\u548c\u591a\u6b65\u65b9\u6cd5\u7684\u7cbe\u5fc3\u6574\u5408\u53ef\u4ee5\u5e26\u6765\u663e\u8457\u6536\u76ca\u3002"}}
{"id": "2506.05718", "pdf": "https://arxiv.org/pdf/2506.05718", "abs": "https://arxiv.org/abs/2506.05718", "authors": ["Pascal Jr Tikeng Notsawo", "Guillaume Dumas", "Guillaume Rabusseau"], "title": "Grokking Beyond the Euclidean Norm of Model Parameters", "categories": ["cs.LG", "cs.AI", "stat.ML", "I.2.6"], "comment": "67 pages, 35 figures. Forty-second International Conference on\n  Machine Learning (ICML), 2025", "summary": "Grokking refers to a delayed generalization following overfitting when\noptimizing artificial neural networks with gradient-based methods. In this\nwork, we demonstrate that grokking can be induced by regularization, either\nexplicit or implicit. More precisely, we show that when there exists a model\nwith a property $P$ (e.g., sparse or low-rank weights) that generalizes on the\nproblem of interest, gradient descent with a small but non-zero regularization\nof $P$ (e.g., $\\ell_1$ or nuclear norm regularization) results in grokking.\nThis extends previous work showing that small non-zero weight decay induces\ngrokking. Moreover, our analysis shows that over-parameterization by adding\ndepth makes it possible to grok or ungrok without explicitly using\nregularization, which is impossible in shallow cases. We further show that the\n$\\ell_2$ norm is not a reliable proxy for generalization when the model is\nregularized toward a different property $P$, as the $\\ell_2$ norm grows in many\ncases where no weight decay is used, but the model generalizes anyway. We also\nshow that grokking can be amplified solely through data selection, with any\nother hyperparameter fixed.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u901a\u8fc7\u6b63\u5219\u5316\uff08\u663e\u5f0f\u6216\u9690\u5f0f\uff09\u8bf1\u5bfc\u795e\u7ecf\u7f51\u7edc\u5728\u68af\u5ea6\u4f18\u5316\u4e2d\u51fa\u73b0\u7684\u5ef6\u8fdf\u6cdb\u5316\u73b0\u8c61\uff08grokking\uff09\uff0c\u5e76\u5206\u6790\u4e86\u4e0d\u540c\u6b63\u5219\u5316\u65b9\u6cd5\u548c\u6a21\u578b\u53c2\u6570\u5316\u5bf9grokking\u7684\u5f71\u54cd\u3002", "motivation": "\u7814\u7a76grokking\u73b0\u8c61\u7684\u4ea7\u751f\u673a\u5236\uff0c\u5c24\u5176\u662f\u6b63\u5219\u5316\u5728\u5176\u4e2d\u7684\u4f5c\u7528\uff0c\u4ee5\u7406\u89e3\u795e\u7ecf\u7f51\u7edc\u4f18\u5316\u4e2d\u7684\u5ef6\u8fdf\u6cdb\u5316\u884c\u4e3a\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\u548c\u7406\u8bba\u5206\u6790\uff0c\u7814\u7a76\u4e0d\u540c\u6b63\u5219\u5316\u65b9\u6cd5\uff08\u5982\u2113\u2081\u6216\u6838\u8303\u6570\u6b63\u5219\u5316\uff09\u548c\u6a21\u578b\u6df1\u5ea6\u5bf9grokking\u7684\u5f71\u54cd\uff0c\u5e76\u63a2\u8ba8\u6570\u636e\u9009\u62e9\u7684\u4f5c\u7528\u3002", "result": "\u53d1\u73b0\u6b63\u5219\u5316\u53ef\u4ee5\u8bf1\u5bfcgrokking\uff0c\u4e14\u6a21\u578b\u6df1\u5ea6\u548c\u7279\u5b9a\u5c5e\u6027P\u7684\u6b63\u5219\u5316\u662f\u5173\u952e\u56e0\u7d20\uff1b\u2113\u2082\u8303\u6570\u5728\u975e\u6743\u91cd\u8870\u51cf\u60c5\u51b5\u4e0b\u4e0d\u53ef\u9760\u3002", "conclusion": "\u6b63\u5219\u5316\u548c\u6a21\u578b\u53c2\u6570\u5316\u662fgrokking\u73b0\u8c61\u7684\u91cd\u8981\u9a71\u52a8\u56e0\u7d20\uff0c\u6570\u636e\u9009\u62e9\u4e5f\u80fd\u653e\u5927\u8fd9\u4e00\u73b0\u8c61\u3002"}}
{"id": "2506.05721", "pdf": "https://arxiv.org/pdf/2506.05721", "abs": "https://arxiv.org/abs/2506.05721", "authors": ["Dumindu Tissera", "Omar Awadallah", "Muhammad Umair Danish", "Ayan Sadhu", "Katarina Grolinger"], "title": "Any-Class Presence Likelihood for Robust Multi-Label Classification with Abundant Negative Data", "categories": ["cs.LG", "cs.AI", "cs.CV", "68T05 (Primary) 62H30 (Secondary)", "I.2.6; I.5.4"], "comment": null, "summary": "Multi-label Classification (MLC) assigns an instance to one or more\nnon-exclusive classes. A challenge arises when the dataset contains a large\nproportion of instances with no assigned class, referred to as negative data,\nwhich can overwhelm the learning process and hinder the accurate identification\nand classification of positive instances. Nevertheless, it is common in MLC\napplications such as industrial defect detection, agricultural disease\nidentification, and healthcare diagnosis to encounter large amounts of negative\ndata. Assigning a separate negative class to these instances further\ncomplicates the learning objective and introduces unnecessary redundancies. To\naddress this challenge, we redesign standard MLC loss functions by deriving a\nlikelihood of any class being present, formulated by a normalized weighted\ngeometric mean of the predicted class probabilities. We introduce a\nregularization parameter that controls the relative contribution of the absent\nclass probabilities to the any-class presence likelihood in positive instances.\nThe any-class presence likelihood complements the multi-label learning by\nencouraging the network to become more aware of implicit positive instances and\nimprove the label classification within those positive instances. Experiments\non large-scale datasets with negative data: SewerML, modified COCO, and\nChestX-ray14, across various networks and base loss functions show that our\nloss functions consistently improve MLC performance of their standard loss\ncounterparts, achieving gains of up to 6.01 percentage points in F1, 8.06 in\nF2, and 3.11 in mean average precision, all without additional parameters or\ncomputational complexity. Code available at:\nhttps://github.com/ML-for-Sensor-Data-Western/gmean-mlc", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u591a\u6807\u7b7e\u5206\u7c7b\uff08MLC\uff09\u635f\u5931\u51fd\u6570\uff0c\u901a\u8fc7\u5f52\u4e00\u5316\u52a0\u6743\u51e0\u4f55\u5e73\u5747\u9884\u6d4b\u7c7b\u522b\u6982\u7387\uff0c\u89e3\u51b3\u4e86\u8d1f\u6570\u636e\u8fc7\u591a\u5bf9\u5b66\u4e60\u8fc7\u7a0b\u7684\u5e72\u6270\u95ee\u9898\u3002", "motivation": "\u5728\u591a\u6807\u7b7e\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u8d1f\u6570\u636e\uff08\u672a\u5206\u914d\u7c7b\u522b\u7684\u5b9e\u4f8b\uff09\u8fc7\u591a\u4f1a\u5e72\u6270\u5b66\u4e60\u8fc7\u7a0b\uff0c\u5f71\u54cd\u6b63\u5b9e\u4f8b\u7684\u51c6\u786e\u5206\u7c7b\u3002", "method": "\u91cd\u65b0\u8bbe\u8ba1\u6807\u51c6MLC\u635f\u5931\u51fd\u6570\uff0c\u5f15\u5165\u5f52\u4e00\u5316\u52a0\u6743\u51e0\u4f55\u5e73\u5747\u9884\u6d4b\u7c7b\u522b\u6982\u7387\uff0c\u5e76\u6dfb\u52a0\u6b63\u5219\u5316\u53c2\u6570\u63a7\u5236\u8d1f\u7c7b\u6982\u7387\u5bf9\u6b63\u5b9e\u4f8b\u7684\u5f71\u54cd\u3002", "result": "\u5728\u591a\u4e2a\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0c\u6539\u8fdb\u7684\u635f\u5931\u51fd\u6570\u663e\u8457\u63d0\u5347\u4e86MLC\u6027\u80fd\uff0cF1\u3001F2\u548c\u5e73\u5747\u7cbe\u5ea6\u5206\u522b\u63d0\u9ad8\u4e866.01\u30018.06\u548c3.11\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "\u63d0\u51fa\u7684\u635f\u5931\u51fd\u6570\u6709\u6548\u89e3\u51b3\u4e86\u8d1f\u6570\u636e\u5e72\u6270\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u591a\u6807\u7b7e\u5206\u7c7b\u6027\u80fd\uff0c\u4e14\u65e0\u9700\u989d\u5916\u53c2\u6570\u6216\u8ba1\u7b97\u590d\u6742\u5ea6\u3002"}}
{"id": "2506.05736", "pdf": "https://arxiv.org/pdf/2506.05736", "abs": "https://arxiv.org/abs/2506.05736", "authors": ["En Yu", "Jie Lu", "Guangquan Zhang"], "title": "Generalized Incremental Learning under Concept Drift across Evolving Data Streams", "categories": ["cs.LG", "cs.AI"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Real-world data streams exhibit inherent non-stationarity characterized by\nconcept drift, posing significant challenges for adaptive learning systems.\nWhile existing methods address isolated distribution shifts, they overlook the\ncritical co-evolution of label spaces and distributions under limited\nsupervision and persistent uncertainty. To address this, we formalize\nGeneralized Incremental Learning under Concept Drift (GILCD), characterizing\nthe joint evolution of distributions and label spaces in open-environment\nstreaming contexts, and propose a novel framework called Calibrated Source-Free\nAdaptation (CSFA). First, CSFA introduces a training-free prototype calibration\nmechanism that dynamically fuses emerging prototypes with base representations,\nenabling stable new-class identification without optimization overhead. Second,\nwe design a novel source-free adaptation algorithm, i.e., Reliable Surrogate\nGap Sharpness-aware (RSGS) minimization. It integrates sharpness-aware\nperturbation loss optimization with surrogate gap minimization, while employing\nentropy-based uncertainty filtering to discard unreliable samples. This\nmechanism ensures robust distribution alignment and mitigates generalization\ndegradation caused by uncertainties. Therefore, CSFA establishes a unified\nframework for stable adaptation to evolving semantics and distributions in\nopen-world streaming scenarios. Extensive experiments validate the superior\nperformance and effectiveness of CSFA compared to state-of-the-art approaches.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCSFA\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u5f00\u653e\u73af\u5883\u6d41\u6570\u636e\u4e2d\u7684\u6982\u5ff5\u6f02\u79fb\u95ee\u9898\uff0c\u901a\u8fc7\u539f\u578b\u6821\u51c6\u548c\u6e90\u65e0\u5173\u9002\u5e94\u7b97\u6cd5\u5b9e\u73b0\u7a33\u5b9a\u9002\u5e94\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u7684\u6570\u636e\u6d41\u5177\u6709\u975e\u5e73\u7a33\u6027\uff0c\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u89e3\u51b3\u6807\u7b7e\u7a7a\u95f4\u548c\u5206\u5e03\u7684\u8054\u5408\u6f14\u5316\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u6709\u9650\u76d1\u7763\u548c\u6301\u7eed\u4e0d\u786e\u5b9a\u6027\u4e0b\u3002", "method": "CSFA\u6846\u67b6\u5305\u62ec\u8bad\u7ec3\u65e0\u5173\u7684\u539f\u578b\u6821\u51c6\u673a\u5236\u548c\u57fa\u4e8e\u53ef\u9760\u4ee3\u7406\u95f4\u9699\u9510\u5ea6\u611f\u77e5\u6700\u5c0f\u5316\u7684\u6e90\u65e0\u5173\u9002\u5e94\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eCSFA\u5728\u5f00\u653e\u4e16\u754c\u6d41\u573a\u666f\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u5bf9\u6f14\u5316\u7684\u8bed\u4e49\u548c\u5206\u5e03\u7684\u7a33\u5b9a\u9002\u5e94\u3002", "conclusion": "CSFA\u4e3a\u5f00\u653e\u73af\u5883\u6d41\u6570\u636e\u4e2d\u7684\u6982\u5ff5\u6f02\u79fb\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u4f18\u8d8a\u7684\u6027\u80fd\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2506.05748", "pdf": "https://arxiv.org/pdf/2506.05748", "abs": "https://arxiv.org/abs/2506.05748", "authors": ["Rudransh Agnihotri", "Ananya Pandey"], "title": "Efficient Online RFT with Plug-and-Play LLM Judges: Unlocking State-of-the-Art Performance", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reward-model training is the cost bottleneck in modern Reinforcement Learning\nHuman Feedback (RLHF) pipelines, often requiring tens of billions of parameters\nand an offline preference-tuning phase. In the proposed method, a frozen,\ninstruction-tuned 7B LLM is augmented with only a one line JSON rubric and a\nrank-16 LoRA adapter (affecting just 0.8% of the model's parameters), enabling\nit to serve as a complete substitute for the previously used heavyweight\nevaluation models. The plug-and-play judge achieves 96.2% accuracy on\nRewardBench, outperforming specialized reward networks ranging from 27B to 70B\nparameters. Additionally, it allows a 7B actor to outperform the top 70B DPO\nbaseline, which scores 61.8%, by achieving 92% exact match accuracy on GSM-8K\nutilizing online PPO. Thorough ablations indicate that (i) six in context\ndemonstrations deliver the majority of the zero-to-few-shot improvements\n(+2pp), and (ii) the LoRA effectively addresses the remaining disparity,\nparticularly in the safety and adversarial Chat-Hard segments. The proposed\nmodel introduces HH-Rationales, a subset of 10,000 pairs from Anthropic\nHH-RLHF, to examine interpretability, accompanied by human generated\njustifications. GPT-4 scoring indicates that our LoRA judge attains\napproximately = 9/10 in similarity to human explanations, while zero-shot\njudges score around =5/10. These results indicate that the combination of\nprompt engineering and tiny LoRA produces a cost effective, transparent, and\neasily adjustable reward function, removing the offline phase while achieving\nnew state-of-the-art outcomes for both static evaluation and online RLHF.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f4e\u6210\u672c\u3001\u9ad8\u6548\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u901a\u8fc7\u51bb\u7ed3\u76847B LLM\u3001\u5355\u884cJSON\u89c4\u5219\u548crank-16 LoRA\u9002\u914d\u5668\uff0c\u66ff\u4ee3\u4f20\u7edf\u91cd\u578b\u5956\u52b1\u6a21\u578b\uff0c\u5728RewardBench\u4e0a\u8fbe\u523096.2%\u51c6\u786e\u7387\uff0c\u5e76\u663e\u8457\u63d0\u5347\u5728\u7ebfRLHF\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u5956\u52b1\u6a21\u578b\u8bad\u7ec3\u6210\u672c\u9ad8\u4e14\u590d\u6742\uff0c\u9700\u8981\u79bb\u7ebf\u8c03\u6574\u9636\u6bb5\uff0c\u9650\u5236\u4e86RLHF\u7684\u6548\u7387\u3002", "method": "\u4f7f\u7528\u51bb\u7ed3\u76847B LLM\uff0c\u7ed3\u5408\u5355\u884cJSON\u89c4\u5219\u548crank-16 LoRA\u9002\u914d\u5668\uff08\u4ec5\u5f71\u54cd0.8%\u53c2\u6570\uff09\uff0c\u65e0\u9700\u79bb\u7ebf\u9636\u6bb5\uff0c\u76f4\u63a5\u4f5c\u4e3a\u5956\u52b1\u6a21\u578b\u3002", "result": "\u5728RewardBench\u4e0a\u51c6\u786e\u7387\u8fbe96.2%\uff0c\u4f18\u4e8e27B-70B\u53c2\u6570\u7684\u4e13\u4e1a\u5956\u52b1\u7f51\u7edc\uff1b7B\u6a21\u578b\u5728GSM-8K\u4e0a\u4ee592%\u51c6\u786e\u7387\u8d85\u8d8a70B DPO\u57fa\u7ebf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u8f7b\u91cf\u7ea7LoRA\u548c\u63d0\u793a\u5de5\u7a0b\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u900f\u660e\u4e14\u53ef\u8c03\u7684\u5956\u52b1\u529f\u80fd\uff0c\u4e3aRLHF\u63d0\u4f9b\u4e86\u65b0\u7684\u6700\u4f18\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.05752", "pdf": "https://arxiv.org/pdf/2506.05752", "abs": "https://arxiv.org/abs/2506.05752", "authors": ["Zhongying Wang", "Thoai D. Ngo", "Hamidreza Zoraghein", "Benjamin Lucas", "Morteza Karimzadeh"], "title": "Integrating Spatiotemporal Features in LSTM for Spatially Informed COVID-19 Hospitalization Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": "36 pages, 12 figures. This is the accepted version of the article\n  published in International Journal of Geographical Information Science. DOI\n  will be added upon publication", "summary": "The COVID-19 pandemic's severe impact highlighted the need for accurate,\ntimely hospitalization forecasting to support effective healthcare planning.\nHowever, most forecasting models struggled, especially during variant surges,\nwhen they were needed most. This study introduces a novel Long Short-Term\nMemory (LSTM) framework for forecasting daily state-level incident\nhospitalizations in the United States. We present a spatiotemporal feature,\nSocial Proximity to Hospitalizations (SPH), derived from Facebook's Social\nConnectedness Index to improve forecasts. SPH serves as a proxy for interstate\npopulation interaction, capturing transmission dynamics across space and time.\nOur parallel LSTM architecture captures both short- and long-term temporal\ndependencies, and our multi-horizon ensembling strategy balances consistency\nand forecasting error. Evaluation against COVID-19 Forecast Hub ensemble models\nduring the Delta and Omicron surges reveals superiority of our model. On\naverage, our model surpasses the ensemble by 27, 42, 54, and 69\nhospitalizations per state on the $7^{th}$, $14^{th}$, $21^{st}$, and $28^{th}$\nforecast days, respectively, during the Omicron surge. Data-ablation\nexperiments confirm SPH's predictive power, highlighting its effectiveness in\nenhancing forecasting models. This research not only advances hospitalization\nforecasting but also underscores the significance of spatiotemporal features,\nsuch as SPH, in refining predictive performance in modeling the complex\ndynamics of infectious disease spread.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLSTM\u7684\u65b0\u6846\u67b6\uff0c\u7ed3\u5408\u65f6\u7a7a\u7279\u5f81SPH\uff0c\u663e\u8457\u63d0\u5347\u4e86COVID-19\u4f4f\u9662\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u5c24\u5176\u5728\u53d8\u5f02\u682a\u6d41\u884c\u671f\u95f4\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "COVID-19\u5927\u6d41\u884c\u51f8\u663e\u4e86\u51c6\u786e\u3001\u53ca\u65f6\u9884\u6d4b\u4f4f\u9662\u9700\u6c42\u7684\u91cd\u8981\u6027\uff0c\u4f46\u73b0\u6709\u6a21\u578b\u5728\u53d8\u5f02\u682a\u6fc0\u589e\u65f6\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u91c7\u7528LSTM\u6846\u67b6\uff0c\u5f15\u5165\u65f6\u7a7a\u7279\u5f81SPH\uff08\u57fa\u4e8eFacebook\u793e\u4ea4\u8fde\u63a5\u6307\u6570\uff09\uff0c\u5e76\u8bbe\u8ba1\u591a\u65f6\u95f4\u8303\u56f4\u96c6\u6210\u7b56\u7565\u3002", "result": "\u5728Delta\u548cOmicron\u6d41\u884c\u671f\u95f4\uff0c\u6a21\u578b\u9884\u6d4b\u4f18\u4e8e\u57fa\u51c6\uff0c\u5c24\u5176\u5728Omicron\u671f\u95f4\uff0c\u9884\u6d4b\u8bef\u5dee\u663e\u8457\u964d\u4f4e\u3002", "conclusion": "SPH\u65f6\u7a7a\u7279\u5f81\u663e\u8457\u63d0\u5347\u9884\u6d4b\u6027\u80fd\uff0c\u4e3a\u4f20\u67d3\u75c5\u4f20\u64ad\u5efa\u6a21\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.05755", "pdf": "https://arxiv.org/pdf/2506.05755", "abs": "https://arxiv.org/abs/2506.05755", "authors": ["Yang Li", "Zhi Chen"], "title": "FlowOE: Imitation Learning with Flow Policy from Ensemble RL Experts for Optimal Execution under Heston Volatility and Concave Market Impacts", "categories": ["cs.LG", "cs.AI", "cs.CE", "q-fin.CP", "q-fin.TR"], "comment": "3 figures, 3 algorithms, 7 tables", "summary": "Optimal execution in financial markets refers to the process of strategically\ntransacting a large volume of assets over a period to achieve the best possible\noutcome by balancing the trade-off between market impact costs and timing or\nvolatility risks. Traditional optimal execution strategies, such as static\nAlmgren-Chriss models, often prove suboptimal in dynamic financial markets.\nThis paper propose flowOE, a novel imitation learning framework based on flow\nmatching models, to address these limitations. FlowOE learns from a diverse set\nof expert traditional strategies and adaptively selects the most suitable\nexpert behavior for prevailing market conditions. A key innovation is the\nincorporation of a refining loss function during the imitation process,\nenabling flowOE not only to mimic but also to improve upon the learned expert\nactions. To the best of our knowledge, this work is the first to apply flow\nmatching models in a stochastic optimal execution problem. Empirical\nevaluations across various market conditions demonstrate that flowOE\nsignificantly outperforms both the specifically calibrated expert models and\nother traditional benchmarks, achieving higher profits with reduced risk. These\nresults underscore the practical applicability and potential of flowOE to\nenhance adaptive optimal execution.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6d41\u5339\u914d\u6a21\u578b\u7684\u6a21\u4eff\u5b66\u4e60\u6846\u67b6flowOE\uff0c\u7528\u4e8e\u4f18\u5316\u91d1\u878d\u5e02\u573a\u7684\u6267\u884c\u7b56\u7565\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u6700\u4f18\u6267\u884c\u7b56\u7565\uff08\u5982\u9759\u6001Almgren-Chriss\u6a21\u578b\uff09\u5728\u52a8\u6001\u5e02\u573a\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u7684\u65b9\u6cd5\u3002", "method": "flowOE\u901a\u8fc7\u6a21\u4eff\u591a\u79cd\u4e13\u5bb6\u7b56\u7565\u5e76\u81ea\u9002\u5e94\u9009\u62e9\u6700\u4f73\u884c\u4e3a\uff0c\u7ed3\u5408\u7cbe\u70bc\u635f\u5931\u51fd\u6570\u6539\u8fdb\u4e13\u5bb6\u884c\u4e3a\u3002", "result": "\u5b9e\u9a8c\u8868\u660eflowOE\u5728\u591a\u79cd\u5e02\u573a\u6761\u4ef6\u4e0b\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u57fa\u51c6\uff0c\u5b9e\u73b0\u66f4\u9ad8\u5229\u6da6\u548c\u66f4\u4f4e\u98ce\u9669\u3002", "conclusion": "flowOE\u5c55\u793a\u4e86\u5728\u81ea\u9002\u5e94\u6700\u4f18\u6267\u884c\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.05762", "pdf": "https://arxiv.org/pdf/2506.05762", "abs": "https://arxiv.org/abs/2506.05762", "authors": ["Yunpeng Qing", "Shuo Chen", "Yixiao Chi", "Shunyu Liu", "Sixu Lin", "Changqing Zou"], "title": "BiTrajDiff: Bidirectional Trajectory Generation with Diffusion Models for Offline Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "Recent advances in offline Reinforcement Learning (RL) have proven that\neffective policy learning can benefit from imposing conservative constraints on\npre-collected datasets. However, such static datasets often exhibit\ndistribution bias, resulting in limited generalizability. To address this\nlimitation, a straightforward solution is data augmentation (DA), which\nleverages generative models to enrich data distribution. Despite the promising\nresults, current DA techniques focus solely on reconstructing future\ntrajectories from given states, while ignoring the exploration of history\ntransitions that reach them. This single-direction paradigm inevitably hinders\nthe discovery of diverse behavior patterns, especially those leading to\ncritical states that may have yielded high-reward outcomes. In this work, we\nintroduce Bidirectional Trajectory Diffusion (BiTrajDiff), a novel DA framework\nfor offline RL that models both future and history trajectories from any\nintermediate states. Specifically, we decompose the trajectory generation task\ninto two independent yet complementary diffusion processes: one generating\nforward trajectories to predict future dynamics, and the other generating\nbackward trajectories to trace essential history transitions.BiTrajDiff can\nefficiently leverage critical states as anchors to expand into potentially\nvaluable yet underexplored regions of the state space, thereby facilitating\ndataset diversity. Extensive experiments on the D4RL benchmark suite\ndemonstrate that BiTrajDiff achieves superior performance compared to other\nadvanced DA methods across various offline RL backbones.", "AI": {"tldr": "BiTrajDiff\u662f\u4e00\u79cd\u53cc\u5411\u8f68\u8ff9\u6269\u6563\u6846\u67b6\uff0c\u901a\u8fc7\u540c\u65f6\u751f\u6210\u672a\u6765\u548c\u5386\u53f2\u8f68\u8ff9\u589e\u5f3a\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7684\u6570\u636e\u591a\u6837\u6027\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u9759\u6001\u6570\u636e\u96c6\u5b58\u5728\u5206\u5e03\u504f\u5dee\uff0c\u9650\u5236\u4e86\u6cdb\u5316\u80fd\u529b\uff0c\u800c\u73b0\u6709\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u4ec5\u5173\u6ce8\u672a\u6765\u8f68\u8ff9\u91cd\u5efa\uff0c\u5ffd\u7565\u4e86\u5386\u53f2\u8fc7\u6e21\u7684\u63a2\u7d22\u3002", "method": "\u63d0\u51faBiTrajDiff\u6846\u67b6\uff0c\u5c06\u8f68\u8ff9\u751f\u6210\u4efb\u52a1\u5206\u89e3\u4e3a\u4e24\u4e2a\u4e92\u8865\u7684\u6269\u6563\u8fc7\u7a0b\uff1a\u524d\u5411\u751f\u6210\u672a\u6765\u8f68\u8ff9\u548c\u540e\u5411\u751f\u6210\u5386\u53f2\u8f68\u8ff9\uff0c\u4ee5\u5173\u952e\u72b6\u6001\u4e3a\u951a\u70b9\u6269\u5c55\u72b6\u6001\u7a7a\u95f4\u3002", "result": "\u5728D4RL\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cBiTrajDiff\u4f18\u4e8e\u5176\u4ed6\u5148\u8fdb\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7684\u6027\u80fd\u3002", "conclusion": "BiTrajDiff\u901a\u8fc7\u53cc\u5411\u8f68\u8ff9\u6269\u6563\u6709\u6548\u589e\u5f3a\u6570\u636e\u591a\u6837\u6027\uff0c\u4e3a\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u6570\u636e\u589e\u5f3a\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.05764", "pdf": "https://arxiv.org/pdf/2506.05764", "abs": "https://arxiv.org/abs/2506.05764", "authors": ["Haochuan", "Wang"], "title": "Exploring Microstructural Dynamics in Cryptocurrency Limit Order Books: Better Inputs Matter More Than Stacking Another Hidden Layer", "categories": ["cs.LG", "q-fin.TR"], "comment": null, "summary": "Cryptocurrency price dynamics are driven largely by microstructural supply\ndemand imbalances in the limit order book (LOB), yet the highly noisy nature of\nLOB data complicates the signal extraction process. Prior research has\ndemonstrated that deep-learning architectures can yield promising predictive\nperformance on pre-processed equity and futures LOB data, but they often treat\nmodel complexity as an unqualified virtue. In this paper, we aim to examine\nwhether adding extra hidden layers or parameters to \"blackbox ish\" neural\nnetworks genuinely enhances short term price forecasting, or if gains are\nprimarily attributable to data preprocessing and feature engineering. We\nbenchmark a spectrum of models from interpretable baselines, logistic\nregression, XGBoost to deep architectures (DeepLOB, Conv1D+LSTM) on BTC/USDT\nLOB snapshots sampled at 100 ms to multi second intervals using publicly\navailable Bybit data. We introduce two data filtering pipelines (Kalman,\nSavitzky Golay) and evaluate both binary (up/down) and ternary (up/flat/down)\nlabeling schemes. Our analysis compares models on out of sample accuracy,\nlatency, and robustness to noise. Results reveal that, with data preprocessing\nand hyperparameter tuning, simpler models can match and even exceed the\nperformance of more complex networks, offering faster inference and greater\ninterpretability.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u52a0\u5bc6\u8d27\u5e01\u4ef7\u683c\u9884\u6d4b\u4e2d\uff0c\u590d\u6742\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u662f\u5426\u6bd4\u7b80\u5355\u6a21\u578b\u66f4\u6709\u6548\uff0c\u53d1\u73b0\u7ecf\u8fc7\u6570\u636e\u9884\u5904\u7406\u548c\u8c03\u4f18\u540e\uff0c\u7b80\u5355\u6a21\u578b\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u9a8c\u8bc1\u5728\u52a0\u5bc6\u8d27\u5e01\u9650\u4ef7\u8ba2\u5355\u7c3f\uff08LOB\uff09\u6570\u636e\u4e2d\uff0c\u590d\u6742\u795e\u7ecf\u7f51\u7edc\u662f\u5426\u771f\u7684\u6bd4\u7b80\u5355\u6a21\u578b\u66f4\u80fd\u63d0\u5347\u77ed\u671f\u4ef7\u683c\u9884\u6d4b\u80fd\u529b\uff0c\u8fd8\u662f\u6027\u80fd\u63d0\u5347\u4e3b\u8981\u6765\u81ea\u6570\u636e\u9884\u5904\u7406\u548c\u7279\u5f81\u5de5\u7a0b\u3002", "method": "\u901a\u8fc7\u5bf9\u6bd4\u4e00\u7cfb\u5217\u6a21\u578b\uff08\u4ece\u903b\u8f91\u56de\u5f52\u3001XGBoost\u5230\u6df1\u5ea6\u67b6\u6784\u5982DeepLOB\u548cConv1D+LSTM\uff09\uff0c\u5e76\u5f15\u5165\u4e24\u79cd\u6570\u636e\u8fc7\u6ee4\u7ba1\u9053\uff08\u5361\u5c14\u66fc\u6ee4\u6ce2\u548cSavitzky-Golay\uff09\uff0c\u8bc4\u4f30\u4e86\u4e8c\u5143\u548c\u4e09\u5143\u6807\u7b7e\u65b9\u6848\u7684\u6027\u80fd\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u7ecf\u8fc7\u6570\u636e\u9884\u5904\u7406\u548c\u8d85\u53c2\u6570\u8c03\u4f18\u540e\uff0c\u7b80\u5355\u6a21\u578b\u7684\u8868\u73b0\u53ef\u4ee5\u5339\u914d\u751a\u81f3\u8d85\u8d8a\u590d\u6742\u7f51\u7edc\uff0c\u540c\u65f6\u63d0\u4f9b\u66f4\u5feb\u7684\u63a8\u7406\u901f\u5ea6\u548c\u66f4\u9ad8\u7684\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\u7ed3\u8bba\uff0c\u5728\u52a0\u5bc6\u8d27\u5e01\u4ef7\u683c\u9884\u6d4b\u4e2d\uff0c\u7b80\u5355\u6a21\u578b\u7ecf\u8fc7\u4f18\u5316\u540e\u53ef\u80fd\u6bd4\u590d\u6742\u6a21\u578b\u66f4\u5177\u4f18\u52bf\uff0c\u5c24\u5176\u662f\u5728\u901f\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u3002"}}
{"id": "2506.05768", "pdf": "https://arxiv.org/pdf/2506.05768", "abs": "https://arxiv.org/abs/2506.05768", "authors": ["Wenyu Zhu", "Jianhui Wang", "Bowen Gao", "Yinjun Jia", "Haichuan Tan", "Ya-Qin Zhang", "Wei-Ying Ma", "Yanyan Lan"], "title": "AANet: Virtual Screening under Structural Uncertainty via Alignment and Aggregation", "categories": ["cs.LG", "q-bio.BM"], "comment": null, "summary": "Virtual screening (VS) is a critical component of modern drug discovery, yet\nmost existing methods--whether physics-based or deep learning-based--are\ndeveloped around holo protein structures with known ligand-bound pockets.\nConsequently, their performance degrades significantly on apo or predicted\nstructures such as those from AlphaFold2, which are more representative of\nreal-world early-stage drug discovery, where pocket information is often\nmissing. In this paper, we introduce an alignment-and-aggregation framework to\nenable accurate virtual screening under structural uncertainty. Our method\ncomprises two core components: (1) a tri-modal contrastive learning module that\naligns representations of the ligand, the holo pocket, and cavities detected\nfrom structures, thereby enhancing robustness to pocket localization error; and\n(2) a cross-attention based adapter for dynamically aggregating candidate\nbinding sites, enabling the model to learn from activity data even without\nprecise pocket annotations. We evaluated our method on a newly curated\nbenchmark of apo structures, where it significantly outperforms\nstate-of-the-art methods in blind apo setting, improving the early enrichment\nfactor (EF1%) from 11.75 to 37.19. Notably, it also maintains strong\nperformance on holo structures. These results demonstrate the promise of our\napproach in advancing first-in-class drug discovery, particularly in scenarios\nlacking experimentally resolved protein-ligand complexes.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5bf9\u9f50\u548c\u805a\u5408\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u7ed3\u6784\u4e0d\u786e\u5b9a\u6027\u4e0b\u8fdb\u884c\u51c6\u786e\u7684\u865a\u62df\u7b5b\u9009\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5728apo\u7ed3\u6784\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u865a\u62df\u7b5b\u9009\u65b9\u6cd5\u4f9d\u8d56\u5df2\u77e5\u914d\u4f53\u7ed3\u5408\u53e3\u888b\u7684holo\u7ed3\u6784\uff0c\u800c\u5728\u65e9\u671f\u836f\u7269\u53d1\u73b0\u4e2d\u66f4\u5e38\u89c1\u7684apo\u6216\u9884\u6d4b\u7ed3\u6784\uff08\u5982AlphaFold2\u751f\u6210\uff09\u6027\u80fd\u8f83\u5dee\u3002", "method": "\u91c7\u7528\u4e09\u6a21\u6001\u5bf9\u6bd4\u5b66\u4e60\u6a21\u5757\u5bf9\u9f50\u914d\u4f53\u3001holo\u53e3\u888b\u548c\u68c0\u6d4b\u5230\u7684\u7a7a\u8154\u8868\u793a\uff0c\u5e76\u901a\u8fc7\u8de8\u6ce8\u610f\u529b\u9002\u914d\u5668\u52a8\u6001\u805a\u5408\u5019\u9009\u7ed3\u5408\u4f4d\u70b9\u3002", "result": "\u5728apo\u7ed3\u6784\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cEF1%\u4ece11.75\u63d0\u5347\u81f337.19\uff0c\u540c\u65f6\u5728holo\u7ed3\u6784\u4e0a\u4fdd\u6301\u9ad8\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u7f3a\u4e4f\u5b9e\u9a8c\u89e3\u6790\u86cb\u767d-\u914d\u4f53\u590d\u5408\u7269\u7684\u60c5\u51b5\u4e0b\uff0c\u6709\u671b\u63a8\u52a8\u9996\u521b\u836f\u7269\u53d1\u73b0\u3002"}}
{"id": "2506.05774", "pdf": "https://arxiv.org/pdf/2506.05774", "abs": "https://arxiv.org/abs/2506.05774", "authors": ["Tuomas Oikarinen", "Ge Yan", "Tsui-Wei Weng"], "title": "Evaluating Neuron Explanations: A Unified Framework with Sanity Checks", "categories": ["cs.LG"], "comment": "Published at ICML 2025", "summary": "Understanding the function of individual units in a neural network is an\nimportant building block for mechanistic interpretability. This is often done\nby generating a simple text explanation of the behavior of individual neurons\nor units. For these explanations to be useful, we must understand how reliable\nand truthful they are. In this work we unify many existing explanation\nevaluation methods under one mathematical framework. This allows us to compare\nexisting evaluation metrics, understand the evaluation pipeline with increased\nclarity and apply existing statistical methods on the evaluation. In addition,\nwe propose two simple sanity checks on the evaluation metrics and show that\nmany commonly used metrics fail these tests and do not change their score after\nmassive changes to the concept labels. Based on our experimental and\ntheoretical results, we propose guidelines that future evaluations should\nfollow and identify a set of reliable evaluation metrics.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6570\u5b66\u6846\u67b6\u6765\u8bc4\u4f30\u795e\u7ecf\u7f51\u7edc\u5355\u5143\u89e3\u91ca\u7684\u53ef\u9760\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e24\u4e2a\u7b80\u5355\u7684\u68c0\u9a8c\u65b9\u6cd5\uff0c\u53d1\u73b0\u8bb8\u591a\u5e38\u7528\u6307\u6807\u4e0d\u53ef\u9760\uff0c\u6700\u540e\u63d0\u51fa\u4e86\u672a\u6765\u8bc4\u4f30\u7684\u6307\u5357\u548c\u53ef\u9760\u6307\u6807\u3002", "motivation": "\u7406\u89e3\u795e\u7ecf\u7f51\u7edc\u4e2d\u5355\u4e2a\u5355\u5143\u7684\u529f\u80fd\u662f\u673a\u5236\u53ef\u89e3\u91ca\u6027\u7684\u91cd\u8981\u57fa\u7840\uff0c\u4f46\u73b0\u6709\u89e3\u91ca\u7684\u53ef\u9760\u6027\u548c\u771f\u5b9e\u6027\u9700\u8981\u8bc4\u4f30\u3002", "method": "\u7edf\u4e00\u73b0\u6709\u89e3\u91ca\u8bc4\u4f30\u65b9\u6cd5\u4e3a\u4e00\u4e2a\u6570\u5b66\u6846\u67b6\uff0c\u6bd4\u8f83\u73b0\u6709\u6307\u6807\uff0c\u5e76\u63d0\u51fa\u4e24\u4e2a\u68c0\u9a8c\u65b9\u6cd5\u3002", "result": "\u8bb8\u591a\u5e38\u7528\u8bc4\u4f30\u6307\u6807\u5728\u6982\u5ff5\u6807\u7b7e\u53d1\u751f\u5de8\u5927\u53d8\u5316\u65f6\u5f97\u5206\u4e0d\u53d8\uff0c\u4e0d\u53ef\u9760\u3002", "conclusion": "\u63d0\u51fa\u4e86\u672a\u6765\u8bc4\u4f30\u5e94\u9075\u5faa\u7684\u6307\u5357\uff0c\u5e76\u786e\u5b9a\u4e86\u4e00\u7ec4\u53ef\u9760\u7684\u8bc4\u4f30\u6307\u6807\u3002"}}
{"id": "2506.05791", "pdf": "https://arxiv.org/pdf/2506.05791", "abs": "https://arxiv.org/abs/2506.05791", "authors": ["Yuki Takezawa", "Xiaowen Jiang", "Anton Rodomanov", "Sebastian U. Stich"], "title": "Exploiting Similarity for Computation and Communication-Efficient Decentralized Optimization", "categories": ["cs.LG", "math.OC"], "comment": "ICML 2025", "summary": "Reducing communication complexity is critical for efficient decentralized\noptimization. The proximal decentralized optimization (PDO) framework is\nparticularly appealing, as methods within this framework can exploit functional\nsimilarity among nodes to reduce communication rounds. Specifically, when local\nfunctions at different nodes are similar, these methods achieve faster\nconvergence with fewer communication steps. However, existing PDO methods often\nrequire highly accurate solutions to subproblems associated with the proximal\noperator, resulting in significant computational overhead. In this work, we\npropose the Stabilized Proximal Decentralized Optimization (SPDO) method, which\nachieves state-of-the-art communication and computational complexities within\nthe PDO framework. Additionally, we refine the analysis of existing PDO methods\nby relaxing subproblem accuracy requirements and leveraging average functional\nsimilarity. Experimental results demonstrate that SPDO significantly\noutperforms existing methods.", "AI": {"tldr": "SPDO\u65b9\u6cd5\u901a\u8fc7\u964d\u4f4e\u5b50\u95ee\u9898\u7cbe\u5ea6\u8981\u6c42\u548c\u5229\u7528\u5e73\u5747\u529f\u80fd\u76f8\u4f3c\u6027\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u901a\u4fe1\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u51cf\u5c11\u901a\u4fe1\u590d\u6742\u5ea6\u5bf9\u5206\u5e03\u5f0f\u4f18\u5316\u81f3\u5173\u91cd\u8981\uff0c\u73b0\u6709PDO\u65b9\u6cd5\u56e0\u9700\u9ad8\u7cbe\u5ea6\u5b50\u95ee\u9898\u89e3\u800c\u8ba1\u7b97\u5f00\u9500\u5927\u3002", "method": "\u63d0\u51faSPDO\u65b9\u6cd5\uff0c\u653e\u5bbd\u5b50\u95ee\u9898\u7cbe\u5ea6\u8981\u6c42\u5e76\u5229\u7528\u5e73\u5747\u529f\u80fd\u76f8\u4f3c\u6027\u3002", "result": "SPDO\u5728\u901a\u4fe1\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "SPDO\u5728PDO\u6846\u67b6\u5185\u5b9e\u73b0\u4e86\u6700\u4f18\u6027\u80fd\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u4f18\u8d8a\u6027\u3002"}}
{"id": "2506.05797", "pdf": "https://arxiv.org/pdf/2506.05797", "abs": "https://arxiv.org/abs/2506.05797", "authors": ["Qianyi Chen", "Tianrun Gao", "Chenbo Jiang", "Tailin Wu"], "title": "EqCollide: Equivariant and Collision-Aware Deformable Objects Neural Simulator", "categories": ["cs.LG", "cs.CE", "cs.RO"], "comment": null, "summary": "Simulating collisions of deformable objects is a fundamental yet challenging\ntask due to the complexity of modeling solid mechanics and multi-body\ninteractions. Existing data-driven methods often suffer from lack of\nequivariance to physical symmetries, inadequate handling of collisions, and\nlimited scalability. Here we introduce EqCollide, the first end-to-end\nequivariant neural fields simulator for deformable objects and their\ncollisions. We propose an equivariant encoder to map object geometry and\nvelocity into latent control points. A subsequent equivariant Graph Neural\nNetwork-based Neural Ordinary Differential Equation models the interactions\namong control points via collision-aware message passing. To reconstruct\nvelocity fields, we query a neural field conditioned on control point features,\nenabling continuous and resolution-independent motion predictions. Experimental\nresults show that EqCollide achieves accurate, stable, and scalable simulations\nacross diverse object configurations, and our model achieves 24.34% to 35.82%\nlower rollout MSE even compared with the best-performing baseline model.\nFurthermore, our model could generalize to more colliding objects and extended\ntemporal horizons, and stay robust to input transformed with group action.", "AI": {"tldr": "EqCollide\u662f\u4e00\u79cd\u7aef\u5230\u7aef\u7684\u7b49\u53d8\u795e\u7ecf\u573a\u6a21\u62df\u5668\uff0c\u7528\u4e8e\u6a21\u62df\u53ef\u53d8\u5f62\u7269\u4f53\u7684\u78b0\u649e\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u7269\u7406\u5bf9\u79f0\u6027\u3001\u78b0\u649e\u5904\u7406\u548c\u53ef\u6269\u5c55\u6027\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "\u6a21\u62df\u53ef\u53d8\u5f62\u7269\u4f53\u7684\u78b0\u649e\u662f\u4e00\u9879\u57fa\u7840\u4f46\u590d\u6742\u7684\u4efb\u52a1\uff0c\u73b0\u6709\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u5728\u7269\u7406\u5bf9\u79f0\u6027\u3001\u78b0\u649e\u5904\u7406\u548c\u53ef\u6269\u5c55\u6027\u4e0a\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7b49\u53d8\u7f16\u7801\u5668\u5c06\u7269\u4f53\u51e0\u4f55\u548c\u901f\u5ea6\u6620\u5c04\u5230\u6f5c\u5728\u63a7\u5236\u70b9\uff0c\u5e76\u901a\u8fc7\u7b49\u53d8\u56fe\u795e\u7ecf\u7f51\u7edc\u548c\u795e\u7ecfODE\u5efa\u6a21\u63a7\u5236\u70b9\u95f4\u7684\u78b0\u649e\u611f\u77e5\u4ea4\u4e92\u3002\u901f\u5ea6\u573a\u901a\u8fc7\u795e\u7ecf\u573a\u91cd\u5efa\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cEqCollide\u5728\u591a\u6837\u7269\u4f53\u914d\u7f6e\u4e0b\u5b9e\u73b0\u4e86\u51c6\u786e\u3001\u7a33\u5b9a\u548c\u53ef\u6269\u5c55\u7684\u6a21\u62df\uff0c\u5176\u6eda\u52a8MSE\u6bd4\u6700\u4f73\u57fa\u7ebf\u6a21\u578b\u4f4e24.34%\u81f335.82%\u3002", "conclusion": "EqCollide\u80fd\u591f\u6cdb\u5316\u5230\u66f4\u591a\u78b0\u649e\u7269\u4f53\u548c\u66f4\u957f\u65f6\u95f4\u8303\u56f4\uff0c\u5e76\u5bf9\u7fa4\u53d8\u6362\u8f93\u5165\u4fdd\u6301\u9c81\u68d2\u6027\u3002"}}
{"id": "2506.05799", "pdf": "https://arxiv.org/pdf/2506.05799", "abs": "https://arxiv.org/abs/2506.05799", "authors": ["Zeyuan Li", "Qingdao Huang"], "title": "Option Pricing Using Ensemble Learning", "categories": ["cs.LG"], "comment": null, "summary": "Ensemble learning is characterized by flexibility, high precision, and\nrefined structure. As a critical component within computational finance, option\npricing with machine learning requires both high predictive accuracy and\nreduced structural complexity-features that align well with the inherent\nadvantages of ensemble learning. This paper investigates the application of\nensemble learning to option pricing, and conducts a comparative analysis with\nclassical machine learning models to assess their performance in terms of\naccuracy, local feature extraction, and robustness to noise. A novel\nexperimental strategy is introduced, leveraging parameter transfer across\nexperiments to improve robustness and realism in financial simulations.Building\nupon this strategy, an evaluation mechanism is developed that incorporates a\nscoring strategy and a weighted evaluation strategy explicitly emphasizing the\nfoundational role of financial theory. This mechanism embodies an orderly\nintegration of theoretical finance and computational methods. In addition, the\nstudy examines the interaction between sliding window technique and noise,\nrevealing nuanced patterns that suggest a potential connection relevant to\nongoing research in machine learning and data science.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u96c6\u6210\u5b66\u4e60\u5728\u671f\u6743\u5b9a\u4ef7\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u4e0e\u7ecf\u5178\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u4e86\u6bd4\u8f83\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5b9e\u9a8c\u7b56\u7565\u548c\u8bc4\u4f30\u673a\u5236\uff0c\u5f3a\u8c03\u4e86\u91d1\u878d\u7406\u8bba\u4e0e\u8ba1\u7b97\u65b9\u6cd5\u7684\u7ed3\u5408\u3002", "motivation": "\u671f\u6743\u5b9a\u4ef7\u5728\u8ba1\u7b97\u91d1\u878d\u4e2d\u9700\u8981\u9ad8\u9884\u6d4b\u7cbe\u5ea6\u548c\u4f4e\u7ed3\u6784\u590d\u6742\u6027\uff0c\u800c\u96c6\u6210\u5b66\u4e60\u6070\u597d\u5177\u5907\u8fd9\u4e9b\u4f18\u52bf\uff0c\u56e0\u6b64\u7814\u7a76\u5176\u5e94\u7528\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u901a\u8fc7\u6bd4\u8f83\u96c6\u6210\u5b66\u4e60\u4e0e\u7ecf\u5178\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5f15\u5165\u53c2\u6570\u4f20\u9012\u5b9e\u9a8c\u7b56\u7565\uff0c\u5e76\u5f00\u53d1\u4e86\u7ed3\u5408\u8bc4\u5206\u548c\u52a0\u6743\u8bc4\u4f30\u7684\u673a\u5236\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u96c6\u6210\u5b66\u4e60\u5728\u51c6\u786e\u6027\u3001\u5c40\u90e8\u7279\u5f81\u63d0\u53d6\u548c\u6297\u566a\u6027\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u6ed1\u52a8\u7a97\u53e3\u6280\u672f\u4e0e\u566a\u58f0\u4e4b\u95f4\u7684\u5fae\u5999\u5173\u7cfb\u3002", "conclusion": "\u96c6\u6210\u5b66\u4e60\u5728\u671f\u6743\u5b9a\u4ef7\u4e2d\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u4e14\u91d1\u878d\u7406\u8bba\u4e0e\u8ba1\u7b97\u65b9\u6cd5\u7684\u7ed3\u5408\u4e3a\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2506.05801", "pdf": "https://arxiv.org/pdf/2506.05801", "abs": "https://arxiv.org/abs/2506.05801", "authors": ["Chuang Ma", "Tomoyuki Obuchi", "Toshiyuki Tanaka"], "title": "Neural Collapse in Cumulative Link Models for Ordinal Regression: An Analysis with Unconstrained Feature Model", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "A phenomenon known as ''Neural Collapse (NC)'' in deep classification tasks,\nin which the penultimate-layer features and the final classifiers exhibit an\nextremely simple geometric structure, has recently attracted considerable\nattention, with the expectation that it can deepen our understanding of how\ndeep neural networks behave. The Unconstrained Feature Model (UFM) has been\nproposed to explain NC theoretically, and there emerges a growing body of work\nthat extends NC to tasks other than classification and leverages it for\npractical applications. In this study, we investigate whether a similar\nphenomenon arises in deep Ordinal Regression (OR) tasks, via combining the\ncumulative link model for OR and UFM. We show that a phenomenon we call Ordinal\nNeural Collapse (ONC) indeed emerges and is characterized by the following\nthree properties: (ONC1) all optimal features in the same class collapse to\ntheir within-class mean when regularization is applied; (ONC2) these class\nmeans align with the classifier, meaning that they collapse onto a\none-dimensional subspace; (ONC3) the optimal latent variables (corresponding to\nlogits or preactivations in classification tasks) are aligned according to the\nclass order, and in particular, in the zero-regularization limit, a highly\nlocal and simple geometric relationship emerges between the latent variables\nand the threshold values. We prove these properties analytically within the UFM\nframework with fixed threshold values and corroborate them empirically across a\nvariety of datasets. We also discuss how these insights can be leveraged in OR,\nhighlighting the use of fixed thresholds.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u6df1\u5ea6\u5e8f\u6570\u56de\u5f52\uff08OR\uff09\u4efb\u52a1\u4e2d\u662f\u5426\u4f1a\u51fa\u73b0\u7c7b\u4f3c\u201c\u795e\u7ecf\u5d29\u6e83\uff08NC\uff09\u201d\u7684\u73b0\u8c61\uff0c\u63d0\u51fa\u4e86\u201c\u5e8f\u6570\u795e\u7ecf\u5d29\u6e83\uff08ONC\uff09\u201d\u6982\u5ff5\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u4e09\u4e2a\u7279\u6027\u3002", "motivation": "\u63a2\u7d22\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5728\u5e8f\u6570\u56de\u5f52\u4efb\u52a1\u4e2d\u7684\u884c\u4e3a\u6a21\u5f0f\uff0c\u4ee5\u52a0\u6df1\u5bf9\u795e\u7ecf\u7f51\u7edc\u7684\u7406\u89e3\uff0c\u5e76\u6269\u5c55NC\u73b0\u8c61\u7684\u5e94\u7528\u8303\u56f4\u3002", "method": "\u7ed3\u5408\u7d2f\u79ef\u94fe\u63a5\u6a21\u578b\u548cUnconstrained Feature Model\uff08UFM\uff09\uff0c\u7406\u8bba\u5206\u6790ONC\u73b0\u8c61\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u53d1\u73b0ONC\u73b0\u8c61\u7684\u4e09\u4e2a\u7279\u6027\uff1a\u7c7b\u5185\u7279\u5f81\u5d29\u6e83\u3001\u7c7b\u5747\u503c\u4e0e\u5206\u7c7b\u5668\u5bf9\u9f50\u3001\u6f5c\u5728\u53d8\u91cf\u6309\u7c7b\u522b\u987a\u5e8f\u6392\u5217\u3002", "conclusion": "ONC\u73b0\u8c61\u5728\u5e8f\u6570\u56de\u5f52\u4efb\u52a1\u4e2d\u5b58\u5728\uff0c\u5176\u7279\u6027\u53ef\u7528\u4e8e\u6539\u8fdbOR\u4efb\u52a1\uff0c\u7279\u522b\u662f\u56fa\u5b9a\u9608\u503c\u7684\u4f7f\u7528\u3002"}}
{"id": "2506.05814", "pdf": "https://arxiv.org/pdf/2506.05814", "abs": "https://arxiv.org/abs/2506.05814", "authors": ["Yogesh Verma", "Amauri H. Souza", "Vikas Garg"], "title": "Positional Encoding meets Persistent Homology on Graphs", "categories": ["cs.LG", "cs.AI", "cs.ET", "cs.SI"], "comment": "Accepted at ICML 2025", "summary": "The local inductive bias of message-passing graph neural networks (GNNs)\nhampers their ability to exploit key structural information (e.g., connectivity\nand cycles). Positional encoding (PE) and Persistent Homology (PH) have emerged\nas two promising approaches to mitigate this issue. PE schemes endow GNNs with\nlocation-aware features, while PH methods enhance GNNs with multiresolution\ntopological features. However, a rigorous theoretical characterization of the\nrelative merits and shortcomings of PE and PH has remained elusive. We bridge\nthis gap by establishing that neither paradigm is more expressive than the\nother, providing novel constructions where one approach fails but the other\nsucceeds. Our insights inform the design of a novel learnable method, PiPE\n(Persistence-informed Positional Encoding), which is provably more expressive\nthan both PH and PE. PiPE demonstrates strong performance across a variety of\ntasks (e.g., molecule property prediction, graph classification, and\nout-of-distribution generalization), thereby advancing the frontiers of graph\nrepresentation learning. Code is available at\nhttps://github.com/Aalto-QuML/PIPE.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNNs\uff09\u4e2d\u6d88\u606f\u4f20\u9012\u7684\u5c40\u90e8\u5f52\u7eb3\u504f\u7f6e\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u89e3\u51b3\u65b9\u6cd5\uff1a\u4f4d\u7f6e\u7f16\u7801\uff08PE\uff09\u548c\u6301\u4e45\u540c\u8c03\uff08PH\uff09\u3002\u7814\u7a76\u53d1\u73b0\u4e24\u8005\u5728\u8868\u8fbe\u80fd\u529b\u4e0a\u65e0\u4f18\u52a3\u4e4b\u5206\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5PiPE\uff0c\u7ed3\u5408\u4e86\u4e24\u8005\u7684\u4f18\u52bf\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6027\u80fd\u4f18\u4e8ePE\u548cPH\u3002", "motivation": "\u89e3\u51b3GNNs\u56e0\u5c40\u90e8\u5f52\u7eb3\u504f\u7f6e\u800c\u65e0\u6cd5\u6709\u6548\u5229\u7528\u7ed3\u6784\u4fe1\u606f\uff08\u5982\u8fde\u901a\u6027\u548c\u5faa\u73af\uff09\u7684\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u6bd4\u8f83PE\u548cPH\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u5e76\u63d0\u51fa\u7ed3\u5408\u4e24\u8005\u7684\u65b0\u65b9\u6cd5PiPE\u3002", "result": "PiPE\u5728\u5206\u5b50\u5c5e\u6027\u9884\u6d4b\u3001\u56fe\u5206\u7c7b\u548c\u5206\u5e03\u5916\u6cdb\u5316\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "PiPE\u7ed3\u5408\u4e86PE\u548cPH\u7684\u4f18\u52bf\uff0c\u663e\u8457\u63d0\u5347\u4e86\u56fe\u8868\u793a\u5b66\u4e60\u7684\u6027\u80fd\u3002"}}
{"id": "2506.05826", "pdf": "https://arxiv.org/pdf/2506.05826", "abs": "https://arxiv.org/abs/2506.05826", "authors": ["Ngoc Bui", "Menglin Yang", "Runjin Chen", "Leonardo Neves", "Mingxuan Ju", "Rex Ying", "Neil Shah", "Tong Zhao"], "title": "Learning Along the Arrow of Time: Hyperbolic Geometry for Backward-Compatible Representation Learning", "categories": ["cs.LG"], "comment": null, "summary": "Backward compatible representation learning enables updated models to\nintegrate seamlessly with existing ones, avoiding to reprocess stored data.\nDespite recent advances, existing compatibility approaches in Euclidean space\nneglect the uncertainty in the old embedding model and force the new model to\nreconstruct outdated representations regardless of their quality, thereby\nhindering the learning process of the new model. In this paper, we propose to\nswitch perspectives to hyperbolic geometry, where we treat time as a natural\naxis for capturing a model's confidence and evolution. By lifting embeddings\ninto hyperbolic space and constraining updated embeddings to lie within the\nentailment cone of the old ones, we maintain generational consistency across\nmodels while accounting for uncertainties in the representations. To further\nenhance compatibility, we introduce a robust contrastive alignment loss that\ndynamically adjusts alignment weights based on the uncertainty of the old\nembeddings. Experiments validate the superiority of the proposed method in\nachieving compatibility, paving the way for more resilient and adaptable\nmachine learning systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u53cc\u66f2\u51e0\u4f55\u4e2d\u5b9e\u73b0\u5411\u540e\u517c\u5bb9\u8868\u793a\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u8003\u8651\u65e7\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u63d0\u5347\u65b0\u6a21\u578b\u7684\u5b66\u4e60\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\u4e2d\u7684\u517c\u5bb9\u6027\u65b9\u6cd5\u5ffd\u7565\u4e86\u65e7\u5d4c\u5165\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5f3a\u5236\u65b0\u6a21\u578b\u91cd\u5efa\u8fc7\u65f6\u7684\u8868\u793a\uff0c\u963b\u788d\u4e86\u65b0\u6a21\u578b\u7684\u5b66\u4e60\u3002", "method": "\u5c06\u5d4c\u5165\u63d0\u5347\u5230\u53cc\u66f2\u7a7a\u95f4\uff0c\u7ea6\u675f\u65b0\u5d4c\u5165\u4f4d\u4e8e\u65e7\u5d4c\u5165\u7684\u8574\u542b\u9525\u5185\uff0c\u5e76\u5f15\u5165\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u7684\u5bf9\u6bd4\u5bf9\u9f50\u635f\u5931\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u5b9e\u73b0\u517c\u5bb9\u6027\u65b9\u9762\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6784\u5efa\u66f4\u5177\u5f39\u6027\u548c\u9002\u5e94\u6027\u7684\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.05831", "pdf": "https://arxiv.org/pdf/2506.05831", "abs": "https://arxiv.org/abs/2506.05831", "authors": ["Yihan Xie", "Sijing Li", "Tianwei Lin", "Zhuonan Wang", "Chenglin Yang", "Yu Zhong", "Wenqiao Zhang", "Haoyuan Li", "Hao Jiang", "Fengda Zhang", "Qishan Chen", "Jun Xiao", "Yueting Zhuang", "Beng Chin Ooi"], "title": "Heartcare Suite: Multi-dimensional Understanding of ECG with Raw Multi-lead Signal Modeling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We present Heartcare Suite, a multimodal comprehensive framework for\nfinegrained electrocardiogram (ECG) understanding. It comprises three key\ncomponents: (i) Heartcare-220K, a high-quality, structured, and comprehensive\nmultimodal ECG dataset covering essential tasks such as disease diagnosis,\nwaveform morphology analysis, and rhythm interpretation. (ii) Heartcare-Bench,\na systematic and multi-dimensional benchmark designed to evaluate diagnostic\nintelligence and guide the optimization of Medical Multimodal Large Language\nModels (Med-MLLMs) in ECG scenarios. and (iii) HeartcareGPT with a tailored\ntokenizer Bidirectional ECG Abstract Tokenization (Beat), which compresses raw\nmulti-lead signals into semantically rich discrete tokens via duallevel vector\nquantization and query-guided bidirectional diffusion mechanism. Built upon\nHeartcare-220K, HeartcareGPT achieves strong generalization and SoTA\nperformance across multiple clinically meaningful tasks. Extensive experiments\ndemonstrate that Heartcare Suite is highly effective in advancing ECGspecific\nmultimodal understanding and evaluation. Our project is available at\nhttps://github.com/DCDmllm/Heartcare-Suite .", "AI": {"tldr": "Heartcare Suite\u662f\u4e00\u4e2a\u591a\u6a21\u6001ECG\u7406\u89e3\u6846\u67b6\uff0c\u5305\u542b\u6570\u636e\u96c6\u3001\u8bc4\u4f30\u57fa\u51c6\u548c\u6a21\u578bHeartcareGPT\uff0c\u5728\u591a\u4e2a\u4e34\u5e8a\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u63d0\u5347\u5fc3\u7535\u56fe\uff08ECG\uff09\u7684\u591a\u6a21\u6001\u7406\u89e3\u548c\u8bc4\u4f30\u80fd\u529b\uff0c\u652f\u6301\u75be\u75c5\u8bca\u65ad\u3001\u6ce2\u5f62\u5206\u6790\u548c\u8282\u5f8b\u89e3\u91ca\u7b49\u4efb\u52a1\u3002", "method": "\u6846\u67b6\u5305\u62ec\u9ad8\u8d28\u91cf\u6570\u636e\u96c6Heartcare-220K\u3001\u8bc4\u4f30\u57fa\u51c6Heartcare-Bench\u548c\u6a21\u578bHeartcareGPT\uff0c\u540e\u8005\u91c7\u7528\u5b9a\u5236\u5206\u8bcd\u5668\u548c\u53cc\u5411\u6269\u6563\u673a\u5236\u3002", "result": "HeartcareGPT\u5728\u591a\u4e2a\u4e34\u5e8a\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u5f3a\u6cdb\u5316\u80fd\u529b\u548c\u6700\u4f18\u6027\u80fd\u3002", "conclusion": "Heartcare Suite\u6709\u6548\u63a8\u52a8\u4e86ECG\u591a\u6a21\u6001\u7406\u89e3\u548c\u8bc4\u4f30\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.05857", "pdf": "https://arxiv.org/pdf/2506.05857", "abs": "https://arxiv.org/abs/2506.05857", "authors": ["Junpeng Lin", "Tian Lan", "Bo Zhang", "Ke Lin", "Dandan Miao", "Huiru He", "Jiantao Ye", "Chen Zhang", "Yan-fu Li"], "title": "Wavelet-based Disentangled Adaptive Normalization for Non-stationary Times Series Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "Forecasting non-stationary time series is a challenging task because their\nstatistical properties often change over time, making it hard for deep models\nto generalize well. Instance-level normalization techniques can help address\nshifts in temporal distribution. However, most existing methods overlook the\nmulti-component nature of time series, where different components exhibit\ndistinct non-stationary behaviors. In this paper, we propose Wavelet-based\nDisentangled Adaptive Normalization (WDAN), a model-agnostic framework designed\nto address non-stationarity in time series forecasting. WDAN uses discrete\nwavelet transforms to break down the input into low-frequency trends and\nhigh-frequency fluctuations. It then applies tailored normalization strategies\nto each part. For trend components that exhibit strong non-stationarity, we\napply first-order differencing to extract stable features used for predicting\nnormalization parameters. Extensive experiments on multiple benchmarks\ndemonstrate that WDAN consistently improves forecasting accuracy across various\nbackbone model. Code is available at this repository:\nhttps://github.com/MonBG/WDAN.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5c0f\u6ce2\u7684\u89e3\u8026\u81ea\u9002\u5e94\u5f52\u4e00\u5316\uff08WDAN\uff09\u6846\u67b6\uff0c\u7528\u4e8e\u5904\u7406\u975e\u5e73\u7a33\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u95ee\u9898\uff0c\u901a\u8fc7\u5206\u89e3\u548c\u5b9a\u5236\u5f52\u4e00\u5316\u7b56\u7565\u63d0\u5347\u9884\u6d4b\u7cbe\u5ea6\u3002", "motivation": "\u975e\u5e73\u7a33\u65f6\u95f4\u5e8f\u5217\u7684\u7edf\u8ba1\u7279\u6027\u968f\u65f6\u95f4\u53d8\u5316\uff0c\u5bfc\u81f4\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u5dee\uff0c\u73b0\u6709\u65b9\u6cd5\u672a\u5145\u5206\u8003\u8651\u65f6\u95f4\u5e8f\u5217\u7684\u591a\u7ec4\u5206\u7279\u6027\u3002", "method": "WDAN\u5229\u7528\u79bb\u6563\u5c0f\u6ce2\u53d8\u6362\u5c06\u8f93\u5165\u5206\u89e3\u4e3a\u4f4e\u9891\u8d8b\u52bf\u548c\u9ad8\u9891\u6ce2\u52a8\uff0c\u5e76\u9488\u5bf9\u4e0d\u540c\u90e8\u5206\u5e94\u7528\u5b9a\u5236\u5f52\u4e00\u5316\u7b56\u7565\uff0c\u5bf9\u5f3a\u975e\u5e73\u7a33\u8d8b\u52bf\u8fdb\u884c\u4e00\u9636\u5dee\u5206\u63d0\u53d6\u7a33\u5b9a\u7279\u5f81\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cWDAN\u663e\u8457\u63d0\u9ad8\u4e86\u4e0d\u540c\u4e3b\u5e72\u6a21\u578b\u7684\u9884\u6d4b\u51c6\u786e\u6027\u3002", "conclusion": "WDAN\u662f\u4e00\u79cd\u6a21\u578b\u65e0\u5173\u7684\u6846\u67b6\uff0c\u80fd\u6709\u6548\u5904\u7406\u975e\u5e73\u7a33\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u95ee\u9898\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2506.05869", "pdf": "https://arxiv.org/pdf/2506.05869", "abs": "https://arxiv.org/abs/2506.05869", "authors": ["Han Ji", "Yuqi Feng", "Jiahao Fan", "Yanan Sun"], "title": "Loss Functions for Predictor-based Neural Architecture Search", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Evaluation is a critical but costly procedure in neural architecture search\n(NAS). Performance predictors have been widely adopted to reduce evaluation\ncosts by directly estimating architecture performance. The effectiveness of\npredictors is heavily influenced by the choice of loss functions. While\ntraditional predictors employ regression loss functions to evaluate the\nabsolute accuracy of architectures, recent approaches have explored various\nranking-based loss functions, such as pairwise and listwise ranking losses, to\nfocus on the ranking of architecture performance. Despite their success in NAS,\nthe effectiveness and characteristics of these loss functions have not been\nthoroughly investigated. In this paper, we conduct the first comprehensive\nstudy on loss functions in performance predictors, categorizing them into three\nmain types: regression, ranking, and weighted loss functions. Specifically, we\nassess eight loss functions using a range of NAS-relevant metrics on 13 tasks\nacross five search spaces. Our results reveal that specific categories of loss\nfunctions can be effectively combined to enhance predictor-based NAS.\nFurthermore, our findings could provide practical guidance for selecting\nappropriate loss functions for various tasks. We hope this work provides\nmeaningful insights to guide the development of loss functions for\npredictor-based methods in the NAS community.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u795e\u7ecf\u67b6\u6784\u641c\u7d22\uff08NAS\uff09\u4e2d\u6027\u80fd\u9884\u6d4b\u5668\u7684\u635f\u5931\u51fd\u6570\u9009\u62e9\uff0c\u6bd4\u8f83\u4e86\u56de\u5f52\u3001\u6392\u5e8f\u548c\u52a0\u6743\u635f\u5931\u51fd\u6570\uff0c\u53d1\u73b0\u7ec4\u5408\u4f7f\u7528\u7279\u5b9a\u7c7b\u522b\u635f\u5931\u51fd\u6570\u53ef\u63d0\u5347\u9884\u6d4b\u6548\u679c\u3002", "motivation": "\u8bc4\u4f30NAS\u67b6\u6784\u6027\u80fd\u6210\u672c\u9ad8\uff0c\u73b0\u6709\u6027\u80fd\u9884\u6d4b\u5668\u7684\u6548\u679c\u53d7\u635f\u5931\u51fd\u6570\u9009\u62e9\u5f71\u54cd\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u635f\u5931\u51fd\u6570\u7279\u6027\u7684\u6df1\u5165\u7814\u7a76\u3002", "method": "\u5c06\u635f\u5931\u51fd\u6570\u5206\u4e3a\u56de\u5f52\u3001\u6392\u5e8f\u548c\u52a0\u6743\u4e09\u7c7b\uff0c\u8bc4\u4f30\u516b\u79cd\u635f\u5931\u51fd\u6570\u572813\u4e2a\u4efb\u52a1\u548c\u4e94\u4e2a\u641c\u7d22\u7a7a\u95f4\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u7279\u5b9a\u7c7b\u522b\u7684\u635f\u5931\u51fd\u6570\u7ec4\u5408\u53ef\u63d0\u5347\u9884\u6d4b\u6548\u679c\uff0c\u5e76\u4e3a\u4e0d\u540c\u4efb\u52a1\u9009\u62e9\u635f\u5931\u51fd\u6570\u63d0\u4f9b\u5b9e\u7528\u6307\u5bfc\u3002", "conclusion": "\u7814\u7a76\u4e3aNAS\u793e\u533a\u63d0\u4f9b\u4e86\u635f\u5931\u51fd\u6570\u9009\u62e9\u7684\u6307\u5bfc\uff0c\u5e76\u63a8\u52a8\u9884\u6d4b\u5668\u65b9\u6cd5\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2506.05871", "pdf": "https://arxiv.org/pdf/2506.05871", "abs": "https://arxiv.org/abs/2506.05871", "authors": ["Xiannan Hu", "Tianyou Zeng", "Xiaoming Yuan", "Liwei Song", "Guangyuan Zhang", "Bangzheng He"], "title": "BestServe: Serving Strategies with Optimal Goodput in Collocation and Disaggregation Architectures", "categories": ["cs.LG", "cs.DC", "cs.PF"], "comment": null, "summary": "Serving large language models (LLMs) to millions of users requires efficient\nresource allocation and parallelism strategies. It is a labor intensive\ntrial-and-error process to find such a strategy. We present BestServe, a novel\nframework for ranking serving strategies by estimating goodput under various\noperating scenarios. Supporting both collocated and disaggregated\narchitectures, BestServe leverages an inference simulator built on an adapted\nroofline model and CPU-GPU dispatch dynamics. Our framework determines the\noptimal strategy in minutes on a single standard CPU, eliminating the need for\ncostly benchmarking, while achieving predictions within a $20\\%$ error margin.\nIt appeals to be practical for rapid deployment planning because of its\nlightweight design and strong extensibility.", "AI": {"tldr": "BestServe\u662f\u4e00\u4e2a\u7528\u4e8e\u9ad8\u6548\u5206\u914d\u548c\u5e76\u884c\u5316\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u670d\u52a1\u8d44\u6e90\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u62df\u548c\u9884\u6d4b\u6027\u80fd\u5feb\u901f\u786e\u5b9a\u6700\u4f18\u7b56\u7565\u3002", "motivation": "\u4e3a\u5927\u89c4\u6a21LLM\u670d\u52a1\u63d0\u4f9b\u9ad8\u6548\u8d44\u6e90\u5206\u914d\u548c\u5e76\u884c\u7b56\u7565\uff0c\u907f\u514d\u4f20\u7edf\u8bd5\u9519\u65b9\u6cd5\u7684\u9ad8\u6210\u672c\u548c\u65f6\u95f4\u6d88\u8017\u3002", "method": "\u7ed3\u5408\u6539\u8fdb\u7684roofline\u6a21\u578b\u548cCPU-GPU\u8c03\u5ea6\u52a8\u6001\uff0c\u6784\u5efa\u63a8\u7406\u6a21\u62df\u5668\uff0c\u652f\u6301\u591a\u79cd\u67b6\u6784\uff08\u96c6\u4e2d\u5f0f\u4e0e\u5206\u5e03\u5f0f\uff09\u3002", "result": "\u5728\u5355CPU\u4e0a\u51e0\u5206\u949f\u5185\u786e\u5b9a\u6700\u4f18\u7b56\u7565\uff0c\u9884\u6d4b\u8bef\u5dee\u572820%\u4ee5\u5185\uff0c\u65e0\u9700\u6602\u8d35\u57fa\u51c6\u6d4b\u8bd5\u3002", "conclusion": "BestServe\u56e0\u5176\u8f7b\u91cf\u7ea7\u8bbe\u8ba1\u548c\u5f3a\u6269\u5c55\u6027\uff0c\u9002\u7528\u4e8e\u5feb\u901f\u90e8\u7f72\u89c4\u5212\u3002"}}
{"id": "2506.05877", "pdf": "https://arxiv.org/pdf/2506.05877", "abs": "https://arxiv.org/abs/2506.05877", "authors": ["Hang Lv", "Lianyu Hu", "Mudi Jiang", "Xinying Liu", "Zengyou He"], "title": "Interpretable Clustering Ensemble", "categories": ["cs.LG"], "comment": null, "summary": "Clustering ensemble has emerged as an important research topic in the field\nof machine learning. Although numerous methods have been proposed to improve\nclustering quality, most existing approaches overlook the need for\ninterpretability in high-stakes applications. In domains such as medical\ndiagnosis and financial risk assessment, algorithms must not only be accurate\nbut also interpretable to ensure transparent and trustworthy decision-making.\nTherefore, to fill the gap of lack of interpretable algorithms in the field of\nclustering ensemble, we propose the first interpretable clustering ensemble\nalgorithm in the literature. By treating base partitions as categorical\nvariables, our method constructs a decision tree in the original feature space\nand use the statistical association test to guide the tree building process.\nExperimental results demonstrate that our algorithm achieves comparable\nperformance to state-of-the-art (SOTA) clustering ensemble methods while\nmaintaining an additional feature of interpretability. To the best of our\nknowledge, this is the first interpretable algorithm specifically designed for\nclustering ensemble, offering a new perspective for future research in\ninterpretable clustering.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u89e3\u91ca\u7684\u805a\u7c7b\u96c6\u6210\u7b97\u6cd5\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u7684\u7a7a\u767d\u3002", "motivation": "\u5728\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\uff08\u5982\u533b\u7597\u8bca\u65ad\u548c\u91d1\u878d\u98ce\u9669\u8bc4\u4f30\uff09\uff0c\u7b97\u6cd5\u4e0d\u4ec5\u9700\u8981\u51c6\u786e\uff0c\u8fd8\u9700\u5177\u5907\u53ef\u89e3\u91ca\u6027\u4ee5\u786e\u4fdd\u900f\u660e\u548c\u53ef\u4fe1\u7684\u51b3\u7b56\u3002", "method": "\u5c06\u57fa\u7840\u5206\u533a\u89c6\u4e3a\u5206\u7c7b\u53d8\u91cf\uff0c\u5728\u539f\u59cb\u7279\u5f81\u7a7a\u95f4\u4e2d\u6784\u5efa\u51b3\u7b56\u6811\uff0c\u5e76\u901a\u8fc7\u7edf\u8ba1\u5173\u8054\u6d4b\u8bd5\u6307\u5bfc\u6811\u7684\u6784\u5efa\u8fc7\u7a0b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u7b97\u6cd5\u5728\u6027\u80fd\u4e0a\u4e0e\u6700\u5148\u8fdb\u7684\u805a\u7c7b\u96c6\u6210\u65b9\u6cd5\u76f8\u5f53\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u4e13\u4e3a\u805a\u7c7b\u96c6\u6210\u8bbe\u8ba1\u7684\u53ef\u89e3\u91ca\u7b97\u6cd5\uff0c\u4e3a\u672a\u6765\u53ef\u89e3\u91ca\u805a\u7c7b\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2506.05878", "pdf": "https://arxiv.org/pdf/2506.05878", "abs": "https://arxiv.org/abs/2506.05878", "authors": ["Andreas Bergmeister", "Manish Krishan Lal", "Stefanie Jegelka", "Suvrit Sra"], "title": "A projection-based framework for gradient-free and parallel learning", "categories": ["cs.LG"], "comment": null, "summary": "We present a feasibility-seeking approach to neural network training. This\nmathematical optimization framework is distinct from conventional\ngradient-based loss minimization and uses projection operators and iterative\nprojection algorithms. We reformulate training as a large-scale feasibility\nproblem: finding network parameters and states that satisfy local constraints\nderived from its elementary operations. Training then involves projecting onto\nthese constraints, a local operation that can be parallelized across the\nnetwork. We introduce PJAX, a JAX-based software framework that enables this\nparadigm. PJAX composes projection operators for elementary operations,\nautomatically deriving the solution operators for the feasibility problems\n(akin to autodiff for derivatives). It inherently supports GPU/TPU\nacceleration, provides a familiar NumPy-like API, and is extensible. We train\ndiverse architectures (MLPs, CNNs, RNNs) on standard benchmarks using PJAX,\ndemonstrating its functionality and generality. Our results show that this\napproach is as a compelling alternative to gradient-based training, with clear\nadvantages in parallelism and the ability to handle non-differentiable\noperations.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53ef\u884c\u6027\u641c\u7d22\u7684\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u65b9\u6cd5\uff0c\u4f7f\u7528\u6295\u5f71\u7b97\u5b50\u548c\u8fed\u4ee3\u6295\u5f71\u7b97\u6cd5\uff0c\u4e0e\u4f20\u7edf\u68af\u5ea6\u4e0b\u964d\u65b9\u6cd5\u4e0d\u540c\u3002", "motivation": "\u4f20\u7edf\u68af\u5ea6\u4e0b\u964d\u65b9\u6cd5\u5728\u5904\u7406\u4e0d\u53ef\u5fae\u64cd\u4f5c\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u4e14\u5e76\u884c\u5316\u80fd\u529b\u6709\u9650\u3002\u672c\u6587\u65e8\u5728\u63d0\u4f9b\u4e00\u79cd\u66ff\u4ee3\u65b9\u6848\uff0c\u901a\u8fc7\u53ef\u884c\u6027\u95ee\u9898\u91cd\u65b0\u5b9a\u4e49\u8bad\u7ec3\u8fc7\u7a0b\u3002", "method": "\u5c06\u8bad\u7ec3\u95ee\u9898\u8f6c\u5316\u4e3a\u5927\u89c4\u6a21\u53ef\u884c\u6027\u95ee\u9898\uff0c\u5229\u7528\u6295\u5f71\u7b97\u5b50\u9010\u5c42\u6ee1\u8db3\u5c40\u90e8\u7ea6\u675f\uff0c\u5e76\u901a\u8fc7PJAX\u6846\u67b6\u5b9e\u73b0\u81ea\u52a8\u5316\u548c\u5e76\u884c\u5316\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u79cd\u7f51\u7edc\u67b6\u6784\uff08MLP\u3001CNN\u3001RNN\uff09\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u5177\u6709\u5e76\u884c\u5316\u4f18\u52bf\u548c\u4e0d\u53ef\u5fae\u64cd\u4f5c\u5904\u7406\u80fd\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\uff0c\u5c24\u5176\u5728\u5e76\u884c\u5316\u548c\u975e\u53ef\u5fae\u64cd\u4f5c\u573a\u666f\u4e0b\u5177\u6709\u6f5c\u529b\u3002"}}
{"id": "2506.05880", "pdf": "https://arxiv.org/pdf/2506.05880", "abs": "https://arxiv.org/abs/2506.05880", "authors": ["Adrien Petralia", "Philippe Charpentier", "Youssef Kadhi", "Themis Palpanas"], "title": "NILMFormer: Non-Intrusive Load Monitoring that Accounts for Non-Stationarity", "categories": ["cs.LG", "eess.SP"], "comment": "12 pages, 8 figures. This paper appeared in ACM SIGKDD 2025", "summary": "Millions of smart meters have been deployed worldwide, collecting the total\npower consumed by individual households. Based on these data, electricity\nsuppliers offer their clients energy monitoring solutions to provide feedback\non the consumption of their individual appliances. Historically, such estimates\nhave relied on statistical methods that use coarse-grained total monthly\nconsumption and static customer data, such as appliance ownership.\nNon-Intrusive Load Monitoring (NILM) is the problem of disaggregating a\nhousehold's collected total power consumption to retrieve the consumed power\nfor individual appliances. Current state-of-the-art (SotA) solutions for NILM\nare based on deep-learning (DL) and operate on subsequences of an entire\nhousehold consumption reading. However, the non-stationary nature of real-world\nsmart meter data leads to a drift in the data distribution within each\nsegmented window, which significantly affects model performance. This paper\nintroduces NILMFormer, a Transformer-based architecture that incorporates a new\nsubsequence stationarization/de-stationarization scheme to mitigate the\ndistribution drift and that uses a novel positional encoding that relies only\non the subsequence's timestamp information. Experiments with 4 real-world\ndatasets show that NILMFormer significantly outperforms the SotA approaches.\nOur solution has been deployed as the backbone algorithm for EDF's\n(Electricit\\'e De France) consumption monitoring service, delivering detailed\ninsights to millions of customers about their individual appliances' power\nconsumption. This paper appeared in KDD 2025.", "AI": {"tldr": "NILMFormer\u662f\u4e00\u79cd\u57fa\u4e8eTransformer\u7684\u67b6\u6784\uff0c\u901a\u8fc7\u5b50\u5e8f\u5217\u5e73\u7a33\u5316/\u53bb\u5e73\u7a33\u5316\u65b9\u6848\u548c\u6570\u636e\u5206\u5e03\u6f02\u79fb\u7f13\u89e3\uff0c\u663e\u8457\u63d0\u5347\u4e86\u975e\u4fb5\u5165\u5f0f\u8d1f\u8f7d\u76d1\u6d4b\uff08NILM\uff09\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edfNILM\u65b9\u6cd5\u4f9d\u8d56\u7c97\u7c92\u5ea6\u6570\u636e\u548c\u9759\u6001\u5ba2\u6237\u4fe1\u606f\uff0c\u800c\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u56e0\u6570\u636e\u5206\u5e03\u6f02\u79fb\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u63d0\u51faNILMFormer\uff0c\u7ed3\u5408\u5b50\u5e8f\u5217\u5e73\u7a33\u5316/\u53bb\u5e73\u7a33\u5316\u65b9\u6848\u548c\u57fa\u4e8e\u65f6\u95f4\u6233\u7684\u4f4d\u7f6e\u7f16\u7801\u3002", "result": "\u57284\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5df2\u90e8\u7f72\u4e3aEDF\u7684\u80fd\u8017\u76d1\u6d4b\u670d\u52a1\u6838\u5fc3\u7b97\u6cd5\u3002", "conclusion": "NILMFormer\u6709\u6548\u89e3\u51b3\u4e86\u6570\u636e\u5206\u5e03\u6f02\u79fb\u95ee\u9898\uff0c\u4e3a\u667a\u80fd\u7535\u8868\u6570\u636e\u63d0\u4f9b\u4e86\u66f4\u7cbe\u786e\u7684\u8d1f\u8f7d\u5206\u89e3\u3002"}}
{"id": "2506.05895", "pdf": "https://arxiv.org/pdf/2506.05895", "abs": "https://arxiv.org/abs/2506.05895", "authors": ["Adrien Petralia", "Paul Boniol", "Philippe Charpentier", "Themis Palpanas"], "title": "Few Labels are all you need: A Weakly Supervised Framework for Appliance Localization in Smart-Meter Series", "categories": ["cs.LG"], "comment": "12 pages, 10 figures. This paper appeared in IEEE ICDE 2025", "summary": "Improving smart grid system management is crucial in the fight against\nclimate change, and enabling consumers to play an active role in this effort is\na significant challenge for electricity suppliers. In this regard, millions of\nsmart meters have been deployed worldwide in the last decade, recording the\nmain electricity power consumed in individual households. This data produces\nvaluable information that can help them reduce their electricity footprint;\nnevertheless, the collected signal aggregates the consumption of the different\nappliances running simultaneously in the house, making it difficult to\napprehend. Non-Intrusive Load Monitoring (NILM) refers to the challenge of\nestimating the power consumption, pattern, or on/off state activation of\nindividual appliances using the main smart meter signal. Recent methods\nproposed to tackle this task are based on a fully supervised deep-learning\napproach that requires both the aggregate signal and the ground truth of\nindividual appliance power. However, such labels are expensive to collect and\nextremely scarce in practice, as they require conducting intrusive surveys in\nhouseholds to monitor each appliance. In this paper, we introduce CamAL, a\nweakly supervised approach for appliance pattern localization that only\nrequires information on the presence of an appliance in a household to be\ntrained. CamAL merges an ensemble of deep-learning classifiers combined with an\nexplainable classification method to be able to localize appliance patterns.\nOur experimental evaluation, conducted on 4 real-world datasets, demonstrates\nthat CamAL significantly outperforms existing weakly supervised baselines and\nthat current SotA fully supervised NILM approaches require significantly more\nlabels to reach CamAL performances. The source of our experiments is available\nat: https://github.com/adrienpetralia/CamAL. This paper appeared in ICDE 2025.", "AI": {"tldr": "CamAL\u63d0\u51fa\u4e86\u4e00\u79cd\u5f31\u76d1\u7763\u65b9\u6cd5\uff0c\u7528\u4e8e\u5bb6\u7535\u6a21\u5f0f\u5b9a\u4f4d\uff0c\u4ec5\u9700\u5bb6\u7535\u5b58\u5728\u4fe1\u606f\u5373\u53ef\u8bad\u7ec3\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u667a\u80fd\u7535\u8868\u6570\u636e\u96be\u4ee5\u5206\u89e3\u4e3a\u5355\u4e2a\u5bb6\u7535\u7684\u7528\u7535\u4fe1\u606f\uff0c\u73b0\u6709\u76d1\u7763\u65b9\u6cd5\u9700\u8981\u6602\u8d35\u4e14\u7a00\u7f3a\u7684\u6807\u7b7e\u6570\u636e\u3002", "method": "CamAL\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u5206\u7c7b\u5668\u4e0e\u53ef\u89e3\u91ca\u5206\u7c7b\u65b9\u6cd5\uff0c\u4ec5\u9700\u5bb6\u7535\u5b58\u5728\u4fe1\u606f\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u57284\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0cCamAL\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5f31\u76d1\u7763\u57fa\u7ebf\uff0c\u4e14\u6027\u80fd\u63a5\u8fd1\u5168\u76d1\u7763\u65b9\u6cd5\u3002", "conclusion": "CamAL\u4e3a\u667a\u80fd\u7535\u7f51\u7ba1\u7406\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u4f4e\u6210\u672c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.05902", "pdf": "https://arxiv.org/pdf/2506.05902", "abs": "https://arxiv.org/abs/2506.05902", "authors": ["Shirui Zhou", "Jiying Yan", "Junfang Tian", "Tao Wang", "Yongfu Li", "Shiquan Zhong"], "title": "A Driving Regime-Embedded Deep Learning Framework for Modeling Intra-Driver Heterogeneity in Multi-Scale Car-Following Dynamics", "categories": ["cs.LG", "physics.soc-ph"], "comment": null, "summary": "A fundamental challenge in car-following modeling lies in accurately\nrepresenting the multi-scale complexity of driving behaviors, particularly the\nintra-driver heterogeneity where a single driver's actions fluctuate\ndynamically under varying conditions. While existing models, both conventional\nand data-driven, address behavioral heterogeneity to some extent, they often\nemphasize inter-driver heterogeneity or rely on simplified assumptions,\nlimiting their ability to capture the dynamic heterogeneity of a single driver\nunder different driving conditions. To address this gap, we propose a novel\ndata-driven car-following framework that systematically embeds discrete driving\nregimes (e.g., steady-state following, acceleration, cruising) into vehicular\nmotion predictions. Leveraging high-resolution traffic trajectory datasets, the\nproposed hybrid deep learning architecture combines Gated Recurrent Units for\ndiscrete driving regime classification with Long Short-Term Memory networks for\ncontinuous kinematic prediction, unifying discrete decision-making processes\nand continuous vehicular dynamics to comprehensively represent inter- and\nintra-driver heterogeneity. Driving regimes are identified using a bottom-up\nsegmentation algorithm and Dynamic Time Warping, ensuring robust\ncharacterization of behavioral states across diverse traffic scenarios.\nComparative analyses demonstrate that the framework significantly reduces\nprediction errors for acceleration (maximum MSE improvement reached 58.47\\%),\nspeed, and spacing metrics while reproducing critical traffic phenomena, such\nas stop-and-go wave propagation and oscillatory dynamics.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6570\u636e\u9a71\u52a8\u8ddf\u8f66\u6a21\u578b\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u79bb\u6563\u9a7e\u9a76\u72b6\u6001\u548c\u8fde\u7eed\u8fd0\u52a8\u9884\u6d4b\uff0c\u89e3\u51b3\u4e86\u5355\u9a7e\u9a76\u5458\u884c\u4e3a\u52a8\u6001\u5f02\u8d28\u6027\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u96be\u4ee5\u51c6\u786e\u6355\u6349\u5355\u9a7e\u9a76\u5458\u5728\u4e0d\u540c\u9a7e\u9a76\u6761\u4ef6\u4e0b\u7684\u52a8\u6001\u5f02\u8d28\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u5168\u9762\u7684\u65b9\u6cd5\u6765\u8868\u5f81\u9a7e\u9a76\u884c\u4e3a\u7684\u590d\u6742\u6027\u3002", "method": "\u91c7\u7528\u6df7\u5408\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\uff0c\u7ed3\u5408GRU\u8fdb\u884c\u79bb\u6563\u9a7e\u9a76\u72b6\u6001\u5206\u7c7b\u548cLSTM\u8fdb\u884c\u8fde\u7eed\u8fd0\u52a8\u9884\u6d4b\uff0c\u5e76\u4f7f\u7528\u52a8\u6001\u65f6\u95f4\u89c4\u6574\u7b97\u6cd5\u8bc6\u522b\u9a7e\u9a76\u72b6\u6001\u3002", "result": "\u6a21\u578b\u663e\u8457\u964d\u4f4e\u4e86\u52a0\u901f\u5ea6\u3001\u901f\u5ea6\u548c\u95f4\u8ddd\u7684\u9884\u6d4b\u8bef\u5dee\uff08\u6700\u5927MSE\u6539\u8fdb\u8fbe58.47%\uff09\uff0c\u5e76\u80fd\u91cd\u73b0\u5173\u952e\u4ea4\u901a\u73b0\u8c61\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u7edf\u4e00\u4e86\u79bb\u6563\u51b3\u7b56\u548c\u8fde\u7eed\u52a8\u6001\uff0c\u4e3a\u8ddf\u8f66\u5efa\u6a21\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.05912", "pdf": "https://arxiv.org/pdf/2506.05912", "abs": "https://arxiv.org/abs/2506.05912", "authors": ["Adrien Petralia", "Paul Boniol", "Philippe Charpentier", "Themis Palpanas"], "title": "DeviceScope: An Interactive App to Detect and Localize Appliance Patterns in Electricity Consumption Time Series", "categories": ["cs.LG", "eess.SP"], "comment": "4 pages, 5 figures. This paper appeared in ICDE 2025", "summary": "In recent years, electricity suppliers have installed millions of smart\nmeters worldwide to improve the management of the smart grid system. These\nmeters collect a large amount of electrical consumption data to produce\nvaluable information to help consumers reduce their electricity footprint.\nHowever, having non-expert users (e.g., consumers or sales advisors) understand\nthese data and derive usage patterns for different appliances has become a\nsignificant challenge for electricity suppliers because these data record the\naggregated behavior of all appliances. At the same time, ground-truth labels\n(which could train appliance detection and localization models) are expensive\nto collect and extremely scarce in practice. This paper introduces DeviceScope,\nan interactive tool designed to facilitate understanding smart meter data by\ndetecting and localizing individual appliance patterns within a given time\nperiod. Our system is based on CamAL (Class Activation Map-based Appliance\nLocalization), a novel weakly supervised approach for appliance localization\nthat only requires the knowledge of the existence of an appliance in a\nhousehold to be trained. This paper appeared in ICDE 2025.", "AI": {"tldr": "DeviceScope\u662f\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u5de5\u5177\uff0c\u65e8\u5728\u901a\u8fc7\u68c0\u6d4b\u548c\u5b9a\u4f4d\u7279\u5b9a\u65f6\u95f4\u6bb5\u5185\u5355\u4e2a\u7535\u5668\u7684\u7528\u7535\u6a21\u5f0f\uff0c\u5e2e\u52a9\u975e\u4e13\u4e1a\u7528\u6237\u7406\u89e3\u667a\u80fd\u7535\u8868\u6570\u636e\u3002", "motivation": "\u667a\u80fd\u7535\u8868\u6570\u636e\u8bb0\u5f55\u4e86\u6240\u6709\u7535\u5668\u7684\u805a\u5408\u884c\u4e3a\uff0c\u4f46\u975e\u4e13\u4e1a\u7528\u6237\u96be\u4ee5\u7406\u89e3\u8fd9\u4e9b\u6570\u636e\u5e76\u63d0\u53d6\u7528\u7535\u6a21\u5f0f\uff0c\u540c\u65f6\u771f\u5b9e\u6807\u7b7e\u6570\u636e\u6602\u8d35\u4e14\u7a00\u7f3a\u3002", "method": "\u57fa\u4e8eCamAL\uff08\u57fa\u4e8e\u7c7b\u6fc0\u6d3b\u56fe\u7684\u7535\u5668\u5b9a\u4f4d\uff09\uff0c\u4e00\u79cd\u65b0\u578b\u5f31\u76d1\u7763\u65b9\u6cd5\uff0c\u4ec5\u9700\u77e5\u9053\u5bb6\u5ead\u4e2d\u662f\u5426\u5b58\u5728\u67d0\u7535\u5668\u5373\u53ef\u8bad\u7ec3\u3002", "result": "DeviceScope\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u548c\u5b9a\u4f4d\u5355\u4e2a\u7535\u5668\u7684\u7528\u7535\u6a21\u5f0f\u3002", "conclusion": "DeviceScope\u4e3a\u89e3\u51b3\u667a\u80fd\u7535\u8868\u6570\u636e\u7406\u89e3\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.05918", "pdf": "https://arxiv.org/pdf/2506.05918", "abs": "https://arxiv.org/abs/2506.05918", "authors": ["Wenxuan Huo", "Qiang He", "Gang Zhu", "Weifeng Huang"], "title": "Over-PINNs: Enhancing Physics-Informed Neural Networks via Higher-Order Partial Derivative Overdetermination of PDEs", "categories": ["cs.LG"], "comment": null, "summary": "Partial differential equations (PDEs) serve as the cornerstone of\nmathematical physics. In recent years, Physics-Informed Neural Networks (PINNs)\nhave significantly reduced the dependence on large datasets by embedding\nphysical laws directly into the training of neural networks. However, when\ndealing with complex problems, the accuracy of PINNs still has room for\nimprovement. To address this issue, we introduce the Over-PINNs framework,\nwhich leverages automatic differentiation (AD) to generate higher-order\nauxiliary equations that impose additional physical constraints. These\nequations are incorporated as extra loss terms in the training process,\neffectively enhancing the model's ability to capture physical information\nthrough an \"overdetermined\" approach. Numerical results illustrate that this\nmethod exhibits strong versatility in solving various types of PDEs. It\nachieves a significant improvement in solution accuracy without incurring\nsubstantial additional computational costs.", "AI": {"tldr": "Over-PINNs\u6846\u67b6\u901a\u8fc7\u81ea\u52a8\u5fae\u5206\u751f\u6210\u9ad8\u9636\u8f85\u52a9\u65b9\u7a0b\uff0c\u589e\u5f3a\u7269\u7406\u7ea6\u675f\uff0c\u63d0\u5347PINNs\u5728\u590d\u6742\u95ee\u9898\u4e2d\u7684\u7cbe\u5ea6\u3002", "motivation": "\u5c3d\u7ba1PINNs\u901a\u8fc7\u5d4c\u5165\u7269\u7406\u5b9a\u5f8b\u51cf\u5c11\u4e86\u5bf9\u5927\u6570\u636e\u96c6\u7684\u4f9d\u8d56\uff0c\u4f46\u5728\u590d\u6742\u95ee\u9898\u4e2d\u7684\u7cbe\u5ea6\u4ecd\u6709\u63d0\u5347\u7a7a\u95f4\u3002", "method": "\u5229\u7528\u81ea\u52a8\u5fae\u5206\u751f\u6210\u9ad8\u9636\u8f85\u52a9\u65b9\u7a0b\uff0c\u4f5c\u4e3a\u989d\u5916\u635f\u5931\u9879\u52a0\u5165\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u91c7\u7528\u201c\u8d85\u5b9a\u201d\u65b9\u6cd5\u589e\u5f3a\u7269\u7406\u4fe1\u606f\u6355\u6349\u80fd\u529b\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u591a\u79cdPDE\u6c42\u89e3\u4e2d\u8868\u73b0\u51fa\u5f3a\u901a\u7528\u6027\uff0c\u663e\u8457\u63d0\u5347\u7cbe\u5ea6\u4e14\u672a\u663e\u8457\u589e\u52a0\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "Over-PINNs\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86PINNs\u7684\u7cbe\u5ea6\uff0c\u9002\u7528\u4e8e\u590d\u6742PDE\u95ee\u9898\u3002"}}
{"id": "2506.05933", "pdf": "https://arxiv.org/pdf/2506.05933", "abs": "https://arxiv.org/abs/2506.05933", "authors": ["Robbert Bosch", "Wouter van Heeswijk", "Patricia Rogetzer", "Martijn Mes"], "title": "Machine Learning Predictions for Traffic Equilibria in Road Renovation Scheduling", "categories": ["cs.LG"], "comment": "15 pages, 2 figures, submitted as conference paper to ICCL 2025", "summary": "Accurately estimating the impact of road maintenance schedules on traffic\nconditions is important because maintenance operations can substantially worsen\ncongestion if not carefully planned. Reliable estimates allow planners to avoid\nexcessive delays during periods of roadwork. Since the exact increase in\ncongestion is difficult to predict analytically, traffic simulations are\ncommonly used to assess the redistribution of the flow of traffic. However,\nwhen applied to long-term maintenance planning involving many overlapping\nprojects and scheduling alternatives, these simulations must be run thousands\nof times, resulting in a significant computational burden. This paper\ninvestigates the use of machine learning-based surrogate models to predict\nnetwork-wide congestion caused by simultaneous road renovations. We frame the\nproblem as a supervised learning task, using one-hot encodings, engineered\ntraffic features, and heuristic approximations. A range of linear,\nensemble-based, probabilistic, and neural regression models is evaluated under\nan online learning framework in which data progressively becomes available. The\nexperimental results show that the Costliest Subset Heuristic provides a\nreasonable approximation when limited training data is available, and that most\nregression models fail to outperform it, with the exception of XGBoost, which\nachieves substantially better accuracy. In overall performance, XGBoost\nsignificantly outperforms alternatives in a range of metrics, most strikingly\nMean Absolute Percentage Error (MAPE) and Pinball loss, where it achieves a\nMAPE of 11% and outperforms the next-best model by 20% and 38% respectively.\nThis modeling approach has the potential to reduce the computational burden of\nlarge-scale traffic assignment problems in maintenance planning.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5229\u7528\u673a\u5668\u5b66\u4e60\u66ff\u4ee3\u6a21\u578b\u9884\u6d4b\u9053\u8def\u7ef4\u62a4\u5bf9\u4ea4\u901a\u62e5\u5835\u7684\u5f71\u54cd\uff0cXGBoost\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u9053\u8def\u7ef4\u62a4\u8ba1\u5212\u5bf9\u4ea4\u901a\u62e5\u5835\u7684\u5f71\u54cd\u96be\u4ee5\u9884\u6d4b\uff0c\u4f20\u7edf\u6a21\u62df\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u3002", "method": "\u91c7\u7528\u76d1\u7763\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408\u591a\u79cd\u7279\u5f81\u548c\u56de\u5f52\u6a21\u578b\uff0c\u8bc4\u4f30XGBoost\u7b49\u6a21\u578b\u6027\u80fd\u3002", "result": "XGBoost\u5728MAPE\u548cPinball\u635f\u5931\u4e0a\u8868\u73b0\u6700\u4f18\uff0c\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\u3002", "conclusion": "\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u53ef\u663e\u8457\u964d\u4f4e\u5927\u89c4\u6a21\u4ea4\u901a\u5206\u914d\u95ee\u9898\u7684\u8ba1\u7b97\u8d1f\u62c5\u3002"}}
{"id": "2506.05937", "pdf": "https://arxiv.org/pdf/2506.05937", "abs": "https://arxiv.org/abs/2506.05937", "authors": ["Charmaine Barker", "Daniel Bethell", "Simos Gerasimou"], "title": "Quantifying Adversarial Uncertainty in Evidential Deep Learning using Conflict Resolution", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reliability of deep learning models is critical for deployment in high-stakes\napplications, where out-of-distribution or adversarial inputs may lead to\ndetrimental outcomes. Evidential Deep Learning, an efficient paradigm for\nuncertainty quantification, models predictions as Dirichlet distributions of a\nsingle forward pass. However, EDL is particularly vulnerable to adversarially\nperturbed inputs, making overconfident errors. Conflict-aware Evidential Deep\nLearning (C-EDL) is a lightweight post-hoc uncertainty quantification approach\nthat mitigates these issues, enhancing adversarial and OOD robustness without\nretraining. C-EDL generates diverse, task-preserving transformations per input\nand quantifies representational disagreement to calibrate uncertainty estimates\nwhen needed. C-EDL's conflict-aware prediction adjustment improves detection of\nOOD and adversarial inputs, maintaining high in-distribution accuracy and low\ncomputational overhead. Our experimental evaluation shows that C-EDL\nsignificantly outperforms state-of-the-art EDL variants and competitive\nbaselines, achieving substantial reductions in coverage for OOD data (up to\n55%) and adversarial data (up to 90%), across a range of datasets, attack\ntypes, and uncertainty metrics.", "AI": {"tldr": "Conflict-aware Evidential Deep Learning (C-EDL) \u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u540e\u5904\u7406\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u751f\u6210\u591a\u6837\u5316\u7684\u4efb\u52a1\u4fdd\u7559\u53d8\u6362\u5e76\u91cf\u5316\u8868\u5f81\u5206\u6b67\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5bf9\u6297\u6027\u548c\u5206\u5e03\u5916\u8f93\u5165\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\u7684\u53ef\u9760\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\uff08\u5982Evidential Deep Learning, EDL\uff09\u5bb9\u6613\u53d7\u5230\u5bf9\u6297\u6027\u6270\u52a8\u7684\u5f71\u54cd\uff0c\u5bfc\u81f4\u8fc7\u5ea6\u81ea\u4fe1\u7684\u9519\u8bef\u9884\u6d4b\u3002", "method": "C-EDL\u901a\u8fc7\u4e3a\u6bcf\u4e2a\u8f93\u5165\u751f\u6210\u591a\u6837\u5316\u7684\u4efb\u52a1\u4fdd\u7559\u53d8\u6362\uff0c\u5e76\u91cf\u5316\u8868\u5f81\u5206\u6b67\u6765\u6821\u51c6\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cC-EDL\u5728\u591a\u79cd\u6570\u636e\u96c6\u3001\u653b\u51fb\u7c7b\u578b\u548c\u4e0d\u786e\u5b9a\u6027\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709EDL\u53d8\u4f53\u548c\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5bf9\u5206\u5e03\u5916\u6570\u636e\u548c\u5bf9\u6297\u6027\u6570\u636e\u7684\u8986\u76d6\u7387\u5206\u522b\u964d\u4f4e\u4e8655%\u548c90%\u3002", "conclusion": "C-EDL\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u8f7b\u91cf\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u5bf9\u6297\u6027\u548c\u5206\u5e03\u5916\u8f93\u5165\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u548c\u4f4e\u8ba1\u7b97\u5f00\u9500\u3002"}}
{"id": "2506.05940", "pdf": "https://arxiv.org/pdf/2506.05940", "abs": "https://arxiv.org/abs/2506.05940", "authors": ["Andr\u00e9s Guzm\u00e1n-Cordero", "Floor Eijkelboom", "Jan-Willem van de Meent"], "title": "Exponential Family Variational Flow Matching for Tabular Data Generation", "categories": ["cs.LG"], "comment": "14 pages, 1 figure, and 9 tables; To be published in the Proceedings\n  of the Forty-Second International Conference on Machine Learning", "summary": "While denoising diffusion and flow matching have driven major advances in\ngenerative modeling, their application to tabular data remains limited, despite\nits ubiquity in real-world applications. To this end, we develop TabbyFlow, a\nvariational Flow Matching (VFM) method for tabular data generation. To apply\nVFM to data with mixed continuous and discrete features, we introduce\nExponential Family Variational Flow Matching (EF-VFM), which represents\nheterogeneous data types using a general exponential family distribution. We\nhereby obtain an efficient, data-driven objective based on moment matching,\nenabling principled learning of probability paths over mixed continuous and\ndiscrete variables. We also establish a connection between variational flow\nmatching and generalized flow matching objectives based on Bregman divergences.\nEvaluation on tabular data benchmarks demonstrates state-of-the-art performance\ncompared to baselines.", "AI": {"tldr": "TabbyFlow\u662f\u4e00\u79cd\u7528\u4e8e\u8868\u683c\u6570\u636e\u751f\u6210\u7684\u53d8\u5206\u6d41\u5339\u914d\u65b9\u6cd5\uff0c\u901a\u8fc7\u6307\u6570\u65cf\u53d8\u5206\u6d41\u5339\u914d\uff08EF-VFM\uff09\u5904\u7406\u6df7\u5408\u8fde\u7eed\u548c\u79bb\u6563\u7279\u5f81\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u6570\u636e\u9a71\u52a8\u76ee\u6807\u3002", "motivation": "\u5c3d\u7ba1\u53bb\u566a\u6269\u6563\u548c\u6d41\u5339\u914d\u5728\u751f\u6210\u5efa\u6a21\u4e2d\u53d6\u5f97\u4e86\u91cd\u5927\u8fdb\u5c55\uff0c\u4f46\u5728\u8868\u683c\u6570\u636e\u4e2d\u7684\u5e94\u7528\u4ecd\u7136\u6709\u9650\uff0c\u800c\u8868\u683c\u6570\u636e\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u975e\u5e38\u666e\u904d\u3002", "method": "\u5f00\u53d1\u4e86TabbyFlow\uff0c\u5f15\u5165EF-VFM\u65b9\u6cd5\uff0c\u5229\u7528\u6307\u6570\u65cf\u5206\u5e03\u8868\u793a\u5f02\u6784\u6570\u636e\u7c7b\u578b\uff0c\u57fa\u4e8e\u77e9\u5339\u914d\u5b9e\u73b0\u9ad8\u6548\u5b66\u4e60\u3002", "result": "\u5728\u8868\u683c\u6570\u636e\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u4f18\u4e8e\u57fa\u7ebf\u7684\u6027\u80fd\u3002", "conclusion": "TabbyFlow\u901a\u8fc7EF-VFM\u4e3a\u6df7\u5408\u6570\u636e\u7c7b\u578b\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u751f\u6210\u5efa\u6a21\u65b9\u6cd5\uff0c\u6027\u80fd\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\u3002"}}
{"id": "2506.05941", "pdf": "https://arxiv.org/pdf/2506.05941", "abs": "https://arxiv.org/abs/2506.05941", "authors": ["Luka Hobor", "Mario Brcic", "Lidija Polutnik", "Ante Kapetanovic"], "title": "Comparative Analysis of Modern Machine Learning Models for Retail Sales Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": "20 total pages, 10 pages article, 10 pages appendix, 3 figures, 24\n  tables", "summary": "Accurate forecasting is key for all business planning. When estimated sales\nare too high, brick-and-mortar retailers may incur higher costs due to unsold\ninventories, higher labor and storage space costs, etc. On the other hand, when\nforecasts underestimate the level of sales, firms experience lost sales,\nshortages, and impact on the reputation of the retailer in their relevant\nmarket. Accurate forecasting presents a competitive advantage for companies. It\nfacilitates the achievement of revenue and profit goals and execution of\npricing strategy and tactics. In this study, we provide an exhaustive\nassessment of the forecasting models applied to a high-resolution\nbrick-and-mortar retail dataset. Our forecasting framework addresses the\nproblems found in retail environments, including intermittent demand, missing\nvalues, and frequent product turnover. We compare tree-based ensembles (such as\nXGBoost and LightGBM) and state-of-the-art neural network architectures\n(including N-BEATS, NHITS, and the Temporal Fusion Transformer) across various\nexperimental settings. Our results show that localized modeling strategies\nespecially those using tree-based models on individual groups with non-imputed\ndata, consistently deliver superior forecasting accuracy and computational\nefficiency. In contrast, neural models benefit from advanced imputation\nmethods, yet still fall short in handling the irregularities typical of\nphysical retail data. These results further practical understanding for model\nselection in retail environment and highlight the significance of data\npreprocessing to improve forecast performance.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u96f6\u552e\u4e1a\u4e2d\u9ad8\u7cbe\u5ea6\u9500\u552e\u9884\u6d4b\u7684\u91cd\u8981\u6027\uff0c\u6bd4\u8f83\u4e86\u57fa\u4e8e\u6811\u7684\u96c6\u6210\u65b9\u6cd5\u548c\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u53d1\u73b0\u57fa\u4e8e\u6811\u7684\u6a21\u578b\u5728\u975e\u63d2\u8865\u6570\u636e\u4e0a\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u51c6\u786e\u7684\u9500\u552e\u9884\u6d4b\u5bf9\u96f6\u552e\u4e1a\u81f3\u5173\u91cd\u8981\uff0c\u8fc7\u9ad8\u6216\u8fc7\u4f4e\u7684\u9884\u6d4b\u90fd\u4f1a\u5e26\u6765\u6210\u672c\u6216\u58f0\u8a89\u635f\u5931\u3002\u672c\u7814\u7a76\u65e8\u5728\u8bc4\u4f30\u4e0d\u540c\u9884\u6d4b\u6a21\u578b\u5728\u96f6\u552e\u73af\u5883\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u6811\u7684\u96c6\u6210\u65b9\u6cd5\uff08\u5982XGBoost\u548cLightGBM\uff09\u548c\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff08\u5982N-BEATS\u548cTemporal Fusion Transformer\uff09\uff0c\u5728\u5305\u542b\u95f4\u6b47\u6027\u9700\u6c42\u3001\u7f3a\u5931\u503c\u548c\u9ad8\u4ea7\u54c1\u5468\u8f6c\u7387\u7684\u96f6\u552e\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u57fa\u4e8e\u6811\u7684\u6a21\u578b\u5728\u975e\u63d2\u8865\u6570\u636e\u4e0a\u8868\u73b0\u66f4\u4f18\uff0c\u800c\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u9700\u8981\u9ad8\u7ea7\u63d2\u8865\u65b9\u6cd5\u4f46\u4ecd\u96be\u4ee5\u5904\u7406\u96f6\u552e\u6570\u636e\u7684\u590d\u6742\u6027\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u6570\u636e\u9884\u5904\u7406\u7684\u91cd\u8981\u6027\uff0c\u5e76\u4e3a\u96f6\u552e\u73af\u5883\u4e2d\u7684\u6a21\u578b\u9009\u62e9\u63d0\u4f9b\u4e86\u5b9e\u8df5\u6307\u5bfc\u3002"}}
{"id": "2506.05942", "pdf": "https://arxiv.org/pdf/2506.05942", "abs": "https://arxiv.org/abs/2506.05942", "authors": ["Samuele Salti", "Andrea Pinto", "Alessandro Lanza", "Serena Morigi"], "title": "Additive decomposition of one-dimensional signals using Transformers", "categories": ["cs.LG"], "comment": "Under consideration at Pattern Recognition Letters", "summary": "One-dimensional signal decomposition is a well-established and widely used\ntechnique across various scientific fields. It serves as a highly valuable\npre-processing step for data analysis. While traditional decomposition\ntechniques often rely on mathematical models, recent research suggests that\napplying the latest deep learning models to this problem presents an exciting,\nunexplored area with promising potential. This work presents a novel method for\nthe additive decomposition of one-dimensional signals. We leverage the\nTransformer architecture to decompose signals into their constituent\ncomponents: piece-wise constant, smooth (low-frequency oscillatory), textured\n(high-frequency oscillatory), and a noise component. Our model, trained on\nsynthetic data, achieves excellent accuracy in modeling and decomposing input\nsignals from the same distribution, as demonstrated by the experimental\nresults.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eTransformer\u67b6\u6784\u7684\u4e00\u7ef4\u4fe1\u53f7\u5206\u89e3\u65b0\u65b9\u6cd5\uff0c\u80fd\u591f\u5c06\u4fe1\u53f7\u5206\u89e3\u4e3a\u5206\u6bb5\u5e38\u6570\u3001\u5e73\u6ed1\u3001\u7eb9\u7406\u548c\u566a\u58f0\u6210\u5206\u3002", "motivation": "\u4f20\u7edf\u4fe1\u53f7\u5206\u89e3\u65b9\u6cd5\u4f9d\u8d56\u6570\u5b66\u6a21\u578b\uff0c\u800c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u8fd9\u4e00\u9886\u57df\u7684\u5e94\u7528\u5c1a\u672a\u5145\u5206\u63a2\u7d22\uff0c\u5177\u6709\u6f5c\u529b\u3002", "method": "\u5229\u7528Transformer\u67b6\u6784\uff0c\u901a\u8fc7\u5408\u6210\u6570\u636e\u8bad\u7ec3\u6a21\u578b\uff0c\u5b9e\u73b0\u4fe1\u53f7\u5206\u89e3\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u76f8\u540c\u5206\u5e03\u4fe1\u53f7\u4e0a\u5177\u6709\u9ad8\u7cbe\u5ea6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u4e00\u7ef4\u4fe1\u53f7\u5206\u89e3\u63d0\u4f9b\u4e86\u65b0\u7684\u6df1\u5ea6\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\uff0c\u5c55\u793a\u4e86Transformer\u67b6\u6784\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.05953", "pdf": "https://arxiv.org/pdf/2506.05953", "abs": "https://arxiv.org/abs/2506.05953", "authors": ["Alessandro Montenegro", "Leonardo Cesani", "Marco Mussi", "Matteo Papini", "Alberto Maria Metelli"], "title": "Learning Deterministic Policies with Policy Gradients in Constrained Markov Decision Processes", "categories": ["cs.LG"], "comment": "arXiv admin note: substantial text overlap with arXiv:2407.10775", "summary": "Constrained Reinforcement Learning (CRL) addresses sequential decision-making\nproblems where agents are required to achieve goals by maximizing the expected\nreturn while meeting domain-specific constraints. In this setting, policy-based\nmethods are widely used thanks to their advantages when dealing with\ncontinuous-control problems. These methods search in the policy space with an\naction-based or a parameter-based exploration strategy, depending on whether\nthey learn the parameters of a stochastic policy or those of a stochastic\nhyperpolicy. We introduce an exploration-agnostic algorithm, called C-PG, which\nenjoys global last-iterate convergence guarantees under gradient domination\nassumptions. Furthermore, under specific noise models where the (hyper)policy\nis expressed as a stochastic perturbation of the actions or of the parameters\nof an underlying deterministic policy, we additionally establish global\nlast-iterate convergence guarantees of C-PG to the optimal deterministic\npolicy. This holds when learning a stochastic (hyper)policy and subsequently\nswitching off the stochasticity at the end of training, thereby deploying a\ndeterministic policy. Finally, we empirically validate both the action-based\n(C-PGAE) and parameter-based (C-PGPE) variants of C-PG on constrained control\ntasks, and compare them against state-of-the-art baselines, demonstrating their\neffectiveness, in particular when deploying deterministic policies after\ntraining.", "AI": {"tldr": "C-PG\u662f\u4e00\u79cd\u63a2\u7d22\u65e0\u5173\u7684\u7b97\u6cd5\uff0c\u5728\u68af\u5ea6\u652f\u914d\u5047\u8bbe\u4e0b\u5177\u6709\u5168\u5c40\u6700\u540e\u8fed\u4ee3\u6536\u655b\u4fdd\u8bc1\uff0c\u9002\u7528\u4e8e\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\uff0c\u5373\u5728\u6700\u5927\u5316\u9884\u671f\u56de\u62a5\u7684\u540c\u65f6\u6ee1\u8db3\u9886\u57df\u7279\u5b9a\u7ea6\u675f\u3002", "method": "\u63d0\u51faC-PG\u7b97\u6cd5\uff0c\u652f\u6301\u57fa\u4e8e\u52a8\u4f5c\u6216\u53c2\u6570\u7684\u63a2\u7d22\u7b56\u7565\uff0c\u5e76\u5728\u7279\u5b9a\u566a\u58f0\u6a21\u578b\u4e0b\u8bc1\u660e\u5176\u6536\u655b\u6027\u3002", "result": "C-PG\u5728\u7ea6\u675f\u63a7\u5236\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5c24\u5176\u5728\u8bad\u7ec3\u540e\u90e8\u7f72\u786e\u5b9a\u6027\u7b56\u7565\u65f6\u6548\u679c\u663e\u8457\u3002", "conclusion": "C-PG\u7b97\u6cd5\u5728\u7406\u8bba\u548c\u5b9e\u8df5\u4e2d\u5747\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.05957", "pdf": "https://arxiv.org/pdf/2506.05957", "abs": "https://arxiv.org/abs/2506.05957", "authors": ["Tianjun Yao", "Haoxuan Li", "Yongqiang Chen", "Tongliang Liu", "Le Song", "Eric Xing", "Zhiqiang Shen"], "title": "Pruning Spurious Subgraphs for Graph Out-of-Distribtuion Generalization", "categories": ["cs.LG", "I.2.6"], "comment": "Submission of ICML2025, with score 4/4/3/3", "summary": "Graph Neural Networks (GNNs) often encounter significant performance\ndegradation under distribution shifts between training and test data, hindering\ntheir applicability in real-world scenarios. Recent studies have proposed\nvarious methods to address the out-of-distribution generalization challenge,\nwith many methods in the graph domain focusing on directly identifying an\ninvariant subgraph that is predictive of the target label. However, we argue\nthat identifying the edges from the invariant subgraph directly is challenging\nand error-prone, especially when some spurious edges exhibit strong\ncorrelations with the targets. In this paper, we propose PrunE, the first\npruning-based graph OOD method that eliminates spurious edges to improve OOD\ngeneralizability. By pruning spurious edges, \\mine{} retains the invariant\nsubgraph more comprehensively, which is critical for OOD generalization.\nSpecifically, PrunE employs two regularization terms to prune spurious edges:\n1) graph size constraint to exclude uninformative spurious edges, and 2)\n$\\epsilon$-probability alignment to further suppress the occurrence of spurious\nedges. Through theoretical analysis and extensive experiments, we show that\nPrunE achieves superior OOD performance and outperforms previous\nstate-of-the-art methods significantly. Codes are available at:\n\\href{https://github.com/tianyao-aka/PrunE-GraphOOD}{https://github.com/tianyao-aka/PrunE-GraphOOD}.", "AI": {"tldr": "PrunE\u662f\u4e00\u79cd\u57fa\u4e8e\u526a\u679d\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\uff0c\u901a\u8fc7\u6d88\u9664\u865a\u5047\u8fb9\u4ee5\u63d0\u9ad8\u5206\u5e03\u5916\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6570\u636e\u5206\u5e03\u504f\u79fb\u65f6\u6027\u80fd\u4e0b\u964d\u7684\u95ee\u9898\uff0c\u5c24\u5176\u662f\u865a\u5047\u8fb9\u4e0e\u76ee\u6807\u6807\u7b7e\u5f3a\u76f8\u5173\u7684\u60c5\u51b5\u3002", "method": "\u63d0\u51faPrunE\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e24\u79cd\u6b63\u5219\u5316\u9879\u526a\u679d\u865a\u5047\u8fb9\uff1a\u56fe\u5927\u5c0f\u7ea6\u675f\u548c\u03b5-\u6982\u7387\u5bf9\u9f50\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u8868\u660e\uff0cPrunE\u5728\u5206\u5e03\u5916\u6cdb\u5316\u6027\u80fd\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "PrunE\u901a\u8fc7\u526a\u679d\u865a\u5047\u8fb9\u6709\u6548\u4fdd\u7559\u4e86\u4e0d\u53d8\u5b50\u56fe\uff0c\u63d0\u5347\u4e86\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u5206\u5e03\u5916\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2506.05960", "pdf": "https://arxiv.org/pdf/2506.05960", "abs": "https://arxiv.org/abs/2506.05960", "authors": ["Adil Hasan", "Thomas Peyrin"], "title": "AQUATIC-Diff: Additive Quantization for Truly Tiny Compressed Diffusion Models", "categories": ["cs.LG"], "comment": null, "summary": "Significant investments have been made towards the commodification of\ndiffusion models for generation of diverse media. Their mass-market adoption is\nhowever still hobbled by the intense hardware resource requirements of\ndiffusion model inference. Model quantization strategies tailored specifically\ntowards diffusion models have been useful in easing this burden, yet have\ngenerally explored the Uniform Scalar Quantization (USQ) family of quantization\nmethods. In contrast, Vector Quantization (VQ) methods, which operate on groups\nof multiple related weights as the basic unit of compression, have seen\nsubstantial success in Large Language Model (LLM) quantization. In this work,\nwe apply codebook-based additive vector quantization to the problem of\ndiffusion model compression. Our resulting approach achieves a new Pareto\nfrontier for the extremely low-bit weight quantization on the standard\nclass-conditional benchmark of LDM-4 on ImageNet at 20 inference time steps.\nNotably, we report sFID 1.92 points lower than the full-precision model at W4A8\nand the best-reported results for FID, sFID and ISC at W2A8. We are also able\nto demonstrate FLOPs savings on arbitrary hardware via an efficient inference\nkernel, as opposed to savings resulting from small integer operations which may\nlack broad hardware support.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5411\u91cf\u91cf\u5316\u7684\u6269\u6563\u6a21\u578b\u538b\u7f29\u65b9\u6cd5\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u786c\u4ef6\u8d44\u6e90\u9700\u6c42\uff0c\u5e76\u5728\u4f4e\u6bd4\u7279\u91cf\u5316\u4e0b\u53d6\u5f97\u4e86\u4f18\u4e8e\u5168\u7cbe\u5ea6\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u7684\u5927\u89c4\u6a21\u5e94\u7528\u53d7\u9650\u4e8e\u5176\u9ad8\u786c\u4ef6\u8d44\u6e90\u9700\u6c42\uff0c\u73b0\u6709\u91cf\u5316\u65b9\u6cd5\u4e3b\u8981\u96c6\u4e2d\u4e8e\u5747\u5300\u6807\u91cf\u91cf\u5316\uff0c\u800c\u5411\u91cf\u91cf\u5316\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u56e0\u6b64\u63a2\u7d22\u5176\u5728\u6269\u6563\u6a21\u578b\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u7801\u4e66\u7684\u52a0\u6027\u5411\u91cf\u91cf\u5316\u65b9\u6cd5\u5bf9\u6269\u6563\u6a21\u578b\u8fdb\u884c\u538b\u7f29\uff0c\u5e76\u5728LDM-4\u6a21\u578b\u4e0a\u9a8c\u8bc1\u5176\u6548\u679c\u3002", "result": "\u5728\u6781\u4f4e\u6bd4\u7279\u91cf\u5316\uff08W4A8\u548cW2A8\uff09\u4e0b\uff0c\u8be5\u65b9\u6cd5\u5728ImageNet\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u5168\u7cbe\u5ea6\u6a21\u578b\uff0c\u5e76\u5b9e\u73b0\u4e86FLOPs\u7684\u8282\u7701\u3002", "conclusion": "\u5411\u91cf\u91cf\u5316\u5728\u6269\u6563\u6a21\u578b\u538b\u7f29\u4e2d\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u4e3a\u4f4e\u6bd4\u7279\u91cf\u5316\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.05968", "pdf": "https://arxiv.org/pdf/2506.05968", "abs": "https://arxiv.org/abs/2506.05968", "authors": ["Motoki Omura", "Kazuki Ota", "Takayuki Osa", "Yusuke Mukuta", "Tatsuya Harada"], "title": "Gradual Transition from Bellman Optimality Operator to Bellman Operator in Online Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "Accepted at ICML 2025. Source code:\n  https://github.com/motokiomura/annealed-q-learning", "summary": "For continuous action spaces, actor-critic methods are widely used in online\nreinforcement learning (RL). However, unlike RL algorithms for discrete\nactions, which generally model the optimal value function using the Bellman\noptimality operator, RL algorithms for continuous actions typically model\nQ-values for the current policy using the Bellman operator. These algorithms\nfor continuous actions rely exclusively on policy updates for improvement,\nwhich often results in low sample efficiency. This study examines the\neffectiveness of incorporating the Bellman optimality operator into\nactor-critic frameworks. Experiments in a simple environment show that modeling\noptimal values accelerates learning but leads to overestimation bias. To\naddress this, we propose an annealing approach that gradually transitions from\nthe Bellman optimality operator to the Bellman operator, thereby accelerating\nlearning while mitigating bias. Our method, combined with TD3 and SAC,\nsignificantly outperforms existing approaches across various locomotion and\nmanipulation tasks, demonstrating improved performance and robustness to\nhyperparameters related to optimality.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4\u4e2d\uff0c\u5c06\u8d1d\u5c14\u66fc\u6700\u4f18\u7b97\u5b50\u5f15\u5165actor-critic\u6846\u67b6\u7684\u6548\u679c\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u9000\u706b\u65b9\u6cd5\u4ee5\u5e73\u8861\u5b66\u4e60\u901f\u5ea6\u548c\u504f\u5dee\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4\u7684RL\u7b97\u6cd5\u901a\u5e38\u4f9d\u8d56\u7b56\u7565\u66f4\u65b0\uff0c\u5bfc\u81f4\u6837\u672c\u6548\u7387\u4f4e\u3002\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u5f15\u5165\u8d1d\u5c14\u66fc\u6700\u4f18\u7b97\u5b50\u52a0\u901f\u5b66\u4e60\uff0c\u540c\u65f6\u89e3\u51b3\u7531\u6b64\u5e26\u6765\u7684\u9ad8\u4f30\u504f\u5dee\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9000\u706b\u65b9\u6cd5\uff0c\u9010\u6b65\u4ece\u8d1d\u5c14\u66fc\u6700\u4f18\u7b97\u5b50\u8fc7\u6e21\u5230\u8d1d\u5c14\u66fc\u7b97\u5b50\uff0c\u7ed3\u5408TD3\u548cSAC\u7b97\u6cd5\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u79cd\u8fd0\u52a8\u548c\u64cd\u4f5c\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u6027\u80fd\u548c\u8d85\u53c2\u6570\u9c81\u68d2\u6027\u3002", "conclusion": "\u901a\u8fc7\u9000\u706b\u65b9\u6cd5\u5e73\u8861\u8d1d\u5c14\u66fc\u6700\u4f18\u7b97\u5b50\u7684\u5f15\u5165\uff0c\u80fd\u591f\u6709\u6548\u52a0\u901f\u5b66\u4e60\u5e76\u51cf\u5c11\u504f\u5dee\uff0c\u4e3a\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4\u7684RL\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.05971", "pdf": "https://arxiv.org/pdf/2506.05971", "abs": "https://arxiv.org/abs/2506.05971", "authors": ["Jacob Bamberger", "Benjamin Gutteridge", "Scott le Roux", "Michael M. Bronstein", "Xiaowen Dong"], "title": "On Measuring Long-Range Interactions in Graph Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": "ICML 2025", "summary": "Long-range graph tasks -- those dependent on interactions between distant\nnodes -- are an open problem in graph neural network research. Real-world\nbenchmark tasks, especially the Long Range Graph Benchmark, have become popular\nfor validating the long-range capability of proposed architectures. However,\nthis is an empirical approach that lacks both robustness and theoretical\nunderpinning; a more principled characterization of the long-range problem is\nrequired. To bridge this gap, we formalize long-range interactions in graph\ntasks, introduce a range measure for operators on graphs, and validate it with\nsynthetic experiments. We then leverage our measure to examine commonly used\ntasks and architectures, and discuss to what extent they are, in fact,\nlong-range. We believe our work advances efforts to define and address the\nlong-range problem on graphs, and that our range measure will aid evaluation of\nnew datasets and architectures.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5f62\u5f0f\u5316\u7684\u957f\u7a0b\u56fe\u4efb\u52a1\u4ea4\u4e92\u65b9\u6cd5\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u79cd\u56fe\u64cd\u4f5c\u7684\u8303\u56f4\u5ea6\u91cf\uff0c\u901a\u8fc7\u5408\u6210\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5f53\u524d\u7684\u957f\u7a0b\u56fe\u4efb\u52a1\u7814\u7a76\u7f3a\u4e4f\u7406\u8bba\u57fa\u7840\u548c\u9c81\u68d2\u6027\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u539f\u5219\u6027\u7684\u65b9\u6cd5\u6765\u5b9a\u4e49\u548c\u89e3\u51b3\u95ee\u9898\u3002", "method": "\u5f62\u5f0f\u5316\u957f\u7a0b\u56fe\u4efb\u52a1\u4ea4\u4e92\uff0c\u5f15\u5165\u56fe\u64cd\u4f5c\u7684\u8303\u56f4\u5ea6\u91cf\uff0c\u5e76\u901a\u8fc7\u5408\u6210\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u9a8c\u8bc1\u4e86\u8303\u56f4\u5ea6\u91cf\u7684\u6709\u6548\u6027\uff0c\u5e76\u5206\u6790\u4e86\u5e38\u7528\u4efb\u52a1\u548c\u67b6\u6784\u7684\u957f\u7a0b\u7279\u6027\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u957f\u7a0b\u56fe\u95ee\u9898\u7684\u5b9a\u4e49\u548c\u89e3\u51b3\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u8303\u56f4\u5ea6\u91cf\u6709\u52a9\u4e8e\u65b0\u6570\u636e\u96c6\u548c\u67b6\u6784\u7684\u8bc4\u4f30\u3002"}}
{"id": "2506.05977", "pdf": "https://arxiv.org/pdf/2506.05977", "abs": "https://arxiv.org/abs/2506.05977", "authors": ["Yujia Huo", "Jianchun Liu", "Hongli Xu", "Zhenguo Ma", "Shilong Wang", "Liusheng Huang"], "title": "Mitigating Catastrophic Forgetting with Adaptive Transformer Block Expansion in Federated Fine-Tuning", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "Federated fine-tuning (FedFT) of large language models (LLMs) has emerged as\na promising solution for adapting models to distributed data environments while\nensuring data privacy.\n  Existing FedFT methods predominantly utilize parameter-efficient fine-tuning\n(PEFT) techniques to reduce communication and computation overhead.\n  However, they often fail to adequately address the catastrophic forgetting, a\ncritical challenge arising from continual adaptation in distributed\nenvironments. The traditional centralized fine-tuning methods, which are not\ndesigned for the heterogeneous and privacy-constrained nature of federated\nenvironments, struggle to mitigate this issue effectively. Moreover, the\nchallenge is further exacerbated by significant variation in data distributions\nand device capabilities across clients, which leads to intensified forgetting\nand degraded model generalization. To tackle these issues, we propose FedBE, a\nnovel FedFT framework that integrates an adaptive transformer block expansion\nmechanism with a dynamic trainable-block allocation strategy. Specifically,\nFedBE expands trainable blocks within the model architecture, structurally\nseparating newly learned task-specific knowledge from the original pre-trained\nrepresentations. Additionally, FedBE dynamically assigns these trainable blocks\nto clients based on their data distributions and computational capabilities.\nThis enables the framework to better accommodate heterogeneous federated\nenvironments and enhances the generalization ability of the model.Extensive\nexperiments show that compared with existing federated fine-tuning methods,\nFedBE achieves 12-74% higher accuracy retention on general tasks after\nfine-tuning and a model convergence acceleration ratio of 1.9-3.1x without\ndegrading the accuracy of downstream tasks.", "AI": {"tldr": "FedBE\u662f\u4e00\u79cd\u65b0\u7684\u8054\u90a6\u5fae\u8c03\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u6269\u5c55\u548c\u52a8\u6001\u5206\u914d\u53ef\u8bad\u7ec3\u5757\uff0c\u89e3\u51b3\u4e86\u5206\u5e03\u5f0f\u73af\u5883\u4e2d\u707e\u96be\u6027\u9057\u5fd8\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u8054\u90a6\u5fae\u8c03\u65b9\u6cd5\u5728\u5206\u5e03\u5f0f\u73af\u5883\u4e2d\u96be\u4ee5\u6709\u6548\u89e3\u51b3\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u4e14\u6570\u636e\u5206\u5e03\u548c\u8bbe\u5907\u80fd\u529b\u5dee\u5f02\u52a0\u5267\u4e86\u8fd9\u4e00\u95ee\u9898\u3002", "method": "FedBE\u7ed3\u5408\u81ea\u9002\u5e94Transformer\u5757\u6269\u5c55\u673a\u5236\u548c\u52a8\u6001\u53ef\u8bad\u7ec3\u5757\u5206\u914d\u7b56\u7565\uff0c\u5206\u79bb\u65b0\u5b66\u77e5\u8bc6\u4e0e\u9884\u8bad\u7ec3\u8868\u793a\uff0c\u5e76\u6839\u636e\u5ba2\u6237\u7aef\u6570\u636e\u5206\u5e03\u548c\u80fd\u529b\u52a8\u6001\u5206\u914d\u5757\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cFedBE\u5728\u901a\u7528\u4efb\u52a1\u4e0a\u7684\u51c6\u786e\u7387\u4fdd\u7559\u63d0\u9ad8\u4e8612-74%\uff0c\u6a21\u578b\u6536\u655b\u901f\u5ea6\u52a0\u5feb1.9-3.1\u500d\uff0c\u4e14\u4e0d\u5f71\u54cd\u4e0b\u6e38\u4efb\u52a1\u51c6\u786e\u7387\u3002", "conclusion": "FedBE\u6709\u6548\u89e3\u51b3\u4e86\u8054\u90a6\u5fae\u8c03\u4e2d\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u5728\u5f02\u6784\u73af\u5883\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u548c\u6027\u80fd\u3002"}}
{"id": "2506.05980", "pdf": "https://arxiv.org/pdf/2506.05980", "abs": "https://arxiv.org/abs/2506.05980", "authors": ["Geonwoo Cho", "Jaemoon Lee", "Jaegyun Im", "Subi Lee", "Jihwan Lee", "Sundong Kim"], "title": "AMPED: Adaptive Multi-objective Projection for balancing Exploration and skill Diversification", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Skill-based reinforcement learning (SBRL) enables rapid adaptation in\nenvironments with sparse rewards by pretraining a skill-conditioned policy.\nEffective skill learning requires jointly maximizing both exploration and skill\ndiversity. However, existing methods often face challenges in simultaneously\noptimizing for these two conflicting objectives. In this work, we propose a new\nmethod, Adaptive Multi-objective Projection for balancing Exploration and skill\nDiversification (AMPED), which explicitly addresses both exploration and skill\ndiversification. We begin by conducting extensive ablation studies to identify\nand define a set of objectives that effectively capture the aspects of\nexploration and skill diversity, respectively. During the skill pretraining\nphase, AMPED introduces a gradient surgery technique to balance the objectives\nof exploration and skill diversity, mitigating conflicts and reducing reliance\non heuristic tuning. In the subsequent fine-tuning phase, AMPED incorporates a\nskill selector module that dynamically selects suitable skills for downstream\ntasks, based on task-specific performance signals. Our approach achieves\nperformance that surpasses SBRL baselines across various benchmarks. These\nresults highlight the importance of explicitly harmonizing exploration and\ndiversity and demonstrate the effectiveness of AMPED in enabling robust and\ngeneralizable skill learning. Project Page: https://geonwoo.me/amped/", "AI": {"tldr": "AMPED\u662f\u4e00\u79cd\u65b0\u7684\u6280\u80fd\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u68af\u5ea6\u624b\u672f\u6280\u672f\u5e73\u8861\u63a2\u7d22\u4e0e\u6280\u80fd\u591a\u6837\u6027\uff0c\u5e76\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u52a8\u6001\u9009\u62e9\u6280\u80fd\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u4f18\u5316\u63a2\u7d22\u4e0e\u6280\u80fd\u591a\u6837\u6027\u8fd9\u4e24\u4e2a\u51b2\u7a81\u76ee\u6807\uff0cAMPED\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "AMPED\u901a\u8fc7\u68af\u5ea6\u624b\u672f\u6280\u672f\u5e73\u8861\u63a2\u7d22\u4e0e\u591a\u6837\u6027\u76ee\u6807\uff0c\u5e76\u5f15\u5165\u6280\u80fd\u9009\u62e9\u6a21\u5757\u52a8\u6001\u9002\u914d\u4e0b\u6e38\u4efb\u52a1\u3002", "result": "AMPED\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6280\u80fd\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "AMPED\u8bc1\u660e\u4e86\u663e\u5f0f\u534f\u8c03\u63a2\u7d22\u4e0e\u591a\u6837\u6027\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u9c81\u68d2\u4e14\u901a\u7528\u7684\u6280\u80fd\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2506.05985", "pdf": "https://arxiv.org/pdf/2506.05985", "abs": "https://arxiv.org/abs/2506.05985", "authors": ["Yuheng Lei", "Sitong Mao", "Shunbo Zhou", "Hongyuan Zhang", "Xuelong Li", "Ping Luo"], "title": "Dynamic Mixture of Progressive Parameter-Efficient Expert Library for Lifelong Robot Learning", "categories": ["cs.LG", "cs.RO"], "comment": null, "summary": "A generalist agent must continuously learn and adapt throughout its lifetime,\nachieving efficient forward transfer while minimizing catastrophic forgetting.\nPrevious work within the dominant pretrain-then-finetune paradigm has explored\nparameter-efficient fine-tuning for single-task adaptation, effectively\nsteering a frozen pretrained model with a small number of parameters. However,\nin the context of lifelong learning, these methods rely on the impractical\nassumption of a test-time task identifier and restrict knowledge sharing among\nisolated adapters. To address these limitations, we propose Dynamic Mixture of\nProgressive Parameter-Efficient Expert Library (DMPEL) for lifelong robot\nlearning. DMPEL progressively learn a low-rank expert library and employs a\nlightweight router to dynamically combine experts into an end-to-end policy,\nfacilitating flexible behavior during lifelong adaptation. Moreover, by\nleveraging the modular structure of the fine-tuned parameters, we introduce\ncoefficient replay to guide the router in accurately retrieving frozen experts\nfor previously encountered tasks, thereby mitigating catastrophic forgetting.\nThis method is significantly more storage- and computationally-efficient than\napplying demonstration replay to the entire policy. Extensive experiments on\nthe lifelong manipulation benchmark LIBERO demonstrate that our framework\noutperforms state-of-the-art lifelong learning methods in success rates across\ncontinual adaptation, while utilizing minimal trainable parameters and storage.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u6df7\u5408\u6e10\u8fdb\u53c2\u6570\u9ad8\u6548\u4e13\u5bb6\u5e93\uff08DMPEL\uff09\u65b9\u6cd5\uff0c\u7528\u4e8e\u7ec8\u8eab\u673a\u5668\u4eba\u5b66\u4e60\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u4efb\u52a1\u6807\u8bc6\u4f9d\u8d56\u548c\u77e5\u8bc6\u5171\u4eab\u9650\u5236\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "\u7ec8\u8eab\u5b66\u4e60\u4e2d\u7684\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u4e0d\u5207\u5b9e\u9645\u7684\u4efb\u52a1\u6807\u8bc6\u5047\u8bbe\uff0c\u5e76\u9650\u5236\u4e86\u5b64\u7acb\u9002\u914d\u5668\u4e4b\u95f4\u7684\u77e5\u8bc6\u5171\u4eab\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u4e14\u7075\u6d3b\u7684\u65b9\u6cd5\u3002", "method": "DMPEL\u901a\u8fc7\u6e10\u8fdb\u5b66\u4e60\u4f4e\u79e9\u4e13\u5bb6\u5e93\uff0c\u5e76\u5229\u7528\u8f7b\u91cf\u7ea7\u8def\u7531\u5668\u52a8\u6001\u7ec4\u5408\u4e13\u5bb6\uff0c\u5f62\u6210\u7aef\u5230\u7aef\u7b56\u7565\uff0c\u540c\u65f6\u5f15\u5165\u7cfb\u6570\u91cd\u653e\u4ee5\u51cf\u5c11\u707e\u96be\u6027\u9057\u5fd8\u3002", "result": "\u5728LIBERO\u7ec8\u8eab\u64cd\u4f5c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDMPEL\u5728\u6301\u7eed\u9002\u5e94\u4efb\u52a1\u4e2d\u7684\u6210\u529f\u7387\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u53c2\u6570\u548c\u5b58\u50a8\u9700\u6c42\u6781\u4f4e\u3002", "conclusion": "DMPEL\u4e3a\u7ec8\u8eab\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u5e76\u964d\u4f4e\u4e86\u8d44\u6e90\u6d88\u8017\u3002"}}
{"id": "2506.05994", "pdf": "https://arxiv.org/pdf/2506.05994", "abs": "https://arxiv.org/abs/2506.05994", "authors": ["Yi-Chun Liao", "Chieh-Lin Tsai", "Yuan-Hao Chang", "Cam\u00e9lia Slimani", "Jalil Boukhobza", "Tei-Wei Kuo"], "title": "RETENTION: Resource-Efficient Tree-Based Ensemble Model Acceleration with Content-Addressable Memory", "categories": ["cs.LG", "cs.AR", "cs.ET"], "comment": null, "summary": "Although deep learning has demonstrated remarkable capabilities in learning\nfrom unstructured data, modern tree-based ensemble models remain superior in\nextracting relevant information and learning from structured datasets. While\nseveral efforts have been made to accelerate tree-based models, the inherent\ncharacteristics of the models pose significant challenges for conventional\naccelerators. Recent research leveraging content-addressable memory (CAM)\noffers a promising solution for accelerating tree-based models, yet existing\ndesigns suffer from excessive memory consumption and low utilization. This work\naddresses these challenges by introducing RETENTION, an end-to-end framework\nthat significantly reduces CAM capacity requirement for tree-based model\ninference. We propose an iterative pruning algorithm with a novel pruning\ncriterion tailored for bagging-based models (e.g., Random Forest), which\nminimizes model complexity while ensuring controlled accuracy degradation.\nAdditionally, we present a tree mapping scheme that incorporates two innovative\ndata placement strategies to alleviate the memory redundancy caused by the\nwidespread use of don't care states in CAM. Experimental results show that\nimplementing the tree mapping scheme alone achieves $1.46\\times$ to $21.30\n\\times$ better space efficiency, while the full RETENTION framework yields\n$4.35\\times$ to $207.12\\times$ improvement with less than 3% accuracy loss.\nThese results demonstrate that RETENTION is highly effective in reducing CAM\ncapacity requirement, providing a resource-efficient direction for tree-based\nmodel acceleration.", "AI": {"tldr": "RETENTION\u6846\u67b6\u901a\u8fc7\u8fed\u4ee3\u526a\u679d\u548c\u6811\u6620\u5c04\u65b9\u6848\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u6811\u6a21\u578b\u63a8\u7406\u4e2dCAM\u7684\u5bb9\u91cf\u9700\u6c42\uff0c\u540c\u65f6\u4fdd\u6301\u7cbe\u5ea6\u635f\u5931\u57283%\u4ee5\u5185\u3002", "motivation": "\u5c3d\u7ba1\u6df1\u5ea6\u5b66\u4e60\u5728\u975e\u7ed3\u6784\u5316\u6570\u636e\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u6811\u6a21\u578b\u5728\u7ed3\u6784\u5316\u6570\u636e\u4e0a\u4ecd\u5360\u4f18\u52bf\u3002\u73b0\u6709CAM\u52a0\u901f\u65b9\u6848\u5b58\u5728\u5185\u5b58\u6d88\u8017\u9ad8\u548c\u5229\u7528\u7387\u4f4e\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u8fed\u4ee3\u526a\u679d\u7b97\u6cd5\u548c\u6811\u6620\u5c04\u65b9\u6848\uff0c\u4f18\u5316CAM\u4f7f\u7528\uff0c\u51cf\u5c11\u5197\u4f59\u3002", "result": "RETENTION\u6846\u67b6\u5b9e\u73b0\u7a7a\u95f4\u6548\u7387\u63d0\u53471.46\u00d7\u81f3207.12\u00d7\uff0c\u7cbe\u5ea6\u635f\u5931\u5c0f\u4e8e3%\u3002", "conclusion": "RETENTION\u4e3a\u6811\u6a21\u578b\u52a0\u901f\u63d0\u4f9b\u4e86\u9ad8\u6548\u8d44\u6e90\u5229\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.05999", "pdf": "https://arxiv.org/pdf/2506.05999", "abs": "https://arxiv.org/abs/2506.05999", "authors": ["Sanna Jarl", "Jens Sj\u00f6lund", "Robert J. W. Frost", "Anders Holst", "Jonathan J. S. Scragg"], "title": "Machine learning for in-situ composition mapping in a self-driving magnetron sputtering system", "categories": ["cs.LG", "cond-mat.mtrl-sci", "I.2.1; J.2.8"], "comment": "24 pages, 10 figures. Submitted to the journal npj computational\n  materials", "summary": "Self-driving labs (SDLs), employing automation and machine learning (ML) to\naccelerate experimental procedures, have enormous potential in the discovery of\nnew materials. However, in thin film science, SDLs are mainly restricted to\nsolution-based synthetic methods which are easier to automate but cannot access\nthe broad chemical space of inorganic materials. This work presents an SDL\nbased on magnetron co-sputtering. We are using combinatorial frameworks,\nobtaining accurate composition maps on multi-element, compositionally graded\nthin films. This normally requires time-consuming ex-situ analysis prone to\nsystematic errors. We present a rapid and calibration-free in-situ, ML driven\napproach to produce composition maps for arbitrary source combinations and\nsputtering conditions. We develop a method to predict the composition\ndistribution in a multi-element combinatorial thin film, using in-situ\nmeasurements from quartz-crystal microbalance sensors placed in a sputter\nchamber. For a given source, the sensor readings are learned as a function of\nthe sputtering pressure and magnetron power, through active learning using\nGaussian processes (GPs). The final GPs are combined with a geometric model of\nthe deposition flux distribution in the chamber, which allows interpolation of\nthe deposition rates from each source, at any position across the sample. We\ninvestigate several acquisition functions for the ML procedure. A fully\nBayesian GP - BALM (Bayesian active learning MacKay) - achieved the best\nperformance, learning the deposition rates for a single source in 10\nexperiments. Prediction accuracy for co-sputtering composition distributions\nwas verified experimentally. Our framework dramatically increases throughput by\navoiding the need for extensive characterisation or calibration, thus\ndemonstrating the potential of ML-guided SDLs to accelerate materials\nexploration.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u78c1\u63a7\u5171\u6e85\u5c04\u7684\u81ea\u9a71\u52a8\u5b9e\u9a8c\u5ba4\uff08SDL\uff09\u65b9\u6cd5\uff0c\u5229\u7528\u673a\u5668\u5b66\u4e60\u548c\u4e3b\u52a8\u5b66\u4e60\u5feb\u901f\u751f\u6210\u591a\u5143\u7d20\u7ec4\u5408\u8584\u819c\u7684\u6210\u5206\u5206\u5e03\u56fe\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u8017\u65f6\u4e14\u6613\u51fa\u9519\u7684\u79bb\u7ebf\u5206\u6790\u3002", "motivation": "\u5728\u8584\u819c\u79d1\u5b66\u4e2d\uff0c\u73b0\u6709\u7684SDL\u4e3b\u8981\u5c40\u9650\u4e8e\u6eb6\u6db2\u5408\u6210\u65b9\u6cd5\uff0c\u96be\u4ee5\u8986\u76d6\u65e0\u673a\u6750\u6599\u7684\u5e7f\u6cdb\u5316\u5b66\u7a7a\u95f4\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5feb\u901f\u3001\u51c6\u786e\u4e14\u65e0\u9700\u6821\u51c6\u7684\u65b9\u6cd5\u6765\u6269\u5c55SDL\u7684\u5e94\u7528\u8303\u56f4\u3002", "method": "\u901a\u8fc7\u78c1\u63a7\u5171\u6e85\u5c04\u6280\u672f\uff0c\u7ed3\u5408\u77f3\u82f1\u6676\u4f53\u5fae\u5929\u5e73\u4f20\u611f\u5668\u8fdb\u884c\u539f\u4f4d\u6d4b\u91cf\uff0c\u5229\u7528\u9ad8\u65af\u8fc7\u7a0b\uff08GPs\uff09\u548c\u4e3b\u52a8\u5b66\u4e60\uff08BALM\uff09\u9884\u6d4b\u591a\u5143\u7d20\u8584\u819c\u7684\u6210\u5206\u5206\u5e03\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u572810\u6b21\u5b9e\u9a8c\u5185\u5373\u53ef\u5b66\u4e60\u5355\u4e2a\u6e90\u7684\u6c89\u79ef\u901f\u7387\uff0c\u4e14\u9884\u6d4b\u7cbe\u5ea6\u9ad8\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6750\u6599\u63a2\u7d22\u7684\u6548\u7387\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u907f\u514d\u7e41\u7410\u7684\u6821\u51c6\u548c\u8868\u5f81\uff0c\u5c55\u793a\u4e86\u673a\u5668\u5b66\u4e60\u5f15\u5bfc\u7684SDL\u5728\u52a0\u901f\u6750\u6599\u63a2\u7d22\u4e2d\u7684\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2506.06001", "pdf": "https://arxiv.org/pdf/2506.06001", "abs": "https://arxiv.org/abs/2506.06001", "authors": ["Shilong Tao", "Zhe Feng", "Haonan Sun", "Zhanxing Zhu", "Yunhuai Liu"], "title": "LaDEEP: A Deep Learning-based Surrogate Model for Large Deformation of Elastic-Plastic Solids", "categories": ["cs.LG"], "comment": "Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery\n  and Data Mining V.2 (KDD '25)", "summary": "Scientific computing for large deformation of elastic-plastic solids is\ncritical for numerous real-world applications. Classical numerical solvers rely\nprimarily on local discrete linear approximation and are constrained by an\ninherent trade-off between accuracy and efficiency. Recently, deep learning\nmodels have achieved impressive progress in solving the continuum mechanism.\nWhile previous models have explored various architectures and constructed\ncoefficient-solution mappings, they are designed for general instances without\nconsidering specific problem properties and hard to accurately handle with\ncomplex elastic-plastic solids involving contact, loading and unloading. In\nthis work, we take stretch bending, a popular metal fabrication technique, as\nour case study and introduce LaDEEP, a deep learning-based surrogate model for\n\\textbf{La}rge \\textbf{De}formation of \\textbf{E}lastic-\\textbf{P}lastic\nSolids. We encode the partitioned regions of the involved slender solids into a\ntoken sequence to maintain their essential order property. To characterize the\nphysical process of the solid deformation, a two-stage Transformer-based module\nis designed to predict the deformation with the sequence of tokens as input.\nEmpirically, LaDEEP achieves five magnitudes faster speed than finite element\nmethods with a comparable accuracy, and gains 20.47\\% relative improvement on\naverage compared to other deep learning baselines. We have also deployed our\nmodel into a real-world industrial production system, and it has shown\nremarkable performance in both accuracy and efficiency.", "AI": {"tldr": "LaDEEP\u662f\u4e00\u4e2a\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u4ee3\u7406\u6a21\u578b\uff0c\u7528\u4e8e\u89e3\u51b3\u5f39\u6027-\u5851\u6027\u56fa\u4f53\u7684\u5927\u53d8\u5f62\u95ee\u9898\uff0c\u901a\u8fc7\u5206\u533a\u7f16\u7801\u548cTransformer\u6a21\u5757\u5b9e\u73b0\u9ad8\u6548\u9884\u6d4b\u3002", "motivation": "\u4f20\u7edf\u6570\u503c\u65b9\u6cd5\u5728\u7cbe\u5ea6\u548c\u6548\u7387\u4e4b\u95f4\u5b58\u5728\u56fa\u6709\u6298\u8877\uff0c\u800c\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u672a\u9488\u5bf9\u7279\u5b9a\u95ee\u9898\u7279\u6027\u8bbe\u8ba1\uff0c\u96be\u4ee5\u5904\u7406\u590d\u6742\u5f39\u6027-\u5851\u6027\u56fa\u4f53\u53d8\u5f62\u3002", "method": "\u5c06\u5206\u533a\u533a\u57df\u7f16\u7801\u4e3a\u4ee4\u724c\u5e8f\u5217\uff0c\u8bbe\u8ba1\u4e24\u9636\u6bb5Transformer\u6a21\u5757\u9884\u6d4b\u53d8\u5f62\u3002", "result": "LaDEEP\u6bd4\u6709\u9650\u5143\u65b9\u6cd5\u5feb\u4e94\u4e2a\u6570\u91cf\u7ea7\uff0c\u7cbe\u5ea6\u76f8\u5f53\uff0c\u4e14\u6bd4\u5176\u4ed6\u6df1\u5ea6\u5b66\u4e60\u57fa\u7ebf\u5e73\u5747\u63d0\u534720.47%\u3002", "conclusion": "LaDEEP\u5728\u5de5\u4e1a\u7cfb\u7edf\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u7cbe\u5ea6\u548c\u6548\u7387\u4e0a\u7684\u4f18\u8d8a\u6027\u3002"}}
{"id": "2506.06003", "pdf": "https://arxiv.org/pdf/2506.06003", "abs": "https://arxiv.org/abs/2506.06003", "authors": ["Neal Mangaokar", "Ashish Hooda", "Zhuohang Li", "Bradley A. Malin", "Kassem Fawaz", "Somesh Jha", "Atul Prakash", "Amrita Roy Chowdhury"], "title": "What Really is a Member? Discrediting Membership Inference via Poisoning", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "Membership inference tests aim to determine whether a particular data point\nwas included in a language model's training set. However, recent works have\nshown that such tests often fail under the strict definition of membership\nbased on exact matching, and have suggested relaxing this definition to include\nsemantic neighbors as members as well. In this work, we show that membership\ninference tests are still unreliable under this relaxation - it is possible to\npoison the training dataset in a way that causes the test to produce incorrect\npredictions for a target point. We theoretically reveal a trade-off between a\ntest's accuracy and its robustness to poisoning. We also present a concrete\ninstantiation of this poisoning attack and empirically validate its\neffectiveness. Our results show that it can degrade the performance of existing\ntests to well below random.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u6210\u5458\u63a8\u65ad\u6d4b\u8bd5\u5728\u8bed\u4e49\u90bb\u5c45\u5b9a\u4e49\u4e0b\u7684\u4e0d\u53ef\u9760\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u8bad\u7ec3\u6570\u636e\u6295\u6bd2\u653b\u51fb\uff0c\u63ed\u793a\u4e86\u6d4b\u8bd5\u51c6\u786e\u6027\u4e0e\u6297\u6295\u6bd2\u80fd\u529b\u4e4b\u95f4\u7684\u6743\u8861\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u9a8c\u8bc1\u6210\u5458\u63a8\u65ad\u6d4b\u8bd5\u5728\u653e\u5bbd\u5b9a\u4e49\uff08\u5305\u62ec\u8bed\u4e49\u90bb\u5c45\uff09\u540e\u662f\u5426\u4ecd\u7136\u53ef\u9760\uff0c\u5e76\u63a2\u7d22\u5176\u5bf9\u6297\u6295\u6bd2\u653b\u51fb\u7684\u8106\u5f31\u6027\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u7406\u8bba\u5206\u6790\u6d4b\u8bd5\u51c6\u786e\u6027\u4e0e\u6297\u6295\u6bd2\u80fd\u529b\u7684\u6743\u8861\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u5177\u4f53\u7684\u8bad\u7ec3\u6570\u636e\u6295\u6bd2\u653b\u51fb\u5b9e\u4f8b\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u6295\u6bd2\u653b\u51fb\u80fd\u663e\u8457\u964d\u4f4e\u73b0\u6709\u6d4b\u8bd5\u7684\u6027\u80fd\uff0c\u751a\u81f3\u4f7f\u5176\u4f4e\u4e8e\u968f\u673a\u731c\u6d4b\u6c34\u5e73\u3002", "conclusion": "\u7ed3\u8bba\u6307\u51fa\u6210\u5458\u63a8\u65ad\u6d4b\u8bd5\u5728\u653e\u5bbd\u5b9a\u4e49\u540e\u4ecd\u4e0d\u53ef\u9760\uff0c\u4e14\u5b58\u5728\u51c6\u786e\u6027\u4e0e\u6297\u6295\u6bd2\u80fd\u529b\u7684\u6839\u672c\u6743\u8861\u3002"}}
{"id": "2506.06005", "pdf": "https://arxiv.org/pdf/2506.06005", "abs": "https://arxiv.org/abs/2506.06005", "authors": ["Yihang Wang", "Yuying Qiu", "Peng Chen", "Yang Shu", "Zhongwen Rao", "Lujia Pan", "Bin Yang", "Chenjuan Guo"], "title": "LightGTS: A Lightweight General Time Series Forecasting Model", "categories": ["cs.LG"], "comment": "Accepted by the 42th International Conference on Machine Learning\n  (ICML 2025)", "summary": "Existing works on general time series forecasting build foundation models\nwith heavy model parameters through large-scale multi-source pre-training.\nThese models achieve superior generalization ability across various datasets at\nthe cost of significant computational burdens and limitations in\nresource-constrained scenarios. This paper introduces LightGTS, a lightweight\ngeneral time series forecasting model designed from the perspective of\nconsistent periodical modeling. To handle diverse scales and intrinsic periods\nin multi-source pre-training, we introduce Periodical Tokenization, which\nextracts consistent periodic patterns across different datasets with varying\nscales. To better utilize the periodicity in the decoding process, we further\nintroduce Periodical Parallel Decoding, which leverages historical tokens to\nimprove forecasting. Based on the two techniques above which fully leverage the\ninductive bias of periods inherent in time series, LightGTS uses a lightweight\nmodel to achieve outstanding performance on general time series forecasting. It\nachieves state-of-the-art forecasting performance on 9 real-world benchmarks in\nboth zero-shot and full-shot settings with much better efficiency compared with\nexisting time series foundation models.", "AI": {"tldr": "LightGTS\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u901a\u7528\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\uff0c\u901a\u8fc7\u5468\u671f\u6027\u5efa\u6a21\u548c\u5e76\u884c\u89e3\u7801\u6280\u672f\uff0c\u5728\u9ad8\u6548\u7684\u540c\u65f6\u5b9e\u73b0\u5353\u8d8a\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\u53c2\u6570\u5e9e\u5927\uff0c\u8ba1\u7b97\u8d1f\u62c5\u91cd\uff0c\u8d44\u6e90\u53d7\u9650\u573a\u666f\u4e0b\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51faPeriodical Tokenization\u63d0\u53d6\u591a\u6e90\u6570\u636e\u4e2d\u7684\u5468\u671f\u6027\u6a21\u5f0f\uff0c\u4ee5\u53caPeriodical Parallel Decoding\u5229\u7528\u5386\u53f2\u4ee4\u724c\u4f18\u5316\u9884\u6d4b\u3002", "result": "\u57289\u4e2a\u771f\u5b9e\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u96f6\u6837\u672c\u548c\u5168\u6837\u672c\u8bbe\u7f6e\u4e0b\u5747\u8fbe\u5230\u6700\u4f18\u6027\u80fd\uff0c\u4e14\u6548\u7387\u663e\u8457\u63d0\u5347\u3002", "conclusion": "LightGTS\u901a\u8fc7\u8f7b\u91cf\u7ea7\u8bbe\u8ba1\u548c\u9ad8\u6548\u7387\uff0c\u4e3a\u901a\u7528\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u63d0\u4f9b\u4e86\u65b0\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.06021", "pdf": "https://arxiv.org/pdf/2506.06021", "abs": "https://arxiv.org/abs/2506.06021", "authors": ["Shilong Tao", "Zhe Feng", "Haonan Sun", "Zhanxing Zhu", "Yunhuai Liu"], "title": "Unisoma: A Unified Transformer-based Solver for Multi-Solid Systems", "categories": ["cs.LG"], "comment": "Proceedings of the 42nd International Conference on Machine Learning", "summary": "Multi-solid systems are foundational to a wide range of real-world\napplications, yet modeling their complex interactions remains challenging.\nExisting deep learning methods predominantly rely on implicit modeling, where\nthe factors influencing solid deformation are not explicitly represented but\nare instead indirectly learned. However, as the number of solids increases,\nthese methods struggle to accurately capture intricate physical interactions.\nIn this paper, we introduce a novel explicit modeling paradigm that\nincorporates factors influencing solid deformation through structured modules.\nSpecifically, we present Unisoma, a unified and flexible Transformer-based\nmodel capable of handling variable numbers of solids. Unisoma directly captures\nphysical interactions using contact modules and adaptive interaction allocation\nmechanism, and learns the deformation through a triplet relationship. Compared\nto implicit modeling techniques, explicit modeling is more well-suited for\nmulti-solid systems with diverse coupling patterns, as it enables detailed\ntreatment of each solid while preventing information blending and confusion.\nExperimentally, Unisoma achieves consistent state-of-the-art performance across\nseven well-established datasets and two complex multi-solid tasks. Code is\navaiable at \\href{this link}{https://github.com/therontau0054/Unisoma}.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u663e\u5f0f\u5efa\u6a21\u65b9\u6cd5Unisoma\uff0c\u7528\u4e8e\u5904\u7406\u591a\u56fa\u4f53\u7cfb\u7edf\u7684\u590d\u6742\u76f8\u4e92\u4f5c\u7528\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u6a21\u5757\u548cTransformer\u67b6\u6784\u5b9e\u73b0\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u9690\u5f0f\u5efa\u6a21\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u9690\u5f0f\u5efa\u6a21\uff0c\u96be\u4ee5\u51c6\u786e\u6355\u6349\u591a\u56fa\u4f53\u7cfb\u7edf\u7684\u590d\u6742\u7269\u7406\u76f8\u4e92\u4f5c\u7528\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u663e\u5f0f\u5efa\u6a21\u65b9\u6cd5\u3002", "method": "\u63d0\u51faUnisoma\u6a21\u578b\uff0c\u91c7\u7528\u7ed3\u6784\u5316\u6a21\u5757\uff08\u5982\u63a5\u89e6\u6a21\u5757\u548c\u81ea\u9002\u5e94\u4ea4\u4e92\u5206\u914d\u673a\u5236\uff09\u548c\u4e09\u91cd\u5173\u7cfb\u5b66\u4e60\u53d8\u5f62\uff0c\u76f4\u63a5\u6355\u6349\u7269\u7406\u76f8\u4e92\u4f5c\u7528\u3002", "result": "Unisoma\u5728\u4e03\u4e2a\u6570\u636e\u96c6\u548c\u4e24\u4e2a\u590d\u6742\u4efb\u52a1\u4e0a\u5747\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "\u663e\u5f0f\u5efa\u6a21\u66f4\u9002\u5408\u591a\u56fa\u4f53\u7cfb\u7edf\uff0cUnisoma\u901a\u8fc7\u7ed3\u6784\u5316\u6a21\u5757\u548cTransformer\u67b6\u6784\u5b9e\u73b0\u4e86\u9ad8\u6548\u5efa\u6a21\u548c\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2506.06039", "pdf": "https://arxiv.org/pdf/2506.06039", "abs": "https://arxiv.org/abs/2506.06039", "authors": ["Jake Robertson", "Arik Reuter", "Siyuan Guo", "Noah Hollmann", "Frank Hutter", "Bernhard Sch\u00f6lkopf"], "title": "Do-PFN: In-Context Learning for Causal Effect Estimation", "categories": ["cs.LG"], "comment": null, "summary": "Estimation of causal effects is critical to a range of scientific\ndisciplines. Existing methods for this task either require interventional data,\nknowledge about the ground truth causal graph, or rely on assumptions such as\nunconfoundedness, restricting their applicability in real-world settings. In\nthe domain of tabular machine learning, Prior-data fitted networks (PFNs) have\nachieved state-of-the-art predictive performance, having been pre-trained on\nsynthetic data to solve tabular prediction problems via in-context learning. To\nassess whether this can be transferred to the harder problem of causal effect\nestimation, we pre-train PFNs on synthetic data drawn from a wide variety of\ncausal structures, including interventions, to predict interventional outcomes\ngiven observational data. Through extensive experiments on synthetic case\nstudies, we show that our approach allows for the accurate estimation of causal\neffects without knowledge of the underlying causal graph. We also perform\nablation studies that elucidate Do-PFN's scalability and robustness across\ndatasets with a variety of causal characteristics.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9884\u8bad\u7ec3\u7f51\u7edc\uff08PFNs\uff09\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u4e0d\u77e5\u9053\u56e0\u679c\u56fe\u7684\u60c5\u51b5\u4e0b\u4f30\u8ba1\u56e0\u679c\u6548\u5e94\uff0c\u901a\u8fc7\u5408\u6210\u6570\u636e\u8bad\u7ec3\u5e76\u5728\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u5176\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u56e0\u679c\u6548\u5e94\u4f30\u8ba1\u65b9\u6cd5\u9700\u8981\u5e72\u9884\u6570\u636e\u6216\u56e0\u679c\u56fe\u77e5\u8bc6\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22PFNs\u5728\u56e0\u679c\u6548\u5e94\u4f30\u8ba1\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u9884\u8bad\u7ec3PFNs\u4e8e\u591a\u79cd\u56e0\u679c\u7ed3\u6784\u7684\u5408\u6210\u6570\u636e\uff0c\u5305\u62ec\u5e72\u9884\u6570\u636e\uff0c\u4ee5\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u9884\u6d4b\u5e72\u9884\u7ed3\u679c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u65e0\u9700\u56e0\u679c\u56fe\u77e5\u8bc6\u5373\u53ef\u51c6\u786e\u4f30\u8ba1\u56e0\u679c\u6548\u5e94\uff0c\u4e14\u5728\u4e0d\u540c\u56e0\u679c\u7279\u6027\u7684\u6570\u636e\u96c6\u4e2d\u8868\u73b0\u51fa\u53ef\u6269\u5c55\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "PFNs\u5728\u56e0\u679c\u6548\u5e94\u4f30\u8ba1\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4e3a\u65e0\u9700\u56e0\u679c\u56fe\u77e5\u8bc6\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.06045", "pdf": "https://arxiv.org/pdf/2506.06045", "abs": "https://arxiv.org/abs/2506.06045", "authors": ["Tobias W\u00fcrth", "Niklas Freymuth", "Gerhard Neumann", "Luise K\u00e4rger"], "title": "Diffusion-Based Hierarchical Graph Neural Networks for Simulating Nonlinear Solid Mechanics", "categories": ["cs.LG", "physics.comp-ph"], "comment": null, "summary": "Graph-based learned simulators have emerged as a promising approach for\nsimulating physical systems on unstructured meshes, offering speed and\ngeneralization across diverse geometries. However, they often struggle with\ncapturing global phenomena, such as bending or long-range correlations, and\nsuffer from error accumulation over long rollouts due to their reliance on\nlocal message passing and direct next-step prediction. We address these\nlimitations by introducing the Rolling Diffusion-Batched Inference Network\n(ROBIN), a novel learned simulator that integrates two key innovations: (i)\nRolling Diffusion, a parallelized inference scheme that amortizes the cost of\ndiffusion-based refinement across physical time steps by overlapping denoising\nsteps across a temporal window. (ii) A Hierarchical Graph Neural Network built\non algebraic multigrid coarsening, enabling multiscale message passing across\ndifferent mesh resolutions. This architecture, implemented via\nAlgebraic-hierarchical Message Passing Networks, captures both fine-scale local\ndynamics and global structural effects critical for phenomena like beam bending\nor multi-body contact. We validate ROBIN on challenging 2D and 3D solid\nmechanics benchmarks involving geometric, material, and contact nonlinearities.\nROBIN achieves state-of-the-art accuracy on all tasks, substantially\noutperforming existing next-step learned simulators while reducing inference\ntime by up to an order of magnitude compared to standard diffusion simulators.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aROBIN\u7684\u65b0\u578b\u5b66\u4e60\u6a21\u62df\u5668\uff0c\u901a\u8fc7Rolling Diffusion\u548c\u5206\u5c42\u56fe\u795e\u7ecf\u7f51\u7edc\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u6355\u6349\u5168\u5c40\u73b0\u8c61\u548c\u957f\u671f\u8bef\u5dee\u7d2f\u79ef\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u56fe\u7684\u5b66\u4e60\u6a21\u62df\u5668\u5728\u6355\u6349\u5168\u5c40\u73b0\u8c61\uff08\u5982\u5f2f\u66f2\u6216\u957f\u7a0b\u76f8\u5173\u6027\uff09\u548c\u957f\u671f\u8bef\u5dee\u7d2f\u79ef\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u4e3b\u8981\u4f9d\u8d56\u5c40\u90e8\u6d88\u606f\u4f20\u9012\u548c\u76f4\u63a5\u4e0b\u4e00\u6b65\u9884\u6d4b\u3002", "method": "ROBIN\u7ed3\u5408\u4e86\u4e24\u79cd\u521b\u65b0\u6280\u672f\uff1a(i) Rolling Diffusion\uff0c\u4e00\u79cd\u5e76\u884c\u5316\u63a8\u7406\u65b9\u6848\uff0c\u901a\u8fc7\u65f6\u95f4\u7a97\u53e3\u91cd\u53e0\u53bb\u566a\u6b65\u9aa4\u6765\u5206\u644a\u6269\u6563\u7ec6\u5316\u6210\u672c\uff1b(ii) \u57fa\u4e8e\u4ee3\u6570\u591a\u91cd\u7f51\u683c\u7c97\u5316\u7684\u5206\u5c42\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u5b9e\u73b0\u591a\u5c3a\u5ea6\u6d88\u606f\u4f20\u9012\u3002", "result": "\u5728\u6d89\u53ca\u51e0\u4f55\u3001\u6750\u6599\u548c\u63a5\u89e6\u975e\u7ebf\u6027\u76842D\u548c3D\u56fa\u4f53\u529b\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cROBIN\u5728\u6240\u6709\u4efb\u52a1\u4e0a\u5747\u8fbe\u5230\u6700\u5148\u8fdb\u7cbe\u5ea6\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5c06\u63a8\u7406\u65f6\u95f4\u51cf\u5c11\u4e00\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "ROBIN\u901a\u8fc7\u521b\u65b0\u8bbe\u8ba1\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u6a21\u62df\u5668\u7684\u5c40\u9650\u6027\uff0c\u5728\u7cbe\u5ea6\u548c\u6548\u7387\u4e0a\u5747\u6709\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2506.06048", "pdf": "https://arxiv.org/pdf/2506.06048", "abs": "https://arxiv.org/abs/2506.06048", "authors": ["Haripriya Harikumar", "Santu Rana"], "title": "TRUST: Test-time Resource Utilization for Superior Trustworthiness", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Standard uncertainty estimation techniques, such as dropout, often struggle\nto clearly distinguish reliable predictions from unreliable ones. We attribute\nthis limitation to noisy classifier weights, which, while not impairing overall\nclass-level predictions, render finer-level statistics less informative. To\naddress this, we propose a novel test-time optimization method that accounts\nfor the impact of such noise to produce more reliable confidence estimates.\nThis score defines a monotonic subset-selection function, where population\naccuracy consistently increases as samples with lower scores are removed, and\nit demonstrates superior performance in standard risk-based metrics such as\nAUSE and AURC. Additionally, our method effectively identifies discrepancies\nbetween training and test distributions, reliably differentiates\nin-distribution from out-of-distribution samples, and elucidates key\ndifferences between CNN and ViT classifiers across various vision datasets.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u6d4b\u8bd5\u65f6\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u51cf\u5c11\u5206\u7c7b\u5668\u6743\u91cd\u566a\u58f0\uff0c\u63d0\u5347\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u4f20\u7edf\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u65b9\u6cd5\uff08\u5982dropout\uff09\u96be\u4ee5\u533a\u5206\u53ef\u9760\u4e0e\u4e0d\u53ef\u9760\u9884\u6d4b\uff0c\u4e3b\u8981\u56e0\u5206\u7c7b\u5668\u6743\u91cd\u566a\u58f0\u5f71\u54cd\u7ec6\u7c92\u5ea6\u7edf\u8ba1\u4fe1\u606f\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u6d4b\u8bd5\u65f6\u4f18\u5316\u65b9\u6cd5\uff0c\u8003\u8651\u566a\u58f0\u5f71\u54cd\u4ee5\u751f\u6210\u66f4\u53ef\u9760\u7684\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\uff0c\u5b9a\u4e49\u5355\u8c03\u5b50\u96c6\u9009\u62e9\u51fd\u6570\u3002", "result": "\u5728AUSE\u548cAURC\u7b49\u98ce\u9669\u6307\u6807\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u80fd\u6709\u6548\u8bc6\u522b\u8bad\u7ec3\u4e0e\u6d4b\u8bd5\u5206\u5e03\u5dee\u5f02\u53ca\u533a\u5206\u5206\u5e03\u5185\u5916\u6837\u672c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u8d28\u91cf\uff0c\u5e76\u63ed\u793a\u4e86CNN\u4e0eViT\u5206\u7c7b\u5668\u5728\u89c6\u89c9\u6570\u636e\u96c6\u4e0a\u7684\u5173\u952e\u5dee\u5f02\u3002"}}
{"id": "2506.06073", "pdf": "https://arxiv.org/pdf/2506.06073", "abs": "https://arxiv.org/abs/2506.06073", "authors": ["Linda Lu", "Ayush Sekhari", "Karthik Sridharan"], "title": "System-Aware Unlearning Algorithms: Use Lesser, Forget Faster", "categories": ["cs.LG"], "comment": "ICML 2025", "summary": "Machine unlearning addresses the problem of updating a machine learning\nmodel/system trained on a dataset $S$ so that the influence of a set of\ndeletion requests $U \\subseteq S$ on the unlearned model is minimized. The gold\nstandard definition of unlearning demands that the updated model, after\ndeletion, be nearly identical to the model obtained by retraining. This\ndefinition is designed for a worst-case attacker (one who can recover not only\nthe unlearned model but also the remaining data samples, i.e., $S \\setminus\nU$). Such a stringent definition has made developing efficient unlearning\nalgorithms challenging. However, such strong attackers are also unrealistic. In\nthis work, we propose a new definition, system-aware unlearning, which aims to\nprovide unlearning guarantees against an attacker that can at best only gain\naccess to the data stored in the system for learning/unlearning requests and\nnot all of $S\\setminus U$. With this new definition, we use the simple\nintuition that if a system can store less to make its learning/unlearning\nupdates, it can be more secure and update more efficiently against a\nsystem-aware attacker. Towards that end, we present an exact system-aware\nunlearning algorithm for linear classification using a selective sampling-based\napproach, and we generalize the method for classification with general function\nclasses. We theoretically analyze the tradeoffs between deletion capacity,\naccuracy, memory, and computation time.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u673a\u5668\u5b66\u4e60\u9057\u5fd8\u5b9a\u4e49\u2014\u2014\u7cfb\u7edf\u611f\u77e5\u9057\u5fd8\uff0c\u9488\u5bf9\u73b0\u5b9e\u653b\u51fb\u8005\u8bbe\u8ba1\uff0c\u901a\u8fc7\u51cf\u5c11\u5b58\u50a8\u9700\u6c42\u63d0\u9ad8\u5b89\u5168\u6027\u548c\u6548\u7387\uff0c\u5e76\u63d0\u51fa\u4e86\u7ebf\u6027\u5206\u7c7b\u7684\u7cbe\u786e\u7b97\u6cd5\u3002", "motivation": "\u73b0\u6709\u9057\u5fd8\u5b9a\u4e49\u7684\u4e25\u683c\u6027\u5bfc\u81f4\u7b97\u6cd5\u5f00\u53d1\u56f0\u96be\uff0c\u4e14\u5047\u8bbe\u7684\u653b\u51fb\u8005\u8fc7\u4e8e\u5f3a\u5927\uff0c\u4e0d\u5207\u5b9e\u9645\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u73b0\u5b9e\u7684\u9057\u5fd8\u5b9a\u4e49\u3002", "method": "\u63d0\u51fa\u7cfb\u7edf\u611f\u77e5\u9057\u5fd8\u5b9a\u4e49\uff0c\u57fa\u4e8e\u9009\u62e9\u6027\u91c7\u6837\u7684\u65b9\u6cd5\u8bbe\u8ba1\u7cbe\u786e\u9057\u5fd8\u7b97\u6cd5\uff0c\u9002\u7528\u4e8e\u7ebf\u6027\u5206\u7c7b\u548c\u4e00\u822c\u51fd\u6570\u5206\u7c7b\u3002", "result": "\u7406\u8bba\u5206\u6790\u4e86\u5220\u9664\u5bb9\u91cf\u3001\u51c6\u786e\u6027\u3001\u5185\u5b58\u548c\u8ba1\u7b97\u65f6\u95f4\u4e4b\u95f4\u7684\u6743\u8861\u3002", "conclusion": "\u7cfb\u7edf\u611f\u77e5\u9057\u5fd8\u5b9a\u4e49\u66f4\u5b9e\u7528\uff0c\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u5b89\u5168\u6027\u548c\u6548\u7387\u4e0a\u8868\u73b0\u826f\u597d\u3002"}}
{"id": "2506.06095", "pdf": "https://arxiv.org/pdf/2506.06095", "abs": "https://arxiv.org/abs/2506.06095", "authors": ["Wenhao Dai", "Haodong Deng", "Mengfei Rong", "Xinyu Yang", "Hongyu Liu", "Fangxin Liu", "Hailong Yang", "Weifeng Liu", "Qingxiao Sun"], "title": "Flexible Operator Fusion for Fast Sparse Transformer with Diverse Masking on GPU", "categories": ["cs.LG"], "comment": null, "summary": "Large language models are popular around the world due to their powerful\nunderstanding capabilities. As the core component of LLMs, accelerating\nTransformer through parallelization has gradually become a hot research topic.\nMask layers introduce sparsity into Transformer to reduce calculations.\nHowever, previous works rarely focus on the performance optimization of sparse\nTransformer. Moreover, rule-based mechanisms ignore the fusion opportunities of\nmixed-type operators and fail to adapt to various sequence lengths. To address\nthe above problems, we propose STOF, a framework that incorporates\noptimizations for Sparse Transformer via flexible masking and operator fusion\non GPU. We firstly unify the storage format and kernel implementation for the\nmulti-head attention. Then, we map fusion schemes to compilation templates and\ndetermine the optimal parameter setting through a two-stage search engine. The\nexperimental results show that compared to the state-of-the-art work, STOF\nachieves maximum speedups of 1.7x in MHA computation and 1.5x in end-to-end\ninference.", "AI": {"tldr": "STOF\u6846\u67b6\u901a\u8fc7\u7075\u6d3b\u7684\u63a9\u7801\u548cGPU\u4e0a\u7684\u7b97\u5b50\u878d\u5408\u4f18\u5316\u7a00\u758fTransformer\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u52a0\u901fTransformer\u5e76\u884c\u5316\u662f\u70ed\u95e8\u7814\u7a76\uff0c\u4f46\u7a00\u758fTransformer\u7684\u6027\u80fd\u4f18\u5316\u548c\u6df7\u5408\u7b97\u5b50\u878d\u5408\u673a\u4f1a\u5e38\u88ab\u5ffd\u89c6\u3002", "method": "\u7edf\u4e00\u591a\u5934\u6ce8\u610f\u529b\u7684\u5b58\u50a8\u683c\u5f0f\u548c\u5185\u6838\u5b9e\u73b0\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u641c\u7d22\u5f15\u64ce\u786e\u5b9a\u6700\u4f73\u53c2\u6570\u8bbe\u7f6e\u3002", "result": "STOF\u5728MHA\u8ba1\u7b97\u548c\u7aef\u5230\u7aef\u63a8\u7406\u4e2d\u5206\u522b\u5b9e\u73b01.7\u500d\u548c1.5\u500d\u7684\u6700\u5927\u52a0\u901f\u3002", "conclusion": "STOF\u6709\u6548\u89e3\u51b3\u4e86\u7a00\u758fTransformer\u7684\u6027\u80fd\u4f18\u5316\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2506.06105", "pdf": "https://arxiv.org/pdf/2506.06105", "abs": "https://arxiv.org/abs/2506.06105", "authors": ["Rujikorn Charakorn", "Edoardo Cetin", "Yujin Tang", "Robert Tjarko Lange"], "title": "Text-to-LoRA: Instant Transformer Adaption", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at ICML 2025", "summary": "While Foundation Models provide a general tool for rapid content creation,\nthey regularly require task-specific adaptation. Traditionally, this exercise\ninvolves careful curation of datasets and repeated fine-tuning of the\nunderlying model. Fine-tuning techniques enable practitioners to adapt\nfoundation models for many new applications but require expensive and lengthy\ntraining while being notably sensitive to hyperparameter choices. To overcome\nthese limitations, we introduce Text-to-LoRA (T2L), a model capable of adapting\nlarge language models (LLMs) on the fly solely based on a natural language\ndescription of the target task. T2L is a hypernetwork trained to construct\nLoRAs in a single inexpensive forward pass. After training T2L on a suite of 9\npre-trained LoRA adapters (GSM8K, Arc, etc.), we show that the ad-hoc\nreconstructed LoRA instances match the performance of task-specific adapters\nacross the corresponding test sets. Furthermore, T2L can compress hundreds of\nLoRA instances and zero-shot generalize to entirely unseen tasks. This approach\nprovides a significant step towards democratizing the specialization of\nfoundation models and enables language-based adaptation with minimal compute\nrequirements.\n  Our code is available at https://github.com/SakanaAI/text-to-lora", "AI": {"tldr": "T2L\u662f\u4e00\u79cd\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u7684\u5373\u65f6\u9002\u914d\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5355\u6b21\u524d\u5411\u4f20\u64ad\u751f\u6210LoRA\u9002\u914d\u5668\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u4f20\u7edf\u5fae\u8c03\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u6570\u636e\u548c\u8ba1\u7b97\u8d44\u6e90\uff0c\u4e14\u5bf9\u8d85\u53c2\u6570\u654f\u611f\uff0cT2L\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "T2L\u662f\u4e00\u79cd\u8d85\u7f51\u7edc\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u751f\u6210LoRA\u9002\u914d\u5668\uff0c\u65e0\u9700\u91cd\u590d\u5fae\u8c03\u3002", "result": "T2L\u751f\u6210\u7684\u9002\u914d\u5668\u6027\u80fd\u4e0e\u4efb\u52a1\u4e13\u7528\u9002\u914d\u5668\u76f8\u5f53\uff0c\u5e76\u80fd\u96f6\u6837\u672c\u6cdb\u5316\u5230\u65b0\u4efb\u52a1\u3002", "conclusion": "T2L\u4e3a\u5927\u89c4\u6a21\u6a21\u578b\u7684\u9002\u914d\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u4f4e\u6210\u672c\u7684\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2506.06108", "pdf": "https://arxiv.org/pdf/2506.06108", "abs": "https://arxiv.org/abs/2506.06108", "authors": ["Graham Cormode", "Samuel Maddock", "Enayat Ullah", "Shripad Gade"], "title": "Synthetic Tabular Data: Methods, Attacks and Defenses", "categories": ["cs.LG", "cs.CR"], "comment": "Survey paper for accepted lecture-style tutorial at ACM KDD 2025", "summary": "Synthetic data is often positioned as a solution to replace sensitive\nfixed-size datasets with a source of unlimited matching data, freed from\nprivacy concerns. There has been much progress in synthetic data generation\nover the last decade, leveraging corresponding advances in machine learning and\ndata analytics. In this survey, we cover the key developments and the main\nconcepts in tabular synthetic data generation, including paradigms based on\nprobabilistic graphical models and on deep learning. We provide background and\nmotivation, before giving a technical deep-dive into the methodologies. We also\naddress the limitations of synthetic data, by studying attacks that seek to\nretrieve information about the original sensitive data. Finally, we present\nextensions and open problems in this area.", "AI": {"tldr": "\u7efc\u8ff0\u4e86\u8868\u683c\u5408\u6210\u6570\u636e\u751f\u6210\u7684\u5173\u952e\u8fdb\u5c55\u548c\u4e3b\u8981\u6982\u5ff5\uff0c\u5305\u62ec\u57fa\u4e8e\u6982\u7387\u56fe\u6a21\u578b\u548c\u6df1\u5ea6\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u5e76\u63a2\u8ba8\u4e86\u5408\u6210\u6570\u636e\u7684\u5c40\u9650\u6027\u53ca\u653b\u51fb\u624b\u6bb5\u3002", "motivation": "\u89e3\u51b3\u654f\u611f\u6570\u636e\u96c6\u7684\u9690\u79c1\u95ee\u9898\uff0c\u5229\u7528\u5408\u6210\u6570\u636e\u63d0\u4f9b\u65e0\u9650\u5339\u914d\u6570\u636e\u6e90\u3002", "method": "\u57fa\u4e8e\u6982\u7387\u56fe\u6a21\u578b\u548c\u6df1\u5ea6\u5b66\u4e60\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u65b9\u6cd5\u3002", "result": "\u603b\u7ed3\u4e86\u5408\u6210\u6570\u636e\u751f\u6210\u7684\u6280\u672f\u8fdb\u5c55\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u5176\u6f5c\u5728\u7684\u4fe1\u606f\u6cc4\u9732\u98ce\u9669\u3002", "conclusion": "\u5408\u6210\u6570\u636e\u5728\u9690\u79c1\u4fdd\u62a4\u65b9\u9762\u6709\u6f5c\u529b\uff0c\u4f46\u4ecd\u9700\u89e3\u51b3\u4fe1\u606f\u6cc4\u9732\u7b49\u5f00\u653e\u6027\u95ee\u9898\u3002"}}
{"id": "2506.06112", "pdf": "https://arxiv.org/pdf/2506.06112", "abs": "https://arxiv.org/abs/2506.06112", "authors": ["Cheng-Long Wang", "Qi Li", "Zihang Xiang", "Yinzhi Cao", "Di Wang"], "title": "Towards Lifecycle Unlearning Commitment Management: Measuring Sample-level Unlearning Completeness", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": "To appear in the Proceedings of USENIX Security Symposium, 2025", "summary": "Growing concerns over data privacy and security highlight the importance of\nmachine unlearning--removing specific data influences from trained models\nwithout full retraining. Techniques like Membership Inference Attacks (MIAs)\nare widely used to externally assess successful unlearning. However, existing\nmethods face two key limitations: (1) maximizing MIA effectiveness (e.g., via\nonline attacks) requires prohibitive computational resources, often exceeding\nretraining costs; (2) MIAs, designed for binary inclusion tests, struggle to\ncapture granular changes in approximate unlearning. To address these\nchallenges, we propose the Interpolated Approximate Measurement (IAM), a\nframework natively designed for unlearning inference. IAM quantifies\nsample-level unlearning completeness by interpolating the model's\ngeneralization-fitting behavior gap on queried samples. IAM achieves strong\nperformance in binary inclusion tests for exact unlearning and high correlation\nfor approximate unlearning--scalable to LLMs using just one pre-trained shadow\nmodel. We theoretically analyze how IAM's scoring mechanism maintains\nperformance efficiently. We then apply IAM to recent approximate unlearning\nalgorithms, revealing general risks of both over-unlearning and\nunder-unlearning, underscoring the need for stronger safeguards in approximate\nunlearning systems. The code is available at\nhttps://github.com/Happy2Git/Unlearning_Inference_IAM.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aIAM\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u91cf\u5316\u673a\u5668\u9057\u5fd8\u7684\u5b8c\u6574\u6027\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u8ba1\u7b97\u8d44\u6e90\u548c\u7c92\u5ea6\u4e0a\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u6570\u636e\u9690\u79c1\u548c\u5b89\u5168\u95ee\u9898\u65e5\u76ca\u7a81\u51fa\uff0c\u673a\u5668\u9057\u5fd8\uff08\u79fb\u9664\u7279\u5b9a\u6570\u636e\u5bf9\u6a21\u578b\u7684\u5f71\u54cd\uff09\u53d8\u5f97\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\uff08\u5982MIA\uff09\u5b58\u5728\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u5927\u548c\u7c92\u5ea6\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86Interpolated Approximate Measurement (IAM)\u6846\u67b6\uff0c\u901a\u8fc7\u63d2\u503c\u6a21\u578b\u7684\u6cdb\u5316-\u62df\u5408\u884c\u4e3a\u5dee\u8ddd\u6765\u91cf\u5316\u6837\u672c\u7ea7\u9057\u5fd8\u5b8c\u6574\u6027\u3002", "result": "IAM\u5728\u4e8c\u8fdb\u5236\u5305\u542b\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u9002\u7528\u4e8e\u8fd1\u4f3c\u9057\u5fd8\uff0c\u4e14\u8ba1\u7b97\u9ad8\u6548\uff0c\u4ec5\u9700\u4e00\u4e2a\u9884\u8bad\u7ec3\u7684shadow\u6a21\u578b\u3002", "conclusion": "IAM\u63ed\u793a\u4e86\u8fd1\u4f3c\u9057\u5fd8\u7b97\u6cd5\u4e2d\u8fc7\u5ea6\u9057\u5fd8\u548c\u4e0d\u8db3\u9057\u5fd8\u7684\u98ce\u9669\uff0c\u5f3a\u8c03\u4e86\u52a0\u5f3a\u8fd1\u4f3c\u9057\u5fd8\u7cfb\u7edf\u5b89\u5168\u6027\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2506.06114", "pdf": "https://arxiv.org/pdf/2506.06114", "abs": "https://arxiv.org/abs/2506.06114", "authors": ["Xudong Zhang", "Renato Cordeiro de Amorim"], "title": "Scalable unsupervised feature selection via weight stability", "categories": ["cs.LG"], "comment": null, "summary": "Unsupervised feature selection is critical for improving clustering\nperformance in high-dimensional data, where irrelevant features can obscure\nmeaningful structure. In this work, we introduce the Minkowski weighted\n$k$-means++, a novel initialisation strategy for the Minkowski Weighted\n$k$-means. Our initialisation selects centroids probabilistically using feature\nrelevance estimates derived from the data itself. Building on this, we propose\ntwo new feature selection algorithms, FS-MWK++, which aggregates feature\nweights across a range of Minkowski exponents to identify stable and\ninformative features, and SFS-MWK++, a scalable variant based on subsampling.\nWe support our approach with a theoretical guarantee under mild assumptions and\nextensive experiments showing that our methods consistently outperform existing\nalternatives.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eMinkowski\u52a0\u6743k-means++\u7684\u521d\u59cb\u5316\u7b56\u7565\uff0c\u5e76\u5f00\u53d1\u4e86\u4e24\u79cd\u65b0\u7279\u5f81\u9009\u62e9\u7b97\u6cd5FS-MWK++\u548cSFS-MWK++\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9ad8\u7ef4\u6570\u636e\u805a\u7c7b\u6027\u80fd\u3002", "motivation": "\u9ad8\u7ef4\u6570\u636e\u4e2d\u65e0\u5173\u7279\u5f81\u4f1a\u63a9\u76d6\u6709\u610f\u4e49\u7684\u7ed3\u6784\uff0c\u65e0\u76d1\u7763\u7279\u5f81\u9009\u62e9\u5bf9\u63d0\u5347\u805a\u7c7b\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51faMinkowski\u52a0\u6743k-means++\u521d\u59cb\u5316\u7b56\u7565\uff0c\u5e76\u57fa\u4e8e\u6b64\u5f00\u53d1FS-MWK++\u548cSFS-MWK++\u4e24\u79cd\u7279\u5f81\u9009\u62e9\u7b97\u6cd5\u3002", "result": "\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u9a8c\u8868\u660e\uff0c\u65b0\u65b9\u6cd5\u5728\u591a\u79cd\u60c5\u51b5\u4e0b\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u65b0\u65b9\u6cd5\u901a\u8fc7\u7279\u5f81\u6743\u91cd\u805a\u5408\u548c\u5b50\u91c7\u6837\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9ad8\u7ef4\u6570\u636e\u805a\u7c7b\u7684\u6548\u679c\u3002"}}
{"id": "2506.06122", "pdf": "https://arxiv.org/pdf/2506.06122", "abs": "https://arxiv.org/abs/2506.06122", "authors": ["Weixun Wang", "Shaopan Xiong", "Gengru Chen", "Wei Gao", "Sheng Guo", "Yancheng He", "Ju Huang", "Jiaheng Liu", "Zhendong Li", "Xiaoyang Li", "Zichen Liu", "Haizhou Zhao", "Dakai An", "Lunxi Cao", "Qiyang Cao", "Wanxi Deng", "Feilei Du", "Yiliang Gu", "Jiahe Li", "Xiang Li", "Mingjie Liu", "Yijia Luo", "Zihe Liu", "Yadao Wang", "Pei Wang", "Tianyuan Wu", "Yanan Wu", "Yuheng Zhao", "Shuaibing Zhao", "Jin Yang", "Siran Yang", "Yingshui Tan", "Huimin Yi", "Yuchi Xu", "Yujin Yuan", "Xingyao Zhang", "Lin Qu", "Wenbo Su", "Wei Wang", "Jiamang Wang", "Bo Zheng"], "title": "Reinforcement Learning Optimization for Large-Scale Learning: An Efficient and User-Friendly Scaling Library", "categories": ["cs.LG", "cs.DC"], "comment": "16 pages", "summary": "We introduce ROLL, an efficient, scalable, and user-friendly library designed\nfor Reinforcement Learning Optimization for Large-scale Learning. ROLL caters\nto three primary user groups: tech pioneers aiming for cost-effective,\nfault-tolerant large-scale training, developers requiring flexible control over\ntraining workflows, and researchers seeking agile experimentation. ROLL is\nbuilt upon several key modules to serve these user groups effectively. First, a\nsingle-controller architecture combined with an abstraction of the parallel\nworker simplifies the development of the training pipeline. Second, the\nparallel strategy and data transfer modules enable efficient and scalable\ntraining. Third, the rollout scheduler offers fine-grained management of each\nsample's lifecycle during the rollout stage. Fourth, the environment worker and\nreward worker support rapid and flexible experimentation with agentic RL\nalgorithms and reward designs. Finally, AutoDeviceMapping allows users to\nassign resources to different models flexibly across various stages.", "AI": {"tldr": "ROLL\u662f\u4e00\u4e2a\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u4e14\u7528\u6237\u53cb\u597d\u7684\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u5e93\uff0c\u9488\u5bf9\u5927\u89c4\u6a21\u5b66\u4e60\u9700\u6c42\u8bbe\u8ba1\uff0c\u670d\u52a1\u4e8e\u6280\u672f\u5148\u9a71\u3001\u5f00\u53d1\u8005\u548c\u7814\u7a76\u4eba\u5458\u3002", "motivation": "\u6ee1\u8db3\u4e0d\u540c\u7528\u6237\u7fa4\u4f53\u5728\u5927\u89c4\u6a21\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u4e2d\u7684\u9700\u6c42\uff0c\u5305\u62ec\u6210\u672c\u6548\u76ca\u3001\u7075\u6d3b\u63a7\u5236\u548c\u5feb\u901f\u5b9e\u9a8c\u3002", "method": "\u91c7\u7528\u5355\u63a7\u5236\u5668\u67b6\u6784\u3001\u5e76\u884c\u7b56\u7565\u6a21\u5757\u3001\u6570\u636e\u4f20\u9012\u6a21\u5757\u3001rollout\u8c03\u5ea6\u5668\u3001\u73af\u5883\u4e0e\u5956\u52b1\u5de5\u4f5c\u5668\uff0c\u4ee5\u53caAutoDeviceMapping\u6280\u672f\u3002", "result": "\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u4e14\u7075\u6d3b\u7684\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6d41\u7a0b\u3002", "conclusion": "ROLL\u4e3a\u4e0d\u540c\u7528\u6237\u7fa4\u4f53\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u5de5\u5177\uff0c\u652f\u6301\u5927\u89c4\u6a21\u5f3a\u5316\u5b66\u4e60\u7684\u4f18\u5316\u4e0e\u5b9e\u9a8c\u3002"}}
{"id": "2506.06127", "pdf": "https://arxiv.org/pdf/2506.06127", "abs": "https://arxiv.org/abs/2506.06127", "authors": ["Pascal Plettenberg", "Dominik K\u00f6hler", "Bernhard Sick", "Josephine M. Thomas"], "title": "Flow-Attentional Graph Neural Networks", "categories": ["cs.LG"], "comment": null, "summary": "Graph Neural Networks (GNNs) have become essential for learning from\ngraph-structured data. However, existing GNNs do not consider the conservation\nlaw inherent in graphs associated with a flow of physical resources, such as\nelectrical current in power grids or traffic in transportation networks, which\ncan lead to reduced model performance. To address this, we propose flow\nattention, which adapts existing graph attention mechanisms to satisfy\nKirchhoff\\'s first law. Furthermore, we discuss how this modification\ninfluences the expressivity and identify sets of non-isomorphic graphs that can\nbe discriminated by flow attention but not by standard attention. Through\nextensive experiments on two flow graph datasets (electronic circuits and power\ngrids), we demonstrate that flow attention enhances the performance of\nattention-based GNNs on both graph-level classification and regression tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u57fa\u5c14\u970d\u592b\u7b2c\u4e00\u5b9a\u5f8b\u7684\u6d41\u6ce8\u610f\u529b\u673a\u5236\uff0c\u63d0\u5347\u4e86\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u6d41\u56fe\u6570\u636e\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u56fe\u795e\u7ecf\u7f51\u7edc\u672a\u8003\u8651\u6d41\u56fe\u6570\u636e\u4e2d\u7684\u5b88\u6052\u5b9a\u5f8b\uff08\u5982\u7535\u6d41\u6216\u4ea4\u901a\u6d41\u91cf\uff09\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u63d0\u51fa\u6d41\u6ce8\u610f\u529b\u673a\u5236\uff0c\u6539\u8fdb\u73b0\u6709\u56fe\u6ce8\u610f\u529b\u673a\u5236\u4ee5\u6ee1\u8db3\u57fa\u5c14\u970d\u592b\u7b2c\u4e00\u5b9a\u5f8b\u3002", "result": "\u5728\u7535\u8def\u548c\u7535\u7f51\u6570\u636e\u96c6\u4e0a\uff0c\u6d41\u6ce8\u610f\u529b\u663e\u8457\u63d0\u5347\u4e86\u56fe\u5206\u7c7b\u548c\u56de\u5f52\u4efb\u52a1\u7684\u6027\u80fd\u3002", "conclusion": "\u6d41\u6ce8\u610f\u529b\u673a\u5236\u80fd\u6709\u6548\u6355\u6349\u6d41\u56fe\u6570\u636e\u7684\u5b88\u6052\u7279\u6027\uff0c\u63d0\u5347\u6a21\u578b\u8868\u73b0\u3002"}}
{"id": "2506.06130", "pdf": "https://arxiv.org/pdf/2506.06130", "abs": "https://arxiv.org/abs/2506.06130", "authors": ["Thomas Borsani", "Andrea Rosani", "Giuseppe Nicosia", "Giuseppe Di Fatta"], "title": "Gradient Similarity Surgery in Multi-Task Deep Learning", "categories": ["cs.LG", "cs.CV"], "comment": "Paper accepted at ECMLPKDD 2025", "summary": "The multi-task learning ($MTL$) paradigm aims to simultaneously learn\nmultiple tasks within a single model capturing higher-level, more general\nhidden patterns that are shared by the tasks. In deep learning, a significant\nchallenge in the backpropagation training process is the design of advanced\noptimisers to improve the convergence speed and stability of the gradient\ndescent learning rule. In particular, in multi-task deep learning ($MTDL$) the\nmultitude of tasks may generate potentially conflicting gradients that would\nhinder the concurrent convergence of the diverse loss functions. This challenge\narises when the gradients of the task objectives have either different\nmagnitudes or opposite directions, causing one or a few to dominate or to\ninterfere with each other, thus degrading the training process. Gradient\nsurgery methods address the problem explicitly dealing with conflicting\ngradients by adjusting the overall gradient trajectory. This work introduces a\nnovel gradient surgery method, the Similarity-Aware Momentum Gradient Surgery\n(SAM-GS), which provides an effective and scalable approach based on a gradient\nmagnitude similarity measure to guide the optimisation process. The SAM-GS\nsurgery adopts gradient equalisation and modulation of the first-order\nmomentum. A series of experimental tests have shown the effectiveness of SAM-GS\non synthetic problems and $MTL$ benchmarks. Gradient magnitude similarity plays\na crucial role in regularising gradient aggregation in $MTDL$ for the\noptimisation of the learning process.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u68af\u5ea6\u624b\u672f\u65b9\u6cd5SAM-GS\uff0c\u901a\u8fc7\u68af\u5ea6\u76f8\u4f3c\u6027\u5ea6\u91cf\u4f18\u5316\u591a\u4efb\u52a1\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u68af\u5ea6\u51b2\u7a81\u95ee\u9898\u3002", "motivation": "\u591a\u4efb\u52a1\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u68af\u5ea6\u51b2\u7a81\u4f1a\u963b\u788d\u4efb\u52a1\u7684\u5e76\u53d1\u6536\u655b\uff0c\u9700\u8981\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u8c03\u6574\u68af\u5ea6\u8f68\u8ff9\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u68af\u5ea6\u5e45\u5ea6\u76f8\u4f3c\u6027\u7684SAM-GS\u65b9\u6cd5\uff0c\u7ed3\u5408\u68af\u5ea6\u5747\u8861\u548c\u4e00\u9636\u52a8\u91cf\u7684\u8c03\u5236\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eSAM-GS\u5728\u5408\u6210\u95ee\u9898\u548c\u591a\u4efb\u52a1\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6709\u6548\u3002", "conclusion": "\u68af\u5ea6\u5e45\u5ea6\u76f8\u4f3c\u6027\u5bf9\u591a\u4efb\u52a1\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u68af\u5ea6\u805a\u5408\u548c\u4f18\u5316\u8fc7\u7a0b\u5177\u6709\u91cd\u8981\u4f5c\u7528\u3002"}}
{"id": "2506.06137", "pdf": "https://arxiv.org/pdf/2506.06137", "abs": "https://arxiv.org/abs/2506.06137", "authors": ["Rihui Jin", "Zheyu Xin", "Xing Xie", "Zuoyi Li", "Guilin Qi", "Yongrui Chen", "Xinbang Dai", "Tongtong Wu", "Gholamreza Haffari"], "title": "Table-r1: Self-supervised and Reinforcement Learning for Program-based Table Reasoning in Small Language Models", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Table reasoning (TR) requires structured reasoning over semi-structured\ntabular data and remains challenging, particularly for small language models\n(SLMs, e.g., LLaMA-8B) due to their limited capacity compared to large LMs\n(LLMs, e.g., GPT-4o). To narrow this gap, we explore program-based TR (P-TR),\nwhich circumvents key limitations of text-based TR (T-TR), notably in numerical\nreasoning, by generating executable programs. However, applying P-TR to SLMs\nintroduces two challenges: (i) vulnerability to heterogeneity in table layouts,\nand (ii) inconsistency in reasoning due to limited code generation capability.\nWe propose Table-r1, a two-stage P-TR method designed for SLMs. Stage 1\nintroduces an innovative self-supervised learning task, Layout Transformation\nInference, to improve tabular layout generalization from a programmatic view.\nStage 2 adopts a mix-paradigm variant of Group Relative Policy Optimization,\nenhancing P-TR consistency while allowing dynamic fallback to T-TR when needed.\nExperiments on four TR benchmarks demonstrate that Table-r1 outperforms all\nSLM-based methods, achieving at least a 15% accuracy improvement over the base\nmodel (LLaMA-8B) across all datasets and reaching performance competitive with\nLLMs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u5c0f\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\u7684\u8868\u683c\u63a8\u7406\u65b9\u6cd5Table-r1\uff0c\u901a\u8fc7\u7a0b\u5e8f\u5316\u63a8\u7406\uff08P-TR\uff09\u89e3\u51b3\u6587\u672c\u63a8\u7406\uff08T-TR\uff09\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5728\u5e03\u5c40\u6cdb\u5316\u548c\u63a8\u7406\u4e00\u81f4\u6027\u4e0a\u8fdb\u884c\u4e86\u4f18\u5316\u3002", "motivation": "\u8868\u683c\u63a8\u7406\uff08TR\uff09\u5bf9\u5c0f\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\u5177\u6709\u6311\u6218\u6027\uff0c\u7a0b\u5e8f\u5316\u63a8\u7406\uff08P-TR\uff09\u867d\u80fd\u89e3\u51b3\u6587\u672c\u63a8\u7406\uff08T-TR\uff09\u7684\u6570\u503c\u63a8\u7406\u95ee\u9898\uff0c\u4f46SLMs\u5728\u5e03\u5c40\u6cdb\u5316\u548c\u4ee3\u7801\u751f\u6210\u80fd\u529b\u4e0a\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u63d0\u51faTable-r1\u65b9\u6cd5\uff0c\u5206\u4e3a\u4e24\u9636\u6bb5\uff1a1\uff09\u901a\u8fc7\u81ea\u76d1\u7763\u5b66\u4e60\u4efb\u52a1Layout Transformation Inference\u63d0\u5347\u5e03\u5c40\u6cdb\u5316\uff1b2\uff09\u91c7\u7528\u6df7\u5408\u8303\u5f0fGroup Relative Policy Optimization\u589e\u5f3a\u63a8\u7406\u4e00\u81f4\u6027\uff0c\u5fc5\u8981\u65f6\u52a8\u6001\u56de\u9000\u5230T-TR\u3002", "result": "\u5728\u56db\u4e2aTR\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cTable-r1\u4f18\u4e8e\u6240\u6709\u57fa\u4e8eSLM\u7684\u65b9\u6cd5\uff0c\u51c6\u786e\u7387\u6bd4\u57fa\u7840\u6a21\u578b\uff08LLaMA-8B\uff09\u63d0\u5347\u81f3\u5c1115%\uff0c\u6027\u80fd\u63a5\u8fd1\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u3002", "conclusion": "Table-r1\u901a\u8fc7\u7a0b\u5e8f\u5316\u63a8\u7406\u548c\u4f18\u5316\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86SLMs\u5728\u8868\u683c\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u7f29\u5c0f\u4e86\u4e0eLLMs\u7684\u5dee\u8ddd\u3002"}}
{"id": "2506.06143", "pdf": "https://arxiv.org/pdf/2506.06143", "abs": "https://arxiv.org/abs/2506.06143", "authors": ["Carolin Benjamins", "Helena Graf", "Sarah Segel", "Difan Deng", "Tim Ruhkopf", "Leona Hennig", "Soham Basu", "Neeratyoy Mallik", "Edward Bergman", "Deyao Chen", "Fran\u00e7ois Cl\u00e9ment", "Matthias Feurer", "Katharina Eggensperger", "Frank Hutter", "Carola Doerr", "Marius Lindauer"], "title": "carps: A Framework for Comparing N Hyperparameter Optimizers on M Benchmarks", "categories": ["cs.LG"], "comment": null, "summary": "Hyperparameter Optimization (HPO) is crucial to develop well-performing\nmachine learning models. In order to ease prototyping and benchmarking of HPO\nmethods, we propose carps, a benchmark framework for Comprehensive Automated\nResearch Performance Studies allowing to evaluate N optimizers on M benchmark\ntasks. In this first release of carps, we focus on the four most important\ntypes of HPO task types: blackbox, multi-fidelity, multi-objective and\nmulti-fidelity-multi-objective. With 3 336 tasks from 5 community benchmark\ncollections and 28 variants of 9 optimizer families, we offer the biggest go-to\nlibrary to date to evaluate and compare HPO methods. The carps framework relies\non a purpose-built, lightweight interface, gluing together optimizers and\nbenchmark tasks. It also features an analysis pipeline, facilitating the\nevaluation of optimizers on benchmarks. However, navigating a huge number of\ntasks while developing and comparing methods can be computationally infeasible.\nTo address this, we obtain a subset of representative tasks by minimizing the\nstar discrepancy of the subset, in the space spanned by the full set. As a\nresult, we propose an initial subset of 10 to 30 diverse tasks for each task\ntype, and include functionality to re-compute subsets as more benchmarks become\navailable, enabling efficient evaluations. We also establish a first set of\nbaseline results on these tasks as a measure for future comparisons. With carps\n(https://www.github.com/automl/CARP-S), we make an important step in the\nstandardization of HPO evaluation.", "AI": {"tldr": "carps\u662f\u4e00\u4e2a\u7528\u4e8e\u8d85\u53c2\u6570\u4f18\u5316\uff08HPO\uff09\u65b9\u6cd5\u8bc4\u4f30\u7684\u57fa\u51c6\u6846\u67b6\uff0c\u63d0\u4f9b\u591a\u6837\u5316\u7684\u4efb\u52a1\u548c\u4f18\u5316\u5668\uff0c\u652f\u6301\u9ad8\u6548\u6bd4\u8f83\u548c\u5206\u6790\u3002", "motivation": "\u7b80\u5316HPO\u65b9\u6cd5\u7684\u539f\u578b\u8bbe\u8ba1\u548c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u63a8\u52a8\u6807\u51c6\u5316\u8bc4\u4f30\u3002", "method": "\u6784\u5efa\u8f7b\u91cf\u7ea7\u63a5\u53e3\u8fde\u63a5\u4f18\u5316\u5668\u548c\u57fa\u51c6\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7\u6700\u5c0f\u5316\u5b50\u96c6\u661f\u5dee\u5f02\u9009\u62e9\u4ee3\u8868\u6027\u4efb\u52a1\u3002", "result": "\u63d0\u4f9b3366\u4e2a\u4efb\u52a1\u548c28\u79cd\u4f18\u5316\u5668\u53d8\u4f53\uff0c\u63d0\u51fa10-30\u4e2a\u4ee3\u8868\u6027\u4efb\u52a1\u5b50\u96c6\uff0c\u5e76\u5efa\u7acb\u57fa\u7ebf\u7ed3\u679c\u3002", "conclusion": "carps\u6846\u67b6\u4e3aHPO\u8bc4\u4f30\u6807\u51c6\u5316\u8fc8\u51fa\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2506.06158", "pdf": "https://arxiv.org/pdf/2506.06158", "abs": "https://arxiv.org/abs/2506.06158", "authors": ["Armand Kassa\u00ef Koupa\u00ef", "Lise Le Boudec", "Louis Serrano", "Patrick Gallinari"], "title": "ENMA: Tokenwise Autoregression for Generative Neural PDE Operators", "categories": ["cs.LG"], "comment": null, "summary": "Solving time-dependent parametric partial differential equations (PDEs)\nremains a fundamental challenge for neural solvers, particularly when\ngeneralizing across a wide range of physical parameters and dynamics. When data\nis uncertain or incomplete-as is often the case-a natural approach is to turn\nto generative models. We introduce ENMA, a generative neural operator designed\nto model spatio-temporal dynamics arising from physical phenomena. ENMA\npredicts future dynamics in a compressed latent space using a generative masked\nautoregressive transformer trained with flow matching loss, enabling tokenwise\ngeneration. Irregularly sampled spatial observations are encoded into uniform\nlatent representations via attention mechanisms and further compressed through\na spatio-temporal convolutional encoder. This allows ENMA to perform in-context\nlearning at inference time by conditioning on either past states of the target\ntrajectory or auxiliary context trajectories with similar dynamics. The result\nis a robust and adaptable framework that generalizes to new PDE regimes and\nsupports one-shot surrogate modeling of time-dependent parametric PDEs.", "AI": {"tldr": "ENMA\u662f\u4e00\u79cd\u751f\u6210\u795e\u7ecf\u7b97\u5b50\uff0c\u7528\u4e8e\u5efa\u6a21\u7269\u7406\u73b0\u8c61\u4e2d\u7684\u65f6\u7a7a\u52a8\u6001\uff0c\u901a\u8fc7\u751f\u6210\u63a9\u7801\u81ea\u56de\u5f52\u53d8\u6362\u5668\u548c\u6d41\u5339\u914d\u635f\u5931\u9884\u6d4b\u672a\u6765\u52a8\u6001\uff0c\u652f\u6301\u5bf9\u65b0PDE\u4f53\u7cfb\u7684\u4e00\u6b21\u6027\u4ee3\u7406\u5efa\u6a21\u3002", "motivation": "\u89e3\u51b3\u65f6\u95f4\u4f9d\u8d56\u53c2\u6570\u504f\u5fae\u5206\u65b9\u7a0b\uff08PDEs\uff09\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u4e0d\u786e\u5b9a\u6216\u4e0d\u5b8c\u6574\u65f6\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6cdb\u5316\u5230\u5e7f\u6cdb\u7269\u7406\u53c2\u6570\u548c\u52a8\u6001\u7684\u65b9\u6cd5\u3002", "method": "ENMA\u4f7f\u7528\u751f\u6210\u63a9\u7801\u81ea\u56de\u5f52\u53d8\u6362\u5668\u548c\u6d41\u5339\u914d\u635f\u5931\u5728\u538b\u7f29\u6f5c\u5728\u7a7a\u95f4\u4e2d\u9884\u6d4b\u52a8\u6001\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u548c\u65f6\u7a7a\u5377\u79ef\u7f16\u7801\u5668\u5904\u7406\u4e0d\u89c4\u5219\u91c7\u6837\u6570\u636e\u3002", "result": "ENMA\u80fd\u591f\u6cdb\u5316\u5230\u65b0\u7684PDE\u4f53\u7cfb\uff0c\u652f\u6301\u4e00\u6b21\u6027\u4ee3\u7406\u5efa\u6a21\uff0c\u5e76\u5177\u5907\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\u3002", "conclusion": "ENMA\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9c81\u68d2\u4e14\u9002\u5e94\u6027\u5f3a\u7684\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u65f6\u95f4\u4f9d\u8d56\u53c2\u6570PDEs\u7684\u5efa\u6a21\u548c\u9884\u6d4b\u3002"}}
{"id": "2506.06166", "pdf": "https://arxiv.org/pdf/2506.06166", "abs": "https://arxiv.org/abs/2506.06166", "authors": ["Tianyi Alex Qiu", "Zhonghao He", "Tejasveer Chugh", "Max Kleiman-Weiner"], "title": "The Lock-in Hypothesis: Stagnation by Algorithm", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CY", "cs.HC"], "comment": "ICML 2025, 46 pages", "summary": "The training and deployment of large language models (LLMs) create a feedback\nloop with human users: models learn human beliefs from data, reinforce these\nbeliefs with generated content, reabsorb the reinforced beliefs, and feed them\nback to users again and again. This dynamic resembles an echo chamber. We\nhypothesize that this feedback loop entrenches the existing values and beliefs\nof users, leading to a loss of diversity and potentially the lock-in of false\nbeliefs. We formalize this hypothesis and test it empirically with agent-based\nLLM simulations and real-world GPT usage data. Analysis reveals sudden but\nsustained drops in diversity after the release of new GPT iterations,\nconsistent with the hypothesized human-AI feedback loop. Code and data\navailable at https://thelockinhypothesis.com", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e0e\u4eba\u7c7b\u7528\u6237\u4e4b\u95f4\u7684\u53cd\u9988\u5faa\u73af\uff0c\u53d1\u73b0\u8fd9\u79cd\u5faa\u73af\u53ef\u80fd\u5bfc\u81f4\u4fe1\u5ff5\u56fa\u5316\u3001\u591a\u6837\u6027\u4e27\u5931\u548c\u865a\u5047\u4fe1\u5ff5\u9501\u5b9a\u3002\u901a\u8fc7\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u9a8c\u8bc1\u4e86\u8fd9\u4e00\u5047\u8bbe\u3002", "motivation": "\u63a2\u8ba8LLM\u4e0e\u4eba\u7c7b\u7528\u6237\u4e4b\u95f4\u7684\u53cd\u9988\u5faa\u73af\u5982\u4f55\u5f71\u54cd\u4fe1\u5ff5\u591a\u6837\u6027\u548c\u771f\u5b9e\u6027\uff0c\u63ed\u793a\u6f5c\u5728\u7684\u8d1f\u9762\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u4ee3\u7406\u7684LLM\u6a21\u62df\u548c\u771f\u5b9eGPT\u4f7f\u7528\u6570\u636e\uff0c\u5f62\u5f0f\u5316\u5e76\u9a8c\u8bc1\u53cd\u9988\u5faa\u73af\u5047\u8bbe\u3002", "result": "\u5206\u6790\u663e\u793a\uff0c\u65b0GPT\u7248\u672c\u53d1\u5e03\u540e\uff0c\u591a\u6837\u6027\u7a81\u7136\u4e14\u6301\u7eed\u4e0b\u964d\uff0c\u9a8c\u8bc1\u4e86\u53cd\u9988\u5faa\u73af\u7684\u5b58\u5728\u3002", "conclusion": "LLM\u4e0e\u4eba\u7c7b\u7684\u53cd\u9988\u5faa\u73af\u53ef\u80fd\u5bfc\u81f4\u4fe1\u5ff5\u56fa\u5316\u548c\u591a\u6837\u6027\u4e27\u5931\uff0c\u9700\u5f15\u8d77\u5173\u6ce8\u3002"}}
{"id": "2506.06178", "pdf": "https://arxiv.org/pdf/2506.06178", "abs": "https://arxiv.org/abs/2506.06178", "authors": ["Alessandro Montenegro", "Federico Mansutti", "Marco Mussi", "Matteo Papini", "Alberto Maria Metelli"], "title": "Reusing Trajectories in Policy Gradients Enables Fast Convergence", "categories": ["cs.LG"], "comment": null, "summary": "Policy gradient (PG) methods are a class of effective reinforcement learning\nalgorithms, particularly when dealing with continuous control problems. These\nmethods learn the parameters of parametric policies via stochastic gradient\nascent, typically using on-policy trajectory data to estimate the policy\ngradient. However, such reliance on fresh data makes them sample-inefficient.\nIndeed, vanilla PG methods require $O(\\epsilon^{-2})$ trajectories to reach an\n$\\epsilon$-approximate stationary point. A common strategy to improve\nefficiency is to reuse off-policy information from past iterations, such as\nprevious gradients or trajectories. While gradient reuse has received\nsubstantial theoretical attention, leading to improved rates of\n$O(\\epsilon^{-3/2})$, the reuse of past trajectories remains largely unexplored\nfrom a theoretical perspective. In this work, we provide the first rigorous\ntheoretical evidence that extensive reuse of past off-policy trajectories can\nsignificantly accelerate convergence in PG methods. We introduce a power mean\ncorrection to the multiple importance weighting estimator and propose RPG\n(Retrospective Policy Gradient), a PG algorithm that combines old and new\ntrajectories for policy updates. Through a novel analysis, we show that, under\nestablished assumptions, RPG achieves a sample complexity of\n$\\widetilde{O}(\\epsilon^{-1})$, the best known rate in the literature. We\nfurther validate empirically our approach against PG methods with\nstate-of-the-art rates.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.06179", "pdf": "https://arxiv.org/pdf/2506.06179", "abs": "https://arxiv.org/abs/2506.06179", "authors": ["Muhammed Ustaomeroglu", "Guannan Qu"], "title": "A Theoretical Study of (Hyper) Self-Attention through the Lens of Interactions: Representation, Training, Generalization", "categories": ["cs.LG", "stat.ML", "68T07, 90C26, 68Q32"], "comment": "Accepted to ICML 2025", "summary": "Self-attention has emerged as a core component of modern neural\narchitectures, yet its theoretical underpinnings remain elusive. In this paper,\nwe study self-attention through the lens of interacting entities, ranging from\nagents in multi-agent reinforcement learning to alleles in genetic sequences,\nand show that a single layer linear self-attention can efficiently represent,\nlearn, and generalize functions capturing pairwise interactions, including\nout-of-distribution scenarios. Our analysis reveals that self-attention acts as\na mutual interaction learner under minimal assumptions on the diversity of\ninteraction patterns observed during training, thereby encompassing a wide\nvariety of real-world domains. In addition, we validate our theoretical\ninsights through experiments demonstrating that self-attention learns\ninteraction functions and generalizes across both population distributions and\nout-of-distribution scenarios. Building on our theories, we introduce\nHyperFeatureAttention, a novel neural network module designed to learn\ncouplings of different feature-level interactions between entities.\nFurthermore, we propose HyperAttention, a new module that extends beyond\npairwise interactions to capture multi-entity dependencies, such as three-way,\nfour-way, or general n-way interactions.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u81ea\u6ce8\u610f\u529b\u673a\u5236\u7684\u7406\u8bba\u57fa\u7840\uff0c\u8868\u660e\u5355\u5c42\u7ebf\u6027\u81ea\u6ce8\u610f\u529b\u80fd\u9ad8\u6548\u8868\u793a\u548c\u5b66\u4e60\u6210\u5bf9\u4ea4\u4e92\u51fd\u6570\uff0c\u5e76\u63a8\u5e7f\u5230\u5206\u5e03\u5916\u573a\u666f\u3002", "motivation": "\u81ea\u6ce8\u610f\u529b\u662f\u73b0\u4ee3\u795e\u7ecf\u67b6\u6784\u7684\u6838\u5fc3\u7ec4\u4ef6\uff0c\u4f46\u5176\u7406\u8bba\u57fa\u7840\u5c1a\u4e0d\u660e\u786e\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u5206\u6790\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u548c\u9057\u4f20\u5e8f\u5217\u4e2d\u7684\u4ea4\u4e92\u5b9e\u4f53\uff0c\u63d0\u51fa\u5355\u5c42\u7ebf\u6027\u81ea\u6ce8\u610f\u529b\u6a21\u578b\uff0c\u5e76\u9a8c\u8bc1\u5176\u5b66\u4e60\u4ea4\u4e92\u51fd\u6570\u7684\u80fd\u529b\u3002", "result": "\u81ea\u6ce8\u610f\u529b\u5728\u8bad\u7ec3\u4e2d\u80fd\u5b66\u4e60\u4ea4\u4e92\u51fd\u6570\uff0c\u5e76\u5728\u5206\u5e03\u5916\u573a\u666f\u4e2d\u6cdb\u5316\u826f\u597d\u3002\u6b64\u5916\uff0c\u63d0\u51fa\u4e86HyperFeatureAttention\u548cHyperAttention\u6a21\u5757\uff0c\u6269\u5c55\u4e86\u4ea4\u4e92\u5efa\u6a21\u80fd\u529b\u3002", "conclusion": "\u81ea\u6ce8\u610f\u529b\u662f\u4e00\u79cd\u901a\u7528\u7684\u4ea4\u4e92\u5b66\u4e60\u673a\u5236\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u5b9e\u9645\u573a\u666f\uff0c\u65b0\u6a21\u5757\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u5176\u5efa\u6a21\u590d\u6742\u4ea4\u4e92\u7684\u80fd\u529b\u3002"}}
{"id": "2506.06185", "pdf": "https://arxiv.org/pdf/2506.06185", "abs": "https://arxiv.org/abs/2506.06185", "authors": ["Jing Jia", "Sifan Liu", "Bowen Song", "Wei Yuan", "Liyue Shen", "Guanyang Wang"], "title": "Antithetic Noise in Diffusion Models", "categories": ["cs.LG", "cs.NA", "math.NA", "stat.CO", "stat.ML"], "comment": "43 pages, 20 figures, 9 tables", "summary": "We initiate a systematic study of antithetic initial noise in diffusion\nmodels. Across unconditional models trained on diverse datasets,\ntext-conditioned latent-diffusion models, and diffusion-posterior samplers, we\nfind that pairing each initial noise with its negation consistently yields\nstrongly negatively correlated samples. To explain this phenomenon, we combine\nexperiments and theoretical analysis, leading to a symmetry conjecture that the\nlearned score function is approximately affine antisymmetric (odd symmetry up\nto a constant shift), and provide evidence supporting it. Leveraging this\nnegative correlation, we enable two applications: (1) enhancing image diversity\nin models like Stable Diffusion without quality loss, and (2) sharpening\nuncertainty quantification (e.g., up to 90% narrower confidence intervals) when\nestimating downstream statistics. Building on these gains, we extend the\ntwo-point pairing to a randomized quasi-Monte Carlo estimator, which further\nimproves estimation accuracy. Our framework is training-free, model-agnostic,\nand adds no runtime overhead.", "AI": {"tldr": "\u7814\u7a76\u4e86\u6269\u6563\u6a21\u578b\u4e2d\u521d\u59cb\u566a\u58f0\u7684\u5bf9\u79f0\u6027\u53ca\u5176\u5e94\u7528\uff0c\u53d1\u73b0\u521d\u59cb\u566a\u58f0\u4e0e\u5176\u5426\u5b9a\u914d\u5bf9\u53ef\u751f\u6210\u8d1f\u76f8\u5173\u6837\u672c\uff0c\u5e76\u63d0\u51fa\u4e86\u5bf9\u79f0\u6027\u731c\u60f3\u3002", "motivation": "\u63a2\u7d22\u6269\u6563\u6a21\u578b\u4e2d\u521d\u59cb\u566a\u58f0\u7684\u5bf9\u79f0\u6027\u53ca\u5176\u5bf9\u6837\u672c\u751f\u6210\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u5f71\u54cd\u3002", "method": "\u7ed3\u5408\u5b9e\u9a8c\u548c\u7406\u8bba\u5206\u6790\uff0c\u63d0\u51fa\u521d\u59cb\u566a\u58f0\u4e0e\u5176\u5426\u5b9a\u914d\u5bf9\u7684\u5bf9\u79f0\u6027\u731c\u60f3\uff0c\u5e76\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "result": "\u53d1\u73b0\u521d\u59cb\u566a\u58f0\u7684\u5bf9\u79f0\u6027\u53ef\u63d0\u5347\u56fe\u50cf\u591a\u6837\u6027\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7cbe\u5ea6\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u3001\u6a21\u578b\u65e0\u5173\u4e14\u65e0\u8fd0\u884c\u65f6\u5f00\u9500\u7684\u6846\u67b6\uff0c\u53ef\u5e94\u7528\u4e8e\u56fe\u50cf\u751f\u6210\u548c\u7edf\u8ba1\u4f30\u8ba1\u3002"}}
{"id": "2506.06188", "pdf": "https://arxiv.org/pdf/2506.06188", "abs": "https://arxiv.org/abs/2506.06188", "authors": ["Luis Kin Miyatake", "Eduardo Camponogara", "Eric Aislan Antonelo", "Alexey Pavlov"], "title": "Physics-Informed Neural Networks for Control of Single-Phase Flow Systems Governed by Partial Differential Equations", "categories": ["cs.LG"], "comment": "62 pages, 14 figures", "summary": "The modeling and control of single-phase flow systems governed by Partial\nDifferential Equations (PDEs) present challenges, especially under transient\nconditions. In this work, we extend the Physics-Informed Neural Nets for\nControl (PINC) framework, originally proposed to modeling and control of\nOrdinary Differential Equations (ODE) without the need of any labeled data, to\nthe PDE case, particularly to single-phase incompressible and compressible\nflows, integrating neural networks with physical conservation laws. The PINC\nmodel for PDEs is structured into two stages: a steady-state network, which\nlearns equilibrium solutions for a wide range of control inputs, and a\ntransient network, which captures dynamic responses under time-varying boundary\nconditions. We propose a simplifying assumption that reduces the dimensionality\nof the spatial coordinate regarding the initial condition, allowing the\nefficient training of the PINC network. This simplification enables the\nderivation of optimal control policies using Model Predictive Control (MPC). We\nvalidate our approach through numerical experiments, demonstrating that the\nPINC model, which is trained exclusively using physical laws, i.e., without\nlabeled data, accurately represents flow dynamics and enables real-time control\napplications. The results highlight the PINC's capability to efficiently\napproximate PDE solutions without requiring iterative solvers, making it a\npromising alternative for fluid flow monitoring and optimization in engineering\napplications.", "AI": {"tldr": "\u8bba\u6587\u6269\u5c55\u4e86PINC\u6846\u67b6\uff0c\u5c06\u5176\u4eceODE\u63a7\u5236\u6269\u5c55\u5230PDE\u63a7\u5236\uff0c\u7528\u4e8e\u5355\u76f8\u6d41\u7cfb\u7edf\uff0c\u7ed3\u5408\u795e\u7ecf\u7f51\u7edc\u4e0e\u7269\u7406\u5b88\u6052\u5b9a\u5f8b\uff0c\u65e0\u9700\u6807\u6ce8\u6570\u636e\u5373\u53ef\u5b9e\u73b0\u5efa\u6a21\u4e0e\u63a7\u5236\u3002", "motivation": "\u5355\u76f8\u6d41\u7cfb\u7edf\u7684PDE\u5efa\u6a21\u4e0e\u63a7\u5236\u5b58\u5728\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u77ac\u6001\u6761\u4ef6\u4e0b\u3002\u7814\u7a76\u65e8\u5728\u901a\u8fc7PINC\u6846\u67b6\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "PINC\u6a21\u578b\u5206\u4e3a\u7a33\u6001\u7f51\u7edc\u548c\u77ac\u6001\u7f51\u7edc\uff0c\u901a\u8fc7\u7b80\u5316\u7a7a\u95f4\u5750\u6807\u7ef4\u5ea6\u5047\u8bbe\uff0c\u7ed3\u5408MPC\u5b9e\u73b0\u9ad8\u6548\u8bad\u7ec3\u4e0e\u63a7\u5236\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u8868\u660e\uff0cPINC\u6a21\u578b\u80fd\u51c6\u786e\u8868\u793a\u6d41\u52a8\u52a8\u529b\u5b66\u5e76\u652f\u6301\u5b9e\u65f6\u63a7\u5236\uff0c\u65e0\u9700\u8fed\u4ee3\u6c42\u89e3\u5668\u3002", "conclusion": "PINC\u4e3a\u6d41\u4f53\u6d41\u52a8\u76d1\u6d4b\u4e0e\u4f18\u5316\u63d0\u4f9b\u4e86\u9ad8\u6548\u66ff\u4ee3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u5de5\u7a0b\u5e94\u7528\u3002"}}
{"id": "2506.06192", "pdf": "https://arxiv.org/pdf/2506.06192", "abs": "https://arxiv.org/abs/2506.06192", "authors": ["Dimitrios Proios", "Alban Bornet", "Anthony Yazdani", "Jose F Rodrigues Jr", "Douglas Teodoro"], "title": "ICU-TSB: A Benchmark for Temporal Patient Representation Learning for Unsupervised Stratification into Patient Cohorts", "categories": ["cs.LG"], "comment": "6 pages 1 table 6 figures", "summary": "Patient stratification identifying clinically meaningful subgroups is\nessential for advancing personalized medicine through improved diagnostics and\ntreatment strategies. Electronic health records (EHRs), particularly those from\nintensive care units (ICUs), contain rich temporal clinical data that can be\nleveraged for this purpose. In this work, we introduce ICU-TSB (Temporal\nStratification Benchmark), the first comprehensive benchmark for evaluating\npatient stratification based on temporal patient representation learning using\nthree publicly available ICU EHR datasets. A key contribution of our benchmark\nis a novel hierarchical evaluation framework utilizing disease taxonomies to\nmeasure the alignment of discovered clusters with clinically validated disease\ngroupings. In our experiments with ICU-TSB, we compared statistical methods and\nseveral recurrent neural networks, including LSTM and GRU, for their ability to\ngenerate effective patient representations for subsequent clustering of patient\ntrajectories. Our results demonstrate that temporal representation learning can\nrediscover clinically meaningful patient cohorts; nevertheless, it remains a\nchallenging task, with v-measuring varying from up to 0.46 at the top level of\nthe taxonomy to up to 0.40 at the lowest level. To further enhance the\npractical utility of our findings, we also evaluate multiple strategies for\nassigning interpretable labels to the identified clusters. The experiments and\nbenchmark are fully reproducible and available at\nhttps://github.com/ds4dh/CBMS2025stratification.", "AI": {"tldr": "ICU-TSB\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u57fa\u4e8e\u65f6\u95f4\u60a3\u8005\u8868\u793a\u5b66\u4e60\u7684\u60a3\u8005\u5206\u5c42\u7684\u57fa\u51c6\uff0c\u5229\u7528ICU\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u6570\u636e\uff0c\u901a\u8fc7\u5206\u5c42\u8bc4\u4f30\u6846\u67b6\u9a8c\u8bc1\u4e34\u5e8a\u610f\u4e49\u3002", "motivation": "\u63a8\u52a8\u4e2a\u6027\u5316\u533b\u7597\uff0c\u901a\u8fc7\u6539\u8fdb\u8bca\u65ad\u548c\u6cbb\u7597\u7b56\u7565\uff0c\u5229\u7528ICU\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u4e2d\u7684\u4e30\u5bcc\u65f6\u95f4\u6570\u636e\u3002", "method": "\u5f15\u5165ICU-TSB\u57fa\u51c6\uff0c\u6bd4\u8f83\u7edf\u8ba1\u65b9\u6cd5\u548c\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff08\u5982LSTM\u548cGRU\uff09\u751f\u6210\u60a3\u8005\u8868\u793a\u7684\u80fd\u529b\uff0c\u5e76\u8bc4\u4f30\u805a\u7c7b\u6548\u679c\u3002", "result": "\u65f6\u95f4\u8868\u793a\u5b66\u4e60\u80fd\u91cd\u65b0\u53d1\u73b0\u4e34\u5e8a\u610f\u4e49\u7684\u60a3\u8005\u7fa4\u4f53\uff0c\u4f46\u4efb\u52a1\u4ecd\u5177\u6311\u6218\u6027\uff08v-measure\u6700\u9ad80.46\uff09\u3002", "conclusion": "ICU-TSB\u4e3a\u60a3\u8005\u5206\u5c42\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u7684\u57fa\u51c6\uff0c\u672a\u6765\u53ef\u8fdb\u4e00\u6b65\u4f18\u5316\u805a\u7c7b\u6807\u7b7e\u7684\u4e34\u5e8a\u89e3\u91ca\u6027\u3002"}}
{"id": "2506.06194", "pdf": "https://arxiv.org/pdf/2506.06194", "abs": "https://arxiv.org/abs/2506.06194", "authors": ["Sibylle Marcotte", "R\u00e9mi Gribonval", "Gabriel Peyr\u00e9"], "title": "Transformative or Conservative? Conservation laws for ResNets and Transformers", "categories": ["cs.LG"], "comment": "Accepted to ICML 2025", "summary": "While conservation laws in gradient flow training dynamics are well\nunderstood for (mostly shallow) ReLU and linear networks, their study remains\nlargely unexplored for more practical architectures. This paper bridges this\ngap by deriving and analyzing conservation laws for modern architectures, with\na focus on convolutional ResNets and Transformer networks. For this, we first\nshow that basic building blocks such as ReLU (or linear) shallow networks, with\nor without convolution, have easily expressed conservation laws, and no more\nthan the known ones. In the case of a single attention layer, we also\ncompletely describe all conservation laws, and we show that residual blocks\nhave the same conservation laws as the same block without a skip connection. We\nthen introduce the notion of conservation laws that depend only on a subset of\nparameters (corresponding e.g. to a pair of consecutive layers, to a residual\nblock, or to an attention layer). We demonstrate that the characterization of\nsuch laws can be reduced to the analysis of the corresponding building block in\nisolation. Finally, we examine how these newly discovered conservation\nprinciples, initially established in the continuous gradient flow regime,\npersist under discrete optimization dynamics, particularly in the context of\nStochastic Gradient Descent (SGD).", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u73b0\u4ee3\u67b6\u6784\uff08\u5982\u5377\u79efResNets\u548cTransformer\u7f51\u7edc\uff09\u4e2d\u7684\u5b88\u6052\u5b9a\u5f8b\uff0c\u586b\u8865\u4e86\u73b0\u6709\u7814\u7a76\u7684\u7a7a\u767d\u3002", "motivation": "\u7814\u7a76\u68af\u5ea6\u6d41\u8bad\u7ec3\u52a8\u6001\u4e2d\u7684\u5b88\u6052\u5b9a\u5f8b\u5728\u5b9e\u7528\u67b6\u6784\u4e2d\u7684\u5e94\u7528\uff0c\u5c24\u5176\u662f\u5377\u79efResNets\u548cTransformer\u7f51\u7edc\u3002", "method": "\u901a\u8fc7\u5206\u6790\u57fa\u672c\u6784\u5efa\u5757\uff08\u5982ReLU\u6216\u7ebf\u6027\u6d45\u5c42\u7f51\u7edc\uff09\u7684\u5b88\u6052\u5b9a\u5f8b\uff0c\u5e76\u6269\u5c55\u5230\u5355\u6ce8\u610f\u529b\u5c42\u548c\u6b8b\u5dee\u5757\u3002\u5f15\u5165\u4f9d\u8d56\u4e8e\u53c2\u6570\u5b50\u96c6\u7684\u5b88\u6052\u5b9a\u5f8b\u6982\u5ff5\u3002", "result": "\u8bc1\u660e\u4e86\u8fd9\u4e9b\u5b88\u6052\u5b9a\u5f8b\u5728\u8fde\u7eed\u68af\u5ea6\u6d41\u548c\u79bb\u6563\u4f18\u5316\u52a8\u6001\uff08\u5982SGD\uff09\u4e2d\u7684\u6301\u4e45\u6027\u3002", "conclusion": "\u8bba\u6587\u4e3a\u73b0\u4ee3\u67b6\u6784\u4e2d\u7684\u5b88\u6052\u5b9a\u5f8b\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5206\u6790\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u79bb\u6563\u4f18\u5316\u4e2d\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2506.06204", "pdf": "https://arxiv.org/pdf/2506.06204", "abs": "https://arxiv.org/abs/2506.06204", "authors": ["Elie Kadoche", "Pascal Bianchi", "Florence Carton", "Philippe Ciblat", "Damien Ernst"], "title": "How to craft a deep reinforcement learning policy for wind farm flow control", "categories": ["cs.LG"], "comment": null, "summary": "Within wind farms, wake effects between turbines can significantly reduce\noverall energy production. Wind farm flow control encompasses methods designed\nto mitigate these effects through coordinated turbine control. Wake steering,\nfor example, consists in intentionally misaligning certain turbines with the\nwind to optimize airflow and increase power output. However, designing a robust\nwake steering controller remains challenging, and existing machine learning\napproaches are limited to quasi-static wind conditions or small wind farms.\nThis work presents a new deep reinforcement learning methodology to develop a\nwake steering policy that overcomes these limitations. Our approach introduces\na novel architecture that combines graph attention networks and multi-head\nself-attention blocks, alongside a novel reward function and training strategy.\nThe resulting model computes the yaw angles of each turbine, optimizing energy\nproduction in time-varying wind conditions. An empirical study conducted on\nsteady-state, low-fidelity simulation, shows that our model requires\napproximately 10 times fewer training steps than a fully connected neural\nnetwork and achieves more robust performance compared to a strong optimization\nbaseline, increasing energy production by up to 14 %. To the best of our\nknowledge, this is the first deep reinforcement learning-based wake steering\ncontroller to generalize effectively across any time-varying wind conditions in\na low-fidelity, steady-state numerical simulation setting.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bbe\u8ba1\u98ce\u7535\u573a\u4e2d\u7684\u5c3e\u6d41\u5bfc\u5411\u63a7\u5236\u5668\uff0c\u4ee5\u4f18\u5316\u80fd\u91cf\u751f\u4ea7\u3002", "motivation": "\u98ce\u7535\u573a\u4e2d\u6da1\u8f6e\u673a\u4e4b\u95f4\u7684\u5c3e\u6d41\u6548\u5e94\u4f1a\u663e\u8457\u964d\u4f4e\u6574\u4f53\u80fd\u91cf\u751f\u4ea7\uff0c\u800c\u73b0\u6709\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u4ec5\u9002\u7528\u4e8e\u9759\u6001\u98ce\u51b5\u6216\u5c0f\u578b\u98ce\u7535\u573a\u3002", "method": "\u91c7\u7528\u7ed3\u5408\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\u548c\u591a\u5934\u81ea\u6ce8\u610f\u529b\u5757\u7684\u65b0\u67b6\u6784\uff0c\u4ee5\u53ca\u65b0\u7684\u5956\u52b1\u51fd\u6570\u548c\u8bad\u7ec3\u7b56\u7565\uff0c\u5f00\u53d1\u5c3e\u6d41\u5bfc\u5411\u7b56\u7565\u3002", "result": "\u6a21\u578b\u5728\u4f4e\u4fdd\u771f\u7a33\u6001\u6a21\u62df\u4e2d\uff0c\u6bd4\u5168\u8fde\u63a5\u795e\u7ecf\u7f51\u7edc\u5c11\u752810\u500d\u8bad\u7ec3\u6b65\u9aa4\uff0c\u80fd\u91cf\u751f\u4ea7\u63d0\u5347\u9ad8\u8fbe14%\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u80fd\u5728\u65f6\u53d8\u98ce\u51b5\u4e0b\u6709\u6548\u6cdb\u5316\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u5c3e\u6d41\u5bfc\u5411\u63a7\u5236\u5668\u3002"}}
{"id": "2506.06212", "pdf": "https://arxiv.org/pdf/2506.06212", "abs": "https://arxiv.org/abs/2506.06212", "authors": ["Ali Azizpour", "Nicolas Zilberstein", "Santiago Segarra"], "title": "Model-Driven Graph Contrastive Learning", "categories": ["cs.LG"], "comment": null, "summary": "We propose $\\textbf{MGCL}$, a model-driven graph contrastive learning (GCL)\nframework that leverages graphons (probabilistic generative models for graphs)\nto guide contrastive learning by accounting for the data's underlying\ngenerative process. GCL has emerged as a powerful self-supervised framework for\nlearning expressive node or graph representations without relying on annotated\nlabels, which are often scarce in real-world data. By contrasting augmented\nviews of graph data, GCL has demonstrated strong performance across various\ndownstream tasks, such as node and graph classification. However, existing\nmethods typically rely on manually designed or heuristic augmentation\nstrategies that are not tailored to the underlying data distribution and\noperate at the individual graph level, ignoring similarities among graphs\ngenerated from the same model. Conversely, in our proposed approach, MGCL first\nestimates the graphon associated with the observed data and then defines a\ngraphon-informed augmentation process, enabling data-adaptive and principled\naugmentations. Additionally, for graph-level tasks, MGCL clusters the dataset\nand estimates a graphon per group, enabling contrastive pairs to reflect shared\nsemantics and structure. Extensive experiments on benchmark datasets\ndemonstrate that MGCL achieves state-of-the-art performance, highlighting the\nadvantages of incorporating generative models into GCL.", "AI": {"tldr": "MGCL\u662f\u4e00\u79cd\u57fa\u4e8e\u6a21\u578b\u9a71\u52a8\u7684\u56fe\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528\u56fe\u751f\u6210\u6a21\u578b\uff08graphons\uff09\u6307\u5bfc\u5bf9\u6bd4\u5b66\u4e60\uff0c\u901a\u8fc7\u6570\u636e\u751f\u6210\u8fc7\u7a0b\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u6709GCL\u65b9\u6cd5\u4f9d\u8d56\u624b\u52a8\u8bbe\u8ba1\u7684\u589e\u5f3a\u7b56\u7565\uff0c\u672a\u8003\u8651\u6570\u636e\u751f\u6210\u5206\u5e03\uff0c\u4e14\u5ffd\u7565\u540c\u6a21\u578b\u751f\u6210\u7684\u56fe\u95f4\u76f8\u4f3c\u6027\u3002MGCL\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "MGCL\u9996\u5148\u4f30\u8ba1\u6570\u636e\u7684graphon\uff0c\u5b9a\u4e49\u57fa\u4e8egraphon\u7684\u589e\u5f3a\u8fc7\u7a0b\uff0c\u5b9e\u73b0\u6570\u636e\u81ea\u9002\u5e94\u589e\u5f3a\uff1b\u5bf9\u56fe\u7ea7\u4efb\u52a1\uff0c\u6309\u7ec4\u805a\u7c7b\u5e76\u4f30\u8ba1graphon\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cMGCL\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u5c06\u751f\u6210\u6a21\u578b\u878d\u5165GCL\u7684\u4f18\u52bf\u3002", "conclusion": "MGCL\u901a\u8fc7\u7ed3\u5408\u751f\u6210\u6a21\u578b\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u4f18\u7684\u56fe\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002"}}
{"id": "2506.06215", "pdf": "https://arxiv.org/pdf/2506.06215", "abs": "https://arxiv.org/abs/2506.06215", "authors": ["Itai Gat", "Neta Shaul", "Uriel Singer", "Yaron Lipman"], "title": "Corrector Sampling in Language Models", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Autoregressive language models accumulate errors due to their fixed,\nirrevocable left-to-right token generation. To address this, we propose a new\nsampling method called Resample-Previous-Tokens (RPT). RPT mitigates error\naccumulation by iteratively revisiting and potentially replacing tokens in a\nwindow of previously generated text. This method can be integrated into\nexisting autoregressive models, preserving their next-token-prediction quality\nand speed. Fine-tuning a pretrained 8B parameter model with RPT for only 100B\nresulted in ~10% relative improvements on reasoning and coding benchmarks\ncompared to the standard sampling.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRPT\u7684\u65b0\u91c7\u6837\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fed\u4ee3\u91cd\u65b0\u8bbf\u95ee\u548c\u66ff\u6362\u5148\u524d\u751f\u6210\u7684\u6587\u672c\u6765\u51cf\u5c11\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u9519\u8bef\u7d2f\u79ef\u3002", "motivation": "\u89e3\u51b3\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u56e0\u56fa\u5b9a\u7684\u4ece\u5de6\u5230\u53f3\u6807\u8bb0\u751f\u6210\u800c\u5bfc\u81f4\u7684\u9519\u8bef\u7d2f\u79ef\u95ee\u9898\u3002", "method": "\u63d0\u51faResample-Previous-Tokens (RPT)\u65b9\u6cd5\uff0c\u8fed\u4ee3\u91cd\u65b0\u8bbf\u95ee\u5e76\u53ef\u80fd\u66ff\u6362\u5148\u524d\u751f\u6210\u7684\u6587\u672c\u7a97\u53e3\u4e2d\u7684\u6807\u8bb0\u3002", "result": "\u57288B\u53c2\u6570\u6a21\u578b\u4e0a\u4ec5\u7528100B\u6570\u636e\u8fdb\u884c\u5fae\u8c03\u540e\uff0c\u63a8\u7406\u548c\u7f16\u7801\u57fa\u51c6\u6d4b\u8bd5\u76f8\u5bf9\u6807\u51c6\u91c7\u6837\u63d0\u5347\u4e86\u7ea610%\u3002", "conclusion": "RPT\u65b9\u6cd5\u6709\u6548\u51cf\u5c11\u4e86\u9519\u8bef\u7d2f\u79ef\uff0c\u4e14\u80fd\u4fdd\u6301\u73b0\u6709\u81ea\u56de\u5f52\u6a21\u578b\u7684\u9884\u6d4b\u8d28\u91cf\u548c\u901f\u5ea6\u3002"}}
{"id": "2506.06231", "pdf": "https://arxiv.org/pdf/2506.06231", "abs": "https://arxiv.org/abs/2506.06231", "authors": ["Mohammad Jalali", "Bahar Dibaei Nia", "Farzan Farnia"], "title": "Towards an Explainable Comparison and Alignment of Feature Embeddings", "categories": ["cs.LG", "cs.AI", "cs.CV", "math.SP"], "comment": null, "summary": "While several feature embedding models have been developed in the literature,\ncomparisons of these embeddings have largely focused on their numerical\nperformance in classification-related downstream applications. However, an\ninterpretable comparison of different embeddings requires identifying and\nanalyzing mismatches between sample groups clustered within the embedding\nspaces. In this work, we propose the \\emph{Spectral Pairwise Embedding\nComparison (SPEC)} framework to compare embeddings and identify their\ndifferences in clustering a reference dataset. Our approach examines the kernel\nmatrices derived from two embeddings and leverages the eigendecomposition of\nthe difference kernel matrix to detect sample clusters that are captured\ndifferently by the two embeddings. We present a scalable implementation of this\nkernel-based approach, with computational complexity that grows linearly with\nthe sample size. Furthermore, we introduce an optimization problem using this\nframework to align two embeddings, ensuring that clusters identified in one\nembedding are also captured in the other model. We provide numerical results\ndemonstrating the SPEC's application to compare and align embeddings on\nlarge-scale datasets such as ImageNet and MS-COCO. The code is available at\n[https://github.com/mjalali/embedding-comparison](github.com/mjalali/embedding-comparison).", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSPEC\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u6bd4\u8f83\u4e0d\u540c\u7279\u5f81\u5d4c\u5165\u6a21\u578b\u5728\u805a\u7c7b\u4efb\u52a1\u4e2d\u7684\u5dee\u5f02\uff0c\u5e76\u901a\u8fc7\u6838\u77e9\u9635\u5206\u6790\u8bc6\u522b\u6837\u672c\u7fa4\u7684\u4e0d\u5339\u914d\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5d4c\u5165\u6a21\u578b\u7684\u6570\u503c\u6027\u80fd\uff0c\u800c\u7f3a\u4e4f\u5bf9\u5d4c\u5165\u7a7a\u95f4\u805a\u7c7b\u5dee\u5f02\u7684\u53ef\u89e3\u91ca\u6027\u6bd4\u8f83\u3002", "method": "\u5229\u7528\u6838\u77e9\u9635\u7684\u8c31\u5206\u89e3\u5206\u6790\u5d4c\u5165\u5dee\u5f02\uff0c\u63d0\u51fa\u53ef\u6269\u5c55\u7684\u7ebf\u6027\u590d\u6742\u5ea6\u5b9e\u73b0\uff0c\u5e76\u901a\u8fc7\u4f18\u5316\u95ee\u9898\u5bf9\u9f50\u5d4c\u5165\u3002", "result": "\u5728ImageNet\u548cMS-COCO\u7b49\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86SPEC\u7684\u6709\u6548\u6027\u3002", "conclusion": "SPEC\u4e3a\u5d4c\u5165\u6a21\u578b\u7684\u6bd4\u8f83\u548c\u5bf9\u9f50\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u5de5\u5177\u3002"}}
{"id": "2506.06244", "pdf": "https://arxiv.org/pdf/2506.06244", "abs": "https://arxiv.org/abs/2506.06244", "authors": ["Aditya Kommineni", "Woojae Jeong", "Kleanthis Avramidis", "Colin McDaniel", "Myzelle Hughes", "Thomas McGee", "Elsi Kaiser", "Kristina Lerman", "Idan A. Blank", "Dani Byrd", "Assal Habibi", "B. Rael Cahn", "Sudarsana Kadiri", "Takfarinas Medani", "Richard M. Leahy", "Shrikanth Narayanan"], "title": "Neural Responses to Affective Sentences Reveal Signatures of Depression", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Major Depressive Disorder (MDD) is a highly prevalent mental health\ncondition, and a deeper understanding of its neurocognitive foundations is\nessential for identifying how core functions such as emotional and\nself-referential processing are affected. We investigate how depression alters\nthe temporal dynamics of emotional processing by measuring neural responses to\nself-referential affective sentences using surface electroencephalography (EEG)\nin healthy and depressed individuals. Our results reveal significant\ngroup-level differences in neural activity during sentence viewing, suggesting\ndisrupted integration of emotional and self-referential information in\ndepression. Deep learning model trained on these responses achieves an area\nunder the receiver operating curve (AUC) of 0.707 in distinguishing healthy\nfrom depressed participants, and 0.624 in differentiating depressed subgroups\nwith and without suicidal ideation. Spatial ablations highlight anterior\nelectrodes associated with semantic and affective processing as key\ncontributors. These findings suggest stable, stimulus-driven neural signatures\nof depression that may inform future diagnostic tools.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7EEG\u6d4b\u91cf\u6291\u90c1\u4e0e\u5065\u5eb7\u4e2a\u4f53\u5bf9\u81ea\u6211\u53c2\u7167\u60c5\u611f\u53e5\u5b50\u7684\u795e\u7ecf\u53cd\u5e94\uff0c\u53d1\u73b0\u6291\u90c1\u60c5\u7eea\u5904\u7406\u5f02\u5e38\uff0c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u53ef\u533a\u5206\u6291\u90c1\u4e0e\u5065\u5eb7\u4eba\u7fa4\u53ca\u6291\u90c1\u4e9a\u7ec4\u3002", "motivation": "\u6df1\u5165\u7406\u89e3\u6291\u90c1\u75c7\u7684\u795e\u7ecf\u8ba4\u77e5\u57fa\u7840\uff0c\u5c24\u5176\u662f\u60c5\u611f\u548c\u81ea\u6211\u53c2\u7167\u5904\u7406\u7684\u5f02\u5e38\u3002", "method": "\u4f7f\u7528\u8868\u9762EEG\u6d4b\u91cf\u5065\u5eb7\u4e0e\u6291\u90c1\u4e2a\u4f53\u5bf9\u81ea\u6211\u53c2\u7167\u60c5\u611f\u53e5\u5b50\u7684\u795e\u7ecf\u53cd\u5e94\uff0c\u5e76\u8bad\u7ec3\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5206\u6790\u6570\u636e\u3002", "result": "\u53d1\u73b0\u6291\u90c1\u7ec4\u5728\u53e5\u5b50\u89c2\u770b\u65f6\u795e\u7ecf\u6d3b\u52a8\u663e\u8457\u4e0d\u540c\uff0c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u533a\u5206\u5065\u5eb7\u4e0e\u6291\u90c1\u7684AUC\u4e3a0.707\uff0c\u533a\u5206\u6291\u90c1\u4e9a\u7ec4\u7684AUC\u4e3a0.624\u3002", "conclusion": "\u6291\u90c1\u5b58\u5728\u7a33\u5b9a\u7684\u795e\u7ecf\u7279\u5f81\uff0c\u53ef\u80fd\u4e3a\u672a\u6765\u8bca\u65ad\u5de5\u5177\u63d0\u4f9b\u4f9d\u636e\u3002"}}
{"id": "2506.06248", "pdf": "https://arxiv.org/pdf/2506.06248", "abs": "https://arxiv.org/abs/2506.06248", "authors": ["Guillaume Pourcel", "Debabrota Basu", "Maxence Ernoult", "Aditya Gilra"], "title": "Lagrangian-based Equilibrium Propagation: generalisation to arbitrary boundary conditions & equivalence with Hamiltonian Echo Learning", "categories": ["cs.LG"], "comment": null, "summary": "Equilibrium Propagation (EP) is a learning algorithm for training\nEnergy-based Models (EBMs) on static inputs which leverages the variational\ndescription of their fixed points. Extending EP to time-varying inputs is a\nchallenging problem, as the variational description must apply to the entire\nsystem trajectory rather than just fixed points, and careful consideration of\nboundary conditions becomes essential. In this work, we present Generalized\nLagrangian Equilibrium Propagation (GLEP), which extends the variational\nformulation of EP to time-varying inputs. We demonstrate that GLEP yields\ndifferent learning algorithms depending on the boundary conditions of the\nsystem, many of which are impractical for implementation. We then show that\nHamiltonian Echo Learning (HEL) -- which includes the recently proposed\nRecurrent HEL (RHEL) and the earlier known Hamiltonian Echo Backpropagation\n(HEB) algorithms -- can be derived as a special case of GLEP. Notably, HEL is\nthe only instance of GLEP we found that inherits the properties that make EP a\ndesirable alternative to backpropagation for hardware implementations: it\noperates in a \"forward-only\" manner (i.e. using the same system for both\ninference and learning), it scales efficiently (requiring only two or more\npasses through the system regardless of model size), and enables local\nlearning.", "AI": {"tldr": "GLEP\u6269\u5c55\u4e86EP\u7b97\u6cd5\uff0c\u9002\u7528\u4e8e\u65f6\u53d8\u8f93\u5165\uff0c\u5e76\u5c55\u793a\u4e86\u4e0d\u540c\u8fb9\u754c\u6761\u4ef6\u5bf9\u5b66\u4e60\u7b97\u6cd5\u7684\u5f71\u54cd\u3002HEL\u662fGLEP\u7684\u7279\u4f8b\uff0c\u7ee7\u627f\u4e86EP\u7684\u786c\u4ef6\u53cb\u597d\u7279\u6027\u3002", "motivation": "\u89e3\u51b3EP\u7b97\u6cd5\u5728\u65f6\u53d8\u8f93\u5165\u4e2d\u7684\u6269\u5c55\u95ee\u9898\uff0c\u5e76\u63a2\u7d22\u5176\u5b9e\u9645\u5e94\u7528\u7684\u53ef\u884c\u6027\u3002", "method": "\u63d0\u51faGLEP\uff0c\u901a\u8fc7\u53d8\u5206\u63cf\u8ff0\u6269\u5c55EP\u81f3\u65f6\u53d8\u8f93\u5165\uff0c\u5206\u6790\u4e0d\u540c\u8fb9\u754c\u6761\u4ef6\u7684\u5f71\u54cd\uff0c\u5e76\u63a8\u5bfcHEL\u4f5c\u4e3a\u7279\u4f8b\u3002", "result": "GLEP\u751f\u6210\u591a\u79cd\u5b66\u4e60\u7b97\u6cd5\uff0c\u4f46\u4ec5HEL\u5177\u5907\u786c\u4ef6\u53cb\u597d\u7279\u6027\uff08\u524d\u5411\u64cd\u4f5c\u3001\u9ad8\u6548\u6269\u5c55\u3001\u5c40\u90e8\u5b66\u4e60\uff09\u3002", "conclusion": "HEL\u662fGLEP\u4e2d\u552f\u4e00\u5b9e\u7528\u7684\u7b97\u6cd5\uff0c\u7ee7\u627f\u4e86EP\u7684\u786c\u4ef6\u4f18\u52bf\uff0c\u9002\u5408\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2506.06278", "pdf": "https://arxiv.org/pdf/2506.06278", "abs": "https://arxiv.org/abs/2506.06278", "authors": ["Bruce W. Lee", "Addie Foote", "Alex Infanger", "Leni Shor", "Harish Kamath", "Jacob Goldman-Wetzler", "Bryce Woodworth", "Alex Cloud", "Alexander Matt Turner"], "title": "Distillation Robustifies Unlearning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Current LLM unlearning methods are not robust: they can be reverted easily\nwith a few steps of finetuning. This is true even for the idealized unlearning\nmethod of training to imitate an oracle model that was never exposed to\nunwanted information, suggesting that output-based finetuning is insufficient\nto achieve robust unlearning. In a similar vein, we find that training a\nrandomly initialized student to imitate an unlearned model transfers desired\nbehaviors while leaving undesired capabilities behind. In other words,\ndistillation robustifies unlearning. Building on this insight, we propose\nUnlearn-Noise-Distill-on-Outputs (UNDO), a scalable method that distills an\nunlearned model into a partially noised copy of itself. UNDO introduces a\ntunable tradeoff between compute cost and robustness, establishing a new Pareto\nfrontier on synthetic language and arithmetic tasks. At its strongest setting,\nUNDO matches the robustness of a model retrained from scratch with perfect data\nfiltering while using only 60-80% of the compute and requiring only 0.01% of\nthe pretraining data to be labeled. We also show that UNDO robustifies\nunlearning on the more realistic Weapons of Mass Destruction Proxy (WMDP)\nbenchmark. Since distillation is widely used in practice, incorporating an\nunlearning step beforehand offers a convenient path to robust capability\nremoval.", "AI": {"tldr": "\u5f53\u524dLLM\u9057\u5fd8\u65b9\u6cd5\u4e0d\u9c81\u68d2\uff0c\u6613\u88ab\u5fae\u8c03\u6062\u590d\u3002\u63d0\u51faUNDO\u65b9\u6cd5\uff0c\u901a\u8fc7\u84b8\u998f\u589e\u5f3a\u9057\u5fd8\u9c81\u68d2\u6027\uff0c\u8ba1\u7b97\u6210\u672c\u4f4e\u4e14\u6548\u679c\u597d\u3002", "motivation": "\u73b0\u6709\u9057\u5fd8\u65b9\u6cd5\u6613\u88ab\u5fae\u8c03\u6062\u590d\uff0c\u8f93\u51fa\u5fae\u8c03\u4e0d\u8db3\u4ee5\u5b9e\u73b0\u9c81\u68d2\u9057\u5fd8\u3002", "method": "\u63d0\u51faUNDO\u65b9\u6cd5\uff0c\u901a\u8fc7\u84b8\u998f\u672a\u5b66\u4e60\u6a21\u578b\u5230\u90e8\u5206\u566a\u58f0\u526f\u672c\u4e2d\uff0c\u5e73\u8861\u8ba1\u7b97\u6210\u672c\u4e0e\u9c81\u68d2\u6027\u3002", "result": "UNDO\u5728\u5408\u6210\u4efb\u52a1\u4e2d\u5339\u914d\u4ece\u5934\u8bad\u7ec3\u7684\u9c81\u68d2\u6027\uff0c\u8ba1\u7b97\u6210\u672c\u4ec560-80%\uff0c\u4e14\u4ec5\u97000.01%\u6807\u8bb0\u6570\u636e\u3002\u5728WMDP\u57fa\u51c6\u4e0a\u4e5f\u8868\u73b0\u826f\u597d\u3002", "conclusion": "\u84b8\u998f\u7ed3\u5408\u9057\u5fd8\u6b65\u9aa4\u4e3a\u9c81\u68d2\u80fd\u529b\u79fb\u9664\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\u3002"}}
{"id": "2506.06280", "pdf": "https://arxiv.org/pdf/2506.06280", "abs": "https://arxiv.org/abs/2506.06280", "authors": ["Yuanzhe Hu", "Kinshuk Goel", "Vlad Killiakov", "Yaoqing Yang"], "title": "Eigenspectrum Analysis of Neural Networks without Aspect Ratio Bias", "categories": ["cs.LG", "cs.AI"], "comment": "30 pages, 14 figures, published to ICML 2025", "summary": "Diagnosing deep neural networks (DNNs) through the eigenspectrum of weight\nmatrices has been an active area of research in recent years. At a high level,\neigenspectrum analysis of DNNs involves measuring the heavytailness of the\nempirical spectral densities (ESD) of weight matrices. It provides insight into\nhow well a model is trained and can guide decisions on assigning better\nlayer-wise training hyperparameters. In this paper, we address a challenge\nassociated with such eigenspectrum methods: the impact of the aspect ratio of\nweight matrices on estimated heavytailness metrics. We demonstrate that\nmatrices of varying sizes (and aspect ratios) introduce a non-negligible bias\nin estimating heavytailness metrics, leading to inaccurate model diagnosis and\nlayer-wise hyperparameter assignment. To overcome this challenge, we propose\nFARMS (Fixed-Aspect-Ratio Matrix Subsampling), a method that normalizes the\nweight matrices by subsampling submatrices with a fixed aspect ratio. Instead\nof measuring the heavytailness of the original ESD, we measure the average ESD\nof these subsampled submatrices. We show that measuring the heavytailness of\nthese submatrices with the fixed aspect ratio can effectively mitigate the\naspect ratio bias. We validate our approach across various optimization\ntechniques and application domains that involve eigenspectrum analysis of\nweights, including image classification in computer vision (CV) models,\nscientific machine learning (SciML) model training, and large language model\n(LLM) pruning. Our results show that despite its simplicity, FARMS uniformly\nimproves the accuracy of eigenspectrum analysis while enabling more effective\nlayer-wise hyperparameter assignment in these application domains. In one of\nthe LLM pruning experiments, FARMS reduces the perplexity of the LLaMA-7B model\nby 17.3% when compared with the state-of-the-art method.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faFARMS\u65b9\u6cd5\uff0c\u901a\u8fc7\u56fa\u5b9a\u957f\u5bbd\u6bd4\u5b50\u77e9\u9635\u91c7\u6837\u89e3\u51b3\u6743\u91cd\u77e9\u9635\u957f\u5bbd\u6bd4\u5bf9\u7279\u5f81\u8c31\u5206\u6790\u7684\u5f71\u54cd\uff0c\u63d0\u5347\u6a21\u578b\u8bca\u65ad\u548c\u8d85\u53c2\u6570\u5206\u914d\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u7814\u7a76\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6743\u91cd\u77e9\u9635\u7279\u5f81\u8c31\u5206\u6790\u4e2d\uff0c\u77e9\u9635\u957f\u5bbd\u6bd4\u5bf9\u91cd\u5c3e\u6027\u4f30\u8ba1\u7684\u504f\u5dee\u95ee\u9898\uff0c\u5f71\u54cd\u6a21\u578b\u8bca\u65ad\u548c\u8d85\u53c2\u6570\u5206\u914d\u3002", "method": "\u63d0\u51faFARMS\u65b9\u6cd5\uff0c\u901a\u8fc7\u56fa\u5b9a\u957f\u5bbd\u6bd4\u5b50\u77e9\u9635\u91c7\u6837\uff0c\u6d4b\u91cf\u5176\u5e73\u5747\u7279\u5f81\u8c31\u5bc6\u5ea6\uff0c\u4ee5\u6d88\u9664\u957f\u5bbd\u6bd4\u504f\u5dee\u3002", "result": "FARMS\u5728\u591a\u79cd\u5e94\u7528\u9886\u57df\uff08\u5982\u56fe\u50cf\u5206\u7c7b\u3001\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4fee\u526a\uff09\u4e2d\u663e\u8457\u63d0\u5347\u7279\u5f81\u8c31\u5206\u6790\u51c6\u786e\u6027\uff0c\u5e76\u5728LLaMA-7B\u6a21\u578b\u4fee\u526a\u4e2d\u964d\u4f4e\u56f0\u60d1\u5ea617.3%\u3002", "conclusion": "FARMS\u662f\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u6d88\u9664\u7279\u5f81\u8c31\u5206\u6790\u4e2d\u7684\u957f\u5bbd\u6bd4\u504f\u5dee\uff0c\u63d0\u5347\u6a21\u578b\u8bca\u65ad\u548c\u8d85\u53c2\u6570\u5206\u914d\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2406.03674", "pdf": "https://arxiv.org/pdf/2406.03674", "abs": "https://arxiv.org/abs/2406.03674", "authors": ["Negin Golrezaei", "Sourav Sahoo"], "title": "Learning Safe Strategies for Value Maximizing Buyers in Uniform Price Auctions", "categories": ["cs.DS", "cs.GT", "cs.LG"], "comment": "61 pages, 4 figures. To appear at ICML 2025", "summary": "We study the bidding problem in repeated uniform price multi-unit auctions\nfrom the perspective of a single value-maximizing buyer who aims to maximize\ntheir cumulative value over $T$ rounds while adhering to return-on-investment\n(RoI) constraints in each round. Buyers adopt $m$-uniform bidding format, where\nthey submit $m$ bid-quantity pairs $(b_i, q_i)$ to demand $q_i$ units at bid\n$b_i$. We introduce safe bidding strategies as those that satisfy RoI\nconstraints in every auction, regardless of competing bids. We show that these\nstrategies depend only on the valuation curve of the bidder, and the bidder can\nfocus on a finite subset of this class without loss of generality. While the\nnumber of strategies in this subset is exponential in $m$, we develop a\npolynomial-time algorithm to learn the optimal safe strategy that achieves\nsublinear regret in the online setting, where regret is measured against a\nclairvoyant benchmark that knows the competing bids a priori and selects a\nfixed hindsight optimal safe strategy. We then evaluate the performance of safe\nstrategies against a clairvoyant that selects the optimal strategy from a\nricher class of strategies in the online setting. In this scenario, we compute\nthe richness ratio, $\\alpha\\in(0, 1]$ for the class of strategies chosen by the\nclairvoyant and show that our algorithm, designed to learn safe strategies,\nachieves $\\alpha$-approximate sublinear regret against these stronger\nbenchmarks. Experiments on semi-synthetic data from real-world auctions show\nthat safe strategies substantially outperform the derived theoretical bounds,\nmaking them quite appealing in practice.", "AI": {"tldr": "\u7814\u7a76\u91cd\u590d\u7edf\u4e00\u4ef7\u683c\u591a\u5355\u4f4d\u62cd\u5356\u4e2d\u7684\u6295\u6807\u95ee\u9898\uff0c\u63d0\u51fa\u5b89\u5168\u6295\u6807\u7b56\u7565\uff0c\u6ee1\u8db3\u6bcf\u8f6eRoI\u7ea6\u675f\uff0c\u5e76\u5f00\u53d1\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u5b66\u4e60\u6700\u4f18\u7b56\u7565\u3002", "motivation": "\u89e3\u51b3\u5728\u91cd\u590d\u62cd\u5356\u4e2d\uff0c\u4e70\u5bb6\u5982\u4f55\u5728\u6ee1\u8db3\u6bcf\u8f6eRoI\u7ea6\u675f\u4e0b\u6700\u5927\u5316\u7d2f\u79ef\u4ef7\u503c\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165m-uniform\u6295\u6807\u683c\u5f0f\u548c\u5b89\u5168\u6295\u6807\u7b56\u7565\uff0c\u5f00\u53d1\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u5b66\u4e60\u6700\u4f18\u7b56\u7565\u3002", "result": "\u7b97\u6cd5\u5728\u5728\u7ebf\u8bbe\u7f6e\u4e2d\u5b9e\u73b0\u4e9a\u7ebf\u6027\u9057\u61be\uff0c\u5b9e\u9a8c\u663e\u793a\u5b89\u5168\u7b56\u7565\u4f18\u4e8e\u7406\u8bba\u754c\u9650\u3002", "conclusion": "\u5b89\u5168\u7b56\u7565\u5728\u5b9e\u8df5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2506.05351", "pdf": "https://arxiv.org/pdf/2506.05351", "abs": "https://arxiv.org/abs/2506.05351", "authors": ["Rukmal Weerawarana", "Maxwell Braun"], "title": "Infinite Time Turing Machines and their Applications", "categories": ["cs.CC", "cs.AI", "cs.FL", "cs.LG"], "comment": "Published by Ren XYZ Inc", "summary": "This work establishes a rigorous theoretical foundation for analyzing deep\nlearning systems by leveraging Infinite Time Turing Machines (ITTMs), which\nextend classical computation into transfinite ordinal steps. Using ITTMs, we\nreinterpret modern architectures like Transformers, revealing fundamental\nlimitations in scalability, efficiency, and interpretability. Building on these\ninsights, we propose the Universal State Machine (USM), a novel computational\nparadigm designed from first principles. The USM employs a dynamic, queryable\ncomputation graph that evolves in real time, enabling modular, interpretable,\nand resource-efficient computation. This framework not only overcomes the\ninefficiencies and rigidity of current models but also lays the groundwork for\nscalable, generalizable artificial intelligence systems.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u65e0\u9650\u65f6\u95f4\u56fe\u7075\u673a\uff08ITTMs\uff09\u4e3a\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\u5efa\u7acb\u4e86\u4e25\u683c\u7684\u7406\u8bba\u57fa\u7840\uff0c\u63ed\u793a\u4e86Transformer\u7b49\u73b0\u4ee3\u67b6\u6784\u5728\u53ef\u6269\u5c55\u6027\u3001\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\u4e0a\u7684\u6839\u672c\u9650\u5236\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8ba1\u7b97\u8303\u5f0f\u2014\u2014\u901a\u7528\u72b6\u6001\u673a\uff08USM\uff09\u3002", "motivation": "\u4e3a\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\u63d0\u4f9b\u7406\u8bba\u652f\u6301\uff0c\u5e76\u89e3\u51b3\u73b0\u6709\u6a21\u578b\u5728\u53ef\u6269\u5c55\u6027\u3001\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\u4e0a\u7684\u4e0d\u8db3\u3002", "method": "\u5229\u7528ITTMs\u5206\u6790\u73b0\u4ee3\u67b6\u6784\uff0c\u63d0\u51fa\u52a8\u6001\u3001\u53ef\u67e5\u8be2\u7684\u8ba1\u7b97\u56fe\u8303\u5f0fUSM\u3002", "result": "USM\u514b\u670d\u4e86\u73b0\u6709\u6a21\u578b\u7684\u4f4e\u6548\u548c\u50f5\u5316\uff0c\u4e3a\u53ef\u6269\u5c55\u3001\u901a\u7528\u7684\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "USM\u662f\u4e00\u79cd\u521b\u65b0\u7684\u8ba1\u7b97\u8303\u5f0f\uff0c\u5177\u6709\u6a21\u5757\u5316\u3001\u53ef\u89e3\u91ca\u548c\u8d44\u6e90\u9ad8\u6548\u7684\u7279\u70b9\uff0c\u4e3a\u672a\u6765AI\u7cfb\u7edf\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2506.05354", "pdf": "https://arxiv.org/pdf/2506.05354", "abs": "https://arxiv.org/abs/2506.05354", "authors": ["Jarek Duda"], "title": "Adaptive stable distribution and Hurst exponent by method of moments moving estimator for nonstationary time series", "categories": ["stat.ME", "cs.LG", "econ.EM", "stat.ML"], "comment": "5 pages, 7 figures. arXiv admin note: text overlap with\n  arXiv:2304.03069", "summary": "Nonstationarity of real-life time series requires model adaptation. In\nclassical approaches like ARMA-ARCH there is assumed some arbitrarily chosen\ndependence type. To avoid their bias, we will focus on novel more agnostic\napproach: moving estimator, which estimates parameters separately for every\ntime $t$: optimizing $F_t=\\sum_{\\tau<t} (1-\\eta)^{t-\\tau} \\ln(\\rho_\\theta\n(x_\\tau))$ local log-likelihood with exponentially weakening weights of the old\nvalues. In practice such moving estimates can be found by EMA (exponential\nmoving average) of some parameters, like $m_p=E[|x-\\mu|^p]$ absolute central\nmoments, updated by $m_{p,t+1} = m_{p,t} + \\eta (|x_t-\\mu_t|^p-m_{p,t})$. We\nwill focus here on its applications for alpha-Stable distribution, which also\ninfluences Hurst exponent, hence can be used for its adaptive estimation. Its\napplication will be shown on financial data as DJIA time series - beside\nstandard estimation of evolution of center $\\mu$ and scale parameter $\\sigma$,\nthere is also estimated evolution of $\\alpha$ parameter allowing to\ncontinuously evaluate market stability - tails having $\\rho(x) \\sim\n1/|x|^{\\alpha+1}$ behavior, controlling probability of potentially dangerous\nextreme events.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u79fb\u52a8\u4f30\u8ba1\u5668\u7684\u975e\u53c2\u6570\u65b9\u6cd5\uff0c\u7528\u4e8e\u9002\u5e94\u975e\u5e73\u7a33\u65f6\u95f4\u5e8f\u5217\uff0c\u5e76\u901a\u8fc7EMA\u66f4\u65b0\u53c2\u6570\uff0c\u5e94\u7528\u4e8ealpha-Stable\u5206\u5e03\u548c\u91d1\u878d\u6570\u636e\uff08\u5982DJIA\uff09\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\uff08\u5982ARMA-ARCH\uff09\u5047\u8bbe\u56fa\u5b9a\u7684\u4f9d\u8d56\u7c7b\u578b\uff0c\u53ef\u80fd\u5f15\u5165\u504f\u5dee\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u66f4\u7075\u6d3b\u7684\u65b9\u6cd5\u9002\u5e94\u975e\u5e73\u7a33\u65f6\u95f4\u5e8f\u5217\u3002", "method": "\u4f7f\u7528\u79fb\u52a8\u4f30\u8ba1\u5668\uff0c\u901a\u8fc7\u5c40\u90e8\u5bf9\u6570\u4f3c\u7136\u4f18\u5316\u548cEMA\u66f4\u65b0\u53c2\u6570\uff08\u5982\u7edd\u5bf9\u4e2d\u5fc3\u77e9\uff09\uff0c\u91cd\u70b9\u5173\u6ce8alpha-Stable\u5206\u5e03\u7684\u5e94\u7528\u3002", "result": "\u65b9\u6cd5\u6210\u529f\u5e94\u7528\u4e8e\u91d1\u878d\u6570\u636e\uff08DJIA\uff09\uff0c\u52a8\u6001\u4f30\u8ba1\u4e2d\u5fc3\u3001\u5c3a\u5ea6\u53c2\u6570\u548c\u03b1\u53c2\u6570\uff0c\u8bc4\u4f30\u5e02\u573a\u7a33\u5b9a\u6027\u3002", "conclusion": "\u79fb\u52a8\u4f30\u8ba1\u5668\u63d0\u4f9b\u4e86\u4e00\u79cd\u7075\u6d3b\u4e14\u65e0\u504f\u7684\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u975e\u5e73\u7a33\u65f6\u95f4\u5e8f\u5217\u5206\u6790\uff0c\u5c24\u5176\u5728\u91d1\u878d\u9886\u57df\u5177\u6709\u5b9e\u9645\u4ef7\u503c\u3002"}}
{"id": "2506.05390", "pdf": "https://arxiv.org/pdf/2506.05390", "abs": "https://arxiv.org/abs/2506.05390", "authors": ["Markelle Kelly", "Mohammad Tahaei", "Padhraic Smyth", "Lauren Wilcox"], "title": "Understanding Gender Bias in AI-Generated Product Descriptions", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted to FAccT 2025", "summary": "While gender bias in large language models (LLMs) has been extensively\nstudied in many domains, uses of LLMs in e-commerce remain largely unexamined\nand may reveal novel forms of algorithmic bias and harm. Our work investigates\nthis space, developing data-driven taxonomic categories of gender bias in the\ncontext of product description generation, which we situate with respect to\nexisting general purpose harms taxonomies. We illustrate how AI-generated\nproduct descriptions can uniquely surface gender biases in ways that require\nspecialized detection and mitigation approaches. Further, we quantitatively\nanalyze issues corresponding to our taxonomic categories in two models used for\nthis task -- GPT-3.5 and an e-commerce-specific LLM -- demonstrating that these\nforms of bias commonly occur in practice. Our results illuminate unique,\nunder-explored dimensions of gender bias, such as assumptions about clothing\nsize, stereotypical bias in which features of a product are advertised, and\ndifferences in the use of persuasive language. These insights contribute to our\nunderstanding of three types of AI harms identified by current frameworks:\nexclusionary norms, stereotyping, and performance disparities, particularly for\nthe context of e-commerce.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u7535\u5b50\u5546\u52a1\u4e2d\u751f\u6210\u4ea7\u54c1\u63cf\u8ff0\u65f6\u7684\u6027\u522b\u504f\u89c1\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u5206\u7c7b\u65b9\u6cd5\uff0c\u5e76\u5206\u6790\u4e86GPT-3.5\u548c\u7535\u5546\u4e13\u7528LLM\u4e2d\u7684\u504f\u89c1\u8868\u73b0\u3002", "motivation": "\u5c3d\u7ba1LLM\u7684\u6027\u522b\u504f\u89c1\u5728\u5176\u4ed6\u9886\u57df\u5df2\u6709\u7814\u7a76\uff0c\u4f46\u5728\u7535\u5546\u9886\u57df\u7684\u5e94\u7528\u5c1a\u672a\u6df1\u5165\u63a2\u8ba8\uff0c\u53ef\u80fd\u63ed\u793a\u65b0\u7684\u7b97\u6cd5\u504f\u89c1\u548c\u5371\u5bb3\u3002", "method": "\u5f00\u53d1\u4e86\u6570\u636e\u9a71\u52a8\u7684\u6027\u522b\u504f\u89c1\u5206\u7c7b\u6cd5\uff0c\u5e76\u4e0e\u73b0\u6709\u901a\u7528\u5371\u5bb3\u5206\u7c7b\u6cd5\u5bf9\u6bd4\uff0c\u5206\u6790\u4e86GPT-3.5\u548c\u7535\u5546\u4e13\u7528LLM\u7684\u504f\u89c1\u8868\u73b0\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u7535\u5546\u573a\u666f\u4e2d\u5b58\u5728\u72ec\u7279\u7684\u6027\u522b\u504f\u89c1\u5f62\u5f0f\uff0c\u5982\u5bf9\u670d\u88c5\u5c3a\u5bf8\u7684\u5047\u8bbe\u3001\u4ea7\u54c1\u7279\u5f81\u523b\u677f\u63cf\u8ff0\u548c\u8bf4\u670d\u6027\u8bed\u8a00\u5dee\u5f02\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u7535\u5546\u4e2d\u672a\u88ab\u5145\u5206\u63a2\u7d22\u7684\u6027\u522b\u504f\u89c1\u7ef4\u5ea6\uff0c\u8865\u5145\u4e86\u73b0\u6709AI\u5371\u5bb3\u6846\u67b6\u4e2d\u7684\u6392\u65a5\u6027\u89c4\u8303\u3001\u523b\u677f\u5370\u8c61\u548c\u6027\u80fd\u5dee\u5f02\u95ee\u9898\u3002"}}
{"id": "2506.05391", "pdf": "https://arxiv.org/pdf/2506.05391", "abs": "https://arxiv.org/abs/2506.05391", "authors": ["Ambrose Emmett-Iwaniw", "Nathan Kirk"], "title": "Enhancing Neural Autoregressive Distribution Estimators for Image Reconstruction", "categories": ["eess.IV", "cs.CV", "cs.LG", "stat.AP"], "comment": "Accepted for publication in conference proceedings, MCQMC 2024", "summary": "Autoregressive models are often employed to learn distributions of image data\nby decomposing the $D$-dimensional density function into a product of\none-dimensional conditional distributions. Each conditional depends on\npreceding variables (pixels, in the case of image data), making the order in\nwhich variables are processed fundamental to the model performance. In this\npaper, we study the problem of observing a small subset of image pixels\n(referred to as a pixel patch) to predict the unobserved parts of the image. As\nour prediction mechanism, we propose a generalized and computationally\nefficient version of the convolutional neural autoregressive distribution\nestimator (ConvNADE) model adapted for real-valued and color images. Moreover,\nwe investigate the quality of image reconstruction when observing both random\npixel patches and low-discrepancy pixel patches inspired by quasi-Monte Carlo\ntheory. Experiments on benchmark datasets demonstrate that choosing the pixels\nakin to a low-discrepancy sequence reduces test loss and produces more\nrealistic reconstructed images.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u901a\u8fc7\u89c2\u5bdf\u56fe\u50cf\u50cf\u7d20\u5b50\u96c6\uff08\u50cf\u7d20\u5757\uff09\u9884\u6d4b\u672a\u89c2\u5bdf\u90e8\u5206\u7684\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684ConvNADE\u6a21\u578b\uff0c\u5e76\u63a2\u8ba8\u4e86\u968f\u673a\u548c\u4f4e\u5dee\u5f02\u50cf\u7d20\u5757\u5bf9\u56fe\u50cf\u91cd\u5efa\u8d28\u91cf\u7684\u5f71\u54cd\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u5c11\u91cf\u50cf\u7d20\u9884\u6d4b\u5b8c\u6574\u56fe\u50cf\uff0c\u63d0\u5347\u81ea\u56de\u5f52\u6a21\u578b\u5728\u56fe\u50cf\u6570\u636e\u5206\u5e03\u5b66\u4e60\u4e2d\u7684\u6548\u7387\u548c\u8d28\u91cf\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9002\u7528\u4e8e\u5b9e\u503c\u548c\u5f69\u8272\u56fe\u50cf\u7684\u6539\u8fdb\u7248ConvNADE\u6a21\u578b\uff0c\u5e76\u6bd4\u8f83\u4e86\u968f\u673a\u50cf\u7d20\u5757\u548c\u4f4e\u5dee\u5f02\u50cf\u7d20\u5757\u5bf9\u91cd\u5efa\u6548\u679c\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528\u4f4e\u5dee\u5f02\u5e8f\u5217\u9009\u62e9\u7684\u50cf\u7d20\u5757\u80fd\u964d\u4f4e\u6d4b\u8bd5\u635f\u5931\u5e76\u751f\u6210\u66f4\u771f\u5b9e\u7684\u56fe\u50cf\u3002", "conclusion": "\u4f4e\u5dee\u5f02\u50cf\u7d20\u5757\u9009\u62e9\u7b56\u7565\u80fd\u663e\u8457\u63d0\u5347\u56fe\u50cf\u91cd\u5efa\u8d28\u91cf\uff0c\u6539\u8fdb\u7684ConvNADE\u6a21\u578b\u5728\u6548\u7387\u548c\u6027\u80fd\u4e0a\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2506.05393", "pdf": "https://arxiv.org/pdf/2506.05393", "abs": "https://arxiv.org/abs/2506.05393", "authors": ["Shenyang Huang", "Ali Parviz", "Emma Kondrup", "Zachary Yang", "Zifeng Ding", "Michael Bronstein", "Reihaneh Rabbany", "Guillaume Rabusseau"], "title": "Are Large Language Models Good Temporal Graph Learners?", "categories": ["cs.CL", "cs.LG"], "comment": "9 pages, 9 tables, 4 figures", "summary": "Large Language Models (LLMs) have recently driven significant advancements in\nNatural Language Processing and various other applications. While a broad range\nof literature has explored the graph-reasoning capabilities of LLMs, including\ntheir use of predictors on graphs, the application of LLMs to dynamic graphs --\nreal world evolving networks -- remains relatively unexplored. Recent work\nstudies synthetic temporal graphs generated by random graph models, but\napplying LLMs to real-world temporal graphs remains an open question. To\naddress this gap, we introduce Temporal Graph Talker (TGTalker), a novel\ntemporal graph learning framework designed for LLMs. TGTalker utilizes the\nrecency bias in temporal graphs to extract relevant structural information,\nconverted to natural language for LLMs, while leveraging temporal neighbors as\nadditional information for prediction. TGTalker demonstrates competitive link\nprediction capabilities compared to existing Temporal Graph Neural Network\n(TGNN) models. Across five real-world networks, TGTalker performs competitively\nwith state-of-the-art temporal graph methods while consistently outperforming\npopular models such as TGN and HTGN. Furthermore, TGTalker generates textual\nexplanations for each prediction, thus opening up exciting new directions in\nexplainability and interpretability for temporal link prediction. The code is\npublicly available at https://github.com/shenyangHuang/TGTalker.", "AI": {"tldr": "TGTalker\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u65f6\u5e8f\u56fe\u5b66\u4e60\u6846\u67b6\uff0c\u4e13\u4e3aLLMs\u8bbe\u8ba1\uff0c\u7528\u4e8e\u52a8\u6001\u56fe\u9884\u6d4b\uff0c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u5e76\u63d0\u4f9b\u89e3\u91ca\u6027\u3002", "motivation": "\u63a2\u7d22LLMs\u5728\u52a8\u6001\u56fe\uff08\u771f\u5b9e\u4e16\u754c\u6f14\u5316\u7f51\u7edc\uff09\u4e2d\u7684\u5e94\u7528\uff0c\u586b\u8865\u73b0\u6709\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u5229\u7528\u65f6\u5e8f\u56fe\u7684\u8fd1\u671f\u504f\u5dee\u63d0\u53d6\u7ed3\u6784\u4fe1\u606f\uff0c\u8f6c\u6362\u4e3a\u81ea\u7136\u8bed\u8a00\u4f9bLLMs\u4f7f\u7528\uff0c\u5e76\u5229\u7528\u65f6\u5e8f\u90bb\u5c45\u4f5c\u4e3a\u9884\u6d4b\u8f85\u52a9\u4fe1\u606f\u3002", "result": "\u5728\u4e94\u4e2a\u771f\u5b9e\u7f51\u7edc\u6570\u636e\u96c6\u4e0a\uff0cTGTalker\u8868\u73b0\u4f18\u4e8eTGN\u548cHTGN\u7b49\u6d41\u884c\u6a21\u578b\uff0c\u5e76\u63d0\u4f9b\u9884\u6d4b\u7684\u6587\u672c\u89e3\u91ca\u3002", "conclusion": "TGTalker\u4e3a\u65f6\u5e8f\u56fe\u9884\u6d4b\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\uff0c\u5c24\u5176\u5728\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u5177\u6709\u6f5c\u529b\u3002"}}
{"id": "2506.05394", "pdf": "https://arxiv.org/pdf/2506.05394", "abs": "https://arxiv.org/abs/2506.05394", "authors": ["Hondamunige Prasanna Silva", "Federico Becattini", "Lorenzo Seidenari"], "title": "Attacking Attention of Foundation Models Disrupts Downstream Tasks", "categories": ["cs.CR", "cs.LG"], "comment": "Paper published at CVPR 2025 Workshop Advml", "summary": "Foundation models represent the most prominent and recent paradigm shift in\nartificial intelligence. Foundation models are large models, trained on broad\ndata that deliver high accuracy in many downstream tasks, often without\nfine-tuning. For this reason, models such as CLIP , DINO or Vision Transfomers\n(ViT), are becoming the bedrock of many industrial AI-powered applications.\nHowever, the reliance on pre-trained foundation models also introduces\nsignificant security concerns, as these models are vulnerable to adversarial\nattacks. Such attacks involve deliberately crafted inputs designed to deceive\nAI systems, jeopardizing their reliability. This paper studies the\nvulnerabilities of vision foundation models, focusing specifically on CLIP and\nViTs, and explores the transferability of adversarial attacks to downstream\ntasks. We introduce a novel attack, targeting the structure of\ntransformer-based architectures in a task-agnostic fashion. We demonstrate the\neffectiveness of our attack on several downstream tasks: classification,\ncaptioning, image/text retrieval, segmentation and depth estimation. Code\navailable at:https://github.com/HondamunigePrasannaSilva/attack-attention", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u89c6\u89c9\u57fa\u7840\u6a21\u578b\uff08\u5982CLIP\u548cViT\uff09\u7684\u5bf9\u6297\u653b\u51fb\u6f0f\u6d1e\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9Transformer\u67b6\u6784\u7684\u65b0\u578b\u653b\u51fb\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u591a\u79cd\u4e0b\u6e38\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002", "motivation": "\u57fa\u7840\u6a21\u578b\u5728AI\u9886\u57df\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5176\u5b89\u5168\u6027\u95ee\u9898\uff08\u5982\u5bf9\u6297\u653b\u51fb\uff09\u5c1a\u672a\u5145\u5206\u7814\u7a76\uff0c\u5c24\u5176\u662f\u89c6\u89c9\u57fa\u7840\u6a21\u578b\u7684\u6f0f\u6d1e\u548c\u653b\u51fb\u53ef\u8fc1\u79fb\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9Transformer\u67b6\u6784\u7684\u4efb\u52a1\u65e0\u5173\u653b\u51fb\u65b9\u6cd5\uff0c\u653b\u51fb\u76ee\u6807\u4e3a\u6a21\u578b\u7ed3\u6784\u672c\u8eab\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u5206\u7c7b\u3001\u63cf\u8ff0\u751f\u6210\u3001\u56fe\u50cf/\u6587\u672c\u68c0\u7d22\u3001\u5206\u5272\u548c\u6df1\u5ea6\u4f30\u8ba1\u7b49\u591a\u79cd\u4e0b\u6e38\u4efb\u52a1\u4e2d\u5747\u6709\u6548\u3002", "conclusion": "\u89c6\u89c9\u57fa\u7840\u6a21\u578b\u5b58\u5728\u5bf9\u6297\u653b\u51fb\u6f0f\u6d1e\uff0c\u65b0\u578b\u653b\u51fb\u65b9\u6cd5\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\uff0c\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u9632\u5fa1\u63aa\u65bd\u3002"}}
{"id": "2506.05402", "pdf": "https://arxiv.org/pdf/2506.05402", "abs": "https://arxiv.org/abs/2506.05402", "authors": ["Tianyu Qi", "Lei Xue", "Yufeng Zhan", "Xiaobo Ma"], "title": "Sylva: Tailoring Personalized Adversarial Defense in Pre-trained Models via Collaborative Fine-tuning", "categories": ["cs.CR", "cs.LG"], "comment": "Accepted by the ACM Conference on Computer and Communications\n  Security (CCS) 2025", "summary": "The growing adoption of large pre-trained models in edge computing has made\ndeploying model inference on mobile clients both practical and popular. These\ndevices are inherently vulnerable to direct adversarial attacks, which pose a\nsubstantial threat to the robustness and security of deployed models. Federated\nadversarial training (FAT) has emerged as an effective solution to enhance\nmodel robustness while preserving client privacy. However, FAT frequently\nproduces a generalized global model, which struggles to address the diverse and\nheterogeneous data distributions across clients, resulting in insufficiently\npersonalized performance, while also encountering substantial communication\nchallenges during the training process. In this paper, we propose\n\\textit{Sylva}, a personalized collaborative adversarial training framework\ndesigned to deliver customized defense models for each client through a\ntwo-phase process. In Phase 1, \\textit{Sylva} employs LoRA for local\nadversarial fine-tuning, enabling clients to personalize model robustness while\ndrastically reducing communication costs by uploading only LoRA parameters\nduring federated aggregation. In Phase 2, a game-based layer selection strategy\nis introduced to enhance accuracy on benign data, further refining the\npersonalized model. This approach ensures that each client receives a tailored\ndefense model that balances robustness and accuracy effectively. Extensive\nexperiments on benchmark datasets demonstrate that \\textit{Sylva} can achieve\nup to 50$\\times$ improvements in communication efficiency compared to\nstate-of-the-art algorithms, while achieving up to 29.5\\% and 50.4\\%\nenhancements in adversarial robustness and benign accuracy, respectively.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSylva\u7684\u4e2a\u6027\u5316\u534f\u4f5c\u5bf9\u6297\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8fc7\u7a0b\u4e3a\u6bcf\u4e2a\u5ba2\u6237\u7aef\u63d0\u4f9b\u5b9a\u5236\u5316\u7684\u9632\u5fa1\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u901a\u4fe1\u6548\u7387\u548c\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u8fb9\u7f18\u8ba1\u7b97\u4e2d\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u90e8\u7f72\u9762\u4e34\u5bf9\u6297\u653b\u51fb\u5a01\u80c1\uff0c\u73b0\u6709\u8054\u90a6\u5bf9\u6297\u8bad\u7ec3\uff08FAT\uff09\u65b9\u6cd5\u5728\u4e2a\u6027\u5316\u6027\u80fd\u548c\u901a\u4fe1\u6548\u7387\u4e0a\u5b58\u5728\u4e0d\u8db3\u3002", "method": "Sylva\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a1\uff09\u4f7f\u7528LoRA\u8fdb\u884c\u672c\u5730\u5bf9\u6297\u5fae\u8c03\u4ee5\u51cf\u5c11\u901a\u4fe1\u6210\u672c\uff1b2\uff09\u5f15\u5165\u57fa\u4e8e\u6e38\u620f\u7684\u5c42\u9009\u62e9\u7b56\u7565\u4f18\u5316\u826f\u6027\u6570\u636e\u51c6\u786e\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSylva\u5728\u901a\u4fe1\u6548\u7387\u4e0a\u63d0\u534750\u500d\uff0c\u5bf9\u6297\u9c81\u68d2\u6027\u548c\u826f\u6027\u6570\u636e\u51c6\u786e\u6027\u5206\u522b\u63d0\u534729.5%\u548c50.4%\u3002", "conclusion": "Sylva\u4e3a\u5ba2\u6237\u7aef\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u4e2a\u6027\u5316\u7684\u9632\u5fa1\u6a21\u578b\uff0c\u5e73\u8861\u4e86\u9c81\u68d2\u6027\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2506.05408", "pdf": "https://arxiv.org/pdf/2506.05408", "abs": "https://arxiv.org/abs/2506.05408", "authors": ["Jonathan Scott", "Christoph H. Lampert", "David Saulpic"], "title": "Differentially Private Federated $k$-Means Clustering with Server-Side Data", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "Clustering is a cornerstone of data analysis that is particularly suited to\nidentifying coherent subgroups or substructures in unlabeled data, as are\ngenerated continuously in large amounts these days. However, in many cases\ntraditional clustering methods are not applicable, because data are\nincreasingly being produced and stored in a distributed way, e.g. on edge\ndevices, and privacy concerns prevent it from being transferred to a central\nserver. To address this challenge, we present \\acronym, a new algorithm for\n$k$-means clustering that is fully-federated as well as differentially private.\nOur approach leverages (potentially small and out-of-distribution) server-side\ndata to overcome the primary challenge of differentially private clustering\nmethods: the need for a good initialization. Combining our initialization with\na simple federated DP-Lloyds algorithm we obtain an algorithm that achieves\nexcellent results on synthetic and real-world benchmark tasks. We also provide\na theoretical analysis of our method that provides bounds on the convergence\nspeed and cluster identification success.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\\acronym\u7684\u8054\u90a6\u5dee\u5206\u9690\u79c1k\u5747\u503c\u805a\u7c7b\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e86\u5206\u5e03\u5f0f\u6570\u636e\u9690\u79c1\u4fdd\u62a4\u4e0b\u7684\u805a\u7c7b\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u805a\u7c7b\u65b9\u6cd5\u4e0d\u9002\u7528\u4e8e\u5206\u5e03\u5f0f\u6570\u636e\uff08\u5982\u8fb9\u7f18\u8bbe\u5907\uff09\u4e14\u9690\u79c1\u95ee\u9898\u963b\u788d\u6570\u636e\u96c6\u4e2d\u5904\u7406\uff0c\u9700\u8981\u4e00\u79cd\u8054\u90a6\u4e14\u9690\u79c1\u4fdd\u62a4\u7684\u805a\u7c7b\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408\u670d\u52a1\u5668\u7aef\u6570\u636e\u521d\u59cb\u5316\uff0c\u91c7\u7528\u8054\u90a6DP-Lloyds\u7b97\u6cd5\u5b9e\u73b0\u5dee\u5206\u9690\u79c1k\u5747\u503c\u805a\u7c7b\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u57fa\u51c6\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u7406\u8bba\u5206\u6790\u63d0\u4f9b\u4e86\u6536\u655b\u901f\u5ea6\u548c\u805a\u7c7b\u8bc6\u522b\u6210\u529f\u7684\u754c\u9650\u3002", "conclusion": "\\acronym\u7b97\u6cd5\u5728\u8054\u90a6\u548c\u9690\u79c1\u4fdd\u62a4\u573a\u666f\u4e0b\u6709\u6548\u89e3\u51b3\u4e86\u805a\u7c7b\u95ee\u9898\uff0c\u5177\u6709\u7406\u8bba\u548c\u5b9e\u9645\u4f18\u52bf\u3002"}}
{"id": "2506.05409", "pdf": "https://arxiv.org/pdf/2506.05409", "abs": "https://arxiv.org/abs/2506.05409", "authors": ["\u00c7a\u011flar H\u0131zl\u0131", "\u00c7a\u011fatay Y\u0131ld\u0131z", "Pekka Marttinen"], "title": "Object-level Self-Distillation for Vision Pretraining", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "State-of-the-art vision pretraining methods rely on image-level\nself-distillation from object-centric datasets such as ImageNet, implicitly\nassuming each image contains a single object. This assumption does not always\nhold: many ImageNet images already contain multiple objects. Further, it limits\nscalability to scene-centric datasets that better mirror real-world complexity.\nWe address these challenges by introducing Object-level Self-DIStillation\n(ODIS), a pretraining approach that shifts the self-distillation granularity\nfrom whole images to individual objects. Using object-aware cropping and masked\nattention, ODIS isolates object-specific regions, guiding the transformer\ntoward semantically meaningful content and transforming a noisy, scene-level\ntask into simpler object-level sub-tasks. We show that this approach improves\nvisual representations both at the image and patch levels. Using masks at\ninference time, our method achieves an impressive $82.6\\%$ $k$-NN accuracy on\nImageNet1k with ViT-Large.", "AI": {"tldr": "ODIS\u662f\u4e00\u79cd\u9884\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u8c61\u7ea7\u81ea\u84b8\u998f\u6539\u8fdb\u89c6\u89c9\u8868\u793a\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u56fe\u50cf\u7ea7\u81ea\u84b8\u998f\u5728\u591a\u5bf9\u8c61\u573a\u666f\u4e2d\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u4f20\u7edf\u56fe\u50cf\u7ea7\u81ea\u84b8\u998f\u5047\u8bbe\u6bcf\u5f20\u56fe\u50cf\u4ec5\u5305\u542b\u5355\u4e00\u5bf9\u8c61\uff0c\u4f46\u5b9e\u9645\u573a\u666f\u4e2d\u5e38\u5305\u542b\u591a\u4e2a\u5bf9\u8c61\uff0c\u9650\u5236\u4e86\u65b9\u6cd5\u7684\u6269\u5c55\u6027\u548c\u9002\u7528\u6027\u3002", "method": "ODIS\u901a\u8fc7\u5bf9\u8c61\u611f\u77e5\u88c1\u526a\u548c\u63a9\u7801\u6ce8\u610f\u529b\uff0c\u5c06\u81ea\u84b8\u998f\u7c92\u5ea6\u4ece\u56fe\u50cf\u7ea7\u7ec6\u5316\u5230\u5bf9\u8c61\u7ea7\uff0c\u7b80\u5316\u4efb\u52a1\u5e76\u63d0\u5347\u8bed\u4e49\u5185\u5bb9\u7684\u5b66\u4e60\u3002", "result": "ODIS\u5728ViT-Large\u4e0a\u5b9e\u73b0\u4e8682.6%\u7684k-NN\u51c6\u786e\u7387\uff0c\u663e\u8457\u63d0\u5347\u4e86\u56fe\u50cf\u548c\u8865\u4e01\u7ea7\u522b\u7684\u89c6\u89c9\u8868\u793a\u3002", "conclusion": "ODIS\u901a\u8fc7\u5bf9\u8c61\u7ea7\u81ea\u84b8\u998f\u6709\u6548\u89e3\u51b3\u4e86\u591a\u5bf9\u8c61\u573a\u666f\u7684\u6311\u6218\uff0c\u4e3a\u590d\u6742\u6570\u636e\u96c6\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u89c6\u89c9\u8868\u793a\u65b9\u6cd5\u3002"}}
{"id": "2506.05413", "pdf": "https://arxiv.org/pdf/2506.05413", "abs": "https://arxiv.org/abs/2506.05413", "authors": ["Patrik Czak\u00f3", "G\u00e1bor Kert\u00e9sz", "S\u00e1ndor Sz\u00e9n\u00e1si"], "title": "SmoothRot: Combining Channel-Wise Scaling and Rotation for Quantization-Friendly LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "6 pages, 3 figures, 5 tables. Submitted to the IEEE SMC 2025\n  conference", "summary": "We present SmoothRot, a novel post-training quantization technique to enhance\nthe efficiency of 4-bit quantization in Large Language Models (LLMs). SmoothRot\naddresses the critical challenge of massive activation outliers, by integrating\nchannel-wise scaling with Hadamard transformations. Our technique effectively\ntransforms extreme outliers into quantization-friendly activations,\nsignificantly improving quantization accuracy. Experiments conducted on popular\nLLMs (LLaMA2 7B, LLaMA3.1 8B, and Mistral 7B) demonstrate that SmoothRot\nconsistently reduces the performance gap between quantized and FP16 models by\napproximately 10-30\\% across language generation and zero-shot reasoning tasks,\nwithout introducing additional inference latency. Code is available at\nhttps://github.com/czakop/smoothrot.", "AI": {"tldr": "SmoothRot\u662f\u4e00\u79cd\u65b0\u9896\u7684\u540e\u8bad\u7ec3\u91cf\u5316\u6280\u672f\uff0c\u901a\u8fc7\u7ed3\u5408\u901a\u9053\u7ea7\u7f29\u653e\u548cHadamard\u53d8\u6362\uff0c\u663e\u8457\u63d0\u53474\u4f4d\u91cf\u5316\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u6548\u7387\uff0c\u51cf\u5c11\u91cf\u5316\u8bef\u5dee\u3002", "motivation": "\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u5927\u89c4\u6a21\u6fc0\u6d3b\u5f02\u5e38\u503c\u5bf94\u4f4d\u91cf\u5316\u7684\u5173\u952e\u6311\u6218\u3002", "method": "\u96c6\u6210\u901a\u9053\u7ea7\u7f29\u653e\u548cHadamard\u53d8\u6362\uff0c\u5c06\u6781\u7aef\u5f02\u5e38\u503c\u8f6c\u5316\u4e3a\u9002\u5408\u91cf\u5316\u7684\u6fc0\u6d3b\u3002", "result": "\u5728LLaMA2 7B\u3001LLaMA3.1 8B\u548cMistral 7B\u7b49\u6a21\u578b\u4e0a\uff0c\u91cf\u5316\u4e0eFP16\u6a21\u578b\u7684\u6027\u80fd\u5dee\u8ddd\u51cf\u5c11\u4e8610-30%\uff0c\u4e14\u4e0d\u5f71\u54cd\u63a8\u7406\u5ef6\u8fdf\u3002", "conclusion": "SmoothRot\u6709\u6548\u63d0\u5347\u4e864\u4f4d\u91cf\u5316\u7684\u51c6\u786e\u6027\uff0c\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6548\u91cf\u5316\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2506.05414", "pdf": "https://arxiv.org/pdf/2506.05414", "abs": "https://arxiv.org/abs/2506.05414", "authors": ["Mingfei Chen", "Zijun Cui", "Xiulong Liu", "Jinlin Xiang", "Caleb Zheng", "Jingyuan Li", "Eli Shlizerman"], "title": "SAVVY: Spatial Awareness via Audio-Visual LLMs through Seeing and Hearing", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM", "cs.SD", "eess.AS"], "comment": "Project website with demo videos: https://zijuncui02.github.io/SAVVY/", "summary": "3D spatial reasoning in dynamic, audio-visual environments is a cornerstone\nof human cognition yet remains largely unexplored by existing Audio-Visual\nLarge Language Models (AV-LLMs) and benchmarks, which predominantly focus on\nstatic or 2D scenes. We introduce SAVVY-Bench, the first benchmark for 3D\nspatial reasoning in dynamic scenes with synchronized spatial audio.\nSAVVY-Bench is comprised of thousands of relationships involving static and\nmoving objects, and requires fine-grained temporal grounding, consistent 3D\nlocalization, and multi-modal annotation. To tackle this challenge, we propose\nSAVVY, a novel training-free reasoning pipeline that consists of two stages:\n(i) Egocentric Spatial Tracks Estimation, which leverages AV-LLMs as well as\nother audio-visual methods to track the trajectories of key objects related to\nthe query using both visual and spatial audio cues, and (ii) Dynamic Global Map\nConstruction, which aggregates multi-modal queried object trajectories and\nconverts them into a unified global dynamic map. Using the constructed map, a\nfinal QA answer is obtained through a coordinate transformation that aligns the\nglobal map with the queried viewpoint. Empirical evaluation demonstrates that\nSAVVY substantially enhances performance of state-of-the-art AV-LLMs, setting a\nnew standard and stage for approaching dynamic 3D spatial reasoning in AV-LLMs.", "AI": {"tldr": "SAVVY-Bench\u662f\u9996\u4e2a\u9488\u5bf9\u52a8\u6001\u573a\u666f\u4e2d3D\u7a7a\u95f4\u63a8\u7406\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7ed3\u5408\u4e86\u540c\u6b65\u7a7a\u95f4\u97f3\u9891\u3002SAVVY\u662f\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u4e24\u9636\u6bb5\u63a8\u7406\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u73b0\u6709AV-LLMs\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709AV-LLMs\u548c\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u5173\u6ce8\u9759\u6001\u62162D\u573a\u666f\uff0c\u800c\u52a8\u60013D\u7a7a\u95f4\u63a8\u7406\u5728\u4eba\u7c7b\u8ba4\u77e5\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5c1a\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002", "method": "SAVVY\u5206\u4e3a\u4e24\u9636\u6bb5\uff1a1) \u5229\u7528AV-LLMs\u548c\u5176\u4ed6\u89c6\u542c\u65b9\u6cd5\u8ddf\u8e2a\u5173\u952e\u5bf9\u8c61\u8f68\u8ff9\uff1b2) \u6784\u5efa\u52a8\u6001\u5168\u5c40\u5730\u56fe\uff0c\u901a\u8fc7\u5750\u6807\u8f6c\u6362\u5bf9\u9f50\u67e5\u8be2\u89c6\u89d2\u3002", "result": "SAVVY\u663e\u8457\u63d0\u5347\u4e86\u73b0\u6709AV-LLMs\u7684\u6027\u80fd\uff0c\u4e3a\u52a8\u60013D\u7a7a\u95f4\u63a8\u7406\u8bbe\u5b9a\u4e86\u65b0\u6807\u51c6\u3002", "conclusion": "SAVVY-Bench\u548cSAVVY\u65b9\u6cd5\u586b\u8865\u4e86\u52a8\u60013D\u7a7a\u95f4\u63a8\u7406\u7684\u7a7a\u767d\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2506.05416", "pdf": "https://arxiv.org/pdf/2506.05416", "abs": "https://arxiv.org/abs/2506.05416", "authors": ["David Zagardo"], "title": "FERRET: Private Deep Learning Faster And Better Than DPSGD", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": "28 pages, 6 figures", "summary": "We revisit 1-bit gradient compression through the lens of mutual-information\ndifferential privacy (MI-DP). Building on signSGD, we propose FERRET--Fast and\nEffective Restricted Release for Ethical Training--which transmits at most one\nsign bit per parameter group with Bernoulli masking.\n  Theory: We prove each fired group leaks at most ln 2 nats; after subsampling\nwith rate s, the total privacy loss of G groups trained for T steps with firing\nprobability p is epsilon = G * T * s * p * ln 2. Thus FERRET achieves MI-DP for\nepsilon in [0.1, 2] without additive noise.\n  Practice: We evaluate three granularities--FERRET-MAX (finest), FERRET-EIGHTH\n(medium), and FERRET-2 (coarsest)--on five LLMs (137M-1.8B parameters) against\nDPSGD and Non-DP baselines. All methods trained for 1, 3, and 5 epochs.\n  Utility: Across all settings, FERRET-MAX/EIGHTH beat DPSGD's perplexity. At\nepsilon=0.5, 5 epochs: FERRET-EIGHTH achieves 3.98 perplexity vs DPSGD's 11.61\n(2.9x better), within 23% of Non-DP (3.25).\n  Privacy: MI-AUC stays at chance for FERRET-MAX/EIGHTH (~0.51), matching DPSGD\nvs Non-DP's 0.76-0.99. FERRET-2 shows higher leakage (~0.55) due to lower\nheadroom.\n  Efficiency: Stricter budgets fire fewer signs, so FERRET uses 19-33% of\nDPSGD's training time and only 34-36% of Non-DP training time.\n  Take-away: Sign-based MI-DP gets closer to achieving all three qualities of\nthe privacy, utility, performance trilemma: FERRET trains up to 5x faster,\nachieves 3x lower perplexity compared to DPSGD and 1.2x greater than Non-DP,\nall while providing formal, mathematically provable privacy guarantees using\nzero additive noise. The results also show that, in certain instances, masked\n1-bit updates can match non-private training utility while safeguarding data.", "AI": {"tldr": "FERRET\u662f\u4e00\u79cd\u57fa\u4e8e1-bit\u68af\u5ea6\u538b\u7f29\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e92\u4fe1\u606f\u5dee\u5206\u9690\u79c1\uff08MI-DP\uff09\u5b9e\u73b0\u9ad8\u6548\u3001\u9690\u79c1\u4fdd\u62a4\u7684\u8bad\u7ec3\uff0c\u6027\u80fd\u4f18\u4e8eDPSGD\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u5728\u68af\u5ea6\u538b\u7f29\u4e2d\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u6548\u6027\u548c\u6a21\u578b\u6027\u80fd\u3002", "method": "\u57fa\u4e8esignSGD\uff0c\u63d0\u51faFERRET\u65b9\u6cd5\uff0c\u901a\u8fc7Bernoulli\u63a9\u7801\u4f20\u8f931-bit\u68af\u5ea6\uff0c\u5e76\u8bc1\u660e\u5176\u6ee1\u8db3MI-DP\u3002", "result": "FERRET\u5728\u9690\u79c1\u3001\u6027\u80fd\u548c\u6548\u7387\u4e0a\u4f18\u4e8eDPSGD\uff0c\u90e8\u5206\u60c5\u51b5\u4e0b\u63a5\u8fd1\u975e\u9690\u79c1\u8bad\u7ec3\u7684\u6548\u679c\u3002", "conclusion": "FERRET\u901a\u8fc71-bit\u68af\u5ea6\u538b\u7f29\u548cMI-DP\uff0c\u5b9e\u73b0\u4e86\u9690\u79c1\u3001\u6027\u80fd\u548c\u6548\u7387\u7684\u5e73\u8861\uff0c\u4e3a\u9690\u79c1\u4fdd\u62a4\u8bad\u7ec3\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.05418", "pdf": "https://arxiv.org/pdf/2506.05418", "abs": "https://arxiv.org/abs/2506.05418", "authors": ["Kyungsoo Kim", "Jeongsoo Ha", "Yusung Kim"], "title": "Self-Predictive Dynamics for Generalization of Vision-based Reinforcement Learning", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "IJCAI 2022", "summary": "Vision-based reinforcement learning requires efficient and robust\nrepresentations of image-based observations, especially when the images contain\ndistracting (task-irrelevant) elements such as shadows, clouds, and light. It\nbecomes more important if those distractions are not exposed during training.\nWe design a Self-Predictive Dynamics (SPD) method to extract task-relevant\nfeatures efficiently, even in unseen observations after training. SPD uses weak\nand strong augmentations in parallel, and learns representations by predicting\ninverse and forward transitions across the two-way augmented versions. In a set\nof MuJoCo visual control tasks and an autonomous driving task (CARLA), SPD\noutperforms previous studies in complex observations, and significantly\nimproves the generalization performance for unseen observations. Our code is\navailable at https://github.com/unigary/SPD.", "AI": {"tldr": "SPD\u65b9\u6cd5\u901a\u8fc7\u5f31\u589e\u5f3a\u548c\u5f3a\u589e\u5f3a\u5e76\u884c\u63d0\u53d6\u4efb\u52a1\u76f8\u5173\u7279\u5f81\uff0c\u663e\u8457\u63d0\u5347\u672a\u89c1\u89c2\u6d4b\u7684\u6cdb\u5316\u6027\u80fd\u3002", "motivation": "\u56fe\u50cf\u89c2\u6d4b\u4e2d\u5e38\u5305\u542b\u5e72\u6270\u5143\u7d20\uff08\u5982\u9634\u5f71\u3001\u4e91\u3001\u5149\uff09\uff0c\u5f71\u54cd\u5f3a\u5316\u5b66\u4e60\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u8bad\u7ec3\u4e2d\u672a\u66b4\u9732\u7684\u5e72\u6270\u4e0b\u3002", "method": "\u8bbe\u8ba1\u81ea\u9884\u6d4b\u52a8\u6001\uff08SPD\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u5e76\u884c\u5f31\u589e\u5f3a\u548c\u5f3a\u589e\u5f3a\u5b66\u4e60\u8868\u793a\uff0c\u9884\u6d4b\u53cc\u5411\u589e\u5f3a\u7248\u672c\u7684\u9006\u548c\u6b63\u5411\u8f6c\u6362\u3002", "result": "\u5728MuJoCo\u89c6\u89c9\u63a7\u5236\u4efb\u52a1\u548cCARLA\u81ea\u52a8\u9a7e\u9a76\u4efb\u52a1\u4e2d\uff0cSPD\u5728\u590d\u6742\u89c2\u6d4b\u4e2d\u4f18\u4e8e\u5148\u524d\u7814\u7a76\uff0c\u663e\u8457\u63d0\u5347\u672a\u89c1\u89c2\u6d4b\u7684\u6cdb\u5316\u6027\u80fd\u3002", "conclusion": "SPD\u80fd\u9ad8\u6548\u63d0\u53d6\u4efb\u52a1\u76f8\u5173\u7279\u5f81\uff0c\u9002\u7528\u4e8e\u590d\u6742\u548c\u672a\u89c1\u89c2\u6d4b\u573a\u666f\u3002"}}
{"id": "2506.05422", "pdf": "https://arxiv.org/pdf/2506.05422", "abs": "https://arxiv.org/abs/2506.05422", "authors": ["Andrei T. Patrascu"], "title": "Constructive Symbolic Reinforcement Learning via Intuitionistic Logic and Goal-Chaining Inference", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "We introduce a novel learning and planning framework that replaces\ntraditional reward-based optimisation with constructive logical inference. In\nour model, actions, transitions, and goals are represented as logical\npropositions, and decision-making proceeds by building constructive proofs\nunder intuitionistic logic. This method ensures that state transitions and\npolicies are accepted only when supported by verifiable preconditions --\neschewing probabilistic trial-and-error in favour of guaranteed logical\nvalidity. We implement a symbolic agent operating in a structured gridworld,\nwhere reaching a goal requires satisfying a chain of intermediate subgoals\n(e.g., collecting keys to open doors), each governed by logical constraints.\nUnlike conventional reinforcement learning agents, which require extensive\nexploration and suffer from unsafe or invalid transitions, our constructive\nagent builds a provably correct plan through goal chaining, condition tracking,\nand knowledge accumulation. Empirical comparison with Q-learning demonstrates\nthat our method achieves perfect safety, interpretable behaviour, and efficient\nconvergence with no invalid actions, highlighting its potential for safe\nplanning, symbolic cognition, and trustworthy AI. This work presents a new\ndirection for reinforcement learning grounded not in numeric optimisation, but\nin constructive logic and proof theory.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u903b\u8f91\u63a8\u7406\u7684\u5b66\u4e60\u4e0e\u89c4\u5212\u6846\u67b6\uff0c\u53d6\u4ee3\u4f20\u7edf\u7684\u57fa\u4e8e\u5956\u52b1\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u5efa\u76f4\u89c9\u903b\u8f91\u7684\u8bc1\u660e\u5b9e\u73b0\u51b3\u7b56\u3002", "motivation": "\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u4f9d\u8d56\u6982\u7387\u63a2\u7d22\uff0c\u53ef\u80fd\u5bfc\u81f4\u4e0d\u5b89\u5168\u6216\u65e0\u6548\u7684\u8fc7\u6e21\uff0c\u800c\u65b0\u65b9\u6cd5\u901a\u8fc7\u903b\u8f91\u9a8c\u8bc1\u786e\u4fdd\u51b3\u7b56\u7684\u6b63\u786e\u6027\u548c\u5b89\u5168\u6027\u3002", "method": "\u5c06\u52a8\u4f5c\u3001\u72b6\u6001\u8f6c\u79fb\u548c\u76ee\u6807\u8868\u793a\u4e3a\u903b\u8f91\u547d\u9898\uff0c\u5229\u7528\u76f4\u89c9\u903b\u8f91\u6784\u5efa\u6784\u9020\u6027\u8bc1\u660e\uff0c\u786e\u4fdd\u6bcf\u4e00\u6b65\u7684\u5408\u6cd5\u6027\u3002\u5728\u7ed3\u6784\u5316\u7f51\u683c\u4e16\u754c\u4e2d\u5b9e\u73b0\u7b26\u53f7\u5316\u4ee3\u7406\u3002", "result": "\u76f8\u6bd4Q\u5b66\u4e60\uff0c\u65b0\u65b9\u6cd5\u5b9e\u73b0\u4e86\u5b8c\u7f8e\u7684\u5b89\u5168\u6027\u3001\u53ef\u89e3\u91ca\u7684\u884c\u4e3a\u548c\u9ad8\u6548\u6536\u655b\uff0c\u65e0\u65e0\u6548\u52a8\u4f5c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u57fa\u4e8e\u6784\u9020\u903b\u8f91\u548c\u8bc1\u660e\u7406\u8bba\u7684\u65b0\u65b9\u5411\uff0c\u9002\u7528\u4e8e\u5b89\u5168\u89c4\u5212\u548c\u53ef\u4fe1AI\u3002"}}
{"id": "2506.05429", "pdf": "https://arxiv.org/pdf/2506.05429", "abs": "https://arxiv.org/abs/2506.05429", "authors": ["Ashwin Ramesh Babu", "Sajad Mousavi", "Vineet Gundecha", "Sahand Ghorbanpour", "Avisek Naug", "Antonio Guillen", "Ricardo Luna Gutierrez", "Soumyendu Sarkar"], "title": "Coordinated Robustness Evaluation Framework for Vision-Language Models", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": "Accepted: IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition Workshops (CVPRW) 2025", "summary": "Vision-language models, which integrate computer vision and natural language\nprocessing capabilities, have demonstrated significant advancements in tasks\nsuch as image captioning and visual question and answering. However, similar to\ntraditional models, they are susceptible to small perturbations, posing a\nchallenge to their robustness, particularly in deployment scenarios. Evaluating\nthe robustness of these models requires perturbations in both the vision and\nlanguage modalities to learn their inter-modal dependencies. In this work, we\ntrain a generic surrogate model that can take both image and text as input and\ngenerate joint representation which is further used to generate adversarial\nperturbations for both the text and image modalities. This coordinated attack\nstrategy is evaluated on the visual question and answering and visual reasoning\ndatasets using various state-of-the-art vision-language models. Our results\nindicate that the proposed strategy outperforms other multi-modal attacks and\nsingle-modality attacks from the recent literature. Our results demonstrate\ntheir effectiveness in compromising the robustness of several state-of-the-art\npre-trained multi-modal models such as instruct-BLIP, ViLT and others.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u7684\u66ff\u4ee3\u6a21\u578b\uff0c\u7528\u4e8e\u751f\u6210\u9488\u5bf9\u89c6\u89c9\u548c\u8bed\u8a00\u6a21\u6001\u7684\u5bf9\u6297\u6027\u6270\u52a8\uff0c\u4ee5\u8bc4\u4f30\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u56fe\u50cf\u63cf\u8ff0\u548c\u89c6\u89c9\u95ee\u7b54\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u5bf9\u5fae\u5c0f\u6270\u52a8\u7684\u654f\u611f\u6027\u9650\u5236\u4e86\u5176\u9c81\u68d2\u6027\uff0c\u5c24\u5176\u662f\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u3002", "method": "\u8bad\u7ec3\u4e00\u4e2a\u901a\u7528\u7684\u66ff\u4ee3\u6a21\u578b\uff0c\u80fd\u591f\u540c\u65f6\u5904\u7406\u56fe\u50cf\u548c\u6587\u672c\u8f93\u5165\uff0c\u751f\u6210\u8054\u5408\u8868\u793a\uff0c\u5e76\u8fdb\u4e00\u6b65\u751f\u6210\u9488\u5bf9\u6587\u672c\u548c\u56fe\u50cf\u6a21\u6001\u7684\u5bf9\u6297\u6027\u6270\u52a8\u3002", "result": "\u5728\u89c6\u89c9\u95ee\u7b54\u548c\u89c6\u89c9\u63a8\u7406\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u7b56\u7565\u4f18\u4e8e\u5176\u4ed6\u591a\u6a21\u6001\u653b\u51fb\u548c\u5355\u6a21\u6001\u653b\u51fb\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u534f\u8c03\u653b\u51fb\u7b56\u7565\u80fd\u6709\u6548\u7834\u574f\u591a\u79cd\u5148\u8fdb\u9884\u8bad\u7ec3\u591a\u6a21\u6001\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2506.05431", "pdf": "https://arxiv.org/pdf/2506.05431", "abs": "https://arxiv.org/abs/2506.05431", "authors": ["Ashwin Ramesh Babu", "Sajad Mousavi", "Vineet Gundecha", "Sahand Ghorbanpour", "Avisek Naug", "Antonio Guillen", "Ricardo Luna Gutierrez", "Soumyendu Sarkar"], "title": "Robustness Evaluation for Video Models with Reinforcement Learning", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted at the IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition Workshops (CVPRW) 2025", "summary": "Evaluating the robustness of Video classification models is very challenging,\nspecifically when compared to image-based models. With their increased temporal\ndimension, there is a significant increase in complexity and computational\ncost. One of the key challenges is to keep the perturbations to a minimum to\ninduce misclassification. In this work, we propose a multi-agent reinforcement\nlearning approach (spatial and temporal) that cooperatively learns to identify\nthe given video's sensitive spatial and temporal regions. The agents consider\ntemporal coherence in generating fine perturbations, leading to a more\neffective and visually imperceptible attack. Our method outperforms the\nstate-of-the-art solutions on the Lp metric and the average queries. Our method\nenables custom distortion types, making the robustness evaluation more relevant\nto the use case. We extensively evaluate 4 popular models for video action\nrecognition on two popular datasets, HMDB-51 and UCF-101.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u89c6\u9891\u5206\u7c7b\u6a21\u578b\u7684\u9c81\u68d2\u6027\u8bc4\u4f30\uff0c\u901a\u8fc7\u65f6\u7a7a\u534f\u540c\u6270\u52a8\u751f\u6210\u66f4\u6709\u6548\u7684\u653b\u51fb\u3002", "motivation": "\u89c6\u9891\u5206\u7c7b\u6a21\u578b\u7684\u9c81\u68d2\u6027\u8bc4\u4f30\u6bd4\u56fe\u50cf\u6a21\u578b\u66f4\u5177\u6311\u6218\u6027\uff0c\u56e0\u5176\u65f6\u95f4\u7ef4\u5ea6\u548c\u8ba1\u7b97\u590d\u6742\u6027\u589e\u52a0\uff0c\u9700\u6700\u5c0f\u5316\u6270\u52a8\u4ee5\u8bf1\u5bfc\u8bef\u5206\u7c7b\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08\u7a7a\u95f4\u548c\u65f6\u95f4\uff09\u534f\u540c\u8bc6\u522b\u89c6\u9891\u654f\u611f\u533a\u57df\uff0c\u751f\u6210\u89c6\u89c9\u4e0d\u53ef\u5bdf\u89c9\u7684\u7cbe\u7ec6\u6270\u52a8\u3002", "result": "\u5728Lp\u5ea6\u91cf\u548c\u5e73\u5747\u67e5\u8be2\u6b21\u6570\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u652f\u6301\u81ea\u5b9a\u4e49\u5931\u771f\u7c7b\u578b\uff0c\u5e76\u5728HMDB-51\u548cUCF-101\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u4e864\u79cd\u6d41\u884c\u6a21\u578b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u89c6\u9891\u52a8\u4f5c\u8bc6\u522b\u6a21\u578b\u7684\u9c81\u68d2\u6027\u8bc4\u4f30\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u63d0\u4f9b\u4e86\u66f4\u8d34\u8fd1\u5b9e\u9645\u5e94\u7528\u7684\u6270\u52a8\u751f\u6210\u65b9\u5f0f\u3002"}}
{"id": "2506.05441", "pdf": "https://arxiv.org/pdf/2506.05441", "abs": "https://arxiv.org/abs/2506.05441", "authors": ["Kimberley M. Bird", "Xujiong Ye", "Alan M. Race", "James M. Brown"], "title": "Deep histological synthesis from mass spectrometry imaging for multimodal registration", "categories": ["eess.IV", "cs.CV", "cs.LG", "I.2; I.4"], "comment": "Medical Image Understanding and Analysis (MIUA) 2025 Extended\n  Abstract Submission", "summary": "Registration of histological and mass spectrometry imaging (MSI) allows for\nmore precise identification of structural changes and chemical interactions in\ntissue. With histology and MSI having entirely different image formation\nprocesses and dimensionalities, registration of the two modalities remains an\nongoing challenge. This work proposes a solution that synthesises histological\nimages from MSI, using a pix2pix model, to effectively enable unimodal\nregistration. Preliminary results show promising synthetic histology images\nwith limited artifacts, achieving increases in mutual information (MI) and\nstructural similarity index measures (SSIM) of +0.924 and +0.419, respectively,\ncompared to a baseline U-Net model. Our source code is available on GitHub:\nhttps://github.com/kimberley/MIUA2025.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7pix2pix\u6a21\u578b\u4eceMSI\u5408\u6210\u7ec4\u7ec7\u5b66\u56fe\u50cf\u7684\u65b9\u6cd5\uff0c\u4ee5\u5b9e\u73b0\u5355\u6a21\u6001\u914d\u51c6\uff0c\u521d\u6b65\u7ed3\u679c\u663e\u793a\u5408\u6210\u56fe\u50cf\u8d28\u91cf\u8f83\u9ad8\uff0c\u4e14\u6027\u80fd\u4f18\u4e8e\u57fa\u7ebfU-Net\u6a21\u578b\u3002", "motivation": "\u7ec4\u7ec7\u5b66\u548cMSI\u7684\u56fe\u50cf\u5f62\u6210\u8fc7\u7a0b\u548c\u7ef4\u5ea6\u4e0d\u540c\uff0c\u5bfc\u81f4\u4e24\u8005\u914d\u51c6\u56f0\u96be\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528pix2pix\u6a21\u578b\u4eceMSI\u5408\u6210\u7ec4\u7ec7\u5b66\u56fe\u50cf\uff0c\u4ee5\u5b9e\u73b0\u5355\u6a21\u6001\u914d\u51c6\u3002", "result": "\u5408\u6210\u7684\u7ec4\u7ec7\u5b66\u56fe\u50cf\u8d28\u91cf\u8f83\u9ad8\uff0c\u4e92\u4fe1\u606f\uff08MI\uff09\u548c\u7ed3\u6784\u76f8\u4f3c\u6027\u6307\u6570\uff08SSIM\uff09\u5206\u522b\u63d0\u9ad8\u4e86+0.924\u548c+0.419\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u7ec4\u7ec7\u5b66\u548cMSI\u7684\u914d\u51c6\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u4e14\u6027\u80fd\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002"}}
{"id": "2506.05444", "pdf": "https://arxiv.org/pdf/2506.05444", "abs": "https://arxiv.org/abs/2506.05444", "authors": ["Marwane Kzadri", "Franco Alberto Cardillo", "Nan\u00e9e Chahinian", "Carole Delenne", "Renaud Hostache", "Jamal Riffi"], "title": "U-NetMN and SegNetMN: Modified U-Net and SegNet models for bimodal SAR image segmentation", "categories": ["cs.CV", "cs.LG", "eess.IV"], "comment": null, "summary": "Segmenting Synthetic Aperture Radar (SAR) images is crucial for many remote\nsensing applications, particularly water body detection. However, deep\nlearning-based segmentation models often face challenges related to convergence\nspeed and stability, mainly due to the complex statistical distribution of this\ntype of data. In this study, we evaluate the impact of mode normalization on\ntwo widely used semantic segmentation models, U-Net and SegNet. Specifically,\nwe integrate mode normalization, to reduce convergence time while maintaining\nthe performance of the baseline models. Experimental results demonstrate that\nmode normalization significantly accelerates convergence. Furthermore,\ncross-validation results indicate that normalized models exhibit increased\nstability in different zones. These findings highlight the effectiveness of\nnormalization in improving computational efficiency and generalization in SAR\nimage segmentation.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86\u6a21\u5f0f\u5f52\u4e00\u5316\u5bf9U-Net\u548cSegNet\u6a21\u578b\u5728SAR\u56fe\u50cf\u5206\u5272\u4e2d\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5176\u80fd\u663e\u8457\u52a0\u901f\u6536\u655b\u5e76\u63d0\u9ad8\u7a33\u5b9a\u6027\u3002", "motivation": "\u7531\u4e8eSAR\u56fe\u50cf\u7684\u590d\u6742\u7edf\u8ba1\u5206\u5e03\uff0c\u6df1\u5ea6\u5b66\u4e60\u5206\u5272\u6a21\u578b\u5728\u6536\u655b\u901f\u5ea6\u548c\u7a33\u5b9a\u6027\u4e0a\u9762\u4e34\u6311\u6218\u3002", "method": "\u5728U-Net\u548cSegNet\u4e2d\u96c6\u6210\u6a21\u5f0f\u5f52\u4e00\u5316\uff0c\u4ee5\u51cf\u5c11\u6536\u655b\u65f6\u95f4\u5e76\u4fdd\u6301\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u6a21\u5f0f\u5f52\u4e00\u5316\u663e\u8457\u52a0\u901f\u6536\u655b\uff0c\u4e14\u5f52\u4e00\u5316\u6a21\u578b\u5728\u4e0d\u540c\u533a\u57df\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u7a33\u5b9a\u6027\u3002", "conclusion": "\u5f52\u4e00\u5316\u6709\u6548\u63d0\u5347\u4e86SAR\u56fe\u50cf\u5206\u5272\u7684\u8ba1\u7b97\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2506.05449", "pdf": "https://arxiv.org/pdf/2506.05449", "abs": "https://arxiv.org/abs/2506.05449", "authors": ["Miguel Silva", "Alexandre Valle de Carvalho"], "title": "AI-powered Contextual 3D Environment Generation: A Systematic Review", "categories": ["cs.GR", "cs.CV", "cs.LG"], "comment": null, "summary": "The generation of high-quality 3D environments is crucial for industries such\nas gaming, virtual reality, and cinema, yet remains resource-intensive due to\nthe reliance on manual processes. This study performs a systematic review of\nexisting generative AI techniques for 3D scene generation, analyzing their\ncharacteristics, strengths, limitations, and potential for improvement. By\nexamining state-of-the-art approaches, it presents key challenges such as scene\nauthenticity and the influence of textual inputs. Special attention is given to\nhow AI can blend different stylistic domains while maintaining coherence, the\nimpact of training data on output quality, and the limitations of current\nmodels. In addition, this review surveys existing evaluation metrics for\nassessing realism and explores how industry professionals incorporate AI into\ntheir workflows. The findings of this study aim to provide a comprehensive\nunderstanding of the current landscape and serve as a foundation for future\nresearch on AI-driven 3D content generation. Key findings include that advanced\ngenerative architectures enable high-quality 3D content creation at a high\ncomputational cost, effective multi-modal integration techniques like\ncross-attention and latent space alignment facilitate text-to-3D tasks, and the\nquality and diversity of training data combined with comprehensive evaluation\nmetrics are critical to achieving scalable, robust 3D scene generation.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7efc\u8ff0\u4e86\u751f\u6210\u5f0fAI\u57283D\u573a\u666f\u751f\u6210\u4e2d\u7684\u5e94\u7528\uff0c\u5206\u6790\u4e86\u73b0\u6709\u6280\u672f\u7684\u7279\u6027\u3001\u4f18\u52bf\u3001\u5c40\u9650\u53ca\u6539\u8fdb\u6f5c\u529b\uff0c\u5e76\u63a2\u8ba8\u4e86\u5173\u952e\u6311\u6218\u5982\u573a\u666f\u771f\u5b9e\u6027\u548c\u6587\u672c\u8f93\u5165\u7684\u5f71\u54cd\u3002", "motivation": "\u9ad8\u8d28\u91cf3D\u73af\u5883\u751f\u6210\u5728\u6e38\u620f\u3001\u865a\u62df\u73b0\u5b9e\u548c\u7535\u5f71\u7b49\u884c\u4e1a\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u76ee\u524d\u4f9d\u8d56\u624b\u52a8\u6d41\u7a0b\uff0c\u8d44\u6e90\u6d88\u8017\u5927\u3002\u7814\u7a76\u65e8\u5728\u901a\u8fc7AI\u6280\u672f\u63d0\u5347\u751f\u6210\u6548\u7387\u548c\u8d28\u91cf\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u7efc\u8ff0\u73b0\u6709\u751f\u6210\u5f0fAI\u6280\u672f\uff0c\u5206\u6790\u5176\u7279\u70b9\u3001\u4f18\u52bf\u548c\u5c40\u9650\uff0c\u5e76\u63a2\u8ba8\u591a\u6a21\u6001\u96c6\u6210\u6280\u672f\u548c\u8bad\u7ec3\u6570\u636e\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5148\u8fdb\u7684\u751f\u6210\u67b6\u6784\u80fd\u4ee5\u9ad8\u8ba1\u7b97\u6210\u672c\u751f\u6210\u9ad8\u8d28\u91cf3D\u5185\u5bb9\uff0c\u591a\u6a21\u6001\u96c6\u6210\u6280\u672f\uff08\u5982\u4ea4\u53c9\u6ce8\u610f\u529b\u548c\u6f5c\u5728\u7a7a\u95f4\u5bf9\u9f50\uff09\u6709\u52a9\u4e8e\u6587\u672c\u52303D\u4efb\u52a1\uff0c\u8bad\u7ec3\u6570\u636e\u7684\u8d28\u91cf\u548c\u591a\u6837\u6027\u5bf9\u751f\u6210\u6548\u679c\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "\u672c\u6587\u4e3aAI\u9a71\u52a8\u76843D\u5185\u5bb9\u751f\u6210\u63d0\u4f9b\u4e86\u5168\u9762\u7406\u89e3\uff0c\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5f3a\u8c03\u8bad\u7ec3\u6570\u636e\u548c\u8bc4\u4f30\u6307\u6807\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2506.05480", "pdf": "https://arxiv.org/pdf/2506.05480", "abs": "https://arxiv.org/abs/2506.05480", "authors": ["Daniel Wang", "Patrick Rim", "Tian Tian", "Alex Wong", "Ganesh Sundaramoorthi"], "title": "ODE-GS: Latent ODEs for Dynamic Scene Extrapolation with 3D Gaussian Splatting", "categories": ["cs.GR", "cs.CV", "cs.LG"], "comment": null, "summary": "We present ODE-GS, a novel method that unifies 3D Gaussian Splatting with\nlatent neural ordinary differential equations (ODEs) to forecast dynamic 3D\nscenes far beyond the time span seen during training. Existing neural rendering\nsystems - whether NeRF- or 3DGS-based - embed time directly in a deformation\nnetwork and therefore excel at interpolation but collapse when asked to predict\nthe future, where timestamps are strictly out-of-distribution. ODE-GS\neliminates this dependency: after learning a high-fidelity, time-conditioned\ndeformation model for the training window, we freeze it and train a Transformer\nencoder that summarizes past Gaussian trajectories into a latent state whose\ncontinuous evolution is governed by a neural ODE. Numerical integration of this\nlatent flow yields smooth, physically plausible Gaussian trajectories that can\nbe queried at any future instant and rendered in real time. Coupled with a\nvariational objective and a lightweight second-derivative regularizer, ODE-GS\nattains state-of-the-art extrapolation on D-NeRF and NVFI benchmarks, improving\nPSNR by up to 10 dB and halving perceptual error (LPIPS) relative to the\nstrongest baselines. Our results demonstrate that continuous-time latent\ndynamics are a powerful, practical route to photorealistic prediction of\ncomplex 3D scenes.", "AI": {"tldr": "ODE-GS\u7ed3\u54083D\u9ad8\u65af\u6cfc\u6e85\u4e0e\u6f5c\u5728\u795e\u7ecfODE\uff0c\u9884\u6d4b\u52a8\u60013D\u573a\u666f\uff0c\u8d85\u8d8a\u8bad\u7ec3\u65f6\u95f4\u8303\u56f4\uff0c\u5b9e\u73b0\u9ad8\u4fdd\u771f\u5916\u63a8\u3002", "motivation": "\u73b0\u6709\u795e\u7ecf\u6e32\u67d3\u7cfb\u7edf\uff08\u5982NeRF\u62163DGS\uff09\u4f9d\u8d56\u65f6\u95f4\u5d4c\u5165\uff0c\u64c5\u957f\u63d2\u503c\u4f46\u65e0\u6cd5\u9884\u6d4b\u672a\u6765\u65f6\u95f4\u70b9\u3002ODE-GS\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u51bb\u7ed3\u65f6\u95f4\u6761\u4ef6\u53d8\u5f62\u6a21\u578b\uff0c\u7528Transformer\u7f16\u7801\u8fc7\u53bb\u9ad8\u65af\u8f68\u8ff9\uff0c\u901a\u8fc7\u795e\u7ecfODE\u63a7\u5236\u6f5c\u5728\u72b6\u6001\u8fde\u7eed\u6f14\u5316\uff0c\u6570\u503c\u79ef\u5206\u751f\u6210\u672a\u6765\u8f68\u8ff9\u3002", "result": "\u5728D-NeRF\u548cNVFI\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cPSNR\u63d0\u5347\u8fbe10 dB\uff0cLPIPS\u51cf\u534a\uff0c\u5b9e\u73b0\u6700\u5148\u8fdb\u7684\u5916\u63a8\u6027\u80fd\u3002", "conclusion": "\u8fde\u7eed\u65f6\u95f4\u6f5c\u5728\u52a8\u529b\u5b66\u662f\u9884\u6d4b\u590d\u67423D\u573a\u666f\u7684\u6709\u6548\u65b9\u6cd5\uff0cODE-GS\u5c55\u793a\u4e86\u5176\u5f3a\u5927\u5b9e\u7528\u6027\u3002"}}
{"id": "2506.05490", "pdf": "https://arxiv.org/pdf/2506.05490", "abs": "https://arxiv.org/abs/2506.05490", "authors": ["Mohammed Almutairi"], "title": "Sentiment Analysis in Learning Management Systems Understanding Student Feedback at Scale", "categories": ["cs.HC", "cs.AI", "cs.LG"], "comment": "10 pages, 10 figures", "summary": "During the wake of the Covid-19 pandemic, the educational paradigm has\nexperienced a major change from in person learning traditional to online\nplatforms. The change of learning convention has impacted the teacher-student\nespecially in non-verbal communication. The absent of non-verbal communication\nhas led to a reliance on verbal feedback which diminished the efficacy of the\neducational experience. This paper explores the integration of sentiment\nanalysis into learning management systems (LMS) to bridge the student-teacher's\ngap by offering an alternative approach to interpreting student feedback beyond\nits verbal context. The research involves data preparation, feature selection,\nand the development of a deep neural network model encompassing word embedding,\nLSTM, and attention mechanisms. This model is compared against a logistic\nregression baseline to evaluate its efficacy in understanding student feedback.\nThe study aims to bridge the communication gap between instructors and students\nin online learning environments, offering insights into the emotional context\nof student feedback and ultimately improving the quality of online education.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u65b0\u51a0\u75ab\u60c5\u671f\u95f4\uff0c\u6559\u80b2\u6a21\u5f0f\u4ece\u4f20\u7edf\u9762\u5bf9\u9762\u8f6c\u5411\u5728\u7ebf\u5e73\u53f0\u540e\uff0c\u975e\u8bed\u8a00\u6c9f\u901a\u7f3a\u5931\u5bfc\u81f4\u6559\u80b2\u6548\u679c\u4e0b\u964d\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u901a\u8fc7\u60c5\u611f\u5206\u6790\u6280\u672f\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u6765\u6539\u5584\u5b66\u751f\u53cd\u9988\u7684\u7406\u89e3\u3002", "motivation": "\u65b0\u51a0\u75ab\u60c5\u5bfc\u81f4\u6559\u80b2\u6a21\u5f0f\u8f6c\u5411\u5728\u7ebf\u5e73\u53f0\uff0c\u975e\u8bed\u8a00\u6c9f\u901a\u7684\u7f3a\u5931\u5f71\u54cd\u4e86\u5e08\u751f\u4e92\u52a8\u6548\u679c\uff0c\u4e9f\u9700\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u5f25\u8865\u8fd9\u4e00\u6c9f\u901a\u9e3f\u6c9f\u3002", "method": "\u7814\u7a76\u5305\u62ec\u6570\u636e\u51c6\u5907\u3001\u7279\u5f81\u9009\u62e9\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u7ed3\u5408\u8bcd\u5d4c\u5165\u3001LSTM\u548c\u6ce8\u610f\u529b\u673a\u5236\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u4e0e\u903b\u8f91\u56de\u5f52\u57fa\u7ebf\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u6a21\u578b\u65e8\u5728\u66f4\u51c6\u786e\u5730\u7406\u89e3\u5b66\u751f\u53cd\u9988\u7684\u60c5\u611f\u80cc\u666f\uff0c\u4e3a\u5728\u7ebf\u6559\u80b2\u63d0\u4f9b\u66f4\u6709\u6548\u7684\u5e08\u751f\u6c9f\u901a\u5de5\u5177\u3002", "conclusion": "\u901a\u8fc7\u60c5\u611f\u5206\u6790\u6280\u672f\uff0c\u7814\u7a76\u4e3a\u5728\u7ebf\u6559\u80b2\u4e2d\u7684\u5e08\u751f\u6c9f\u901a\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u6709\u671b\u63d0\u5347\u6559\u80b2\u8d28\u91cf\u3002"}}
{"id": "2506.05495", "pdf": "https://arxiv.org/pdf/2506.05495", "abs": "https://arxiv.org/abs/2506.05495", "authors": ["Vladimir Braverman", "Jon C. Ergun", "Chen Wang", "Samson Zhou"], "title": "Learning-Augmented Hierarchical Clustering", "categories": ["cs.DS", "cs.LG"], "comment": "ICML 2025; abstract shortened for arxiv requirements", "summary": "Hierarchical clustering (HC) is an important data analysis technique in which\nthe goal is to recursively partition a dataset into a tree-like structure while\ngrouping together similar data points at each level of granularity.\nUnfortunately, for many of the proposed HC objectives, there exist strong\nbarriers to approximation algorithms with the hardness of approximation. Thus,\nwe consider the problem of hierarchical clustering given auxiliary information\nfrom natural oracles. Specifically, we focus on a *splitting oracle* which,\nwhen provided with a triplet of vertices $(u,v,w)$, answers (possibly\nerroneously) the pairs of vertices whose lowest common ancestor includes all\nthree vertices in an optimal tree, i.e., identifying which vertex ``splits\naway'' from the others. Using such an oracle, we obtain the following results:\n  - A polynomial-time algorithm that outputs a hierarchical clustering tree\nwith $O(1)$-approximation to the Dasgupta objective (Dasgupta [STOC'16]).\n  - A near-linear time algorithm that outputs a hierarchical clustering tree\nwith $(1-o(1))$-approximation to the Moseley-Wang objective (Moseley and Wang\n[NeurIPS'17]).\n  Under the plausible Small Set Expansion Hypothesis, no polynomial-time\nalgorithm can achieve any constant approximation for Dasgupta's objective or\n$(1-C)$-approximation for the Moseley-Wang objective for some constant $C>0$.\nAs such, our results demonstrate that the splitting oracle enables algorithms\nto outperform standard HC approaches and overcome hardness constraints.\nFurthermore, our approaches extend to sublinear settings, in which we show new\nstreaming and PRAM algorithms for HC with improved guarantees.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5206\u88c2\u9884\u8a00\u673a\u8f85\u52a9\u7684\u5206\u5c42\u805a\u7c7b\u65b9\u6cd5\uff0c\u514b\u670d\u4e86\u4f20\u7edfHC\u7b97\u6cd5\u7684\u8fd1\u4f3c\u56f0\u96be\uff0c\u5e76\u63d0\u4f9b\u4e86\u591a\u9879\u5f0f\u65f6\u95f4\u548c\u8fd1\u7ebf\u6027\u65f6\u95f4\u7684\u8fd1\u4f3c\u7b97\u6cd5\u3002", "motivation": "\u4f20\u7edf\u5206\u5c42\u805a\u7c7b\uff08HC\uff09\u76ee\u6807\u5b58\u5728\u8fd1\u4f3c\u7b97\u6cd5\u7684\u56f0\u96be\uff0c\u56e0\u6b64\u7814\u7a76\u5982\u4f55\u5229\u7528\u8f85\u52a9\u4fe1\u606f\uff08\u5982\u5206\u88c2\u9884\u8a00\u673a\uff09\u6765\u514b\u670d\u8fd9\u4e9b\u9650\u5236\u3002", "method": "\u4f7f\u7528\u5206\u88c2\u9884\u8a00\u673a\uff0c\u63d0\u4f9b\u9876\u70b9\u4e09\u5143\u7ec4\u7684\u4fe1\u606f\uff0c\u8bbe\u8ba1\u591a\u9879\u5f0f\u65f6\u95f4\u548c\u8fd1\u7ebf\u6027\u65f6\u95f4\u7684\u8fd1\u4f3c\u7b97\u6cd5\u3002", "result": "\u5b9e\u73b0\u4e86\u5bf9Dasgupta\u76ee\u6807\u7684O(1)\u8fd1\u4f3c\u548c\u5bf9Moseley-Wang\u76ee\u6807\u7684(1-o(1))\u8fd1\u4f3c\uff0c\u5e76\u6269\u5c55\u81f3\u5b50\u7ebf\u6027\u8bbe\u7f6e\u3002", "conclusion": "\u5206\u88c2\u9884\u8a00\u673a\u80fd\u591f\u5e2e\u52a9\u7b97\u6cd5\u8d85\u8d8a\u4f20\u7edfHC\u65b9\u6cd5\u7684\u9650\u5236\uff0c\u514b\u670d\u8fd1\u4f3c\u56f0\u96be\uff0c\u5e76\u5728\u5b50\u7ebf\u6027\u8bbe\u7f6e\u4e2d\u63d0\u4f9b\u65b0\u7684\u7b97\u6cd5\u4fdd\u8bc1\u3002"}}
{"id": "2506.05498", "pdf": "https://arxiv.org/pdf/2506.05498", "abs": "https://arxiv.org/abs/2506.05498", "authors": ["Niruthiha Selvanayagam"], "title": "Multidimensional Analysis of Specific Language Impairment Using Unsupervised Learning Through PCA and Clustering", "categories": ["cs.CL", "cs.LG", "62H30, 62P10", "I.2.7; J.3"], "comment": "14 pages, 3 figures, 16 tables", "summary": "Specific Language Impairment (SLI) affects approximately 7 percent of\nchildren, presenting as isolated language deficits despite normal cognitive\nabilities, sensory systems, and supportive environments. Traditional diagnostic\napproaches often rely on standardized assessments, which may overlook subtle\ndevelopmental patterns. This study aims to identify natural language\ndevelopment trajectories in children with and without SLI using unsupervised\nmachine learning techniques, providing insights for early identification and\ntargeted interventions. Narrative samples from 1,163 children aged 4-16 years\nacross three corpora (Conti-Ramsden 4, ENNI, and Gillam) were analyzed using\nPrincipal Component Analysis (PCA) and clustering. A total of 64 linguistic\nfeatures were evaluated to uncover developmental trajectories and distinguish\nlinguistic profiles. Two primary clusters emerged: (1) high language production\nwith low SLI prevalence, and (2) limited production but higher syntactic\ncomplexity with higher SLI prevalence. Additionally, boundary cases exhibited\nintermediate traits, supporting a continuum model of language abilities.\nFindings suggest SLI manifests primarily through reduced production capacity\nrather than syntactic complexity deficits. The results challenge categorical\ndiagnostic frameworks and highlight the potential of unsupervised learning\ntechniques for refining diagnostic criteria and intervention strategies.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f7f\u7528\u65e0\u76d1\u7763\u673a\u5668\u5b66\u4e60\u6280\u672f\u5206\u6790\u513f\u7ae5\u8bed\u8a00\u53d1\u5c55\u8f68\u8ff9\uff0c\u53d1\u73b0\u7279\u5b9a\u8bed\u8a00\u969c\u788d\uff08SLI\uff09\u4e3b\u8981\u8868\u73b0\u4e3a\u8bed\u8a00\u4ea7\u51fa\u80fd\u529b\u4e0b\u964d\u800c\u975e\u53e5\u6cd5\u590d\u6742\u6027\u7f3a\u9677\uff0c\u6311\u6218\u4e86\u4f20\u7edf\u5206\u7c7b\u8bca\u65ad\u6846\u67b6\u3002", "motivation": "\u4f20\u7edf\u8bca\u65ad\u65b9\u6cd5\u53ef\u80fd\u5ffd\u7565\u7ec6\u5fae\u53d1\u5c55\u6a21\u5f0f\uff0c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u65e0\u76d1\u7763\u5b66\u4e60\u6280\u672f\u8bc6\u522bSLI\u513f\u7ae5\u7684\u81ea\u7136\u8bed\u8a00\u53d1\u5c55\u8f68\u8ff9\uff0c\u4e3a\u65e9\u671f\u8bc6\u522b\u548c\u5e72\u9884\u63d0\u4f9b\u4f9d\u636e\u3002", "method": "\u5206\u67901,163\u540d4-16\u5c81\u513f\u7ae5\u7684\u53d9\u4e8b\u6837\u672c\uff0c\u4f7f\u7528\u4e3b\u6210\u5206\u5206\u6790\uff08PCA\uff09\u548c\u805a\u7c7b\u6280\u672f\u8bc4\u4f3064\u4e2a\u8bed\u8a00\u7279\u5f81\uff0c\u63ed\u793a\u53d1\u5c55\u8f68\u8ff9\u548c\u533a\u5206\u8bed\u8a00\u7279\u5f81\u3002", "result": "\u53d1\u73b0\u4e24\u4e2a\u4e3b\u8981\u805a\u7c7b\uff1a\u9ad8\u8bed\u8a00\u4ea7\u51fa\u4f4eSLI\u60a3\u75c5\u7387\u7ec4\u548c\u4f4e\u4ea7\u51fa\u9ad8\u53e5\u6cd5\u590d\u6742\u6027\u9ad8SLI\u60a3\u75c5\u7387\u7ec4\uff0c\u652f\u6301\u8bed\u8a00\u80fd\u529b\u7684\u8fde\u7eed\u6a21\u578b\u3002", "conclusion": "SLI\u4e3b\u8981\u8868\u73b0\u4e3a\u8bed\u8a00\u4ea7\u51fa\u80fd\u529b\u4e0b\u964d\uff0c\u7814\u7a76\u7ed3\u679c\u652f\u6301\u65e0\u76d1\u7763\u5b66\u4e60\u6280\u672f\u5728\u4f18\u5316\u8bca\u65ad\u6807\u51c6\u548c\u5e72\u9884\u7b56\u7565\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.05516", "pdf": "https://arxiv.org/pdf/2506.05516", "abs": "https://arxiv.org/abs/2506.05516", "authors": ["Boyuan Deng", "Luca Rossini", "Jin Wang", "Weijie Wang", "Nikolaos Tsagarakis"], "title": "Learning to Recover: Dynamic Reward Shaping with Wheel-Leg Coordination for Fallen Robots", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "Adaptive recovery from fall incidents are essential skills for the practical\ndeployment of wheeled-legged robots, which uniquely combine the agility of legs\nwith the speed of wheels for rapid recovery. However, traditional methods\nrelying on preplanned recovery motions, simplified dynamics or sparse rewards\noften fail to produce robust recovery policies. This paper presents a\nlearning-based framework integrating Episode-based Dynamic Reward Shaping and\ncurriculum learning, which dynamically balances exploration of diverse recovery\nmaneuvers with precise posture refinement. An asymmetric actor-critic\narchitecture accelerates training by leveraging privileged information in\nsimulation, while noise-injected observations enhance robustness against\nuncertainties. We further demonstrate that synergistic wheel-leg coordination\nreduces joint torque consumption by 15.8% and 26.2% and improves stabilization\nthrough energy transfer mechanisms. Extensive evaluations on two distinct\nquadruped platforms achieve recovery success rates up to 99.1% and 97.8%\nwithout platform-specific tuning. The supplementary material is available at\nhttps://boyuandeng.github.io/L2R-WheelLegCoordination/", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u7ed3\u5408\u52a8\u6001\u5956\u52b1\u8c03\u6574\u548c\u8bfe\u7a0b\u5b66\u4e60\uff0c\u7528\u4e8e\u8f6e\u817f\u673a\u5668\u4eba\u8dcc\u5012\u540e\u7684\u81ea\u9002\u5e94\u6062\u590d\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6062\u590d\u6210\u529f\u7387\u548c\u80fd\u91cf\u6548\u7387\u3002", "motivation": "\u8f6e\u817f\u673a\u5668\u4eba\u7ed3\u5408\u4e86\u817f\u7684\u654f\u6377\u6027\u548c\u8f6e\u7684\u901f\u5ea6\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u5728\u6062\u590d\u7b56\u7565\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u66f4\u9c81\u68d2\u7684\u5b66\u4e60\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u52a8\u6001\u5956\u52b1\u8c03\u6574\u548c\u8bfe\u7a0b\u5b66\u4e60\uff0c\u7ed3\u5408\u975e\u5bf9\u79f0actor-critic\u67b6\u6784\u548c\u566a\u58f0\u6ce8\u5165\u89c2\u5bdf\uff0c\u4f18\u5316\u6062\u590d\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u4e24\u79cd\u56db\u8db3\u5e73\u53f0\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u8fbe99.1%\u548c97.8%\u7684\u6062\u590d\u6210\u529f\u7387\uff0c\u5e76\u51cf\u5c11\u4e86\u5173\u8282\u626d\u77e9\u6d88\u8017\u3002", "conclusion": "\u8be5\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u8f6e\u817f\u673a\u5668\u4eba\u7684\u6062\u590d\u80fd\u529b\u548c\u80fd\u91cf\u6548\u7387\uff0c\u65e0\u9700\u5e73\u53f0\u7279\u5b9a\u8c03\u6574\u3002"}}
{"id": "2506.05523", "pdf": "https://arxiv.org/pdf/2506.05523", "abs": "https://arxiv.org/abs/2506.05523", "authors": ["Zikui Cai", "Andrew Wang", "Anirudh Satheesh", "Ankit Nakhawa", "Hyunwoo Jae", "Keenan Powell", "Minghui Liu", "Neel Jay", "Sungbin Oh", "Xiyao Wang", "Yongyuan Liang", "Tom Goldstein", "Furong Huang"], "title": "MORSE-500: A Programmatically Controllable Video Benchmark to Stress-Test Multimodal Reasoning", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Despite rapid advances in vision-language models (VLMs), current benchmarks\nfor multimodal reasoning fall short in three key dimensions. First, they\noverwhelmingly rely on static images, failing to capture the temporal\ncomplexity of real-world environments. Second, they narrowly focus on\nmathematical problem-solving, neglecting the broader spectrum of reasoning\nskills -- including abstract, physical, planning, spatial, and temporal\ncapabilities -- required for robust multimodal intelligence. Third, many\nbenchmarks quickly saturate, offering limited headroom for diagnosing failure\nmodes or measuring continued progress. We introduce MORSE-500 (Multimodal\nReasoning Stress-test Environment), a video benchmark composed of 500 fully\nscripted clips with embedded questions spanning six complementary reasoning\ncategories. Each instance is programmatically generated using deterministic\nPython scripts (via Manim, Matplotlib, MoviePy), generative video models, and\ncurated real footage. This script-driven design allows fine-grained control\nover visual complexity, distractor density, and temporal dynamics -- enabling\ndifficulty to be scaled systematically as models improve. Unlike static\nbenchmarks that become obsolete once saturated, MORSE-500 is built to evolve:\nits controllable generation pipeline supports the creation of arbitrarily\nchallenging new instances, making it ideally suited for stress-testing\nnext-generation models. Initial experiments with state-of-the-art systems --\nincluding various Gemini 2.5 Pro and OpenAI o3 which represent the strongest\navailable at the time, alongside strong open-source models -- reveal\nsubstantial performance gaps across all categories, with particularly large\ndeficits in abstract and planning tasks. We release the full dataset,\ngeneration scripts, and evaluation harness to support transparent,\nreproducible, and forward-looking multimodal reasoning research.", "AI": {"tldr": "MORSE-500\u662f\u4e00\u4e2a\u52a8\u6001\u89c6\u9891\u57fa\u51c6\u6d4b\u8bd5\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709\u591a\u6a21\u6001\u63a8\u7406\u57fa\u51c6\u7684\u4e0d\u8db3\uff0c\u8986\u76d6\u516d\u79cd\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u901a\u8fc7\u53ef\u63a7\u751f\u6210\u652f\u6301\u6301\u7eed\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4f9d\u8d56\u9759\u6001\u56fe\u50cf\u3001\u5c40\u9650\u4e8e\u6570\u5b66\u95ee\u9898\u89e3\u51b3\u4e14\u6613\u9971\u548c\uff0c\u65e0\u6cd5\u5168\u9762\u8bc4\u4f30\u591a\u6a21\u6001\u63a8\u7406\u80fd\u529b\u3002", "method": "\u4f7f\u7528Python\u811a\u672c\u3001\u751f\u6210\u89c6\u9891\u6a21\u578b\u548c\u771f\u5b9e\u7d20\u6750\u751f\u6210500\u4e2a\u811a\u672c\u5316\u89c6\u9891\u7247\u6bb5\uff0c\u5d4c\u5165\u516d\u7c7b\u63a8\u7406\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u5f53\u524d\u5148\u8fdb\u6a21\u578b\u5728\u6240\u6709\u63a8\u7406\u7c7b\u522b\u4e2d\u5b58\u5728\u663e\u8457\u6027\u80fd\u5dee\u8ddd\uff0c\u5c24\u5176\u5728\u62bd\u8c61\u548c\u89c4\u5212\u4efb\u52a1\u4e0a\u3002", "conclusion": "MORSE-500\u901a\u8fc7\u53ef\u63a7\u751f\u6210\u652f\u6301\u6301\u7eed\u6311\u6218\uff0c\u4e3a\u591a\u6a21\u6001\u63a8\u7406\u7814\u7a76\u63d0\u4f9b\u900f\u660e\u3001\u53ef\u590d\u73b0\u7684\u5de5\u5177\u3002"}}
{"id": "2506.05529", "pdf": "https://arxiv.org/pdf/2506.05529", "abs": "https://arxiv.org/abs/2506.05529", "authors": ["Rodney Sanchez", "Ferat Sahin", "Alexander Ororbia", "Jamison Heard"], "title": "Avoiding Death through Fear Intrinsic Conditioning", "categories": ["cs.AI", "cs.LG", "I.2.0; I.2.8"], "comment": null, "summary": "Biological and psychological concepts have inspired reinforcement learning\nalgorithms to create new complex behaviors that expand agents' capacity. These\nbehaviors can be seen in the rise of techniques like goal decomposition,\ncurriculum, and intrinsic rewards, which have paved the way for these complex\nbehaviors. One limitation in evaluating these methods is the requirement for\nengineered extrinsic for realistic environments. A central challenge in\nengineering the necessary reward function(s) comes from these environments\ncontaining states that carry high negative rewards, but provide no feedback to\nthe agent. Death is one such stimuli that fails to provide direct feedback to\nthe agent. In this work, we introduce an intrinsic reward function inspired by\nearly amygdala development and produce this intrinsic reward through a novel\nmemory-augmented neural network (MANN) architecture. We show how this intrinsic\nmotivation serves to deter exploration of terminal states and results in\navoidance behavior similar to fear conditioning observed in animals.\nFurthermore, we demonstrate how modifying a threshold where the fear response\nis active produces a range of behaviors that are described under the paradigm\nof general anxiety disorders (GADs). We demonstrate this behavior in the\nMiniworld Sidewalk environment, which provides a partially observable Markov\ndecision process (POMDP) and a sparse reward with a non-descriptive terminal\ncondition, i.e., death. In effect, this study results in a\nbiologically-inspired neural architecture and framework for fear conditioning\nparadigms; we empirically demonstrate avoidance behavior in a constructed agent\nthat is able to solve environments with non-descriptive terminal conditions.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53d7\u65e9\u671f\u674f\u4ec1\u6838\u53d1\u80b2\u542f\u53d1\u7684\u5185\u5728\u5956\u52b1\u51fd\u6570\uff0c\u901a\u8fc7\u65b0\u578b\u8bb0\u5fc6\u589e\u5f3a\u795e\u7ecf\u7f51\u7edc\uff08MANN\uff09\u67b6\u6784\u5b9e\u73b0\uff0c\u7528\u4e8e\u907f\u514d\u7ec8\u7aef\u72b6\u6001\u63a2\u7d22\uff0c\u6a21\u62df\u52a8\u7269\u6050\u60e7\u6761\u4ef6\u53cd\u5c04\u884c\u4e3a\u3002", "motivation": "\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u8bc4\u4f30\u65f6\u9700\u8981\u8bbe\u8ba1\u5916\u5728\u5956\u52b1\u51fd\u6570\uff0c\u4f46\u73af\u5883\u4e2d\u5b58\u5728\u9ad8\u8d1f\u9762\u5956\u52b1\u72b6\u6001\uff08\u5982\u6b7b\u4ea1\uff09\u4e14\u65e0\u6cd5\u63d0\u4f9b\u76f4\u63a5\u53cd\u9988\uff0c\u9650\u5236\u4e86\u65b9\u6cd5\u7684\u5e94\u7528\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u674f\u4ec1\u6838\u53d1\u80b2\u7684\u5185\u5728\u5956\u52b1\u51fd\u6570\uff0c\u901a\u8fc7MANN\u67b6\u6784\u5b9e\u73b0\uff0c\u8c03\u6574\u6050\u60e7\u54cd\u5e94\u9608\u503c\u4ee5\u6a21\u62df\u5e7f\u6cdb\u6027\u7126\u8651\u969c\u788d\uff08GADs\uff09\u884c\u4e3a\u3002", "result": "\u5728Miniworld Sidewalk\u73af\u5883\u4e2d\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u5bf9\u975e\u63cf\u8ff0\u6027\u7ec8\u7aef\u6761\u4ef6\uff08\u5982\u6b7b\u4ea1\uff09\u7684\u907f\u514d\u884c\u4e3a\u3002", "conclusion": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u751f\u7269\u542f\u53d1\u7684\u795e\u7ecf\u67b6\u6784\u548c\u6050\u60e7\u6761\u4ef6\u53cd\u5c04\u6846\u67b6\uff0c\u4e3a\u5904\u7406\u975e\u63cf\u8ff0\u6027\u7ec8\u7aef\u6761\u4ef6\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.05544", "pdf": "https://arxiv.org/pdf/2506.05544", "abs": "https://arxiv.org/abs/2506.05544", "authors": ["Shibo Li", "Yao Zheng"], "title": "Online Conformal Model Selection for Nonstationary Time Series", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "This paper introduces the MPS (Model Prediction Set), a novel framework for\nonline model selection for nonstationary time series. Classical model selection\nmethods, such as information criteria and cross-validation, rely heavily on the\nstationarity assumption and often fail in dynamic environments which undergo\ngradual or abrupt changes over time. Yet real-world data are rarely stationary,\nand model selection under nonstationarity remains a largely open problem. To\ntackle this challenge, we combine conformal inference with model confidence\nsets to develop a procedure that adaptively selects models best suited to the\nevolving dynamics at any given time. Concretely, the MPS updates in real time a\nconfidence set of candidate models that covers the best model for the next time\nperiod with a specified long-run probability, while adapting to nonstationarity\nof unknown forms. Through simulations and real-world data analysis, we\ndemonstrate that MPS reliably and efficiently identifies optimal models under\nnonstationarity, an essential capability lacking in offline methods. Moreover,\nMPS frequently produces high-quality sets with small cardinality, whose\nevolution offers deeper insights into changing dynamics. As a generic\nframework, MPS accommodates any data-generating process, data structure, model\nclass, training method, and evaluation metric, making it broadly applicable\nacross diverse problem settings.", "AI": {"tldr": "MPS\uff08\u6a21\u578b\u9884\u6d4b\u96c6\uff09\u662f\u4e00\u79cd\u7528\u4e8e\u975e\u5e73\u7a33\u65f6\u95f4\u5e8f\u5217\u5728\u7ebf\u6a21\u578b\u9009\u62e9\u7684\u65b0\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u5171\u5f62\u63a8\u65ad\u548c\u6a21\u578b\u7f6e\u4fe1\u96c6\uff0c\u80fd\u81ea\u9002\u5e94\u9009\u62e9\u6700\u4f73\u6a21\u578b\u3002", "motivation": "\u89e3\u51b3\u975e\u5e73\u7a33\u73af\u5883\u4e0b\u4f20\u7edf\u6a21\u578b\u9009\u62e9\u65b9\u6cd5\uff08\u5982\u4fe1\u606f\u51c6\u5219\u548c\u4ea4\u53c9\u9a8c\u8bc1\uff09\u56e0\u4f9d\u8d56\u5e73\u7a33\u5047\u8bbe\u800c\u5931\u6548\u7684\u95ee\u9898\u3002", "method": "\u7ed3\u5408\u5171\u5f62\u63a8\u65ad\u4e0e\u6a21\u578b\u7f6e\u4fe1\u96c6\uff0c\u5b9e\u65f6\u66f4\u65b0\u5019\u9009\u6a21\u578b\u7684\u7f6e\u4fe1\u96c6\uff0c\u8986\u76d6\u4e0b\u4e00\u65f6\u95f4\u5468\u671f\u7684\u6700\u4f73\u6a21\u578b\u3002", "result": "MPS\u5728\u975e\u5e73\u7a33\u73af\u5883\u4e0b\u53ef\u9760\u4e14\u9ad8\u6548\u5730\u8bc6\u522b\u6700\u4f18\u6a21\u578b\uff0c\u5e76\u80fd\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u5c0f\u89c4\u6a21\u96c6\u5408\u3002", "conclusion": "MPS\u662f\u4e00\u79cd\u901a\u7528\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u6570\u636e\u751f\u6210\u8fc7\u7a0b\u3001\u6a21\u578b\u7c7b\u522b\u548c\u8bc4\u4f30\u6307\u6807\uff0c\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\u3002"}}
{"id": "2506.05556", "pdf": "https://arxiv.org/pdf/2506.05556", "abs": "https://arxiv.org/abs/2506.05556", "authors": ["Stefano Fiscale", "Laura Inno", "Alessandra Rotundi", "Angelo Ciaramella", "Alessio Ferone", "Christian Magliano", "Luca Cacciapuoti", "Veselin Kostov", "Elisa Quintana", "Giovanni Covone", "Maria Teresa Muscari Tomajoli", "Vito Saggese", "Luca Tonietti", "Antonio Vanzanella", "Vincenzo Della Corte"], "title": "DART-Vetter: A Deep LeARning Tool for automatic triage of exoplanet candidates", "categories": ["astro-ph.EP", "astro-ph.IM", "cs.LG"], "comment": "Number of pages: 24, Number of figures: 8, Article accepted for\n  publication in The Astronomical Journal on 2025-05-30", "summary": "In the identification of new planetary candidates in transit surveys, the\nemployment of Deep Learning models proved to be essential to efficiently\nanalyse a continuously growing volume of photometric observations. To further\nimprove the robustness of these models, it is necessary to exploit the\ncomplementarity of data collected from different transit surveys such as NASA's\nKepler, Transiting Exoplanet Survey Satellite (TESS), and, in the near future,\nthe ESA PLAnetary Transits and Oscillation of stars (PLATO) mission. In this\nwork, we present a Deep Learning model, named DART-Vetter, able to distinguish\nplanetary candidates (PC) from false positives signals (NPC) detected by any\npotential transiting survey. DART-Vetter is a Convolutional Neural Network that\nprocesses only the light curves folded on the period of the relative signal,\nfeaturing a simpler and more compact architecture with respect to other\ntriaging and/or vetting models available in the literature. We trained and\ntested DART-Vetter on several dataset of publicly available and homogeneously\nlabelled TESS and Kepler light curves in order to prove the effectiveness of\nour model. Despite its simplicity, DART-Vetter achieves highly competitive\ntriaging performance, with a recall rate of 91% on an ensemble of TESS and\nKepler data, when compared to Exominer and Astronet-Triage. Its compact, open\nsource and easy to replicate architecture makes DART-Vetter a particularly\nuseful tool for automatizing triaging procedures or assisting human vetters,\nshowing a discrete generalization on TCEs with Multiple Event Statistic (MES) >\n20 and orbital period < 50 days.", "AI": {"tldr": "DART-Vetter\u662f\u4e00\u79cd\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u7528\u4e8e\u533a\u5206\u884c\u661f\u5019\u9009\u4fe1\u53f7\u548c\u5047\u9633\u6027\u4fe1\u53f7\uff0c\u5177\u6709\u7b80\u5355\u7d27\u51d1\u7684\u67b6\u6784\uff0c\u5728TESS\u548cKepler\u6570\u636e\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u63d0\u9ad8\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u884c\u661f\u5019\u9009\u8bc6\u522b\u4e2d\u7684\u9c81\u68d2\u6027\uff0c\u5229\u7528\u4e0d\u540c\u5de1\u5929\u6570\u636e\u7684\u4e92\u8865\u6027\u3002", "method": "\u4f7f\u7528\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5904\u7406\u6298\u53e0\u5149\u53d8\u66f2\u7ebf\uff0c\u7b80\u5316\u67b6\u6784\uff0c\u5e76\u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u548c\u6d4b\u8bd5\u3002", "result": "\u5728TESS\u548cKepler\u6570\u636e\u4e0a\u53ec\u56de\u7387\u8fbe91%\uff0c\u6027\u80fd\u4f18\u4e8eExominer\u548cAstronet-Triage\u3002", "conclusion": "DART-Vetter\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u6613\u4e8e\u590d\u5236\u7684\u5de5\u5177\uff0c\u9002\u7528\u4e8e\u81ea\u52a8\u5316\u7b5b\u9009\u6216\u8f85\u52a9\u4eba\u5de5\u9a8c\u8bc1\u3002"}}
{"id": "2506.05565", "pdf": "https://arxiv.org/pdf/2506.05565", "abs": "https://arxiv.org/abs/2506.05565", "authors": ["Feliks Ba\u0144ka", "Jaros\u0142aw A. Chudziak"], "title": "Applying Informer for Option Pricing: A Transformer-Based Approach", "categories": ["cs.CE", "cs.AI", "cs.LG", "q-fin.CP", "91G60, 68T07", "I.2.6; J.4"], "comment": "8 pages, 3 tables, 7 figures. Accepted at the 17th International\n  Conference on Agents and Artificial Intelligence (ICAART 2025). Final version\n  published in Proceedings of ICAART 2025 (Vol. 3), pages 1270-1277", "summary": "Accurate option pricing is essential for effective trading and risk\nmanagement in financial markets, yet it remains challenging due to market\nvolatility and the limitations of traditional models like Black-Scholes. In\nthis paper, we investigate the application of the Informer neural network for\noption pricing, leveraging its ability to capture long-term dependencies and\ndynamically adjust to market fluctuations. This research contributes to the\nfield of financial forecasting by introducing Informer's efficient architecture\nto enhance prediction accuracy and provide a more adaptable and resilient\nframework compared to existing methods. Our results demonstrate that Informer\noutperforms traditional approaches in option pricing, advancing the\ncapabilities of data-driven financial forecasting in this domain.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u4f7f\u7528Informer\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u671f\u6743\u5b9a\u4ef7\uff0c\u76f8\u6bd4\u4f20\u7edf\u6a21\u578b\uff08\u5982Black-Scholes\uff09\uff0c\u5176\u80fd\u66f4\u597d\u5730\u6355\u6349\u957f\u671f\u4f9d\u8d56\u5173\u7cfb\u5e76\u9002\u5e94\u5e02\u573a\u6ce2\u52a8\uff0c\u4ece\u800c\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u7531\u4e8e\u5e02\u573a\u6ce2\u52a8\u548c\u4f20\u7edf\u6a21\u578b\uff08\u5982Black-Scholes\uff09\u7684\u5c40\u9650\u6027\uff0c\u51c6\u786e\u7684\u671f\u6743\u5b9a\u4ef7\u5bf9\u4ea4\u6613\u548c\u98ce\u9669\u7ba1\u7406\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5e94\u7528Informer\u795e\u7ecf\u7f51\u7edc\uff0c\u5229\u7528\u5176\u6355\u6349\u957f\u671f\u4f9d\u8d56\u5173\u7cfb\u548c\u52a8\u6001\u9002\u5e94\u5e02\u573a\u6ce2\u52a8\u7684\u80fd\u529b\u3002", "result": "Informer\u5728\u671f\u6743\u5b9a\u4ef7\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u3002", "conclusion": "Informer\u4e3a\u6570\u636e\u9a71\u52a8\u7684\u91d1\u878d\u9884\u6d4b\u63d0\u4f9b\u4e86\u66f4\u9002\u5e94\u6027\u5f3a\u4e14\u7a33\u5065\u7684\u6846\u67b6\uff0c\u63a8\u52a8\u4e86\u8be5\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.05567", "pdf": "https://arxiv.org/pdf/2506.05567", "abs": "https://arxiv.org/abs/2506.05567", "authors": ["Fuat Can Beylunioglu", "Mehrdad Pirnia", "P. Robert Duimering"], "title": "Partially-Supervised Neural Network Model For Quadratic Multiparametric Programming", "categories": ["math.OC", "cs.LG", "14J60 (Primary) 14F05, 14J26 (Secondary)"], "comment": "36 pages including references and appendix", "summary": "Neural Networks (NN) with ReLU activation functions are used to model\nmultiparametric quadratic optimization problems (mp-QP) in diverse engineering\napplications. Researchers have suggested leveraging the piecewise affine\nproperty of deep NN models to solve mp-QP with linear constraints, which also\nexhibit piecewise affine behaviour. However, traditional deep NN applications\nto mp-QP fall short of providing optimal and feasible predictions, even when\ntrained on large datasets. This study proposes a partially-supervised NN (PSNN)\narchitecture that directly represents the mathematical structure of the global\nsolution function. In contrast to generic NN training approaches, the proposed\nPSNN method derives a large proportion of model weights directly from the\nmathematical properties of the optimization problem, producing more accurate\nsolutions despite significantly smaller training data sets. Many energy\nmanagement problems are formulated as QP, so we apply the proposed approach to\nenergy systems (specifically DC optimal power flow) to demonstrate proof of\nconcept. Model performance in terms of solution accuracy and speed of\npredictions was compared against a commercial solver and a generic Deep NN\nmodel based on classical training. Results show KKT sufficient conditions for\nPSNN consistently outperform generic NN architectures with classical training\nusing far less data, including when tested on extreme, out-of-training\ndistribution test data. Given its speed advantages over traditional solvers,\nthe PSNN model can quickly produce optimal and feasible solutions within a\nsecond for millions of input parameters sampled from a distribution of\nstochastic demands and renewable generator dispatches, which can be used for\nsimulations and long term planning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u90e8\u5206\u76d1\u7763\u795e\u7ecf\u7f51\u7edc\uff08PSNN\uff09\u67b6\u6784\uff0c\u76f4\u63a5\u8868\u793a\u5168\u5c40\u89e3\u51fd\u6570\u7684\u6570\u5b66\u7ed3\u6784\uff0c\u76f8\u6bd4\u4f20\u7edf\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff08NN\uff09\u5728\u89e3\u51b3\u591a\u53c2\u6570\u4e8c\u6b21\u4f18\u5316\u95ee\u9898\uff08mp-QP\uff09\u65f6\u66f4\u51c6\u786e\u4e14\u9700\u8981\u66f4\u5c11\u8bad\u7ec3\u6570\u636e\u3002", "motivation": "\u4f20\u7edf\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5728\u89e3\u51b3mp-QP\u95ee\u9898\u65f6\u65e0\u6cd5\u63d0\u4f9b\u6700\u4f18\u4e14\u53ef\u884c\u7684\u9884\u6d4b\uff0c\u5373\u4f7f\u5728\u5927\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u3002", "method": "PSNN\u76f4\u63a5\u4ece\u4f18\u5316\u95ee\u9898\u7684\u6570\u5b66\u6027\u8d28\u4e2d\u63a8\u5bfc\u5927\u90e8\u5206\u6a21\u578b\u6743\u91cd\uff0c\u800c\u975e\u4f9d\u8d56\u4f20\u7edf\u8bad\u7ec3\u65b9\u6cd5\u3002", "result": "PSNN\u5728\u89e3\u7cbe\u5ea6\u548c\u9884\u6d4b\u901f\u5ea6\u4e0a\u4f18\u4e8e\u5546\u4e1a\u6c42\u89e3\u5668\u548c\u4f20\u7edf\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff0c\u4e14\u6240\u9700\u8bad\u7ec3\u6570\u636e\u66f4\u5c11\u3002", "conclusion": "PSNN\u5728\u80fd\u6e90\u7ba1\u7406\uff08\u5982\u76f4\u6d41\u6700\u4f18\u6f6e\u6d41\uff09\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u5feb\u901f\u751f\u6210\u6700\u4f18\u89e3\uff0c\u9002\u7528\u4e8e\u4eff\u771f\u548c\u957f\u671f\u89c4\u5212\u3002"}}
{"id": "2506.05587", "pdf": "https://arxiv.org/pdf/2506.05587", "abs": "https://arxiv.org/abs/2506.05587", "authors": ["Junjie Xing", "Yeye He", "Mengyu Zhou", "Haoyu Dong", "Shi Han", "Lingjiao Chen", "Dongmei Zhang", "Surajit Chaudhuri", "H. V. Jagadish"], "title": "MMTU: A Massive Multi-Task Table Understanding and Reasoning Benchmark", "categories": ["cs.AI", "cs.CL", "cs.DB", "cs.LG"], "comment": null, "summary": "Tables and table-based use cases play a crucial role in many important\nreal-world applications, such as spreadsheets, databases, and computational\nnotebooks, which traditionally require expert-level users like data engineers,\ndata analysts, and database administrators to operate. Although LLMs have shown\nremarkable progress in working with tables (e.g., in spreadsheet and database\ncopilot scenarios), comprehensive benchmarking of such capabilities remains\nlimited. In contrast to an extensive and growing list of NLP benchmarks,\nevaluations of table-related tasks are scarce, and narrowly focus on tasks like\nNL-to-SQL and Table-QA, overlooking the broader spectrum of real-world tasks\nthat professional users face. This gap limits our understanding and model\nprogress in this important area.\n  In this work, we introduce MMTU, a large-scale benchmark with over 30K\nquestions across 25 real-world table tasks, designed to comprehensively\nevaluate models ability to understand, reason, and manipulate real tables at\nthe expert-level. These tasks are drawn from decades' worth of computer science\nresearch on tabular data, with a focus on complex table tasks faced by\nprofessional users. We show that MMTU require a combination of skills --\nincluding table understanding, reasoning, and coding -- that remain challenging\nfor today's frontier models, where even frontier reasoning models like OpenAI\no4-mini and DeepSeek R1 score only around 60%, suggesting significant room for\nimprovement. We highlight key findings in our evaluation using MMTU and hope\nthat this benchmark drives further advances in understanding and developing\nfoundation models for structured data processing and analysis. Our code and\ndata are available at https://github.com/MMTU-Benchmark/MMTU and\nhttps://huggingface.co/datasets/MMTU-benchmark/MMTU.", "AI": {"tldr": "MMTU\u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b30K\u95ee\u9898\u548c25\u4e2a\u771f\u5b9e\u8868\u683c\u4efb\u52a1\uff0c\u65e8\u5728\u5168\u9762\u8bc4\u4f30\u6a21\u578b\u5728\u4e13\u5bb6\u7ea7\u8868\u683c\u5904\u7406\u4e2d\u7684\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u5bf9\u8868\u683c\u76f8\u5173\u4efb\u52a1\u7684\u8bc4\u4f30\u6709\u9650\uff0c\u4e3b\u8981\u96c6\u4e2d\u5728NL-to-SQL\u548cTable-QA\uff0c\u5ffd\u7565\u4e86\u4e13\u4e1a\u7528\u6237\u9762\u4e34\u7684\u66f4\u5e7f\u6cdb\u4efb\u52a1\uff0c\u9650\u5236\u4e86\u6a21\u578b\u5728\u8fd9\u4e00\u9886\u57df\u7684\u53d1\u5c55\u3002", "method": "MMTU\u4ece\u6570\u5341\u5e74\u7684\u8ba1\u7b97\u673a\u79d1\u5b66\u7814\u7a76\u4e2d\u63d0\u53d6\u590d\u6742\u8868\u683c\u4efb\u52a1\uff0c\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5305\u542b30K\u95ee\u9898\u548c25\u79cd\u4efb\u52a1\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u524d\u6cbf\u6a21\u578b\uff08\u5982OpenAI o4-mini\u548cDeepSeek R1\uff09\u5728MMTU\u4e0a\u7684\u5f97\u5206\u4ec5\u7ea660%\uff0c\u8868\u660e\u4ecd\u6709\u663e\u8457\u6539\u8fdb\u7a7a\u95f4\u3002", "conclusion": "MMTU\u4e3a\u7ed3\u6784\u5316\u6570\u636e\u5904\u7406\u548c\u5206\u6790\u7684\u57fa\u7840\u6a21\u578b\u53d1\u5c55\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u51c6\uff0c\u63a8\u52a8\u4e86\u8be5\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2506.05590", "pdf": "https://arxiv.org/pdf/2506.05590", "abs": "https://arxiv.org/abs/2506.05590", "authors": ["Stella Huang", "Qing Zhou"], "title": "Nonlinear Causal Discovery through a Sequential Edge Orientation Approach", "categories": ["stat.ML", "cs.LG"], "comment": "42 Pages, 13 figures, 3 tables", "summary": "Recent advances have established the identifiability of a directed acyclic\ngraph (DAG) under additive noise models (ANMs), spurring the development of\nvarious causal discovery methods. However, most existing methods make\nrestrictive model assumptions, rely heavily on general independence tests, or\nrequire substantial computational time. To address these limitations, we\npropose a sequential procedure to orient undirected edges in a completed\npartial DAG (CPDAG), representing an equivalence class of DAGs, by leveraging\nthe pairwise additive noise model (PANM) to identify their causal directions.\nWe prove that this procedure can recover the true causal DAG assuming a\nrestricted ANM. Building on this result, we develop a novel constraint-based\nalgorithm for learning causal DAGs under nonlinear ANMs. Given an estimated\nCPDAG, we develop a ranking procedure that sorts undirected edges by their\nadherence to the PANM, which defines an evaluation order of the edges. To\ndetermine the edge direction, we devise a statistical test that compares the\nlog-likelihood values, evaluated with respect to the competing directions, of a\nsub-graph comprising just the candidate nodes and their identified parents in\nthe partial DAG. We further establish the structural learning consistency of\nour algorithm in the large-sample limit. Extensive experiments on synthetic and\nreal-world datasets demonstrate that our method is computationally efficient,\nrobust to model misspecification, and consistently outperforms many existing\nnonlinear DAG learning methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6210\u5bf9\u52a0\u6027\u566a\u58f0\u6a21\u578b\uff08PANM\uff09\u7684\u987a\u5e8f\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u90e8\u5206\u6709\u5411\u65e0\u73af\u56fe\uff08CPDAG\uff09\u4e2d\u5b9a\u5411\u8fb9\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\u5b58\u5728\u6a21\u578b\u5047\u8bbe\u4e25\u683c\u3001\u4f9d\u8d56\u72ec\u7acb\u6027\u68c0\u9a8c\u6216\u8ba1\u7b97\u91cf\u5927\u7b49\u95ee\u9898\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u3001\u7a33\u5065\u7684\u65b9\u6cd5\u3002", "method": "\u5229\u7528PANM\u5b9a\u5411CPDAG\u4e2d\u7684\u8fb9\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u7ea6\u675f\u7684\u7b97\u6cd5\uff0c\u5e76\u901a\u8fc7\u7edf\u8ba1\u6d4b\u8bd5\u786e\u5b9a\u8fb9\u65b9\u5411\u3002", "result": "\u7b97\u6cd5\u5728\u5927\u6837\u672c\u6781\u9650\u4e0b\u5177\u6709\u7ed3\u6784\u5b66\u4e60\u4e00\u81f4\u6027\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u8ba1\u7b97\u9ad8\u6548\u4e14\u4f18\u4e8e\u73b0\u6709\u975e\u7ebf\u6027DAG\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u8ba1\u7b97\u6548\u7387\u548c\u9c81\u68d2\u6027\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4e3a\u975e\u7ebf\u6027DAG\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.05619", "pdf": "https://arxiv.org/pdf/2506.05619", "abs": "https://arxiv.org/abs/2506.05619", "authors": ["Kihyun Kim", "Jiawei Zhang", "Asuman Ozdaglar", "Pablo A. Parrilo"], "title": "Population-Proportional Preference Learning from Human Feedback: An Axiomatic Approach", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Conventional preference learning methods often prioritize opinions held more\nwidely when aggregating preferences from multiple evaluators. This may result\nin policies that are biased in favor of some types of opinions or groups. The\nobjective of this paper is to develop a novel preference learning framework\ncapable of aligning aggregate opinions and policies proportionally with the\ntrue population distribution of evaluator preferences. Our approach infers the\nfeasible set of evaluator population distributions directly from pairwise\ncomparison data. Using these estimates, the algorithm constructs a policy that\nsatisfies foundational axioms from social choice theory, namely monotonicity\nand Pareto efficiency, as well as our newly-introduced axioms of\npopulation-proportional representation and population-bounded robustness. We\npropose a soft-max relaxation method that smoothly trade-offs\npopulation-proportional representation with the selection of the Condorcet\nwinner (which beats all other options in pairwise comparisons). Finally, we\nvalidate the effectiveness and scalability of our approach through experiments\non both tabular recommendation tasks and large-scale language model alignment.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u504f\u597d\u5b66\u4e60\u6846\u67b6\uff0c\u65e8\u5728\u901a\u8fc7\u6bd4\u4f8b\u5bf9\u9f50\u7fa4\u4f53\u610f\u89c1\u548c\u653f\u7b56\uff0c\u907f\u514d\u4f20\u7edf\u65b9\u6cd5\u4e2d\u7684\u504f\u89c1\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u504f\u597d\u5b66\u4e60\u65b9\u6cd5\u53ef\u80fd\u504f\u5411\u5e7f\u6cdb\u6301\u6709\u7684\u610f\u89c1\uff0c\u5bfc\u81f4\u653f\u7b56\u5bf9\u67d0\u4e9b\u7fa4\u4f53\u4e0d\u516c\u5e73\u3002\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u6bd4\u4f8b\u5bf9\u9f50\u7fa4\u4f53\u504f\u597d\u548c\u653f\u7b56\u7684\u65b0\u6846\u67b6\u3002", "method": "\u901a\u8fc7\u6210\u5bf9\u6bd4\u8f83\u6570\u636e\u63a8\u65ad\u8bc4\u4f30\u8005\u7fa4\u4f53\u5206\u5e03\uff0c\u6784\u5efa\u6ee1\u8db3\u793e\u4f1a\u9009\u62e9\u7406\u8bba\u516c\u7406\uff08\u5982\u5355\u8c03\u6027\u548c\u5e15\u7d2f\u6258\u6548\u7387\uff09\u7684\u653f\u7b56\uff0c\u5e76\u5f15\u5165\u65b0\u516c\u7406\uff08\u6bd4\u4f8b\u4ee3\u8868\u548c\u7fa4\u4f53\u7a33\u5065\u6027\uff09\u3002\u63d0\u51fa\u8f6f\u6700\u5927\u677e\u5f1b\u65b9\u6cd5\uff0c\u5e73\u8861\u6bd4\u4f8b\u4ee3\u8868\u548cCondorcet\u80dc\u8005\u9009\u62e9\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u9002\u7528\u4e8e\u8868\u683c\u63a8\u8350\u4efb\u52a1\u548c\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u3002", "conclusion": "\u65b0\u6846\u67b6\u80fd\u591f\u66f4\u516c\u5e73\u5730\u53cd\u6620\u7fa4\u4f53\u504f\u597d\uff0c\u540c\u65f6\u6ee1\u8db3\u5173\u952e\u516c\u7406\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2506.05625", "pdf": "https://arxiv.org/pdf/2506.05625", "abs": "https://arxiv.org/abs/2506.05625", "authors": ["Anushka Tiwari", "Haimonti Dutta", "Shahrzad Khanizadeh"], "title": "Heterogeneous Sequel-Aware Graph Neural Networks for Sequential Learning", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "Graph-based recommendation systems use higher-order user and item embeddings\nfor next-item predictions. Dynamically adding collaborative signals from\nneighbors helps to use similar users' preferences during learning. While\nitem-item correlations and their impact on recommendations have been studied,\nthe efficacy of temporal item sequences for recommendations is much less\nexplored. In this paper, we examine temporal item sequence (sequel-aware)\nembeddings along with higher-order user embeddings and show that sequel-aware\nGraph Neural Networks have better (or comparable) recommendation performance\nthan graph-based recommendation systems that do not consider sequel\ninformation. Extensive empirical results comparing Heterogeneous Sequel-aware\nGraph Neural Networks (HSAL-GNNs) to other algorithms for sequential learning\n(such as transformers, graph neural networks, auto-encoders) are presented on\nthree synthetic and three real-world datasets. Our results indicate that the\nincorporation of sequence information from items greatly enhances\nrecommendations.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u65f6\u5e8f\u7269\u54c1\u5e8f\u5217\uff08sequel-aware\uff09\u5d4c\u5165\u4e0e\u9ad8\u9636\u7528\u6237\u5d4c\u5165\u7684\u7ed3\u5408\uff0c\u8bc1\u660e\u5176\u63a8\u8350\u6027\u80fd\u4f18\u4e8e\u6216\u7b49\u540c\u4e8e\u4e0d\u8003\u8651\u65f6\u5e8f\u4fe1\u606f\u7684\u56fe\u63a8\u8350\u7cfb\u7edf\u3002", "motivation": "\u63a2\u7d22\u65f6\u5e8f\u7269\u54c1\u5e8f\u5217\u5bf9\u63a8\u8350\u7cfb\u7edf\u7684\u5f71\u54cd\uff0c\u586b\u8865\u4e86\u73b0\u6709\u7814\u7a76\u4e2d\u65f6\u5e8f\u4fe1\u606f\u5229\u7528\u4e0d\u8db3\u7684\u7a7a\u767d\u3002", "method": "\u63d0\u51faHeterogeneous Sequel-aware Graph Neural Networks (HSAL-GNNs)\uff0c\u7ed3\u5408\u65f6\u5e8f\u7269\u54c1\u5e8f\u5217\u548c\u9ad8\u9636\u7528\u6237\u5d4c\u5165\uff0c\u4e0e\u5176\u4ed6\u5e8f\u5217\u5b66\u4e60\u7b97\u6cd5\uff08\u5982Transformer\u3001\u56fe\u795e\u7ecf\u7f51\u7edc\u3001\u81ea\u7f16\u7801\u5668\uff09\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u5728\u4e09\u4e2a\u5408\u6210\u548c\u4e09\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5f15\u5165\u7269\u54c1\u5e8f\u5217\u4fe1\u606f\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u6027\u80fd\u3002", "conclusion": "\u65f6\u5e8f\u7269\u54c1\u5e8f\u5217\u4fe1\u606f\u5bf9\u63a8\u8350\u7cfb\u7edf\u6709\u91cd\u8981\u4ef7\u503c\uff0cHSAL-GNNs\u5728\u63a8\u8350\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2506.05631", "pdf": "https://arxiv.org/pdf/2506.05631", "abs": "https://arxiv.org/abs/2506.05631", "authors": ["Veselin B. Kostov", "Brian P. Powell", "Aline U. Fornear", "Marco Z. Di Fraia", "Robert Gagliano", "Thomas L. Jacobs", "Julien S. de Lambilly", "Hugo A. Durantini Luca", "Steven R. Majewski", "Mark Omohundro", "Jerome Orosz", "Saul A. Rappaport", "Ryan Salik", "Donald Short", "William Welsh", "Svetoslav Alexandrov", "Cledison Marcos da Silva", "Erika Dunning", "Gerd Guhne", "Marc Huten", "Michiharu Hyogo", "Davide Iannone", "Sam Lee", "Christian Magliano", "Manya Sharma", "Allan Tarr", "John Yablonsky", "Sovan Acharya", "Fred Adams", "Thomas Barclay", "Benjamin T. Montet", "Susan Mullally", "Greg Olmschenk", "Andrej Prsa", "Elisa Quintana", "Robert Wilson", "Hasret Balcioglu", "Ethan Kruse", "the Eclipsing Binary Patrol Collaboration"], "title": "The TESS Ten Thousand Catalog: 10,001 uniformly-vetted and -validated Eclipsing Binary Stars detected in Full-Frame Image data by machine learning and analyzed by citizen scientists", "categories": ["astro-ph.SR", "astro-ph.EP", "astro-ph.IM", "cs.LG"], "comment": "40 pages, 39 figures, 4 tables", "summary": "The Transiting Exoplanet Survey Satellite (TESS) has surveyed nearly the\nentire sky in Full-Frame Image mode with a time resolution of 200 seconds to 30\nminutes and a temporal baseline of at least 27 days. In addition to the primary\ngoal of discovering new exoplanets, TESS is exceptionally capable at detecting\nvariable stars, and in particular short-period eclipsing binaries which are\nrelatively common, making up a few percent of all stars, and represent powerful\nastrophysical laboratories for deep investigations of stellar formation and\nevolution. We combed Sectors 1-82 of TESS Full-Frame Image data searching for\neclipsing binary stars using a neural network that identified ~1.2 million\nstars with eclipse-like features. Of these, we have performed an in-depth\nanalysis on ~60,000 targets using automated methods and manual inspection by\ncitizen scientists. Here we present a catalog of 10001 uniformly-vetted and\n-validated eclipsing binary stars that passed all our ephemeris and photocenter\ntests, as well as complementary visual inspection. Of these, 7936 are new\neclipsing binaries while the remaining 2065 are known systems for which we\nupdate the published ephemerides. We outline the detection and analysis of the\ntargets, discuss the properties of the sample, and highlight potentially\ninteresting systems. Finally, we also provide a list of ~900,000 unvetted and\nunvalidated targets for which the neural network found eclipse-like features\nwith a score higher than 0.9, and for which there are no known eclipsing\nbinaries within a sky-projected separation of a TESS pixel (~21 arcsec).", "AI": {"tldr": "TESS\u536b\u661f\u901a\u8fc7\u5168\u5e27\u56fe\u50cf\u6a21\u5f0f\u89c2\u6d4b\u4e86\u51e0\u4e4e\u6574\u4e2a\u5929\u7a7a\uff0c\u53d1\u73b0\u5e76\u9a8c\u8bc1\u4e8610001\u4e2a\u98df\u53cc\u661f\u7cfb\u7edf\uff0c\u5176\u4e2d7936\u4e2a\u4e3a\u65b0\u53d1\u73b0\uff0c2065\u4e2a\u4e3a\u5df2\u77e5\u7cfb\u7edf\u7684\u66f4\u65b0\u3002", "motivation": "\u7814\u7a76\u98df\u53cc\u661f\u7cfb\u7edf\uff0c\u4e3a\u6052\u661f\u5f62\u6210\u548c\u6f14\u5316\u63d0\u4f9b\u5b9e\u9a8c\u5ba4\u3002", "method": "\u5229\u7528\u795e\u7ecf\u7f51\u7edc\u5206\u6790TESS\u5168\u5e27\u56fe\u50cf\u6570\u636e\uff0c\u7ed3\u5408\u81ea\u52a8\u5316\u65b9\u6cd5\u548c\u516c\u6c11\u79d1\u5b66\u5bb6\u7684\u624b\u52a8\u68c0\u67e5\u3002", "result": "\u53d1\u73b0\u5e76\u9a8c\u8bc1\u4e8610001\u4e2a\u98df\u53cc\u661f\u7cfb\u7edf\uff0c\u63d0\u4f9b\u4e86\u7ea690\u4e07\u4e2a\u672a\u9a8c\u8bc1\u76ee\u6807\u3002", "conclusion": "TESS\u6570\u636e\u4e3a\u98df\u53cc\u661f\u7814\u7a76\u63d0\u4f9b\u4e86\u4e30\u5bcc\u8d44\u6e90\uff0c\u672a\u6765\u53ef\u8fdb\u4e00\u6b65\u63a2\u7d22\u6f5c\u5728\u6709\u8da3\u7cfb\u7edf\u3002"}}
{"id": "2506.05639", "pdf": "https://arxiv.org/pdf/2506.05639", "abs": "https://arxiv.org/abs/2506.05639", "authors": ["John Kirchenbauer", "Janny Mongkolsupawan", "Yuxin Wen", "Tom Goldstein", "Daphne Ippolito"], "title": "A Fictional Q&A Dataset for Studying Memorization and Knowledge Acquisition", "categories": ["cs.CL", "cs.LG"], "comment": "10 pages and 8 figures in the main body", "summary": "When language models are trained on textual data, they acquire both knowledge\nabout the structure of language as well as knowledge of facts about the world.\nAt inference time, their knowledge of facts can be leveraged to solve\ninteresting problems and perform useful knowledge work for users. It is well\nknown that language models can verbatim memorize long sequences from their\ntraining data. However, it is much less well understood how language models\nmemorize facts seen during training. In this work, we propose a new dataset to\nspecifically empower researchers to study the dual processes of fact\nmemorization and verbatim sequence memorization. The dataset consists of\nsynthetically-generated, webtext-like documents about fictional events, as well\nas question-answer pairs about the events. We conduct training experiments\nshowing how synthetic data about fictional events can be effective in teasing\napart different forms of memorization. We also document the challenges in\neffectively building realistic, fictional synthetic data.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e00\u4e2a\u65b0\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u7814\u7a76\u8bed\u8a00\u6a21\u578b\u5bf9\u4e8b\u5b9e\u8bb0\u5fc6\u548c\u9010\u5b57\u5e8f\u5217\u8bb0\u5fc6\u7684\u53cc\u91cd\u8fc7\u7a0b\uff0c\u901a\u8fc7\u5408\u6210\u6570\u636e\u5b9e\u9a8c\u63ed\u793a\u8bb0\u5fc6\u5f62\u5f0f\u5dee\u5f02\u3002", "motivation": "\u7406\u89e3\u8bed\u8a00\u6a21\u578b\u5982\u4f55\u8bb0\u5fc6\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u4e8b\u5b9e\u548c\u9010\u5b57\u5e8f\u5217\uff0c\u586b\u8865\u73b0\u6709\u7814\u7a76\u7684\u7a7a\u767d\u3002", "method": "\u6784\u5efa\u5408\u6210\u6570\u636e\u96c6\uff0c\u5305\u542b\u865a\u6784\u4e8b\u4ef6\u7684\u7c7b\u7f51\u7edc\u6587\u672c\u53ca\u95ee\u7b54\u5bf9\uff0c\u901a\u8fc7\u8bad\u7ec3\u5b9e\u9a8c\u5206\u6790\u8bb0\u5fc6\u5f62\u5f0f\u3002", "result": "\u5408\u6210\u6570\u636e\u80fd\u6709\u6548\u533a\u5206\u4e0d\u540c\u8bb0\u5fc6\u5f62\u5f0f\uff0c\u4f46\u6784\u5efa\u903c\u771f\u865a\u6784\u6570\u636e\u5b58\u5728\u6311\u6218\u3002", "conclusion": "\u5408\u6210\u6570\u636e\u4e3a\u7814\u7a76\u8bed\u8a00\u6a21\u578b\u8bb0\u5fc6\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\uff0c\u4f46\u9700\u8fdb\u4e00\u6b65\u4f18\u5316\u6570\u636e\u771f\u5b9e\u6027\u3002"}}
{"id": "2506.05657", "pdf": "https://arxiv.org/pdf/2506.05657", "abs": "https://arxiv.org/abs/2506.05657", "authors": ["Anarya Ray"], "title": "Emulating compact binary population synthesis simulations with robust uncertainty quantification and model comparison: Bayesian normalizing flows", "categories": ["astro-ph.HE", "cs.LG", "gr-qc"], "comment": "16 pages, 4 figures", "summary": "Population synthesis simulations of compact binary coalescences~(CBCs) play a\ncrucial role in extracting astrophysical insights from an ensemble of\ngravitational wave~(GW) observations. However, realistic simulations are costly\nto implement for a dense grid of initial conditions. Normalizing flows can\nemulate the distribution functions of a simulated population of binary\nparameters and thereby enable empirical constraints on the astrophysical\ninitial conditions and branching fractions of various formation channels given\ndata from a catalog of GW observations. They can also be used for data\namplification in sparse regions of the CBC parameter space to guide the\ndevelopment of phenomenological population models for rarely synthesizable\nsystems with components in theorized mass gaps, without having to simulate a\nprohibitively large number of binaries. But flow predictions are wrought with\nuncertainties, especially for sparse training sets. In this work I develop a\nmethod for quantifying and marginalizing uncertainties in the emulators by\nintroducing the Bayesian Normalizing flow, a conditional density estimator\nconstructed from Bayesian neural networks. Using the exact likelihood function\nassociated with density estimators I sample the posterior distribution of flow\nparameters with suitably chosen priors to quantify and marginalize over flow\nuncertainties. I demonstrate the accuracy, calibration, and data-amplification\nimpacts of the estimated uncertainties for simulations of binary black hole\npopulations formed through common envelope evolution. I outline applications of\nthe methodology in simulation-based inference from growing GW catalogs and\nsketch other uses for general simulation-based approaches in GW astronomy.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8d1d\u53f6\u65af\u5f52\u4e00\u5316\u6d41\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u91cf\u5316\u5e76\u8fb9\u7f18\u5316\u6a21\u62df\u7d27\u51d1\u53cc\u661f\u5408\u5e76\uff08CBCs\uff09\u5206\u5e03\u51fd\u6570\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u4ee5\u652f\u6301\u5f15\u529b\u6ce2\uff08GW\uff09\u89c2\u6d4b\u6570\u636e\u7684\u5206\u6790\u3002", "motivation": "\u7531\u4e8e\u7d27\u51d1\u53cc\u661f\u5408\u5e76\u7684\u6a21\u62df\u6210\u672c\u9ad8\u6602\uff0c\u4e14\u7a00\u758f\u8bad\u7ec3\u96c6\u4f1a\u5bfc\u81f4\u6d41\u9884\u6d4b\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u91cf\u5316\u8fd9\u4e9b\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u4f5c\u8005\u5f00\u53d1\u4e86\u8d1d\u53f6\u65af\u5f52\u4e00\u5316\u6d41\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\u7684\u5bc6\u5ea6\u4f30\u8ba1\u5668\uff0c\u901a\u8fc7\u91c7\u6837\u6d41\u53c2\u6570\u7684\u540e\u9a8c\u5206\u5e03\u6765\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u6a21\u62df\u9ed1\u6d1e\u53cc\u661f\u7fa4\u4f53\u65f6\u8868\u73b0\u51fa\u9ad8\u7cbe\u5ea6\u548c\u826f\u597d\u7684\u6821\u51c6\u6027\uff0c\u5e76\u80fd\u6709\u6548\u653e\u5927\u7a00\u758f\u53c2\u6570\u7a7a\u95f4\u7684\u6570\u636e\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u9002\u7528\u4e8e\u5f15\u529b\u6ce2\u89c2\u6d4b\u6570\u636e\u7684\u6a21\u62df\u63a8\u65ad\uff0c\u5e76\u6709\u671b\u63a8\u5e7f\u5230\u5176\u4ed6\u5f15\u529b\u6ce2\u5929\u6587\u5b66\u7814\u7a76\u4e2d\u3002"}}
{"id": "2506.05688", "pdf": "https://arxiv.org/pdf/2506.05688", "abs": "https://arxiv.org/abs/2506.05688", "authors": ["Keinichi Fujita", "Shota Horiguchi", "Yusuke Ijima"], "title": "Voice Impression Control in Zero-Shot TTS", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "comment": "5 pages,5 figures, Accepted to INTERSPEECH 2025", "summary": "Para-/non-linguistic information in speech is pivotal in shaping the\nlisteners' impression. Although zero-shot text-to-speech (TTS) has achieved\nhigh speaker fidelity, modulating subtle para-/non-linguistic information to\ncontrol perceived voice characteristics, i.e., impressions, remains\nchallenging. We have therefore developed a voice impression control method in\nzero-shot TTS that utilizes a low-dimensional vector to represent the\nintensities of various voice impression pairs (e.g., dark-bright). The results\nof both objective and subjective evaluations have demonstrated our method's\neffectiveness in impression control. Furthermore, generating this vector via a\nlarge language model enables target-impression generation from a natural\nlanguage description of the desired impression, thus eliminating the need for\nmanual optimization.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u96f6\u6837\u672cTTS\u4e2d\u901a\u8fc7\u4f4e\u7ef4\u5411\u91cf\u63a7\u5236\u8bed\u97f3\u5370\u8c61\u7684\u65b9\u6cd5\uff0c\u5e76\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u76ee\u6807\u5370\u8c61\u5411\u91cf\u3002", "motivation": "\u8bed\u97f3\u4e2d\u7684\u526f\u8bed\u8a00/\u975e\u8bed\u8a00\u4fe1\u606f\u5bf9\u542c\u8005\u7684\u5370\u8c61\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u96f6\u6837\u672cTTS\u5728\u63a7\u5236\u8fd9\u4e9b\u7ec6\u5fae\u4fe1\u606f\u4ee5\u5851\u9020\u8bed\u97f3\u5370\u8c61\u65b9\u9762\u4ecd\u6709\u6311\u6218\u3002", "method": "\u4f7f\u7528\u4f4e\u7ef4\u5411\u91cf\u8868\u793a\u8bed\u97f3\u5370\u8c61\u5bf9\u7684\u5f3a\u5ea6\uff08\u5982\u6697-\u4eae\uff09\uff0c\u5e76\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u751f\u6210\u76ee\u6807\u5370\u8c61\u5411\u91cf\u3002", "result": "\u4e3b\u5ba2\u89c2\u8bc4\u4f30\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u8bed\u97f3\u5370\u8c61\u63a7\u5236\u4e0a\u6709\u6548\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u65e0\u9700\u624b\u52a8\u4f18\u5316\u5373\u53ef\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u751f\u6210\u76ee\u6807\u8bed\u97f3\u5370\u8c61\uff0c\u5177\u6709\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2506.05695", "pdf": "https://arxiv.org/pdf/2506.05695", "abs": "https://arxiv.org/abs/2506.05695", "authors": ["Lingyuan Liu", "Mengxiang Zhang"], "title": "Being Strong Progressively! Enhancing Knowledge Distillation of Large Language Models through a Curriculum Learning Framework", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Knowledge Distillation (KD) compresses large language models (LLMs) by\ntransferring the teacher model's capabilities to a smaller student model,\nreducing inference cost and memory usage while maintaining performance.\nHowever, existing KD methods for LLMs often fail to prevent significant shifts\nin the student model's distribution during training, leading to issues such as\ncatastrophic forgetting, mode collapse, and training-inference mismatch. To\naddress these challenges, we propose a novel, plug-in curriculum learning\nframework inspired by the strength training principle of \"progressive overload\"\n(POCL), which can be seamlessly integrated into existing white-box KD\napproaches with minimal computational overhead. The framework comprises two\ncore components: (1) a difficulty measurer that ranks and partitions training\nsamples from easy to hard, and (2) a training scheduler that incrementally\nintroduces these subsets into the distillation process at fixed intervals while\napplying loss functions with progressively rising temperatures. By starting\nwith the easiest samples and progressively increasing the difficulty, the\napproach enhances both the stability and efficiency of learning. Extensive\nexperiments in instruction-following settings demonstrate that POCL\nconsistently improves the performance of distilled student models across\nvarious white-box KD methods and model families. Our findings highlight the\neffectiveness of sorted training samples in KD for LLMs. More generally, our\nwork demonstrates how to structure training data within the KD process to\nenhance the stability and performance of distilled LLMs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6e10\u8fdb\u5f0f\u8fc7\u8f7d\u539f\u5219\u7684\u8bfe\u7a0b\u5b66\u4e60\u6846\u67b6\uff08POCL\uff09\uff0c\u7528\u4e8e\u6539\u8fdb\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u77e5\u8bc6\u84b8\u998f\uff08KD\uff09\uff0c\u901a\u8fc7\u9010\u6b65\u589e\u52a0\u8bad\u7ec3\u6837\u672c\u96be\u5ea6\u63d0\u5347\u5b66\u4e60\u7a33\u5b9a\u6027\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709KD\u65b9\u6cd5\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5bb9\u6613\u5bfc\u81f4\u5b66\u751f\u6a21\u578b\u5206\u5e03\u663e\u8457\u504f\u79fb\uff0c\u5f15\u53d1\u707e\u96be\u6027\u9057\u5fd8\u3001\u6a21\u5f0f\u5d29\u6e83\u7b49\u95ee\u9898\uff0c\u9700\u6539\u8fdb\u3002", "method": "POCL\u6846\u67b6\u5305\u542b\u96be\u5ea6\u6d4b\u91cf\u5668\u548c\u8bad\u7ec3\u8c03\u5ea6\u5668\uff0c\u9010\u6b65\u5f15\u5165\u4ece\u6613\u5230\u96be\u7684\u6837\u672c\uff0c\u5e76\u5e94\u7528\u6e29\u5ea6\u9010\u6e10\u5347\u9ad8\u7684\u635f\u5931\u51fd\u6570\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cPOCL\u80fd\u663e\u8457\u63d0\u5347\u84b8\u998f\u5b66\u751f\u6a21\u578b\u7684\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u767d\u76d2KD\u65b9\u6cd5\u548c\u6a21\u578b\u5bb6\u65cf\u3002", "conclusion": "POCL\u901a\u8fc7\u7ed3\u6784\u5316\u8bad\u7ec3\u6570\u636e\uff0c\u589e\u5f3a\u4e86\u84b8\u998fLLMs\u7684\u7a33\u5b9a\u6027\u548c\u6027\u80fd\u3002"}}
{"id": "2506.05725", "pdf": "https://arxiv.org/pdf/2506.05725", "abs": "https://arxiv.org/abs/2506.05725", "authors": ["Fang Wu", "Vijay Prakash Dwivedi", "Jure Leskovec"], "title": "Large Language Models are Good Relational Learners", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) have demonstrated remarkable capabilities across\nvarious domains, yet their application to relational deep learning (RDL)\nremains underexplored. Existing approaches adapt LLMs by traversing relational\nlinks between entities in a database and converting the structured data into\nflat text documents. Still, this text-based serialization disregards critical\nrelational structures, introduces redundancy, and often exceeds standard LLM\ncontext lengths. We introduce Rel-LLM, a novel architecture that utilizes a\ngraph neural network (GNN)- based encoder to generate structured relational\nprompts for LLMs within a retrieval-augmented generation (RAG) framework.\nUnlike traditional text-based serialization approaches, our method preserves\nthe inherent relational structure of databases while enabling LLMs to\neffectively process and reason over complex entity relationships. Specifically,\nthe GNN encoder extracts a local subgraph around an entity to build feature\nrepresentations that contain relevant entity relationships and temporal\ndependencies. These representations are transformed into structured prompts\nusing a denormalization process, effectively allowing the LLM to reason over\nrelational structures. Through extensive experiments, we demonstrate that\nRel-LLM outperforms existing methods on key RDL tasks, offering a scalable and\nefficient approach to integrating LLMs with structured data sources. Code is\navailable at https://github.com/smiles724/Rel-LLM.", "AI": {"tldr": "Rel-LLM\u662f\u4e00\u79cd\u65b0\u578b\u67b6\u6784\uff0c\u7ed3\u5408\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6846\u67b6\uff0c\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u7ed3\u6784\u5316\u5173\u7cfb\u63d0\u793a\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u6587\u672c\u5e8f\u5217\u5316\u65b9\u6cd5\u5728\u5173\u7cfb\u6df1\u5ea6\u5b66\u4e60\uff08RDL\uff09\u4e2d\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5c06\u7ed3\u6784\u5316\u6570\u636e\u8f6c\u6362\u4e3a\u6241\u5e73\u6587\u672c\uff0c\u5ffd\u89c6\u4e86\u5173\u7cfb\u7ed3\u6784\u5e76\u5bfc\u81f4\u5197\u4f59\uff0c\u4e14\u5e38\u8d85\u51faLLM\u4e0a\u4e0b\u6587\u957f\u5ea6\u9650\u5236\u3002", "method": "\u5229\u7528GNN\u7f16\u7801\u5668\u63d0\u53d6\u5b9e\u4f53\u5468\u56f4\u7684\u5c40\u90e8\u5b50\u56fe\uff0c\u751f\u6210\u5305\u542b\u5173\u7cfb\u548c\u65f6\u95f4\u4f9d\u8d56\u7684\u7279\u5f81\u8868\u793a\uff0c\u5e76\u901a\u8fc7\u53cd\u89c4\u8303\u5316\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u63d0\u793a\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cRel-LLM\u5728\u5173\u952eRDL\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684LLM\u4e0e\u7ed3\u6784\u5316\u6570\u636e\u96c6\u6210\u65b9\u6848\u3002", "conclusion": "Rel-LLM\u4fdd\u7559\u4e86\u6570\u636e\u5e93\u7684\u5173\u7cfb\u7ed3\u6784\uff0c\u4f7fLLM\u80fd\u6709\u6548\u5904\u7406\u590d\u6742\u5b9e\u4f53\u5173\u7cfb\uff0c\u4e3aRDL\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.05735", "pdf": "https://arxiv.org/pdf/2506.05735", "abs": "https://arxiv.org/abs/2506.05735", "authors": ["Rongzhe Wei", "Peizhi Niu", "Hans Hao-Hsun Hsu", "Ruihan Wu", "Haoteng Yin", "Mohsen Ghassemi", "Yifan Li", "Vamsi K. Potluru", "Eli Chien", "Kamalika Chaudhuri", "Olgica Milenkovic", "Pan Li"], "title": "Do LLMs Really Forget? Evaluating Unlearning with Knowledge Correlation and Confidence Awareness", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Machine unlearning techniques aim to mitigate unintended memorization in\nlarge language models (LLMs). However, existing approaches predominantly focus\non the explicit removal of isolated facts, often overlooking latent inferential\ndependencies and the non-deterministic nature of knowledge within LLMs.\nConsequently, facts presumed forgotten may persist implicitly through\ncorrelated information. To address these challenges, we propose a knowledge\nunlearning evaluation framework that more accurately captures the implicit\nstructure of real-world knowledge by representing relevant factual contexts as\nknowledge graphs with associated confidence scores. We further develop an\ninference-based evaluation protocol leveraging powerful LLMs as judges; these\njudges reason over the extracted knowledge subgraph to determine unlearning\nsuccess. Our LLM judges utilize carefully designed prompts and are calibrated\nagainst human evaluations to ensure their trustworthiness and stability.\nExtensive experiments on our newly constructed benchmark demonstrate that our\nframework provides a more realistic and rigorous assessment of unlearning\nperformance. Moreover, our findings reveal that current evaluation strategies\ntend to overestimate unlearning effectiveness. Our code is publicly available\nat https://github.com/Graph-COM/Knowledge_Unlearning.git.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u548c\u63a8\u7406\u7684\u77e5\u8bc6\u9057\u5fd8\u8bc4\u4f30\u6846\u67b6\uff0c\u4ee5\u66f4\u51c6\u786e\u5730\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u77e5\u8bc6\u9057\u5fd8\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u663e\u5f0f\u4e8b\u5b9e\u7684\u79fb\u9664\uff0c\u5ffd\u7565\u4e86\u9690\u5f0f\u63a8\u7406\u4f9d\u8d56\u548c\u77e5\u8bc6\u7684\u975e\u786e\u5b9a\u6027\uff0c\u5bfc\u81f4\u9057\u5fd8\u6548\u679c\u88ab\u9ad8\u4f30\u3002", "method": "\u63d0\u51fa\u77e5\u8bc6\u56fe\u8c31\u8868\u793a\u4e8b\u5b9e\u4e0a\u4e0b\u6587\uff0c\u5e76\u8bbe\u8ba1\u57fa\u4e8e\u63a8\u7406\u7684\u8bc4\u4f30\u534f\u8bae\uff0c\u5229\u7528LLM\u4f5c\u4e3a\u8bc4\u4f30\u8005\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u65b0\u6846\u67b6\u80fd\u66f4\u771f\u5b9e\u3001\u4e25\u683c\u5730\u8bc4\u4f30\u9057\u5fd8\u6548\u679c\uff0c\u5e76\u53d1\u73b0\u73b0\u6709\u65b9\u6cd5\u9ad8\u4f30\u4e86\u9057\u5fd8\u6548\u679c\u3002", "conclusion": "\u65b0\u6846\u67b6\u4e3a\u77e5\u8bc6\u9057\u5fd8\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u7684\u8bc4\u4f30\u5de5\u5177\uff0c\u63ed\u793a\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2506.05745", "pdf": "https://arxiv.org/pdf/2506.05745", "abs": "https://arxiv.org/abs/2506.05745", "authors": ["Emil Biju", "Shayan Talaei", "Zhemin Huang", "Mohammadreza Pourreza", "Azalia Mirhoseini", "Amin Saberi"], "title": "SPRINT: Enabling Interleaved Planning and Parallelized Execution in Reasoning Models", "categories": ["cs.AI", "cs.LG"], "comment": "Emil Biju, Shayan Talaei, and Zhemin Huang contributed equally to\n  this work", "summary": "Large reasoning models (LRMs) excel at complex reasoning tasks but typically\ngenerate lengthy sequential chains-of-thought, resulting in long inference\ntimes before arriving at the final answer. To address this challenge, we\nintroduce SPRINT, a novel post-training and inference-time framework designed\nto enable LRMs to dynamically identify and exploit opportunities for\nparallelization during their reasoning process. SPRINT incorporates an\ninnovative data curation pipeline that reorganizes natural language reasoning\ntrajectories into structured rounds of long-horizon planning and parallel\nexecution. By fine-tuning LRMs on a small amount of such curated data, the\nmodels learn to dynamically identify independent subtasks within extended\nreasoning processes and effectively execute them in parallel. Through extensive\nevaluations, we show that the models fine-tuned with the SPRINT framework match\nthe performance of reasoning models on complex domains such as mathematics\nwhile generating up to ~39% fewer sequential tokens on problems requiring more\nthan 8000 output tokens. Finally, we observe consistent results transferred to\ntwo out-of-distribution tasks of GPQA and Countdown with up to 45% and 65%\nreduction in average sequential tokens for longer reasoning trajectories, while\nachieving the performance of the fine-tuned reasoning model.", "AI": {"tldr": "SPRINT\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u5e76\u884c\u5316\u4f18\u5316\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u63a8\u7406\u6548\u7387\uff0c\u51cf\u5c11\u5e8f\u5217\u4ee4\u724c\u6570\u91cf\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u751f\u6210\u5197\u957f\u7684\u94fe\u5f0f\u63a8\u7406\u5bfc\u81f4\u63a8\u7406\u65f6\u95f4\u8fc7\u957f\u3002", "method": "SPRINT\u901a\u8fc7\u6570\u636e\u91cd\u7ec4\u548c\u5fae\u8c03\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u52a8\u6001\u8bc6\u522b\u5e76\u884c\u5316\u673a\u4f1a\u5e76\u6267\u884c\u72ec\u7acb\u5b50\u4efb\u52a1\u3002", "result": "\u5728\u6570\u5b66\u7b49\u9886\u57df\uff0cSPRINT\u5fae\u8c03\u7684\u6a21\u578b\u6027\u80fd\u4e0e\u539f\u59cb\u6a21\u578b\u76f8\u5f53\uff0c\u4f46\u5e8f\u5217\u4ee4\u724c\u51cf\u5c1139%\u3002", "conclusion": "SPRINT\u663e\u8457\u63d0\u5347\u63a8\u7406\u6548\u7387\uff0c\u9002\u7528\u4e8e\u957f\u63a8\u7406\u8f68\u8ff9\u4efb\u52a1\uff0c\u4e14\u80fd\u6cdb\u5316\u5230\u5176\u4ed6\u9886\u57df\u3002"}}
{"id": "2506.05754", "pdf": "https://arxiv.org/pdf/2506.05754", "abs": "https://arxiv.org/abs/2506.05754", "authors": ["Emmanuel Anaya Gonzalez", "Sairam Vaidya", "Kanghee Park", "Ruyi Ji", "Taylor Berg-Kirkpatrick", "Loris D'Antoni"], "title": "Constrained Sampling for Language Models Should Be Easy: An MCMC Perspective", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Constrained decoding enables Language Models (LMs) to produce samples that\nprovably satisfy hard constraints. However, existing constrained-decoding\napproaches often distort the underlying model distribution, a limitation that\nis especially problematic in applications like program fuzzing, where one wants\nto generate diverse and valid program inputs for testing purposes. We propose a\nnew constrained sampling framework based on Markov Chain Monte Carlo (MCMC)\nthat simultaneously satisfies three core desiderata: constraint satisfying\n(every sample satisfies the constraint), monotonically converging (the sampling\nprocess converges to the true conditional distribution), and efficient\n(high-quality samples emerge in few steps). Our method constructs a proposal\ndistribution over valid outputs and applies a Metropolis-Hastings acceptance\ncriterion based on the LM's likelihood, ensuring principled and efficient\nexploration of the constrained space. Empirically, our sampler outperforms\nexisting methods on both synthetic benchmarks and real-world program fuzzing\ntasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eMCMC\u7684\u7ea6\u675f\u91c7\u6837\u6846\u67b6\uff0c\u6ee1\u8db3\u7ea6\u675f\u6ee1\u8db3\u3001\u5355\u8c03\u6536\u655b\u548c\u9ad8\u6548\u6027\u4e09\u4e2a\u6838\u5fc3\u9700\u6c42\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7ea6\u675f\u89e3\u7801\u65b9\u6cd5\u4f1a\u626d\u66f2\u6a21\u578b\u5206\u5e03\uff0c\u5f71\u54cd\u591a\u6837\u6027\uff0c\u5c24\u5176\u5728\u7a0b\u5e8f\u6a21\u7cca\u6d4b\u8bd5\u7b49\u5e94\u7528\u4e2d\u3002", "method": "\u6784\u5efa\u6709\u6548\u8f93\u51fa\u7684\u63d0\u8bae\u5206\u5e03\uff0c\u5e76\u57fa\u4e8eLM\u4f3c\u7136\u5e94\u7528Metropolis-Hastings\u63a5\u53d7\u51c6\u5219\u3002", "result": "\u5728\u5408\u6210\u57fa\u51c6\u548c\u5b9e\u9645\u7a0b\u5e8f\u6a21\u7cca\u6d4b\u8bd5\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u65b0\u6846\u67b6\u5728\u6ee1\u8db3\u7ea6\u675f\u7684\u540c\u65f6\u9ad8\u6548\u63a2\u7d22\u7ea6\u675f\u7a7a\u95f4\uff0c\u63d0\u5347\u4e86\u6837\u672c\u8d28\u91cf\u3002"}}
{"id": "2506.05758", "pdf": "https://arxiv.org/pdf/2506.05758", "abs": "https://arxiv.org/abs/2506.05758", "authors": ["Guang-Xing Li"], "title": "Mapping correlations and coherence: adjacency-based approach to data visualization and regularity discovery", "categories": ["physics.comp-ph", "astro-ph.IM", "cs.LG", "math.DS"], "comment": "Code is avaliable at\n  https://github.com/gxli/Adjacent-Correlation-Analysis", "summary": "The development of science has been transforming man's view towards nature\nfor centuries. Observing structures and patterns in an effective approach to\ndiscover regularities from data is a key step toward theory-building. With\nincreasingly complex data being obtained, revealing regularities systematically\nhas become a challenge. Correlation is a most commonly-used and effective\napproach to describe regularities in data, yet for complex patterns, spatial\ninhomogeneity and complexity can often undermine the correlations. We present\nan algorithm to derive maps representing the type and degree of correlations,\nby taking the two-fold symmetry of the correlation vector into full account\nusing the Stokes parameter. The method allows for a spatially resolved view of\nthe nature and strength of correlations between physical quantities. In the\ncorrelation view, a region can often be separated into different subregions\nwith different types of correlations. Subregions correspond to physical regimes\nfor physical systems, or climate zones for climate maps. The simplicity of the\nmethod makes it widely applicable to a variety of data, where the\ncorrelation-based approach makes the map particularly useful in revealing\nregularities in physical systems and alike. As a new and efficient approach to\nrepresent data, the method should facilitate the development of new\ncomputational approaches to regularity discovery.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u65af\u6258\u514b\u65af\u53c2\u6570\u7684\u7b97\u6cd5\uff0c\u7528\u4e8e\u751f\u6210\u8868\u793a\u76f8\u5173\u6027\u7684\u7c7b\u578b\u548c\u7a0b\u5ea6\u7684\u5730\u56fe\uff0c\u89e3\u51b3\u4e86\u590d\u6742\u6570\u636e\u4e2d\u7a7a\u95f4\u4e0d\u5747\u5300\u6027\u548c\u590d\u6742\u6027\u5bf9\u76f8\u5173\u6027\u5206\u6790\u7684\u6311\u6218\u3002", "motivation": "\u968f\u7740\u6570\u636e\u590d\u6742\u6027\u7684\u589e\u52a0\uff0c\u7cfb\u7edf\u6027\u63ed\u793a\u6570\u636e\u4e2d\u7684\u89c4\u5f8b\u6027\u53d8\u5f97\u66f4\u5177\u6311\u6218\u6027\uff0c\u5c24\u5176\u662f\u7a7a\u95f4\u4e0d\u5747\u5300\u6027\u548c\u590d\u6742\u6027\u4f1a\u524a\u5f31\u76f8\u5173\u6027\u5206\u6790\u7684\u6548\u679c\u3002", "method": "\u5229\u7528\u65af\u6258\u514b\u65af\u53c2\u6570\u5145\u5206\u8003\u8651\u4e86\u76f8\u5173\u6027\u5411\u91cf\u7684\u53cc\u91cd\u5bf9\u79f0\u6027\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7b97\u6cd5\uff0c\u751f\u6210\u7a7a\u95f4\u5206\u8fa8\u7684\u76f8\u5173\u6027\u5730\u56fe\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5c06\u533a\u57df\u5212\u5206\u4e3a\u5177\u6709\u4e0d\u540c\u76f8\u5173\u6027\u7c7b\u578b\u7684\u5b50\u533a\u57df\uff0c\u9002\u7528\u4e8e\u7269\u7406\u7cfb\u7edf\u548c\u6c14\u5019\u5730\u56fe\u7b49\u591a\u79cd\u6570\u636e\u3002", "conclusion": "\u8fd9\u79cd\u7b80\u5355\u4e14\u9ad8\u6548\u7684\u65b9\u6cd5\u4e3a\u89c4\u5f8b\u6027\u53d1\u73b0\u63d0\u4f9b\u4e86\u65b0\u7684\u8ba1\u7b97\u5de5\u5177\uff0c\u6709\u671b\u63a8\u52a8\u76f8\u5173\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.05779", "pdf": "https://arxiv.org/pdf/2506.05779", "abs": "https://arxiv.org/abs/2506.05779", "authors": ["Yinchao Zhang", "Su Yao", "Yong Feng", "Kang Chen", "Tong Li", "Zhuotao Liu", "Yi Zhao", "Lexuan Zhang", "Xiangyu Gao", "Feng Xiong", "Qi Li", "Ke Xu"], "title": "Pegasus: A Universal Framework for Scalable Deep Learning Inference on the Dataplane", "categories": ["cs.NI", "cs.LG"], "comment": "to be published in Sigcomm 2025", "summary": "The paradigm of Intelligent DataPlane (IDP) embeds deep learning (DL) models\non the network dataplane to enable intelligent traffic analysis at line-speed.\nHowever, the current use of the match-action table (MAT) abstraction on the\ndataplane is misaligned with DL inference, leading to several key limitations,\nincluding accuracy degradation, limited scale, and lack of generality. This\npaper proposes Pegasus to address these limitations. Pegasus translates DL\noperations into three dataplane-oriented primitives to achieve generality:\nPartition, Map, and SumReduce. Specifically, Partition \"divides\"\nhigh-dimensional features into multiple low-dimensional vectors, making them\nmore suitable for the dataplane; Map \"conquers\" computations on the\nlow-dimensional vectors in parallel with the technique of fuzzy matching, while\nSumReduce \"combines\" the computation results. Additionally, Pegasus employs\nPrimitive Fusion to merge computations, improving scalability. Finally, Pegasus\nadopts full precision weights with fixed-point activations to improve accuracy.\nOur implementation on a P4 switch demonstrates that Pegasus can effectively\nsupport various types of DL models, including Multi-Layer Perceptron (MLP),\nRecurrent Neural Network (RNN), Convolutional Neural Network (CNN), and\nAutoEncoder models on the dataplane. Meanwhile, Pegasus outperforms\nstate-of-the-art approaches with an average accuracy improvement of up to\n22.8%, along with up to 248x larger model size and 212x larger input scale.", "AI": {"tldr": "Pegasus\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u6df1\u5ea6\u5b66\u4e60\u64cd\u4f5c\u8f6c\u5316\u4e3a\u6570\u636e\u5e73\u9762\u539f\u8bed\u7684\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6570\u636e\u5e73\u9762\u5728\u6df1\u5ea6\u5b66\u4e60\u63a8\u7406\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u51c6\u786e\u6027\u3001\u89c4\u6a21\u548c\u901a\u7528\u6027\u3002", "motivation": "\u5f53\u524d\u6570\u636e\u5e73\u9762\u7684\u5339\u914d-\u52a8\u4f5c\u8868\u62bd\u8c61\u4e0e\u6df1\u5ea6\u5b66\u4e60\u63a8\u7406\u4e0d\u5339\u914d\uff0c\u5bfc\u81f4\u51c6\u786e\u6027\u4e0b\u964d\u3001\u89c4\u6a21\u53d7\u9650\u548c\u7f3a\u4e4f\u901a\u7528\u6027\u3002", "method": "Pegasus\u5c06\u6df1\u5ea6\u5b66\u4e60\u64cd\u4f5c\u8f6c\u5316\u4e3a\u4e09\u4e2a\u6570\u636e\u5e73\u9762\u539f\u8bed\uff1aPartition\u3001Map\u548cSumReduce\uff0c\u5e76\u91c7\u7528Primitive Fusion\u548c\u5168\u7cbe\u5ea6\u6743\u91cd\u63d0\u5347\u6027\u80fd\u3002", "result": "\u5728P4\u4ea4\u6362\u673a\u4e0a\u7684\u5b9e\u73b0\u8868\u660e\uff0cPegasus\u652f\u6301\u591a\u79cdDL\u6a21\u578b\uff0c\u51c6\u786e\u6027\u63d0\u534722.8%\uff0c\u6a21\u578b\u89c4\u6a21\u548c\u8f93\u5165\u89c4\u6a21\u5206\u522b\u63d0\u5347248\u500d\u548c212\u500d\u3002", "conclusion": "Pegasus\u901a\u8fc7\u6570\u636e\u5e73\u9762\u539f\u8bed\u548c\u4f18\u5316\u6280\u672f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6df1\u5ea6\u5b66\u4e60\u5728\u6570\u636e\u5e73\u9762\u4e0a\u7684\u6027\u80fd\u548c\u9002\u7528\u6027\u3002"}}
{"id": "2506.05780", "pdf": "https://arxiv.org/pdf/2506.05780", "abs": "https://arxiv.org/abs/2506.05780", "authors": ["Meng Fan", "Yifan Zuo", "Patrick Blaes", "Harley Montgomery", "Subhasis Das"], "title": "Robust sensor fusion against on-vehicle sensor staleness", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "comment": "This paper has been accepted by CVPR 2025 Precognition Workshop", "summary": "Sensor fusion is crucial for a performant and robust Perception system in\nautonomous vehicles, but sensor staleness, where data from different sensors\narrives with varying delays, poses significant challenges. Temporal\nmisalignment between sensor modalities leads to inconsistent object state\nestimates, severely degrading the quality of trajectory predictions that are\ncritical for safety. We present a novel and model-agnostic approach to address\nthis problem via (1) a per-point timestamp offset feature (for LiDAR and radar\nboth relative to camera) that enables fine-grained temporal awareness in sensor\nfusion, and (2) a data augmentation strategy that simulates realistic sensor\nstaleness patterns observed in deployed vehicles. Our method is integrated into\na perspective-view detection model that consumes sensor data from multiple\nLiDARs, radars and cameras. We demonstrate that while a conventional model\nshows significant regressions when one sensor modality is stale, our approach\nreaches consistently good performance across both synchronized and stale\nconditions.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u89e3\u51b3\u81ea\u52a8\u9a7e\u9a76\u4e2d\u4f20\u611f\u5668\u6570\u636e\u65f6\u95f4\u4e0d\u540c\u6b65\u95ee\u9898\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u70b9\u7ea7\u65f6\u95f4\u6233\u504f\u79fb\u548c\u6570\u636e\u589e\u5f3a\u7b56\u7565\uff0c\u63d0\u5347\u4e86\u611f\u77e5\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u4f20\u611f\u5668\u6570\u636e\u7684\u65f6\u95f4\u4e0d\u540c\u6b65\uff08staleness\uff09\u4f1a\u5bfc\u81f4\u7269\u4f53\u72b6\u6001\u4f30\u8ba1\u4e0d\u4e00\u81f4\uff0c\u4e25\u91cd\u5f71\u54cd\u8f68\u8ff9\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u4ece\u800c\u5a01\u80c1\u81ea\u52a8\u9a7e\u9a76\u7684\u5b89\u5168\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u578b\u65e0\u5173\u7684\u65b9\u6cd5\uff0c\u5305\u62ec\uff081\uff09\u4e3aLiDAR\u548c\u96f7\u8fbe\u6570\u636e\u6dfb\u52a0\u76f8\u5bf9\u4e8e\u76f8\u673a\u7684\u65f6\u95f4\u6233\u504f\u79fb\u7279\u5f81\uff0c\uff082\uff09\u6a21\u62df\u771f\u5b9e\u573a\u666f\u4e2d\u4f20\u611f\u5668staleness\u6a21\u5f0f\u7684\u6570\u636e\u589e\u5f3a\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4f20\u7edf\u6a21\u578b\u5728\u4f20\u611f\u5668\u6570\u636e\u4e0d\u540c\u6b65\u65f6\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u800c\u65b0\u65b9\u6cd5\u5728\u540c\u6b65\u548c\u4e0d\u540c\u6b65\u6761\u4ef6\u4e0b\u5747\u8868\u73b0\u826f\u597d\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u611f\u5668\u6570\u636e\u65f6\u95f4\u4e0d\u540c\u6b65\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u81ea\u52a8\u9a7e\u9a76\u611f\u77e5\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u548c\u6027\u80fd\u3002"}}
{"id": "2506.05834", "pdf": "https://arxiv.org/pdf/2506.05834", "abs": "https://arxiv.org/abs/2506.05834", "authors": ["Sandro Preto", "Marcelo Finger"], "title": "Regional, Lattice and Logical Representations of Neural Networks", "categories": ["cs.LO", "cs.AI", "cs.LG"], "comment": "In Proceedings LSFA 2024, arXiv:2506.05219", "summary": "A possible path to the interpretability of neural networks is to\n(approximately) represent them in the regional format of piecewise linear\nfunctions, where regions of inputs are associated to linear functions computing\nthe network outputs. We present an algorithm for the translation of feedforward\nneural networks with ReLU activation functions in hidden layers and truncated\nidentity activation functions in the output layer. We also empirically\ninvestigate the complexity of regional representations outputted by our method\nfor neural networks with varying sizes. Lattice and logical representations of\nneural networks are straightforward from regional representations as long as\nthey satisfy a specific property. So we empirically investigate to what extent\nthe translations by our algorithm satisfy such property.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06ReLU\u6fc0\u6d3b\u7684\u795e\u7ecf\u7f51\u7edc\u8f6c\u6362\u4e3a\u5206\u6bb5\u7ebf\u6027\u51fd\u6570\u533a\u57df\u8868\u793a\u7684\u65b9\u6cd5\uff0c\u5e76\u7814\u7a76\u4e86\u5176\u590d\u6742\u6027\u548c\u9002\u7528\u6027\u3002", "motivation": "\u63a2\u7d22\u795e\u7ecf\u7f51\u7edc\u53ef\u89e3\u91ca\u6027\u7684\u4e00\u79cd\u53ef\u80fd\u8def\u5f84\uff0c\u901a\u8fc7\u5c06\u5176\u8868\u793a\u4e3a\u5206\u6bb5\u7ebf\u6027\u51fd\u6570\u7684\u533a\u57df\u5f62\u5f0f\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u7b97\u6cd5\uff0c\u5c06\u5177\u6709ReLU\u9690\u85cf\u5c42\u548c\u622a\u65ad\u6052\u7b49\u8f93\u51fa\u5c42\u7684\u795e\u7ecf\u7f51\u7edc\u8f6c\u6362\u4e3a\u533a\u57df\u8868\u793a\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u7814\u7a76\u4e86\u4e0d\u540c\u89c4\u6a21\u795e\u7ecf\u7f51\u7edc\u533a\u57df\u8868\u793a\u7684\u590d\u6742\u6027\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u6ee1\u8db3\u7279\u5b9a\u6027\u8d28\u7684\u7a0b\u5ea6\u3002", "conclusion": "\u533a\u57df\u8868\u793a\u4e3a\u795e\u7ecf\u7f51\u7edc\u7684\u53ef\u89e3\u91ca\u6027\u63d0\u4f9b\u4e86\u6f5c\u5728\u8def\u5f84\uff0c\u4e14\u7b97\u6cd5\u751f\u6210\u7684\u8868\u793a\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u53ef\u76f4\u63a5\u8f6c\u6362\u4e3a\u683c\u548c\u903b\u8f91\u8868\u793a\u3002"}}
{"id": "2506.05853", "pdf": "https://arxiv.org/pdf/2506.05853", "abs": "https://arxiv.org/abs/2506.05853", "authors": ["Nikita Vasilenko", "Alexander Demin", "Vladimir Boorlakov"], "title": "Training-Free Query Optimization via LLM-Based Plan Similarity", "categories": ["cs.DB", "cs.LG"], "comment": "18 pages, 5 figures", "summary": "Large language model (LLM) embeddings offer a promising new avenue for\ndatabase query optimization. In this paper, we explore how pre-trained\nexecution plan embeddings can guide SQL query execution without the need for\nadditional model training. We introduce LLM-PM (LLM-based Plan Mapping), a\nframework that embeds the default execution plan of a query, finds its k\nnearest neighbors among previously executed plans, and recommends database\nhintsets based on neighborhood voting. A lightweight consistency check\nvalidates the selected hint, while a fallback mechanism searches the full hint\nspace when needed. Evaluated on the JOB-CEB benchmark using OpenGauss, LLM-PM\nachieves an average speed-up of 21% query latency reduction. This work\nhighlights the potential of LLM-powered embeddings to deliver practical\nimprovements in query performance and opens new directions for training-free,\nembedding-based optimizer guidance systems.", "AI": {"tldr": "LLM-PM\u5229\u7528\u9884\u8bad\u7ec3\u7684\u6267\u884c\u8ba1\u5212\u5d4c\u5165\u6307\u5bfcSQL\u67e5\u8be2\u6267\u884c\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\uff0c\u901a\u8fc7\u90bb\u5c45\u6295\u7968\u63a8\u8350\u6570\u636e\u5e93\u63d0\u793a\u96c6\uff0c\u5e73\u5747\u51cf\u5c1121%\u67e5\u8be2\u5ef6\u8fdf\u3002", "motivation": "\u63a2\u7d22\u9884\u8bad\u7ec3\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5d4c\u5165\u5982\u4f55\u4f18\u5316\u6570\u636e\u5e93\u67e5\u8be2\u6267\u884c\uff0c\u907f\u514d\u989d\u5916\u6a21\u578b\u8bad\u7ec3\u7684\u5f00\u9500\u3002", "method": "\u63d0\u51faLLM-PM\u6846\u67b6\uff0c\u5d4c\u5165\u67e5\u8be2\u7684\u9ed8\u8ba4\u6267\u884c\u8ba1\u5212\uff0c\u901a\u8fc7k\u8fd1\u90bb\u7b97\u6cd5\u627e\u5230\u76f8\u4f3c\u8ba1\u5212\u5e76\u63a8\u8350\u63d0\u793a\u96c6\uff0c\u8f85\u4ee5\u4e00\u81f4\u6027\u68c0\u67e5\u548c\u56de\u9000\u673a\u5236\u3002", "result": "\u5728JOB-CEB\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4f7f\u7528OpenGauss\u5b9e\u73b0\u5e73\u574721%\u7684\u67e5\u8be2\u5ef6\u8fdf\u964d\u4f4e\u3002", "conclusion": "LLM\u5d4c\u5165\u4e3a\u67e5\u8be2\u4f18\u5316\u63d0\u4f9b\u4e86\u5b9e\u7528\u6539\u8fdb\u6f5c\u529b\uff0c\u5f00\u8f9f\u4e86\u65e0\u8bad\u7ec3\u3001\u57fa\u4e8e\u5d4c\u5165\u7684\u4f18\u5316\u5668\u6307\u5bfc\u65b0\u65b9\u5411\u3002"}}
{"id": "2506.05862", "pdf": "https://arxiv.org/pdf/2506.05862", "abs": "https://arxiv.org/abs/2506.05862", "authors": ["Rembert Daems", "Sven Seys", "Val\u00e9rie Hox", "Adam Chaker", "Glynnis De Greve", "Winde Lemmens", "Anne-Lise Poirrier", "Eline Beckers", "Zuzana Diamant", "Carmen Dierickx", "Peter W. Hellings", "Caroline Huart", "Claudia Jerin", "Mark Jorissen", "Hanne Osc\u00e9", "Karolien Roux", "Mark Thompson", "Sophie Tombu", "Saartje Uyttebroek", "Andrzej Zarowski", "Senne Gorris", "Laura Van Gerven", "Dirk Loeckx", "Thomas Demeester"], "title": "Improved Allergy Wheal Detection for the Skin Prick Automated Test Device", "categories": ["cs.CV", "cs.LG"], "comment": "This work is presented at Artificial Intelligence in Medicine 2025,\n  this is the longer (10 pages) version", "summary": "Background: The skin prick test (SPT) is the gold standard for diagnosing\nsensitization to inhalant allergies. The Skin Prick Automated Test (SPAT)\ndevice was designed for increased consistency in test results, and captures 32\nimages to be jointly used for allergy wheal detection and delineation, which\nleads to a diagnosis.\n  Materials and Methods: Using SPAT data from $868$ patients with suspected\ninhalant allergies, we designed an automated method to detect and delineate\nwheals on these images. To this end, $10,416$ wheals were manually annotated by\ndrawing detailed polygons along the edges. The unique data-modality of the SPAT\ndevice, with $32$ images taken under distinct lighting conditions, requires a\ncustom-made approach. Our proposed method consists of two parts: a neural\nnetwork component that segments the wheals on the pixel level, followed by an\nalgorithmic and interpretable approach for detecting and delineating the\nwheals.\n  Results: We evaluate the performance of our method on a hold-out validation\nset of $217$ patients. As a baseline we use a single conventionally lighted\nimage per SPT as input to our method.\n  Conclusion: Using the $32$ SPAT images under various lighting conditions\noffers a considerably higher accuracy than a single image in conventional,\nuniform light.", "AI": {"tldr": "SPAT\u8bbe\u5907\u901a\u8fc7\u591a\u5149\u7167\u6761\u4ef6\u56fe\u50cf\u63d0\u9ad8\u8fc7\u654f\u68c0\u6d4b\u51c6\u786e\u6027\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u795e\u7ecf\u7f51\u7edc\u548c\u7b97\u6cd5\u7684\u81ea\u52a8\u5316\u65b9\u6cd5\u3002", "motivation": "\u63d0\u9ad8\u76ae\u80a4\u70b9\u523a\u8bd5\u9a8c\uff08SPT\uff09\u7684\u68c0\u6d4b\u4e00\u81f4\u6027\u548c\u51c6\u786e\u6027\u3002", "method": "\u4f7f\u7528SPAT\u8bbe\u5907\u768432\u5f20\u591a\u5149\u7167\u56fe\u50cf\uff0c\u7ed3\u5408\u795e\u7ecf\u7f51\u7edc\u5206\u5272\u548c\u7b97\u6cd5\u68c0\u6d4b\u8fc7\u654f\u53cd\u5e94\u3002", "result": "32\u5f20\u56fe\u50cf\u6bd4\u5355\u5f20\u56fe\u50cf\u5728\u68c0\u6d4b\u51c6\u786e\u6027\u4e0a\u663e\u8457\u63d0\u9ad8\u3002", "conclusion": "\u591a\u5149\u7167\u6761\u4ef6\u56fe\u50cf\u53ef\u663e\u8457\u63d0\u5347\u8fc7\u654f\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2506.05867", "pdf": "https://arxiv.org/pdf/2506.05867", "abs": "https://arxiv.org/abs/2506.05867", "authors": ["Zhixiong Zhuang", "Hui-Po Wang", "Maria-Irina Nicolae", "Mario Fritz"], "title": "Stealix: Model Stealing via Prompt Evolution", "categories": ["cs.CR", "cs.LG"], "comment": "Accepted at ICML 2025. The project page is at\n  https://zhixiongzh.github.io/stealix/", "summary": "Model stealing poses a significant security risk in machine learning by\nenabling attackers to replicate a black-box model without access to its\ntraining data, thus jeopardizing intellectual property and exposing sensitive\ninformation. Recent methods that use pre-trained diffusion models for data\nsynthesis improve efficiency and performance but rely heavily on manually\ncrafted prompts, limiting automation and scalability, especially for attackers\nwith little expertise. To assess the risks posed by open-source pre-trained\nmodels, we propose a more realistic threat model that eliminates the need for\nprompt design skills or knowledge of class names. In this context, we introduce\nStealix, the first approach to perform model stealing without predefined\nprompts. Stealix uses two open-source pre-trained models to infer the victim\nmodel's data distribution, and iteratively refines prompts through a genetic\nalgorithm, progressively improving the precision and diversity of synthetic\nimages. Our experimental results demonstrate that Stealix significantly\noutperforms other methods, even those with access to class names or\nfine-grained prompts, while operating under the same query budget. These\nfindings highlight the scalability of our approach and suggest that the risks\nposed by pre-trained generative models in model stealing may be greater than\npreviously recognized.", "AI": {"tldr": "Stealix\u662f\u4e00\u79cd\u65e0\u9700\u9884\u5b9a\u4e49\u63d0\u793a\u7684\u6a21\u578b\u7a83\u53d6\u65b9\u6cd5\uff0c\u5229\u7528\u5f00\u6e90\u9884\u8bad\u7ec3\u6a21\u578b\u548c\u9057\u4f20\u7b97\u6cd5\u4f18\u5316\u63d0\u793a\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5408\u6210\u56fe\u50cf\u7684\u7cbe\u5ea6\u548c\u591a\u6837\u6027\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u6a21\u578b\u7a83\u53d6\u5bf9\u673a\u5668\u5b66\u4e60\u5b89\u5168\u6784\u6210\u5a01\u80c1\uff0c\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u624b\u5de5\u63d0\u793a\uff0c\u9650\u5236\u4e86\u81ea\u52a8\u5316\u548c\u53ef\u6269\u5c55\u6027\u3002Stealix\u65e8\u5728\u6d88\u9664\u5bf9\u63d0\u793a\u8bbe\u8ba1\u6280\u80fd\u7684\u9700\u6c42\uff0c\u8bc4\u4f30\u5f00\u6e90\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u98ce\u9669\u3002", "method": "Stealix\u4f7f\u7528\u4e24\u4e2a\u5f00\u6e90\u9884\u8bad\u7ec3\u6a21\u578b\u63a8\u65ad\u53d7\u5bb3\u8005\u6a21\u578b\u7684\u6570\u636e\u5206\u5e03\uff0c\u5e76\u901a\u8fc7\u9057\u4f20\u7b97\u6cd5\u8fed\u4ee3\u4f18\u5316\u63d0\u793a\uff0c\u63d0\u5347\u5408\u6210\u56fe\u50cf\u8d28\u91cf\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cStealix\u5728\u76f8\u540c\u67e5\u8be2\u9884\u7b97\u4e0b\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u5305\u62ec\u4f9d\u8d56\u7c7b\u540d\u6216\u7cbe\u7ec6\u63d0\u793a\u7684\u65b9\u6cd5\u3002", "conclusion": "Stealix\u5c55\u793a\u4e86\u9884\u8bad\u7ec3\u751f\u6210\u6a21\u578b\u5728\u6a21\u578b\u7a83\u53d6\u4e2d\u7684\u6f5c\u5728\u98ce\u9669\u53ef\u80fd\u88ab\u4f4e\u4f30\uff0c\u5176\u65b9\u6cd5\u5177\u6709\u9ad8\u5ea6\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2506.05888", "pdf": "https://arxiv.org/pdf/2506.05888", "abs": "https://arxiv.org/abs/2506.05888", "authors": ["Luca Nepote", "Alix Lh\u00e9ritier", "Nicolas Bondoux", "Marios Kountouris", "Maurizio Filippone"], "title": "Variational Inference for Quantum HyperNetworks", "categories": ["quant-ph", "cs.LG", "stat.ML", "68Q12"], "comment": "This work has been accepted for publication in 2025 International\n  Joint Conference on Neural Networks (IJCNN 2025) and will be published on\n  IEEE Xplore", "summary": "Binary Neural Networks (BiNNs), which employ single-bit precision weights,\nhave emerged as a promising solution to reduce memory usage and power\nconsumption while maintaining competitive performance in large-scale systems.\nHowever, training BiNNs remains a significant challenge due to the limitations\nof conventional training algorithms. Quantum HyperNetworks offer a novel\nparadigm for enhancing the optimization of BiNN by leveraging quantum\ncomputing. Specifically, a Variational Quantum Algorithm is employed to\ngenerate binary weights through quantum circuit measurements, while key quantum\nphenomena such as superposition and entanglement facilitate the exploration of\na broader solution space. In this work, we establish a connection between this\napproach and Bayesian inference by deriving the Evidence Lower Bound (ELBO),\nwhen direct access to the output distribution is available (i.e., in\nsimulations), and introducing a surrogate ELBO based on the Maximum Mean\nDiscrepancy (MMD) metric for scenarios involving implicit distributions, as\ncommonly encountered in practice. Our experimental results demonstrate that the\nproposed methods outperform standard Maximum Likelihood Estimation (MLE),\nimproving trainability and generalization.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u91cf\u5b50\u8d85\u7f51\u7edc\u4f18\u5316\u4e8c\u8fdb\u5236\u795e\u7ecf\u7f51\u7edc\uff08BiNNs\uff09\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cf\u5b50\u8ba1\u7b97\u751f\u6210\u4e8c\u8fdb\u5236\u6743\u91cd\uff0c\u5e76\u5229\u7528\u91cf\u5b50\u73b0\u8c61\uff08\u5982\u53e0\u52a0\u548c\u7ea0\u7f20\uff09\u6269\u5c55\u89e3\u7a7a\u95f4\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u4f20\u7edf\u7684\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\uff08MLE\uff09\u3002", "motivation": "\u4e8c\u8fdb\u5236\u795e\u7ecf\u7f51\u7edc\uff08BiNNs\uff09\u867d\u7136\u80fd\u51cf\u5c11\u5185\u5b58\u548c\u529f\u8017\uff0c\u4f46\u8bad\u7ec3\u96be\u5ea6\u5927\u3002\u91cf\u5b50\u8d85\u7f51\u7edc\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u4f18\u5316\u8303\u5f0f\uff0c\u5229\u7528\u91cf\u5b50\u8ba1\u7b97\u63d0\u5347BiNNs\u7684\u6027\u80fd\u3002", "method": "\u91c7\u7528\u53d8\u5206\u91cf\u5b50\u7b97\u6cd5\u751f\u6210\u4e8c\u8fdb\u5236\u6743\u91cd\uff0c\u5e76\u7ed3\u5408\u8d1d\u53f6\u65af\u63a8\u65ad\u63a8\u5bfc\u4e86\u8bc1\u636e\u4e0b\u754c\uff08ELBO\uff09\uff0c\u540c\u65f6\u63d0\u51fa\u4e86\u57fa\u4e8e\u6700\u5927\u5747\u503c\u5dee\u5f02\uff08MMD\uff09\u7684\u66ff\u4ee3ELBO\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u53ef\u8bad\u7ec3\u6027\u548c\u6cdb\u5316\u80fd\u529b\u4e0a\u4f18\u4e8e\u4f20\u7edf\u7684\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\uff08MLE\uff09\u3002", "conclusion": "\u91cf\u5b50\u8d85\u7f51\u7edc\u4e3a\u4f18\u5316\u4e8c\u8fdb\u5236\u795e\u7ecf\u7f51\u7edc\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b0\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002"}}
{"id": "2506.05894", "pdf": "https://arxiv.org/pdf/2506.05894", "abs": "https://arxiv.org/abs/2506.05894", "authors": ["Philipp Plank", "Yufei Zhang"], "title": "Policy Optimization for Continuous-time Linear-Quadratic Graphon Mean Field Games", "categories": ["math.OC", "cs.LG", "math.PR", "68Q25, 91A15, 49N80, 91A07, 91A43, 49N10"], "comment": null, "summary": "Multi-agent reinforcement learning, despite its popularity and empirical\nsuccess, faces significant scalability challenges in large-population dynamic\ngames. Graphon mean field games (GMFGs) offer a principled framework for\napproximating such games while capturing heterogeneity among players. In this\npaper, we propose and analyze a policy optimization framework for\ncontinuous-time, finite-horizon linear-quadratic GMFGs. Exploiting the\nstructural properties of GMFGs, we design an efficient policy parameterization\nin which each player's policy is represented as an affine function of their\nprivate state, with a shared slope function and player-specific intercepts. We\ndevelop a bilevel optimization algorithm that alternates between policy\ngradient updates for best-response computation under a fixed population\ndistribution, and distribution updates using the resulting policies. We prove\nlinear convergence of the policy gradient steps to best-response policies and\nestablish global convergence of the overall algorithm to the Nash equilibrium.\nThe analysis relies on novel landscape characterizations over\ninfinite-dimensional policy spaces. Numerical experiments demonstrate the\nconvergence and robustness of the proposed algorithm under varying graphon\nstructures, noise levels, and action frequencies.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u8fde\u7eed\u65f6\u95f4\u3001\u6709\u9650\u65f6\u57df\u7ebf\u6027\u4e8c\u6b21\u56fe\u5e73\u5747\u573a\u535a\u5f08\u7684\u7b56\u7565\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u5c42\u4f18\u5316\u7b97\u6cd5\u5b9e\u73b0\u7eb3\u4ec0\u5747\u8861\u7684\u5168\u5c40\u6536\u655b\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u5728\u5927\u89c4\u6a21\u52a8\u6001\u535a\u5f08\u4e2d\u9762\u4e34\u53ef\u6269\u5c55\u6027\u6311\u6218\uff0c\u56fe\u5e73\u5747\u573a\u535a\u5f08\u63d0\u4f9b\u4e86\u4e00\u79cd\u6355\u6349\u73a9\u5bb6\u5f02\u8d28\u6027\u7684\u8fd1\u4f3c\u6846\u67b6\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u7b56\u7565\u53c2\u6570\u5316\u65b9\u6cd5\uff0c\u6bcf\u4e2a\u73a9\u5bb6\u7684\u7b56\u7565\u8868\u793a\u4e3a\u79c1\u6709\u72b6\u6001\u7684\u4eff\u5c04\u51fd\u6570\uff0c\u5e76\u5f00\u53d1\u4e86\u53cc\u5c42\u4f18\u5316\u7b97\u6cd5\uff0c\u4ea4\u66ff\u8fdb\u884c\u7b56\u7565\u68af\u5ea6\u66f4\u65b0\u548c\u5206\u5e03\u66f4\u65b0\u3002", "result": "\u8bc1\u660e\u4e86\u7b56\u7565\u68af\u5ea6\u6b65\u9aa4\u7ebf\u6027\u6536\u655b\u5230\u6700\u4f73\u54cd\u5e94\u7b56\u7565\uff0c\u6574\u4f53\u7b97\u6cd5\u5168\u5c40\u6536\u655b\u5230\u7eb3\u4ec0\u5747\u8861\u3002", "conclusion": "\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u5728\u4e0d\u540c\u56fe\u7ed3\u6784\u3001\u566a\u58f0\u6c34\u5e73\u548c\u52a8\u4f5c\u9891\u7387\u4e0b\u7684\u6536\u655b\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2506.05917", "pdf": "https://arxiv.org/pdf/2506.05917", "abs": "https://arxiv.org/abs/2506.05917", "authors": ["Steven Landgraf", "Markus Hillemann", "Markus Ulrich"], "title": "Rethinking Semi-supervised Segmentation Beyond Accuracy: Reliability and Robustness", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Semantic segmentation is critical for scene understanding but demands costly\npixel-wise annotations, attracting increasing attention to semi-supervised\napproaches to leverage abundant unlabeled data. While semi-supervised\nsegmentation is often promoted as a path toward scalable, real-world\ndeployment, it is astonishing that current evaluation protocols exclusively\nfocus on segmentation accuracy, entirely overlooking reliability and\nrobustness. These qualities, which ensure consistent performance under diverse\nconditions (robustness) and well-calibrated model confidences as well as\nmeaningful uncertainties (reliability), are essential for safety-critical\napplications like autonomous driving, where models must handle unpredictable\nenvironments and avoid sudden failures at all costs. To address this gap, we\nintroduce the Reliable Segmentation Score (RSS), a novel metric that combines\npredictive accuracy, calibration, and uncertainty quality measures via a\nharmonic mean. RSS penalizes deficiencies in any of its components, providing\nan easy and intuitive way of holistically judging segmentation models.\nComprehensive evaluations of UniMatchV2 against its predecessor and a\nsupervised baseline show that semi-supervised methods often trade reliability\nfor accuracy. While out-of-domain evaluations demonstrate UniMatchV2's\nrobustness, they further expose persistent reliability shortcomings. We\nadvocate for a shift in evaluation protocols toward more holistic metrics like\nRSS to better align semi-supervised learning research with real-world\ndeployment needs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8bc4\u4f30\u6307\u6807RSS\uff0c\u7528\u4e8e\u8861\u91cf\u534a\u76d1\u7763\u8bed\u4e49\u5206\u5272\u6a21\u578b\u7684\u51c6\u786e\u6027\u3001\u53ef\u9760\u6027\u548c\u9c81\u68d2\u6027\uff0c\u586b\u8865\u4e86\u73b0\u6709\u8bc4\u4f30\u534f\u8bae\u7684\u4e0d\u8db3\u3002", "motivation": "\u5f53\u524d\u534a\u76d1\u7763\u5206\u5272\u8bc4\u4f30\u4ec5\u5173\u6ce8\u51c6\u786e\u6027\uff0c\u5ffd\u7565\u4e86\u53ef\u9760\u6027\u548c\u9c81\u68d2\u6027\uff0c\u800c\u8fd9\u4e9b\u5bf9\u81ea\u52a8\u9a7e\u9a76\u7b49\u5b89\u5168\u5173\u952e\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5f15\u5165Reliable Segmentation Score (RSS)\uff0c\u901a\u8fc7\u8c03\u548c\u5e73\u5747\u503c\u7ed3\u5408\u9884\u6d4b\u51c6\u786e\u6027\u3001\u6821\u51c6\u548c\u4e0d\u786e\u5b9a\u6027\u8d28\u91cf\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u534a\u76d1\u7763\u65b9\u6cd5\u5e38\u4ee5\u53ef\u9760\u6027\u6362\u53d6\u51c6\u786e\u6027\uff0cUniMatchV2\u5728\u9c81\u68d2\u6027\u4e0a\u8868\u73b0\u826f\u597d\u4f46\u53ef\u9760\u6027\u4ecd\u6709\u4e0d\u8db3\u3002", "conclusion": "\u547c\u5401\u91c7\u7528RSS\u7b49\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u6307\u6807\uff0c\u4ee5\u66f4\u597d\u5730\u6ee1\u8db3\u5b9e\u9645\u90e8\u7f72\u9700\u6c42\u3002"}}
{"id": "2506.05958", "pdf": "https://arxiv.org/pdf/2506.05958", "abs": "https://arxiv.org/abs/2506.05958", "authors": ["Alicia Beneyto-Rodriguez", "Gregorio I. Sainz-Palmero", "Marta Galende-Hern\u00e1ndez", "Mar\u00eda J. Fuente", "Jos\u00e9 M. Cuenca"], "title": "Applying XAI based unsupervised knowledge discovering for Operation modes in a WWTP. A real case: AQUAVALL WWTP", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": null, "summary": "Water reuse is a key point when fresh water is a commodity in ever greater\ndemand, but which is also becoming ever more available. Furthermore, the return\nof clean water to its natural environment is also mandatory. Therefore,\nwastewater treatment plants (WWTPs) are essential in any policy focused on\nthese serious challenges.\n  WWTPs are complex facilities which need to operate at their best to achieve\ntheir goals. Nowadays, they are largely monitored, generating large databases\nof historical data concerning their functioning over time. All this implies a\nlarge amount of embedded information which is not usually easy for plant\nmanagers to assimilate, correlate and understand; in other words, for them to\nknow the global operation of the plant at any given time. At this point, the\nintelligent and Machine Learning (ML) approaches can give support for that\nneed, managing all the data and translating them into manageable, interpretable\nand explainable knowledge about how the WWTP plant is operating at a glance.\n  Here, an eXplainable Artificial Intelligence (XAI) based methodology is\nproposed and tested for a real WWTP, in order to extract explainable service\nknowledge concerning the operation modes of the WWTP managed by AQUAVALL, which\nis the public service in charge of the integral water cycle in the City Council\nof Valladolid (Castilla y Le\\'on, Spain). By applying well-known approaches of\nXAI and ML focused on the challenge of WWTP, it has been possible to summarize\na large number of historical databases through a few explained operation modes\nof the plant in a low-dimensional data space, showing the variables and\nfacility units involved in each case.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\uff08XAI\uff09\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u4ece\u6c61\u6c34\u5904\u7406\u5382\uff08WWTP\uff09\u7684\u5386\u53f2\u6570\u636e\u4e2d\u63d0\u53d6\u53ef\u89e3\u91ca\u7684\u64cd\u4f5c\u6a21\u5f0f\uff0c\u5e2e\u52a9\u7ba1\u7406\u4eba\u5458\u5feb\u901f\u7406\u89e3\u5de5\u5382\u8fd0\u884c\u72b6\u6001\u3002", "motivation": "\u968f\u7740\u6de1\u6c34\u9700\u6c42\u589e\u52a0\u548c\u6c61\u6c34\u5904\u7406\u5382\u6570\u636e\u590d\u6742\u5316\uff0c\u9700\u8981\u667a\u80fd\u65b9\u6cd5\u5e2e\u52a9\u7ba1\u7406\u4eba\u5458\u7406\u89e3\u5927\u91cf\u6570\u636e\u3002", "method": "\u91c7\u7528XAI\u548c\u673a\u5668\u5b66\u4e60\u6280\u672f\uff0c\u5206\u6790\u6c61\u6c34\u5904\u7406\u5382\u7684\u5386\u53f2\u6570\u636e\uff0c\u63d0\u53d6\u4f4e\u7ef4\u7a7a\u95f4\u4e2d\u7684\u64cd\u4f5c\u6a21\u5f0f\u3002", "result": "\u6210\u529f\u5c06\u5927\u91cf\u5386\u53f2\u6570\u636e\u603b\u7ed3\u4e3a\u5c11\u6570\u53ef\u89e3\u91ca\u7684\u64cd\u4f5c\u6a21\u5f0f\uff0c\u5e76\u8bc6\u522b\u51fa\u5173\u952e\u53d8\u91cf\u548c\u8bbe\u65bd\u5355\u5143\u3002", "conclusion": "XAI\u65b9\u6cd5\u80fd\u6709\u6548\u652f\u6301\u6c61\u6c34\u5904\u7406\u5382\u7684\u6570\u636e\u7ba1\u7406\u548c\u64cd\u4f5c\u7406\u89e3\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2506.05967", "pdf": "https://arxiv.org/pdf/2506.05967", "abs": "https://arxiv.org/abs/2506.05967", "authors": ["Katarzyna Kobalczyk", "Mihaela van der Schaar"], "title": "Preference Learning for AI Alignment: a Causal Perspective", "categories": ["cs.AI", "cs.LG", "stat.ML"], "comment": null, "summary": "Reward modelling from preference data is a crucial step in aligning large\nlanguage models (LLMs) with human values, requiring robust generalisation to\nnovel prompt-response pairs. In this work, we propose to frame this problem in\na causal paradigm, providing the rich toolbox of causality to identify the\npersistent challenges, such as causal misidentification, preference\nheterogeneity, and confounding due to user-specific factors. Inheriting from\nthe literature of causal inference, we identify key assumptions necessary for\nreliable generalisation and contrast them with common data collection\npractices. We illustrate failure modes of naive reward models and demonstrate\nhow causally-inspired approaches can improve model robustness. Finally, we\noutline desiderata for future research and practices, advocating targeted\ninterventions to address inherent limitations of observational data.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u7528\u56e0\u679c\u8303\u5f0f\u89e3\u51b3LLMs\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u5bf9\u9f50\u4e2d\u7684\u5956\u52b1\u5efa\u6a21\u95ee\u9898\uff0c\u5f3a\u8c03\u56e0\u679c\u5de5\u5177\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u5956\u52b1\u5efa\u6a21\u5728LLMs\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u5bf9\u9f50\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u9762\u4e34\u56e0\u679c\u8bef\u8bc6\u522b\u3001\u504f\u597d\u5f02\u8d28\u6027\u548c\u7528\u6237\u7279\u5b9a\u56e0\u7d20\u7b49\u6311\u6218\u3002", "method": "\u91c7\u7528\u56e0\u679c\u63a8\u7406\u6846\u67b6\uff0c\u8bc6\u522b\u53ef\u9760\u6cdb\u5316\u7684\u5173\u952e\u5047\u8bbe\uff0c\u5e76\u4e0e\u5e38\u89c1\u6570\u636e\u6536\u96c6\u5b9e\u8df5\u5bf9\u6bd4\u3002", "result": "\u5c55\u793a\u4e86\u6734\u7d20\u5956\u52b1\u6a21\u578b\u7684\u5931\u8d25\u6a21\u5f0f\uff0c\u5e76\u8bc1\u660e\u56e0\u679c\u65b9\u6cd5\u80fd\u63d0\u5347\u6a21\u578b\u9c81\u68d2\u6027\u3002", "conclusion": "\u547c\u5401\u672a\u6765\u7814\u7a76\u5173\u6ce8\u5e72\u9884\u63aa\u65bd\uff0c\u4ee5\u89e3\u51b3\u89c2\u6d4b\u6570\u636e\u7684\u56fa\u6709\u5c40\u9650\u6027\u3002"}}
{"id": "2506.06024", "pdf": "https://arxiv.org/pdf/2506.06024", "abs": "https://arxiv.org/abs/2506.06024", "authors": ["Deborah Pereg"], "title": "On Inverse Problems, Parameter Estimation, and Domain Generalization", "categories": ["cs.IT", "cs.LG", "math.IT"], "comment": null, "summary": "Signal restoration and inverse problems are key elements in most real-world\ndata science applications. In the past decades, with the emergence of machine\nlearning methods, inversion of measurements has become a popular step in almost\nall physical applications, which is normally executed prior to downstream tasks\nthat often involve parameter estimation. In this work, we analyze the general\nproblem of parameter estimation in an inverse problem setting. First, we\naddress the domain-shift problem by re-formulating it in direct relation with\nthe discrete parameter estimation analysis. We analyze a significant\nvulnerability in current attempts to enforce domain generalization, which we\ndubbed the Double Meaning Theorem. Our theoretical findings are experimentally\nillustrated for domain shift examples in image deblurring and speckle\nsuppression in medical imaging. We then proceed to a theoretical analysis of\nparameter estimation given observed measurements before and after data\nprocessing involving an inversion of the observations. We compare this setting\nfor invertible and non-invertible (degradation) processes. We distinguish\nbetween continuous and discrete parameter estimation, corresponding with\nregression and classification problems, respectively. Our theoretical findings\nalign with the well-known information-theoretic data processing inequality, and\nto a certain degree question the common misconception that data-processing for\ninversion, based on modern generative models that may often produce outstanding\nperceptual quality, will necessarily improve the following parameter estimation\nobjective. It is our hope that this paper will provide practitioners with\ndeeper insights that may be leveraged in the future for the development of more\nefficient and informed strategic system planning, critical in safety-sensitive\napplications.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u9006\u95ee\u9898\u4e2d\u7684\u53c2\u6570\u4f30\u8ba1\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u9886\u57df\u504f\u79fb\u7684\u91cd\u65b0\u5b9a\u4e49\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u9886\u57df\u6cdb\u5316\u65b9\u6cd5\u7684\u6f0f\u6d1e\uff08\u53cc\u4e49\u5b9a\u7406\uff09\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u53d1\u73b0\u3002", "motivation": "\u7814\u7a76\u9006\u95ee\u9898\u4e2d\u7684\u53c2\u6570\u4f30\u8ba1\uff0c\u89e3\u51b3\u9886\u57df\u504f\u79fb\u95ee\u9898\uff0c\u5e76\u63a2\u8ba8\u6570\u636e\u5904\u7406\u5bf9\u53c2\u6570\u4f30\u8ba1\u7684\u5f71\u54cd\u3002", "method": "\u91cd\u65b0\u5b9a\u4e49\u9886\u57df\u504f\u79fb\u95ee\u9898\uff0c\u5206\u6790\u53cc\u4e49\u5b9a\u7406\uff0c\u5e76\u901a\u8fc7\u56fe\u50cf\u53bb\u6a21\u7cca\u548c\u533b\u5b66\u6210\u50cf\u4e2d\u7684\u6591\u70b9\u6291\u5236\u5b9e\u9a8c\u9a8c\u8bc1\u7406\u8bba\u3002", "result": "\u7406\u8bba\u53d1\u73b0\u4e0e\u4fe1\u606f\u8bba\u6570\u636e\u5904\u7406\u4e0d\u7b49\u5f0f\u4e00\u81f4\uff0c\u8d28\u7591\u4e86\u57fa\u4e8e\u73b0\u4ee3\u751f\u6210\u6a21\u578b\u7684\u6570\u636e\u5904\u7406\u5fc5\u7136\u6539\u5584\u53c2\u6570\u4f30\u8ba1\u7684\u5e38\u89c1\u8bef\u89e3\u3002", "conclusion": "\u8bba\u6587\u4e3a\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u66f4\u6df1\u5165\u7684\u89c1\u89e3\uff0c\u6709\u52a9\u4e8e\u5728\u5b89\u5168\u654f\u611f\u5e94\u7528\u4e2d\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u7cfb\u7edf\u89c4\u5212\u7b56\u7565\u3002"}}
{"id": "2506.06027", "pdf": "https://arxiv.org/pdf/2506.06027", "abs": "https://arxiv.org/abs/2506.06027", "authors": ["Yuhao Sun", "Jiacheng Zhang", "Zesheng Ye", "Chaowei Xiao", "Feng Liu"], "title": "Sample-Specific Noise Injection For Diffusion-Based Adversarial Purification", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Diffusion-based purification (DBP) methods aim to remove adversarial noise\nfrom the input sample by first injecting Gaussian noise through a forward\ndiffusion process, and then recovering the clean example through a reverse\ngenerative process. In the above process, how much Gaussian noise is injected\nto the input sample is key to the success of DBP methods, which is controlled\nby a constant noise level $t^*$ for all samples in existing methods. In this\npaper, we discover that an optimal $t^*$ for each sample indeed could be\ndifferent. Intuitively, the cleaner a sample is, the less the noise it should\nbe injected, and vice versa. Motivated by this finding, we propose a new\nframework, called Sample-specific Score-aware Noise Injection (SSNI).\nSpecifically, SSNI uses a pre-trained score network to estimate how much a data\npoint deviates from the clean data distribution (i.e., score norms). Then,\nbased on the magnitude of score norms, SSNI applies a reweighting function to\nadaptively adjust $t^*$ for each sample, achieving sample-specific noise\ninjections. Empirically, incorporating our framework with existing DBP methods\nresults in a notable improvement in both accuracy and robustness on CIFAR-10\nand ImageNet-1K, highlighting the necessity to allocate distinct noise levels\nto different samples in DBP methods. Our code is available at:\nhttps://github.com/tmlr-group/SSNI.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6837\u672c\u7279\u5b9a\u7684\u566a\u58f0\u6ce8\u5165\u65b9\u6cd5\uff08SSNI\uff09\uff0c\u901a\u8fc7\u9884\u8bad\u7ec3\u7684\u8bc4\u5206\u7f51\u7edc\u81ea\u9002\u5e94\u8c03\u6574\u566a\u58f0\u6c34\u5e73\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6269\u6563\u51c0\u5316\u65b9\u6cd5\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u6269\u6563\u51c0\u5316\u65b9\u6cd5\u5bf9\u6240\u6709\u6837\u672c\u4f7f\u7528\u56fa\u5b9a\u7684\u566a\u58f0\u6c34\u5e73\uff0c\u800c\u7814\u7a76\u53d1\u73b0\u4e0d\u540c\u6837\u672c\u7684\u6700\u4f18\u566a\u58f0\u6c34\u5e73\u53ef\u80fd\u4e0d\u540c\u3002", "method": "SSNI\u5229\u7528\u9884\u8bad\u7ec3\u7684\u8bc4\u5206\u7f51\u7edc\u4f30\u8ba1\u6837\u672c\u504f\u79bb\u5e72\u51c0\u6570\u636e\u5206\u5e03\u7684\u7a0b\u5ea6\uff0c\u5e76\u6839\u636e\u8bc4\u5206\u8303\u6570\u81ea\u9002\u5e94\u8c03\u6574\u566a\u58f0\u6c34\u5e73\u3002", "result": "\u5728CIFAR-10\u548cImageNet-1K\u4e0a\uff0cSSNI\u663e\u8457\u63d0\u5347\u4e86\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u6837\u672c\u7279\u5b9a\u7684\u566a\u58f0\u5206\u914d\u662f\u6269\u6563\u51c0\u5316\u65b9\u6cd5\u7684\u5173\u952e\u6539\u8fdb\u65b9\u5411\u3002"}}
{"id": "2506.06041", "pdf": "https://arxiv.org/pdf/2506.06041", "abs": "https://arxiv.org/abs/2506.06041", "authors": ["Joscha Diehl", "Rasheed Ibraheem", "Leonard Schmitz", "Yue Wu"], "title": "Tensor-to-Tensor Models with Fast Iterated Sum Features", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Data in the form of images or higher-order tensors is ubiquitous in modern\ndeep learning applications. Owing to their inherent high dimensionality, the\nneed for subquadratic layers processing such data is even more pressing than\nfor sequence data. We propose a novel tensor-to-tensor layer with linear cost\nin the input size, utilizing the mathematical gadget of ``corner trees'' from\nthe field of permutation counting. In particular, for order-two tensors, we\nprovide an image-to-image layer that can be plugged into image processing\npipelines. On the one hand, our method can be seen as a higher-order\ngeneralization of state-space models. On the other hand, it is based on a\nmultiparameter generalization of the signature of iterated integrals (or sums).\nThe proposed tensor-to-tensor concept is used to build a neural network layer\ncalled the Fast Iterated Sums (FIS) layer which integrates seamlessly with\nother layer types. We demonstrate the usability of the FIS layer with both\nclassification and anomaly detection tasks. By replacing some layers of a\nsmaller ResNet architecture with FIS, a similar accuracy (with a difference of\nonly 0.1\\%) was achieved in comparison to a larger ResNet while reducing the\nnumber of trainable parameters and multi-add operations. The FIS layer was also\nused to build an anomaly detection model that achieved an average AUROC of\n97.3\\% on the texture images of the popular MVTec AD dataset. The processing\nand modelling codes are publicly available at\nhttps://github.com/diehlj/fast-iterated-sums.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u201c\u89d2\u6811\u201d\u6570\u5b66\u5de5\u5177\u7684\u65b0\u578b\u5f20\u91cf\u5230\u5f20\u91cf\u5c42\uff08FIS\u5c42\uff09\uff0c\u5177\u6709\u7ebf\u6027\u8ba1\u7b97\u6210\u672c\uff0c\u9002\u7528\u4e8e\u56fe\u50cf\u548c\u9ad8\u9636\u5f20\u91cf\u5904\u7406\u3002", "motivation": "\u9ad8\u7ef4\u6570\u636e\uff08\u5982\u56fe\u50cf\u6216\u5f20\u91cf\uff09\u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\u666e\u904d\u5b58\u5728\uff0c\u9700\u8981\u9ad8\u6548\u7684\u5b50\u4e8c\u6b21\u8ba1\u7b97\u5c42\u3002", "method": "\u5229\u7528\u201c\u89d2\u6811\u201d\u548c\u8fed\u4ee3\u79ef\u5206\uff08\u6216\u548c\uff09\u7684\u591a\u53c2\u6570\u6cdb\u5316\uff0c\u6784\u5efa\u4e86FIS\u5c42\uff0c\u53ef\u65e0\u7f1d\u96c6\u6210\u5230\u795e\u7ecf\u7f51\u7edc\u4e2d\u3002", "result": "\u5728\u5206\u7c7b\u548c\u5f02\u5e38\u68c0\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u66ff\u6362ResNet\u90e8\u5206\u5c42\u540e\u6027\u80fd\u63a5\u8fd1\u4f46\u53c2\u6570\u66f4\u5c11\uff0c\u5f02\u5e38\u68c0\u6d4bAUROC\u8fbe97.3%\u3002", "conclusion": "FIS\u5c42\u4e3a\u9ad8\u7ef4\u6570\u636e\u5904\u7406\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u517c\u5177\u6027\u80fd\u548c\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2506.06042", "pdf": "https://arxiv.org/pdf/2506.06042", "abs": "https://arxiv.org/abs/2506.06042", "authors": ["Taoran Yue", "Xiaojin Lu", "Jiaxi Cai", "Yuanping Chen", "Shibing Chu"], "title": "SDS-Net: Shallow-Deep Synergism-detection Network for infrared small target detection", "categories": ["cs.CV", "cs.LG"], "comment": "13 pages,9 figures, Submitted IEEE Transactions on Geoscience and\n  Remote Sensing", "summary": "Current CNN-based infrared small target detection(IRSTD) methods generally\noverlook the heterogeneity between shallow and deep features, leading to\ninefficient collaboration between shallow fine grained structural information\nand deep high-level semantic representations. Additionally, the dependency\nrelationships and fusion mechanisms across different feature hierarchies lack\nsystematic modeling, which fails to fully exploit the complementarity of\nmultilevel features. These limitations hinder IRSTD performance while incurring\nsubstantial computational costs. To address these challenges, this paper\nproposes a shallow-deep synergistic detection network (SDS-Net) that\nefficiently models multilevel feature representations to increase both the\ndetection accuracy and computational efficiency in IRSTD tasks. SDS-Net\nintroduces a dual-branch architecture that separately models the structural\ncharacteristics and semantic properties of features, effectively preserving\nshallow spatial details while capturing deep semantic representations, thereby\nachieving high-precision detection with significantly improved inference speed.\nFurthermore, the network incorporates an adaptive feature fusion module to\ndynamically model cross-layer feature correlations, enhancing overall feature\ncollaboration and representation capability. Comprehensive experiments on three\npublic datasets (NUAA-SIRST, NUDT-SIRST, and IRSTD-1K) demonstrate that SDS-Net\noutperforms state-of-the-art IRSTD methods while maintaining low computational\ncomplexity and high inference efficiency, showing superior detection\nperformance and broad application prospects. Our code will be made public at\nhttps://github.com/PhysiLearn/SDS-Net.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6d45\u5c42-\u6df1\u5c42\u534f\u540c\u68c0\u6d4b\u7f51\u7edc\uff08SDS-Net\uff09\uff0c\u901a\u8fc7\u53cc\u5206\u652f\u67b6\u6784\u548c\u81ea\u9002\u5e94\u7279\u5f81\u878d\u5408\u6a21\u5757\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7ea2\u5916\u5c0f\u76ee\u6807\u68c0\u6d4b\u7684\u7cbe\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u73b0\u6709CNN\u65b9\u6cd5\u5ffd\u89c6\u4e86\u6d45\u5c42\u4e0e\u6df1\u5c42\u7279\u5f81\u7684\u5f02\u8d28\u6027\uff0c\u5bfc\u81f4\u7279\u5f81\u534f\u4f5c\u4e0d\u8db3\uff0c\u5f71\u54cd\u4e86\u68c0\u6d4b\u6027\u80fd\u548c\u8ba1\u7b97\u6548\u7387\u3002", "method": "\u91c7\u7528\u53cc\u5206\u652f\u67b6\u6784\u5206\u522b\u5efa\u6a21\u7279\u5f81\u7684\u7ed3\u6784\u7279\u6027\u548c\u8bed\u4e49\u5c5e\u6027\uff0c\u5e76\u5f15\u5165\u81ea\u9002\u5e94\u7279\u5f81\u878d\u5408\u6a21\u5757\u52a8\u6001\u5efa\u6a21\u8de8\u5c42\u7279\u5f81\u76f8\u5173\u6027\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4f4e\u8ba1\u7b97\u590d\u6742\u6027\u548c\u9ad8\u63a8\u7406\u6548\u7387\u3002", "conclusion": "SDS-Net\u5728\u7ea2\u5916\u5c0f\u76ee\u6807\u68c0\u6d4b\u4e2d\u5c55\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u548c\u5e7f\u6cdb\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2506.06069", "pdf": "https://arxiv.org/pdf/2506.06069", "abs": "https://arxiv.org/abs/2506.06069", "authors": ["Maor Ashkenazi", "Ofir Brenner", "Tal Furman Shohet", "Eran Treister"], "title": "Zero-Shot Detection of LLM-Generated Code via Approximated Task Conditioning", "categories": ["cs.CL", "cs.LG"], "comment": "To appear in the Proceedings of ECML-PKDD 2025, Springer Lecture\n  Notes in Computer Science (LNCS)", "summary": "Detecting Large Language Model (LLM)-generated code is a growing challenge\nwith implications for security, intellectual property, and academic integrity.\nWe investigate the role of conditional probability distributions in improving\nzero-shot LLM-generated code detection, when considering both the code and the\ncorresponding task prompt that generated it. Our key insight is that when\nevaluating the probability distribution of code tokens using an LLM, there is\nlittle difference between LLM-generated and human-written code. However,\nconditioning on the task reveals notable differences. This contrasts with\nnatural language text, where differences exist even in the unconditional\ndistributions. Leveraging this, we propose a novel zero-shot detection approach\nthat approximates the original task used to generate a given code snippet and\nthen evaluates token-level entropy under the approximated task conditioning\n(ATC). We further provide a mathematical intuition, contextualizing our method\nrelative to previous approaches. ATC requires neither access to the generator\nLLM nor the original task prompts, making it practical for real-world\napplications. To the best of our knowledge, it achieves state-of-the-art\nresults across benchmarks and generalizes across programming languages,\nincluding Python, CPP, and Java. Our findings highlight the importance of\ntask-level conditioning for LLM-generated code detection. The supplementary\nmaterials and code are available at https://github.com/maorash/ATC, including\nthe dataset gathering implementation, to foster further research in this area.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6761\u4ef6\u6982\u7387\u5206\u5e03\u7684\u96f6\u6837\u672c\u68c0\u6d4b\u65b9\u6cd5\uff08ATC\uff09\uff0c\u7528\u4e8e\u533a\u5206LLM\u751f\u6210\u7684\u4ee3\u7801\u548c\u4eba\u7c7b\u7f16\u5199\u7684\u4ee3\u7801\uff0c\u901a\u8fc7\u4efb\u52a1\u7ea7\u6761\u4ef6\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u6548\u679c\u3002", "motivation": "\u968f\u7740LLM\u751f\u6210\u4ee3\u7801\u7684\u666e\u53ca\uff0c\u68c0\u6d4b\u5176\u6765\u6e90\u5bf9\u5b89\u5168\u3001\u77e5\u8bc6\u4ea7\u6743\u548c\u5b66\u672f\u8bda\u4fe1\u81f3\u5173\u91cd\u8981\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u4ee3\u7801\u548c\u751f\u6210\u4efb\u52a1\u7684\u6761\u4ef6\u6982\u7387\u5206\u5e03\u80fd\u6709\u6548\u533a\u5206LLM\u751f\u6210\u548c\u4eba\u7c7b\u7f16\u5199\u7684\u4ee3\u7801\u3002", "method": "\u63d0\u51faATC\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fd1\u4f3c\u751f\u6210\u4ee3\u7801\u7684\u4efb\u52a1\u6761\u4ef6\uff0c\u8bc4\u4f30\u4ee4\u724c\u7ea7\u71b5\uff0c\u65e0\u9700\u8bbf\u95ee\u751f\u6210LLM\u6216\u539f\u59cb\u4efb\u52a1\u63d0\u793a\u3002", "result": "ATC\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u652f\u6301\u591a\u79cd\u7f16\u7a0b\u8bed\u8a00\uff08\u5982Python\u3001CPP\u3001Java\uff09\u3002", "conclusion": "\u4efb\u52a1\u7ea7\u6761\u4ef6\u5bf9LLM\u751f\u6210\u4ee3\u7801\u68c0\u6d4b\u81f3\u5173\u91cd\u8981\uff0cATC\u65b9\u6cd5\u5b9e\u7528\u4e14\u9ad8\u6548\uff0c\u4ee3\u7801\u548c\u6570\u636e\u5df2\u5f00\u6e90\u4ee5\u4fc3\u8fdb\u7814\u7a76\u3002"}}
{"id": "2506.06072", "pdf": "https://arxiv.org/pdf/2506.06072", "abs": "https://arxiv.org/abs/2506.06072", "authors": ["Hongyi Zhou", "Weiran Liao", "Xi Huang", "Yucheng Tang", "Fabian Otto", "Xiaogang Jia", "Xinkai Jiang", "Simon Hilber", "Ge Li", "Qian Wang", "\u00d6mer Erdin\u00e7 Ya\u011fmurlu", "Nils Blank", "Moritz Reuss", "Rudolf Lioutikov"], "title": "BEAST: Efficient Tokenization of B-Splines Encoded Action Sequences for Imitation Learning", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "We present the B-spline Encoded Action Sequence Tokenizer (BEAST), a novel\naction tokenizer that encodes action sequences into compact discrete or\ncontinuous tokens using B-splines. In contrast to existing action tokenizers\nbased on vector quantization or byte pair encoding, BEAST requires no separate\ntokenizer training and consistently produces tokens of uniform length, enabling\nfast action sequence generation via parallel decoding. Leveraging our B-spline\nformulation, BEAST inherently ensures generating smooth trajectories without\ndiscontinuities between adjacent segments. We extensively evaluate BEAST by\nintegrating it with three distinct model architectures: a Variational\nAutoencoder (VAE) with continuous tokens, a decoder-only Transformer with\ndiscrete tokens, and Florence-2, a pretrained Vision-Language Model with an\nencoder-decoder architecture, demonstrating BEAST's compatibility and\nscalability with large pretrained models. We evaluate BEAST across three\nestablished benchmarks consisting of 166 simulated tasks and on three distinct\nrobot settings with a total of 8 real-world tasks. Experimental results\ndemonstrate that BEAST (i) significantly reduces both training and inference\ncomputational costs, and (ii) consistently generates smooth, high-frequency\ncontrol signals suitable for continuous control tasks while (iii) reliably\nachieves competitive task success rates compared to state-of-the-art methods.", "AI": {"tldr": "BEAST\u662f\u4e00\u79cd\u57fa\u4e8eB\u6837\u6761\u7684\u52a8\u4f5c\u5e8f\u5217\u6807\u8bb0\u5668\uff0c\u65e0\u9700\u5355\u72ec\u8bad\u7ec3\u6807\u8bb0\u5668\uff0c\u652f\u6301\u5e76\u884c\u89e3\u7801\uff0c\u751f\u6210\u5e73\u6ed1\u8f68\u8ff9\uff0c\u5e76\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u52a8\u4f5c\u6807\u8bb0\u5668\uff08\u5982\u5411\u91cf\u91cf\u5316\u6216\u5b57\u8282\u5bf9\u7f16\u7801\uff09\u9700\u8981\u5355\u72ec\u8bad\u7ec3\u4e14\u6807\u8bb0\u957f\u5ea6\u4e0d\u4e00\u81f4\uff0cBEAST\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u5229\u7528B\u6837\u6761\u7f16\u7801\u52a8\u4f5c\u5e8f\u5217\u4e3a\u7d27\u51d1\u7684\u79bb\u6563\u6216\u8fde\u7eed\u6807\u8bb0\uff0c\u652f\u6301\u5e76\u884c\u89e3\u7801\uff0c\u786e\u4fdd\u8f68\u8ff9\u5e73\u6ed1\u3002", "result": "\u5728166\u4e2a\u6a21\u62df\u4efb\u52a1\u548c8\u4e2a\u771f\u5b9e\u4efb\u52a1\u4e2d\uff0cBEAST\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u751f\u6210\u5e73\u6ed1\u63a7\u5236\u4fe1\u53f7\uff0c\u5e76\u4fdd\u6301\u9ad8\u4efb\u52a1\u6210\u529f\u7387\u3002", "conclusion": "BEAST\u662f\u4e00\u79cd\u9ad8\u6548\u3001\u517c\u5bb9\u6027\u5f3a\u4e14\u6027\u80fd\u4f18\u8d8a\u7684\u52a8\u4f5c\u6807\u8bb0\u5668\uff0c\u9002\u7528\u4e8e\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u3002"}}
{"id": "2506.06083", "pdf": "https://arxiv.org/pdf/2506.06083", "abs": "https://arxiv.org/abs/2506.06083", "authors": ["Lama Alqazlan", "Zheng Fang", "Michael Castelle", "Rob Procter"], "title": "A Novel, Human-in-the-Loop Computational Grounded Theory Framework for Big Social Data", "categories": ["cs.HC", "cs.IR", "cs.LG", "H.4; I.7; J.4"], "comment": "24 pages, 2 figures, 15 tables", "summary": "The availability of big data has significantly influenced the possibilities\nand methodological choices for conducting large-scale behavioural and social\nscience research. In the context of qualitative data analysis, a major\nchallenge is that conventional methods require intensive manual labour and are\noften impractical to apply to large datasets. One effective way to address this\nissue is by integrating emerging computational methods to overcome scalability\nlimitations. However, a critical concern for researchers is the trustworthiness\nof results when Machine Learning (ML) and Natural Language Processing (NLP)\ntools are used to analyse such data. We argue that confidence in the\ncredibility and robustness of results depends on adopting a 'human-in-the-loop'\nmethodology that is able to provide researchers with control over the\nanalytical process, while retaining the benefits of using ML and NLP. With this\nin mind, we propose a novel methodological framework for Computational Grounded\nTheory (CGT) that supports the analysis of large qualitative datasets, while\nmaintaining the rigour of established Grounded Theory (GT) methodologies. To\nillustrate the framework's value, we present the results of testing it on a\ndataset collected from Reddit in a study aimed at understanding tutors'\nexperiences in the gig economy.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4eba\u7c7b\u76d1\u7763\u4e0e\u8ba1\u7b97\u65b9\u6cd5\u7684\u6846\u67b6\uff08CGT\uff09\uff0c\u7528\u4e8e\u5206\u6790\u5927\u89c4\u6a21\u5b9a\u6027\u6570\u636e\uff0c\u540c\u65f6\u4fdd\u6301\u4f20\u7edf\u624e\u6839\u7406\u8bba\u7684\u4e25\u8c28\u6027\u3002", "motivation": "\u5927\u6570\u636e\u65f6\u4ee3\u4e0b\uff0c\u4f20\u7edf\u5b9a\u6027\u5206\u6790\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u4e14\u8ba1\u7b97\u65b9\u6cd5\u7684\u53ef\u4fe1\u5ea6\u95ee\u9898\u4e9f\u5f85\u89e3\u51b3\u3002", "method": "\u63d0\u51fa\u2018\u4eba\u5728\u5faa\u73af\u2019\uff08human-in-the-loop\uff09\u65b9\u6cd5\uff0c\u7ed3\u5408ML\u548cNLP\u5de5\u5177\uff0c\u5f00\u53d1\u4e86\u8ba1\u7b97\u624e\u6839\u7406\u8bba\uff08CGT\uff09\u6846\u67b6\u3002", "result": "\u5728Reddit\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\u4e86\u8be5\u6846\u67b6\uff0c\u6210\u529f\u5206\u6790\u4e86\u96f6\u5de5\u7ecf\u6d4e\u4e2d\u5bfc\u5e08\u7684\u7ecf\u9a8c\u3002", "conclusion": "CGT\u6846\u67b6\u80fd\u591f\u6709\u6548\u89e3\u51b3\u5927\u89c4\u6a21\u5b9a\u6027\u6570\u636e\u5206\u6790\u7684\u53ef\u6269\u5c55\u6027\u548c\u53ef\u4fe1\u5ea6\u95ee\u9898\u3002"}}
{"id": "2506.06087", "pdf": "https://arxiv.org/pdf/2506.06087", "abs": "https://arxiv.org/abs/2506.06087", "authors": ["Yuga Hikida", "Ayush Bharti", "Niall Jeffrey", "Fran\u00e7ois-Xavier Briol"], "title": "Multilevel neural simulation-based inference", "categories": ["stat.ML", "astro-ph.CO", "astro-ph.IM", "cs.LG", "stat.CO"], "comment": null, "summary": "Neural simulation-based inference (SBI) is a popular set of methods for\nBayesian inference when models are only available in the form of a simulator.\nThese methods are widely used in the sciences and engineering, where writing\ndown a likelihood can be significantly more challenging than constructing a\nsimulator. However, the performance of neural SBI can suffer when simulators\nare computationally expensive, thereby limiting the number of simulations that\ncan be performed. In this paper, we propose a novel approach to neural SBI\nwhich leverages multilevel Monte Carlo techniques for settings where several\nsimulators of varying cost and fidelity are available. We demonstrate through\nboth theoretical analysis and extensive experiments that our method can\nsignificantly enhance the accuracy of SBI methods given a fixed computational\nbudget.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u7ea7\u8499\u7279\u5361\u7f57\u6280\u672f\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u63d0\u5347\u795e\u7ecf\u6a21\u62df\u63a8\u65ad\uff08SBI\uff09\u5728\u591a\u4e2a\u6a21\u62df\u5668\u53ef\u7528\u65f6\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u795e\u7ecfSBI\u65b9\u6cd5\u5728\u6a21\u62df\u5668\u8ba1\u7b97\u6210\u672c\u9ad8\u65f6\u6027\u80fd\u53d7\u9650\uff0c\u9650\u5236\u4e86\u6a21\u62df\u6b21\u6570\u3002", "method": "\u5229\u7528\u591a\u7ea7\u8499\u7279\u5361\u7f57\u6280\u672f\uff0c\u7ed3\u5408\u4e0d\u540c\u6210\u672c\u548c\u4fdd\u771f\u5ea6\u7684\u6a21\u62df\u5668\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u56fa\u5b9a\u8ba1\u7b97\u9884\u7b97\u4e0b\u663e\u8457\u63d0\u9ad8\u4e86SBI\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u65b0\u65b9\u6cd5\u4e3a\u9ad8\u6210\u672c\u6a21\u62df\u5668\u4e0b\u7684SBI\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.06092", "pdf": "https://arxiv.org/pdf/2506.06092", "abs": "https://arxiv.org/abs/2506.06092", "authors": ["Nadine Garibli", "Mayank Patwari", "Bence Csiba", "Yi Wei", "Kostas Sidiropoulos"], "title": "LinGuinE: Longitudinal Guidance Estimation for Volumetric Lung Tumour Segmentation", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": "10 pages, 3 figures", "summary": "Segmentation of lung gross tumour volumes is an important first step in\nradiotherapy and surgical intervention, and is starting to play a role in\nassessing chemotherapy response. Response to a drug is measured by tracking the\ntumour volumes over a series of CT scans over a time period i.e. a longitudinal\nstudy. However, there currently exist few solutions for automated or\nsemi-automated longitudinal tumour segmentation. This paper introduces\nLinGuinE, an automated method to segment a longitudinal series of lung tumours.\nA radiologist must provide an initial input, indicating the location of the\ntumour in a CT scan at an arbitrary time point. LinGuinE samples points inside\nthis tumour and propagates them to another time point using rigid registration.\nA click validity classifier selects points which still fall within the tumour;\nthese are used to automatically create a segmentation in the new time point. We\ntest LinGuinE on a dataset acquired from a phase 3 clinical trial for lung\ntumours and the publicly available 4-D lung CBCT dataset. We find that LinGuinE\nimproves the Dice on both test sets by over 20% (p< 0.05) across 63\nlongitudinal studies. We show that any time point can be used as a starting\npoint, conduct ablation experiments, and find that our LinGuinE setup yields\nthe best results on both test datasets.", "AI": {"tldr": "LinGuinE\u662f\u4e00\u79cd\u81ea\u52a8\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u5206\u5272\u80ba\u90e8\u80bf\u7624\u7684\u7eb5\u5411CT\u626b\u63cf\u5e8f\u5217\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5206\u5272\u7cbe\u5ea6\u3002", "motivation": "\u76ee\u524d\u7f3a\u4e4f\u81ea\u52a8\u5316\u6216\u534a\u81ea\u52a8\u5316\u7684\u7eb5\u5411\u80bf\u7624\u5206\u5272\u89e3\u51b3\u65b9\u6848\uff0c\u800c\u8fd9\u662f\u8bc4\u4f30\u5316\u7597\u53cd\u5e94\u7684\u5173\u952e\u6b65\u9aa4\u3002", "method": "\u901a\u8fc7\u521a\u6027\u914d\u51c6\u548c\u70b9\u51fb\u6709\u6548\u6027\u5206\u7c7b\u5668\uff0c\u4ece\u521d\u59cb\u80bf\u7624\u6807\u8bb0\u70b9\u4f20\u64ad\u5230\u5176\u4ed6\u65f6\u95f4\u70b9\uff0c\u5b9e\u73b0\u81ea\u52a8\u5206\u5272\u3002", "result": "\u5728\u4e24\u4e2a\u6d4b\u8bd5\u6570\u636e\u96c6\u4e0a\uff0cLinGuinE\u5c06Dice\u7cfb\u6570\u63d0\u9ad8\u4e8620%\u4ee5\u4e0a\uff08p<0.05\uff09\u3002", "conclusion": "LinGuinE\u5728\u7eb5\u5411\u80bf\u7624\u5206\u5272\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4e14\u8d77\u59cb\u65f6\u95f4\u70b9\u7075\u6d3b\u3002"}}
{"id": "2506.06094", "pdf": "https://arxiv.org/pdf/2506.06094", "abs": "https://arxiv.org/abs/2506.06094", "authors": ["Elim Kwan", "Rehman Qureshi", "Liam Fletcher", "Colin Laganier", "Victoria Nockles", "Richard Walters"], "title": "On-board Mission Replanning for Adaptive Cooperative Multi-Robot Systems", "categories": ["cs.RO", "cs.LG"], "comment": "9 pages, 5 figures, 1 table", "summary": "Cooperative autonomous robotic systems have significant potential for\nexecuting complex multi-task missions across space, air, ground, and maritime\ndomains. But they commonly operate in remote, dynamic and hazardous\nenvironments, requiring rapid in-mission adaptation without reliance on fragile\nor slow communication links to centralised compute. Fast, on-board replanning\nalgorithms are therefore needed to enhance resilience. Reinforcement Learning\nshows strong promise for efficiently solving mission planning tasks when\nformulated as Travelling Salesperson Problems (TSPs), but existing methods: 1)\nare unsuitable for replanning, where agents do not start at a single location;\n2) do not allow cooperation between agents; 3) are unable to model tasks with\nvariable durations; or 4) lack practical considerations for on-board\ndeployment. Here we define the Cooperative Mission Replanning Problem as a\nnovel variant of multiple TSP with adaptations to overcome these issues, and\ndevelop a new encoder/decoder-based model using Graph Attention Networks and\nAttention Models to solve it effectively and efficiently. Using a simple\nexample of cooperative drones, we show our replanner consistently (90% of the\ntime) maintains performance within 10% of the state-of-the-art LKH3 heuristic\nsolver, whilst running 85-370 times faster on a Raspberry Pi. This work paves\nthe way for increased resilience in autonomous multi-agent systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u5feb\u901f\u91cd\u89c4\u5212\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u534f\u540c\u4efb\u52a1\u4e2d\u7684\u52a8\u6001\u91cd\u89c4\u5212\u95ee\u9898\uff0c\u5e76\u5728\u6027\u80fd\u548c\u901f\u5ea6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u590d\u6742\u73af\u5883\u4e2d\u6267\u884c\u4efb\u52a1\u65f6\uff0c\u9700\u8981\u5feb\u901f\u9002\u5e94\u52a8\u6001\u53d8\u5316\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u91cd\u89c4\u5212\u3001\u534f\u4f5c\u3001\u4efb\u52a1\u65f6\u957f\u5efa\u6a21\u548c\u5b9e\u9645\u90e8\u7f72\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u65c5\u884c\u5546\u95ee\u9898\u53d8\u4f53\uff0c\u5e76\u5f00\u53d1\u4e86\u57fa\u4e8e\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\u548c\u6ce8\u610f\u529b\u6a21\u578b\u7684\u7f16\u7801\u5668/\u89e3\u7801\u5668\u6a21\u578b\u3002", "result": "\u5728\u65e0\u4eba\u673a\u534f\u540c\u4efb\u52a1\u4e2d\uff0c\u8be5\u7b97\u6cd590%\u7684\u60c5\u51b5\u4e0b\u6027\u80fd\u63a5\u8fd1\u6700\u4f18\u89e3\uff0c\u4e14\u5728\u6811\u8393\u6d3e\u4e0a\u8fd0\u884c\u901f\u5ea6\u5feb85-370\u500d\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u81ea\u4e3b\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.06096", "pdf": "https://arxiv.org/pdf/2506.06096", "abs": "https://arxiv.org/abs/2506.06096", "authors": ["Zijian Yang", "Minh-Nghia Phan", "Ralf Schl\u00fcter", "Hermann Ney"], "title": "Label-Context-Dependent Internal Language Model Estimation for CTC", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "comment": "accepted to Interspeech 2025", "summary": "Although connectionist temporal classification (CTC) has the label context\nindependence assumption, it can still implicitly learn a context-dependent\ninternal language model (ILM) due to modern powerful encoders. In this work, we\ninvestigate the implicit context dependency modeled in the ILM of CTC. To this\nend, we propose novel context-dependent ILM estimation methods for CTC based on\nknowledge distillation (KD) with theoretical justifications. Furthermore, we\nintroduce two regularization methods for KD. We conduct experiments on\nLibrispeech and TED-LIUM Release 2 datasets for in-domain and cross-domain\nevaluation, respectively. Experimental results show that context-dependent ILMs\noutperform the context-independent priors in cross-domain evaluation,\nindicating that CTC learns a context-dependent ILM. The proposed label-level KD\nwith smoothing method surpasses other ILM estimation approaches, with more than\n13% relative improvement in word error rate compared to shallow fusion.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86CTC\uff08\u8fde\u63a5\u65f6\u5e8f\u5206\u7c7b\uff09\u4e2d\u9690\u5f0f\u4e0a\u4e0b\u6587\u4f9d\u8d56\u7684\u5185\u90e8\u8bed\u8a00\u6a21\u578b\uff08ILM\uff09\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u77e5\u8bc6\u84b8\u998f\uff08KD\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5c3d\u7ba1CTC\u5047\u8bbe\u6807\u7b7e\u4e0a\u4e0b\u6587\u72ec\u7acb\uff0c\u4f46\u73b0\u4ee3\u5f3a\u5927\u7f16\u7801\u5668\u4ecd\u80fd\u9690\u5f0f\u5b66\u4e60\u4e0a\u4e0b\u6587\u4f9d\u8d56\u7684ILM\u3002\u672c\u6587\u65e8\u5728\u63a2\u7a76CTC\u4e2dILM\u7684\u9690\u5f0f\u4e0a\u4e0b\u6587\u4f9d\u8d56\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u77e5\u8bc6\u84b8\u998f\uff08KD\uff09\u7684\u4e0a\u4e0b\u6587\u4f9d\u8d56ILM\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5e76\u5f15\u5165\u4e24\u79cd\u6b63\u5219\u5316\u65b9\u6cd5\u3002\u5b9e\u9a8c\u5728Librispeech\u548cTED-LIUM Release 2\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0a\u4e0b\u6587\u4f9d\u8d56\u7684ILM\u5728\u8de8\u57df\u8bc4\u4f30\u4e2d\u4f18\u4e8e\u4e0a\u4e0b\u6587\u72ec\u7acb\u7684\u5148\u9a8c\u6a21\u578b\uff0c\u4e14\u63d0\u51fa\u7684\u6807\u7b7e\u7ea7KD\u5e73\u6ed1\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u8bcd\u9519\u8bef\u7387\u76f8\u5bf9\u964d\u4f4e13%\u4ee5\u4e0a\u3002", "conclusion": "CTC\u786e\u5b9e\u5b66\u4e60\u4e86\u4e0a\u4e0b\u6587\u4f9d\u8d56\u7684ILM\uff0c\u63d0\u51fa\u7684KD\u65b9\u6cd5\u5728\u8de8\u57df\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2506.06125", "pdf": "https://arxiv.org/pdf/2506.06125", "abs": "https://arxiv.org/abs/2506.06125", "authors": ["Hamza Fawzi", "Omar Fawzi"], "title": "Convergence of linear programming hierarchies for Gibbs states of spin systems", "categories": ["math.OC", "cs.IT", "cs.LG", "math.IT", "math.PR"], "comment": "11 pages", "summary": "We consider the problem of computing expectation values of local functions\nunder the Gibbs distribution of a spin system. In particular, we study two\nfamilies of linear programming hierarchies for this problem. The first\nhierarchy imposes local spin flip equalities and has been considered in the\nbootstrap literature in high energy physics. For this hierarchy, we prove fast\nconvergence under a spatial mixing (decay of correlations) condition. This\ncondition is satisfied for example above the critical temperature for Ising\nmodels on a $d$-dimensional grid. The second hierarchy is based on a Markov\nchain having the Gibbs state as a fixed point and has been studied in the\noptimization literature and more recently in the bootstrap literature. For this\nhierarchy, we prove fast convergence provided the Markov chain mixes rapidly.\nBoth hierarchies lead to an $\\varepsilon$-approximation for local expectation\nvalues using a linear program of size quasi-polynomial in $n/\\varepsilon$,\nwhere $n$ is the total number of sites, provided the interactions can be\nembedded in a $d$-dimensional grid with constant $d$. Compared to standard\nMonte Carlo methods, an advantage of this approach is that it always (i.e., for\nany system) outputs rigorous upper and lower bounds on the expectation value of\ninterest, without needing an a priori analysis of the convergence speed.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u8ba1\u7b97\u81ea\u65cb\u7cfb\u7edfGibbs\u5206\u5e03\u4e0b\u5c40\u90e8\u51fd\u6570\u671f\u671b\u503c\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u7ebf\u6027\u89c4\u5212\u5c42\u6b21\u7ed3\u6784\uff0c\u5e76\u8bc1\u660e\u4e86\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u7684\u5feb\u901f\u6536\u655b\u6027\u3002", "motivation": "\u89e3\u51b3\u5728\u81ea\u65cb\u7cfb\u7edf\u4e2d\u8ba1\u7b97\u5c40\u90e8\u51fd\u6570\u671f\u671b\u503c\u7684\u6548\u7387\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u9ad8\u7ef4\u7f51\u683c\u4e2d\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u79cd\u7ebf\u6027\u89c4\u5212\u5c42\u6b21\u7ed3\u6784\uff1a\u7b2c\u4e00\u79cd\u57fa\u4e8e\u5c40\u90e8\u81ea\u65cb\u7ffb\u8f6c\u7b49\u5f0f\uff0c\u7b2c\u4e8c\u79cd\u57fa\u4e8e\u9a6c\u5c14\u53ef\u592b\u94fe\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u7a7a\u95f4\u6df7\u5408\u6761\u4ef6\u6216\u9a6c\u5c14\u53ef\u592b\u94fe\u5feb\u901f\u6df7\u5408\u6761\u4ef6\u4e0b\uff0c\u4e24\u79cd\u5c42\u6b21\u7ed3\u6784\u80fd\u5feb\u901f\u6536\u655b\uff0c\u5e76\u63d0\u4f9b\u4e25\u683c\u7684\u4e0a\u4e0b\u754c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u65e0\u9700\u9884\u5148\u5206\u6790\u6536\u655b\u901f\u5ea6\u7684\u60c5\u51b5\u4e0b\uff0c\u80fd\u9ad8\u6548\u4e14\u4e25\u683c\u5730\u8fd1\u4f3c\u5c40\u90e8\u671f\u671b\u503c\u3002"}}
{"id": "2506.06134", "pdf": "https://arxiv.org/pdf/2506.06134", "abs": "https://arxiv.org/abs/2506.06134", "authors": ["Veronica Centorrino", "Francesco Bullo", "Giovanni Russo"], "title": "Similarity Matching Networks: Hebbian Learning and Convergence Over Multiple Time Scales", "categories": ["q-bio.NC", "cs.LG", "math.OC"], "comment": "28 pages, 9 figures", "summary": "A recent breakthrough in biologically-plausible normative frameworks for\ndimensionality reduction is based upon the similarity matching cost function\nand the low-rank matrix approximation problem. Despite clear biological\ninterpretation, successful application in several domains, and experimental\nvalidation, a formal complete convergence analysis remains elusive. Building on\nthis framework, we consider and analyze a continuous-time neural network, the\n\\emph{similarity matching network}, for principal subspace projection. Derived\nfrom a min-max-min objective, this biologically-plausible network consists of\nthree coupled dynamics evolving at different time scales: neural dynamics,\nlateral synaptic dynamics, and feedforward synaptic dynamics at the fast,\nintermediate, and slow time scales, respectively. The feedforward and lateral\nsynaptic dynamics consist of Hebbian and anti-Hebbian learning rules,\nrespectively. By leveraging a multilevel optimization framework, we prove\nconvergence of the dynamics in the offline setting. Specifically, at the first\nlevel (fast time scale), we show strong convexity of the cost function and\nglobal exponential convergence of the corresponding gradient-flow dynamics. At\nthe second level (intermediate time scale), we prove strong concavity of the\ncost function and exponential convergence of the corresponding gradient-flow\ndynamics within the space of positive definite matrices. At the third and final\nlevel (slow time scale), we study a non-convex and non-smooth cost function,\nprovide explicit expressions for its global minima, and prove almost sure\nconvergence of the corresponding gradient-flow dynamics to the global minima.\nThese results rely on two empirically motivated conjectures that are supported\nby thorough numerical experiments. Finally, we validate the effectiveness of\nour approach via a numerical example.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u76f8\u4f3c\u6027\u5339\u914d\u7684\u8fde\u7eed\u65f6\u95f4\u795e\u7ecf\u7f51\u7edc\uff0c\u7528\u4e8e\u4e3b\u6210\u5206\u5b50\u7a7a\u95f4\u6295\u5f71\uff0c\u5e76\u901a\u8fc7\u591a\u7ea7\u4f18\u5316\u6846\u67b6\u8bc1\u660e\u4e86\u5176\u6536\u655b\u6027\u3002", "motivation": "\u5c3d\u7ba1\u76f8\u4f3c\u6027\u5339\u914d\u6210\u672c\u51fd\u6570\u5728\u751f\u7269\u5b66\u89e3\u91ca\u548c\u5e94\u7528\u4e0a\u53d6\u5f97\u4e86\u6210\u529f\uff0c\u4f46\u5176\u5b8c\u6574\u7684\u6536\u655b\u5206\u6790\u5c1a\u672a\u89e3\u51b3\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u795e\u7ecf\u52a8\u6001\u3001\u4fa7\u5411\u7a81\u89e6\u52a8\u6001\u548c\u524d\u9988\u7a81\u89e6\u52a8\u6001\u7684\u4e09\u5c42\u52a8\u6001\u7f51\u7edc\uff0c\u5206\u522b\u5bf9\u5e94\u5feb\u3001\u4e2d\u3001\u6162\u4e09\u4e2a\u65f6\u95f4\u5c3a\u5ea6\uff0c\u5e76\u5229\u7528\u591a\u7ea7\u4f18\u5316\u6846\u67b6\u5206\u6790\u5176\u6536\u655b\u6027\u3002", "result": "\u5728\u5feb\u65f6\u95f4\u5c3a\u5ea6\u4e0a\u8bc1\u660e\u4e86\u5f3a\u51f8\u6027\u548c\u5168\u5c40\u6307\u6570\u6536\u655b\uff1b\u5728\u4e2d\u65f6\u95f4\u5c3a\u5ea6\u4e0a\u8bc1\u660e\u4e86\u5f3a\u51f9\u6027\u548c\u6307\u6570\u6536\u655b\uff1b\u5728\u6162\u65f6\u95f4\u5c3a\u5ea6\u4e0a\u8bc1\u660e\u4e86\u51e0\u4e4e\u5fc5\u7136\u6536\u655b\u5230\u5168\u5c40\u6700\u5c0f\u503c\u3002", "conclusion": "\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u586b\u8865\u4e86\u76f8\u4f3c\u6027\u5339\u914d\u6846\u67b6\u6536\u655b\u5206\u6790\u7684\u7a7a\u767d\u3002"}}
{"id": "2506.06155", "pdf": "https://arxiv.org/pdf/2506.06155", "abs": "https://arxiv.org/abs/2506.06155", "authors": ["Wenyuan Li", "Shunlin Liang", "Yuxiang Zhang", "Liqin Liu", "Keyan Chen", "Yongzhe Chen", "Han Ma", "Jianglei Xu", "Yichuan Ma", "Shikang Guan", "Zhenwei Shi"], "title": "Fine-grained Hierarchical Crop Type Classification from Integrated Hyperspectral EnMAP Data and Multispectral Sentinel-2 Time Series: A Large-scale Dataset and Dual-stream Transformer Method", "categories": ["cs.CV", "cs.LG"], "comment": "27 pages, 12 figures", "summary": "Fine-grained crop type classification serves as the fundamental basis for\nlarge-scale crop mapping and plays a vital role in ensuring food security. It\nrequires simultaneous capture of both phenological dynamics (obtained from\nmulti-temporal satellite data like Sentinel-2) and subtle spectral variations\n(demanding nanometer-scale spectral resolution from hyperspectral imagery).\nResearch combining these two modalities remains scarce currently due to\nchallenges in hyperspectral data acquisition and crop types annotation costs.\nTo address these issues, we construct a hierarchical hyperspectral crop dataset\n(H2Crop) by integrating 30m-resolution EnMAP hyperspectral data with Sentinel-2\ntime series. With over one million annotated field parcels organized in a\nfour-tier crop taxonomy, H2Crop establishes a vital benchmark for fine-grained\nagricultural crop classification and hyperspectral image processing. We propose\na dual-stream Transformer architecture that synergistically processes these\nmodalities. It coordinates two specialized pathways: a spectral-spatial\nTransformer extracts fine-grained signatures from hyperspectral EnMAP data,\nwhile a temporal Swin Transformer extracts crop growth patterns from Sentinel-2\ntime series. The designed hierarchical classification head with hierarchical\nfusion then simultaneously delivers multi-level crop type classification across\nall taxonomic tiers. Experiments demonstrate that adding hyperspectral EnMAP\ndata to Sentinel-2 time series yields a 4.2% average F1-scores improvement\n(peaking at 6.3%). Extensive comparisons also confirm our method's higher\naccuracy over existing deep learning approaches for crop type classification\nand the consistent benefits of hyperspectral data across varying temporal\nwindows and crop change scenarios. Codes and dataset are available at\nhttps://github.com/flyakon/H2Crop.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u6d41Transformer\u67b6\u6784\uff0c\u7ed3\u5408\u9ad8\u5149\u8c31EnMAP\u6570\u636e\u548cSentinel-2\u65f6\u95f4\u5e8f\u5217\uff0c\u7528\u4e8e\u7ec6\u7c92\u5ea6\u4f5c\u7269\u5206\u7c7b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5206\u7c7b\u7cbe\u5ea6\u3002", "motivation": "\u7ec6\u7c92\u5ea6\u4f5c\u7269\u5206\u7c7b\u5bf9\u5927\u89c4\u6a21\u4f5c\u7269\u5236\u56fe\u548c\u7cae\u98df\u5b89\u5168\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u56e0\u9ad8\u5149\u8c31\u6570\u636e\u83b7\u53d6\u548c\u6807\u6ce8\u6210\u672c\u9ad8\u800c\u7a00\u7f3a\u3002", "method": "\u6784\u5efa\u4e86H2Crop\u6570\u636e\u96c6\uff0c\u63d0\u51fa\u53cc\u6d41Transformer\u67b6\u6784\uff0c\u5206\u522b\u5904\u7406\u9ad8\u5149\u8c31\u6570\u636e\u7684\u7cbe\u7ec6\u5149\u8c31\u7279\u5f81\u548cSentinel-2\u65f6\u95f4\u5e8f\u5217\u7684\u4f5c\u7269\u751f\u957f\u6a21\u5f0f\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u52a0\u5165\u9ad8\u5149\u8c31\u6570\u636e\u540e\uff0cF1\u5206\u6570\u5e73\u5747\u63d0\u53474.2%\uff0c\u6700\u9ad8\u8fbe6.3%\uff0c\u4e14\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u3002", "conclusion": "\u9ad8\u5149\u8c31\u6570\u636e\u5728\u4f5c\u7269\u5206\u7c7b\u4e2d\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u4e3a\u7ec6\u7c92\u5ea6\u519c\u4e1a\u5206\u7c7b\u548c\u9ad8\u5149\u8c31\u56fe\u50cf\u5904\u7406\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u51c6\u3002"}}
{"id": "2506.06202", "pdf": "https://arxiv.org/pdf/2506.06202", "abs": "https://arxiv.org/abs/2506.06202", "authors": ["Renato Cordeiro Ferreira", "Rowanne Trapmann", "Willem-Jan van den Heuvel"], "title": "MLOps with Microservices: A Case Study on the Maritime Domain", "categories": ["cs.SE", "cs.AI", "cs.LG", "D.2.11; D.2.9; I.2.m; I.5.0"], "comment": "13 pages, 3 figures, to be published in SummerSOC 2025", "summary": "This case study describes challenges and lessons learned on building Ocean\nGuard: a Machine Learning-Enabled System (MLES) for anomaly detection in the\nmaritime domain. First, the paper presents the system's specification, and\narchitecture. Ocean Guard was designed with a microservices' architecture to\nenable multiple teams to work on the project in parallel. Then, the paper\ndiscusses how the developers adapted contract-based design to MLOps for\nachieving that goal. As a MLES, Ocean Guard employs code, model, and data\ncontracts to establish guidelines between its services. This case study hopes\nto inspire software engineers, machine learning engineers, and data scientists\nto leverage similar approaches for their systems.", "AI": {"tldr": "Ocean Guard\u662f\u4e00\u4e2a\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u5f02\u5e38\u68c0\u6d4b\u7cfb\u7edf\uff0c\u91c7\u7528\u5fae\u670d\u52a1\u67b6\u6784\u548c\u5951\u7ea6\u8bbe\u8ba1\uff0c\u65e8\u5728\u4e3a\u6d77\u4e8b\u9886\u57df\u63d0\u4f9b\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u89e3\u51b3\u6d77\u4e8b\u9886\u57df\u5f02\u5e38\u68c0\u6d4b\u7684\u6311\u6218\uff0c\u5e76\u901a\u8fc7\u5fae\u670d\u52a1\u548c\u5951\u7ea6\u8bbe\u8ba1\u5b9e\u73b0\u591a\u56e2\u961f\u5e76\u884c\u5f00\u53d1\u3002", "method": "\u91c7\u7528\u5fae\u670d\u52a1\u67b6\u6784\u548c\u5951\u7ea6\u8bbe\u8ba1\uff08\u4ee3\u7801\u3001\u6a21\u578b\u548c\u6570\u636e\u5951\u7ea6\uff09\u6765\u6784\u5efa\u7cfb\u7edf\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86Ocean Guard\u7cfb\u7edf\uff0c\u5c55\u793a\u4e86\u5951\u7ea6\u8bbe\u8ba1\u5728MLOps\u4e2d\u7684\u9002\u7528\u6027\u3002", "conclusion": "\u8be5\u6848\u4f8b\u4e3a\u5de5\u7a0b\u5e08\u548c\u79d1\u5b66\u5bb6\u63d0\u4f9b\u4e86\u6784\u5efa\u7c7b\u4f3c\u7cfb\u7edf\u7684\u7075\u611f\u548c\u65b9\u6cd5\u3002"}}
{"id": "2506.06221", "pdf": "https://arxiv.org/pdf/2506.06221", "abs": "https://arxiv.org/abs/2506.06221", "authors": ["Yan Shen", "Ruihai Wu", "Yubin Ke", "Xinyuan Song", "Zeyi Li", "Xiaoqi Li", "Hongwei Fan", "Haoran Lu", "Hao dong"], "title": "BiAssemble: Learning Collaborative Affordance for Bimanual Geometric Assembly", "categories": ["cs.RO", "cs.LG"], "comment": "ICML 2025", "summary": "Shape assembly, the process of combining parts into a complete whole, is a\ncrucial robotic skill with broad real-world applications. Among various\nassembly tasks, geometric assembly--where broken parts are reassembled into\ntheir original form (e.g., reconstructing a shattered bowl)--is particularly\nchallenging. This requires the robot to recognize geometric cues for grasping,\nassembly, and subsequent bimanual collaborative manipulation on varied\nfragments. In this paper, we exploit the geometric generalization of\npoint-level affordance, learning affordance aware of bimanual collaboration in\ngeometric assembly with long-horizon action sequences. To address the\nevaluation ambiguity caused by geometry diversity of broken parts, we introduce\na real-world benchmark featuring geometric variety and global reproducibility.\nExtensive experiments demonstrate the superiority of our approach over both\nprevious affordance-based and imitation-based methods. Project page:\nhttps://sites.google.com/view/biassembly/.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u70b9\u7ea7\u529f\u80fd\u611f\u77e5\u7684\u53cc\u81c2\u534f\u4f5c\u51e0\u4f55\u88c5\u914d\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u788e\u7247\u51e0\u4f55\u591a\u6837\u6027\u5e26\u6765\u7684\u8bc4\u4f30\u6a21\u7cca\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u51e0\u4f55\u88c5\u914d\uff08\u5982\u4fee\u590d\u7834\u788e\u7684\u7897\uff09\u662f\u673a\u5668\u4eba\u6280\u672f\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u9700\u8981\u8bc6\u522b\u51e0\u4f55\u7ebf\u7d22\u5e76\u5b9e\u73b0\u53cc\u81c2\u534f\u4f5c\u64cd\u4f5c\u3002", "method": "\u5229\u7528\u70b9\u7ea7\u529f\u80fd\u611f\u77e5\u7684\u51e0\u4f55\u6cdb\u5316\u80fd\u529b\uff0c\u5b66\u4e60\u53cc\u81c2\u534f\u4f5c\u7684\u529f\u80fd\u611f\u77e5\uff0c\u5e76\u5f15\u5165\u5177\u6709\u51e0\u4f55\u591a\u6837\u6027\u548c\u5168\u5c40\u53ef\u91cd\u590d\u6027\u7684\u771f\u5b9e\u57fa\u51c6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u51e0\u4f55\u88c5\u914d\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u7684\u529f\u80fd\u611f\u77e5\u548c\u6a21\u4eff\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u51e0\u4f55\u88c5\u914d\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u901a\u8fc7\u57fa\u51c6\u9a8c\u8bc1\u4e86\u5176\u6027\u80fd\u3002"}}
{"id": "2506.06243", "pdf": "https://arxiv.org/pdf/2506.06243", "abs": "https://arxiv.org/abs/2506.06243", "authors": ["Benjamin Smith", "Jianhui Gao", "Jessica Gronsbell"], "title": "fairmetrics: An R package for group fairness evaluation", "categories": ["stat.CO", "cs.LG", "stat.ML", "G.3; G.4"], "comment": "6 pages, 1 figure, 1 table", "summary": "Fairness is a growing area of machine learning (ML) that focuses on ensuring\nmodels do not produce systematically biased outcomes for specific groups,\nparticularly those defined by protected attributes such as race, gender, or\nage. Evaluating fairness is a critical aspect of ML model development, as\nbiased models can perpetuate structural inequalities. The {fairmetrics} R\npackage offers a user-friendly framework for rigorously evaluating numerous\ngroup-based fairness criteria, including metrics based on independence (e.g.,\nstatistical parity), separation (e.g., equalized odds), and sufficiency (e.g.,\npredictive parity). Group-based fairness criteria assess whether a model is\nequally accurate or well-calibrated across a set of predefined groups so that\nappropriate bias mitigation strategies can be implemented. {fairmetrics}\nprovides both point and interval estimates for multiple metrics through a\nconvenient wrapper function and includes an example dataset derived from the\nMedical Information Mart for Intensive Care, version II (MIMIC-II) database\n(Goldberger et al., 2000; Raffa, 2016).", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86{fairmetrics} R\u5305\uff0c\u7528\u4e8e\u8bc4\u4f30\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u516c\u5e73\u6027\uff0c\u786e\u4fdd\u6a21\u578b\u5bf9\u4e0d\u540c\u7fa4\u4f53\u65e0\u7cfb\u7edf\u6027\u504f\u89c1\u3002", "motivation": "\u786e\u4fdd\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e0d\u56e0\u4fdd\u62a4\u5c5e\u6027\uff08\u5982\u79cd\u65cf\u3001\u6027\u522b\u3001\u5e74\u9f84\uff09\u4ea7\u751f\u504f\u89c1\u7ed3\u679c\uff0c\u907f\u514d\u52a0\u5267\u7ed3\u6784\u6027\u4e0d\u5e73\u7b49\u3002", "method": "\u901a\u8fc7{fairmetrics} R\u5305\u63d0\u4f9b\u7528\u6237\u53cb\u597d\u7684\u6846\u67b6\uff0c\u8bc4\u4f30\u591a\u79cd\u57fa\u4e8e\u7fa4\u4f53\u7684\u516c\u5e73\u6027\u6807\u51c6\uff0c\u5305\u62ec\u72ec\u7acb\u6027\u3001\u5206\u79bb\u6027\u548c\u5145\u5206\u6027\u76f8\u5173\u6307\u6807\u3002", "result": "{fairmetrics}\u63d0\u4f9b\u4e86\u70b9\u4f30\u8ba1\u548c\u533a\u95f4\u4f30\u8ba1\uff0c\u5e76\u5305\u542b\u6765\u81eaMIMIC-II\u6570\u636e\u5e93\u7684\u793a\u4f8b\u6570\u636e\u96c6\u3002", "conclusion": "{fairmetrics}\u4e3a\u516c\u5e73\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u5b9e\u65bd\u504f\u89c1\u7f13\u89e3\u7b56\u7565\u3002"}}
{"id": "2506.06254", "pdf": "https://arxiv.org/pdf/2506.06254", "abs": "https://arxiv.org/abs/2506.06254", "authors": ["Weizhi Zhang", "Xinyang Zhang", "Chenwei Zhang", "Liangwei Yang", "Jingbo Shang", "Zhepei Wei", "Henry Peng Zou", "Zijie Huang", "Zhengyang Wang", "Yifan Gao", "Xiaoman Pan", "Lian Xiong", "Jingguo Liu", "Philip S. Yu", "Xian Li"], "title": "PersonaAgent: When Large Language Model Agents Meet Personalization at Test Time", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Large Language Model (LLM) empowered agents have recently emerged as advanced\nparadigms that exhibit impressive capabilities in a wide range of domains and\ntasks. Despite their potential, current LLM agents often adopt a\none-size-fits-all approach, lacking the flexibility to respond to users'\nvarying needs and preferences. This limitation motivates us to develop\nPersonaAgent, the first personalized LLM agent framework designed to address\nversatile personalization tasks. Specifically, PersonaAgent integrates two\ncomplementary components - a personalized memory module that includes episodic\nand semantic memory mechanisms; a personalized action module that enables the\nagent to perform tool actions tailored to the user. At the core, the persona\n(defined as unique system prompt for each user) functions as an intermediary:\nit leverages insights from personalized memory to control agent actions, while\nthe outcomes of these actions in turn refine the memory. Based on the\nframework, we propose a test-time user-preference alignment strategy that\nsimulate the latest n interactions to optimize the persona prompt, ensuring\nreal-time user preference alignment through textual loss feedback between\nsimulated and ground-truth responses. Experimental evaluations demonstrate that\nPersonaAgent significantly outperforms other baseline methods by not only\npersonalizing the action space effectively but also scaling during test-time\nreal-world applications. These results underscore the feasibility and potential\nof our approach in delivering tailored, dynamic user experiences.", "AI": {"tldr": "PersonaAgent\u662f\u4e00\u4e2a\u4e2a\u6027\u5316\u7684LLM\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u4e2a\u6027\u5316\u8bb0\u5fc6\u548c\u52a8\u4f5c\u6a21\u5757\u5b9e\u73b0\u7528\u6237\u5b9a\u5236\u5316\u4efb\u52a1\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524dLLM\u4ee3\u7406\u7f3a\u4e4f\u7075\u6d3b\u6027\uff0c\u65e0\u6cd5\u6ee1\u8db3\u7528\u6237\u591a\u6837\u5316\u9700\u6c42\uff0c\u56e0\u6b64\u5f00\u53d1\u4e86PersonaAgent\u4ee5\u5b9e\u73b0\u4e2a\u6027\u5316\u670d\u52a1\u3002", "method": "PersonaAgent\u5305\u542b\u4e2a\u6027\u5316\u8bb0\u5fc6\u6a21\u5757\uff08\u60c5\u666f\u548c\u8bed\u4e49\u8bb0\u5fc6\uff09\u548c\u52a8\u4f5c\u6a21\u5757\uff0c\u901a\u8fc7\u7528\u6237\u504f\u597d\u5bf9\u9f50\u7b56\u7565\u4f18\u5316\u7cfb\u7edf\u63d0\u793a\u3002", "result": "\u5b9e\u9a8c\u8868\u660ePersonaAgent\u5728\u52a8\u4f5c\u7a7a\u95f4\u4e2a\u6027\u5316\u548c\u5b9e\u65f6\u5e94\u7528\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "PersonaAgent\u5c55\u793a\u4e86\u63d0\u4f9b\u52a8\u6001\u3001\u5b9a\u5236\u5316\u7528\u6237\u4f53\u9a8c\u7684\u53ef\u884c\u6027\u548c\u6f5c\u529b\u3002"}}
{"id": "2506.06261", "pdf": "https://arxiv.org/pdf/2506.06261", "abs": "https://arxiv.org/abs/2506.06261", "authors": ["Jihwan Jeong", "Xiaoyu Wang", "Jingmin Wang", "Scott Sanner", "Pascal Poupart"], "title": "Reflect-then-Plan: Offline Model-Based Planning through a Doubly Bayesian Lens", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Offline reinforcement learning (RL) is crucial when online exploration is\ncostly or unsafe but often struggles with high epistemic uncertainty due to\nlimited data. Existing methods rely on fixed conservative policies, restricting\nadaptivity and generalization. To address this, we propose Reflect-then-Plan\n(RefPlan), a novel doubly Bayesian offline model-based (MB) planning approach.\nRefPlan unifies uncertainty modeling and MB planning by recasting planning as\nBayesian posterior estimation. At deployment, it updates a belief over\nenvironment dynamics using real-time observations, incorporating uncertainty\ninto MB planning via marginalization. Empirical results on standard benchmarks\nshow that RefPlan significantly improves the performance of conservative\noffline RL policies. In particular, RefPlan maintains robust performance under\nhigh epistemic uncertainty and limited data, while demonstrating resilience to\nchanging environment dynamics, improving the flexibility, generalizability, and\nrobustness of offline-learned policies.", "AI": {"tldr": "RefPlan\u662f\u4e00\u79cd\u57fa\u4e8e\u53cc\u91cd\u8d1d\u53f6\u65af\u7684\u79bb\u7ebf\u6a21\u578b\u89c4\u5212\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b9e\u65f6\u89c2\u6d4b\u66f4\u65b0\u73af\u5883\u52a8\u6001\u4fe1\u5ff5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4fdd\u5b88\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u7684\u6027\u80fd\u3002", "motivation": "\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u5728\u5728\u7ebf\u63a2\u7d22\u6210\u672c\u9ad8\u6216\u4e0d\u5b89\u5168\u65f6\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5e38\u56e0\u6570\u636e\u6709\u9650\u800c\u9762\u4e34\u9ad8\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff0c\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u56fa\u5b9a\u4fdd\u5b88\u7b56\u7565\uff0c\u9650\u5236\u4e86\u9002\u5e94\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51faReflect-then-Plan\uff08RefPlan\uff09\uff0c\u5c06\u89c4\u5212\u91cd\u65b0\u5b9a\u4e49\u4e3a\u8d1d\u53f6\u65af\u540e\u9a8c\u4f30\u8ba1\uff0c\u901a\u8fc7\u5b9e\u65f6\u89c2\u6d4b\u66f4\u65b0\u73af\u5883\u52a8\u6001\u4fe1\u5ff5\uff0c\u5e76\u5c06\u4e0d\u786e\u5b9a\u6027\u7eb3\u5165\u6a21\u578b\u89c4\u5212\u3002", "result": "\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRefPlan\u663e\u8457\u63d0\u5347\u4e86\u4fdd\u5b88\u79bb\u7ebfRL\u7b56\u7565\u7684\u6027\u80fd\uff0c\u5728\u9ad8\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u548c\u6709\u9650\u6570\u636e\u4e0b\u8868\u73b0\u7a33\u5065\uff0c\u4e14\u5bf9\u73af\u5883\u52a8\u6001\u53d8\u5316\u5177\u6709\u97e7\u6027\u3002", "conclusion": "RefPlan\u63d0\u9ad8\u4e86\u79bb\u7ebf\u5b66\u4e60\u7b56\u7565\u7684\u7075\u6d3b\u6027\u3001\u6cdb\u5316\u80fd\u529b\u548c\u9c81\u68d2\u6027\uff0c\u4e3a\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.06266", "pdf": "https://arxiv.org/pdf/2506.06266", "abs": "https://arxiv.org/abs/2506.06266", "authors": ["Sabri Eyuboglu", "Ryan Ehrlich", "Simran Arora", "Neel Guha", "Dylan Zinsley", "Emily Liu", "Will Tennien", "Atri Rudra", "James Zou", "Azalia Mirhoseini", "Christopher Re"], "title": "Cartridges: Lightweight and general-purpose long context representations via self-study", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large language models are often used to answer queries grounded in large text\ncorpora (e.g. codebases, legal documents, or chat histories) by placing the\nentire corpus in the context window and leveraging in-context learning (ICL).\nAlthough current models support contexts of 100K-1M tokens, this setup is\ncostly to serve because the memory consumption of the KV cache scales with\ninput length. We explore an alternative: training a smaller KV cache offline on\neach corpus. At inference time, we load this trained KV cache, which we call a\nCartridge, and decode a response. Critically, the cost of training a Cartridge\ncan be amortized across all the queries referencing the same corpus. However,\nwe find that the naive approach of training the Cartridge with next-token\nprediction on the corpus is not competitive with ICL. Instead, we propose\nself-study, a training recipe in which we generate synthetic conversations\nabout the corpus and train the Cartridge with a context-distillation objective.\nWe find that Cartridges trained with self-study replicate the functionality of\nICL, while being significantly cheaper to serve. On challenging long-context\nbenchmarks, Cartridges trained with self-study match ICL performance while\nusing 38.6x less memory and enabling 26.4x higher throughput. Self-study also\nextends the model's effective context length (e.g. from 128k to 484k tokens on\nMTOB) and surprisingly, leads to Cartridges that can be composed at inference\ntime without retraining.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCartridge\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u79bb\u7ebf\u8bad\u7ec3\u8f83\u5c0f\u7684KV\u7f13\u5b58\u6765\u66ff\u4ee3\u6602\u8d35\u7684\u5728\u7ebfICL\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5185\u5b58\u6d88\u8017\u5e76\u63d0\u9ad8\u4e86\u541e\u5410\u91cf\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u957f\u6587\u672c\u8bed\u6599\u65f6\uff0cKV\u7f13\u5b58\u7684\u5185\u5b58\u6d88\u8017\u968f\u8f93\u5165\u957f\u5ea6\u589e\u52a0\u800c\u663e\u8457\u589e\u52a0\uff0c\u5bfc\u81f4\u670d\u52a1\u6210\u672c\u9ad8\u6602\u3002", "method": "\u63d0\u51faCartridge\u65b9\u6cd5\uff0c\u901a\u8fc7\u79bb\u7ebf\u8bad\u7ec3KV\u7f13\u5b58\uff0c\u5e76\u4f7f\u7528self-study\u8bad\u7ec3\u7b56\u7565\u751f\u6210\u5408\u6210\u5bf9\u8bdd\u4ee5\u4f18\u5316\u6027\u80fd\u3002", "result": "Cartridge\u5728\u6027\u80fd\u4e0a\u4e0eICL\u76f8\u5f53\uff0c\u4f46\u5185\u5b58\u6d88\u8017\u51cf\u5c1138.6\u500d\uff0c\u541e\u5410\u91cf\u63d0\u9ad826.4\u500d\uff0c\u5e76\u6269\u5c55\u4e86\u6709\u6548\u4e0a\u4e0b\u6587\u957f\u5ea6\u3002", "conclusion": "Cartridge\u7ed3\u5408self-study\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u7ecf\u6d4e\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u957f\u4e0a\u4e0b\u6587\u4efb\u52a1\u3002"}}
{"id": "2506.06275", "pdf": "https://arxiv.org/pdf/2506.06275", "abs": "https://arxiv.org/abs/2506.06275", "authors": ["Emmanouil Zaranis", "Ant\u00f3nio Farinhas", "Saul Santos", "Beatriz Canaverde", "Miguel Moura Ramos", "Aditya K Surikuchi", "Andr\u00e9 Viveiros", "Baohao Liao", "Elena Bueno-Benito", "Nithin Sivakumaran", "Pavlo Vasylenko", "Shoubin Yu", "Sonal Sannigrahi", "Wafaa Mohammed", "Ben Peters", "Danae S\u00e1nchez Villegas", "Elias Stengel-Eskin", "Giuseppe Attanasio", "Jaehong Yoon", "Stella Frank", "Alessandro Suglia", "Chrysoula Zerva", "Desmond Elliott", "Mariella Dimiccoli", "Mohit Bansal", "Oswald Lanz", "Raffaella Bernardi", "Raquel Fern\u00e1ndez", "Sandro Pezzelle", "Vlad Niculae", "Andr\u00e9 F. T. Martins"], "title": "Movie Facts and Fibs (MF$^2$): A Benchmark for Long Movie Understanding", "categories": ["cs.CV", "cs.CL", "cs.LG"], "comment": "Under Review", "summary": "Despite recent progress in vision-language models (VLMs), holistic\nunderstanding of long-form video content remains a significant challenge,\npartly due to limitations in current benchmarks. Many focus on peripheral,\n``needle-in-a-haystack'' details, encouraging context-insensitive retrieval\nover deep comprehension. Others rely on large-scale, semi-automatically\ngenerated questions (often produced by language models themselves) that are\neasier for models to answer but fail to reflect genuine understanding. In this\npaper, we introduce MF$^2$, a new benchmark for evaluating whether models can\ncomprehend, consolidate, and recall key narrative information from full-length\nmovies (50-170 minutes long). MF$^2$ includes over 50 full-length,\nopen-licensed movies, each paired with manually constructed sets of claim pairs\n-- one true (fact) and one plausible but false (fib), totalling over 850 pairs.\nThese claims target core narrative elements such as character motivations and\nemotions, causal chains, and event order, and refer to memorable moments that\nhumans can recall without rewatching the movie. Instead of multiple-choice\nformats, we adopt a binary claim evaluation protocol: for each pair, models\nmust correctly identify both the true and false claims. This reduces biases\nlike answer ordering and enables a more precise assessment of reasoning. Our\nexperiments demonstrate that both open-weight and closed state-of-the-art\nmodels fall well short of human performance, underscoring the relative ease of\nthe task for humans and their superior ability to retain and reason over\ncritical narrative information -- an ability current VLMs lack.", "AI": {"tldr": "MF$^2$\u662f\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u6a21\u578b\u662f\u5426\u80fd\u4ece\u5168\u957f\u7535\u5f71\u4e2d\u7406\u89e3\u548c\u56de\u5fc6\u5173\u952e\u53d9\u4e8b\u4fe1\u606f\u3002", "motivation": "\u5f53\u524d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u5728\u957f\u89c6\u9891\u5185\u5bb9\u7406\u89e3\u4e0a\u5b58\u5728\u5c40\u9650\uff0c\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u591a\u5173\u6ce8\u7ec6\u8282\u6216\u4f9d\u8d56\u81ea\u52a8\u5316\u751f\u6210\u7684\u95ee\u9898\uff0c\u672a\u80fd\u53cd\u6620\u771f\u5b9e\u7406\u89e3\u3002", "method": "MF$^2$\u5305\u542b50\u591a\u90e8\u5168\u957f\u7535\u5f71\uff0c\u6bcf\u90e8\u7535\u5f71\u914d\u6709\u4eba\u5de5\u6784\u5efa\u7684\u771f\u5b9e\u548c\u865a\u5047\u58f0\u660e\u5bf9\uff0c\u5171850\u591a\u5bf9\uff0c\u6d4b\u8bd5\u6a21\u578b\u662f\u5426\u80fd\u6b63\u786e\u8bc6\u522b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u73b0\u6709\u6a21\u578b\u5728\u8bc6\u522b\u5173\u952e\u53d9\u4e8b\u4fe1\u606f\u4e0a\u8fdc\u4e0d\u53ca\u4eba\u7c7b\u8868\u73b0\u3002", "conclusion": "MF$^2$\u63ed\u793a\u4e86\u5f53\u524dVLMs\u5728\u957f\u89c6\u9891\u5185\u5bb9\u7406\u89e3\u4e0a\u7684\u4e0d\u8db3\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2506.06290", "pdf": "https://arxiv.org/pdf/2506.06290", "abs": "https://arxiv.org/abs/2506.06290", "authors": ["Mingyu Lu", "Ethan Weinberger", "Chanwoo Kim", "Su-In Lee"], "title": "CellCLIP -- Learning Perturbation Effects in Cell Painting via Text-Guided Contrastive Learning", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "High-content screening (HCS) assays based on high-throughput microscopy\ntechniques such as Cell Painting have enabled the interrogation of cells'\nmorphological responses to perturbations at an unprecedented scale. The\ncollection of such data promises to facilitate a better understanding of the\nrelationships between different perturbations and their effects on cellular\nstate. Towards achieving this goal, recent advances in cross-modal contrastive\nlearning could, in theory, be leveraged to learn a unified latent space that\naligns perturbations with their corresponding morphological effects. However,\nthe application of such methods to HCS data is not straightforward due to\nsubstantial differences in the semantics of Cell Painting images compared to\nnatural images, and the difficulty of representing different classes of\nperturbations (e.g., small molecule vs CRISPR gene knockout) in a single latent\nspace. In response to these challenges, here we introduce CellCLIP, a\ncross-modal contrastive learning framework for HCS data. CellCLIP leverages\npre-trained image encoders coupled with a novel channel encoding scheme to\nbetter capture relationships between different microscopy channels in image\nembeddings, along with natural language encoders for representing\nperturbations. Our framework outperforms current open-source models,\ndemonstrating the best performance in both cross-modal retrieval and\nbiologically meaningful downstream tasks while also achieving significant\nreductions in computation time.", "AI": {"tldr": "CellCLIP\u662f\u4e00\u79cd\u7528\u4e8e\u9ad8\u5185\u6db5\u7b5b\u9009\u6570\u636e\u7684\u8de8\u6a21\u6001\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u9884\u8bad\u7ec3\u56fe\u50cf\u7f16\u7801\u5668\u548c\u65b0\u578b\u901a\u9053\u7f16\u7801\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8de8\u6a21\u6001\u68c0\u7d22\u548c\u751f\u7269\u5b66\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u9ad8\u5185\u6db5\u7b5b\u9009\u6280\u672f\uff08\u5982Cell Painting\uff09\u80fd\u5927\u89c4\u6a21\u7814\u7a76\u7ec6\u80de\u5f62\u6001\u5bf9\u6270\u52a8\u7684\u54cd\u5e94\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u5176\u4e0e\u81ea\u7136\u56fe\u50cf\u7684\u8bed\u4e49\u5dee\u5f02\u53ca\u6270\u52a8\u7c7b\u578b\u7684\u591a\u6837\u6027\u3002", "method": "\u7ed3\u5408\u9884\u8bad\u7ec3\u56fe\u50cf\u7f16\u7801\u5668\u3001\u65b0\u578b\u901a\u9053\u7f16\u7801\u65b9\u6848\u548c\u81ea\u7136\u8bed\u8a00\u7f16\u7801\u5668\uff0cCellCLIP\u6784\u5efa\u4e86\u7edf\u4e00\u7684\u6f5c\u5728\u7a7a\u95f4\uff0c\u5bf9\u9f50\u6270\u52a8\u4e0e\u5176\u5f62\u6001\u6548\u5e94\u3002", "result": "CellCLIP\u5728\u8de8\u6a21\u6001\u68c0\u7d22\u548c\u4e0b\u6e38\u751f\u7269\u5b66\u4efb\u52a1\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c11\u4e86\u8ba1\u7b97\u65f6\u95f4\u3002", "conclusion": "CellCLIP\u4e3a\u9ad8\u5185\u6db5\u7b5b\u9009\u6570\u636e\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u8de8\u6a21\u6001\u5b66\u4e60\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6311\u6218\u3002"}}
{"id": "2506.06291", "pdf": "https://arxiv.org/pdf/2506.06291", "abs": "https://arxiv.org/abs/2506.06291", "authors": ["Xiaoke Wang", "Batuhan Altundas", "Zhaoxin Li", "Aaron Zhao", "Matthew Gombolay"], "title": "Improvement of Optimization using Learning Based Models in Mixed Integer Linear Programming Tasks", "categories": ["cs.LG", "cs.AI", "cs.MA"], "comment": "4 pages, 4 figures", "summary": "Mixed Integer Linear Programs (MILPs) are essential tools for solving\nplanning and scheduling problems across critical industries such as\nconstruction, manufacturing, and logistics. However, their widespread adoption\nis limited by long computational times, especially in large-scale, real-time\nscenarios. To address this, we present a learning-based framework that\nleverages Behavior Cloning (BC) and Reinforcement Learning (RL) to train Graph\nNeural Networks (GNNs), producing high-quality initial solutions for\nwarm-starting MILP solvers in Multi-Agent Task Allocation and Scheduling\nProblems. Experimental results demonstrate that our method reduces optimization\ntime and variance compared to traditional techniques while maintaining solution\nquality and feasibility.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5b66\u4e60\u548cGNN\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u4e3aMILP\u6c42\u89e3\u5668\u751f\u6210\u9ad8\u8d28\u91cf\u521d\u59cb\u89e3\uff0c\u4ee5\u51cf\u5c11\u8ba1\u7b97\u65f6\u95f4\u548c\u65b9\u5dee\u3002", "motivation": "MILP\u5728\u89c4\u5212\u548c\u8c03\u5ea6\u95ee\u9898\u4e2d\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u8ba1\u7b97\u65f6\u95f4\u957f\u9650\u5236\u4e86\u5176\u5728\u5927\u89c4\u6a21\u5b9e\u65f6\u573a\u666f\u4e2d\u7684\u4f7f\u7528\u3002", "method": "\u7ed3\u5408\u884c\u4e3a\u514b\u9686\uff08BC\uff09\u548c\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u8bad\u7ec3\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u4efb\u52a1\u5206\u914d\u548c\u8c03\u5ea6\u95ee\u9898\u751f\u6210\u521d\u59cb\u89e3\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u89e3\u7684\u8d28\u91cf\u548c\u53ef\u884c\u6027\u7684\u540c\u65f6\uff0c\u51cf\u5c11\u4e86\u4f18\u5316\u65f6\u95f4\u548c\u65b9\u5dee\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86MILP\u6c42\u89e3\u5668\u7684\u6548\u7387\uff0c\u9002\u7528\u4e8e\u5b9e\u65f6\u548c\u5927\u89c4\u6a21\u573a\u666f\u3002"}}
{"id": "2506.06292", "pdf": "https://arxiv.org/pdf/2506.06292", "abs": "https://arxiv.org/abs/2506.06292", "authors": ["Tianyuan Shi", "Canbin Huang", "Fanqi Wan", "Longguang Zhong", "Ziyi Yang", "Weizhou Shen", "Xiaojun Quan", "Ming Yan"], "title": "Mutual-Taught for Co-adapting Policy and Reward Models", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to ACL 2025 (Main Conference)", "summary": "During the preference optimization of large language models (LLMs),\ndistribution shifts may arise between newly generated model samples and the\ndata used to train the reward model (RM). This shift reduces the efficacy of\nthe RM, which in turn negatively impacts the performance of the policy model\n(PM). To address this challenge, we propose Mutual-Taught, a self-training\nmethod that iteratively improves both the PM and RM without requiring\nadditional human annotation. Our approach mirrors the expectation-maximization\n(EM) algorithm. In the E-step, the PM is updated using feedback from the\ncurrent RM, guiding the PM toward a better approximation of the latent optimal\npreference distribution. In the M-step, we update the RM by constructing\ntraining data from the outputs of the PM before and after the E-step update.\nThis process ensures that the RM adapts to the evolving policy distribution.\nExperimental results demonstrate that this iterative approach leads to\nconsistent improvements in both models. Specifically, our 8B policy model,\nLLaMA-3-8B-Instruct-MT, achieves a length-controlled win rate of 54.1\\% on\nAlpacaEval-2, while our 8B reward model, FsfairX-LLaMA3-RM-MT, performs on par\nwith GPT-4o-2024-08-06 on RewardBench.", "AI": {"tldr": "Mutual-Taught\u662f\u4e00\u79cd\u81ea\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fed\u4ee3\u4f18\u5316\u7b56\u7565\u6a21\u578b\uff08PM\uff09\u548c\u5956\u52b1\u6a21\u578b\uff08RM\uff09\u6765\u89e3\u51b3\u5206\u5e03\u504f\u79fb\u95ee\u9898\uff0c\u65e0\u9700\u989d\u5916\u4eba\u5de5\u6807\u6ce8\u3002", "motivation": "\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u504f\u597d\u4f18\u5316\u4e2d\uff0c\u65b0\u751f\u6210\u7684\u6a21\u578b\u6837\u672c\u4e0e\u5956\u52b1\u6a21\u578b\u8bad\u7ec3\u6570\u636e\u4e4b\u95f4\u7684\u5206\u5e03\u504f\u79fb\u4f1a\u964d\u4f4eRM\u7684\u6548\u679c\uff0c\u8fdb\u800c\u5f71\u54cdPM\u7684\u6027\u80fd\u3002", "method": "\u91c7\u7528\u7c7b\u4f3c\u671f\u671b\u6700\u5927\u5316\uff08EM\uff09\u7b97\u6cd5\u7684\u81ea\u8bad\u7ec3\u65b9\u6cd5\uff1aE\u6b65\u7528\u5f53\u524dRM\u53cd\u9988\u66f4\u65b0PM\uff0cM\u6b65\u7528PM\u8f93\u51fa\u66f4\u65b0RM\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6301\u7eed\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c8B\u7b56\u7565\u6a21\u578b\u5728AlpacaEval-2\u4e0a\u80dc\u7387\u4e3a54.1%\uff0c8B\u5956\u52b1\u6a21\u578b\u5728RewardBench\u4e0a\u4e0eGPT-4o-2024-08-06\u8868\u73b0\u76f8\u5f53\u3002", "conclusion": "Mutual-Taught\u901a\u8fc7\u8fed\u4ee3\u4f18\u5316PM\u548cRM\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5206\u5e03\u504f\u79fb\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2506.06293", "pdf": "https://arxiv.org/pdf/2506.06293", "abs": "https://arxiv.org/abs/2506.06293", "authors": ["Junyi Liu", "Stanley Kok"], "title": "Prediction of Bank Credit Ratings using Heterogeneous Topological Graph Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": "WITS 2024 (Workshop on Information Technologies and Systems 2024)", "summary": "Agencies such as Standard & Poor's and Moody's provide bank credit ratings\nthat influence economic stability and decision-making by stakeholders. Accurate\nand timely predictions support informed decision-making, regulatory actions,\nand investor protection. However, a complete interbank connection graph is\noften unavailable due to privacy concerns, complicating the direct application\nof Graph Neural Networks (GNNs) for rating prediction. our research utilizes\npersistent homology to construct a network that captures relationships among\nbanks and combines this with a traditional lending network to create a\nheterogeneous network that integrates information from both sources, leading to\nimproved predictions. Experiments on a global, real-world dataset validate the\neffectiveness of HTGNN. This research has implications for investors and\nregulatory bodies in enhancing proactive risk mitigation and the implementation\nof effective market interventions.The code can be find at\nhttps://github.com/Liu-Jun-Yi/HTGNN.", "AI": {"tldr": "\u7814\u7a76\u5229\u7528\u6301\u4e45\u540c\u8c03\u6784\u5efa\u94f6\u884c\u5173\u7cfb\u7f51\u7edc\uff0c\u7ed3\u5408\u4f20\u7edf\u501f\u8d37\u7f51\u7edc\u5f62\u6210\u5f02\u6784\u7f51\u7edc\uff0c\u63d0\u5347\u4fe1\u7528\u8bc4\u7ea7\u9884\u6d4b\u6548\u679c\u3002", "motivation": "\u94f6\u884c\u4fe1\u7528\u8bc4\u7ea7\u5bf9\u7ecf\u6d4e\u7a33\u5b9a\u548c\u51b3\u7b56\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5b8c\u6574\u7684\u94f6\u884c\u95f4\u8fde\u63a5\u56fe\u5e38\u56e0\u9690\u79c1\u95ee\u9898\u7f3a\u5931\uff0c\u9650\u5236\u4e86\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u5e94\u7528\u3002", "method": "\u4f7f\u7528\u6301\u4e45\u540c\u8c03\u6784\u5efa\u94f6\u884c\u5173\u7cfb\u7f51\u7edc\uff0c\u7ed3\u5408\u4f20\u7edf\u501f\u8d37\u7f51\u7edc\u5f62\u6210\u5f02\u6784\u7f51\u7edc\uff0c\u63d0\u51faHTGNN\u6a21\u578b\u3002", "result": "\u5728\u771f\u5b9e\u5168\u7403\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86HTGNN\u7684\u6709\u6548\u6027\uff0c\u9884\u6d4b\u6548\u679c\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u7814\u7a76\u4e3a\u6295\u8d44\u8005\u548c\u76d1\u7ba1\u673a\u6784\u63d0\u4f9b\u4e86\u6539\u8fdb\u98ce\u9669\u7f13\u89e3\u548c\u5e02\u573a\u5e72\u9884\u7684\u5de5\u5177\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2506.06294", "pdf": "https://arxiv.org/pdf/2506.06294", "abs": "https://arxiv.org/abs/2506.06294", "authors": ["Yunqing Liu", "Wenqi Fan", "Xiaoyong Wei", "Qing Li"], "title": "GLProtein: Global-and-Local Structure Aware Protein Representation Learning", "categories": ["cs.LG", "cs.AI", "cs.CL", "q-bio.BM"], "comment": null, "summary": "Proteins are central to biological systems, participating as building blocks\nacross all forms of life. Despite advancements in understanding protein\nfunctions through protein sequence analysis, there remains potential for\nfurther exploration in integrating protein structural information. We argue\nthat the structural information of proteins is not only limited to their 3D\ninformation but also encompasses information from amino acid molecules (local\ninformation) to protein-protein structure similarity (global information). To\naddress this, we propose \\textbf{GLProtein}, the first framework in protein\npre-training that incorporates both global structural similarity and local\namino acid details to enhance prediction accuracy and functional insights.\nGLProtein innovatively combines protein-masked modelling with triplet structure\nsimilarity scoring, protein 3D distance encoding and substructure-based amino\nacid molecule encoding. Experimental results demonstrate that GLProtein\noutperforms previous methods in several bioinformatics tasks, including\npredicting protein-protein interaction, contact prediction, and so on.", "AI": {"tldr": "GLProtein\u662f\u4e00\u4e2a\u7ed3\u5408\u5168\u5c40\u7ed3\u6784\u76f8\u4f3c\u6027\u548c\u5c40\u90e8\u6c28\u57fa\u9178\u7ec6\u8282\u7684\u86cb\u767d\u8d28\u9884\u8bad\u7ec3\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u86cb\u767d\u8d28\u7ed3\u6784\u4fe1\u606f\u4e0d\u4ec5\u9650\u4e8e3D\u4fe1\u606f\uff0c\u8fd8\u5305\u62ec\u4ece\u6c28\u57fa\u9178\u5206\u5b50\u5230\u86cb\u767d\u8d28-\u86cb\u767d\u8d28\u7ed3\u6784\u76f8\u4f3c\u6027\u7684\u591a\u5c42\u6b21\u4fe1\u606f\uff0c\u73b0\u6709\u65b9\u6cd5\u5c1a\u672a\u5145\u5206\u6574\u5408\u8fd9\u4e9b\u4fe1\u606f\u3002", "method": "GLProtein\u521b\u65b0\u6027\u5730\u7ed3\u5408\u4e86\u86cb\u767d\u8d28\u63a9\u7801\u5efa\u6a21\u3001\u4e09\u91cd\u7ed3\u6784\u76f8\u4f3c\u6027\u8bc4\u5206\u3001\u86cb\u767d\u8d283D\u8ddd\u79bb\u7f16\u7801\u548c\u57fa\u4e8e\u5b50\u7ed3\u6784\u7684\u6c28\u57fa\u9178\u5206\u5b50\u7f16\u7801\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cGLProtein\u5728\u86cb\u767d\u8d28-\u86cb\u767d\u8d28\u76f8\u4e92\u4f5c\u7528\u9884\u6d4b\u3001\u63a5\u89e6\u9884\u6d4b\u7b49\u751f\u7269\u4fe1\u606f\u5b66\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "GLProtein\u901a\u8fc7\u6574\u5408\u5168\u5c40\u548c\u5c40\u90e8\u7ed3\u6784\u4fe1\u606f\uff0c\u4e3a\u86cb\u767d\u8d28\u529f\u80fd\u9884\u6d4b\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u89c6\u89d2\u548c\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2506.06295", "pdf": "https://arxiv.org/pdf/2506.06295", "abs": "https://arxiv.org/abs/2506.06295", "authors": ["Zhiyuan Liu", "Yicun Yang", "Yaojie Zhang", "Junjie Chen", "Chang Zou", "Qingyuan Wei", "Shaobo Wang", "Linfeng Zhang"], "title": "dLLM-Cache: Accelerating Diffusion Large Language Models with Adaptive Caching", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Autoregressive Models (ARMs) have long dominated the landscape of Large\nLanguage Models. Recently, a new paradigm has emerged in the form of\ndiffusion-based Large Language Models (dLLMs), which generate text by\niteratively denoising masked segments. This approach has shown significant\nadvantages and potential. However, dLLMs suffer from high inference latency.\nTraditional ARM acceleration techniques, such as Key-Value caching, are\nincompatible with dLLMs due to their bidirectional attention mechanism. To\naddress this specific challenge, our work begins with a key observation that\ndLLM inference involves a static prompt and a partially dynamic response, where\nmost tokens remain stable across adjacent denoising steps. Based on this, we\npropose dLLM-Cache, a training-free adaptive caching framework that combines\nlong-interval prompt caching with partial response updates guided by feature\nsimilarity. This design enables efficient reuse of intermediate computations\nwithout compromising model performance. Extensive experiments on representative\ndLLMs, including LLaDA 8B and Dream 7B, show that dLLM-Cache achieves up to 9.1\nx speedup over standard inference without compromising output quality. Notably,\nour method brings dLLM inference latency close to that of ARMs under many\nsettings. Codes are provided in the supplementary material and will be released\npublicly on GitHub.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3adLLM-Cache\u7684\u7f13\u5b58\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u6269\u6563\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\uff08dLLMs\uff09\u7684\u9ad8\u63a8\u7406\u5ef6\u8fdf\u95ee\u9898\uff0c\u901a\u8fc7\u9759\u6001\u63d0\u793a\u7f13\u5b58\u548c\u90e8\u5206\u54cd\u5e94\u66f4\u65b0\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u52a0\u901f\u6548\u679c\u3002", "motivation": "\u6269\u6563\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\uff08dLLMs\uff09\u5728\u6587\u672c\u751f\u6210\u65b9\u9762\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u5176\u9ad8\u63a8\u7406\u5ef6\u8fdf\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002\u4f20\u7edf\u52a0\u901f\u6280\u672f\u4e0d\u9002\u7528\u4e8edLLMs\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fadLLM-Cache\u6846\u67b6\uff0c\u7ed3\u5408\u957f\u95f4\u9694\u63d0\u793a\u7f13\u5b58\u548c\u57fa\u4e8e\u7279\u5f81\u76f8\u4f3c\u6027\u7684\u90e8\u5206\u54cd\u5e94\u66f4\u65b0\uff0c\u5b9e\u73b0\u4e2d\u95f4\u8ba1\u7b97\u7684\u9ad8\u6548\u590d\u7528\u3002", "result": "\u5728LLaDA 8B\u548cDream 7B\u7b49\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cdLLM-Cache\u5b9e\u73b0\u4e86\u9ad8\u8fbe9.1\u500d\u7684\u52a0\u901f\uff0c\u4e14\u4e0d\u5f71\u54cd\u8f93\u51fa\u8d28\u91cf\u3002", "conclusion": "dLLM-Cache\u663e\u8457\u964d\u4f4e\u4e86dLLMs\u7684\u63a8\u7406\u5ef6\u8fdf\uff0c\u4f7f\u5176\u63a5\u8fd1\u81ea\u56de\u5f52\u6a21\u578b\uff08ARMs\uff09\u7684\u6027\u80fd\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u6027\u3002"}}
{"id": "2506.06296", "pdf": "https://arxiv.org/pdf/2506.06296", "abs": "https://arxiv.org/abs/2506.06296", "authors": ["Hanaa El Afia", "Said Ohamouddou", "Raddouane Chiheb", "Abdellatif El Afia"], "title": "Dynamic Graph CNN with Jacobi Kolmogorov-Arnold Networks for 3D Classification of Point Sets", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We introduce Jacobi-KAN-DGCNN, a framework that integrates Dynamic Graph\nConvolutional Neural Network (DGCNN) with Jacobi Kolmogorov-Arnold Networks\n(KAN) for the classification of three-dimensional point clouds. This method\nreplaces Multi-Layer Perceptron (MLP) layers with adaptable univariate\npolynomial expansions within a streamlined DGCNN architecture, circumventing\ndeep levels for both MLP and KAN to facilitate a layer-by-layer comparison. In\ncomparative experiments on the ModelNet40 dataset, KAN layers employing Jacobi\npolynomials outperform the traditional linear layer-based DGCNN baseline in\nterms of accuracy and convergence speed, while maintaining parameter\nefficiency. Our results demonstrate that higher polynomial degrees do not\nautomatically improve performance, highlighting the need for further\ntheoretical and empirical investigation to fully understand the interactions\nbetween polynomial bases, degrees, and the mechanisms of graph-based learning.", "AI": {"tldr": "Jacobi-KAN-DGCNN\u7ed3\u5408\u52a8\u6001\u56fe\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u4e0eJacobi\u591a\u9879\u5f0fKAN\uff0c\u7528\u4e8e\u4e09\u7ef4\u70b9\u4e91\u5206\u7c7b\uff0c\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u63a2\u7d22\u591a\u9879\u5f0f\u6269\u5c55\u5728\u52a8\u6001\u56fe\u5377\u79ef\u7f51\u7edc\u4e2d\u7684\u5e94\u7528\uff0c\u4ee5\u63d0\u5347\u5206\u7c7b\u7cbe\u5ea6\u548c\u6536\u655b\u901f\u5ea6\u3002", "method": "\u7528\u53ef\u8c03\u5355\u53d8\u91cf\u591a\u9879\u5f0f\u6269\u5c55\u66ff\u6362MLP\u5c42\uff0c\u7ed3\u5408DGCNN\u67b6\u6784\uff0c\u907f\u514d\u6df1\u5c42\u7f51\u7edc\u3002", "result": "\u5728ModelNet40\u6570\u636e\u96c6\u4e0a\uff0cJacobi\u591a\u9879\u5f0fKAN\u5c42\u5728\u7cbe\u5ea6\u548c\u6536\u655b\u901f\u5ea6\u4e0a\u4f18\u4e8e\u4f20\u7edf\u7ebf\u6027\u5c42\uff0c\u4e14\u53c2\u6570\u9ad8\u6548\u3002", "conclusion": "\u9ad8\u591a\u9879\u5f0f\u9636\u6570\u4e0d\u4e00\u5b9a\u63d0\u5347\u6027\u80fd\uff0c\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u591a\u9879\u5f0f\u57fa\u4e0e\u56fe\u5b66\u4e60\u673a\u5236\u7684\u4ea4\u4e92\u3002"}}
{"id": "2506.06297", "pdf": "https://arxiv.org/pdf/2506.06297", "abs": "https://arxiv.org/abs/2506.06297", "authors": ["Bozhi Sun", "Seda Tierney", "Jeffrey A. Feinstein", "Frederick Damen", "Alison L. Marsden", "Daniele E. Schiavazzi"], "title": "Optimal patient allocation for echocardiographic assessments", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Scheduling echocardiographic exams in a hospital presents significant\nchallenges due to non-deterministic factors (e.g., patient no-shows, patient\narrival times, diverse exam durations, etc.) and asymmetric resource\nconstraints between fetal and non-fetal patient streams. To address these\nchallenges, we first conducted extensive pre-processing on one week of\noperational data from the Echo Laboratory at Stanford University's Lucile\nPackard Children's Hospital, to estimate patient no-show probabilities and\nderive empirical distributions of arrival times and exam durations. Based on\nthese inputs, we developed a discrete-event stochastic simulation model using\nSimPy, and integrate it with the open source Gymnasium Python library. As a\nbaseline for policy optimization, we developed a comparative framework to\nevaluate on-the-fly versus reservation-based allocation strategies, in which\ndifferent proportions of resources are reserved in advance. Considering a\nhospital configuration with a 1:6 ratio of fetal to non-fetal rooms and a 4:2\nratio of fetal to non-fetal sonographers, we show that on-the-fly allocation\ngenerally yields better performance, more effectively adapting to patient\nvariability and resource constraints. Building on this foundation, we apply\nreinforcement learning (RL) to derive an approximated optimal dynamic\nallocation policy. This RL-based policy is benchmarked against the\nbest-performing rule-based strategies, allowing us to quantify their\ndifferences and provide actionable insights for improving echo lab efficiency\nthrough intelligent, data-driven resource management.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u79bb\u6563\u4e8b\u4ef6\u968f\u673a\u6a21\u62df\u548c\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u533b\u9662\u8d85\u58f0\u68c0\u67e5\u8c03\u5ea6\uff0c\u52a8\u6001\u5206\u914d\u7b56\u7565\u4f18\u4e8e\u9759\u6001\u9884\u7559\u7b56\u7565\u3002", "motivation": "\u533b\u9662\u8d85\u58f0\u68c0\u67e5\u8c03\u5ea6\u9762\u4e34\u975e\u786e\u5b9a\u6027\u56e0\u7d20\uff08\u5982\u60a3\u8005\u723d\u7ea6\u3001\u5230\u8fbe\u65f6\u95f4\u4e0d\u786e\u5b9a\u7b49\uff09\u548c\u8d44\u6e90\u4e0d\u5bf9\u79f0\u7ea6\u675f\uff0c\u9700\u4f18\u5316\u8d44\u6e90\u5206\u914d\u4ee5\u63d0\u9ad8\u6548\u7387\u3002", "method": "\u57fa\u4e8e\u4e00\u5468\u8fd0\u8425\u6570\u636e\u9884\u5904\u7406\uff0c\u6784\u5efaSimPy\u79bb\u6563\u4e8b\u4ef6\u968f\u673a\u6a21\u62df\u6a21\u578b\uff0c\u7ed3\u5408Gymnasium\u5e93\uff0c\u6bd4\u8f83\u52a8\u6001\u5206\u914d\u4e0e\u9884\u7559\u7b56\u7565\uff0c\u5e76\u5e94\u7528\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u7b56\u7565\u3002", "result": "\u52a8\u6001\u5206\u914d\u7b56\u7565\u5728\u8d44\u6e90\u7ea6\u675f\u4e0b\u8868\u73b0\u66f4\u4f18\uff0c\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u8c03\u5ea6\u6548\u7387\u3002", "conclusion": "\u6570\u636e\u9a71\u52a8\u7684\u52a8\u6001\u8d44\u6e90\u7ba1\u7406\u7b56\u7565\u53ef\u663e\u8457\u63d0\u5347\u8d85\u58f0\u68c0\u67e5\u8c03\u5ea6\u6548\u7387\uff0c\u5f3a\u5316\u5b66\u4e60\u4e3a\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2506.06298", "pdf": "https://arxiv.org/pdf/2506.06298", "abs": "https://arxiv.org/abs/2506.06298", "authors": ["Daniel Halpern", "Evi Micha", "Ariel D. Procaccia", "Itai Shapira"], "title": "Pairwise Calibrated Rewards for Pluralistic Alignment", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Current alignment pipelines presume a single, universal notion of desirable\nbehavior. However, human preferences often diverge across users, contexts, and\ncultures. As a result, disagreement collapses into the majority signal and\nminority perspectives are discounted. To address this, we propose reflecting\ndiverse human preferences through a distribution over multiple reward\nfunctions, each inducing a distinct aligned policy. The distribution is learned\ndirectly from pairwise preference without annotator identifiers or predefined\ngroups. Instead, annotator disagreements are treated as informative soft\nlabels. Our central criterion is pairwise calibration: for every pair of\ncandidate responses, the proportion of reward functions preferring one response\nmatches the fraction of annotators with that preference. We prove that even a\nsmall outlier-free ensemble can accurately represent diverse preference\ndistributions. Empirically, we introduce and validate a practical training\nheuristic to learn such ensembles, and demonstrate its effectiveness through\nimproved calibration, implying a more faithful representation of pluralistic\nvalues.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u591a\u5956\u52b1\u51fd\u6570\u5206\u5e03\u53cd\u6620\u591a\u6837\u5316\u4eba\u7c7b\u504f\u597d\u7684\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5bf9\u9f50\u6d41\u7a0b\u4e2d\u5c11\u6570\u89c2\u70b9\u88ab\u5ffd\u89c6\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u5bf9\u9f50\u65b9\u6cd5\u5047\u8bbe\u5b58\u5728\u5355\u4e00\u7406\u60f3\u884c\u4e3a\uff0c\u4f46\u4eba\u7c7b\u504f\u597d\u56e0\u7528\u6237\u3001\u80cc\u666f\u548c\u6587\u5316\u800c\u5f02\uff0c\u5bfc\u81f4\u5c11\u6570\u89c2\u70b9\u88ab\u591a\u6570\u4fe1\u53f7\u63a9\u76d6\u3002", "method": "\u901a\u8fc7\u76f4\u63a5\u4ece\u6210\u5bf9\u504f\u597d\u4e2d\u5b66\u4e60\u591a\u5956\u52b1\u51fd\u6570\u5206\u5e03\uff0c\u65e0\u9700\u6807\u6ce8\u8005\u6807\u8bc6\u6216\u9884\u5b9a\u4e49\u7ec4\uff0c\u5c06\u6807\u6ce8\u8005\u5206\u6b67\u89c6\u4e3a\u4fe1\u606f\u6027\u8f6f\u6807\u7b7e\u3002\u6838\u5fc3\u6807\u51c6\u662f\u6210\u5bf9\u6821\u51c6\u3002", "result": "\u8bc1\u660e\u5373\u4f7f\u5c0f\u89c4\u6a21\u65e0\u5f02\u5e38\u96c6\u5408\u4e5f\u80fd\u51c6\u786e\u8868\u793a\u591a\u6837\u5316\u504f\u597d\u5206\u5e03\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8bad\u7ec3\u542f\u53d1\u5f0f\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u66f4\u5fe0\u5b9e\u53cd\u6620\u591a\u5143\u5316\u4ef7\u503c\u89c2\uff0c\u6821\u51c6\u6548\u679c\u63d0\u5347\u3002"}}
{"id": "2506.06300", "pdf": "https://arxiv.org/pdf/2506.06300", "abs": "https://arxiv.org/abs/2506.06300", "authors": ["Yuanye Zhou", "Zhaokun Wang", "Kai Zhou", "Hui Tang", "Xiaofan Li"], "title": "LT-PINN: Lagrangian Topology-conscious Physics-informed Neural Network for Boundary-focused Engineering Optimization", "categories": ["cs.LG", "physics.comp-ph"], "comment": null, "summary": "Physics-informed neural networks (PINNs) have emerged as a powerful meshless\ntool for topology optimization, capable of simultaneously determining optimal\ntopologies and physical solutions. However, conventional PINNs rely on\ndensity-based topology descriptions, which necessitate manual interpolation and\nlimit their applicability to complex geometries. To address this, we propose\nLagrangian topology-conscious PINNs (LT-PINNs), a novel framework for\nboundary-focused engineering optimization. By parameterizing the control\nvariables of topology boundary curves as learnable parameters, LT-PINNs\neliminate the need for manual interpolation and enable precise boundary\ndetermination. We further introduce specialized boundary condition loss\nfunction and topology loss function to ensure sharp and accurate boundary\nrepresentations, even for intricate topologies. The accuracy and robustness of\nLT-PINNs are validated via two types of partial differential equations (PDEs),\nincluding elastic equation with Dirichlet boundary conditions and Laplace's\nequation with Neumann boundary conditions. Furthermore, we demonstrate\neffectiveness of LT-PINNs on more complex time-dependent and time-independent\nflow problems without relying on measurement data, and showcase their\nengineering application potential in flow velocity rearrangement, transforming\na uniform upstream velocity into a sine-shaped downstream profile. The results\ndemonstrate (1) LT-PINNs achieve substantial reductions in relative L2 errors\ncompared with the state-of-art density topology-oriented PINNs (DT-PINNs), (2)\nLT-PINNs can handle arbitrary boundary conditions, making them suitable for a\nwide range of PDEs, and (3) LT-PINNs can infer clear topology boundaries\nwithout manual interpolation, especially for complex topologies.", "AI": {"tldr": "LT-PINNs\u662f\u4e00\u79cd\u65b0\u578b\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\uff0c\u901a\u8fc7\u53c2\u6570\u5316\u62d3\u6251\u8fb9\u754c\u66f2\u7ebf\uff0c\u907f\u514d\u4e86\u624b\u52a8\u63d2\u503c\uff0c\u63d0\u5347\u4e86\u590d\u6742\u51e0\u4f55\u4f18\u5316\u7684\u7cbe\u5ea6\u548c\u9002\u7528\u6027\u3002", "motivation": "\u4f20\u7edfPINNs\u4f9d\u8d56\u57fa\u4e8e\u5bc6\u5ea6\u7684\u62d3\u6251\u63cf\u8ff0\uff0c\u9700\u8981\u624b\u52a8\u63d2\u503c\u4e14\u96be\u4ee5\u5904\u7406\u590d\u6742\u51e0\u4f55\u5f62\u72b6\uff0c\u9650\u5236\u4e86\u5176\u5e94\u7528\u3002", "method": "\u63d0\u51faLT-PINNs\uff0c\u5c06\u62d3\u6251\u8fb9\u754c\u66f2\u7ebf\u7684\u63a7\u5236\u53d8\u91cf\u53c2\u6570\u5316\u4e3a\u53ef\u5b66\u4e60\u53c2\u6570\uff0c\u5e76\u5f15\u5165\u8fb9\u754c\u6761\u4ef6\u635f\u5931\u51fd\u6570\u548c\u62d3\u6251\u635f\u5931\u51fd\u6570\u3002", "result": "LT-PINNs\u5728\u591a\u79cdPDE\u95ee\u9898\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u76f8\u5bf9L2\u8bef\u5dee\uff0c\u5e76\u80fd\u5904\u7406\u4efb\u610f\u8fb9\u754c\u6761\u4ef6\u3002", "conclusion": "LT-PINNs\u4e3a\u5de5\u7a0b\u4f18\u5316\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u3001\u7cbe\u786e\u7684\u8fb9\u754c\u805a\u7126\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u590d\u6742\u62d3\u6251\u95ee\u9898\u3002"}}
{"id": "2506.06303", "pdf": "https://arxiv.org/pdf/2506.06303", "abs": "https://arxiv.org/abs/2506.06303", "authors": ["Kefan Song", "Amir Moeini", "Peng Wang", "Lei Gong", "Rohan Chandra", "Yanjun Qi", "Shangtong Zhang"], "title": "Reward Is Enough: LLMs Are In-Context Reinforcement Learners", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Reinforcement learning (RL) is a human-designed framework for solving\nsequential decision making problems. In this work, we demonstrate that,\nsurprisingly, RL emerges in LLM's (Large Language Model) inference time -- a\nphenomenon known as in-context RL (ICRL). Specifically, we propose a novel\nmulti-round prompting framework called ICRL prompting. The goal is to prompt\nthe LLM to complete a task. After the LLM generates a response at the current\nround, we give numerical scalar feedbacks for the response, called the rewards.\nAt the next round, we prompt the LLM again with the same task and a context\nconsisting of all previous responses and rewards. We observe that the quality\nof the LLM's response increases as the context grows. In other words, the LLM\nis able to maximize the scalar reward signal in the inference time, just like\nan RL algorithm. We evaluate ICRL prompting in three benchmarks (Game of 24,\ncreative writing, and ScienceWorld) and demonstrate significant performance\nimprovements over baseline methods such as Self-Refine and Reflexion.\nSurprisingly, in some experiments the reward signals are generated by the LLM\nitself, yet performance improvements are still observed from ICRL prompting,\noffering a promising paradigm for scaling test-time compute.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aICRL prompting\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u8f6e\u63d0\u793a\u548c\u5956\u52b1\u53cd\u9988\uff0c\u4f7fLLM\u5728\u63a8\u7406\u65f6\u8868\u73b0\u51fa\u7c7b\u4f3c\u5f3a\u5316\u5b66\u4e60\u7684\u884c\u4e3a\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4efb\u52a1\u5b8c\u6210\u8d28\u91cf\u3002", "motivation": "\u63a2\u7d22LLM\u5728\u63a8\u7406\u65f6\u662f\u5426\u80fd\u591f\u901a\u8fc7\u591a\u8f6e\u63d0\u793a\u548c\u5956\u52b1\u53cd\u9988\u8868\u73b0\u51fa\u7c7b\u4f3c\u5f3a\u5316\u5b66\u4e60\u7684\u884c\u4e3a\uff0c\u4ece\u800c\u63d0\u5347\u4efb\u52a1\u5b8c\u6210\u6548\u679c\u3002", "method": "\u63d0\u51faICRL prompting\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u8f6e\u63d0\u793a\u548c\u5956\u52b1\u53cd\u9988\uff0c\u9010\u6b65\u4f18\u5316LLM\u7684\u54cd\u5e94\u8d28\u91cf\u3002", "result": "\u5728Game of 24\u3001\u521b\u610f\u5199\u4f5c\u548cScienceWorld\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cICRL prompting\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u751a\u81f3\u5728\u67d0\u4e9b\u5b9e\u9a8c\u4e2d\u4ec5\u4f9d\u8d56LLM\u81ea\u8eab\u751f\u6210\u7684\u5956\u52b1\u4fe1\u53f7\u4e5f\u80fd\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "ICRL prompting\u4e3aLLM\u5728\u63a8\u7406\u65f6\u5b9e\u73b0\u7c7b\u4f3c\u5f3a\u5316\u5b66\u4e60\u7684\u884c\u4e3a\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\uff0c\u5c55\u793a\u4e86\u6269\u5c55\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u80fd\u529b\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.06327", "pdf": "https://arxiv.org/pdf/2506.06327", "abs": "https://arxiv.org/abs/2506.06327", "authors": ["Zilang Chen"], "title": "Wine Quality Prediction with Ensemble Trees: A Unified, Leak-Free Comparative Study", "categories": ["cs.LG"], "comment": "14pages, 7figures,2tables", "summary": "Accurate and reproducible wine-quality assessment is critical for production\ncontrol yet remains dominated by subjective, labour-intensive tasting panels.\nWe present the first unified benchmark of five ensemble learners (Random\nForest, Gradient Boosting, XGBoost, LightGBM, CatBoost) on the canonical Vinho\nVerde red- and white-wine datasets (1,599 and 4,898 instances, 11\nphysicochemical attributes). Our leakage-free workflow employs an 80:20\nstratified train-test split, five-fold StratifiedGroupKFold within the training\nset, per-fold standardisation, SMOTE-Tomek resampling, inverse-frequency cost\nweighting, Optuna hyper-parameter search (120-200 trials per model) and a\ntwo-stage feature-selection refit. Final scores on untouched test sets are\nreported with weighted F1 as the headline metric. Gradient Boosting achieves\nthe highest accuracy (weighted F1 0.693 +/- 0.028 for red and 0.664 +/- 0.016\nfor white), followed within three percentage points by Random Forest and\nXGBoost. Limiting each model to its five top-ranked variables lowers\ndimensionality by 55 percent while reducing weighted F1 by only 2.6 percentage\npoints for red and 3.0 percentage points for white, indicating that alcohol,\nvolatile acidity, sulphates, free SO2 and chlorides capture most predictive\nsignal. Runtime profiling on an EPYC 9K84/H20 node reveals a steep efficiency\ngradient: Gradient Boosting averages 12 h per five-fold study, XGBoost and\nLightGBM require 2-3 h, CatBoost 1 h, and Random Forest under 50 min. We\ntherefore recommend Random Forest as the most cost-effective production model,\nXGBoost and LightGBM as GPU-efficient alternatives, and Gradient Boosting as\nthe accuracy ceiling for offline benchmarking. The fully documented pipeline\nand metric set provide a reproducible baseline for future work on imbalanced\nmulti-class wine-quality prediction.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u4e94\u79cd\u96c6\u6210\u5b66\u4e60\u65b9\u6cd5\u7684\u8461\u8404\u9152\u8d28\u91cf\u8bc4\u4f30\u57fa\u51c6\uff0c\u901a\u8fc7\u6cc4\u6f0f\u907f\u514d\u7684\u5de5\u4f5c\u6d41\u7a0b\u548c\u591a\u79cd\u4f18\u5316\u6280\u672f\uff0c\u6bd4\u8f83\u4e86\u5404\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u6700\u7ec8\u63a8\u8350\u4e86\u4e0d\u540c\u573a\u666f\u4e0b\u7684\u6700\u4f73\u6a21\u578b\u3002", "motivation": "\u8461\u8404\u9152\u8d28\u91cf\u8bc4\u4f30\u901a\u5e38\u4f9d\u8d56\u4e3b\u89c2\u7684\u4eba\u5de5\u54c1\u5c1d\uff0c\u7f3a\u4e4f\u5ba2\u89c2\u6027\u548c\u53ef\u91cd\u590d\u6027\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u63d0\u4f9b\u4e00\u79cd\u51c6\u786e\u4e14\u53ef\u91cd\u590d\u7684\u8bc4\u4f30\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u4e94\u79cd\u96c6\u6210\u5b66\u4e60\u65b9\u6cd5\uff08\u968f\u673a\u68ee\u6797\u3001\u68af\u5ea6\u63d0\u5347\u3001XGBoost\u3001LightGBM\u3001CatBoost\uff09\uff0c\u7ed3\u5408\u5206\u5c42\u8bad\u7ec3-\u6d4b\u8bd5\u5206\u5272\u3001SMOTE-Tomek\u91cd\u91c7\u6837\u3001\u8d85\u53c2\u6570\u641c\u7d22\u7b49\u6280\u672f\uff0c\u5bf9\u7ea2\u8461\u8404\u9152\u548c\u767d\u8461\u8404\u9152\u6570\u636e\u96c6\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u68af\u5ea6\u63d0\u5347\u65b9\u6cd5\u5728\u52a0\u6743F1\u5f97\u5206\u4e0a\u8868\u73b0\u6700\u4f73\uff08\u7ea2\u8461\u8404\u91520.693\uff0c\u767d\u8461\u8404\u91520.664\uff09\uff0c\u4f46\u968f\u673a\u68ee\u6797\u5728\u6548\u7387\u4e0a\u66f4\u5177\u4f18\u52bf\u3002\u7279\u5f81\u9009\u62e9\u540e\uff0c\u4ec5\u4f7f\u7528\u4e94\u4e2a\u5173\u952e\u53d8\u91cf\u5373\u53ef\u4fdd\u7559\u5927\u90e8\u5206\u9884\u6d4b\u4fe1\u53f7\u3002", "conclusion": "\u968f\u673a\u68ee\u6797\u662f\u6027\u4ef7\u6bd4\u6700\u9ad8\u7684\u751f\u4ea7\u6a21\u578b\uff0cXGBoost\u548cLightGBM\u9002\u5408GPU\u9ad8\u6548\u573a\u666f\uff0c\u68af\u5ea6\u63d0\u5347\u9002\u7528\u4e8e\u79bb\u7ebf\u57fa\u51c6\u6d4b\u8bd5\u3002\u8bba\u6587\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u6d41\u7a0b\u548c\u6307\u6807\u96c6\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u7684\u57fa\u7ebf\u3002"}}
{"id": "2506.06330", "pdf": "https://arxiv.org/pdf/2506.06330", "abs": "https://arxiv.org/abs/2506.06330", "authors": ["James Afful"], "title": "ExplainBench: A Benchmark Framework for Local Model Explanations in Fairness-Critical Applications", "categories": ["cs.LG"], "comment": null, "summary": "As machine learning systems are increasingly deployed in high-stakes domains\nsuch as criminal justice, finance, and healthcare, the demand for interpretable\nand trustworthy models has intensified. Despite the proliferation of local\nexplanation techniques, including SHAP, LIME, and counterfactual methods, there\nexists no standardized, reproducible framework for their comparative\nevaluation, particularly in fairness-sensitive settings.\n  We introduce ExplainBench, an open-source benchmarking suite for systematic\nevaluation of local model explanations across ethically consequential datasets.\nExplainBench provides unified wrappers for popular explanation algorithms,\nintegrates end-to-end pipelines for model training and explanation generation,\nand supports evaluation via fidelity, sparsity, and robustness metrics. The\nframework includes a Streamlit-based graphical interface for interactive\nexploration and is packaged as a Python module for seamless integration into\nresearch workflows.\n  We demonstrate ExplainBench on datasets commonly used in fairness research,\nsuch as COMPAS, UCI Adult Income, and LendingClub, and showcase how different\nexplanation methods behave under a shared experimental protocol. By enabling\nreproducible, comparative analysis of local explanations, ExplainBench advances\nthe methodological foundations of interpretable machine learning and\nfacilitates accountability in real-world AI systems.", "AI": {"tldr": "ExplainBench\u662f\u4e00\u4e2a\u5f00\u6e90\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\uff0c\u7528\u4e8e\u7cfb\u7edf\u8bc4\u4f30\u5c40\u90e8\u6a21\u578b\u89e3\u91ca\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u516c\u5e73\u654f\u611f\u573a\u666f\u4e0b\u3002", "motivation": "\u968f\u7740\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u5728\u9ad8\u98ce\u9669\u9886\u57df\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5bf9\u53ef\u89e3\u91ca\u548c\u53ef\u4fe1\u8d56\u6a21\u578b\u7684\u9700\u6c42\u589e\u52a0\uff0c\u4f46\u7f3a\u4e4f\u6807\u51c6\u5316\u3001\u53ef\u590d\u73b0\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "ExplainBench\u63d0\u4f9b\u7edf\u4e00\u7684\u89e3\u91ca\u7b97\u6cd5\u5c01\u88c5\u3001\u7aef\u5230\u7aef\u6a21\u578b\u8bad\u7ec3\u548c\u89e3\u91ca\u751f\u6210\u6d41\u7a0b\uff0c\u5e76\u901a\u8fc7\u4fdd\u771f\u5ea6\u3001\u7a00\u758f\u6027\u548c\u9c81\u68d2\u6027\u6307\u6807\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5728COMPAS\u3001UCI Adult Income\u548cLendingClub\u7b49\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u4e0d\u540c\u89e3\u91ca\u65b9\u6cd5\u7684\u884c\u4e3a\u3002", "conclusion": "ExplainBench\u901a\u8fc7\u652f\u6301\u53ef\u590d\u73b0\u7684\u5c40\u90e8\u89e3\u91ca\u6bd4\u8f83\u5206\u6790\uff0c\u63a8\u52a8\u4e86\u53ef\u89e3\u91ca\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5\u5b66\u57fa\u7840\uff0c\u5e76\u63d0\u5347\u4e86\u5b9e\u9645AI\u7cfb\u7edf\u7684\u95ee\u8d23\u6027\u3002"}}
{"id": "2506.06333", "pdf": "https://arxiv.org/pdf/2506.06333", "abs": "https://arxiv.org/abs/2506.06333", "authors": ["Benjamin von Berg", "Bernhard K. Aichernig"], "title": "Extending AALpy with Passive Learning: A Generalized State-Merging Approach", "categories": ["cs.LG", "cs.FL"], "comment": "Accepted for publication at CAV 2025, the 37th International\n  Conference on Computer Aided Verification", "summary": "AALpy is a well-established open-source automata learning library written in\nPython with a focus on active learning of systems with IO behavior. It provides\na wide range of state-of-the-art algorithms for different automaton types\nranging from fully deterministic to probabilistic automata. In this work, we\npresent the recent addition of a generalized implementation of an important\nmethod from the domain of passive automata learning: state-merging in the\nred-blue framework. Using a common internal representation for different\nautomaton types allows for a general and highly configurable implementation of\nthe red-blue framework. We describe how to define and execute state-merging\nalgorithms using AALpy, which reduces the implementation effort for\nstate-merging algorithms mainly to the definition of compatibility criteria and\nscoring. This aids the implementation of both existing and novel algorithms. In\nparticular, defining some existing state-merging algorithms from the literature\nwith AALpy only takes a few lines of code.", "AI": {"tldr": "AALpy\u662f\u4e00\u4e2aPython\u5f00\u6e90\u81ea\u52a8\u673a\u5b66\u4e60\u5e93\uff0c\u4e13\u6ce8\u4e8eIO\u884c\u4e3a\u7cfb\u7edf\u7684\u4e3b\u52a8\u5b66\u4e60\uff0c\u65b0\u589e\u4e86\u88ab\u52a8\u5b66\u4e60\u4e2d\u7684\u72b6\u6001\u5408\u5e76\u65b9\u6cd5\u5b9e\u73b0\u3002", "motivation": "\u63d0\u4f9b\u4e00\u79cd\u901a\u7528\u7684\u72b6\u6001\u5408\u5e76\u65b9\u6cd5\u5b9e\u73b0\uff0c\u51cf\u5c11\u7b97\u6cd5\u5b9e\u73b0\u7684\u590d\u6742\u6027\uff0c\u652f\u6301\u73b0\u6709\u548c\u65b0\u7b97\u6cd5\u7684\u5feb\u901f\u5f00\u53d1\u3002", "method": "\u4f7f\u7528\u7ea2\u84dd\u6846\u67b6\u548c\u901a\u7528\u5185\u90e8\u8868\u793a\uff0c\u901a\u8fc7\u5b9a\u4e49\u517c\u5bb9\u6027\u6807\u51c6\u548c\u8bc4\u5206\u5b9e\u73b0\u72b6\u6001\u5408\u5e76\u7b97\u6cd5\u3002", "result": "AALpy\u7b80\u5316\u4e86\u72b6\u6001\u5408\u5e76\u7b97\u6cd5\u7684\u5b9e\u73b0\uff0c\u73b0\u6709\u7b97\u6cd5\u4ec5\u9700\u51e0\u884c\u4ee3\u7801\u5373\u53ef\u5b9a\u4e49\u3002", "conclusion": "AALpy\u7684\u901a\u7528\u8bbe\u8ba1\u4e3a\u81ea\u52a8\u673a\u5b66\u4e60\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.06337", "pdf": "https://arxiv.org/pdf/2506.06337", "abs": "https://arxiv.org/abs/2506.06337", "authors": ["Ali Murad", "Bo Hui", "Wei-Shinn Ku"], "title": "Optimized Local Updates in Federated Learning via Reinforcement Learning", "categories": ["cs.LG"], "comment": "This paper is accepted at IEEE IJCNN 2025", "summary": "Federated Learning (FL) is a distributed framework for collaborative model\ntraining over large-scale distributed data, enabling higher performance while\nmaintaining client data privacy. However, the nature of model aggregation at\nthe centralized server can result in a performance drop in the presence of\nnon-IID data across different clients. We remark that training a client locally\non more data than necessary does not benefit the overall performance of all\nclients. In this paper, we devise a novel framework that leverages a Deep\nReinforcement Learning (DRL) agent to select an optimized amount of data\nnecessary to train a client model without oversharing information with the\nserver. Starting without awareness of the client's performance, the DRL agent\nutilizes the change in training loss as a reward signal and learns to optimize\nthe amount of training data necessary for improving the client's performance.\nSpecifically, after each aggregation round, the DRL algorithm considers the\nlocal performance as the current state and outputs the optimized weights for\neach class, in the training data, to be used during the next round of local\ntraining. In doing so, the agent learns a policy that creates an optimized\npartition of the local training dataset during the FL rounds. After FL, the\nclient utilizes the entire local training dataset to further enhance its\nperformance on its own data distribution, mitigating the non-IID effects of\naggregation. Through extensive experiments, we demonstrate that training FL\nclients through our algorithm results in superior performance on multiple\nbenchmark datasets and FL frameworks. Our code is available at\nhttps://github.com/amuraddd/optimized_client_training.git.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u7684\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u6846\u67b6\uff0c\u4f18\u5316\u5ba2\u6237\u7aef\u8bad\u7ec3\u6570\u636e\u91cf\u4ee5\u63d0\u5347\u6027\u80fd\u5e76\u89e3\u51b3\u975e\u72ec\u7acb\u540c\u5206\u5e03\uff08non-IID\uff09\u6570\u636e\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u4e2d\u56e0\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u5bfc\u81f4\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\uff0c\u540c\u65f6\u907f\u514d\u5ba2\u6237\u7aef\u8fc7\u5ea6\u5171\u4eab\u6570\u636e\u3002", "method": "\u5229\u7528DRL\u4ee3\u7406\u52a8\u6001\u9009\u62e9\u5ba2\u6237\u7aef\u8bad\u7ec3\u6570\u636e\u91cf\uff0c\u4ee5\u8bad\u7ec3\u635f\u5931\u53d8\u5316\u4e3a\u5956\u52b1\u4fe1\u53f7\uff0c\u4f18\u5316\u6bcf\u8f6e\u8bad\u7ec3\u7684\u6570\u636e\u5206\u914d\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u548cFL\u6846\u67b6\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684DRL\u6846\u67b6\u6709\u6548\u4f18\u5316\u4e86\u5ba2\u6237\u7aef\u8bad\u7ec3\u6570\u636e\u5206\u914d\uff0c\u7f13\u89e3\u4e86\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u7684\u5f71\u54cd\uff0c\u63d0\u5347\u4e86\u8054\u90a6\u5b66\u4e60\u6027\u80fd\u3002"}}
{"id": "2506.06359", "pdf": "https://arxiv.org/pdf/2506.06359", "abs": "https://arxiv.org/abs/2506.06359", "authors": ["Gabriel Antonesi", "Tudor Cioara", "Ionut Anghel", "Vasilis Michalakopoulos", "Elissaios Sarmas", "Liana Toderean"], "title": "From Transformers to Large Language Models: A systematic review of AI applications in the energy sector towards Agentic Digital Twins", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Artificial intelligence (AI) has long promised to improve energy management\nin smart grids by enhancing situational awareness and supporting more effective\ndecision-making. While traditional machine learning has demonstrated notable\nresults in forecasting and optimization, it often struggles with\ngeneralization, situational awareness, and heterogeneous data integration.\nRecent advances in foundation models such as Transformer architecture and Large\nLanguage Models (LLMs) have demonstrated improved capabilities in modelling\ncomplex temporal and contextual relationships, as well as in multi-modal data\nfusion which is essential for most AI applications in the energy sector. In\nthis review we synthesize the rapid expanding field of AI applications in the\nenergy domain focusing on Transformers and LLMs. We examine the architectural\nfoundations, domain-specific adaptations and practical implementations of\ntransformer models across various forecasting and grid management tasks. We\nthen explore the emerging role of LLMs in the field: adaptation and fine tuning\nfor the energy sector, the type of tasks they are suited for, and the new\nchallenges they introduce. Along the way, we highlight practical\nimplementations, innovations, and areas where the research frontier is rapidly\nexpanding. These recent developments reviewed underscore a broader trend:\nGenerative AI (GenAI) is beginning to augment decision-making not only in\nhigh-level planning but also in day-to-day operations, from forecasting and\ngrid balancing to workforce training and asset onboarding. Building on these\ndevelopments, we introduce the concept of the Agentic Digital Twin, a\nnext-generation model that integrates LLMs to bring autonomy, proactivity, and\nsocial interaction into digital twin-based energy management systems.", "AI": {"tldr": "\u7efc\u8ff0\u63a2\u8ba8\u4e86AI\u5728\u80fd\u6e90\u9886\u57df\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u7279\u522b\u662fTransformer\u548cLLMs\u5728\u667a\u80fd\u7535\u7f51\u4e2d\u7684\u5e94\u7528\uff0c\u63d0\u51fa\u4e86Agentic Digital Twin\u7684\u6982\u5ff5\u3002", "motivation": "\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u5728\u80fd\u6e90\u7ba1\u7406\u4e2d\u9762\u4e34\u6cdb\u5316\u3001\u60c5\u5883\u611f\u77e5\u548c\u591a\u6e90\u6570\u636e\u6574\u5408\u7684\u6311\u6218\uff0c\u800cTransformer\u548cLLMs\u5c55\u793a\u4e86\u66f4\u5f3a\u7684\u80fd\u529b\u3002", "method": "\u7efc\u8ff0\u4e86Transformer\u548cLLMs\u7684\u67b6\u6784\u57fa\u7840\u3001\u9886\u57df\u9002\u914d\u53ca\u5b9e\u9645\u5e94\u7528\uff0c\u5e76\u63a2\u8ba8\u4e86LLMs\u5728\u80fd\u6e90\u9886\u57df\u7684\u6f5c\u529b\u4e0e\u6311\u6218\u3002", "result": "GenAI\u6b63\u9010\u6b65\u5728\u80fd\u6e90\u7ba1\u7406\u7684\u9ad8\u5c42\u89c4\u5212\u548c\u65e5\u5e38\u64cd\u4f5c\u4e2d\u53d1\u6325\u4f5c\u7528\uff0cLLMs\u4e3a\u6570\u5b57\u5b6a\u751f\u7cfb\u7edf\u5f15\u5165\u81ea\u4e3b\u6027\u548c\u793e\u4ea4\u4ea4\u4e92\u3002", "conclusion": "Agentic Digital Twin\u662f\u4e0b\u4e00\u4ee3\u80fd\u6e90\u7ba1\u7406\u6a21\u578b\uff0c\u6574\u5408LLMs\u4ee5\u5b9e\u73b0\u66f4\u667a\u80fd\u7684\u51b3\u7b56\u548c\u64cd\u4f5c\u3002"}}
{"id": "2506.06380", "pdf": "https://arxiv.org/pdf/2506.06380", "abs": "https://arxiv.org/abs/2506.06380", "authors": ["Jingyi Gu", "Xuan Zhang", "Guiling Wang"], "title": "Beyond the Norm: A Survey of Synthetic Data Generation for Rare Events", "categories": ["cs.LG", "cs.AI", "cs.CE"], "comment": null, "summary": "Extreme events, such as market crashes, natural disasters, and pandemics, are\nrare but catastrophic, often triggering cascading failures across\ninterconnected systems. Accurate prediction and early warning can help minimize\nlosses and improve preparedness. While data-driven methods offer powerful\ncapabilities for extreme event modeling, they require abundant training data,\nyet extreme event data is inherently scarce, creating a fundamental challenge.\nSynthetic data generation has emerged as a powerful solution. However, existing\nsurveys focus on general data with privacy preservation emphasis, rather than\nextreme events' unique performance requirements. This survey provides the first\noverview of synthetic data generation for extreme events. We systematically\nreview generative modeling techniques and large language models, particularly\nthose enhanced by statistical theory as well as specialized training and\nsampling mechanisms to capture heavy-tailed distributions. We summarize\nbenchmark datasets and introduce a tailored evaluation framework covering\nstatistical, dependence, visual, and task-oriented metrics. A central\ncontribution is our in-depth analysis of each metric's applicability in\nextremeness and domain-specific adaptations, providing actionable guidance for\nmodel evaluation in extreme settings. We categorize key application domains and\nidentify underexplored areas like behavioral finance, wildfires, earthquakes,\nwindstorms, and infectious outbreaks. Finally, we outline open challenges,\nproviding a structured foundation for advancing synthetic rare-event research.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u6781\u7aef\u4e8b\u4ef6\u5408\u6210\u6570\u636e\u751f\u6210\u7684\u9996\u6b21\u6982\u8ff0\uff0c\u5305\u62ec\u751f\u6210\u6a21\u578b\u3001\u8bc4\u4f30\u6846\u67b6\u548c\u5e94\u7528\u9886\u57df\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u6781\u7aef\u4e8b\u4ef6\uff08\u5982\u5e02\u573a\u5d29\u6e83\u3001\u81ea\u7136\u707e\u5bb3\uff09\u7f55\u89c1\u4f46\u7834\u574f\u6027\u5f3a\uff0c\u6570\u636e\u7a00\u7f3a\u5bfc\u81f4\u5efa\u6a21\u56f0\u96be\uff0c\u5408\u6210\u6570\u636e\u751f\u6210\u6210\u4e3a\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7cfb\u7edf\u56de\u987e\u751f\u6210\u6a21\u578b\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u7ed3\u5408\u7edf\u8ba1\u7406\u8bba\u548c\u4e13\u95e8\u8bad\u7ec3\u673a\u5236\uff0c\u63d0\u51fa\u8bc4\u4f30\u6846\u67b6\u548c\u9886\u57df\u5e94\u7528\u5206\u7c7b\u3002", "result": "\u603b\u7ed3\u4e86\u751f\u6210\u6280\u672f\u548c\u8bc4\u4f30\u6307\u6807\uff0c\u5206\u6790\u4e86\u5404\u6307\u6807\u5728\u6781\u7aef\u4e8b\u4ef6\u4e2d\u7684\u9002\u7528\u6027\uff0c\u5e76\u8bc6\u522b\u4e86\u672a\u5145\u5206\u63a2\u7d22\u7684\u5e94\u7528\u9886\u57df\u3002", "conclusion": "\u4e3a\u6781\u7aef\u4e8b\u4ef6\u5408\u6210\u6570\u636e\u7814\u7a76\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u57fa\u7840\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u6311\u6218\u548c\u65b9\u5411\u3002"}}
{"id": "2506.06398", "pdf": "https://arxiv.org/pdf/2506.06398", "abs": "https://arxiv.org/abs/2506.06398", "authors": ["Yin Li"], "title": "Theoretical Analysis of Positional Encodings in Transformer Models: Impact on Expressiveness and Generalization", "categories": ["cs.LG", "cs.AI", "68T07, 68Q32", "I.2.6; I.2.7; F.1.1"], "comment": null, "summary": "Positional encodings are a core part of transformer-based models, enabling\nprocessing of sequential data without recurrence. This paper presents a\ntheoretical framework to analyze how various positional encoding methods,\nincluding sinusoidal, learned, relative, and bias-based methods like Attention\nwith Linear Biases (ALiBi), impact a transformer's expressiveness,\ngeneralization ability, and extrapolation to longer sequences. Expressiveness\nis defined via function approximation, generalization bounds are established\nusing Rademacher complexity, and new encoding methods based on orthogonal\nfunctions, such as wavelets and Legendre polynomials, are proposed. The\nextrapolation capacity of existing and proposed encodings is analyzed,\nextending ALiBi's biasing approach to a unified theoretical context.\nExperimental evaluation on synthetic sequence-to-sequence tasks shows that\northogonal transform-based encodings outperform traditional sinusoidal\nencodings in generalization and extrapolation. This work addresses a critical\ngap in transformer theory, providing insights for design choices in natural\nlanguage processing, computer vision, and other transformer applications.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\uff0c\u5206\u6790\u4e0d\u540c\u4f4d\u7f6e\u7f16\u7801\u65b9\u6cd5\u5bf9Transformer\u8868\u8fbe\u80fd\u529b\u3001\u6cdb\u5316\u80fd\u529b\u548c\u957f\u5e8f\u5217\u5916\u63a8\u80fd\u529b\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u6b63\u4ea4\u51fd\u6570\u7684\u65b0\u7f16\u7801\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3Transformer\u4e2d\u4f4d\u7f6e\u7f16\u7801\u65b9\u6cd5\u7684\u7406\u8bba\u5206\u6790\u4e0d\u8db3\u95ee\u9898\uff0c\u4e3a\u81ea\u7136\u8bed\u8a00\u5904\u7406\u3001\u8ba1\u7b97\u673a\u89c6\u89c9\u7b49\u9886\u57df\u7684\u8bbe\u8ba1\u9009\u62e9\u63d0\u4f9b\u7406\u8bba\u652f\u6301\u3002", "method": "\u901a\u8fc7\u51fd\u6570\u903c\u8fd1\u5b9a\u4e49\u8868\u8fbe\u80fd\u529b\uff0c\u4f7f\u7528Rademacher\u590d\u6742\u5ea6\u5efa\u7acb\u6cdb\u5316\u754c\u9650\uff0c\u63d0\u51fa\u57fa\u4e8e\u6b63\u4ea4\u51fd\u6570\uff08\u5982\u5c0f\u6ce2\u548cLegendre\u591a\u9879\u5f0f\uff09\u7684\u65b0\u7f16\u7801\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u57fa\u4e8e\u6b63\u4ea4\u53d8\u6362\u7684\u7f16\u7801\u65b9\u6cd5\u5728\u6cdb\u5316\u548c\u5916\u63a8\u80fd\u529b\u4e0a\u4f18\u4e8e\u4f20\u7edf\u7684\u6b63\u5f26\u7f16\u7801\u65b9\u6cd5\u3002", "conclusion": "\u8bba\u6587\u586b\u8865\u4e86Transformer\u7406\u8bba\u7684\u7a7a\u767d\uff0c\u4e3a\u4f4d\u7f6e\u7f16\u7801\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u4f9d\u636e\u548c\u5b9e\u7528\u65b9\u6cd5\u3002"}}
{"id": "2506.06411", "pdf": "https://arxiv.org/pdf/2506.06411", "abs": "https://arxiv.org/abs/2506.06411", "authors": ["Paul Fogel", "Christophe Geissler", "George Luta"], "title": "CoxNTF: A New Approach for Joint Clustering and Prediction in Survival Analysis", "categories": ["cs.LG"], "comment": "7 pages, 3 figures, Conference on Lifetime Data Science 2025,\n  Brooklyn, New York, USA", "summary": "The interpretation of the results of survival analysis often benefits from\nlatent factor representations of baseline covariates. However, existing\nmethods, such as Nonnegative Matrix Factorization (NMF), do not incorporate\nsurvival information, limiting their predictive power. We present CoxNTF, a\nnovel approach that uses non-negative tensor factorization (NTF) to derive\nmeaningful latent representations that are closely associated with survival\noutcomes. CoxNTF constructs a weighted covariate tensor in which survival\nprobabilities derived from the Coxnet model are used to guide the tensorization\nprocess. Our results show that CoxNTF achieves survival prediction performance\ncomparable to using Coxnet with the original covariates, while providing a\nstructured and interpretable clustering framework. In addition, the new\napproach effectively handles feature redundancy, making it a powerful tool for\njoint clustering and prediction in survival analysis.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u975e\u8d1f\u5f20\u91cf\u5206\u89e3\uff08NTF\uff09\u548c\u751f\u5b58\u5206\u6790\u7684CoxNTF\u65b9\u6cd5\uff0c\u7528\u4e8e\u751f\u6210\u4e0e\u751f\u5b58\u7ed3\u679c\u76f8\u5173\u7684\u6f5c\u5728\u7279\u5f81\u8868\u793a\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\uff08\u5982NMF\uff09\u672a\u7ed3\u5408\u751f\u5b58\u4fe1\u606f\uff0c\u9650\u5236\u4e86\u9884\u6d4b\u80fd\u529b\u3002", "method": "\u4f7f\u7528NTF\u6784\u5efa\u52a0\u6743\u534f\u53d8\u91cf\u5f20\u91cf\uff0c\u5e76\u901a\u8fc7Coxnet\u6a21\u578b\u7684\u751f\u5b58\u6982\u7387\u6307\u5bfc\u5f20\u91cf\u5316\u8fc7\u7a0b\u3002", "result": "CoxNTF\u5728\u751f\u5b58\u9884\u6d4b\u6027\u80fd\u4e0a\u4e0e\u539f\u59cb\u534f\u53d8\u91cf\u7684Coxnet\u76f8\u5f53\uff0c\u540c\u65f6\u63d0\u4f9b\u7ed3\u6784\u5316\u4e14\u53ef\u89e3\u91ca\u7684\u805a\u7c7b\u6846\u67b6\u3002", "conclusion": "CoxNTF\u662f\u4e00\u79cd\u5f3a\u5927\u7684\u5de5\u5177\uff0c\u80fd\u6709\u6548\u5904\u7406\u7279\u5f81\u5197\u4f59\uff0c\u9002\u7528\u4e8e\u751f\u5b58\u5206\u6790\u7684\u8054\u5408\u805a\u7c7b\u548c\u9884\u6d4b\u3002"}}
{"id": "2506.06412", "pdf": "https://arxiv.org/pdf/2506.06412", "abs": "https://arxiv.org/abs/2506.06412", "authors": ["Junming Wang", "Yi Shi"], "title": "NeurNCD: Novel Class Discovery via Implicit Neural Representation", "categories": ["cs.LG", "cs.CV"], "comment": "Accepted by ICMR 2024", "summary": "Discovering novel classes in open-world settings is crucial for real-world\napplications. Traditional explicit representations, such as object descriptors\nor 3D segmentation maps, are constrained by their discrete, hole-prone, and\nnoisy nature, which hinders accurate novel class discovery. To address these\nchallenges, we introduce NeurNCD, the first versatile and data-efficient\nframework for novel class discovery that employs the meticulously designed\nEmbedding-NeRF model combined with KL divergence as a substitute for\ntraditional explicit 3D segmentation maps to aggregate semantic embedding and\nentropy in visual embedding space. NeurNCD also integrates several key\ncomponents, including feature query, feature modulation and clustering,\nfacilitating efficient feature augmentation and information exchange between\nthe pre-trained semantic segmentation network and implicit neural\nrepresentations. As a result, our framework achieves superior segmentation\nperformance in both open and closed-world settings without relying on densely\nlabelled datasets for supervised training or human interaction to generate\nsparse label supervision. Extensive experiments demonstrate that our method\nsignificantly outperforms state-of-the-art approaches on the NYUv2 and Replica\ndatasets.", "AI": {"tldr": "NeurNCD\u662f\u4e00\u79cd\u7528\u4e8e\u5f00\u653e\u4e16\u754c\u65b0\u7c7b\u53d1\u73b0\u7684\u6570\u636e\u9ad8\u6548\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408Embedding-NeRF\u6a21\u578b\u548cKL\u6563\u5ea6\uff0c\u66ff\u4ee3\u4f20\u7edf\u663e\u5f0f3D\u5206\u5272\u56fe\uff0c\u63d0\u5347\u8bed\u4e49\u5d4c\u5165\u548c\u89c6\u89c9\u5d4c\u5165\u7a7a\u95f4\u7684\u4fe1\u606f\u805a\u5408\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u663e\u5f0f\u8868\u793a\uff08\u5982\u5bf9\u8c61\u63cf\u8ff0\u7b26\u62163D\u5206\u5272\u56fe\uff09\u5b58\u5728\u79bb\u6563\u3001\u6613\u4ea7\u751f\u6f0f\u6d1e\u548c\u566a\u58f0\u7684\u95ee\u9898\uff0c\u9650\u5236\u4e86\u65b0\u7c7b\u53d1\u73b0\u7684\u51c6\u786e\u6027\u3002", "method": "NeurNCD\u91c7\u7528Embedding-NeRF\u6a21\u578b\u7ed3\u5408KL\u6563\u5ea6\uff0c\u96c6\u6210\u7279\u5f81\u67e5\u8be2\u3001\u8c03\u5236\u548c\u805a\u7c7b\u7b49\u5173\u952e\u7ec4\u4ef6\uff0c\u5b9e\u73b0\u8bed\u4e49\u5206\u5272\u7f51\u7edc\u4e0e\u9690\u5f0f\u795e\u7ecf\u8868\u793a\u4e4b\u95f4\u7684\u9ad8\u6548\u4fe1\u606f\u4ea4\u6362\u3002", "result": "\u5728NYUv2\u548cReplica\u6570\u636e\u96c6\u4e0a\uff0cNeurNCD\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u65e0\u9700\u5bc6\u96c6\u6807\u6ce8\u6570\u636e\u6216\u4eba\u5de5\u4ea4\u4e92\u751f\u6210\u7a00\u758f\u6807\u7b7e\u76d1\u7763\u3002", "conclusion": "NeurNCD\u5728\u5f00\u653e\u548c\u5c01\u95ed\u4e16\u754c\u8bbe\u7f6e\u4e2d\u5747\u8868\u73b0\u51fa\u5353\u8d8a\u7684\u5206\u5272\u6027\u80fd\uff0c\u4e3a\u65b0\u7c7b\u53d1\u73b0\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.06443", "pdf": "https://arxiv.org/pdf/2506.06443", "abs": "https://arxiv.org/abs/2506.06443", "authors": ["Luis Pinto"], "title": "Unlocking Chemical Insights: Superior Molecular Representations from Intermediate Encoder Layers", "categories": ["cs.LG", "cs.AI", "physics.chem-ph", "q-bio.BM"], "comment": null, "summary": "Pretrained molecular encoders have become indispensable in computational\nchemistry for tasks such as property prediction and molecular generation.\nHowever, the standard practice of relying solely on final-layer embeddings for\ndownstream tasks may discard valuable information. In this work, we challenge\nthis convention by conducting a comprehensive layer-wise analysis of five\ndiverse molecular encoders across 22 ADMET property prediction tasks. Our\nresults demonstrate that embeddings from intermediate layers consistently\noutperform final-layer representations. Specifically, using fixed embeddings\nfrom the optimal intermediate layers improved downstream performance by an\naverage of 5.4%, reaching gains up to 28.6%. Furthermore, finetuning up to\nthese intermediate layers yielded even greater average improvements of 8.5%,\nwith performance increases as high as 40.8%, achieving new state-of-the-art\nresults on several benchmarks. Additionally, a strong positive correlation\nbetween fixed embedding performance and finetuning outcomes supports an\nefficient evaluate-then-finetune approach, enabling identification of optimal\nlayers with reduced computational cost. These findings highlight the importance\nof exploring the full representational depth of molecular encoders to achieve\nsubstantial performance improvements and computational efficiency. The code is\nmade publicly available at\nhttps://github.com/luispintoc/Unlocking-Chemical-Insights.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u5206\u5b50\u7f16\u7801\u5668\u7684\u4e2d\u95f4\u5c42\u5d4c\u5165\u6bd4\u6700\u7ec8\u5c42\u8868\u73b0\u66f4\u597d\uff0c\u56fa\u5b9a\u5d4c\u5165\u5e73\u5747\u63d0\u53475.4%\uff0c\u5fae\u8c03\u540e\u5e73\u5747\u63d0\u53478.5%\uff0c\u5e76\u63d0\u51fa\u4e86\u9ad8\u6548\u8bc4\u4f30\u518d\u5fae\u8c03\u7684\u65b9\u6cd5\u3002", "motivation": "\u6311\u6218\u4ec5\u4f9d\u8d56\u6700\u7ec8\u5c42\u5d4c\u5165\u7684\u5e38\u89c4\u505a\u6cd5\uff0c\u63a2\u7d22\u5206\u5b50\u7f16\u7801\u5668\u5168\u5c42\u8868\u793a\u7684\u4ef7\u503c\u3002", "method": "\u5bf9\u4e94\u79cd\u5206\u5b50\u7f16\u7801\u5668\u8fdb\u884c\u5206\u5c42\u5206\u6790\uff0c\u6d4b\u8bd522\u79cdADMET\u6027\u8d28\u9884\u6d4b\u4efb\u52a1\uff0c\u6bd4\u8f83\u56fa\u5b9a\u5d4c\u5165\u548c\u5fae\u8c03\u6548\u679c\u3002", "result": "\u4e2d\u95f4\u5c42\u5d4c\u5165\u8868\u73b0\u66f4\u4f18\uff0c\u56fa\u5b9a\u5d4c\u5165\u5e73\u5747\u63d0\u53475.4%\uff0c\u5fae\u8c03\u540e\u5e73\u5747\u63d0\u53478.5%\uff0c\u90e8\u5206\u4efb\u52a1\u63d0\u5347\u9ad8\u8fbe40.8%\u3002", "conclusion": "\u5145\u5206\u5229\u7528\u5206\u5b50\u7f16\u7801\u5668\u7684\u5168\u5c42\u8868\u793a\u53ef\u663e\u8457\u63d0\u5347\u6027\u80fd\u4e0e\u8ba1\u7b97\u6548\u7387\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2506.06444", "pdf": "https://arxiv.org/pdf/2506.06444", "abs": "https://arxiv.org/abs/2506.06444", "authors": ["Ruizhong Qiu", "Gaotang Li", "Tianxin Wei", "Jingrui He", "Hanghang Tong"], "title": "Saffron-1: Towards an Inference Scaling Paradigm for LLM Safety Assurance", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": "19 pages", "summary": "Existing safety assurance research has primarily focused on training-phase\nalignment to instill safe behaviors into LLMs. However, recent studies have\nexposed these methods' susceptibility to diverse jailbreak attacks.\nConcurrently, inference scaling has significantly advanced LLM reasoning\ncapabilities but remains unexplored in the context of safety assurance.\nAddressing this gap, our work pioneers inference scaling for robust and\neffective LLM safety against emerging threats. We reveal that conventional\ninference scaling techniques, despite their success in reasoning tasks, perform\npoorly in safety contexts, even falling short of basic approaches like\nBest-of-N Sampling. We attribute this inefficiency to a newly identified\nchallenge, the exploration--efficiency dilemma, arising from the high\ncomputational overhead associated with frequent process reward model (PRM)\nevaluations. To overcome this dilemma, we propose SAFFRON, a novel inference\nscaling paradigm tailored explicitly for safety assurance. Central to our\napproach is the introduction of a multifurcation reward model (MRM) that\nsignificantly reduces the required number of reward model evaluations. To\noperationalize this paradigm, we further propose: (i) a partial supervision\ntraining objective for MRM, (ii) a conservative exploration constraint to\nprevent out-of-distribution explorations, and (iii) a Trie-based key--value\ncaching strategy that facilitates cache sharing across sequences during tree\nsearch. Extensive experiments validate the effectiveness of our method.\nAdditionally, we publicly release our trained multifurcation reward model\n(Saffron-1) and the accompanying token-level safety reward dataset (Safety4M)\nto accelerate future research in LLM safety. Our code, model, and data are\npublicly available at https://github.com/q-rz/saffron , and our project\nhomepage is at https://q-rz.github.io/p/saffron .", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faSAFFRON\uff0c\u4e00\u79cd\u9488\u5bf9LLM\u5b89\u5168\u6027\u7684\u65b0\u578b\u63a8\u7406\u6269\u5c55\u8303\u5f0f\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u5b89\u5168\u6027\u4e0a\u4e0b\u6587\u4e2d\u7684\u4f4e\u6548\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u5b89\u5168\u4fdd\u8bc1\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u8bad\u7ec3\u9636\u6bb5\u7684\u5bf9\u9f50\uff0c\u4f46\u6613\u53d7\u8d8a\u72f1\u653b\u51fb\u5f71\u54cd\uff0c\u800c\u63a8\u7406\u6269\u5c55\u5728\u5b89\u5168\u6027\u9886\u57df\u7684\u6f5c\u529b\u5c1a\u672a\u63a2\u7d22\u3002", "method": "\u63d0\u51faSAFFRON\u8303\u5f0f\uff0c\u5f15\u5165\u591a\u53c9\u5956\u52b1\u6a21\u578b\uff08MRM\uff09\u51cf\u5c11\u5956\u52b1\u6a21\u578b\u8bc4\u4f30\u6b21\u6570\uff0c\u5e76\u8bbe\u8ba1\u90e8\u5206\u76d1\u7763\u8bad\u7ec3\u76ee\u6807\u3001\u4fdd\u5b88\u63a2\u7d22\u7ea6\u675f\u548cTrie\u7f13\u5b58\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86SAFFRON\u7684\u6709\u6548\u6027\uff0c\u5e76\u516c\u5f00\u4e86\u6a21\u578b\u548c\u6570\u636e\u96c6\u4ee5\u63a8\u52a8\u672a\u6765\u7814\u7a76\u3002", "conclusion": "SAFFRON\u4e3aLLM\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u586b\u8865\u4e86\u63a8\u7406\u6269\u5c55\u5728\u5b89\u5168\u9886\u57df\u7684\u7a7a\u767d\u3002"}}
{"id": "2506.06454", "pdf": "https://arxiv.org/pdf/2506.06454", "abs": "https://arxiv.org/abs/2506.06454", "authors": ["Abrar Majeedi", "Viswanatha Reddy Gajjala", "Satya Sai Srinath Namburi GNVV", "Nada Magdi Elkordi", "Yin Li"], "title": "LETS Forecast: Learning Embedology for Time Series Forecasting", "categories": ["cs.LG", "stat.ML"], "comment": "Accepted at International Conference on Machine Learning (ICML) 2025", "summary": "Real-world time series are often governed by complex nonlinear dynamics.\nUnderstanding these underlying dynamics is crucial for precise future\nprediction. While deep learning has achieved major success in time series\nforecasting, many existing approaches do not explicitly model the dynamics. To\nbridge this gap, we introduce DeepEDM, a framework that integrates nonlinear\ndynamical systems modeling with deep neural networks. Inspired by empirical\ndynamic modeling (EDM) and rooted in Takens' theorem, DeepEDM presents a novel\ndeep model that learns a latent space from time-delayed embeddings, and employs\nkernel regression to approximate the underlying dynamics, while leveraging\nefficient implementation of softmax attention and allowing for accurate\nprediction of future time steps. To evaluate our method, we conduct\ncomprehensive experiments on synthetic data of nonlinear dynamical systems as\nwell as real-world time series across domains. Our results show that DeepEDM is\nrobust to input noise, and outperforms state-of-the-art methods in forecasting\naccuracy. Our code is available at: https://abrarmajeedi.github.io/deep_edm.", "AI": {"tldr": "DeepEDM\u662f\u4e00\u4e2a\u7ed3\u5408\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u5efa\u6a21\u4e0e\u6df1\u5ea6\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5b66\u4e60\u5ef6\u8fdf\u5d4c\u5165\u7684\u6f5c\u5728\u7a7a\u95f4\u548c\u6838\u56de\u5f52\u6765\u903c\u8fd1\u52a8\u6001\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u7684\u65f6\u95f4\u5e8f\u5217\u901a\u5e38\u5177\u6709\u590d\u6742\u7684\u975e\u7ebf\u6027\u52a8\u6001\uff0c\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u672a\u660e\u786e\u5efa\u6a21\u8fd9\u4e9b\u52a8\u6001\u3002", "method": "DeepEDM\u7ed3\u5408\u4e86\u7ecf\u9a8c\u52a8\u6001\u5efa\u6a21\uff08EDM\uff09\u548c\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff0c\u5229\u7528\u5ef6\u8fdf\u5d4c\u5165\u5b66\u4e60\u6f5c\u5728\u7a7a\u95f4\uff0c\u5e76\u901a\u8fc7\u6838\u56de\u5f52\u903c\u8fd1\u52a8\u6001\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cDeepEDM\u5bf9\u8f93\u5165\u566a\u58f0\u5177\u6709\u9c81\u68d2\u6027\uff0c\u5e76\u5728\u9884\u6d4b\u7cbe\u5ea6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "DeepEDM\u6210\u529f\u5730\u5c06\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u5efa\u6a21\u4e0e\u6df1\u5ea6\u5b66\u4e60\u7ed3\u5408\uff0c\u63d0\u5347\u4e86\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2506.06455", "pdf": "https://arxiv.org/pdf/2506.06455", "abs": "https://arxiv.org/abs/2506.06455", "authors": ["Antonio Jes\u00fas Banegas-Luna", "Horacio P\u00e9rez-S\u00e1nchez", "Carlos Mart\u00ednez-Cort\u00e9s"], "title": "WISCA: A Consensus-Based Approach to Harmonizing Interpretability in Tabular Datasets", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "27 pages, 11 figures, 2 tables, 13 equations", "summary": "While predictive accuracy is often prioritized in machine learning (ML)\nmodels, interpretability remains essential in scientific and high-stakes\ndomains. However, diverse interpretability algorithms frequently yield\nconflicting explanations, highlighting the need for consensus to harmonize\nresults. In this study, six ML models were trained on six synthetic datasets\nwith known ground truths, utilizing various model-agnostic interpretability\ntechniques. Consensus explanations were generated using established methods and\na novel approach: WISCA (Weighted Scaled Consensus Attributions), which\nintegrates class probability and normalized attributions. WISCA consistently\naligned with the most reliable individual method, underscoring the value of\nrobust consensus strategies in improving explanation reliability.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5171\u8bc6\u65b9\u6cd5WISCA\uff0c\u7528\u4e8e\u6574\u5408\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u89e3\u91ca\u6027\u7ed3\u679c\uff0c\u4ee5\u63d0\u9ad8\u53ef\u9760\u6027\u3002", "motivation": "\u5728\u79d1\u5b66\u548c\u9ad8\u98ce\u9669\u9886\u57df\uff0c\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u89e3\u91ca\u65b9\u6cd5\u5e38\u4ea7\u751f\u51b2\u7a81\u7ed3\u679c\uff0c\u9700\u8981\u5171\u8bc6\u7b56\u7565\u6765\u7edf\u4e00\u3002", "method": "\u4f7f\u7528\u516d\u79cd\u6a21\u578b\u548c\u5408\u6210\u6570\u636e\u96c6\uff0c\u7ed3\u5408\u591a\u79cd\u6a21\u578b\u65e0\u5173\u7684\u89e3\u91ca\u6280\u672f\uff0c\u63d0\u51faWISCA\u65b9\u6cd5\u6574\u5408\u6982\u7387\u548c\u5f52\u4e00\u5316\u5c5e\u6027\u3002", "result": "WISCA\u4e0e\u6700\u53ef\u9760\u7684\u4e2a\u4f53\u65b9\u6cd5\u4e00\u81f4\uff0c\u9a8c\u8bc1\u4e86\u5171\u8bc6\u7b56\u7565\u5728\u63d0\u5347\u89e3\u91ca\u53ef\u9760\u6027\u4e2d\u7684\u4ef7\u503c\u3002", "conclusion": "WISCA\u662f\u4e00\u79cd\u6709\u6548\u7684\u5171\u8bc6\u65b9\u6cd5\uff0c\u80fd\u663e\u8457\u63d0\u9ad8\u673a\u5668\u5b66\u4e60\u6a21\u578b\u89e3\u91ca\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2506.06459", "pdf": "https://arxiv.org/pdf/2506.06459", "abs": "https://arxiv.org/abs/2506.06459", "authors": ["Ruitao Chen", "Mozhang Guo", "Jinge Li"], "title": "Towards Infant Sleep-Optimized Driving: Synergizing Wearable and Vehicle Sensing in Intelligent Cruise Control", "categories": ["cs.LG", "cs.ET", "cs.RO", "cs.SY", "eess.SY"], "comment": null, "summary": "Automated driving (AD) has substantially improved vehicle safety and driving\ncomfort, but their impact on passenger well-being, particularly infant sleep,\nis not sufficiently studied. Sudden acceleration, abrupt braking, and sharp\nmaneuvers can disrupt infant sleep, compromising both passenger comfort and\nparental convenience. To solve this problem, this paper explores the\nintegration of reinforcement learning (RL) within AD to personalize driving\nbehavior and optimally balance occupant comfort and travel efficiency. In\nparticular, we propose an intelligent cruise control framework that adapts to\nvarying driving conditions to enhance infant sleep quality by effectively\nsynergizing wearable sensing and vehicle data. Long short-term memory (LSTM)\nand transformer-based neural networks are integrated with RL to model the\nrelationship between driving behavior and infant sleep quality under diverse\ntraffic and road conditions. Based on the sleep quality indicators from the\nwearable sensors, driving action data from vehicle controllers, and map data\nfrom map applications, the model dynamically computes the optimal driving\naggressiveness level, which is subsequently translated into specific AD control\nstrategies, e.g., the magnitude and frequency of acceleration, lane change, and\novertaking. Simulation results demonstrate that the proposed solution\nsignificantly improves infant sleep quality compared to baseline methods, while\npreserving desirable travel efficiency.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u7684\u667a\u80fd\u5de1\u822a\u63a7\u5236\u6846\u67b6\uff0c\u901a\u8fc7\u4f18\u5316\u9a7e\u9a76\u884c\u4e3a\u63d0\u5347\u5a74\u513f\u7761\u7720\u8d28\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u51fa\u884c\u6548\u7387\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u867d\u63d0\u5347\u4e86\u5b89\u5168\u6027\u548c\u8212\u9002\u6027\uff0c\u4f46\u5bf9\u5a74\u513f\u7761\u7720\u7684\u5f71\u54cd\u7814\u7a76\u4e0d\u8db3\u3002\u6025\u52a0\u901f\u3001\u6025\u5239\u8f66\u7b49\u884c\u4e3a\u53ef\u80fd\u5e72\u6270\u5a74\u513f\u7761\u7720\uff0c\u5f71\u54cd\u4e58\u5ba2\u8212\u9002\u5ea6\u548c\u5bb6\u957f\u4fbf\u5229\u6027\u3002", "method": "\u6574\u5408LSTM\u548cTransformer\u795e\u7ecf\u7f51\u7edc\u4e0e\u5f3a\u5316\u5b66\u4e60\uff0c\u5229\u7528\u7a7f\u6234\u8bbe\u5907\u6570\u636e\u548c\u8f66\u8f86\u6570\u636e\u52a8\u6001\u4f18\u5316\u9a7e\u9a76\u884c\u4e3a\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u5a74\u513f\u7761\u7720\u8d28\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u51fa\u884c\u6548\u7387\u3002", "conclusion": "\u7814\u7a76\u4e3a\u81ea\u52a8\u9a7e\u9a76\u4e2d\u4e58\u5ba2\u8212\u9002\u5ea6\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u6709\u5a74\u513f\u7684\u5bb6\u5ead\u3002"}}
{"id": "2506.06482", "pdf": "https://arxiv.org/pdf/2506.06482", "abs": "https://arxiv.org/abs/2506.06482", "authors": ["Zhiyuan Zhao", "Juntong Ni", "Shangqing Xu", "Haoxin Liu", "Wei Jin", "B. Aditya Prakash"], "title": "TimeRecipe: A Time-Series Forecasting Recipe via Benchmarking Module Level Effectiveness", "categories": ["cs.LG"], "comment": "46 pages, 1 figure, 28 tables", "summary": "Time-series forecasting is an essential task with wide real-world\napplications across domains. While recent advances in deep learning have\nenabled time-series forecasting models with accurate predictions, there remains\nconsiderable debate over which architectures and design components, such as\nseries decomposition or normalization, are most effective under varying\nconditions. Existing benchmarks primarily evaluate models at a high level,\noffering limited insight into why certain designs work better. To mitigate this\ngap, we propose TimeRecipe, a unified benchmarking framework that\nsystematically evaluates time-series forecasting methods at the module level.\nTimeRecipe conducts over 10,000 experiments to assess the effectiveness of\nindividual components across a diverse range of datasets, forecasting horizons,\nand task settings. Our results reveal that exhaustive exploration of the design\nspace can yield models that outperform existing state-of-the-art methods and\nuncover meaningful intuitions linking specific design choices to forecasting\nscenarios. Furthermore, we release a practical toolkit within TimeRecipe that\nrecommends suitable model architectures based on these empirical insights. The\nbenchmark is available at: https://github.com/AdityaLab/TimeRecipe.", "AI": {"tldr": "TimeRecipe\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u57fa\u51c6\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u5757\u7ea7\u8bc4\u4f30\u63ed\u793a\u8bbe\u8ba1\u9009\u62e9\u7684\u6709\u6548\u6027\uff0c\u5e76\u63a8\u8350\u6700\u4f73\u6a21\u578b\u67b6\u6784\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u5bf9\u6a21\u578b\u8bc4\u4f30\u8f83\u4e3a\u7b3c\u7edf\uff0c\u7f3a\u4e4f\u5bf9\u8bbe\u8ba1\u7ec4\u4ef6\u6709\u6548\u6027\u7684\u6df1\u5165\u7406\u89e3\u3002", "method": "TimeRecipe\u901a\u8fc710,000\u591a\u6b21\u5b9e\u9a8c\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e0d\u540c\u8bbe\u8ba1\u7ec4\u4ef6\u5728\u591a\u6837\u5316\u6570\u636e\u96c6\u548c\u4efb\u52a1\u8bbe\u7f6e\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5168\u9762\u63a2\u7d22\u8bbe\u8ba1\u7a7a\u95f4\u53ef\u4ee5\u8d85\u8d8a\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\uff0c\u5e76\u63ed\u793a\u8bbe\u8ba1\u9009\u62e9\u4e0e\u9884\u6d4b\u573a\u666f\u7684\u5173\u8054\u3002", "conclusion": "TimeRecipe\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u5de5\u5177\u5305\uff0c\u57fa\u4e8e\u5b9e\u8bc1\u7ed3\u679c\u63a8\u8350\u6a21\u578b\u67b6\u6784\uff0c\u586b\u8865\u4e86\u73b0\u6709\u57fa\u51c6\u7684\u4e0d\u8db3\u3002"}}
{"id": "2506.06486", "pdf": "https://arxiv.org/pdf/2506.06486", "abs": "https://arxiv.org/abs/2506.06486", "authors": ["Umit Yigit Basaran", "Sk Miraj Ahmed", "Amit Roy-Chowdhury", "Basak Guler"], "title": "A Certified Unlearning Approach without Access to Source Data", "categories": ["cs.LG", "cs.CR", "stat.ML"], "comment": "Accepted by ICML 2025", "summary": "With the growing adoption of data privacy regulations, the ability to erase\nprivate or copyrighted information from trained models has become a crucial\nrequirement. Traditional unlearning methods often assume access to the complete\ntraining dataset, which is unrealistic in scenarios where the source data is no\nlonger available. To address this challenge, we propose a certified unlearning\nframework that enables effective data removal \\final{without access to the\noriginal training data samples}. Our approach utilizes a surrogate dataset that\napproximates the statistical properties of the source data, allowing for\ncontrolled noise scaling based on the statistical distance between the two.\n\\updated{While our theoretical guarantees assume knowledge of the exact\nstatistical distance, practical implementations typically approximate this\ndistance, resulting in potentially weaker but still meaningful privacy\nguarantees.} This ensures strong guarantees on the model's behavior\npost-unlearning while maintaining its overall utility. We establish theoretical\nbounds, introduce practical noise calibration techniques, and validate our\nmethod through extensive experiments on both synthetic and real-world datasets.\nThe results demonstrate the effectiveness and reliability of our approach in\nprivacy-sensitive settings.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u539f\u59cb\u8bad\u7ec3\u6570\u636e\u7684\u8ba4\u8bc1\u9057\u5fd8\u6846\u67b6\uff0c\u901a\u8fc7\u66ff\u4ee3\u6570\u636e\u96c6\u8fd1\u4f3c\u6e90\u6570\u636e\u7edf\u8ba1\u7279\u6027\uff0c\u5b9e\u73b0\u6709\u6548\u6570\u636e\u5220\u9664\u3002", "motivation": "\u968f\u7740\u6570\u636e\u9690\u79c1\u6cd5\u89c4\u7684\u666e\u53ca\uff0c\u4ece\u8bad\u7ec3\u6a21\u578b\u4e2d\u5220\u9664\u79c1\u6709\u6216\u53d7\u7248\u6743\u4fdd\u62a4\u4fe1\u606f\u7684\u9700\u6c42\u65e5\u76ca\u91cd\u8981\u3002\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u5b8c\u6574\u8bad\u7ec3\u6570\u636e\uff0c\u4f46\u73b0\u5b9e\u4e2d\u6e90\u6570\u636e\u53ef\u80fd\u4e0d\u53ef\u7528\u3002", "method": "\u5229\u7528\u66ff\u4ee3\u6570\u636e\u96c6\u8fd1\u4f3c\u6e90\u6570\u636e\u7edf\u8ba1\u7279\u6027\uff0c\u901a\u8fc7\u63a7\u5236\u566a\u58f0\u7f29\u653e\u5b9e\u73b0\u6570\u636e\u5220\u9664\u3002\u7406\u8bba\u4fdd\u8bc1\u57fa\u4e8e\u7edf\u8ba1\u8ddd\u79bb\uff0c\u5b9e\u9645\u5b9e\u73b0\u4e2d\u8fd1\u4f3c\u8be5\u8ddd\u79bb\u3002", "result": "\u7406\u8bba\u8fb9\u754c\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u9690\u79c1\u654f\u611f\u573a\u666f\u4e2d\u6709\u6548\u53ef\u9760\uff0c\u4fdd\u6301\u6a21\u578b\u5b9e\u7528\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u8ba4\u8bc1\u9057\u5fd8\u6846\u67b6\u5728\u65e0\u9700\u539f\u59cb\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u5b9e\u73b0\u4e86\u5f3a\u9690\u79c1\u4fdd\u8bc1\u548c\u6a21\u578b\u5b9e\u7528\u6027\u3002"}}
{"id": "2506.06488", "pdf": "https://arxiv.org/pdf/2506.06488", "abs": "https://arxiv.org/abs/2506.06488", "authors": ["Pratiksha Thaker", "Neil Kale", "Zhiwei Steven Wu", "Virginia Smith"], "title": "Membership Inference Attacks for Unseen Classes", "categories": ["cs.LG", "cs.CR", "stat.ML"], "comment": "Preprint", "summary": "Shadow model attacks are the state-of-the-art approach for membership\ninference attacks on machine learning models. However, these attacks typically\nassume an adversary has access to a background (nonmember) data distribution\nthat matches the distribution the target model was trained on. We initiate a\nstudy of membership inference attacks where the adversary or auditor cannot\naccess an entire subclass from the distribution -- a more extreme but realistic\nversion of distribution shift than has been studied previously. In this\nsetting, we first show that the performance of shadow model attacks degrades\ncatastrophically, and then demonstrate the promise of another approach,\nquantile regression, that does not have the same limitations. We show that\nquantile regression attacks consistently outperform shadow model attacks in the\nclass dropout setting -- for example, quantile regression attacks achieve up to\n11$\\times$ the TPR of shadow models on the unseen class on CIFAR-100, and\nachieve nontrivial TPR on ImageNet even with 90% of training classes removed.\nWe also provide a theoretical model that illustrates the potential and\nlimitations of this approach.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5728\u65e0\u6cd5\u8bbf\u95ee\u5b8c\u6574\u5b50\u7c7b\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u6210\u5458\u63a8\u7406\u653b\u51fb\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5206\u4f4d\u6570\u56de\u5f52\u7684\u65b0\u65b9\u6cd5\uff0c\u5176\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u7684\u5f71\u5b50\u6a21\u578b\u653b\u51fb\u3002", "motivation": "\u73b0\u6709\u5f71\u5b50\u6a21\u578b\u653b\u51fb\u5047\u8bbe\u653b\u51fb\u8005\u80fd\u8bbf\u95ee\u4e0e\u76ee\u6807\u6a21\u578b\u8bad\u7ec3\u6570\u636e\u5206\u5e03\u5339\u914d\u7684\u80cc\u666f\u6570\u636e\uff0c\u4f46\u5728\u5b9e\u9645\u4e2d\uff0c\u653b\u51fb\u8005\u53ef\u80fd\u65e0\u6cd5\u8bbf\u95ee\u5b8c\u6574\u5b50\u7c7b\u6570\u636e\u3002\u8bba\u6587\u63a2\u8ba8\u4e86\u8fd9\u79cd\u6781\u7aef\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u6210\u5458\u63a8\u7406\u653b\u51fb\u95ee\u9898\u3002", "method": "\u8bba\u6587\u6bd4\u8f83\u4e86\u5f71\u5b50\u6a21\u578b\u653b\u51fb\u548c\u5206\u4f4d\u6570\u56de\u5f52\u653b\u51fb\u5728\u7c7b\u4e22\u5931\u8bbe\u7f6e\u4e0b\u7684\u6027\u80fd\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5206\u4f4d\u6570\u56de\u5f52\u65b9\u6cd5\u7684\u4f18\u52bf\u3002", "result": "\u5206\u4f4d\u6570\u56de\u5f52\u653b\u51fb\u5728\u7c7b\u4e22\u5931\u8bbe\u7f6e\u4e0b\u8868\u73b0\u4f18\u5f02\uff0c\u4f8b\u5982\u5728CIFAR-100\u4e0a\u5bf9\u672a\u89c1\u7c7b\u7684TPR\u662f\u5f71\u5b50\u6a21\u578b\u768411\u500d\uff0c\u5728ImageNet\u4e0a\u5373\u4f7f\u79fb\u966490%\u7684\u8bad\u7ec3\u7c7b\u4ecd\u80fd\u53d6\u5f97\u663e\u8457\u6548\u679c\u3002", "conclusion": "\u5206\u4f4d\u6570\u56de\u5f52\u653b\u51fb\u5728\u6781\u7aef\u5206\u5e03\u504f\u79fb\u4e0b\u4f18\u4e8e\u5f71\u5b50\u6a21\u578b\u653b\u51fb\uff0c\u8bba\u6587\u8fd8\u63d0\u4f9b\u4e86\u7406\u8bba\u6a21\u578b\u8bf4\u660e\u5176\u6f5c\u529b\u4e0e\u5c40\u9650\u6027\u3002"}}
{"id": "2506.06489", "pdf": "https://arxiv.org/pdf/2506.06489", "abs": "https://arxiv.org/abs/2506.06489", "authors": ["Daniel Kunin", "Giovanni Luca Marchetti", "Feng Chen", "Dhruva Karkada", "James B. Simon", "Michael R. DeWeese", "Surya Ganguli", "Nina Miolane"], "title": "Alternating Gradient Flows: A Theory of Feature Learning in Two-layer Neural Networks", "categories": ["cs.LG", "stat.ML"], "comment": "35 pages, 7 figures", "summary": "What features neural networks learn, and how, remains an open question. In\nthis paper, we introduce Alternating Gradient Flows (AGF), an algorithmic\nframework that describes the dynamics of feature learning in two-layer networks\ntrained from small initialization. Prior works have shown that gradient flow in\nthis regime exhibits a staircase-like loss curve, alternating between plateaus\nwhere neurons slowly align to useful directions and sharp drops where neurons\nrapidly grow in norm. AGF approximates this behavior as an alternating two-step\nprocess: maximizing a utility function over dormant neurons and minimizing a\ncost function over active ones. AGF begins with all neurons dormant. At each\nround, a dormant neuron activates, triggering the acquisition of a feature and\na drop in the loss. AGF quantifies the order, timing, and magnitude of these\ndrops, matching experiments across architectures. We show that AGF unifies and\nextends existing saddle-to-saddle analyses in fully connected linear networks\nand attention-only linear transformers, where the learned features are singular\nmodes and principal components, respectively. In diagonal linear networks, we\nprove AGF converges to gradient flow in the limit of vanishing initialization.\nApplying AGF to quadratic networks trained to perform modular addition, we give\nthe first complete characterization of the training dynamics, revealing that\nnetworks learn Fourier features in decreasing order of coefficient magnitude.\nAltogether, AGF offers a promising step towards understanding feature learning\nin neural networks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4ea4\u66ff\u68af\u5ea6\u6d41\uff08AGF\uff09\u6846\u67b6\uff0c\u7528\u4e8e\u63cf\u8ff0\u5c0f\u521d\u59cb\u5316\u4e0b\u4e24\u5c42\u795e\u7ecf\u7f51\u7edc\u7684\u7279\u5f81\u5b66\u4e60\u52a8\u6001\uff0c\u7edf\u4e00\u5e76\u6269\u5c55\u4e86\u73b0\u6709\u5206\u6790\u3002", "motivation": "\u7814\u7a76\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u7684\u7279\u5f81\u53ca\u5176\u52a8\u6001\u8fc7\u7a0b\uff0c\u586b\u8865\u73b0\u6709\u7406\u8bba\u7a7a\u767d\u3002", "method": "\u63d0\u51faAGF\u6846\u67b6\uff0c\u5c06\u68af\u5ea6\u6d41\u884c\u4e3a\u8fd1\u4f3c\u4e3a\u4ea4\u66ff\u4e24\u6b65\u8fc7\u7a0b\uff1a\u4f11\u7720\u795e\u7ecf\u5143\u6700\u5927\u5316\u6548\u7528\u51fd\u6570\uff0c\u6d3b\u8dc3\u795e\u7ecf\u5143\u6700\u5c0f\u5316\u6210\u672c\u51fd\u6570\u3002", "result": "AGF\u91cf\u5316\u4e86\u7279\u5f81\u83b7\u53d6\u7684\u987a\u5e8f\u3001\u65f6\u95f4\u548c\u5e45\u5ea6\uff0c\u4e0e\u5b9e\u9a8c\u4e00\u81f4\uff0c\u5e76\u5728\u591a\u79cd\u67b6\u6784\u4e2d\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "conclusion": "AGF\u4e3a\u7406\u89e3\u795e\u7ecf\u7f51\u7edc\u7684\u7279\u5f81\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u662f\u7406\u8bba\u5206\u6790\u7684\u91cd\u8981\u8fdb\u5c55\u3002"}}
{"id": "2506.06499", "pdf": "https://arxiv.org/pdf/2506.06499", "abs": "https://arxiv.org/abs/2506.06499", "authors": ["Alex Havrilla", "Edward Hughes", "Mikayel Samvelyan", "Jacob Abernethy"], "title": "Synthetic Problem Generation for Reasoning via Quality-Diversity Algorithms", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language model (LLM) driven synthetic data generation has emerged as a\npowerful method for improving model reasoning capabilities. However, most\nmethods either distill large state-of-the-art models into small students or use\nnatural ground-truth problem statements to guarantee problem statement quality.\nThis limits the scalability of these approaches to more complex and diverse\nproblem domains. To address this, we present SPARQ: Synthetic Problem\nGeneration for Reasoning via Quality-Diversity Algorithms, a novel approach for\ngenerating high-quality and diverse synthetic math problem and solution pairs\nusing only a single model by measuring a problem's solve-rate: a proxy for\nproblem difficulty. Starting from a seed dataset of 7.5K samples, we generate\nover 20 million new problem-solution pairs. We show that filtering the\ngenerated data by difficulty and then fine-tuning the same model on the\nresulting data improves relative model performance by up to 24\\%. Additionally,\nwe conduct ablations studying the impact of synthetic data quantity, quality\nand diversity on model generalization. We find that higher quality, as measured\nby problem difficulty, facilitates better in-distribution performance. Further,\nwhile generating diverse synthetic data does not as strongly benefit\nin-distribution performance, filtering for more diverse data facilitates more\nrobust OOD generalization. We also confirm the existence of model and data\nscaling laws for synthetically generated problems, which positively benefit\ndownstream model generalization.", "AI": {"tldr": "SPARQ\u5229\u7528\u8d28\u91cf-\u591a\u6837\u6027\u7b97\u6cd5\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u591a\u6837\u5316\u7684\u6570\u5b66\u95ee\u9898-\u89e3\u51b3\u65b9\u6848\u5bf9\uff0c\u901a\u8fc7\u5355\u4e00\u6a21\u578b\u6d4b\u91cf\u95ee\u9898\u89e3\u51b3\u7387\uff08\u96be\u5ea6\u4ee3\u7406\uff09\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u5927\u6a21\u578b\u84b8\u998f\u6216\u81ea\u7136\u771f\u5b9e\u95ee\u9898\uff0c\u9650\u5236\u4e86\u590d\u6742\u548c\u591a\u6837\u5316\u95ee\u9898\u9886\u57df\u7684\u6269\u5c55\u6027\u3002", "method": "SPARQ\u901a\u8fc7\u8d28\u91cf-\u591a\u6837\u6027\u7b97\u6cd5\u751f\u6210\u95ee\u9898-\u89e3\u51b3\u65b9\u6848\u5bf9\uff0c\u57fa\u4e8e\u89e3\u51b3\u7387\u7b5b\u9009\u6570\u636e\uff0c\u5e76\u7528\u5176\u5fae\u8c03\u6a21\u578b\u3002", "result": "\u751f\u62102000\u4e07\u5bf9\u6570\u636e\uff0c\u5fae\u8c03\u540e\u6a21\u578b\u6027\u80fd\u63d0\u534724%\uff1b\u591a\u6837\u6027\u548c\u8d28\u91cf\u5206\u522b\u5f71\u54cd\u5206\u5e03\u5185\u548c\u5206\u5e03\u5916\u6cdb\u5316\u3002", "conclusion": "SPARQ\u5c55\u793a\u4e86\u5408\u6210\u6570\u636e\u751f\u6210\u7684\u53ef\u6269\u5c55\u6027\uff0c\u8d28\u91cf\u4e0e\u591a\u6837\u6027\u5bf9\u6a21\u578b\u6cdb\u5316\u5404\u6709\u8d21\u732e\u3002"}}
{"id": "2506.06501", "pdf": "https://arxiv.org/pdf/2506.06501", "abs": "https://arxiv.org/abs/2506.06501", "authors": ["Ran Levinstein", "Amit Attia", "Matan Schliserman", "Uri Sherman", "Tomer Koren", "Daniel Soudry", "Itay Evron"], "title": "Optimal Rates in Continual Linear Regression via Increasing Regularization", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We study realizable continual linear regression under random task orderings,\na common setting for developing continual learning theory. In this setup, the\nworst-case expected loss after $k$ learning iterations admits a lower bound of\n$\\Omega(1/k)$. However, prior work using an unregularized scheme has only\nestablished an upper bound of $O(1/k^{1/4})$, leaving a significant gap. Our\npaper proves that this gap can be narrowed, or even closed, using two\nfrequently used regularization schemes: (1) explicit isotropic $\\ell_2$\nregularization, and (2) implicit regularization via finite step budgets. We\nshow that these approaches, which are used in practice to mitigate forgetting,\nreduce to stochastic gradient descent (SGD) on carefully defined surrogate\nlosses. Through this lens, we identify a fixed regularization strength that\nyields a near-optimal rate of $O(\\log k / k)$. Moreover, formalizing and\nanalyzing a generalized variant of SGD for time-varying functions, we derive an\nincreasing regularization strength schedule that provably achieves an optimal\nrate of $O(1/k)$. This suggests that schedules that increase the regularization\ncoefficient or decrease the number of steps per task are beneficial, at least\nin the worst case.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u968f\u673a\u4efb\u52a1\u6392\u5e8f\u4e0b\u7684\u53ef\u5b9e\u73b0\u8fde\u7eed\u7ebf\u6027\u56de\u5f52\uff0c\u901a\u8fc7\u4e24\u79cd\u6b63\u5219\u5316\u65b9\u6cd5\u7f29\u5c0f\u6216\u6d88\u9664\u7406\u8bba\u4e0a\u7684\u6027\u80fd\u5dee\u8ddd\u3002", "motivation": "\u73b0\u6709\u672a\u6b63\u5219\u5316\u65b9\u6cd5\u7684\u4e0a\u754c\u4e0e\u7406\u8bba\u4e0b\u754c\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u6b63\u5219\u5316\u65b9\u6cd5\u6539\u8fdb\u6027\u80fd\u3002", "method": "\u91c7\u7528\u663e\u5f0f\u5404\u5411\u540c\u6027\u21132\u6b63\u5219\u5316\u548c\u9690\u5f0f\u6b63\u5219\u5316\uff08\u6709\u9650\u6b65\u9884\u7b97\uff09\uff0c\u5e76\u5c06\u5176\u8f6c\u5316\u4e3a\u5bf9\u7279\u5b9a\u66ff\u4ee3\u635f\u5931\u7684SGD\u4f18\u5316\u3002", "result": "\u56fa\u5b9a\u6b63\u5219\u5316\u5f3a\u5ea6\u53ef\u5b9e\u73b0\u63a5\u8fd1\u6700\u4f18\u7684O(log k / k)\u901f\u7387\uff0c\u800c\u9012\u589e\u6b63\u5219\u5316\u5f3a\u5ea6\u8c03\u5ea6\u53ef\u8fbe\u5230\u6700\u4f18O(1/k)\u901f\u7387\u3002", "conclusion": "\u589e\u52a0\u6b63\u5219\u5316\u7cfb\u6570\u6216\u51cf\u5c11\u6bcf\u4efb\u52a1\u6b65\u6570\u7684\u8c03\u5ea6\u5728\u7406\u8bba\u4e0a\u662f\u6709\u76ca\u7684\u3002"}}
{"id": "2506.06505", "pdf": "https://arxiv.org/pdf/2506.06505", "abs": "https://arxiv.org/abs/2506.06505", "authors": ["Keisuke Sugiura", "Hiroki Matsutani"], "title": "InstantFT: An FPGA-Based Runtime Subsecond Fine-tuning of CNN Models", "categories": ["cs.LG", "cs.AR"], "comment": null, "summary": "Training deep neural networks (DNNs) requires significantly more computation\nand memory than inference, making runtime adaptation of DNNs challenging on\nresource-limited IoT platforms. We propose InstantFT, an FPGA-based method for\nultra-fast CNN fine-tuning on IoT devices, by optimizing the forward and\nbackward computations in parameter-efficient fine-tuning (PEFT). Experiments on\ndatasets with concept drift demonstrate that InstantFT fine-tunes a pre-trained\nCNN 17.4x faster than existing Low-Rank Adaptation (LoRA)-based approaches,\nwhile achieving comparable accuracy. Our FPGA-based InstantFT reduces the\nfine-tuning time to just 0.36s and improves energy-efficiency by 16.3x,\nenabling on-the-fly adaptation of CNNs to non-stationary data distributions.", "AI": {"tldr": "InstantFT\u662f\u4e00\u79cd\u57fa\u4e8eFPGA\u7684\u8d85\u5feb\u901fCNN\u5fae\u8c03\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u7684IoT\u8bbe\u5907\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8ba1\u7b97\u901f\u5ea6\u548c\u80fd\u6548\u3002", "motivation": "\u7531\u4e8e\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff08DNNs\uff09\u7684\u8bad\u7ec3\u9700\u8981\u5927\u91cf\u8ba1\u7b97\u548c\u5185\u5b58\uff0c\u8d44\u6e90\u53d7\u9650\u7684IoT\u5e73\u53f0\u96be\u4ee5\u5b9e\u73b0\u8fd0\u884c\u65f6\u9002\u5e94\u3002", "method": "\u901a\u8fc7\u4f18\u5316\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff08PEFT\uff09\u4e2d\u7684\u524d\u5411\u548c\u53cd\u5411\u8ba1\u7b97\uff0cInstantFT\u5728FPGA\u4e0a\u5b9e\u73b0\u4e86\u5feb\u901fCNN\u5fae\u8c03\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cInstantFT\u6bd4\u73b0\u6709\u7684LoRA\u65b9\u6cd5\u5feb17.4\u500d\uff0c\u5fae\u8c03\u65f6\u95f4\u4ec5\u4e3a0.36\u79d2\uff0c\u80fd\u6548\u63d0\u534716.3\u500d\u3002", "conclusion": "InstantFT\u80fd\u591f\u9ad8\u6548\u5730\u5728IoT\u8bbe\u5907\u4e0a\u5b9e\u73b0CNN\u7684\u52a8\u6001\u9002\u5e94\uff0c\u9002\u7528\u4e8e\u975e\u7a33\u6001\u6570\u636e\u5206\u5e03\u3002"}}
{"id": "2506.06521", "pdf": "https://arxiv.org/pdf/2506.06521", "abs": "https://arxiv.org/abs/2506.06521", "authors": ["Shulun Chen", "Runlong Zhou", "Zihan Zhang", "Maryam Fazel", "Simon S. Du"], "title": "Sharp Gap-Dependent Variance-Aware Regret Bounds for Tabular MDPs", "categories": ["cs.LG", "stat.ML"], "comment": "30 pages", "summary": "We consider the gap-dependent regret bounds for episodic MDPs. We show that\nthe Monotonic Value Propagation (MVP) algorithm achieves a variance-aware\ngap-dependent regret bound of $$\\tilde{O}\\left(\\left(\\sum_{\\Delta_h(s,a)>0}\n\\frac{H^2 \\log K \\land \\mathtt{Var}_{\\max}^{\\text{c}}}{\\Delta_h(s,a)}\n+\\sum_{\\Delta_h(s,a)=0}\\frac{ H^2 \\land\n\\mathtt{Var}_{\\max}^{\\text{c}}}{\\Delta_{\\mathrm{min}}} + SAH^4 (S \\lor H)\n\\right) \\log K\\right),$$ where $H$ is the planning horizon, $S$ is the number\nof states, $A$ is the number of actions, and $K$ is the number of episodes.\nHere, $\\Delta_h(s,a) =V_h^* (a) - Q_h^* (s, a)$ represents the suboptimality\ngap and $\\Delta_{\\mathrm{min}} := \\min_{\\Delta_h (s,a) > 0} \\Delta_h(s,a)$. The\nterm $\\mathtt{Var}_{\\max}^{\\text{c}}$ denotes the maximum conditional total\nvariance, calculated as the maximum over all $(\\pi, h, s)$ tuples of the\nexpected total variance under policy $\\pi$ conditioned on trajectories visiting\nstate $s$ at step $h$. $\\mathtt{Var}_{\\max}^{\\text{c}}$ characterizes the\nmaximum randomness encountered when learning any $(h, s)$ pair. Our result\nstems from a novel analysis of the weighted sum of the suboptimality gap and\ncan be potentially adapted for other algorithms. To complement the study, we\nestablish a lower bound of $$\\Omega \\left( \\sum_{\\Delta_h(s,a)>0} \\frac{H^2\n\\land \\mathtt{Var}_{\\max}^{\\text{c}}}{\\Delta_h(s,a)}\\cdot \\log K\\right),$$\ndemonstrating the necessity of dependence on $\\mathtt{Var}_{\\max}^{\\text{c}}$\neven when the maximum unconditional total variance (without conditioning on\n$(h, s)$) approaches zero.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u5dee\u8ddd\u7684\u9057\u61be\u8fb9\u754c\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b9\u5dee\u611f\u77e5\u7684\u7b97\u6cd5MVP\uff0c\u5e76\u7ed9\u51fa\u4e86\u4e0a\u754c\u548c\u4e0b\u754c\u5206\u6790\u3002", "motivation": "\u63a2\u8ba8\u5728\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08MDP\uff09\u4e2d\uff0c\u5982\u4f55\u901a\u8fc7\u65b9\u5dee\u611f\u77e5\u7684\u65b9\u6cd5\u4f18\u5316\u9057\u61be\u8fb9\u754c\uff0c\u5c24\u5176\u662f\u5728\u5b50\u6700\u4f18\u5dee\u8ddd\u5b58\u5728\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u4f7f\u7528Monotonic Value Propagation (MVP)\u7b97\u6cd5\uff0c\u7ed3\u5408\u65b9\u5dee\u611f\u77e5\u7684\u52a0\u6743\u5b50\u6700\u4f18\u5dee\u8ddd\u5206\u6790\u3002", "result": "MVP\u7b97\u6cd5\u5b9e\u73b0\u4e86\u65b9\u5dee\u611f\u77e5\u7684\u9057\u61be\u4e0a\u754c\uff0c\u5e76\u8bc1\u660e\u4e86\u65b9\u5dee\u4f9d\u8d56\u7684\u5fc5\u8981\u6027\u3002", "conclusion": "\u65b9\u5dee\u611f\u77e5\u7684\u9057\u61be\u8fb9\u754c\u5206\u6790\u662f\u5fc5\u8981\u7684\uff0cMVP\u7b97\u6cd5\u5728\u6b64\u7c7b\u95ee\u9898\u4e2d\u8868\u73b0\u4f18\u8d8a\u3002"}}
{"id": "2506.06532", "pdf": "https://arxiv.org/pdf/2506.06532", "abs": "https://arxiv.org/abs/2506.06532", "authors": ["Zijiang Yan", "Hao Zhou", "Jianhua Pei", "Hina Tabassum"], "title": "Hierarchical and Collaborative LLM-Based Control for Multi-UAV Motion and Communication in Integrated Terrestrial and Non-Terrestrial Networks", "categories": ["cs.LG", "cs.AI", "cs.NI", "cs.RO", "cs.SY", "eess.SY"], "comment": "Accepted in ICML 2025 Workshop on Machine Learning for Wireless\n  Communication and Networks (ML4Wireless)", "summary": "Unmanned aerial vehicles (UAVs) have been widely adopted in various\nreal-world applications. However, the control and optimization of multi-UAV\nsystems remain a significant challenge, particularly in dynamic and constrained\nenvironments. This work explores the joint motion and communication control of\nmultiple UAVs operating within integrated terrestrial and non-terrestrial\nnetworks that include high-altitude platform stations (HAPS). Specifically, we\nconsider an aerial highway scenario in which UAVs must accelerate, decelerate,\nand change lanes to avoid collisions and maintain overall traffic flow.\nDifferent from existing studies, we propose a novel hierarchical and\ncollaborative method based on large language models (LLMs). In our approach, an\nLLM deployed on the HAPS performs UAV access control, while another LLM onboard\neach UAV handles motion planning and control. This LLM-based framework\nleverages the rich knowledge embedded in pre-trained models to enable both\nhigh-level strategic planning and low-level tactical decisions. This\nknowledge-driven paradigm holds great potential for the development of\nnext-generation 3D aerial highway systems. Experimental results demonstrate\nthat our proposed collaborative LLM-based method achieves higher system\nrewards, lower operational costs, and significantly reduced UAV collision rates\ncompared to baseline approaches.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5206\u5c42\u534f\u4f5c\u65b9\u6cd5\uff0c\u7528\u4e8e\u591a\u65e0\u4eba\u673a\uff08UAV\uff09\u5728\u52a8\u6001\u548c\u53d7\u9650\u73af\u5883\u4e2d\u7684\u8054\u5408\u8fd0\u52a8\u4e0e\u901a\u4fe1\u63a7\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u6027\u80fd\u3002", "motivation": "\u591a\u65e0\u4eba\u673a\u7cfb\u7edf\u5728\u52a8\u6001\u548c\u53d7\u9650\u73af\u5883\u4e2d\u7684\u63a7\u5236\u4e0e\u4f18\u5316\u662f\u4e00\u4e2a\u91cd\u8981\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u96c6\u6210\u5730\u9762\u548c\u975e\u5730\u9762\u7f51\u7edc\uff08\u5982\u9ad8\u7a7a\u5e73\u53f0\u7ad9HAPS\uff09\u7684\u573a\u666f\u4e2d\u3002", "method": "\u91c7\u7528\u5206\u5c42\u534f\u4f5c\u7684LLM\u6846\u67b6\uff0cHAPS\u4e0a\u7684LLM\u8d1f\u8d23\u65e0\u4eba\u673a\u63a5\u5165\u63a7\u5236\uff0c\u800c\u6bcf\u67b6\u65e0\u4eba\u673a\u4e0a\u7684LLM\u5904\u7406\u8fd0\u52a8\u89c4\u5212\u4e0e\u63a7\u5236\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u7cfb\u7edf\u5956\u52b1\u3001\u8fd0\u8425\u6210\u672c\u548c\u65e0\u4eba\u673a\u78b0\u649e\u7387\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u57fa\u4e8eLLM\u7684\u77e5\u8bc6\u9a71\u52a8\u8303\u5f0f\u4e3a\u4e0b\u4e00\u4ee33D\u7a7a\u4e2d\u9ad8\u901f\u516c\u8def\u7cfb\u7edf\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u6f5c\u529b\u3002"}}
{"id": "2506.06549", "pdf": "https://arxiv.org/pdf/2506.06549", "abs": "https://arxiv.org/abs/2506.06549", "authors": ["Atefeh Gilani", "Naima Tasnim", "Lalitha Sankar", "Oliver Kosut"], "title": "GeoClip: Geometry-Aware Clipping for Differentially Private SGD", "categories": ["cs.LG", "cs.CR", "cs.IT", "math.IT"], "comment": null, "summary": "Differentially private stochastic gradient descent (DP-SGD) is the most\nwidely used method for training machine learning models with provable privacy\nguarantees. A key challenge in DP-SGD is setting the per-sample gradient\nclipping threshold, which significantly affects the trade-off between privacy\nand utility. While recent adaptive methods improve performance by adjusting\nthis threshold during training, they operate in the standard coordinate system\nand fail to account for correlations across the coordinates of the gradient. We\npropose GeoClip, a geometry-aware framework that clips and perturbs gradients\nin a transformed basis aligned with the geometry of the gradient distribution.\nGeoClip adaptively estimates this transformation using only previously released\nnoisy gradients, incurring no additional privacy cost. We provide convergence\nguarantees for GeoClip and derive a closed-form solution for the optimal\ntransformation that minimizes the amount of noise added while keeping the\nprobability of gradient clipping under control. Experiments on both tabular and\nimage datasets demonstrate that GeoClip consistently outperforms existing\nadaptive clipping methods under the same privacy budget.", "AI": {"tldr": "GeoClip\u662f\u4e00\u79cd\u51e0\u4f55\u611f\u77e5\u6846\u67b6\uff0c\u901a\u8fc7\u53d8\u6362\u68af\u5ea6\u5206\u5e03\u7684\u57fa\u7840\u6765\u4f18\u5316DP-SGD\u4e2d\u7684\u68af\u5ea6\u88c1\u526a\u548c\u6270\u52a8\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9690\u79c1\u4e0e\u6548\u7528\u7684\u6743\u8861\u3002", "motivation": "DP-SGD\u4e2d\u68af\u5ea6\u88c1\u526a\u9608\u503c\u7684\u8bbe\u7f6e\u5bf9\u9690\u79c1\u4e0e\u6548\u7528\u6743\u8861\u81f3\u5173\u91cd\u8981\uff0c\u73b0\u6709\u65b9\u6cd5\u672a\u8003\u8651\u68af\u5ea6\u5750\u6807\u95f4\u7684\u76f8\u5173\u6027\u3002", "method": "\u63d0\u51faGeoClip\u6846\u67b6\uff0c\u5728\u53d8\u6362\u540e\u7684\u57fa\u7840\u4e0a\u88c1\u526a\u548c\u6270\u52a8\u68af\u5ea6\uff0c\u81ea\u9002\u5e94\u4f30\u8ba1\u53d8\u6362\u4e14\u4e0d\u589e\u52a0\u9690\u79c1\u6210\u672c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cGeoClip\u5728\u76f8\u540c\u9690\u79c1\u9884\u7b97\u4e0b\u4f18\u4e8e\u73b0\u6709\u81ea\u9002\u5e94\u88c1\u526a\u65b9\u6cd5\u3002", "conclusion": "GeoClip\u901a\u8fc7\u51e0\u4f55\u611f\u77e5\u7684\u68af\u5ea6\u5904\u7406\uff0c\u663e\u8457\u63d0\u5347\u4e86DP-SGD\u7684\u6027\u80fd\u3002"}}
{"id": "2506.06556", "pdf": "https://arxiv.org/pdf/2506.06556", "abs": "https://arxiv.org/abs/2506.06556", "authors": ["Long Dang", "Thushari Hapuarachchi", "Kaiqi Xiong", "Yi Li"], "title": "SDN-Based False Data Detection With Its Mitigation and Machine Learning Robustness for In-Vehicle Networks", "categories": ["cs.LG", "cs.CR"], "comment": "The 34th International Conference on Computer Communications and\n  Networks (ICCCN 2025)", "summary": "As the development of autonomous and connected vehicles advances, the\ncomplexity of modern vehicles increases, with numerous Electronic Control Units\n(ECUs) integrated into the system. In an in-vehicle network, these ECUs\ncommunicate with one another using an standard protocol called Controller Area\nNetwork (CAN). Securing communication among ECUs plays a vital role in\nmaintaining the safety and security of the vehicle. This paper proposes a\nrobust SDN-based False Data Detection and Mitigation System (FDDMS) for\nin-vehicle networks. Leveraging the unique capabilities of Software-Defined\nNetworking (SDN), FDDMS is designed to monitor and detect false data injection\nattacks in real-time. Specifically, we focus on brake-related ECUs within an\nSDN-enabled in-vehicle network. First, we decode raw CAN data to create an\nattack model that illustrates how false data can be injected into the system.\nThen, FDDMS, incorporating a Long Short Term Memory (LSTM)-based detection\nmodel, is used to identify false data injection attacks. We further propose an\neffective variant of DeepFool attack to evaluate the model's robustness. To\ncountermeasure the impacts of four adversarial attacks including Fast gradient\ndescent method, Basic iterative method, DeepFool, and the DeepFool variant, we\nfurther enhance a re-training technique method with a threshold based selection\nstrategy. Finally, a mitigation scheme is implemented to redirect attack\ntraffic by dynamically updating flow rules through SDN. Our experimental\nresults show that the proposed FDDMS is robust against adversarial attacks and\neffectively detects and mitigates false data injection attacks in real-time.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eSDN\u7684\u865a\u5047\u6570\u636e\u68c0\u6d4b\u4e0e\u7f13\u89e3\u7cfb\u7edf\uff08FDDMS\uff09\uff0c\u7528\u4e8e\u5b9e\u65f6\u68c0\u6d4b\u548c\u7f13\u89e3\u8f66\u5185\u7f51\u7edc\u4e2d\u7684\u865a\u5047\u6570\u636e\u6ce8\u5165\u653b\u51fb\u3002", "motivation": "\u968f\u7740\u81ea\u52a8\u9a7e\u9a76\u548c\u8054\u7f51\u8f66\u8f86\u7684\u53d1\u5c55\uff0c\u8f66\u5185\u7f51\u7edc\u7684\u5b89\u5168\u6027\u81f3\u5173\u91cd\u8981\uff0c\u5c24\u5176\u662fECU\u4e4b\u95f4\u7684\u901a\u4fe1\u5b89\u5168\u3002", "method": "\u5229\u7528SDN\u6280\u672f\uff0c\u7ed3\u5408LSTM\u68c0\u6d4b\u6a21\u578b\u548c\u5bf9\u6297\u653b\u51fb\u8bc4\u4f30\uff0c\u8bbe\u8ba1\u5e76\u5b9e\u73b0FDDMS\u7cfb\u7edf\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cFDDMS\u80fd\u6709\u6548\u5bf9\u6297\u591a\u79cd\u5bf9\u6297\u653b\u51fb\uff0c\u5b9e\u65f6\u68c0\u6d4b\u548c\u7f13\u89e3\u865a\u5047\u6570\u636e\u6ce8\u5165\u3002", "conclusion": "FDDMS\u4e3a\u8f66\u5185\u7f51\u7edc\u5b89\u5168\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u9c81\u68d2\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.06558", "pdf": "https://arxiv.org/pdf/2506.06558", "abs": "https://arxiv.org/abs/2506.06558", "authors": ["Atamert Rahma", "Chinmay Datar", "Ana Cukarska", "Felix Dietrich"], "title": "Rapid training of Hamiltonian graph networks without gradient descent", "categories": ["cs.LG", "cs.NE", "68T07", "I.2.6"], "comment": "10 pages, 7 figures, 2 tables, and an appendix", "summary": "Learning dynamical systems that respect physical symmetries and constraints\nremains a fundamental challenge in data-driven modeling. Integrating physical\nlaws with graph neural networks facilitates principled modeling of complex\nN-body dynamics and yields accurate and permutation-invariant models. However,\ntraining graph neural networks with iterative, gradient-based optimization\nalgorithms (e.g., Adam, RMSProp, LBFGS) often leads to slow training,\nespecially for large, complex systems. In comparison to 15 different\noptimizers, we demonstrate that Hamiltonian Graph Networks (HGN) can be trained\nup to 600x faster--but with comparable accuracy--by replacing iterative\noptimization with random feature-based parameter construction. We show robust\nperformance in diverse simulations, including N-body mass-spring systems in up\nto 3 dimensions with different geometries, while retaining essential physical\ninvariances with respect to permutation, rotation, and translation. We reveal\nthat even when trained on minimal 8-node systems, the model can generalize in a\nzero-shot manner to systems as large as 4096 nodes without retraining. Our work\nchallenges the dominance of iterative gradient-descent-based optimization\nalgorithms for training neural network models for physical systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u54c8\u5bc6\u987f\u56fe\u7f51\u7edc\uff08HGN\uff09\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u968f\u673a\u7279\u5f81\u53c2\u6570\u6784\u9020\u66ff\u4ee3\u4f20\u7edf\u8fed\u4ee3\u4f18\u5316\u7b97\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bad\u7ec3\u901f\u5ea6\uff08\u6700\u9ad8600\u500d\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u7269\u7406\u5bf9\u79f0\u6027\u548c\u7ea6\u675f\u3002", "motivation": "\u89e3\u51b3\u6570\u636e\u9a71\u52a8\u5efa\u6a21\u4e2d\u5982\u4f55\u9ad8\u6548\u5b66\u4e60\u7269\u7406\u5bf9\u79f0\u6027\u548c\u7ea6\u675f\u7684\u52a8\u6001\u7cfb\u7edf\u7684\u6311\u6218\u3002", "method": "\u4f7f\u7528\u54c8\u5bc6\u987f\u56fe\u7f51\u7edc\uff08HGN\uff09\u7ed3\u5408\u968f\u673a\u7279\u5f81\u53c2\u6570\u6784\u9020\uff0c\u66ff\u4ee3\u4f20\u7edf\u7684\u68af\u5ea6\u4f18\u5316\u7b97\u6cd5\uff08\u5982Adam\u3001RMSProp\uff09\u3002", "result": "\u5728\u591a\u79cd\u6a21\u62df\u4e2d\u8868\u73b0\u7a33\u5065\uff0c\u5305\u62ec3\u7ef4N\u4f53\u8d28\u91cf-\u5f39\u7c27\u7cfb\u7edf\uff0c\u4e14\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u6cdb\u5316\u5230\u66f4\u5927\u7cfb\u7edf\uff08\u59824096\u8282\u70b9\uff09\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6311\u6218\u4e86\u4f20\u7edf\u68af\u5ea6\u4f18\u5316\u7b97\u6cd5\u5728\u7269\u7406\u7cfb\u7edf\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\u7684\u4e3b\u5bfc\u5730\u4f4d\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2506.06571", "pdf": "https://arxiv.org/pdf/2506.06571", "abs": "https://arxiv.org/abs/2506.06571", "authors": ["Mattie Ji", "Amauri H. Souza", "Vikas Garg"], "title": "Graph Persistence goes Spectral", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "24 pages, 4 figures, 6 tables", "summary": "Including intricate topological information (e.g., cycles) provably enhances\nthe expressivity of message-passing graph neural networks (GNNs) beyond the\nWeisfeiler-Leman (WL) hierarchy. Consequently, Persistent Homology (PH) methods\nare increasingly employed for graph representation learning. In this context,\nrecent works have proposed decorating classical PH diagrams with vertex and\nedge features for improved expressivity. However, due to their dependence on\nfeatures, these methods still fail to capture basic graph structural\ninformation. In this paper, we propose SpectRe -- a new topological descriptor\nfor graphs that integrates spectral information into PH diagrams. Notably,\nSpectRe is strictly more expressive than existing descriptors on graphs. We\nalso introduce notions of global and local stability to analyze existing\ndescriptors and establish that SpectRe is locally stable. Finally, experiments\non synthetic and real-world datasets demonstrate the effectiveness of SpectRe\nand its potential to enhance the capabilities of graph models in relevant\nlearning tasks.", "AI": {"tldr": "SpectRe\u662f\u4e00\u79cd\u65b0\u7684\u56fe\u62d3\u6251\u63cf\u8ff0\u7b26\uff0c\u901a\u8fc7\u5c06\u8c31\u4fe1\u606f\u878d\u5165\u6301\u4e45\u540c\u8c03\u56fe\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8868\u8fbe\u80fd\u529b\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u5c40\u90e8\u7a33\u5b9a\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u9876\u70b9\u548c\u8fb9\u7279\u5f81\uff0c\u65e0\u6cd5\u6355\u6349\u57fa\u672c\u56fe\u7ed3\u6784\u4fe1\u606f\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u5f3a\u5927\u7684\u63cf\u8ff0\u7b26\u3002", "method": "\u63d0\u51faSpectRe\uff0c\u5c06\u8c31\u4fe1\u606f\u96c6\u6210\u5230\u6301\u4e45\u540c\u8c03\u56fe\u4e2d\uff0c\u5e76\u5206\u6790\u5176\u5168\u5c40\u548c\u5c40\u90e8\u7a33\u5b9a\u6027\u3002", "result": "SpectRe\u5728\u8868\u8fbe\u80fd\u529b\u548c\u7a33\u5b9a\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "SpectRe\u4e3a\u56fe\u8868\u793a\u5b66\u4e60\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u5de5\u5177\uff0c\u6709\u671b\u63d0\u5347\u76f8\u5173\u5b66\u4e60\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2506.06579", "pdf": "https://arxiv.org/pdf/2506.06579", "abs": "https://arxiv.org/abs/2506.06579", "authors": ["Adarsh Prasad Behera", "Jaya Prakash Champati", "Roberto Morabito", "Sasu Tarkoma", "James Gross"], "title": "Towards Efficient Multi-LLM Inference: Characterization and Analysis of LLM Routing and Hierarchical Techniques", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.DC"], "comment": null, "summary": "Recent progress in Language Models (LMs) has dramatically advanced the field\nof natural language processing (NLP), excelling at tasks like text generation,\nsummarization, and question answering. However, their inference remains\ncomputationally expensive and energy intensive, especially in settings with\nlimited hardware, power, or bandwidth. This makes it difficult to deploy LMs in\nmobile, edge, or cost sensitive environments. To address these challenges,\nrecent approaches have introduced multi LLM intelligent model selection\nstrategies that dynamically allocate computational resources based on query\ncomplexity -- using lightweight models for simpler queries and escalating to\nlarger models only when necessary. This survey explores two complementary\nstrategies for efficient LLM inference: (i) routing, which selects the most\nsuitable model based on the query, and (ii) cascading or hierarchical inference\n(HI), which escalates queries through a sequence of models until a confident\nresponse is found. Both approaches aim to reduce computation by using\nlightweight models for simpler tasks while offloading only when needed. We\nprovide a comparative analysis of these techniques across key performance\nmetrics, discuss benchmarking efforts, and outline open challenges. Finally, we\noutline future research directions to enable faster response times, adaptive\nmodel selection based on task complexity, and scalable deployment across\nheterogeneous environments, making LLM based systems more efficient and\naccessible for real world applications.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u901a\u8fc7\u52a8\u6001\u6a21\u578b\u9009\u62e9\u548c\u5206\u5c42\u63a8\u7406\u7b56\u7565\u4f18\u5316\u8bed\u8a00\u6a21\u578b\u7684\u8ba1\u7b97\u6548\u7387\uff0c\u4ee5\u5728\u8d44\u6e90\u53d7\u9650\u7684\u73af\u5883\u4e2d\u90e8\u7f72\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u7684\u8ba1\u7b97\u548c\u80fd\u6e90\u6d88\u8017\u9ad8\uff0c\u96be\u4ee5\u5728\u79fb\u52a8\u3001\u8fb9\u7f18\u6216\u6210\u672c\u654f\u611f\u73af\u5883\u4e2d\u90e8\u7f72\uff0c\u9700\u8981\u9ad8\u6548\u63a8\u7406\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u8def\u7531\u548c\u5206\u5c42\u63a8\u7406\uff08HI\uff09\u7b56\u7565\uff0c\u52a8\u6001\u9009\u62e9\u6a21\u578b\u6216\u9010\u6b65\u5347\u7ea7\u6a21\u578b\u4ee5\u5904\u7406\u67e5\u8be2\u3002", "result": "\u8fd9\u4e9b\u7b56\u7565\u80fd\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u4e0d\u540c\u590d\u6742\u5ea6\u7684\u4efb\u52a1\u3002", "conclusion": "\u672a\u6765\u7814\u7a76\u65b9\u5411\u5305\u62ec\u66f4\u5feb\u54cd\u5e94\u65f6\u95f4\u3001\u81ea\u9002\u5e94\u6a21\u578b\u9009\u62e9\u548c\u53ef\u6269\u5c55\u90e8\u7f72\uff0c\u4ee5\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u7684\u5b9e\u7528\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2506.06582", "pdf": "https://arxiv.org/pdf/2506.06582", "abs": "https://arxiv.org/abs/2506.06582", "authors": ["Diaaeldin Taha", "James Chapman", "Marzieh Eidi", "Karel Devriendt", "Guido Mont\u00fafar"], "title": "Demystifying Topological Message-Passing with Relational Structures: A Case Study on Oversquashing in Simplicial Message-Passing", "categories": ["cs.LG", "stat.ML", "I.5.1"], "comment": "50 pages, 12 figures, published at ICLR 2025. The Thirteenth\n  International Conference on Learning Representations. 2025", "summary": "Topological deep learning (TDL) has emerged as a powerful tool for modeling\nhigher-order interactions in relational data. However, phenomena such as\noversquashing in topological message-passing remain understudied and lack\ntheoretical analysis. We propose a unifying axiomatic framework that bridges\ngraph and topological message-passing by viewing simplicial and cellular\ncomplexes and their message-passing schemes through the lens of relational\nstructures. This approach extends graph-theoretic results and algorithms to\nhigher-order structures, facilitating the analysis and mitigation of\noversquashing in topological message-passing networks. Through theoretical\nanalysis and empirical studies on simplicial networks, we demonstrate the\npotential of this framework to advance TDL.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u516c\u7406\u5316\u6846\u67b6\uff0c\u5c06\u56fe\u548c\u62d3\u6251\u6d88\u606f\u4f20\u9012\u8054\u7cfb\u8d77\u6765\uff0c\u4ee5\u5206\u6790\u5e76\u7f13\u89e3\u62d3\u6251\u6d88\u606f\u4f20\u9012\u4e2d\u7684\u8fc7\u5ea6\u538b\u7f29\u95ee\u9898\u3002", "motivation": "\u62d3\u6251\u6df1\u5ea6\u5b66\u4e60\uff08TDL\uff09\u5728\u5efa\u6a21\u5173\u7cfb\u6570\u636e\u4e2d\u7684\u9ad8\u9636\u4ea4\u4e92\u65b9\u9762\u8868\u73b0\u51fa\u5f3a\u5927\u80fd\u529b\uff0c\u4f46\u62d3\u6251\u6d88\u606f\u4f20\u9012\u4e2d\u7684\u8fc7\u5ea6\u538b\u7f29\u73b0\u8c61\u7f3a\u4e4f\u7406\u8bba\u5206\u6790\u3002", "method": "\u901a\u8fc7\u5c06\u5355\u7eaf\u548c\u7ec6\u80de\u590d\u5f62\u53ca\u5176\u6d88\u606f\u4f20\u9012\u65b9\u6848\u89c6\u4e3a\u5173\u7cfb\u7ed3\u6784\uff0c\u6269\u5c55\u56fe\u8bba\u7ed3\u679c\u548c\u7b97\u6cd5\u5230\u9ad8\u9636\u7ed3\u6784\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u5355\u7eaf\u7f51\u7edc\u7684\u5b9e\u8bc1\u7814\u7a76\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u63a8\u52a8TDL\u65b9\u9762\u5177\u6709\u6f5c\u529b\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u62d3\u6251\u6d88\u606f\u4f20\u9012\u4e2d\u7684\u95ee\u9898\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728TDL\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2506.06584", "pdf": "https://arxiv.org/pdf/2506.06584", "abs": "https://arxiv.org/abs/2506.06584", "authors": ["Mo Zhou", "Weihang Xu", "Maryam Fazel", "Simon S. Du"], "title": "Global Convergence of Gradient EM for Over-Parameterized Gaussian Mixtures", "categories": ["cs.LG", "stat.ML"], "comment": "77 pages", "summary": "Learning Gaussian Mixture Models (GMMs) is a fundamental problem in machine\nlearning, with the Expectation-Maximization (EM) algorithm and its popular\nvariant gradient EM being arguably the most widely used algorithms in practice.\nIn the exact-parameterized setting, where both the ground truth GMM and the\nlearning model have the same number of components $m$, a vast line of work has\naimed to establish rigorous recovery guarantees for EM. However, global\nconvergence has only been proven for the case of $m=2$, and EM is known to fail\nto recover the ground truth when $m\\geq 3$.\n  In this paper, we consider the $\\textit{over-parameterized}$ setting, where\nthe learning model uses $n>m$ components to fit an $m$-component ground truth\nGMM. In contrast to the exact-parameterized case, we provide a rigorous global\nconvergence guarantee for gradient EM. Specifically, for any well separated\nGMMs in general position, we prove that with only mild over-parameterization $n\n= \\Omega(m\\log m)$, randomly initialized gradient EM converges globally to the\nground truth at a polynomial rate with polynomial samples. Our analysis\nproceeds in two stages and introduces a suite of novel tools for Gaussian\nMixture analysis. We use Hermite polynomials to study the dynamics of gradient\nEM and employ tensor decomposition to characterize the geometric landscape of\nthe likelihood loss. This is the first global convergence and recovery result\nfor EM or Gradient EM beyond the special case of $m=2$.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u9ad8\u65af\u6df7\u5408\u6a21\u578b\uff08GMM\uff09\u5728\u8fc7\u53c2\u6570\u5316\u8bbe\u7f6e\u4e0b\u7684\u5168\u5c40\u6536\u655b\u6027\uff0c\u8bc1\u660e\u4e86\u68af\u5ea6EM\u7b97\u6cd5\u5728\u968f\u673a\u521d\u59cb\u5316\u4e0b\u53ef\u4ee5\u5168\u5c40\u6536\u655b\u5230\u771f\u5b9e\u53c2\u6570\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4ec5\u8bc1\u660e\u4e86EM\u7b97\u6cd5\u5728m=2\u65f6\u7684\u5168\u5c40\u6536\u655b\u6027\uff0c\u800c\u5728m\u22653\u65f6\u5931\u8d25\u3002\u672c\u6587\u65e8\u5728\u63a2\u8ba8\u8fc7\u53c2\u6570\u5316\u8bbe\u7f6e\u4e0b\u68af\u5ea6EM\u7684\u5168\u5c40\u6536\u655b\u6027\u3002", "method": "\u4f7f\u7528Hermite\u591a\u9879\u5f0f\u5206\u6790\u68af\u5ea6EM\u7684\u52a8\u6001\uff0c\u5e76\u5229\u7528\u5f20\u91cf\u5206\u89e3\u523b\u753b\u4f3c\u7136\u635f\u5931\u51fd\u6570\u7684\u51e0\u4f55\u7279\u6027\u3002", "result": "\u8bc1\u660e\u4e86\u5bf9\u4e8e\u4efb\u4f55\u826f\u597d\u5206\u79bb\u7684GMM\uff0c\u5728n=\u03a9(mlogm)\u7684\u8fc7\u53c2\u6570\u5316\u6761\u4ef6\u4e0b\uff0c\u68af\u5ea6EM\u80fd\u5168\u5c40\u6536\u655b\u5230\u771f\u5b9e\u53c2\u6570\u3002", "conclusion": "\u8fd9\u662f\u9996\u6b21\u5728m>2\u7684\u60c5\u51b5\u4e0b\u8bc1\u660eEM\u6216\u68af\u5ea6EM\u7684\u5168\u5c40\u6536\u655b\u6027\uff0c\u4e3aGMM\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2506.06599", "pdf": "https://arxiv.org/pdf/2506.06599", "abs": "https://arxiv.org/abs/2506.06599", "authors": ["Yuanjie Shi", "Hooman Shahrokhi", "Xuesong Jia", "Xiongzhi Chen", "Janardhan Rao Doppa", "Yan Yan"], "title": "Direct Prediction Set Minimization via Bilevel Conformal Classifier Training", "categories": ["cs.LG", "stat.ML"], "comment": "Accepted for Publication at International Conference on Machine\n  Learning (ICML), 2025", "summary": "Conformal prediction (CP) is a promising uncertainty quantification framework\nwhich works as a wrapper around a black-box classifier to construct prediction\nsets (i.e., subset of candidate classes) with provable guarantees. However,\nstandard calibration methods for CP tend to produce large prediction sets which\nmakes them less useful in practice. This paper considers the problem of\nintegrating conformal principles into the training process of deep classifiers\nto directly minimize the size of prediction sets. We formulate conformal\ntraining as a bilevel optimization problem and propose the {\\em Direct\nPrediction Set Minimization (DPSM)} algorithm to solve it. The key insight\nbehind DPSM is to minimize a measure of the prediction set size (upper level)\nthat is conditioned on the learned quantile of conformity scores (lower level).\nWe analyze that DPSM has a learning bound of $O(1/\\sqrt{n})$ (with $n$ training\nsamples), while prior conformal training methods based on stochastic\napproximation for the quantile has a bound of $\\Omega(1/s)$ (with batch size\n$s$ and typically $s \\ll \\sqrt{n}$). Experiments on various benchmark datasets\nand deep models show that DPSM significantly outperforms the best prior\nconformal training baseline with $20.46\\%\\downarrow$ in the prediction set size\nand validates our theory.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDPSM\u7684\u7b97\u6cd5\uff0c\u901a\u8fc7\u5c06\u5171\u5f62\u9884\u6d4b\u539f\u5219\u878d\u5165\u6df1\u5ea6\u5206\u7c7b\u5668\u7684\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u76f4\u63a5\u6700\u5c0f\u5316\u9884\u6d4b\u96c6\u7684\u5927\u5c0f\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u6807\u51c6\u5171\u5f62\u9884\u6d4b\u6821\u51c6\u65b9\u6cd5\u751f\u6210\u7684\u9884\u6d4b\u96c6\u901a\u5e38\u8fc7\u5927\uff0c\u9650\u5236\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u8bad\u7ec3\u8fc7\u7a0b\u76f4\u63a5\u4f18\u5316\u9884\u6d4b\u96c6\u5927\u5c0f\u3002", "method": "\u5c06\u5171\u5f62\u8bad\u7ec3\u5efa\u6a21\u4e3a\u53cc\u5c42\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u51faDPSM\u7b97\u6cd5\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u9884\u6d4b\u96c6\u5927\u5c0f\u7684\u5ea6\u91cf\uff08\u4e0a\u5c42\uff09\u5e76\u57fa\u4e8e\u4e00\u81f4\u6027\u5206\u6570\u7684\u5206\u4f4d\u6570\uff08\u4e0b\u5c42\uff09\u5b9e\u73b0\u3002", "result": "DPSM\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u548c\u6df1\u5ea6\u6a21\u578b\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u9884\u6d4b\u96c6\u5927\u5c0f\u51cf\u5c11\u4e8620.46%\uff0c\u4e14\u7406\u8bba\u5206\u6790\u663e\u793a\u5176\u5b66\u4e60\u8fb9\u754c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "DPSM\u901a\u8fc7\u76f4\u63a5\u4f18\u5316\u9884\u6d4b\u96c6\u5927\u5c0f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5171\u5f62\u9884\u6d4b\u7684\u5b9e\u7528\u6027\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u7406\u8bba\u4f18\u52bf\u3002"}}
{"id": "2506.06603", "pdf": "https://arxiv.org/pdf/2506.06603", "abs": "https://arxiv.org/abs/2506.06603", "authors": ["Joseph T Colonel", "Carolyn Hagler", "Guiselle Wismer", "Laura Curtis", "Jacqueline Becker", "Juan Wisnivesky", "Alex Federman", "Gaurav Pandey"], "title": "CAtCh: Cognitive Assessment through Cookie Thief", "categories": ["cs.LG", "cs.AI", "cs.SD", "eess.AS"], "comment": null, "summary": "Several machine learning algorithms have been developed for the prediction of\nAlzheimer's disease and related dementia (ADRD) from spontaneous speech.\nHowever, none of these algorithms have been translated for the prediction of\nbroader cognitive impairment (CI), which in some cases is a precursor and risk\nfactor of ADRD. In this paper, we evaluated several speech-based open-source\nmethods originally proposed for the prediction of ADRD, as well as methods from\nmultimodal sentiment analysis for the task of predicting CI from patient audio\nrecordings. Results demonstrated that multimodal methods outperformed unimodal\nones for CI prediction, and that acoustics-based approaches performed better\nthan linguistics-based ones. Specifically, interpretable acoustic features\nrelating to affect and prosody were found to significantly outperform\nBERT-based linguistic features and interpretable linguistic features,\nrespectively. All the code developed for this study is available at\nhttps://github.com/JTColonel/catch.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u4ece\u8bed\u97f3\u4e2d\u9884\u6d4b\u8ba4\u77e5\u969c\u788d\uff08CI\uff09\u7684\u65b9\u6cd5\uff0c\u6bd4\u8f83\u4e86\u591a\u6a21\u6001\u548c\u5355\u6a21\u6001\u65b9\u6cd5\uff0c\u53d1\u73b0\u591a\u6a21\u6001\u65b9\u6cd5\u8868\u73b0\u66f4\u4f18\uff0c\u4e14\u58f0\u5b66\u7279\u5f81\u4f18\u4e8e\u8bed\u8a00\u5b66\u7279\u5f81\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u4e3b\u8981\u9488\u5bf9\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u53ca\u76f8\u5173\u75f4\u5446\uff08ADRD\uff09\u7684\u9884\u6d4b\uff0c\u4f46\u672a\u6269\u5c55\u5230\u66f4\u5e7f\u6cdb\u7684\u8ba4\u77e5\u969c\u788d\uff08CI\uff09\u9884\u6d4b\uff0c\u800cCI\u53ef\u80fd\u662fADRD\u7684\u524d\u5146\u548c\u98ce\u9669\u56e0\u7d20\u3002", "method": "\u8bc4\u4f30\u4e86\u57fa\u4e8e\u8bed\u97f3\u7684\u5f00\u6e90\u65b9\u6cd5\uff08\u539f\u7528\u4e8eADRD\u9884\u6d4b\uff09\u548c\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u65b9\u6cd5\uff0c\u7528\u4e8e\u4ece\u60a3\u8005\u97f3\u9891\u4e2d\u9884\u6d4bCI\u3002", "result": "\u591a\u6a21\u6001\u65b9\u6cd5\u4f18\u4e8e\u5355\u6a21\u6001\u65b9\u6cd5\uff0c\u58f0\u5b66\u7279\u5f81\uff08\u5c24\u5176\u662f\u60c5\u611f\u548c\u97f5\u5f8b\u76f8\u5173\u7279\u5f81\uff09\u663e\u8457\u4f18\u4e8eBERT\u8bed\u8a00\u5b66\u7279\u5f81\u548c\u53ef\u89e3\u91ca\u8bed\u8a00\u5b66\u7279\u5f81\u3002", "conclusion": "\u58f0\u5b66\u7279\u5f81\u5728\u591a\u6a21\u6001\u65b9\u6cd5\u4e2d\u5bf9CI\u9884\u6d4b\u66f4\u6709\u6548\uff0c\u7814\u7a76\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2506.06606", "pdf": "https://arxiv.org/pdf/2506.06606", "abs": "https://arxiv.org/abs/2506.06606", "authors": ["Xinyu Luo", "Cedar Site Bai", "Bolian Li", "Petros Drineas", "Ruqi Zhang", "Brian Bullins"], "title": "Stacey: Promoting Stochastic Steepest Descent via Accelerated $\\ell_p$-Smooth Nonconvex Optimization", "categories": ["cs.LG"], "comment": null, "summary": "While popular optimization methods such as SGD, AdamW, and Lion depend on\nsteepest descent updates in either $\\ell_2$ or $\\ell_\\infty$ norms, there\nremains a critical gap in handling the non-Euclidean structure observed in\nmodern deep networks training. In this work, we address this need by\nintroducing a new accelerated $\\ell_p$ steepest descent algorithm, called\nStacey, which uses interpolated primal-dual iterate sequences to effectively\nnavigate non-Euclidean smooth optimization tasks. In addition to providing\nnovel theoretical guarantees for the foundations of our algorithm, we\nempirically compare our approach against these popular methods on tasks\nincluding image classification and language model (LLM) pretraining,\ndemonstrating both faster convergence and higher final accuracy. We further\nevaluate different values of $p$ across various models and datasets,\nunderscoring the importance and efficiency of non-Euclidean approaches over\nstandard Euclidean methods. Code can be found at\nhttps://github.com/xinyuluo8561/Stacey .", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.06632", "pdf": "https://arxiv.org/pdf/2506.06632", "abs": "https://arxiv.org/abs/2506.06632", "authors": ["Shubham Parashar", "Shurui Gui", "Xiner Li", "Hongyi Ling", "Sushil Vemuri", "Blake Olson", "Eric Li", "Yu Zhang", "James Caverlee", "Dileep Kalathil", "Shuiwang Ji"], "title": "Curriculum Reinforcement Learning from Easy to Hard Tasks Improves LLM Reasoning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "We aim to improve the reasoning capabilities of language models via\nreinforcement learning (RL). Recent RL post-trained models like DeepSeek-R1\nhave demonstrated reasoning abilities on mathematical and coding tasks.\nHowever, prior studies suggest that using RL alone to improve reasoning on\ninherently difficult tasks is less effective. Here, we draw inspiration from\ncurriculum learning and propose to schedule tasks from easy to hard (E2H),\nallowing LLMs to build reasoning skills gradually. Our method is termed E2H\nReasoner. Empirically, we observe that, although easy tasks are important\ninitially, fading them out through appropriate scheduling is essential in\npreventing overfitting. Theoretically, we establish convergence guarantees for\nE2H Reasoner within an approximate policy iteration framework. We derive\nfinite-sample complexity bounds and show that when tasks are appropriately\ndecomposed and conditioned, learning through curriculum stages requires fewer\ntotal samples than direct learning. Experiments across multiple domains show\nthat E2H Reasoner significantly improves the reasoning ability of small LLMs\n(1.5B to 3B), which otherwise struggle when trained with vanilla RL alone,\nhighlighting the effectiveness of our method.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aE2H Reasoner\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ece\u6613\u5230\u96be\u7684\u4efb\u52a1\u8c03\u5ea6\uff08E2H\uff09\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8868\u660e\uff0c\u4ec5\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u96be\u4ee5\u6709\u6548\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u7684\u63a8\u7406\u80fd\u529b\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u8bfe\u7a0b\u5b66\u4e60\u601d\u8def\uff0c\u8bbe\u8ba1\u4ece\u6613\u5230\u96be\u7684\u4efb\u52a1\u8c03\u5ea6\uff08E2H\uff09\uff0c\u5e76\u901a\u8fc7\u9002\u5f53\u7684\u8c03\u5ea6\u9632\u6b62\u8fc7\u62df\u5408\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cE2H Reasoner\u663e\u8457\u63d0\u5347\u4e86\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff081.5B\u52303B\uff09\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4e14\u6837\u672c\u6548\u7387\u66f4\u9ad8\u3002", "conclusion": "E2H Reasoner\u662f\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4efb\u52a1\u8c03\u5ea6\u9010\u6b65\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u5c0f\u578b\u6a21\u578b\u3002"}}
{"id": "2506.06633", "pdf": "https://arxiv.org/pdf/2506.06633", "abs": "https://arxiv.org/abs/2506.06633", "authors": ["Chi-Sheng Chen"], "title": "Vision-QRWKV: Exploring Quantum-Enhanced RWKV Models for Image Classification", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Recent advancements in quantum machine learning have shown promise in\nenhancing classical neural network architectures, particularly in domains\ninvolving complex, high-dimensional data. Building upon prior work in temporal\nsequence modeling, this paper introduces Vision-QRWKV, a hybrid\nquantum-classical extension of the Receptance Weighted Key Value (RWKV)\narchitecture, applied for the first time to image classification tasks. By\nintegrating a variational quantum circuit (VQC) into the channel mixing\ncomponent of RWKV, our model aims to improve nonlinear feature transformation\nand enhance the expressive capacity of visual representations.\n  We evaluate both classical and quantum RWKV models on a diverse collection of\n14 medical and standard image classification benchmarks, including MedMNIST\ndatasets, MNIST, and FashionMNIST. Our results demonstrate that the\nquantum-enhanced model outperforms its classical counterpart on a majority of\ndatasets, particularly those with subtle or noisy class distinctions (e.g.,\nChestMNIST, RetinaMNIST, BloodMNIST). This study represents the first\nsystematic application of quantum-enhanced RWKV in the visual domain, offering\ninsights into the architectural trade-offs and future potential of quantum\nmodels for lightweight and efficient vision tasks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aVision-QRWKV\u7684\u6df7\u5408\u91cf\u5b50-\u7ecf\u5178\u6a21\u578b\uff0c\u7528\u4e8e\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\uff0c\u901a\u8fc7\u5c06\u53d8\u5206\u91cf\u5b50\u7535\u8def\u96c6\u6210\u5230RWKV\u67b6\u6784\u4e2d\uff0c\u63d0\u5347\u4e86\u975e\u7ebf\u6027\u7279\u5f81\u8f6c\u6362\u80fd\u529b\u3002", "motivation": "\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u5728\u590d\u6742\u9ad8\u7ef4\u6570\u636e\u9886\u57df\u5c55\u73b0\u51fa\u6f5c\u529b\uff0c\u672c\u6587\u65e8\u5728\u63a2\u7d22\u91cf\u5b50\u589e\u5f3a\u7684RWKV\u67b6\u6784\u5728\u89c6\u89c9\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u5c06\u53d8\u5206\u91cf\u5b50\u7535\u8def\uff08VQC\uff09\u96c6\u6210\u5230RWKV\u7684\u901a\u9053\u6df7\u5408\u7ec4\u4ef6\u4e2d\uff0c\u6784\u5efa\u4e86Vision-QRWKV\u6a21\u578b\u3002", "result": "\u572814\u4e2a\u533b\u5b66\u548c\u6807\u51c6\u56fe\u50cf\u5206\u7c7b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u91cf\u5b50\u589e\u5f3a\u6a21\u578b\u5728\u591a\u6570\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u7ecf\u5178\u6a21\u578b\uff0c\u5c24\u5176\u5728\u5177\u6709\u7ec6\u5fae\u6216\u566a\u58f0\u7c7b\u522b\u533a\u5206\u7684\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "\u8be5\u7814\u7a76\u9996\u6b21\u7cfb\u7edf\u5730\u5c06\u91cf\u5b50\u589e\u5f3aRWKV\u5e94\u7528\u4e8e\u89c6\u89c9\u9886\u57df\uff0c\u4e3a\u8f7b\u91cf\u9ad8\u6548\u7684\u91cf\u5b50\u89c6\u89c9\u6a21\u578b\u63d0\u4f9b\u4e86\u672a\u6765\u53d1\u5c55\u65b9\u5411\u3002"}}
{"id": "2506.06637", "pdf": "https://arxiv.org/pdf/2506.06637", "abs": "https://arxiv.org/abs/2506.06637", "authors": ["Olimjon Toirov", "Wei Yu"], "title": "Non-Intrusive Load Monitoring Based on Image Load Signatures and Continual Learning", "categories": ["cs.LG", "cs.AI", "cs.CV", "eess.SP"], "comment": "10 pages, 3 figures, 2025 2nd International Conference on Digital\n  Society and Artificial Intelligence (DSAI 2025), Conference dates: May 23-25,\n  2025", "summary": "Non-Intrusive Load Monitoring (NILM) identifies the operating status and\nenergy consumption of each electrical device in the circuit by analyzing the\nelectrical signals at the bus, which is of great significance for smart power\nmanagement. However, the complex and changeable load combinations and\napplication environments lead to the challenges of poor feature robustness and\ninsufficient model generalization of traditional NILM methods. To this end,\nthis paper proposes a new non-intrusive load monitoring method that integrates\n\"image load signature\" and continual learning. This method converts\nmulti-dimensional power signals such as current, voltage, and power factor into\nvisual image load feature signatures, and combines deep convolutional neural\nnetworks to realize the identification and classification of multiple devices;\nat the same time, self-supervised pre-training is introduced to improve feature\ngeneralization, and continual online learning strategies are used to overcome\nmodel forgetting to adapt to the emergence of new loads. This paper conducts a\nlarge number of experiments on high-sampling rate load datasets, and compares a\nvariety of existing methods and model variants. The results show that the\nproposed method has achieved significant improvements in recognition accuracy.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u56fe\u50cf\u8d1f\u8f7d\u7279\u5f81\u548c\u6301\u7eed\u5b66\u4e60\u7684\u975e\u4fb5\u5165\u5f0f\u8d1f\u8f7d\u76d1\u6d4b\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8bc6\u522b\u7cbe\u5ea6\u3002", "motivation": "\u4f20\u7edfNILM\u65b9\u6cd5\u5728\u590d\u6742\u8d1f\u8f7d\u7ec4\u5408\u548c\u5e94\u7528\u73af\u5883\u4e0b\u7279\u5f81\u9c81\u68d2\u6027\u548c\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u3002", "method": "\u5c06\u591a\u7ef4\u7535\u529b\u4fe1\u53f7\u8f6c\u6362\u4e3a\u56fe\u50cf\u8d1f\u8f7d\u7279\u5f81\uff0c\u7ed3\u5408\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u548c\u6301\u7eed\u5728\u7ebf\u5b66\u4e60\u7b56\u7565\u3002", "result": "\u5728\u9ad8\u91c7\u6837\u7387\u8d1f\u8f7d\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0c\u8bc6\u522b\u7cbe\u5ea6\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edfNILM\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u9002\u5e94\u65b0\u8d1f\u8f7d\u7684\u51fa\u73b0\u3002"}}
{"id": "2506.06644", "pdf": "https://arxiv.org/pdf/2506.06644", "abs": "https://arxiv.org/abs/2506.06644", "authors": ["Chong You", "Kan Wu", "Zhipeng Jia", "Lin Chen", "Srinadh Bhojanapalli", "Jiaxian Guo", "Utku Evci", "Jan Wassenberg", "Praneeth Netrapalli", "Jeremiah J. Willcock", "Suvinay Subramanian", "Felix Chern", "Alek Andreev", "Shreya Pathak", "Felix Yu", "Prateek Jain", "David E. Culler", "Henry M. Levy", "Sanjiv Kumar"], "title": "Spark Transformer: Reactivating Sparsity in FFN and Attention", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "The discovery of the lazy neuron phenomenon in trained Transformers, where\nthe vast majority of neurons in their feed-forward networks (FFN) are inactive\nfor each token, has spurred tremendous interests in activation sparsity for\nenhancing large model efficiency. While notable progress has been made in\ntranslating such sparsity to wall-time benefits, modern Transformers have moved\naway from the ReLU activation function crucial to this phenomenon. Existing\nefforts on re-introducing activation sparsity often degrade model quality,\nincrease parameter count, complicate or slow down training. Sparse attention,\nthe application of sparse activation to the attention mechanism, often faces\nsimilar challenges.\n  This paper introduces the Spark Transformer, a novel architecture that\nachieves a high level of activation sparsity in both FFN and the attention\nmechanism while maintaining model quality, parameter count, and standard\ntraining procedures. Our method realizes sparsity via top-k masking for\nexplicit control over sparsity level. Crucially, we introduce statistical\ntop-k, a hardware-accelerator-friendly, linear-time approximate algorithm that\navoids costly sorting and mitigates significant training slowdown from standard\ntop-$k$ operators. Furthermore, Spark Transformer reallocates existing FFN\nparameters and attention key embeddings to form a low-cost predictor for\nidentifying activated entries. This design not only mitigates quality loss from\nenforced sparsity, but also enhances wall-time benefit. Pretrained with the\nGemma-2 recipe, Spark Transformer demonstrates competitive performance on\nstandard benchmarks while exhibiting significant sparsity: only 8% of FFN\nneurons are activated, and each token attends to a maximum of 256 tokens. This\nsparsity translates to a 2.5x reduction in FLOPs, leading to decoding wall-time\nspeedups of up to 1.79x on CPU and 1.40x on GPU.", "AI": {"tldr": "Spark Transformer\u901a\u8fc7top-k\u63a9\u7801\u548c\u7edf\u8ba1top-k\u7b97\u6cd5\u5b9e\u73b0\u9ad8\u6fc0\u6d3b\u7a00\u758f\u6027\uff0c\u4fdd\u6301\u6a21\u578b\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u91cf\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709Transformer\u4e2d\u6fc0\u6d3b\u7a00\u758f\u6027\u5f15\u5165\u5bfc\u81f4\u7684\u6a21\u578b\u8d28\u91cf\u4e0b\u964d\u3001\u53c2\u6570\u589e\u52a0\u6216\u8bad\u7ec3\u590d\u6742\u5316\u95ee\u9898\u3002", "method": "\u91c7\u7528top-k\u63a9\u7801\u548c\u7edf\u8ba1top-k\u7b97\u6cd5\uff0c\u91cd\u65b0\u5206\u914dFFN\u53c2\u6570\u548c\u6ce8\u610f\u529b\u952e\u5d4c\u5165\u4ee5\u9884\u6d4b\u6fc0\u6d3b\u6761\u76ee\u3002", "result": "\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0cFFN\u795e\u7ecf\u5143\u6fc0\u6d3b\u7387\u4ec58%\uff0c\u8ba1\u7b97\u91cf\u51cf\u5c112.5\u500d\uff0c\u89e3\u7801\u901f\u5ea6\u63d0\u53471.79x\uff08CPU\uff09\u548c1.40x\uff08GPU\uff09\u3002", "conclusion": "Spark Transformer\u5728\u4fdd\u6301\u9ad8\u6548\u8bad\u7ec3\u548c\u6a21\u578b\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6fc0\u6d3b\u7a00\u758f\u6027\u548c\u8ba1\u7b97\u6548\u7387\u63d0\u5347\u3002"}}
{"id": "2506.06649", "pdf": "https://arxiv.org/pdf/2506.06649", "abs": "https://arxiv.org/abs/2506.06649", "authors": ["Yishan Shen", "Yuyang Ye", "Hui Xiong", "Yong Chen"], "title": "SAFER: A Calibrated Risk-Aware Multimodal Recommendation Model for Dynamic Treatment Regimes", "categories": ["cs.LG", "stat.ML"], "comment": "Accepted by ICML 2025", "summary": "Dynamic treatment regimes (DTRs) are critical to precision medicine,\noptimizing long-term outcomes through personalized, real-time decision-making\nin evolving clinical contexts, but require careful supervision for unsafe\ntreatment risks. Existing efforts rely primarily on clinician-prescribed gold\nstandards despite the absence of a known optimal strategy, and predominantly\nusing structured EHR data without extracting valuable insights from clinical\nnotes, limiting their reliability for treatment recommendations. In this work,\nwe introduce SAFER, a calibrated risk-aware tabular-language recommendation\nframework for DTR that integrates both structured EHR and clinical notes,\nenabling them to learn from each other, and addresses inherent label\nuncertainty by assuming ambiguous optimal treatment solution for deceased\npatients. Moreover, SAFER employs conformal prediction to provide statistical\nguarantees, ensuring safe treatment recommendations while filtering out\nuncertain predictions. Experiments on two publicly available sepsis datasets\ndemonstrate that SAFER outperforms state-of-the-art baselines across multiple\nrecommendation metrics and counterfactual mortality rate, while offering robust\nformal assurances. These findings underscore SAFER potential as a trustworthy\nand theoretically grounded solution for high-stakes DTR applications.", "AI": {"tldr": "SAFER\u662f\u4e00\u4e2a\u7ed3\u5408\u7ed3\u6784\u5316\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u548c\u4e34\u5e8a\u7b14\u8bb0\u7684\u98ce\u9669\u611f\u77e5\u63a8\u8350\u6846\u67b6\uff0c\u7528\u4e8e\u52a8\u6001\u6cbb\u7597\u7b56\u7565\uff08DTR\uff09\uff0c\u63d0\u4f9b\u7edf\u8ba1\u4fdd\u8bc1\u548c\u66f4\u4f18\u7684\u6cbb\u7597\u5efa\u8bae\u3002", "motivation": "\u52a8\u6001\u6cbb\u7597\u7b56\u7565\u5728\u7cbe\u51c6\u533b\u5b66\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u4e34\u5e8a\u6807\u51c6\u4e14\u672a\u5145\u5206\u5229\u7528\u4e34\u5e8a\u7b14\u8bb0\uff0c\u9650\u5236\u4e86\u53ef\u9760\u6027\u3002", "method": "SAFER\u6574\u5408\u7ed3\u6784\u5316\u6570\u636e\u548c\u4e34\u5e8a\u7b14\u8bb0\uff0c\u901a\u8fc7\u5047\u8bbe\u6a21\u7cca\u6700\u4f18\u6cbb\u7597\u89e3\u51b3\u6807\u7b7e\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u91c7\u7528\u4fdd\u5f62\u9884\u6d4b\u63d0\u4f9b\u7edf\u8ba1\u4fdd\u8bc1\u3002", "result": "\u5728\u516c\u5f00\u7684\u8d25\u8840\u75c7\u6570\u636e\u96c6\u4e0a\uff0cSAFER\u5728\u63a8\u8350\u6307\u6807\u548c\u53cd\u4e8b\u5b9e\u6b7b\u4ea1\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u63d0\u4f9b\u7a33\u5065\u7684\u7edf\u8ba1\u4fdd\u8bc1\u3002", "conclusion": "SAFER\u662f\u4e00\u4e2a\u53ef\u4fe1\u8d56\u4e14\u7406\u8bba\u624e\u5b9e\u7684\u9ad8\u98ce\u9669DTR\u5e94\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.06656", "pdf": "https://arxiv.org/pdf/2506.06656", "abs": "https://arxiv.org/abs/2506.06656", "authors": ["Ittai Rubinstein", "Samuel B. Hopkins"], "title": "Rescaled Influence Functions: Accurate Data Attribution in High Dimension", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "How does the training data affect a model's behavior? This is the question we\nseek to answer with data attribution. The leading practical approaches to data\nattribution are based on influence functions (IF). IFs utilize a first-order\nTaylor approximation to efficiently predict the effect of removing a set of\nsamples from the training set without retraining the model, and are used in a\nwide variety of machine learning applications. However, especially in the\nhigh-dimensional regime (# params $\\geq \\Omega($# samples$)$), they are often\nimprecise and tend to underestimate the effect of sample removals, even for\nsimple models such as logistic regression. We present rescaled influence\nfunctions (RIF), a new tool for data attribution which can be used as a drop-in\nreplacement for influence functions, with little computational overhead but\nsignificant improvement in accuracy. We compare IF and RIF on a range of\nreal-world datasets, showing that RIFs offer significantly better predictions\nin practice, and present a theoretical analysis explaining this improvement.\nFinally, we present a simple class of data poisoning attacks that would fool\nIF-based detections but would be detected by RIF.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u5f71\u54cd\u51fd\u6570\u65b9\u6cd5\uff08RIF\uff09\uff0c\u7528\u4e8e\u66f4\u51c6\u786e\u5730\u8bc4\u4f30\u8bad\u7ec3\u6570\u636e\u5bf9\u6a21\u578b\u884c\u4e3a\u7684\u5f71\u54cd\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u5f71\u54cd\u51fd\u6570\uff08IF\uff09\u5728\u9ad8\u7ef4\u6570\u636e\u4e2d\u7684\u4e0d\u7cbe\u786e\u95ee\u9898\u3002", "motivation": "\u7814\u7a76\u8bad\u7ec3\u6570\u636e\u5982\u4f55\u5f71\u54cd\u6a21\u578b\u884c\u4e3a\uff0c\u4f20\u7edf\u5f71\u54cd\u51fd\u6570\uff08IF\uff09\u5728\u9ad8\u7ef4\u6570\u636e\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u66f4\u7cbe\u786e\u7684\u6570\u636e\u5f52\u56e0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u5f71\u54cd\u51fd\u6570\u65b9\u6cd5\uff08RIF\uff09\uff0c\u901a\u8fc7\u91cd\u65b0\u7f29\u653e\u63d0\u5347\u7cbe\u5ea6\uff0c\u5e76\u9a8c\u8bc1\u5176\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u3002", "result": "RIF\u5728\u591a\u79cd\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8eIF\uff0c\u4e14\u80fd\u68c0\u6d4b\u5230IF\u65e0\u6cd5\u8bc6\u522b\u7684\u6570\u636e\u6295\u6bd2\u653b\u51fb\u3002", "conclusion": "RIF\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u6570\u636e\u5f52\u56e0\u5de5\u5177\uff0c\u53ef\u4f5c\u4e3aIF\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u673a\u5668\u5b66\u4e60\u5e94\u7528\u3002"}}
{"id": "2506.06665", "pdf": "https://arxiv.org/pdf/2506.06665", "abs": "https://arxiv.org/abs/2506.06665", "authors": ["Hong-Ming Chiu", "Hao Chen", "Huan Zhang", "Richard Y. Zhang"], "title": "SDP-CROWN: Efficient Bound Propagation for Neural Network Verification with Tightness of Semidefinite Programming", "categories": ["cs.LG"], "comment": "ICML 2025", "summary": "Neural network verifiers based on linear bound propagation scale impressively\nto massive models but can be surprisingly loose when neuron coupling is\ncrucial. Conversely, semidefinite programming (SDP) verifiers capture\ninter-neuron coupling naturally, but their cubic complexity restricts them to\nonly small models. In this paper, we propose SDP-CROWN, a novel hybrid\nverification framework that combines the tightness of SDP relaxations with the\nscalability of bound-propagation verifiers. At the core of SDP-CROWN is a new\nlinear bound, derived via SDP principles, that explicitly captures\n$\\ell_{2}$-norm-based inter-neuron coupling while adding only one extra\nparameter per layer. This bound can be integrated seamlessly into any linear\nbound-propagation pipeline, preserving the inherent scalability of such methods\nyet significantly improving tightness. In theory, we prove that our\ninter-neuron bound can be up to a factor of $\\sqrt{n}$ tighter than traditional\nper-neuron bounds. In practice, when incorporated into the state-of-the-art\n$\\alpha$-CROWN verifier, we observe markedly improved verification performance\non large models with up to 65 thousand neurons and 2.47 million parameters,\nachieving tightness that approaches that of costly SDP-based methods.", "AI": {"tldr": "SDP-CROWN\u662f\u4e00\u79cd\u65b0\u578b\u6df7\u5408\u9a8c\u8bc1\u6846\u67b6\uff0c\u7ed3\u5408\u4e86SDP\u677e\u5f1b\u7684\u7d27\u81f4\u6027\u548c\u8fb9\u754c\u4f20\u64ad\u9a8c\u8bc1\u5668\u7684\u53ef\u6269\u5c55\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u89c4\u6a21\u795e\u7ecf\u7f51\u7edc\u7684\u9a8c\u8bc1\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u7ebf\u6027\u8fb9\u754c\u4f20\u64ad\u9a8c\u8bc1\u5668\u5728\u5927\u89c4\u6a21\u6a21\u578b\u4e0a\u8868\u73b0\u826f\u597d\u4f46\u7d27\u81f4\u6027\u4e0d\u8db3\uff0c\u800cSDP\u9a8c\u8bc1\u5668\u867d\u80fd\u6355\u6349\u795e\u7ecf\u5143\u8026\u5408\u4f46\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u3002", "method": "\u63d0\u51faSDP-CROWN\u6846\u67b6\uff0c\u901a\u8fc7SDP\u539f\u7406\u63a8\u5bfc\u65b0\u7684\u7ebf\u6027\u8fb9\u754c\uff0c\u663e\u5f0f\u6355\u6349\u795e\u7ecf\u5143\u95f4\u7684\u8026\u5408\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u6269\u5c55\u6027\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u65b0\u8fb9\u754c\u6bd4\u4f20\u7edf\u65b9\u6cd5\u7d27\u81f4\u221an\u500d\uff1b\u5b9e\u8df5\u9a8c\u8bc1\u4e2d\uff0c\u5728\u5927\u578b\u6a21\u578b\u4e0a\u6027\u80fd\u663e\u8457\u63d0\u5347\uff0c\u63a5\u8fd1SDP\u65b9\u6cd5\u7684\u7d27\u81f4\u6027\u3002", "conclusion": "SDP-CROWN\u6210\u529f\u7ed3\u5408\u4e86SDP\u7684\u7d27\u81f4\u6027\u548c\u8fb9\u754c\u4f20\u64ad\u7684\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u5927\u89c4\u6a21\u795e\u7ecf\u7f51\u7edc\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.06666", "pdf": "https://arxiv.org/pdf/2506.06666", "abs": "https://arxiv.org/abs/2506.06666", "authors": ["Oktay Karaku\u015f", "Hasan Arkada\u015f"], "title": "Through the Gaps: Uncovering Tactical Line-Breaking Passes with Clustering", "categories": ["cs.LG", "stat.ML"], "comment": "12 pages and 5 figures", "summary": "Line-breaking passes (LBPs) are crucial tactical actions in football,\nallowing teams to penetrate defensive lines and access high-value spaces. In\nthis study, we present an unsupervised, clustering-based framework for\ndetecting and analysing LBPs using synchronised event and tracking data from\nelite matches. Our approach models opponent team shape through vertical spatial\nsegmentation and identifies passes that disrupt defensive lines within open\nplay. Beyond detection, we introduce several tactical metrics, including the\nspace build-up ratio (SBR) and two chain-based variants, LBPCh$^1$ and\nLBPCh$^2$, which quantify the effectiveness of LBPs in generating immediate or\nsustained attacking threats. We evaluate these metrics across teams and players\nin the 2022 FIFA World Cup, revealing stylistic differences in vertical\nprogression and structural disruption. The proposed methodology is explainable,\nscalable, and directly applicable to modern performance analysis and scouting\nworkflows.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u805a\u7c7b\u7684\u65e0\u76d1\u7763\u6846\u67b6\uff0c\u7528\u4e8e\u68c0\u6d4b\u548c\u5206\u6790\u8db3\u7403\u6bd4\u8d5b\u4e2d\u7684\u7ebf\u7a81\u7834\u4f20\u7403\uff08LBPs\uff09\uff0c\u5e76\u5f15\u5165\u6218\u672f\u6307\u6807\u8bc4\u4f30\u5176\u6548\u679c\u3002", "motivation": "\u7ebf\u7a81\u7834\u4f20\u7403\uff08LBPs\uff09\u662f\u8db3\u7403\u4e2d\u5173\u952e\u7684\u6218\u672f\u52a8\u4f5c\uff0c\u80fd\u591f\u7a7f\u900f\u9632\u7ebf\u5e76\u8fdb\u5165\u9ad8\u4ef7\u503c\u533a\u57df\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u7684\u5206\u6790\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u5782\u76f4\u7a7a\u95f4\u5206\u5272\u5efa\u6a21\u5bf9\u624b\u961f\u5f62\uff0c\u5229\u7528\u540c\u6b65\u4e8b\u4ef6\u548c\u8ffd\u8e2a\u6570\u636e\u68c0\u6d4bLBPs\uff0c\u5e76\u5f15\u5165\u7a7a\u95f4\u6784\u5efa\u6bd4\uff08SBR\uff09\u548c\u94fe\u5f0f\u6307\u6807\uff08LBPCh^1\u3001LBPCh^2\uff09\u91cf\u5316\u5176\u6548\u679c\u3002", "result": "\u57282022\u5e74\u4e16\u754c\u676f\u6570\u636e\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u7403\u961f\u548c\u7403\u5458\u5728\u5782\u76f4\u63a8\u8fdb\u548c\u7ed3\u6784\u7834\u574f\u4e0a\u7684\u98ce\u683c\u5dee\u5f02\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u89e3\u91ca\u3001\u53ef\u6269\u5c55\uff0c\u9002\u7528\u4e8e\u73b0\u4ee3\u8868\u73b0\u5206\u6790\u548c\u7403\u63a2\u5de5\u4f5c\u6d41\u7a0b\u3002"}}
{"id": "2506.06682", "pdf": "https://arxiv.org/pdf/2506.06682", "abs": "https://arxiv.org/abs/2506.06682", "authors": ["Di Lin", "Wanjing Ren", "Xuanbin Li", "Rui Zhang"], "title": "Learning Robust Heterogeneous Graph Representations via Contrastive-Reconstruction under Sparse Semantics", "categories": ["cs.LG"], "comment": null, "summary": "In graph self-supervised learning, masked autoencoders (MAE) and contrastive\nlearning (CL) are two prominent paradigms. MAE focuses on reconstructing masked\nelements, while CL maximizes similarity between augmented graph views. Recent\nstudies highlight their complementarity: MAE excels at local feature capture,\nand CL at global information extraction. Hybrid frameworks for homogeneous\ngraphs have been proposed, but face challenges in designing shared encoders to\nmeet the semantic requirements of both tasks. In semantically sparse scenarios,\nCL struggles with view construction, and gradient imbalance between positive\nand negative samples persists. This paper introduces HetCRF, a novel\ndual-channel self-supervised learning framework for heterogeneous graphs.\nHetCRF uses a two-stage aggregation strategy to adapt embedding semantics,\nmaking it compatible with both MAE and CL. To address semantic sparsity, it\nenhances encoder output for view construction instead of relying on raw\nfeatures, improving efficiency. Two positive sample augmentation strategies are\nalso proposed to balance gradient contributions. Node classification\nexperiments on four real-world heterogeneous graph datasets demonstrate that\nHetCRF outperforms state-of-the-art baselines. On datasets with missing node\nfeatures, such as Aminer and Freebase, at a 40% label rate in node\nclassification, HetCRF improves the Macro-F1 score by 2.75% and 2.2%\nrespectively compared to the second-best baseline, validating its effectiveness\nand superiority.", "AI": {"tldr": "HetCRF\u662f\u4e00\u79cd\u9488\u5bf9\u5f02\u6784\u56fe\u7684\u53cc\u901a\u9053\u81ea\u76d1\u7763\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u805a\u5408\u7b56\u7565\u548c\u6b63\u6837\u672c\u589e\u5f3a\u7b56\u7565\uff0c\u89e3\u51b3\u4e86MAE\u548cCL\u5728\u5f02\u6784\u56fe\u4e2d\u7684\u517c\u5bb9\u6027\u95ee\u9898\uff0c\u5e76\u5728\u8282\u70b9\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u89e3\u51b3\u5f02\u6784\u56fe\u81ea\u76d1\u7763\u5b66\u4e60\u4e2dMAE\u548cCL\u7684\u4e92\u8865\u6027\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u8bed\u4e49\u7a00\u758f\u573a\u666f\u4e0bCL\u7684\u89c6\u56fe\u6784\u5efa\u56f0\u96be\u548c\u68af\u5ea6\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "method": "\u63d0\u51faHetCRF\u6846\u67b6\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u805a\u5408\u7b56\u7565\u9002\u5e94\u5d4c\u5165\u8bed\u4e49\uff0c\u589e\u5f3a\u7f16\u7801\u5668\u8f93\u51fa\u4ee5\u6539\u8fdb\u89c6\u56fe\u6784\u5efa\uff0c\u5e76\u63d0\u51fa\u4e24\u79cd\u6b63\u6837\u672c\u589e\u5f3a\u7b56\u7565\u5e73\u8861\u68af\u5ea6\u8d21\u732e\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u5f02\u6784\u56fe\u6570\u636e\u96c6\u4e0a\u7684\u8282\u70b9\u5206\u7c7b\u5b9e\u9a8c\u4e2d\uff0cHetCRF\u5728\u7f3a\u5931\u8282\u70b9\u7279\u5f81\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0cMacro-F1\u5206\u6570\u63d0\u5347\u663e\u8457\u3002", "conclusion": "HetCRF\u901a\u8fc7\u521b\u65b0\u7684\u53cc\u901a\u9053\u8bbe\u8ba1\u548c\u6b63\u6837\u672c\u589e\u5f3a\u7b56\u7565\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5f02\u6784\u56fe\u81ea\u76d1\u7763\u5b66\u4e60\u7684\u6027\u80fd\uff0c\u5c24\u5176\u5728\u8bed\u4e49\u7a00\u758f\u573a\u666f\u4e0b\u8868\u73b0\u7a81\u51fa\u3002"}}
{"id": "2506.06694", "pdf": "https://arxiv.org/pdf/2506.06694", "abs": "https://arxiv.org/abs/2506.06694", "authors": ["Yuan Yuan", "Yukun Liu", "Chonghua Han", "Jie Feng", "Yong Li"], "title": "Breaking Data Silos: Towards Open and Scalable Mobility Foundation Models via Generative Continual Learning", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "Foundation models have revolutionized fields such as natural language\nprocessing and computer vision by enabling general-purpose learning across\ndiverse tasks and datasets. However, building analogous models for human\nmobility remains challenging due to the privacy-sensitive nature of mobility\ndata and the resulting data silos across institutions. To bridge this gap, we\npropose MoveGCL, a scalable and privacy-preserving framework for training\nmobility foundation models via generative continual learning. Without sharing\nraw data, MoveGCL enables decentralized and progressive model evolution by\nreplaying synthetic trajectories generated from a frozen teacher model, and\nreinforces knowledge retention through a tailored distillation strategy that\nmitigates catastrophic forgetting. To address the heterogeneity of mobility\npatterns, MoveGCL incorporates a Mixture-of-Experts Transformer with a\nmobility-aware expert routing mechanism, and employs a layer-wise progressive\nadaptation strategy to stabilize continual updates. Experiments on six\nreal-world urban datasets demonstrate that MoveGCL achieves performance\ncomparable to joint training and significantly outperforms federated learning\nbaselines, while offering strong privacy protection. MoveGCL marks a crucial\nstep toward unlocking foundation models for mobility, offering a practical\nblueprint for open, scalable, and privacy-preserving model development in the\nera of foundation models.", "AI": {"tldr": "MoveGCL\u662f\u4e00\u4e2a\u9690\u79c1\u4fdd\u62a4\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u751f\u6210\u5f0f\u6301\u7eed\u5b66\u4e60\u8bad\u7ec3\u79fb\u52a8\u6027\u57fa\u7840\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u6570\u636e\u5b64\u5c9b\u548c\u9690\u79c1\u95ee\u9898\uff0c\u6027\u80fd\u63a5\u8fd1\u8054\u5408\u8bad\u7ec3\uff0c\u4f18\u4e8e\u8054\u90a6\u5b66\u4e60\u3002", "motivation": "\u7531\u4e8e\u79fb\u52a8\u6570\u636e\u7684\u9690\u79c1\u654f\u611f\u6027\u548c\u6570\u636e\u5b64\u5c9b\u95ee\u9898\uff0c\u6784\u5efa\u7c7b\u4f3c\u57fa\u7840\u6a21\u578b\u5177\u6709\u6311\u6218\u6027\u3002", "method": "MoveGCL\u91c7\u7528\u751f\u6210\u5f0f\u6301\u7eed\u5b66\u4e60\uff0c\u901a\u8fc7\u51bb\u7ed3\u6559\u5e08\u6a21\u578b\u751f\u6210\u5408\u6210\u8f68\u8ff9\uff0c\u7ed3\u5408\u77e5\u8bc6\u84b8\u998f\u548cMixture-of-Experts Transformer\u3002", "result": "\u5728\u516d\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0cMoveGCL\u6027\u80fd\u63a5\u8fd1\u8054\u5408\u8bad\u7ec3\uff0c\u663e\u8457\u4f18\u4e8e\u8054\u90a6\u5b66\u4e60\u57fa\u7ebf\u3002", "conclusion": "MoveGCL\u4e3a\u79fb\u52a8\u6027\u57fa\u7840\u6a21\u578b\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u5f00\u653e\u3001\u53ef\u6269\u5c55\u4e14\u9690\u79c1\u4fdd\u62a4\u7684\u84dd\u56fe\u3002"}}
{"id": "2506.06699", "pdf": "https://arxiv.org/pdf/2506.06699", "abs": "https://arxiv.org/abs/2506.06699", "authors": ["Rajeev Bhatt Ambati", "James Lester", "Shashank Srivastava", "Snigdha Chaturvedi"], "title": "MarginSel : Max-Margin Demonstration Selection for LLMs", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) excel at few-shot learning via in-context\nlearning (ICL). However, the effectiveness of ICL is often sensitive to the\nselection and ordering of demonstration examples. To address this, we present\nMarginSel: Max-Margin Demonstration Selection for LLMs, a two-step method that\nselects hard demonstration examples for the ICL prompt, adapting to each test\ninstance. Our approach achieves 2-7% absolute improvement in F1-score across\nclassification tasks, compared to a random selection of examples. We also\nprovide theoretical insights and empirical evidence showing that MarginSel\ninduces max-margin behavior in LLMs by effectively increasing the margin for\nhard examples, analogous to support vectors, thereby shifting the decision\nboundary in a beneficial direction.", "AI": {"tldr": "MarginSel\u662f\u4e00\u79cd\u901a\u8fc7\u9009\u62e9\u56f0\u96be\u793a\u4f8b\u63d0\u5347LLM\u4e0a\u4e0b\u6587\u5b66\u4e60\u6548\u679c\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5206\u7c7b\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u6548\u679c\u5bf9\u793a\u4f8b\u9009\u62e9\u548c\u987a\u5e8f\u654f\u611f\uff0c\u9700\u8981\u4e00\u79cd\u81ea\u9002\u5e94\u7684\u65b9\u6cd5\u6765\u4f18\u5316\u6f14\u793a\u793a\u4f8b\u7684\u9009\u62e9\u3002", "method": "\u63d0\u51faMarginSel\uff0c\u4e00\u79cd\u4e24\u6b65\u6cd5\uff0c\u4e3a\u6bcf\u4e2a\u6d4b\u8bd5\u5b9e\u4f8b\u9009\u62e9\u56f0\u96be\u793a\u4f8b\uff0c\u4ee5\u6700\u5927\u5316\u6a21\u578b\u6027\u80fd\u3002", "result": "\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0cMarginSel\u76f8\u6bd4\u968f\u673a\u9009\u62e9\u793a\u4f8b\uff0cF1\u5206\u6570\u7edd\u5bf9\u63d0\u53472-7%\u3002", "conclusion": "MarginSel\u901a\u8fc7\u589e\u52a0\u56f0\u96be\u793a\u4f8b\u7684\u8fb9\u754c\uff0c\u6709\u6548\u6539\u5584\u4e86LLM\u7684\u51b3\u7b56\u8fb9\u754c\uff0c\u63d0\u5347\u4e86\u6027\u80fd\u3002"}}
{"id": "2506.06701", "pdf": "https://arxiv.org/pdf/2506.06701", "abs": "https://arxiv.org/abs/2506.06701", "authors": ["Fudong Lin", "Wanrou Du", "Jinchan Liu", "Tarikul Milon", "Shelby Meche", "Wu Xu", "Xiaoqi Qin", "Xu Yuan"], "title": "Do Protein Transformers Have Biological Intelligence?", "categories": ["cs.LG", "cs.AI", "q-bio.BM"], "comment": "Accepted by European Conference on Machine Learning and Principles\n  and Practice of Knowledge Discovery in Databases (ECML-PKDD 2025)", "summary": "Deep neural networks, particularly Transformers, have been widely adopted for\npredicting the functional properties of proteins. In this work, we focus on\nexploring whether Protein Transformers can capture biological intelligence\namong protein sequences. To achieve our goal, we first introduce a protein\nfunction dataset, namely Protein-FN, providing over 9000 protein data with\nmeaningful labels. Second, we devise a new Transformer architecture, namely\nSequence Protein Transformers (SPT), for computationally efficient protein\nfunction predictions. Third, we develop a novel Explainable Artificial\nIntelligence (XAI) technique called Sequence Score, which can efficiently\ninterpret the decision-making processes of protein models, thereby overcoming\nthe difficulty of deciphering biological intelligence bided in Protein\nTransformers. Remarkably, even our smallest SPT-Tiny model, which contains only\n5.4M parameters, demonstrates impressive predictive accuracy, achieving 94.3%\non the Antibiotic Resistance (AR) dataset and 99.6% on the Protein-FN dataset,\nall accomplished by training from scratch. Besides, our Sequence Score\ntechnique helps reveal that our SPT models can discover several meaningful\npatterns underlying the sequence structures of protein data, with these\npatterns aligning closely with the domain knowledge in the biology community.\nWe have officially released our Protein-FN dataset on Hugging Face Datasets\nhttps://huggingface.co/datasets/Protein-FN/Protein-FN. Our code is available at\nhttps://github.com/fudong03/BioIntelligence.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684Transformer\u67b6\u6784\uff08SPT\uff09\u548c\u53ef\u89e3\u91caAI\u6280\u672f\uff08Sequence Score\uff09\uff0c\u7528\u4e8e\u9ad8\u6548\u9884\u6d4b\u86cb\u767d\u8d28\u529f\u80fd\u5e76\u63ed\u793a\u5176\u751f\u7269\u5b66\u667a\u80fd\u3002", "motivation": "\u63a2\u7d22\u86cb\u767d\u8d28Transformer\u662f\u5426\u80fd\u6355\u6349\u86cb\u767d\u8d28\u5e8f\u5217\u4e2d\u7684\u751f\u7269\u5b66\u667a\u80fd\u3002", "method": "1. \u5f15\u5165Protein-FN\u6570\u636e\u96c6\uff1b2. \u8bbe\u8ba1SPT\u67b6\u6784\uff1b3. \u5f00\u53d1Sequence Score\u6280\u672f\u3002", "result": "SPT-Tiny\u6a21\u578b\u5728AR\u548cProtein-FN\u6570\u636e\u96c6\u4e0a\u5206\u522b\u8fbe\u523094.3%\u548c99.6%\u7684\u51c6\u786e\u7387\u3002Sequence Score\u63ed\u793a\u4e86\u4e0e\u751f\u7269\u5b66\u77e5\u8bc6\u4e00\u81f4\u7684\u5e8f\u5217\u6a21\u5f0f\u3002", "conclusion": "SPT\u548cSequence Score\u6280\u672f\u6210\u529f\u6355\u6349\u4e86\u86cb\u767d\u8d28\u5e8f\u5217\u4e2d\u7684\u751f\u7269\u5b66\u667a\u80fd\uff0c\u5e76\u63d0\u4f9b\u4e86\u9ad8\u6548\u9884\u6d4b\u548c\u89e3\u91ca\u80fd\u529b\u3002"}}
{"id": "2506.06715", "pdf": "https://arxiv.org/pdf/2506.06715", "abs": "https://arxiv.org/abs/2506.06715", "authors": ["Minh-Duc Nguyen", "Dung D. Le"], "title": "A Framework for Controllable Multi-objective Learning with Annealed Stein Variational Hypernetworks", "categories": ["cs.LG", "stat.ML"], "comment": "Paper is under review", "summary": "Pareto Set Learning (PSL) is popular as an efficient approach to obtaining\nthe complete optimal solution in Multi-objective Learning (MOL). A set of\noptimal solutions approximates the Pareto set, and its mapping is a set of\ndense points in the Pareto front in objective space. However, some current\nmethods face a challenge: how to make the Pareto solution is diverse while\nmaximizing the hypervolume value. In this paper, we propose a novel method to\naddress this challenge, which employs Stein Variational Gradient Descent (SVGD)\nto approximate the entire Pareto set. SVGD pushes a set of particles towards\nthe Pareto set by applying a form of functional gradient descent, which helps\nto converge and diversify optimal solutions. Additionally, we employ diverse\ngradient direction strategies to thoroughly investigate a unified framework for\nSVGD in multi-objective optimization and adapt this framework with an annealing\nschedule to promote stability. We introduce our method, SVH-MOL, and validate\nits effectiveness through extensive experiments on multi-objective problems and\nmulti-task learning, demonstrating its superior performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eStein\u53d8\u5206\u68af\u5ea6\u4e0b\u964d\uff08SVGD\uff09\u7684\u65b0\u65b9\u6cd5SVH-MOL\uff0c\u7528\u4e8e\u89e3\u51b3\u591a\u76ee\u6807\u5b66\u4e60\u4e2dPareto\u89e3\u7684\u591a\u6837\u6027\u4e0e\u8d85\u4f53\u79ef\u503c\u6700\u5927\u5316\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u65b9\u6cd5\u5728Pareto\u89e3\u7684\u591a\u6837\u6027\u4e0e\u8d85\u4f53\u79ef\u503c\u6700\u5927\u5316\u4e4b\u95f4\u5b58\u5728\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u5e73\u8861\u8fd9\u4e24\u8005\u3002", "method": "\u91c7\u7528SVGD\u903c\u8fd1\u6574\u4e2aPareto\u96c6\uff0c\u901a\u8fc7\u529f\u80fd\u68af\u5ea6\u4e0b\u964d\u63a8\u52a8\u7c92\u5b50\u96c6\u5411Pareto\u96c6\u6536\u655b\u5e76\u591a\u6837\u5316\u3002\u7ed3\u5408\u591a\u6837\u5316\u68af\u5ea6\u65b9\u5411\u7b56\u7565\u548c\u9000\u706b\u8c03\u5ea6\u4ee5\u63d0\u5347\u7a33\u5b9a\u6027\u3002", "result": "\u5728\u591a\u79cd\u591a\u76ee\u6807\u95ee\u9898\u548c\u591a\u4efb\u52a1\u5b66\u4e60\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86SVH-MOL\u7684\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "SVH-MOL\u662f\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u540c\u65f6\u5b9e\u73b0Pareto\u89e3\u7684\u591a\u6837\u6027\u548c\u8d85\u4f53\u79ef\u503c\u6700\u5927\u5316\u3002"}}
{"id": "2506.06761", "pdf": "https://arxiv.org/pdf/2506.06761", "abs": "https://arxiv.org/abs/2506.06761", "authors": ["Adri\u00e0 Molina Rodr\u00edguez", "Oriol Ramos Terrades", "Josep Llad\u00f3s"], "title": "The OCR Quest for Generalization: Learning to recognize low-resource alphabets with model editing", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Achieving robustness in recognition systems across diverse domains is crucial\nfor their practical utility. While ample data availability is usually assumed,\nlow-resource languages, such as ancient manuscripts and non-western languages,\ntend to be kept out of the equations of massive pretraining and foundational\ntechniques due to an under representation. In this work, we aim for building\nmodels which can generalize to new distributions of data, such as alphabets,\nfaster than centralized fine-tune strategies. For doing so, we take advantage\nof the recent advancements in model editing to enhance the incorporation of\nunseen scripts (low-resource learning). In contrast to state-of-the-art\nmeta-learning, we showcase the effectiveness of domain merging in sparse\ndistributions of data, with agnosticity of its relation to the overall\ndistribution or any other prototyping necessity. Even when using the same exact\ntraining data, our experiments showcase significant performance boosts in\n\\textbf{transfer learning} to new alphabets and \\textbf{out-of-domain\nevaluation} in challenging domain shifts, including historical ciphered texts\nand non-Latin scripts. This research contributes a novel approach into building\nmodels that can easily adopt under-represented alphabets and, therefore, enable\ndocument recognition to a wider set of contexts and cultures.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u6a21\u578b\u7f16\u8f91\u6280\u672f\u63d0\u5347\u4f4e\u8d44\u6e90\u8bed\u8a00\uff08\u5982\u53e4\u4ee3\u624b\u7a3f\u548c\u975e\u897f\u65b9\u8bed\u8a00\uff09\u7684\u8bc6\u522b\u80fd\u529b\uff0c\u4f18\u4e8e\u4f20\u7edf\u7684\u5143\u5b66\u4e60\u65b9\u6cd5\uff0c\u5e76\u5728\u8de8\u9886\u57df\u8bc4\u4f30\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u89e3\u51b3\u4f4e\u8d44\u6e90\u8bed\u8a00\u5728\u8bc6\u522b\u7cfb\u7edf\u4e2d\u4ee3\u8868\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u63d0\u5347\u6a21\u578b\u5bf9\u65b0\u6570\u636e\u5206\u5e03\uff08\u5982\u65b0\u5b57\u6bcd\u8868\uff09\u7684\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u5229\u7528\u6a21\u578b\u7f16\u8f91\u6280\u672f\uff0c\u7ed3\u5408\u9886\u57df\u5408\u5e76\u7b56\u7565\uff0c\u65e0\u9700\u4f9d\u8d56\u5927\u91cf\u6570\u636e\u6216\u539f\u578b\u8bbe\u8ba1\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5373\u4f7f\u5728\u76f8\u540c\u8bad\u7ec3\u6570\u636e\u4e0b\uff0c\u8be5\u65b9\u6cd5\u5728\u8de8\u5b57\u6bcd\u8868\u8fc1\u79fb\u5b66\u4e60\u548c\u9886\u57df\u5916\u8bc4\u4f30\u4e2d\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u6587\u6863\u8bc6\u522b\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u6269\u5c55\u4e86\u8bc6\u522b\u7cfb\u7edf\u7684\u9002\u7528\u573a\u666f\u548c\u6587\u5316\u8986\u76d6\u8303\u56f4\u3002"}}
{"id": "2506.06782", "pdf": "https://arxiv.org/pdf/2506.06782", "abs": "https://arxiv.org/abs/2506.06782", "authors": ["Qinting Jiang", "Chuyang Ye", "Dongyan Wei", "Bingli Wang", "Yuan Xue", "Jingyan Jiang", "Zhi Wang"], "title": "Feature-Based Instance Neighbor Discovery: Advanced Stable Test-Time Adaptation in Dynamic World", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Despite progress, deep neural networks still suffer performance declines\nunder distribution shifts between training and test domains, leading to a\nsubstantial decrease in Quality of Experience (QoE) for applications. Existing\ntest-time adaptation (TTA) methods are challenged by dynamic, multiple test\ndistributions within batches. We observe that feature distributions across\ndifferent domains inherently cluster into distinct groups with varying means\nand variances. This divergence reveals a critical limitation of previous global\nnormalization strategies in TTA, which inevitably distort the original data\ncharacteristics. Based on this insight, we propose Feature-based Instance\nNeighbor Discovery (FIND), which comprises three key components: Layer-wise\nFeature Disentanglement (LFD), Feature Aware Batch Normalization (FABN) and\nSelective FABN (S-FABN). LFD stably captures features with similar\ndistributions at each layer by constructing graph structures. While FABN\noptimally combines source statistics with test-time distribution specific\nstatistics for robust feature representation. Finally, S-FABN determines which\nlayers require feature partitioning and which can remain unified, thereby\nenhancing inference efficiency. Extensive experiments demonstrate that FIND\nsignificantly outperforms existing methods, achieving a 30\\% accuracy\nimprovement in dynamic scenarios while maintaining computational efficiency.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFIND\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u7279\u5f81\u805a\u7c7b\u548c\u52a8\u6001\u5f52\u4e00\u5316\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5728\u52a8\u6001\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u6027\u80fd\u3002", "motivation": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5728\u8bad\u7ec3\u548c\u6d4b\u8bd5\u57df\u4e4b\u95f4\u7684\u5206\u5e03\u504f\u79fb\u4e0b\u6027\u80fd\u4e0b\u964d\uff0c\u5f71\u54cd\u5e94\u7528\u4f53\u9a8c\u3002\u73b0\u6709\u6d4b\u8bd5\u65f6\u9002\u5e94\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u52a8\u6001\u3001\u591a\u5206\u5e03\u7684\u6d4b\u8bd5\u6570\u636e\u3002", "method": "FIND\u65b9\u6cd5\u5305\u62ec\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a\u5c42\u95f4\u7279\u5f81\u89e3\u8026\uff08LFD\uff09\u3001\u7279\u5f81\u611f\u77e5\u6279\u91cf\u5f52\u4e00\u5316\uff08FABN\uff09\u548c\u9009\u62e9\u6027FABN\uff08S-FABN\uff09\uff0c\u5206\u522b\u7528\u4e8e\u7279\u5f81\u805a\u7c7b\u3001\u52a8\u6001\u5f52\u4e00\u5316\u548c\u4f18\u5316\u6548\u7387\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cFIND\u5728\u52a8\u6001\u573a\u666f\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u51c6\u786e\u7387\u63d0\u534730%\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "FIND\u901a\u8fc7\u7279\u5f81\u805a\u7c7b\u548c\u52a8\u6001\u5f52\u4e00\u5316\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u52a8\u6001\u5206\u5e03\u504f\u79fb\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u9c81\u68d2\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2506.06784", "pdf": "https://arxiv.org/pdf/2506.06784", "abs": "https://arxiv.org/abs/2506.06784", "authors": ["Marek \u010cern\u00fd"], "title": "Caterpillar GNN: Replacing Message Passing with Efficient Aggregation", "categories": ["cs.LG", "68T07 (Primary), 05C60, 05C85 (Secondary)", "I.2.6; G.2.2"], "comment": "40 pages, 9 figures, 3 tables", "summary": "Message-passing graph neural networks (MPGNNs) dominate modern graph\nlearning, typically prioritizing maximal expressive power. In contrast, we\nintroduce an \\emph{efficient aggregation} mechanism, deliberately trading off\nsome expressivity for stronger and more structured aggregation capabilities.\nOur approach allows seamless scaling between classical message-passing and\nsimpler methods based on colored or plain walks. We rigorously characterize the\nexpressive power at each intermediate step using homomorphism counts from a\nhierarchy of generalized \\emph{caterpillar graphs}. Based on this foundation,\nwe propose the \\emph{Caterpillar GNN}, whose robust graph-level aggregation\nenables it to successfully tackle synthetic graph-level task specifically\ndesigned to be challenging for classical MPGNNs. Moreover, we demonstrate that,\non real-world datasets, the Caterpillar GNN achieves comparable predictive\nperformance while significantly reducing the number of nodes in the hidden\nlayers of the computational graph.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u805a\u5408\u673a\u5236\uff0c\u727a\u7272\u90e8\u5206\u8868\u8fbe\u80fd\u529b\u4ee5\u589e\u5f3a\u7ed3\u6784\u5316\u805a\u5408\u80fd\u529b\uff0c\u5e76\u57fa\u4e8e\u6b64\u8bbe\u8ba1\u4e86Caterpillar GNN\uff0c\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u4f20\u7edf\u7684\u6d88\u606f\u4f20\u9012\u56fe\u795e\u7ecf\u7f51\u7edc\uff08MPGNNs\uff09\u901a\u5e38\u8ffd\u6c42\u6700\u5927\u8868\u8fbe\u80fd\u529b\uff0c\u4f46\u672c\u6587\u5e0c\u671b\u901a\u8fc7\u727a\u7272\u90e8\u5206\u8868\u8fbe\u80fd\u529b\u6765\u589e\u5f3a\u805a\u5408\u80fd\u529b\uff0c\u5e76\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u56fe\u5b66\u4e60\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u805a\u5408\u673a\u5236\uff0c\u901a\u8fc7\u5e7f\u4e49\u7684caterpillar\u56fe\u7684\u540c\u6001\u8ba1\u6570\u6765\u4e25\u683c\u8868\u5f81\u8868\u8fbe\u80fd\u529b\uff0c\u5e76\u8bbe\u8ba1\u4e86Caterpillar GNN\u3002", "result": "Caterpillar GNN\u5728\u5408\u6210\u56fe\u7ea7\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u4e8e\u4f20\u7edfMPGNNs\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u9884\u6d4b\u6027\u80fd\u76f8\u5f53\u4f46\u663e\u8457\u51cf\u5c11\u4e86\u9690\u85cf\u5c42\u8282\u70b9\u6570\u3002", "conclusion": "\u901a\u8fc7\u9ad8\u6548\u805a\u5408\u673a\u5236\uff0cCaterpillar GNN\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2506.06787", "pdf": "https://arxiv.org/pdf/2506.06787", "abs": "https://arxiv.org/abs/2506.06787", "authors": ["Qiyun Zhao"], "title": "FuncGNN: Learning Functional Semantics of Logic Circuits with Graph Neural Networks", "categories": ["cs.LG", "cs.AR"], "comment": null, "summary": "As integrated circuit scale grows and design complexity rises, effective\ncircuit representation helps support logic synthesis, formal verification, and\nother automated processes in electronic design automation. And-Inverter Graphs\n(AIGs), as a compact and canonical structure, are widely adopted for\nrepresenting Boolean logic in these workflows. However, the increasing\ncomplexity and integration density of modern circuits introduce structural\nheterogeneity and global logic information loss in AIGs, posing significant\nchallenges to accurate circuit modeling. To address these issues, we propose\nFuncGNN, which integrates hybrid feature aggregation to extract\nmulti-granularity topological patterns, thereby mitigating structural\nheterogeneity and enhancing logic circuit representations. FuncGNN further\nintroduces gate-aware normalization that adapts to circuit-specific gate\ndistributions, improving robustness to structural heterogeneity. Finally,\nFuncGNN employs multi-layer integration to merge intermediate features across\nlayers, effectively synthesizing local and global semantic information for\ncomprehensive logic representations. Experimental results on two logic-level\nanalysis tasks (i.e., signal probability prediction and truth-table distance\nprediction) demonstrate that FuncGNN outperforms existing state-of-the-art\nmethods, achieving improvements of 2.06% and 18.71%, respectively, while\nreducing training time by approximately 50.6% and GPU memory usage by about\n32.8%.", "AI": {"tldr": "FuncGNN\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u7535\u8def\u8868\u793a\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u7c92\u5ea6\u62d3\u6251\u7279\u5f81\u63d0\u53d6\u548c\u95e8\u611f\u77e5\u5f52\u4e00\u5316\uff0c\u89e3\u51b3\u4e86AIGs\u4e2d\u7684\u7ed3\u6784\u5f02\u8d28\u6027\u548c\u5168\u5c40\u4fe1\u606f\u4e22\u5931\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u903b\u8f91\u7535\u8def\u7684\u8868\u793a\u6548\u679c\u3002", "motivation": "\u968f\u7740\u96c6\u6210\u7535\u8def\u89c4\u6a21\u548c\u8bbe\u8ba1\u590d\u6742\u5ea6\u7684\u589e\u52a0\uff0c\u4f20\u7edfAIGs\u5728\u8868\u793a\u5e03\u5c14\u903b\u8f91\u65f6\u9762\u4e34\u7ed3\u6784\u5f02\u8d28\u6027\u548c\u5168\u5c40\u4fe1\u606f\u4e22\u5931\u7684\u6311\u6218\uff0c\u4e9f\u9700\u66f4\u6709\u6548\u7684\u8868\u793a\u65b9\u6cd5\u3002", "method": "FuncGNN\u7ed3\u5408\u4e86\u6df7\u5408\u7279\u5f81\u805a\u5408\u3001\u95e8\u611f\u77e5\u5f52\u4e00\u5316\u548c\u591a\u5c42\u96c6\u6210\u6280\u672f\uff0c\u4ee5\u63d0\u53d6\u591a\u7c92\u5ea6\u62d3\u6251\u6a21\u5f0f\u5e76\u7efc\u5408\u5c40\u90e8\u4e0e\u5168\u5c40\u8bed\u4e49\u4fe1\u606f\u3002", "result": "\u5728\u4fe1\u53f7\u6982\u7387\u9884\u6d4b\u548c\u771f\u503c\u8868\u8ddd\u79bb\u9884\u6d4b\u4efb\u52a1\u4e2d\uff0cFuncGNN\u5206\u522b\u63d0\u5347\u4e862.06%\u548c18.71%\u7684\u6027\u80fd\uff0c\u540c\u65f6\u51cf\u5c11\u4e8650.6%\u7684\u8bad\u7ec3\u65f6\u95f4\u548c32.8%\u7684GPU\u5185\u5b58\u4f7f\u7528\u3002", "conclusion": "FuncGNN\u901a\u8fc7\u521b\u65b0\u7684\u7279\u5f81\u63d0\u53d6\u548c\u96c6\u6210\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u903b\u8f91\u7535\u8def\u7684\u8868\u793a\u80fd\u529b\uff0c\u4e3a\u7535\u5b50\u8bbe\u8ba1\u81ea\u52a8\u5316\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.06793", "pdf": "https://arxiv.org/pdf/2506.06793", "abs": "https://arxiv.org/abs/2506.06793", "authors": ["Zixuan Dong", "Yumi Omori", "Keith Ross"], "title": "Is Optimal Transport Necessary for Inverse Reinforcement Learning?", "categories": ["cs.LG", "cs.AI"], "comment": "19 pages, 10 tables", "summary": "Inverse Reinforcement Learning (IRL) aims to recover a reward function from\nexpert demonstrations. Recently, Optimal Transport (OT) methods have been\nsuccessfully deployed to align trajectories and infer rewards. While OT-based\nmethods have shown strong empirical results, they introduce algorithmic\ncomplexity, hyperparameter sensitivity, and require solving the OT optimization\nproblems. In this work, we challenge the necessity of OT in IRL by proposing\ntwo simple, heuristic alternatives: (1) Minimum-Distance Reward, which assigns\nrewards based on the nearest expert state regardless of temporal order; and (2)\nSegment-Matching Reward, which incorporates lightweight temporal alignment by\nmatching agent states to corresponding segments in the expert trajectory. These\nmethods avoid optimization, exhibit linear-time complexity, and are easy to\nimplement. Through extensive evaluations across 32 online and offline\nbenchmarks with three reinforcement learning algorithms, we show that our\nsimple rewards match or outperform recent OT-based approaches. Our findings\nsuggest that the core benefits of OT may arise from basic proximity alignment\nrather than its optimal coupling formulation, advocating for reevaluation of\ncomplexity in future IRL design.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e24\u79cd\u7b80\u5355\u7684\u542f\u53d1\u5f0f\u66ff\u4ee3\u65b9\u6cd5\uff08\u6700\u5c0f\u8ddd\u79bb\u5956\u52b1\u548c\u5206\u6bb5\u5339\u914d\u5956\u52b1\uff09\uff0c\u6311\u6218\u4e86\u9006\u5f3a\u5316\u5b66\u4e60\u4e2d\u6700\u4f18\u4f20\u8f93\u7684\u5fc5\u8981\u6027\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u4e8e\u6216\u5339\u914d\u57fa\u4e8e\u6700\u4f18\u4f20\u8f93\u7684\u65b9\u6cd5\u3002", "motivation": "\u6700\u4f18\u4f20\u8f93\u65b9\u6cd5\u5728\u9006\u5f3a\u5316\u5b66\u4e60\u4e2d\u867d\u7136\u6709\u6548\uff0c\u4f46\u5f15\u5165\u4e86\u7b97\u6cd5\u590d\u6742\u6027\u3001\u8d85\u53c2\u6570\u654f\u611f\u6027\u7b49\u95ee\u9898\uff0c\u4f5c\u8005\u8d28\u7591\u5176\u5fc5\u8981\u6027\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u7b80\u5355\u65b9\u6cd5\uff1a\u6700\u5c0f\u8ddd\u79bb\u5956\u52b1\uff08\u5ffd\u7565\u65f6\u95f4\u987a\u5e8f\uff09\u548c\u5206\u6bb5\u5339\u914d\u5956\u52b1\uff08\u8f7b\u91cf\u7ea7\u65f6\u95f4\u5bf9\u9f50\uff09\uff0c\u907f\u514d\u4f18\u5316\u95ee\u9898\uff0c\u590d\u6742\u5ea6\u4f4e\u3002", "result": "\u572832\u4e2a\u5728\u7ebf\u548c\u79bb\u7ebf\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4e24\u79cd\u7b80\u5355\u65b9\u6cd5\u4e0e\u4e09\u79cd\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u7ed3\u5408\uff0c\u8868\u73b0\u4f18\u4e8e\u6216\u5339\u914d\u6700\u4f18\u4f20\u8f93\u65b9\u6cd5\u3002", "conclusion": "\u6700\u4f18\u4f20\u8f93\u7684\u6838\u5fc3\u4f18\u52bf\u53ef\u80fd\u6e90\u4e8e\u57fa\u672c\u63a5\u8fd1\u5bf9\u9f50\u800c\u975e\u5176\u6700\u4f18\u8026\u5408\u516c\u5f0f\uff0c\u5efa\u8bae\u672a\u6765\u9006\u5f3a\u5316\u5b66\u4e60\u8bbe\u8ba1\u91cd\u65b0\u8bc4\u4f30\u590d\u6742\u6027\u3002"}}
{"id": "2506.06809", "pdf": "https://arxiv.org/pdf/2506.06809", "abs": "https://arxiv.org/abs/2506.06809", "authors": ["Di Lin", "Wanjing Ren", "Xuanbin Li", "Rui Zhang"], "title": "IMPA-HGAE:Intra-Meta-Path Augmented Heterogeneous Graph Autoencoder", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Self-supervised learning (SSL) methods have been increasingly applied to\ndiverse downstream tasks due to their superior generalization capabilities and\nlow annotation costs. However, most existing heterogeneous graph SSL models\nconvert heterogeneous graphs into homogeneous ones via meta-paths for training,\nwhich only leverage information from nodes at both ends of meta-paths while\nunderutilizing the heterogeneous node information along the meta-paths. To\naddress this limitation, this paper proposes a novel framework named IMPA-HGAE\nto enhance target node embeddings by fully exploiting internal node information\nalong meta-paths. Experimental results validate that IMPA-HGAE achieves\nsuperior performance on heterogeneous datasets. Furthermore, this paper\nintroduce innovative masking strategies to strengthen the representational\ncapacity of generative SSL models on heterogeneous graph data. Additionally,\nthis paper discuss the interpretability of the proposed method and potential\nfuture directions for generative self-supervised learning in heterogeneous\ngraphs. This work provides insights into leveraging meta-path-guided structural\nsemantics for robust representation learning in complex graph scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aIMPA-HGAE\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u5145\u5206\u5229\u7528\u5143\u8def\u5f84\u4e0a\u7684\u5185\u90e8\u8282\u70b9\u4fe1\u606f\u6765\u589e\u5f3a\u76ee\u6807\u8282\u70b9\u5d4c\u5165\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5f02\u6784\u56fe\u81ea\u76d1\u7763\u5b66\u4e60\u6a21\u578b\u4fe1\u606f\u5229\u7528\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u5f02\u6784\u56fe\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u901a\u8fc7\u5143\u8def\u5f84\u5c06\u5f02\u6784\u56fe\u8f6c\u6362\u4e3a\u540c\u6784\u56fe\u8fdb\u884c\u8bad\u7ec3\uff0c\u4ec5\u5229\u7528\u5143\u8def\u5f84\u4e24\u7aef\u8282\u70b9\u7684\u4fe1\u606f\uff0c\u800c\u5ffd\u7565\u4e86\u5143\u8def\u5f84\u4e0a\u7684\u5f02\u6784\u8282\u70b9\u4fe1\u606f\u3002", "method": "\u63d0\u51faIMPA-HGAE\u6846\u67b6\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u63a9\u7801\u7b56\u7565\u548c\u751f\u6210\u5f0f\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff0c\u5145\u5206\u5229\u7528\u5143\u8def\u5f84\u4e0a\u7684\u5185\u90e8\u8282\u70b9\u4fe1\u606f\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eIMPA-HGAE\u5728\u5f02\u6784\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u589e\u5f3a\u4e86\u751f\u6210\u5f0f\u81ea\u76d1\u7763\u5b66\u4e60\u6a21\u578b\u7684\u8868\u793a\u80fd\u529b\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u590d\u6742\u56fe\u573a\u666f\u4e2d\u5229\u7528\u5143\u8def\u5f84\u5f15\u5bfc\u7684\u7ed3\u6784\u8bed\u4e49\u8fdb\u884c\u9c81\u68d2\u8868\u793a\u5b66\u4e60\u63d0\u4f9b\u4e86\u89c1\u89e3\uff0c\u5e76\u63a2\u8ba8\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2506.06815", "pdf": "https://arxiv.org/pdf/2506.06815", "abs": "https://arxiv.org/abs/2506.06815", "authors": ["Max McGuinness", "Eirik Fladmark", "Francisco Vargas"], "title": "Path Integral Optimiser: Global Optimisation via Neural Schr\u00f6dinger-F\u00f6llmer Diffusion", "categories": ["cs.LG"], "comment": "6 pages. Presented at the OPT Workshop, NeurIPS 2024, Vancouver, CA", "summary": "We present an early investigation into the use of neural diffusion processes\nfor global optimisation, focusing on Zhang et al.'s Path Integral Sampler. One\ncan use the Boltzmann distribution to formulate optimization as solving a\nSchr\\\"odinger bridge sampling problem, then apply Girsanov's theorem with a\nsimple (single-point) prior to frame it in stochastic control terms, and\ncompute the solution's integral terms via a neural approximation (a Fourier\nMLP). We provide theoretical bounds for this optimiser, results on toy\noptimisation tasks, and a summary of the stochastic theory motivating the\nmodel. Ultimately, we found the optimiser to display promising per-step\nperformance at optimisation tasks between 2 and 1,247 dimensions, but struggle\nto explore higher-dimensional spaces when faced with a 15.9k parameter model,\nindicating a need for work on adaptation in such environments.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u795e\u7ecf\u6269\u6563\u8fc7\u7a0b\u5728\u5168\u5c40\u4f18\u5316\u4e2d\u7684\u5e94\u7528\uff0c\u57fa\u4e8eZhang\u7b49\u4eba\u7684Path Integral Sampler\uff0c\u901a\u8fc7Boltzmann\u5206\u5e03\u5c06\u4f18\u5316\u95ee\u9898\u8f6c\u5316\u4e3aSchr\u00f6dinger\u6865\u91c7\u6837\u95ee\u9898\uff0c\u5e76\u5229\u7528Girsanov\u5b9a\u7406\u548c\u795e\u7ecf\u8fd1\u4f3c\uff08Fourier MLP\uff09\u6c42\u89e3\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u57282\u81f31,247\u7ef4\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u572815.9k\u53c2\u6570\u6a21\u578b\u4e2d\u63a2\u7d22\u9ad8\u7ef4\u7a7a\u95f4\u65f6\u5b58\u5728\u56f0\u96be\u3002", "motivation": "\u63a2\u7d22\u795e\u7ecf\u6269\u6563\u8fc7\u7a0b\u5728\u5168\u5c40\u4f18\u5316\u4e2d\u7684\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5982\u4f55\u901a\u8fc7Boltzmann\u5206\u5e03\u548cSchr\u00f6dinger\u6865\u91c7\u6837\u95ee\u9898\u6765\u4f18\u5316\u9ad8\u7ef4\u4efb\u52a1\u3002", "method": "\u4f7f\u7528Boltzmann\u5206\u5e03\u5c06\u4f18\u5316\u95ee\u9898\u8f6c\u5316\u4e3aSchr\u00f6dinger\u6865\u91c7\u6837\u95ee\u9898\uff0c\u5e94\u7528Girsanov\u5b9a\u7406\u548c\u795e\u7ecf\u8fd1\u4f3c\uff08Fourier MLP\uff09\u6c42\u89e3\u3002", "result": "\u57282\u81f31,247\u7ef4\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u572815.9k\u53c2\u6570\u6a21\u578b\u4e2d\u63a2\u7d22\u9ad8\u7ef4\u7a7a\u95f4\u65f6\u8868\u73b0\u4e0d\u4f73\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u4f4e\u7ef4\u4efb\u52a1\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u5728\u9ad8\u7ef4\u73af\u5883\u4e2d\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\u4ee5\u9002\u5e94\u66f4\u590d\u6742\u7684\u4f18\u5316\u9700\u6c42\u3002"}}
{"id": "2506.06853", "pdf": "https://arxiv.org/pdf/2506.06853", "abs": "https://arxiv.org/abs/2506.06853", "authors": ["Ilya Kaufman Sirot", "Omri Azencot"], "title": "Curvature Enhanced Data Augmentation for Regression", "categories": ["cs.LG", "stat.ML"], "comment": "Accepted to ICML 2025", "summary": "Deep learning models with a large number of parameters, often referred to as\nover-parameterized models, have achieved exceptional performance across various\ntasks. Despite concerns about overfitting, these models frequently generalize\nwell to unseen data, thanks to effective regularization techniques, with data\naugmentation being among the most widely used. While data augmentation has\nshown great success in classification tasks using label-preserving\ntransformations, its application in regression problems has received less\nattention. Recently, a novel \\emph{manifold learning} approach for generating\nsynthetic data was proposed, utilizing a first-order approximation of the data\nmanifold. Building on this foundation, we present a theoretical framework and\npractical tools for approximating and sampling general data manifolds.\nFurthermore, we introduce the Curvature-Enhanced Manifold Sampling (CEMS)\nmethod for regression tasks. CEMS leverages a second-order representation of\nthe data manifold to enable efficient sampling and reconstruction of new data\npoints. Extensive evaluations across multiple datasets and comparisons with\nstate-of-the-art methods demonstrate that CEMS delivers superior performance in\nboth in-distribution and out-of-distribution scenarios, while introducing only\nminimal computational overhead. Code is available at\nhttps://github.com/azencot-group/CEMS.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e8c\u9636\u6570\u636e\u6d41\u5f62\u8868\u793a\u7684Curvature-Enhanced Manifold Sampling (CEMS)\u65b9\u6cd5\uff0c\u7528\u4e8e\u56de\u5f52\u4efb\u52a1\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u6570\u636e\u589e\u5f3a\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u56de\u5f52\u95ee\u9898\u4e2d\u5e94\u7528\u8f83\u5c11\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u751f\u6210\u5408\u6210\u6570\u636e\u4ee5\u63d0\u5347\u56de\u5f52\u4efb\u52a1\u7684\u6027\u80fd\u3002", "method": "\u5229\u7528\u4e8c\u9636\u6570\u636e\u6d41\u5f62\u8868\u793a\uff0c\u63d0\u51faCEMS\u65b9\u6cd5\uff0c\u901a\u8fc7\u9ad8\u6548\u91c7\u6837\u548c\u91cd\u5efa\u65b0\u6570\u636e\u70b9\u6765\u589e\u5f3a\u56de\u5f52\u4efb\u52a1\u7684\u6027\u80fd\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0cCEMS\u5728\u5206\u5e03\u5185\u548c\u5206\u5e03\u5916\u573a\u666f\u4e0b\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u8ba1\u7b97\u5f00\u9500\u6781\u5c0f\u3002", "conclusion": "CEMS\u4e3a\u56de\u5f52\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2506.06858", "pdf": "https://arxiv.org/pdf/2506.06858", "abs": "https://arxiv.org/abs/2506.06858", "authors": ["Ziwei Li", "Yuhan Duan", "Tianyu Xiong", "Yi-Tang Chen", "Wei-Lun Chao", "Han-Wei Shen"], "title": "High-Fidelity Scientific Simulation Surrogates via Adaptive Implicit Neural Representations", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Effective surrogate models are critical for accelerating scientific\nsimulations. Implicit neural representations (INRs) offer a compact and\ncontinuous framework for modeling spatially structured data, but they often\nstruggle with complex scientific fields exhibiting localized, high-frequency\nvariations. Recent approaches address this by introducing additional features\nalong rigid geometric structures (e.g., grids), but at the cost of flexibility\nand increased model size. In this paper, we propose a simple yet effective\nalternative: Feature-Adaptive INR (FA-INR). FA-INR leverages cross-attention to\nan augmented memory bank to learn flexible feature representations, enabling\nadaptive allocation of model capacity based on data characteristics, rather\nthan rigid structural assumptions. To further improve scalability, we introduce\na coordinate-guided mixture of experts (MoE) that enhances the specialization\nand efficiency of feature representations. Experiments on three large-scale\nensemble simulation datasets show that FA-INR achieves state-of-the-art\nfidelity while significantly reducing model size, establishing a new trade-off\nfrontier between accuracy and compactness for INR-based surrogates.", "AI": {"tldr": "FA-INR\u662f\u4e00\u79cd\u57fa\u4e8e\u4ea4\u53c9\u6ce8\u610f\u529b\u548c\u8bb0\u5fc6\u5e93\u7684\u9690\u5f0f\u795e\u7ecf\u8868\u793a\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u7279\u5f81\u5206\u914d\u548c\u4e13\u5bb6\u6df7\u5408\u63d0\u5347\u6a21\u578b\u6548\u7387\u548c\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709\u9690\u5f0f\u795e\u7ecf\u8868\u793a\uff08INR\uff09\u5728\u5904\u7406\u590d\u6742\u79d1\u5b66\u6570\u636e\u65f6\uff0c\u5e38\u56e0\u5c40\u90e8\u9ad8\u9891\u53d8\u5316\u800c\u8868\u73b0\u4e0d\u4f73\uff0c\u4e14\u4f20\u7edf\u65b9\u6cd5\u5f15\u5165\u521a\u6027\u7ed3\u6784\u7279\u5f81\u4f1a\u589e\u52a0\u6a21\u578b\u590d\u6742\u5ea6\u3002", "method": "\u63d0\u51faFA-INR\uff0c\u5229\u7528\u4ea4\u53c9\u6ce8\u610f\u529b\u4ece\u8bb0\u5fc6\u5e93\u5b66\u4e60\u81ea\u9002\u5e94\u7279\u5f81\u8868\u793a\uff0c\u5e76\u7ed3\u5408\u5750\u6807\u5f15\u5bfc\u7684\u4e13\u5bb6\u6df7\u5408\uff08MoE\uff09\u63d0\u5347\u53ef\u6269\u5c55\u6027\u3002", "result": "\u5728\u4e09\u4e2a\u5927\u89c4\u6a21\u4eff\u771f\u6570\u636e\u96c6\u4e0a\uff0cFA-INR\u5728\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c0f\u6a21\u578b\u89c4\u6a21\uff0c\u5b9e\u73b0\u4e86\u7cbe\u5ea6\u4e0e\u7d27\u51d1\u6027\u7684\u65b0\u5e73\u8861\u3002", "conclusion": "FA-INR\u4e3a\u57fa\u4e8eINR\u7684\u4ee3\u7406\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u7075\u6d3b\u7684\u65b0\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u590d\u6742\u79d1\u5b66\u6570\u636e\u7684\u5efa\u6a21\u3002"}}
{"id": "2506.06861", "pdf": "https://arxiv.org/pdf/2506.06861", "abs": "https://arxiv.org/abs/2506.06861", "authors": ["Xizhi Tian", "Meng Ding", "Touming Tao", "Zihang Xiang", "Di Wang"], "title": "Differentially Private Sparse Linear Regression with Heavy-tailed Responses", "categories": ["cs.LG", "cs.CR"], "comment": "Accepted at ECML 2025", "summary": "As a fundamental problem in machine learning and differential privacy (DP),\nDP linear regression has been extensively studied. However, most existing\nmethods focus primarily on either regular data distributions or low-dimensional\ncases with irregular data. To address these limitations, this paper provides a\ncomprehensive study of DP sparse linear regression with heavy-tailed responses\nin high-dimensional settings. In the first part, we introduce the DP-IHT-H\nmethod, which leverages the Huber loss and private iterative hard thresholding\nto achieve an estimation error bound of \\(\n  \\tilde{O}\\biggl(\n  s^{* \\frac{1 }{2}}\n  \\cdot \\biggl(\\frac{\\log d}{n}\\biggr)^{\\frac{\\zeta}{1 + \\zeta}}\n  +\n  s^{* \\frac{1 + 2\\zeta}{2 + 2\\zeta}}\n  \\cdot \\biggl(\\frac{\\log^2 d}{n \\varepsilon}\\biggr)^{\\frac{\\zeta}{1 + \\zeta}}\n  \\biggr) \\) under the $(\\varepsilon, \\delta)$-DP model, where $n$ is the\nsample size, $d$ is the dimensionality, $s^*$ is the sparsity of the parameter,\nand $\\zeta \\in (0, 1]$ characterizes the tail heaviness of the data. In the\nsecond part, we propose DP-IHT-L, which further improves the error bound under\nadditional assumptions on the response and achieves \\(\n  \\tilde{O}\\Bigl(\\frac{(s^*)^{3/2} \\log d}{n \\varepsilon}\\Bigr). \\) Compared to\nthe first result, this bound is independent of the tail parameter $\\zeta$.\nFinally, through experiments on synthetic and real-world datasets, we\ndemonstrate that our methods outperform standard DP algorithms designed for\n``regular'' data.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u9ad8\u7ef4\u8bbe\u7f6e\u4e0b\u5177\u6709\u91cd\u5c3e\u54cd\u5e94\u7684\u5dee\u5206\u9690\u79c1\u7a00\u758f\u7ebf\u6027\u56de\u5f52\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u65b9\u6cd5\uff08DP-IHT-H\u548cDP-IHT-L\uff09\uff0c\u5206\u522b\u5728\u65e0\u548c\u6709\u989d\u5916\u5047\u8bbe\u4e0b\u4f18\u5316\u4e86\u8bef\u5dee\u754c\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u5e38\u89c4\u6570\u636e\u5206\u5e03\u6216\u4f4e\u7ef4\u4e0d\u89c4\u5219\u6570\u636e\uff0c\u65e0\u6cd5\u6ee1\u8db3\u9ad8\u7ef4\u91cd\u5c3e\u6570\u636e\u7684\u9700\u6c42\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faDP-IHT-H\uff08\u57fa\u4e8eHuber\u635f\u5931\u548c\u79c1\u6709\u8fed\u4ee3\u786c\u9608\u503c\uff09\u548cDP-IHT-L\uff08\u5728\u989d\u5916\u5047\u8bbe\u4e0b\u8fdb\u4e00\u6b65\u4f18\u5316\uff09\uff0c\u5206\u522b\u9488\u5bf9\u4e0d\u540c\u6570\u636e\u7279\u6027\u3002", "result": "DP-IHT-H\u5728(\u03b5, \u03b4)-DP\u6a21\u578b\u4e0b\u8fbe\u5230\u7279\u5b9a\u8bef\u5dee\u754c\uff0cDP-IHT-L\u5728\u989d\u5916\u5047\u8bbe\u4e0b\u8fdb\u4e00\u6b65\u4f18\u5316\u8bef\u5dee\u754c\u3002\u5b9e\u9a8c\u8868\u660e\u65b9\u6cd5\u4f18\u4e8e\u5e38\u89c4DP\u7b97\u6cd5\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u9ad8\u7ef4\u91cd\u5c3e\u6570\u636e\u4e0b\u8868\u73b0\u4f18\u8d8a\uff0c\u6269\u5c55\u4e86\u5dee\u5206\u9690\u79c1\u7ebf\u6027\u56de\u5f52\u7684\u5e94\u7528\u8303\u56f4\u3002"}}
{"id": "2506.06866", "pdf": "https://arxiv.org/pdf/2506.06866", "abs": "https://arxiv.org/abs/2506.06866", "authors": ["Dongyeop Lee", "Kwanhee Lee", "Jinseok Chung", "Namhoon Lee"], "title": "SAFE: Finding Sparse and Flat Minima to Improve Pruning", "categories": ["cs.LG", "cs.AI"], "comment": "ICML 2025", "summary": "Sparsifying neural networks often suffers from seemingly inevitable\nperformance degradation, and it remains challenging to restore the original\nperformance despite much recent progress. Motivated by recent studies in robust\noptimization, we aim to tackle this problem by finding subnetworks that are\nboth sparse and flat at the same time. Specifically, we formulate pruning as a\nsparsity-constrained optimization problem where flatness is encouraged as an\nobjective. We solve it explicitly via an augmented Lagrange dual approach and\nextend it further by proposing a generalized projection operation, resulting in\nnovel pruning methods called SAFE and its extension, SAFE$^+$. Extensive\nevaluations on standard image classification and language modeling tasks reveal\nthat SAFE consistently yields sparse networks with improved generalization\nperformance, which compares competitively to well-established baselines. In\naddition, SAFE demonstrates resilience to noisy data, making it well-suited for\nreal-world conditions.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSAFE\u7684\u65b0\u526a\u679d\u65b9\u6cd5\uff0c\u901a\u8fc7\u540c\u65f6\u8ffd\u6c42\u7a00\u758f\u6027\u548c\u5e73\u5766\u6027\u6765\u6062\u590d\u795e\u7ecf\u7f51\u7edc\u6027\u80fd\uff0c\u5e76\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u7a00\u758f\u5316\u795e\u7ecf\u7f51\u7edc\u5e38\u4f34\u968f\u6027\u80fd\u4e0b\u964d\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u6062\u590d\u539f\u59cb\u6027\u80fd\u3002\u53d7\u9c81\u68d2\u4f18\u5316\u7814\u7a76\u542f\u53d1\uff0c\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u540c\u65f6\u4f18\u5316\u7a00\u758f\u6027\u548c\u5e73\u5766\u6027\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5c06\u526a\u679d\u95ee\u9898\u5efa\u6a21\u4e3a\u7a00\u758f\u6027\u7ea6\u675f\u7684\u4f18\u5316\u95ee\u9898\uff0c\u5e73\u5766\u6027\u4f5c\u4e3a\u76ee\u6807\u4e4b\u4e00\u3002\u91c7\u7528\u589e\u5f3a\u62c9\u683c\u6717\u65e5\u5bf9\u5076\u65b9\u6cd5\u6c42\u89e3\uff0c\u5e76\u6269\u5c55\u4e3a\u5e7f\u4e49\u6295\u5f71\u64cd\u4f5c\uff0c\u63d0\u51fa\u4e86SAFE\u53ca\u5176\u6269\u5c55SAFE$^+$\u3002", "result": "\u5728\u56fe\u50cf\u5206\u7c7b\u548c\u8bed\u8a00\u5efa\u6a21\u4efb\u52a1\u4e2d\uff0cSAFE\u751f\u6210\u7684\u7a00\u758f\u7f51\u7edc\u6cdb\u5316\u6027\u80fd\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e14\u5bf9\u566a\u58f0\u6570\u636e\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "SAFE\u65b9\u6cd5\u901a\u8fc7\u7ed3\u5408\u7a00\u758f\u6027\u548c\u5e73\u5766\u6027\uff0c\u6709\u6548\u63d0\u5347\u4e86\u526a\u679d\u7f51\u7edc\u7684\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u73b0\u5b9e\u573a\u666f\u3002"}}
{"id": "2506.06873", "pdf": "https://arxiv.org/pdf/2506.06873", "abs": "https://arxiv.org/abs/2506.06873", "authors": ["Armin Behnamnia", "Gholamali Aminian", "Alireza Aghaei", "Chengchun Shi", "Vincent Y. F. Tan", "Hamid R. Rabiee"], "title": "Log-Sum-Exponential Estimator for Off-Policy Evaluation and Learning", "categories": ["cs.LG", "stat.ML"], "comment": "Accepted as spotlight poster in ICML 2025", "summary": "Off-policy learning and evaluation leverage logged bandit feedback datasets,\nwhich contain context, action, propensity score, and feedback for each data\npoint. These scenarios face significant challenges due to high variance and\npoor performance with low-quality propensity scores and heavy-tailed reward\ndistributions. We address these issues by introducing a novel estimator based\non the log-sum-exponential (LSE) operator, which outperforms traditional\ninverse propensity score estimators. Our LSE estimator demonstrates variance\nreduction and robustness under heavy-tailed conditions. For off-policy\nevaluation, we derive upper bounds on the estimator's bias and variance. In the\noff-policy learning scenario, we establish bounds on the regret -- the\nperformance gap between our LSE estimator and the optimal policy -- assuming\nbounded $(1+\\epsilon)$-th moment of weighted reward. Notably, we achieve a\nconvergence rate of $O(n^{-\\epsilon/(1+ \\epsilon)})$ for the regret bounds,\nwhere $\\epsilon \\in [0,1]$ and $n$ is the size of logged bandit feedback\ndataset. Theoretical analysis is complemented by comprehensive empirical\nevaluations in both off-policy learning and evaluation scenarios, confirming\nthe practical advantages of our approach. The code for our estimator is\navailable at the following link:\nhttps://github.com/armin-behnamnia/lse-offpolicy-learning.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8elog-sum-exponential\uff08LSE\uff09\u7b97\u5b50\u7684\u65b0\u4f30\u8ba1\u5668\uff0c\u7528\u4e8e\u89e3\u51b3\u79bb\u7ebf\u5b66\u4e60\u548c\u8bc4\u4f30\u4e2d\u7684\u9ad8\u65b9\u5dee\u548c\u91cd\u5c3e\u5956\u52b1\u5206\u5e03\u95ee\u9898\uff0c\u5e76\u5728\u7406\u8bba\u548c\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u79bb\u7ebf\u5b66\u4e60\u548c\u8bc4\u4f30\u4e2d\uff0c\u4f20\u7edf\u9006\u503e\u5411\u5f97\u5206\u4f30\u8ba1\u5668\u5728\u9ad8\u65b9\u5dee\u548c\u4f4e\u8d28\u91cf\u503e\u5411\u5f97\u5206\u4e0b\u8868\u73b0\u4e0d\u4f73\uff0c\u4e14\u5bf9\u91cd\u5c3e\u5956\u52b1\u5206\u5e03\u654f\u611f\u3002", "method": "\u5f15\u5165LSE\u7b97\u5b50\u4f5c\u4e3a\u65b0\u4f30\u8ba1\u5668\uff0c\u63a8\u5bfc\u5176\u504f\u5dee\u548c\u65b9\u5dee\u4e0a\u754c\uff0c\u5e76\u5728\u79bb\u7ebf\u5b66\u4e60\u548c\u8bc4\u4f30\u573a\u666f\u4e2d\u5206\u6790\u5176\u6027\u80fd\u3002", "result": "LSE\u4f30\u8ba1\u5668\u5728\u65b9\u5dee\u51cf\u5c11\u548c\u91cd\u5c3e\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u9c81\u68d2\u6027\uff0c\u7406\u8bba\u5206\u6790\u663e\u793a\u5176\u9057\u61be\u754c\u9650\u6536\u655b\u901f\u5ea6\u4e3aO(n^(-\u03b5/(1+\u03b5)))\u3002", "conclusion": "LSE\u4f30\u8ba1\u5668\u5728\u7406\u8bba\u548c\u5b9e\u8df5\u4e2d\u5747\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u79bb\u7ebf\u5b66\u4e60\u548c\u8bc4\u4f30\u573a\u666f\u3002"}}
{"id": "2506.06884", "pdf": "https://arxiv.org/pdf/2506.06884", "abs": "https://arxiv.org/abs/2506.06884", "authors": ["Divya Jyoti Bajpai", "Manjesh Kumar Hanawal"], "title": "FREE: Fast and Robust Vision Language Models with Early Exits", "categories": ["cs.LG", "cs.CV"], "comment": "To appear at the Association of Computational Linguistics (ACL) 2025\n  Conference", "summary": "In recent years, Vision-Language Models (VLMs) have shown remarkable\nperformance improvements in Vision-Language tasks. However, their large size\nposes challenges for real-world applications where inference latency is a\nconcern. To tackle this issue, we propose employing Early Exit (EE) strategies\nin VLMs. However, training exit classifiers in VLMs is challenging,\nparticularly with limited labeled training data. To address this, we introduce\nFREE, an adversarial training approach within a GAN-based framework. Here, each\nexit consists of a transformer layer and a classifier. The transformer layer is\nadversarially trained to produce feature representations similar to the final\nlayer, while a feature classifier serves as the discriminator. Our method\nfocuses on performing input-adaptive inference that increases inference speed\nwith minimal drop in performance. Experimental results demonstrate the\neffectiveness of our approach in enhancing accuracy and model robustness by\nmitigating overthinking and the phenomenon of mid-crisis that we highlight. We\nexperimentally validate that our method speeds up the inference process by more\nthan 1.51x while retaining comparable performance. The source code is available\nat https://github.com/Div290/FREE.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFREE\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u6297\u8bad\u7ec3\u548cGAN\u6846\u67b6\u5728\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e2d\u5b9e\u73b0\u65e9\u671f\u9000\u51fa\u7b56\u7565\uff0c\u4ee5\u63d0\u9ad8\u63a8\u7406\u901f\u5ea6\u5e76\u4fdd\u6301\u6027\u80fd\u3002", "motivation": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u5728\u6027\u80fd\u63d0\u5347\u7684\u540c\u65f6\uff0c\u5176\u5927\u5c3a\u5bf8\u5bfc\u81f4\u63a8\u7406\u5ef6\u8fdf\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u91c7\u7528\u5bf9\u6297\u8bad\u7ec3\u65b9\u6cd5\uff08FREE\uff09\uff0c\u6bcf\u4e2a\u9000\u51fa\u70b9\u5305\u542b\u4e00\u4e2aTransformer\u5c42\u548c\u4e00\u4e2a\u5206\u7c7b\u5668\uff0c\u901a\u8fc7\u751f\u6210\u7c7b\u4f3c\u6700\u7ec8\u5c42\u7684\u7279\u5f81\u8868\u793a\u6765\u4f18\u5316\u63a8\u7406\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u5347\u8d85\u8fc71.51\u500d\uff0c\u5e76\u589e\u5f3a\u4e86\u6a21\u578b\u9c81\u68d2\u6027\u3002", "conclusion": "FREE\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86VLMs\u7684\u63a8\u7406\u5ef6\u8fdf\u95ee\u9898\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.06891", "pdf": "https://arxiv.org/pdf/2506.06891", "abs": "https://arxiv.org/abs/2506.06891", "authors": ["Paulius Sasnauskas", "Yi\u011fit Yal\u0131n", "Goran Radanovi\u0107"], "title": "Can In-Context Reinforcement Learning Recover From Reward Poisoning Attacks?", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "We study the corruption-robustness of in-context reinforcement learning\n(ICRL), focusing on the Decision-Pretrained Transformer (DPT, Lee et al.,\n2023). To address the challenge of reward poisoning attacks targeting the DPT,\nwe propose a novel adversarial training framework, called Adversarially Trained\nDecision-Pretrained Transformer (AT-DPT). Our method simultaneously trains an\nattacker to minimize the true reward of the DPT by poisoning environment\nrewards, and a DPT model to infer optimal actions from the poisoned data. We\nevaluate the effectiveness of our approach against standard bandit algorithms,\nincluding robust baselines designed to handle reward contamination. Our results\nshow that the proposed method significantly outperforms these baselines in\nbandit settings, under a learned attacker. We additionally evaluate AT-DPT on\nan adaptive attacker, and observe similar results. Furthermore, we extend our\nevaluation to the MDP setting, confirming that the robustness observed in\nbandit scenarios generalizes to more complex environments.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e0a\u4e0b\u6587\u5f3a\u5316\u5b66\u4e60\uff08ICRL\uff09\u7684\u6297\u5e72\u6270\u6027\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5bf9\u6297\u8bad\u7ec3\u6846\u67b6AT-DPT\uff0c\u4ee5\u5e94\u5bf9\u9488\u5bf9DPT\u7684\u5956\u52b1\u6295\u6bd2\u653b\u51fb\u3002", "motivation": "\u9488\u5bf9DPT\u5728\u5956\u52b1\u6295\u6bd2\u653b\u51fb\u4e0b\u7684\u8106\u5f31\u6027\uff0c\u7814\u7a76\u5982\u4f55\u63d0\u5347\u5176\u6297\u5e72\u6270\u80fd\u529b\u3002", "method": "\u63d0\u51faAT-DPT\u6846\u67b6\uff0c\u540c\u65f6\u8bad\u7ec3\u653b\u51fb\u8005\u548cDPT\u6a21\u578b\uff0c\u653b\u51fb\u8005\u901a\u8fc7\u6c61\u67d3\u73af\u5883\u5956\u52b1\u6765\u6700\u5c0f\u5316\u771f\u5b9e\u5956\u52b1\uff0cDPT\u5219\u4ece\u6c61\u67d3\u6570\u636e\u4e2d\u63a8\u65ad\u6700\u4f18\u52a8\u4f5c\u3002", "result": "\u5728\u5f3a\u76d7\u95ee\u9898\u548cMDP\u8bbe\u7f6e\u4e2d\uff0cAT-DPT\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u6297\u5e72\u6270\u80fd\u529b\u3002", "conclusion": "AT-DPT\u5728\u590d\u6742\u73af\u5883\u4e2d\u5c55\u73b0\u4e86\u826f\u597d\u7684\u6297\u5e72\u6270\u6027\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u5f3a\u76d7\u95ee\u9898\u4e2d\u7684\u9c81\u68d2\u6027\u53ef\u4ee5\u63a8\u5e7f\u5230\u66f4\u590d\u6742\u573a\u666f\u3002"}}
{"id": "2506.06895", "pdf": "https://arxiv.org/pdf/2506.06895", "abs": "https://arxiv.org/abs/2506.06895", "authors": ["Jihao Andreas Lin", "Sebastian Ament", "Maximilian Balandat", "David Eriksson", "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato", "Eytan Bakshy"], "title": "Scalable Gaussian Processes with Latent Kronecker Structure", "categories": ["cs.LG", "stat.ML"], "comment": "International Conference on Machine Learning 2025", "summary": "Applying Gaussian processes (GPs) to very large datasets remains a challenge\ndue to limited computational scalability. Matrix structures, such as the\nKronecker product, can accelerate operations significantly, but their\napplication commonly entails approximations or unrealistic assumptions. In\nparticular, the most common path to creating a Kronecker-structured kernel\nmatrix is by evaluating a product kernel on gridded inputs that can be\nexpressed as a Cartesian product. However, this structure is lost if any\nobservation is missing, breaking the Cartesian product structure, which\nfrequently occurs in real-world data such as time series. To address this\nlimitation, we propose leveraging latent Kronecker structure, by expressing the\nkernel matrix of observed values as the projection of a latent Kronecker\nproduct. In combination with iterative linear system solvers and pathwise\nconditioning, our method facilitates inference of exact GPs while requiring\nsubstantially fewer computational resources than standard iterative methods. We\ndemonstrate that our method outperforms state-of-the-art sparse and variational\nGPs on real-world datasets with up to five million examples, including\nrobotics, automated machine learning, and climate applications.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u6f5c\u5728Kronecker\u7ed3\u6784\u7684\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u9ad8\u65af\u8fc7\u7a0b\u5728\u5927\u6570\u636e\u96c6\u4e0a\u7684\u8ba1\u7b97\u6269\u5c55\u6027\u95ee\u9898\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u3002", "motivation": "\u9ad8\u65af\u8fc7\u7a0b\u5728\u5927\u6570\u636e\u96c6\u4e0a\u7684\u8ba1\u7b97\u6269\u5c55\u6027\u53d7\u9650\uff0c\u73b0\u6709\u65b9\u6cd5\uff08\u5982Kronecker\u79ef\uff09\u5e38\u9700\u8fd1\u4f3c\u6216\u4e0d\u73b0\u5b9e\u5047\u8bbe\uff0c\u4e14\u7f3a\u5931\u6570\u636e\u4f1a\u7834\u574f\u7ed3\u6784\u3002", "method": "\u901a\u8fc7\u5c06\u89c2\u6d4b\u503c\u7684\u6838\u77e9\u9635\u8868\u793a\u4e3a\u6f5c\u5728Kronecker\u79ef\u7684\u6295\u5f71\uff0c\u7ed3\u5408\u8fed\u4ee3\u7ebf\u6027\u7cfb\u7edf\u6c42\u89e3\u5668\u548c\u8def\u5f84\u6761\u4ef6\uff0c\u5b9e\u73b0\u7cbe\u786e\u9ad8\u65af\u8fc7\u7a0b\u63a8\u65ad\u3002", "result": "\u65b9\u6cd5\u5728\u591a\u8fbe\u4e94\u767e\u4e07\u6837\u672c\u7684\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u7a00\u758f\u548c\u53d8\u5206\u9ad8\u65af\u8fc7\u7a0b\uff0c\u9002\u7528\u4e8e\u673a\u5668\u4eba\u3001\u81ea\u52a8\u673a\u5668\u5b66\u4e60\u548c\u6c14\u5019\u5e94\u7528\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u9ad8\u65af\u8fc7\u7a0b\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u7684\u8ba1\u7b97\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u7cbe\u786e\u6027\u3002"}}
{"id": "2506.06907", "pdf": "https://arxiv.org/pdf/2506.06907", "abs": "https://arxiv.org/abs/2506.06907", "authors": ["Fred Xu", "Thomas Markovich"], "title": "Uncertainty Estimation on Graphs with Structure Informed Stochastic Partial Differential Equations", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph Neural Networks have achieved impressive results across diverse network\nmodeling tasks, but accurately estimating uncertainty on graphs remains\ndifficult, especially under distributional shifts. Unlike traditional\nuncertainty estimation, graph-based uncertainty must account for randomness\narising from both the graph's structure and its label distribution, which adds\ncomplexity. In this paper, making an analogy between the evolution of a\nstochastic partial differential equation (SPDE) driven by Matern Gaussian\nProcess and message passing using GNN layers, we present a principled way to\ndesign a novel message passing scheme that incorporates spatial-temporal noises\nmotivated by the Gaussian Process approach to SPDE. Our method simultaneously\ncaptures uncertainty across space and time and allows explicit control over the\ncovariance kernel smoothness, thereby enhancing uncertainty estimates on graphs\nwith both low and high label informativeness. Our extensive experiments on\nOut-of-Distribution (OOD) detection on graph datasets with varying label\ninformativeness demonstrate the soundness and superiority of our model to\nexisting approaches.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9ad8\u65af\u8fc7\u7a0b\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u6d88\u606f\u4f20\u9012\u65b9\u6cd5\uff0c\u7528\u4e8e\u6539\u8fdb\u56fe\u6570\u636e\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u5c24\u5176\u5728\u5206\u5e03\u504f\u79fb\u60c5\u51b5\u4e0b\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u4f20\u7edf\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u56fe\u6570\u636e\u4e2d\u7ed3\u6784\u548c\u6807\u7b7e\u5206\u5e03\u5e26\u6765\u7684\u968f\u673a\u6027\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u5168\u9762\u7684\u65b9\u6cd5\u3002", "method": "\u5c06\u968f\u673a\u504f\u5fae\u5206\u65b9\u7a0b\uff08SPDE\uff09\u4e0e\u9ad8\u65af\u8fc7\u7a0b\u7c7b\u6bd4\uff0c\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u7684\u6d88\u606f\u4f20\u9012\u65b9\u6848\uff0c\u7ed3\u5408\u65f6\u7a7a\u566a\u58f0\u3002", "result": "\u5728\u5206\u5e03\u5916\u68c0\u6d4b\u4efb\u52a1\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u79cd\u6807\u7b7e\u4fe1\u606f\u91cf\u7684\u56fe\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u63a7\u5236\u534f\u65b9\u5dee\u6838\u5e73\u6ed1\u5ea6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u56fe\u6570\u636e\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2506.06917", "pdf": "https://arxiv.org/pdf/2506.06917", "abs": "https://arxiv.org/abs/2506.06917", "authors": ["Shangjie Du", "Hui Wei", "Dong Yoon Lee", "Zhizhang Hu", "Shijia Pan"], "title": "Graph-Based Physics-Guided Urban PM2.5 Air Quality Imputation with Constrained Monitoring Data", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by ACM Transactions on Sensor Networks (TOSN) 2025", "summary": "This work introduces GraPhy, a graph-based, physics-guided learning framework\nfor high-resolution and accurate air quality modeling in urban areas with\nlimited monitoring data. Fine-grained air quality monitoring information is\nessential for reducing public exposure to pollutants. However, monitoring\nnetworks are often sparse in socioeconomically disadvantaged regions, limiting\nthe accuracy and resolution of air quality modeling. To address this, we\npropose a physics-guided graph neural network architecture called GraPhy with\nlayers and edge features designed specifically for low-resolution monitoring\ndata. Experiments using data from California's socioeconomically disadvantaged\nSan Joaquin Valley show that GraPhy achieves the overall best performance\nevaluated by mean squared error (MSE), mean absolute error (MAE), and R-square\nvalue (R2), improving the performance by 9%-56% compared to various baseline\nmodels. Moreover, GraPhy consistently outperforms baselines across different\nspatial heterogeneity levels, demonstrating the effectiveness of our model\ndesign.", "AI": {"tldr": "GraPhy\u662f\u4e00\u79cd\u57fa\u4e8e\u56fe\u7684\u7269\u7406\u5f15\u5bfc\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u76d1\u6d4b\u6570\u636e\u6709\u9650\u7684\u57ce\u533a\u8fdb\u884c\u9ad8\u5206\u8fa8\u7387\u3001\u51c6\u786e\u7684\u7a7a\u6c14\u8d28\u91cf\u5efa\u6a21\u3002", "motivation": "\u7ec6\u7c92\u5ea6\u7a7a\u6c14\u8d28\u91cf\u76d1\u6d4b\u5bf9\u51cf\u5c11\u516c\u4f17\u6c61\u67d3\u7269\u66b4\u9732\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u793e\u4f1a\u7ecf\u6d4e\u5f31\u52bf\u5730\u533a\u76d1\u6d4b\u7f51\u7edc\u7a00\u758f\uff0c\u9650\u5236\u4e86\u5efa\u6a21\u7684\u51c6\u786e\u6027\u548c\u5206\u8fa8\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7269\u7406\u5f15\u5bfc\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u67b6\u6784GraPhy\uff0c\u4e13\u4e3a\u4f4e\u5206\u8fa8\u7387\u76d1\u6d4b\u6570\u636e\u8bbe\u8ba1\uff0c\u5305\u542b\u7279\u5b9a\u5c42\u548c\u8fb9\u7279\u5f81\u3002", "result": "\u5728\u52a0\u5dde\u5723\u534e\u91d1\u8c37\u7684\u5b9e\u9a8c\u663e\u793a\uff0cGraPhy\u5728MSE\u3001MAE\u548cR2\u6307\u6807\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u6027\u80fd\u63d0\u53479%-56%\u3002", "conclusion": "GraPhy\u5728\u4e0d\u540c\u7a7a\u95f4\u5f02\u8d28\u6027\u6c34\u5e73\u4e0b\u5747\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u9a8c\u8bc1\u4e86\u5176\u8bbe\u8ba1\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2506.06926", "pdf": "https://arxiv.org/pdf/2506.06926", "abs": "https://arxiv.org/abs/2506.06926", "authors": ["Wei Min Loh", "Jiaqi Shang", "Pascal Poupart"], "title": "Basis Transformers for Multi-Task Tabular Regression", "categories": ["cs.LG"], "comment": null, "summary": "Dealing with tabular data is challenging due to partial information, noise,\nand heterogeneous structure. Existing techniques often struggle to\nsimultaneously address key aspects of tabular data such as textual information,\na variable number of columns, and unseen data without metadata besides column\nnames. We propose a novel architecture, \\textit{basis transformers},\nspecifically designed to tackle these challenges while respecting inherent\ninvariances in tabular data, including hierarchical structure and the\nrepresentation of numeric values. We evaluate our design on a multi-task\ntabular regression benchmark, achieving an improvement of 0.338 in the median\n$R^2$ score and the lowest standard deviation across 34 tasks from the\nOpenML-CTR23 benchmark. Furthermore, our model has five times fewer parameters\nthan the best-performing baseline and surpasses pretrained large language model\nbaselines -- even when initialized from randomized weights.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u57fa\u7840\u53d8\u6362\u5668\u201d\u7684\u65b0\u67b6\u6784\uff0c\u7528\u4e8e\u89e3\u51b3\u8868\u683c\u6570\u636e\u4e2d\u7684\u90e8\u5206\u4fe1\u606f\u3001\u566a\u58f0\u548c\u5f02\u6784\u7ed3\u6784\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u4efb\u52a1\u8868\u683c\u56de\u5f52\u6027\u80fd\u3002", "motivation": "\u5904\u7406\u8868\u683c\u6570\u636e\u65f6\uff0c\u73b0\u6709\u6280\u672f\u96be\u4ee5\u540c\u65f6\u5904\u7406\u6587\u672c\u4fe1\u606f\u3001\u53ef\u53d8\u5217\u6570\u548c\u65e0\u5143\u6570\u636e\u7b49\u95ee\u9898\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u65b9\u6cd5\u3002", "method": "\u8bbe\u8ba1\u4e86\u201c\u57fa\u7840\u53d8\u6362\u5668\u201d\u67b6\u6784\uff0c\u8003\u8651\u4e86\u8868\u683c\u6570\u636e\u7684\u56fa\u6709\u4e0d\u53d8\u6027\uff08\u5982\u5c42\u6b21\u7ed3\u6784\u548c\u6570\u503c\u8868\u793a\uff09\u3002", "result": "\u5728OpenML-CTR23\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4e2d\u4f4d\u6570R\u00b2\u5f97\u5206\u63d0\u9ad8\u4e860.338\uff0c\u53c2\u6570\u6570\u91cf\u6bd4\u6700\u4f73\u57fa\u7ebf\u5c11\u4e94\u500d\uff0c\u4e14\u4f18\u4e8e\u9884\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002", "conclusion": "\u57fa\u7840\u53d8\u6362\u5668\u5728\u8868\u683c\u6570\u636e\u5904\u7406\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5177\u6709\u9ad8\u6548\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2506.06933", "pdf": "https://arxiv.org/pdf/2506.06933", "abs": "https://arxiv.org/abs/2506.06933", "authors": ["Mahdi Salmani", "Alireza Abdollahpoorrostam", "Seyed-Mohsen Moosavi-Dezfooli"], "title": "Rewriting the Budget: A General Framework for Black-Box Attacks Under Cost Asymmetry", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.CV"], "comment": null, "summary": "Traditional decision-based black-box adversarial attacks on image classifiers\naim to generate adversarial examples by slightly modifying input images while\nkeeping the number of queries low, where each query involves sending an input\nto the model and observing its output. Most existing methods assume that all\nqueries have equal cost. However, in practice, queries may incur asymmetric\ncosts; for example, in content moderation systems, certain output classes may\ntrigger additional review, enforcement, or penalties, making them more costly\nthan others. While prior work has considered such asymmetric cost settings,\neffective algorithms for this scenario remain underdeveloped. In this paper, we\npropose a general framework for decision-based attacks under asymmetric query\ncosts, which we refer to as asymmetric black-box attacks. We modify two core\ncomponents of existing attacks: the search strategy and the gradient estimation\nprocess. Specifically, we propose Asymmetric Search (AS), a more conservative\nvariant of binary search that reduces reliance on high-cost queries, and\nAsymmetric Gradient Estimation (AGREST), which shifts the sampling distribution\nto favor low-cost queries. We design efficient algorithms that minimize total\nattack cost by balancing different query types, in contrast to earlier methods\nsuch as stealthy attacks that focus only on limiting expensive (high-cost)\nqueries. Our method can be integrated into a range of existing black-box\nattacks with minimal changes. We perform both theoretical analysis and\nempirical evaluation on standard image classification benchmarks. Across\nvarious cost regimes, our method consistently achieves lower total query cost\nand smaller perturbations than existing approaches, with improvements of up to\n40% in some settings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u56fe\u50cf\u5206\u7c7b\u5668\u7684\u975e\u5bf9\u79f0\u9ed1\u76d2\u653b\u51fb\u6846\u67b6\uff0c\u901a\u8fc7\u4f18\u5316\u641c\u7d22\u7b56\u7565\u548c\u68af\u5ea6\u4f30\u8ba1\u8fc7\u7a0b\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u653b\u51fb\u7684\u603b\u67e5\u8be2\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5047\u8bbe\u6240\u6709\u67e5\u8be2\u6210\u672c\u76f8\u540c\uff0c\u4f46\u5b9e\u9645\u4e2d\u67d0\u4e9b\u67e5\u8be2\u53ef\u80fd\u6210\u672c\u66f4\u9ad8\uff08\u5982\u89e6\u53d1\u989d\u5916\u5ba1\u67e5\u7684\u7c7b\u522b\uff09\u3002\u9488\u5bf9\u8fd9\u79cd\u975e\u5bf9\u79f0\u6210\u672c\u573a\u666f\uff0c\u73b0\u6709\u7b97\u6cd5\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u975e\u5bf9\u79f0\u641c\u7d22\uff08AS\uff09\u548c\u975e\u5bf9\u79f0\u68af\u5ea6\u4f30\u8ba1\uff08AGREST\uff09\uff0c\u51cf\u5c11\u5bf9\u9ad8\u6210\u672c\u67e5\u8be2\u7684\u4f9d\u8d56\uff0c\u5e76\u901a\u8fc7\u91c7\u6837\u5206\u5e03\u4f18\u5316\u964d\u4f4e\u6210\u672c\u3002", "result": "\u5728\u591a\u79cd\u6210\u672c\u8bbe\u7f6e\u4e0b\uff0c\u8be5\u65b9\u6cd5\u603b\u67e5\u8be2\u6210\u672c\u548c\u6270\u52a8\u5e45\u5ea6\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u67d0\u4e9b\u573a\u666f\u4e0b\u63d0\u5347\u8fbe40%\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u6709\u6548\u964d\u4f4e\u975e\u5bf9\u79f0\u67e5\u8be2\u6210\u672c\uff0c\u4e14\u6613\u4e8e\u96c6\u6210\u5230\u73b0\u6709\u9ed1\u76d2\u653b\u51fb\u65b9\u6cd5\u4e2d\u3002"}}
{"id": "2506.06940", "pdf": "https://arxiv.org/pdf/2506.06940", "abs": "https://arxiv.org/abs/2506.06940", "authors": ["Geonhui Yoo", "Minhak Song", "Chulhee Yun"], "title": "Understanding Sharpness Dynamics in NN Training with a Minimalist Example: The Effects of Dataset Difficulty, Depth, Stochasticity, and More", "categories": ["cs.LG"], "comment": "ICML 2025", "summary": "When training deep neural networks with gradient descent, sharpness often\nincreases -- a phenomenon known as progressive sharpening -- before saturating\nat the edge of stability. Although commonly observed in practice, the\nunderlying mechanisms behind progressive sharpening remain poorly understood.\nIn this work, we study this phenomenon using a minimalist model: a deep linear\nnetwork with a single neuron per layer. We show that this simple model\neffectively captures the sharpness dynamics observed in recent empirical\nstudies, offering a simple testbed to better understand neural network\ntraining. Moreover, we theoretically analyze how dataset properties, network\ndepth, stochasticity of optimizers, and step size affect the degree of\nprogressive sharpening in the minimalist model. We then empirically demonstrate\nhow these theoretical insights extend to practical scenarios. This study offers\na deeper understanding of sharpness dynamics in neural network training,\nhighlighting the interplay between depth, training data, and optimizers.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\u68af\u5ea6\u4e0b\u964d\u5bfc\u81f4\u7684\u6e10\u8fdb\u9510\u5316\u73b0\u8c61\uff0c\u901a\u8fc7\u7b80\u5316\u6a21\u578b\uff08\u6df1\u5ea6\u7ebf\u6027\u7f51\u7edc\uff09\u5206\u6790\u5176\u673a\u5236\uff0c\u5e76\u63a2\u8ba8\u4e86\u6570\u636e\u96c6\u3001\u7f51\u7edc\u6df1\u5ea6\u3001\u4f18\u5316\u5668\u968f\u673a\u6027\u548c\u6b65\u957f\u7684\u5f71\u54cd\u3002", "motivation": "\u6e10\u8fdb\u9510\u5316\u73b0\u8c61\u5728\u5b9e\u8df5\u4e2d\u5e38\u89c1\uff0c\u4f46\u5176\u673a\u5236\u5c1a\u4e0d\u660e\u786e\uff0c\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u7b80\u5316\u6a21\u578b\u63ed\u793a\u5176\u80cc\u540e\u7684\u539f\u7406\u3002", "method": "\u4f7f\u7528\u5355\u795e\u7ecf\u5143\u6bcf\u5c42\u7684\u6df1\u5ea6\u7ebf\u6027\u7f51\u7edc\u4f5c\u4e3a\u7b80\u5316\u6a21\u578b\uff0c\u5206\u6790\u5176\u9510\u5316\u52a8\u6001\uff0c\u5e76\u7406\u8bba\u63a2\u8ba8\u6570\u636e\u96c6\u3001\u7f51\u7edc\u6df1\u5ea6\u3001\u4f18\u5316\u5668\u548c\u6b65\u957f\u7684\u5f71\u54cd\u3002", "result": "\u7b80\u5316\u6a21\u578b\u6210\u529f\u6355\u6349\u4e86\u5b9e\u9645\u89c2\u5bdf\u5230\u7684\u9510\u5316\u52a8\u6001\uff0c\u7406\u8bba\u5206\u6790\u63ed\u793a\u4e86\u8fd9\u4e9b\u56e0\u7d20\u5bf9\u6e10\u8fdb\u9510\u5316\u7684\u5f71\u54cd\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u679c\u7684\u666e\u9002\u6027\u3002", "conclusion": "\u7814\u7a76\u6df1\u5316\u4e86\u5bf9\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\u9510\u5316\u52a8\u6001\u7684\u7406\u89e3\uff0c\u5f3a\u8c03\u4e86\u6df1\u5ea6\u3001\u8bad\u7ec3\u6570\u636e\u548c\u4f18\u5316\u5668\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u3002"}}
{"id": "2506.06954", "pdf": "https://arxiv.org/pdf/2506.06954", "abs": "https://arxiv.org/abs/2506.06954", "authors": ["Clinton Enwerem", "Aniruddh G. Puranic", "John S. Baras", "Calin Belta"], "title": "Safety-Aware Reinforcement Learning for Control via Risk-Sensitive Action-Value Iteration and Quantile Regression", "categories": ["cs.LG", "cs.RO"], "comment": "13 pages, 4 figures. Submission under review", "summary": "Mainstream approximate action-value iteration reinforcement learning (RL)\nalgorithms suffer from overestimation bias, leading to suboptimal policies in\nhigh-variance stochastic environments. Quantile-based action-value iteration\nmethods reduce this bias by learning a distribution of the expected cost-to-go\nusing quantile regression. However, ensuring that the learned policy satisfies\nsafety constraints remains a challenge when these constraints are not\nexplicitly integrated into the RL framework. Existing methods often require\ncomplex neural architectures or manual tradeoffs due to combined cost\nfunctions. To address this, we propose a risk-regularized quantile-based\nalgorithm integrating Conditional Value-at-Risk (CVaR) to enforce safety\nwithout complex architectures. We also provide theoretical guarantees on the\ncontraction properties of the risk-sensitive distributional Bellman operator in\nWasserstein space, ensuring convergence to a unique cost distribution.\nSimulations of a mobile robot in a dynamic reach-avoid task show that our\napproach leads to more goal successes, fewer collisions, and better\nsafety-performance trade-offs compared to risk-neutral methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5206\u4f4d\u6570\u548cCVaR\u7684\u98ce\u9669\u6b63\u5219\u5316\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u5b89\u5168\u7ea6\u675f\u4e0b\u7684\u8fc7\u4f30\u8ba1\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u4f20\u7edf\u8fd1\u4f3c\u52a8\u4f5c\u503c\u8fed\u4ee3\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5728\u9ad8\u65b9\u5dee\u968f\u673a\u73af\u5883\u4e2d\u5b58\u5728\u8fc7\u4f30\u8ba1\u504f\u5dee\uff0c\u5bfc\u81f4\u7b56\u7565\u6b21\u4f18\uff0c\u4e14\u96be\u4ee5\u6ee1\u8db3\u5b89\u5168\u7ea6\u675f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5206\u4f4d\u6570\u56de\u5f52\u548cCVaR\u7684\u98ce\u9669\u6b63\u5219\u5316\u7b97\u6cd5\uff0c\u65e0\u9700\u590d\u6742\u67b6\u6784\u5373\u53ef\u5b9e\u73b0\u5b89\u5168\u7ea6\u675f\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u4e86\u98ce\u9669\u654f\u611f\u5206\u5e03Bellman\u7b97\u5b50\u7684\u6536\u655b\u6027\uff0c\u5b9e\u9a8c\u663e\u793a\u5728\u52a8\u6001\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u76ee\u6807\u8fbe\u6210\u7387\u548c\u66f4\u5c11\u78b0\u649e\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u5b89\u5168\u6027\u548c\u6027\u80fd\u4e4b\u95f4\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u5e73\u8861\uff0c\u4f18\u4e8e\u98ce\u9669\u4e2d\u6027\u65b9\u6cd5\u3002"}}
{"id": "2506.06977", "pdf": "https://arxiv.org/pdf/2506.06977", "abs": "https://arxiv.org/abs/2506.06977", "authors": ["Pengfei Hu", "Xiaoxue Han", "Fei Wang", "Yue Ning"], "title": "UdonCare: Hierarchy Pruning for Unseen Domain Discovery in Predictive Healthcare", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Domain generalization has become a critical challenge in clinical prediction,\nwhere patient cohorts often exhibit shifting data distributions that degrade\nmodel performance. Typical domain generalization approaches struggle in\nreal-world healthcare settings for two main reasons: (1) patient-specific\ndomain labels are typically unavailable, making domain discovery especially\ndifficult; (2) purely data-driven approaches overlook key clinical insights,\nleading to a gap in medical knowledge integration. To address these problems,\nwe leverage hierarchical medical ontologies like the ICD-9-CM hierarchy to\ngroup diseases into higher-level categories and discover more flexible latent\ndomains. In this paper, we introduce UdonCare, a hierarchy-guided framework\nthat iteratively prunes fine-grained domains, encodes these refined domains,\nand applies a Siamese-type inference mechanism to separate domain-related\nsignals from patient-level features. Experimental results on clinical datasets\n(MIMIC-III and MIMIC-IV) show that the proposed model achieves higher\nperformance compared to other domain generalization baselines when substantial\ndomain gaps presents, highlighting the untapped potential of medical knowledge\nfor enhancing domain generalization in practical healthcare applications.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faUdonCare\u6846\u67b6\uff0c\u5229\u7528\u533b\u5b66\u672c\u4f53\u8bba\uff08\u5982ICD-9-CM\uff09\u53d1\u73b0\u6f5c\u5728\u9886\u57df\uff0c\u7ed3\u5408\u5c42\u6b21\u5316\u65b9\u6cd5\u63d0\u5347\u4e34\u5e8a\u9884\u6d4b\u7684\u9886\u57df\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3\u4e34\u5e8a\u9884\u6d4b\u4e2d\u6570\u636e\u5206\u5e03\u53d8\u5316\u5bfc\u81f4\u7684\u6a21\u578b\u6027\u80fd\u4e0b\u964d\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u56e0\u7f3a\u4e4f\u9886\u57df\u6807\u7b7e\u548c\u5ffd\u89c6\u533b\u5b66\u77e5\u8bc6\u800c\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u63d0\u51faUdonCare\u6846\u67b6\uff0c\u901a\u8fc7\u5c42\u6b21\u5316\u533b\u5b66\u672c\u4f53\u8bba\u5206\u7ec4\u75be\u75c5\uff0c\u8fed\u4ee3\u4fee\u526a\u7ec6\u7c92\u5ea6\u9886\u57df\uff0c\u5e76\u91c7\u7528Siamese\u578b\u63a8\u7406\u673a\u5236\u5206\u79bb\u9886\u57df\u4fe1\u53f7\u4e0e\u60a3\u8005\u7279\u5f81\u3002", "result": "\u5728MIMIC-III\u548cMIMIC-IV\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u9886\u57df\u6cdb\u5316\u57fa\u7ebf\uff0c\u5c24\u5176\u5728\u9886\u57df\u5dee\u5f02\u663e\u8457\u65f6\u3002", "conclusion": "UdonCare\u5c55\u793a\u4e86\u533b\u5b66\u77e5\u8bc6\u5728\u63d0\u5347\u9886\u57df\u6cdb\u5316\u80fd\u529b\u4e2d\u7684\u6f5c\u529b\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u533b\u7597\u5e94\u7528\u3002"}}
{"id": "2506.06978", "pdf": "https://arxiv.org/pdf/2506.06978", "abs": "https://arxiv.org/abs/2506.06978", "authors": ["Zitian Li", "Wang Chi Cheung"], "title": "Near Optimal Non-asymptotic Sample Complexity of 1-Identification", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Motivated by an open direction in existing literature, we study the\n1-identification problem, a fundamental multi-armed bandit formulation on pure\nexploration. The goal is to determine whether there exists an arm whose mean\nreward is at least a known threshold $\\mu_0$, or to output None if it believes\nsuch an arm does not exist. The agent needs to guarantee its output is correct\nwith probability at least $1-\\delta$. Degenne & Koolen 2019 has established the\nasymptotically tight sample complexity for the 1-identification problem, but\nthey commented that the non-asymptotic analysis remains unclear. We design a\nnew algorithm Sequential-Exploration-Exploitation (SEE), and conduct\ntheoretical analysis from the non-asymptotic perspective. Novel to the\nliterature, we achieve near optimality, in the sense of matching upper and\nlower bounds on the pulling complexity. The gap between the upper and lower\nbounds is up to a polynomial logarithmic factor. The numerical result also\nindicates the effectiveness of our algorithm, compared to existing benchmarks.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e861-identification\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7b97\u6cd5SEE\uff0c\u5e76\u5728\u975e\u6e10\u8fd1\u89c6\u89d2\u4e0b\u8fdb\u884c\u4e86\u7406\u8bba\u5206\u6790\uff0c\u5b9e\u73b0\u4e86\u8fd1\u4e4e\u6700\u4f18\u7684\u6837\u672c\u590d\u6742\u5ea6\u3002", "motivation": "\u73b0\u6709\u6587\u732e\u4e2d\u5173\u4e8e1-identification\u95ee\u9898\u7684\u975e\u6e10\u8fd1\u5206\u6790\u5c1a\u4e0d\u660e\u786e\uff0c\u672c\u6587\u586b\u8865\u4e86\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u8bbe\u8ba1\u4e86\u65b0\u7b97\u6cd5Sequential-Exploration-Exploitation (SEE)\uff0c\u5e76\u4ece\u975e\u6e10\u8fd1\u89c6\u89d2\u8fdb\u884c\u4e86\u7406\u8bba\u5206\u6790\u3002", "result": "\u7b97\u6cd5SEE\u5728\u6837\u672c\u590d\u6742\u5ea6\u4e0a\u5b9e\u73b0\u4e86\u8fd1\u4e4e\u6700\u4f18\u7684\u4e0a\u754c\u548c\u4e0b\u754c\u5339\u914d\uff0c\u5dee\u8ddd\u4ec5\u4e3a\u591a\u9879\u5f0f\u5bf9\u6570\u56e0\u5b50\u3002\u6570\u503c\u5b9e\u9a8c\u4e5f\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "SEE\u7b97\u6cd5\u57281-identification\u95ee\u9898\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u586b\u8865\u4e86\u975e\u6e10\u8fd1\u5206\u6790\u7684\u7a7a\u767d\u3002"}}
{"id": "2506.06980", "pdf": "https://arxiv.org/pdf/2506.06980", "abs": "https://arxiv.org/abs/2506.06980", "authors": ["Sajib Acharjee Dip", "Uddip Acharjee Shuvo", "Dipanwita Mallick", "Abrar Rahman Abir", "Liqing Zhang"], "title": "MoXGATE: Modality-aware cross-attention for multi-omic gastrointestinal cancer sub-type classification", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages, 1 figure, 6 tables", "summary": "Cancer subtype classification is crucial for personalized treatment and\nprognostic assessment. However, effectively integrating multi-omic data remains\nchallenging due to the heterogeneous nature of genomic, epigenomic, and\ntranscriptomic features. In this work, we propose Modality-Aware\nCross-Attention MoXGATE, a novel deep-learning framework that leverages\ncross-attention and learnable modality weights to enhance feature fusion across\nmultiple omics sources. Our approach effectively captures inter-modality\ndependencies, ensuring robust and interpretable integration. Through\nexperiments on Gastrointestinal Adenocarcinoma (GIAC) and Breast Cancer (BRCA)\ndatasets from TCGA, we demonstrate that MoXGATE outperforms existing methods,\nachieving 95\\% classification accuracy. Ablation studies validate the\neffectiveness of cross-attention over simple concatenation and highlight the\nimportance of different omics modalities. Moreover, our model generalizes well\nto unseen cancer types e.g., breast cancer, underscoring its adaptability. Key\ncontributions include (1) a cross-attention-based multi-omic integration\nframework, (2) modality-weighted fusion for enhanced interpretability, (3)\napplication of focal loss to mitigate data imbalance, and (4) validation across\nmultiple cancer subtypes. Our results indicate that MoXGATE is a promising\napproach for multi-omic cancer subtype classification, offering improved\nperformance and biological generalizability.", "AI": {"tldr": "MoXGATE\u662f\u4e00\u79cd\u57fa\u4e8e\u4ea4\u53c9\u6ce8\u610f\u529b\u548c\u53ef\u5b66\u4e60\u6a21\u6001\u6743\u91cd\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u591a\u7ec4\u5b66\u6570\u636e\u878d\u5408\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u764c\u75c7\u4e9a\u578b\u5206\u7c7b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u764c\u75c7\u4e9a\u578b\u5206\u7c7b\u5bf9\u4e2a\u6027\u5316\u6cbb\u7597\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u591a\u7ec4\u5b66\u6570\u636e\u7684\u5f02\u8d28\u6027\u4f7f\u5176\u6574\u5408\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u63d0\u51faModality-Aware Cross-Attention MoXGATE\u6846\u67b6\uff0c\u5229\u7528\u4ea4\u53c9\u6ce8\u610f\u529b\u548c\u6a21\u6001\u6743\u91cd\u5b9e\u73b0\u591a\u7ec4\u5b66\u7279\u5f81\u878d\u5408\u3002", "result": "\u5728GIAC\u548cBRCA\u6570\u636e\u96c6\u4e0a\u8fbe\u523095%\u7684\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "MoXGATE\u5728\u591a\u7ec4\u5b66\u764c\u75c7\u4e9a\u578b\u5206\u7c7b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5177\u6709\u9ad8\u6027\u80fd\u548c\u751f\u7269\u5b66\u901a\u7528\u6027\u3002"}}
{"id": "2506.06985", "pdf": "https://arxiv.org/pdf/2506.06985", "abs": "https://arxiv.org/abs/2506.06985", "authors": ["Anastasia Koloskova", "Youssef Allouah", "Animesh Jha", "Rachid Guerraoui", "Sanmi Koyejo"], "title": "Certified Unlearning for Neural Networks", "categories": ["cs.LG", "cs.CR", "stat.ML"], "comment": null, "summary": "We address the problem of machine unlearning, where the goal is to remove the\ninfluence of specific training data from a model upon request, motivated by\nprivacy concerns and regulatory requirements such as the \"right to be\nforgotten.\" Unfortunately, existing methods rely on restrictive assumptions or\nlack formal guarantees. To this end, we propose a novel method for certified\nmachine unlearning, leveraging the connection between unlearning and privacy\namplification by stochastic post-processing. Our method uses noisy fine-tuning\non the retain data, i.e., data that does not need to be removed, to ensure\nprovable unlearning guarantees. This approach requires no assumptions about the\nunderlying loss function, making it broadly applicable across diverse settings.\nWe analyze the theoretical trade-offs in efficiency and accuracy and\ndemonstrate empirically that our method not only achieves formal unlearning\nguarantees but also performs effectively in practice, outperforming existing\nbaselines. Our code is available at\nhttps://github.com/stair-lab/certified-unlearningneural-networks-icml-2025", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8ba4\u8bc1\u673a\u5668\u9057\u5fd8\u65b9\u6cd5\uff0c\u901a\u8fc7\u566a\u58f0\u5fae\u8c03\u4fdd\u7559\u6570\u636e\u5b9e\u73b0\u53ef\u8bc1\u660e\u7684\u9057\u5fd8\u4fdd\u8bc1\uff0c\u65e0\u9700\u5bf9\u635f\u5931\u51fd\u6570\u505a\u5047\u8bbe\uff0c\u5e76\u5728\u5b9e\u8df5\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u89e3\u51b3\u673a\u5668\u9057\u5fd8\u95ee\u9898\uff0c\u6ee1\u8db3\u9690\u79c1\u9700\u6c42\u548c\u6cd5\u89c4\u8981\u6c42\uff08\u5982\u201c\u88ab\u9057\u5fd8\u6743\u201d\uff09\uff0c\u73b0\u6709\u65b9\u6cd5\u5047\u8bbe\u4e25\u683c\u6216\u7f3a\u4e4f\u5f62\u5f0f\u5316\u4fdd\u8bc1\u3002", "method": "\u5229\u7528\u9057\u5fd8\u4e0e\u968f\u673a\u540e\u5904\u7406\u7684\u9690\u79c1\u653e\u5927\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u63d0\u51fa\u57fa\u4e8e\u566a\u58f0\u5fae\u8c03\u4fdd\u7559\u6570\u636e\u7684\u8ba4\u8bc1\u9057\u5fd8\u65b9\u6cd5\u3002", "result": "\u65b9\u6cd5\u5728\u7406\u8bba\u548c\u5b9e\u8df5\u4e2d\u5747\u8868\u73b0\u826f\u597d\uff0c\u63d0\u4f9b\u5f62\u5f0f\u5316\u9057\u5fd8\u4fdd\u8bc1\u4e14\u6548\u7387\u4e0e\u51c6\u786e\u6027\u5e73\u8861\uff0c\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u673a\u5668\u9057\u5fd8\u63d0\u4f9b\u4e86\u901a\u7528\u4e14\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u591a\u6837\u5316\u573a\u666f\u3002"}}
{"id": "2506.06986", "pdf": "https://arxiv.org/pdf/2506.06986", "abs": "https://arxiv.org/abs/2506.06986", "authors": ["Austin Snyder", "Ryan Gallagher", "Boris Kovalerchuk"], "title": "Fully Explainable Classification Models Using Hyperblocks", "categories": ["cs.LG"], "comment": "7 pages, 8 figures, 6 tables", "summary": "Building on existing work with Hyperblocks, which classify data using minimum\nand maximum bounds for each attribute, we focus on enhancing interpretability,\ndecreasing training time, and reducing model complexity without sacrificing\naccuracy. This system allows subject matter experts (SMEs) to directly inspect\nand understand the model's decision logic without requiring extensive machine\nlearning expertise. To reduce Hyperblock complexity while retaining\nperformance, we introduce a suite of algorithms for Hyperblock simplification.\nThese include removing redundant attributes, removing redundant blocks through\noverlap analysis, and creating disjunctive units. These methods eliminate\nunnecessary parameters, dramatically reducing model size without harming\nclassification power. We increase robustness by introducing an interpretable\nfallback mechanism using k-Nearest Neighbor (k-NN) classifiers for points not\ncovered by any block, ensuring complete data coverage while preserving model\ntransparency. Our results demonstrate that interpretable models can scale to\nhigh-dimensional, large-volume datasets while maintaining competitive accuracy.\nOn benchmark datasets such as WBC (9-D), we achieve strong predictive\nperformance with significantly reduced complexity. On MNIST (784-D), our method\ncontinues to improve through tuning and simplification, showing promise as a\ntransparent alternative to black-box models in domains where trust, clarity,\nand control are crucial.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eHyperblocks\u7684\u6539\u8fdb\u65b9\u6cd5\uff0c\u65e8\u5728\u63d0\u5347\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u3001\u51cf\u5c11\u8bad\u7ec3\u65f6\u95f4\u5e76\u964d\u4f4e\u590d\u6742\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\u3002\u901a\u8fc7\u7b80\u5316\u7b97\u6cd5\u548c\u5f15\u5165k-NN\u56de\u9000\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6027\u80fd\u4e14\u900f\u660e\u7684\u5206\u7c7b\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u7684Hyperblocks\u65b9\u6cd5\u867d\u7136\u80fd\u5206\u7c7b\u6570\u636e\uff0c\u4f46\u5728\u53ef\u89e3\u91ca\u6027\u3001\u8bad\u7ec3\u65f6\u95f4\u548c\u6a21\u578b\u590d\u6742\u5ea6\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002\u8bba\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u4f7f\u9886\u57df\u4e13\u5bb6\u80fd\u76f4\u63a5\u7406\u89e3\u6a21\u578b\u903b\u8f91\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u7cfb\u5217Hyperblock\u7b80\u5316\u7b97\u6cd5\uff0c\u5305\u62ec\u53bb\u9664\u5197\u4f59\u5c5e\u6027\u3001\u5206\u6790\u91cd\u53e0\u5757\u4ee5\u53bb\u9664\u5197\u4f59\u5757\uff0c\u4ee5\u53ca\u521b\u5efa\u5206\u79bb\u5355\u5143\u3002\u540c\u65f6\u5f15\u5165k-NN\u56de\u9000\u673a\u5236\u4ee5\u8986\u76d6\u672a\u88ab\u5757\u8986\u76d6\u7684\u6570\u636e\u70b9\u3002", "result": "\u5728WBC\uff089\u7ef4\uff09\u548cMNIST\uff08784\u7ef4\uff09\u7b49\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0c\u6a21\u578b\u5728\u4fdd\u6301\u9ad8\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u590d\u6742\u5ea6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u8bc1\u660e\u4e86\u53ef\u89e3\u91ca\u6a21\u578b\u5728\u9ad8\u7ef4\u5927\u6570\u636e\u96c6\u4e0a\u7684\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u9700\u8981\u900f\u660e\u6027\u548c\u53ef\u63a7\u6027\u7684\u9886\u57df\u63d0\u4f9b\u4e86\u66ff\u4ee3\u9ed1\u76d2\u6a21\u578b\u7684\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2506.06990", "pdf": "https://arxiv.org/pdf/2506.06990", "abs": "https://arxiv.org/abs/2506.06990", "authors": ["Mingyi Li", "Michael R. Metel", "Akiko Takeda"], "title": "Modified K-means Algorithm with Local Optimality Guarantees", "categories": ["cs.LG"], "comment": "ICML 2025", "summary": "The K-means algorithm is one of the most widely studied clustering algorithms\nin machine learning. While extensive research has focused on its ability to\nachieve a globally optimal solution, there still lacks a rigorous analysis of\nits local optimality guarantees. In this paper, we first present conditions\nunder which the K-means algorithm converges to a locally optimal solution.\nBased on this, we propose simple modifications to the K-means algorithm which\nensure local optimality in both the continuous and discrete sense, with the\nsame computational complexity as the original K-means algorithm. As the\ndissimilarity measure, we consider a general Bregman divergence, which is an\nextension of the squared Euclidean distance often used in the K-means\nalgorithm. Numerical experiments confirm that the K-means algorithm does not\nalways find a locally optimal solution in practice, while our proposed methods\nprovide improved locally optimal solutions with reduced clustering loss. Our\ncode is available at https://github.com/lmingyi/LO-K-means.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86K-means\u7b97\u6cd5\u7684\u5c40\u90e8\u6700\u4f18\u6027\uff0c\u63d0\u51fa\u4e86\u6539\u8fdb\u65b9\u6cd5\u4ee5\u786e\u4fdd\u5c40\u90e8\u6700\u4f18\u89e3\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5c3d\u7ba1K-means\u7b97\u6cd5\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u88ab\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u5176\u5c40\u90e8\u6700\u4f18\u6027\u7f3a\u4e4f\u4e25\u683c\u5206\u6790\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u63d0\u51fa\u4e86\u5bf9K-means\u7b97\u6cd5\u7684\u7b80\u5355\u4fee\u6539\uff0c\u786e\u4fdd\u5728\u8fde\u7eed\u548c\u79bb\u6563\u610f\u4e49\u4e0a\u8fbe\u5230\u5c40\u90e8\u6700\u4f18\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u539f\u7b97\u6cd5\u76f8\u540c\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u539f\u59cbK-means\u7b97\u6cd5\u5728\u5b9e\u8df5\u4e2d\u4e0d\u4e00\u5b9a\u627e\u5230\u5c40\u90e8\u6700\u4f18\u89e3\uff0c\u800c\u6539\u8fdb\u65b9\u6cd5\u80fd\u63d0\u4f9b\u66f4\u4f18\u7684\u805a\u7c7b\u7ed3\u679c\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u4fdd\u8bc1\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u5347\u4e86K-means\u7b97\u6cd5\u7684\u5c40\u90e8\u6700\u4f18\u6027\u3002"}}
{"id": "2506.06999", "pdf": "https://arxiv.org/pdf/2506.06999", "abs": "https://arxiv.org/abs/2506.06999", "authors": ["Arun Sharma", "Mingzhou Yang", "Majid Farhadloo", "Subhankar Ghosh", "Bharat Jayaprakash", "Shashi Shekhar"], "title": "Towards Physics-informed Diffusion for Anomaly Detection in Trajectories", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "comment": null, "summary": "Given trajectory data, a domain-specific study area, and a user-defined\nthreshold, we aim to find anomalous trajectories indicative of possible GPS\nspoofing (e.g., fake trajectory). The problem is societally important to curb\nillegal activities in international waters, such as unauthorized fishing and\nillicit oil transfers. The problem is challenging due to advances in AI\ngenerated in deep fakes generation (e.g., additive noise, fake trajectories)\nand lack of adequate amount of labeled samples for ground-truth verification.\nRecent literature shows promising results for anomalous trajectory detection\nusing generative models despite data sparsity. However, they do not consider\nfine-scale spatiotemporal dependencies and prior physical knowledge, resulting\nin higher false-positive rates. To address these limitations, we propose a\nphysics-informed diffusion model that integrates kinematic constraints to\nidentify trajectories that do not adhere to physical laws. Experimental results\non real-world datasets in the maritime and urban domains show that the proposed\nframework results in higher prediction accuracy and lower estimation error rate\nfor anomaly detection and trajectory generation methods, respectively. Our\nimplementation is available at\nhttps://github.com/arunshar/Physics-Informed-Diffusion-Probabilistic-Model.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7269\u7406\u7ea6\u675f\u7684\u6269\u6563\u6a21\u578b\uff0c\u7528\u4e8e\u68c0\u6d4b\u5f02\u5e38\u8f68\u8ff9\uff0c\u7279\u522b\u662f\u5728GPS\u6b3a\u9a97\u573a\u666f\u4e2d\uff0c\u63d0\u9ad8\u4e86\u51c6\u786e\u7387\u5e76\u964d\u4f4e\u4e86\u8bef\u62a5\u7387\u3002", "motivation": "\u89e3\u51b3\u56fd\u9645\u6c34\u57df\u975e\u6cd5\u6d3b\u52a8\uff08\u5982\u975e\u6cd5\u6355\u9c7c\u548c\u77f3\u6cb9\u8d70\u79c1\uff09\u4e2d\u7684GPS\u6b3a\u9a97\u95ee\u9898\uff0c\u540c\u65f6\u5e94\u5bf9AI\u751f\u6210\u7684\u5047\u8f68\u8ff9\u548c\u6807\u8bb0\u6570\u636e\u4e0d\u8db3\u7684\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7269\u7406\u4fe1\u606f\u6269\u6563\u6a21\u578b\uff0c\u7ed3\u5408\u8fd0\u52a8\u5b66\u7ea6\u675f\uff0c\u8bc6\u522b\u4e0d\u7b26\u5408\u7269\u7406\u89c4\u5f8b\u7684\u8f68\u8ff9\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\uff08\u6d77\u4e8b\u548c\u57ce\u5e02\u9886\u57df\uff09\u4e0a\u5b9e\u9a8c\uff0c\u663e\u793a\u51fa\u66f4\u9ad8\u7684\u5f02\u5e38\u68c0\u6d4b\u51c6\u786e\u7387\u548c\u66f4\u4f4e\u7684\u8f68\u8ff9\u751f\u6210\u8bef\u5dee\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u6574\u5408\u7269\u7406\u77e5\u8bc6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5f02\u5e38\u8f68\u8ff9\u68c0\u6d4b\u7684\u6027\u80fd\uff0c\u4e14\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2506.07003", "pdf": "https://arxiv.org/pdf/2506.07003", "abs": "https://arxiv.org/abs/2506.07003", "authors": ["Utkarsh Utkarsh", "Danielle C. Maddix", "Ruijun Ma", "Michael W. Mahoney", "Yuyang Wang"], "title": "End-to-End Probabilistic Framework for Learning with Hard Constraints", "categories": ["cs.LG", "cs.AI", "cs.CE"], "comment": "46 pages, 5 figures, 10 tables", "summary": "We present a general purpose probabilistic forecasting framework,\nProbHardE2E, to learn systems that can incorporate operational/physical\nconstraints as hard requirements. ProbHardE2E enforces hard constraints by\nexploiting variance information in a novel way; and thus it is also capable of\nperforming uncertainty quantification (UQ) on the model. Our methodology uses a\nnovel differentiable probabilistic projection layer (DPPL) that can be combined\nwith a wide range of neural network architectures. This DPPL allows the model\nto learn the system in an end-to-end manner, compared to other approaches where\nthe constraints are satisfied either through a post-processing step or at\ninference. In addition, ProbHardE2E can optimize a strictly proper scoring\nrule, without making any distributional assumptions on the target, which\nenables it to obtain robust distributional estimates (in contrast to existing\napproaches that generally optimize likelihood-based objectives, which are\nheavily biased by their distributional assumptions and model choices); and it\ncan incorporate a range of non-linear constraints (increasing the power of\nmodeling and flexibility). We apply ProbHardE2E to problems in learning partial\ndifferential equations with uncertainty estimates and to probabilistic\ntime-series forecasting, showcasing it as a broadly applicable general setup\nthat connects these seemingly disparate domains.", "AI": {"tldr": "ProbHardE2E\u662f\u4e00\u4e2a\u901a\u7528\u7684\u6982\u7387\u9884\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u65b0\u9896\u7684\u53ef\u5fae\u5206\u6982\u7387\u6295\u5f71\u5c42\uff08DPPL\uff09\u5b9e\u73b0\u786c\u7ea6\u675f\uff0c\u652f\u6301\u7aef\u5230\u7aef\u5b66\u4e60\uff0c\u5e76\u4f18\u5316\u4e25\u683c\u8bc4\u5206\u89c4\u5219\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u975e\u7ebf\u6027\u7ea6\u675f\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u901a\u8fc7\u540e\u5904\u7406\u6216\u63a8\u7406\u9636\u6bb5\u6ee1\u8db3\u7ea6\u675f\uff0c\u4e14\u4f9d\u8d56\u5206\u5e03\u5047\u8bbe\uff0c\u9650\u5236\u4e86\u6a21\u578b\u7684\u7075\u6d3b\u6027\u548c\u9c81\u68d2\u6027\u3002ProbHardE2E\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u5229\u7528DPPL\u5c42\u7ed3\u5408\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u7aef\u5230\u7aef\u5b66\u4e60\u7cfb\u7edf\uff0c\u5e76\u901a\u8fc7\u65b9\u5dee\u4fe1\u606f\u5b9e\u73b0\u786c\u7ea6\u675f\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "result": "\u5728\u504f\u5fae\u5206\u65b9\u7a0b\u5b66\u4e60\u548c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u5c55\u793a\u4e86\u5e7f\u6cdb\u9002\u7528\u6027\uff0c\u4f18\u4e8e\u4f9d\u8d56\u5206\u5e03\u5047\u8bbe\u7684\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "ProbHardE2E\u662f\u4e00\u4e2a\u7075\u6d3b\u4e14\u5f3a\u5927\u7684\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u7ea6\u675f\u95ee\u9898\u7684\u6982\u7387\u9884\u6d4b\u3002"}}
{"id": "2506.07014", "pdf": "https://arxiv.org/pdf/2506.07014", "abs": "https://arxiv.org/abs/2506.07014", "authors": ["Yutaro Nakagama", "Daisuke Ishii", "Kazuki Yoshizoe"], "title": "Comparison of Lightweight Methods for Vehicle Dynamics-Based Driver Drowsiness Detection", "categories": ["cs.LG"], "comment": "8 pages, 3 figures, to be published at IV 2025", "summary": "Driver drowsiness detection (DDD) prevents road accidents caused by driver\nfatigue. Vehicle dynamics-based DDD has been proposed as a method that is both\neconomical and high performance. However, there are concerns about the\nreliability of performance metrics and the reproducibility of many of the\nexisting methods. For instance, some previous studies seem to have a data\nleakage issue among training and test datasets, and many do not openly provide\nthe datasets they used. To this end, this paper aims to compare the performance\nof representative vehicle dynamics-based DDD methods under a transparent and\nfair framework that uses a public dataset. We first develop a framework for\nextracting features from an open dataset by Aygun et al. and performing DDD\nwith lightweight ML models; the framework is carefully designed to support a\nvariety of onfigurations. Second, we implement three existing representative\nmethods and a concise random forest (RF)-based method in the framework.\nFinally, we report the results of experiments to verify the reproducibility and\nclarify the performance of DDD based on common metrics. Among the evaluated\nmethods, the RF-based method achieved the highest accuracy of 88 %. Our\nfindings imply the issues inherent in DDD methods developed in a non-standard\nmanner, and demonstrate a high performance method implemented appropriately.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u900f\u660e\u516c\u5e73\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u6bd4\u8f83\u57fa\u4e8e\u8f66\u8f86\u52a8\u529b\u5b66\u7684\u9a7e\u9a76\u5458\u75b2\u52b3\u68c0\u6d4b\uff08DDD\uff09\u65b9\u6cd5\uff0c\u5e76\u9a8c\u8bc1\u5176\u53ef\u91cd\u590d\u6027\u548c\u6027\u80fd\u3002", "motivation": "\u73b0\u6709DDD\u65b9\u6cd5\u5b58\u5728\u6027\u80fd\u6307\u6807\u4e0d\u53ef\u9760\u548c\u53ef\u91cd\u590d\u6027\u5dee\u7684\u95ee\u9898\uff0c\u90e8\u5206\u7814\u7a76\u5b58\u5728\u6570\u636e\u6cc4\u9732\u6216\u672a\u516c\u5f00\u6570\u636e\u96c6\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u516c\u5f00\u6570\u636e\u96c6\u548c\u6807\u51c6\u5316\u6846\u67b6\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u6846\u67b6\uff0c\u4ece\u516c\u5f00\u6570\u636e\u96c6\u4e2d\u63d0\u53d6\u7279\u5f81\u5e76\u4f7f\u7528\u8f7b\u91cf\u7ea7\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8fdb\u884cDDD\u3002\u5b9e\u73b0\u4e86\u4e09\u79cd\u73b0\u6709\u4ee3\u8868\u6027\u65b9\u6cd5\u548c\u4e00\u79cd\u57fa\u4e8e\u968f\u673a\u68ee\u6797\uff08RF\uff09\u7684\u65b0\u65b9\u6cd5\u3002", "result": "\u5728\u8bc4\u4f30\u7684\u65b9\u6cd5\u4e2d\uff0c\u57fa\u4e8eRF\u7684\u65b9\u6cd5\u8fbe\u5230\u4e8688%\u7684\u6700\u9ad8\u51c6\u786e\u7387\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u975e\u6807\u51c6\u5316\u5f00\u53d1\u7684DDD\u65b9\u6cd5\u7684\u56fa\u6709\u95ee\u9898\uff0c\u5e76\u5c55\u793a\u4e86\u4e00\u79cd\u9ad8\u6027\u80fd\u4e14\u5b9e\u73b0\u5f97\u5f53\u7684\u65b9\u6cd5\u3002"}}
{"id": "2506.07022", "pdf": "https://arxiv.org/pdf/2506.07022", "abs": "https://arxiv.org/abs/2506.07022", "authors": ["Leheng Sheng", "Changshuo Shen", "Weixiang Zhao", "Junfeng Fang", "Xiaohao Liu", "Zhenkai Liang", "Xiang Wang", "An Zhang", "Tat-Seng Chua"], "title": "AlphaSteer: Learning Refusal Steering with Principled Null-Space Constraint", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "As LLMs are increasingly deployed in real-world applications, ensuring their\nability to refuse malicious prompts, especially jailbreak attacks, is essential\nfor safe and reliable use. Recently, activation steering has emerged as an\neffective approach for enhancing LLM safety by adding a refusal direction\nvector to internal activations of LLMs during inference, which will further\ninduce the refusal behaviors of LLMs. However, indiscriminately applying\nactivation steering fundamentally suffers from the trade-off between safety and\nutility, since the same steering vector can also lead to over-refusal and\ndegraded performance on benign prompts. Although prior efforts, such as vector\ncalibration and conditional steering, have attempted to mitigate this\ntrade-off, their lack of theoretical grounding limits their robustness and\neffectiveness. To better address the trade-off between safety and utility, we\npresent a theoretically grounded and empirically effective activation steering\nmethod called AlphaSteer. Specifically, it considers activation steering as a\nlearnable process with two principled learning objectives: utility preservation\nand safety enhancement. For utility preservation, it learns to construct a\nnearly zero vector for steering benign data, with the null-space constraints.\nFor safety enhancement, it learns to construct a refusal direction vector for\nsteering malicious data, with the help of linear regression. Experiments across\nmultiple jailbreak attacks and utility benchmarks demonstrate the effectiveness\nof AlphaSteer, which significantly improves the safety of LLMs without\ncompromising general capabilities. Our codes are available at\nhttps://github.com/AlphaLab-USTC/AlphaSteer.", "AI": {"tldr": "AlphaSteer\u662f\u4e00\u79cd\u57fa\u4e8e\u7406\u8bba\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f18\u5316\u6fc0\u6d3b\u5bfc\u5411\u5411\u91cf\u6765\u5e73\u8861LLMs\u7684\u5b89\u5168\u6027\u548c\u5b9e\u7528\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u5b89\u5168\u6027\u800c\u4e0d\u635f\u5bb3\u5176\u901a\u7528\u80fd\u529b\u3002", "motivation": "\u968f\u7740LLMs\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u7684\u5e7f\u6cdb\u90e8\u7f72\uff0c\u786e\u4fdd\u5176\u80fd\u591f\u62d2\u7edd\u6076\u610f\u63d0\u793a\uff08\u5982\u8d8a\u72f1\u653b\u51fb\uff09\u662f\u5b89\u5168\u53ef\u9760\u4f7f\u7528\u7684\u5173\u952e\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u5b89\u5168\u6027\u548c\u5b9e\u7528\u6027\u4e4b\u95f4\u5b58\u5728\u6743\u8861\uff0c\u7f3a\u4e4f\u7406\u8bba\u652f\u6301\u3002", "method": "AlphaSteer\u5c06\u6fc0\u6d3b\u5bfc\u5411\u89c6\u4e3a\u53ef\u5b66\u4e60\u8fc7\u7a0b\uff0c\u901a\u8fc7\u4e24\u4e2a\u76ee\u6807\u4f18\u5316\uff1a\u5b9e\u7528\u6027\u4fdd\u6301\uff08\u6784\u9020\u63a5\u8fd1\u96f6\u7684\u5bfc\u5411\u5411\u91cf\uff09\u548c\u5b89\u5168\u6027\u589e\u5f3a\uff08\u6784\u9020\u62d2\u7edd\u5bfc\u5411\u5411\u91cf\uff09\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cAlphaSteer\u5728\u591a\u79cd\u8d8a\u72f1\u653b\u51fb\u548c\u5b9e\u7528\u6027\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u5347\u4e86LLMs\u7684\u5b89\u5168\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5176\u901a\u7528\u80fd\u529b\u3002", "conclusion": "AlphaSteer\u662f\u4e00\u79cd\u7406\u8bba\u652f\u6301\u4e14\u5b9e\u8bc1\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u6210\u529f\u89e3\u51b3\u4e86LLMs\u5728\u5b89\u5168\u6027\u548c\u5b9e\u7528\u6027\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\u3002"}}
{"id": "2506.07033", "pdf": "https://arxiv.org/pdf/2506.07033", "abs": "https://arxiv.org/abs/2506.07033", "authors": ["Yung-Chien Wang", "Kuang-Da Wang", "Wei-Yao Wang", "Wen-Chih Peng"], "title": "Mixture Experts with Test-Time Self-Supervised Aggregation for Tabular Imbalanced Regression", "categories": ["cs.LG"], "comment": "Preprint", "summary": "Tabular data serve as a fundamental and ubiquitous representation of\nstructured information in numerous real-world applications, e.g., finance and\nurban planning. In the realm of tabular imbalanced applications, data imbalance\nhas been investigated in classification tasks with insufficient instances in\ncertain labels, causing the model's ineffective generalizability. However, the\nimbalance issue of tabular regression tasks is underexplored, and yet is\ncritical due to unclear boundaries for continuous labels and simplifying\nassumptions in existing imbalance regression work, which often rely on known\nand balanced test distributions. Such assumptions may not hold in practice and\ncan lead to performance degradation. To address these issues, we propose MATI:\nMixture Experts with Test-Time Self-Supervised Aggregation for Tabular\nImbalance Regression, featuring two key innovations: (i) the Region-Aware\nMixture Expert, which adopts a Gaussian Mixture Model to capture the underlying\nrelated regions. The statistical information of each Gaussian component is then\nused to synthesize and train region-specific experts to capture the unique\ncharacteristics of their respective regions. (ii) Test-Time Self-Supervised\nExpert Aggregation, which dynamically adjusts region expert weights based on\ntest data features to reinforce expert adaptation across varying test\ndistributions. We evaluated MATI on four real-world tabular imbalance\nregression datasets, including house pricing, bike sharing, and age prediction.\nTo reflect realistic deployment scenarios, we adopted three types of test\ndistributions: a balanced distribution with uniform target frequencies, a\nnormal distribution that follows the training data, and an inverse distribution\nthat emphasizes rare target regions. On average across these three test\ndistributions, MATI achieved a 7.1% improvement in MAE compared to existing\nmethods.", "AI": {"tldr": "MATI\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u8868\u683c\u4e0d\u5e73\u8861\u56de\u5f52\u95ee\u9898\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u533a\u57df\u611f\u77e5\u6df7\u5408\u4e13\u5bb6\u548c\u6d4b\u8bd5\u65f6\u81ea\u76d1\u7763\u4e13\u5bb6\u805a\u5408\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u8868\u683c\u6570\u636e\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u5e7f\u6cdb\u5b58\u5728\uff0c\u4f46\u8868\u683c\u56de\u5f52\u4efb\u52a1\u4e2d\u7684\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\u7814\u7a76\u4e0d\u8db3\uff0c\u73b0\u6709\u65b9\u6cd5\u5047\u8bbe\u6d4b\u8bd5\u5206\u5e03\u5df2\u77e5\u4e14\u5e73\u8861\uff0c\u5b9e\u9645\u4e2d\u53ef\u80fd\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002", "method": "MATI\u91c7\u7528\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u6355\u83b7\u76f8\u5173\u533a\u57df\uff0c\u8bad\u7ec3\u533a\u57df\u7279\u5b9a\u4e13\u5bb6\uff0c\u5e76\u901a\u8fc7\u6d4b\u8bd5\u65f6\u81ea\u76d1\u7763\u52a8\u6001\u8c03\u6574\u4e13\u5bb6\u6743\u91cd\u4ee5\u9002\u5e94\u4e0d\u540c\u6d4b\u8bd5\u5206\u5e03\u3002", "result": "\u5728\u56db\u79cd\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0cMATI\u5728\u4e09\u79cd\u6d4b\u8bd5\u5206\u5e03\u4e0b\u5e73\u5747MAE\u63d0\u53477.1%\u3002", "conclusion": "MATI\u6709\u6548\u89e3\u51b3\u4e86\u8868\u683c\u4e0d\u5e73\u8861\u56de\u5f52\u95ee\u9898\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2506.07040", "pdf": "https://arxiv.org/pdf/2506.07040", "abs": "https://arxiv.org/abs/2506.07040", "authors": ["Yang Xu", "Swetha Ganesh", "Vaneet Aggarwal"], "title": "Efficient $Q$-Learning and Actor-Critic Methods for Robust Average Reward Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "arXiv admin note: text overlap with arXiv:2502.16816", "summary": "We present the first $Q$-learning and actor-critic algorithms for robust\naverage reward Markov Decision Processes (MDPs) with non-asymptotic convergence\nunder contamination, TV distance and Wasserstein distance uncertainty sets. We\nshow that the robust $Q$ Bellman operator is a strict contractive mapping with\nrespect to a carefully constructed semi-norm with constant functions being\nquotiented out. This property supports a stochastic approximation update, that\nlearns the optimal robust $Q$ function in $\\tilde{\\cO}(\\epsilon^{-2})$ samples.\nWe also show that the same idea can be used for robust $Q$ function estimation,\nwhich can be further used for critic estimation. Coupling it with theories in\nrobust policy mirror descent update, we present a natural actor-critic\nalgorithm that attains an $\\epsilon$-optimal robust policy in\n$\\tilde{\\cO}(\\epsilon^{-3})$ samples. These results advance the theory of\ndistributionally robust reinforcement learning in the average reward setting.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.07049", "pdf": "https://arxiv.org/pdf/2506.07049", "abs": "https://arxiv.org/abs/2506.07049", "authors": ["Jake Robertson", "Noah Hollmann", "Samuel M\u00fcller", "Noor Awad", "Frank Hutter"], "title": "FairPFN: A Tabular Foundation Model for Causal Fairness", "categories": ["cs.LG", "cs.CY"], "comment": null, "summary": "Machine learning (ML) systems are utilized in critical sectors, such as\nhealthcare, law enforcement, and finance. However, these systems are often\ntrained on historical data that contains demographic biases, leading to ML\ndecisions that perpetuate or exacerbate existing social inequalities. Causal\nfairness provides a transparent, human-in-the-loop framework to mitigate\nalgorithmic discrimination, aligning closely with legal doctrines of direct and\nindirect discrimination. However, current causal fairness frameworks hold a key\nlimitation in that they assume prior knowledge of the correct causal model,\nrestricting their applicability in complex fairness scenarios where causal\nmodels are unknown or difficult to identify. To bridge this gap, we propose\nFairPFN, a tabular foundation model pre-trained on synthetic causal fairness\ndata to identify and mitigate the causal effects of protected attributes in its\npredictions. FairPFN's key contribution is that it requires no knowledge of the\ncausal model and still demonstrates strong performance in identifying and\nremoving protected causal effects across a diverse set of hand-crafted and\nreal-world scenarios relative to robust baseline methods. FairPFN paves the way\nfor promising future research, making causal fairness more accessible to a\nwider variety of complex fairness problems.", "AI": {"tldr": "FairPFN\u662f\u4e00\u79cd\u65e0\u9700\u56e0\u679c\u6a21\u578b\u5148\u9a8c\u77e5\u8bc6\u7684\u8868\u683c\u57fa\u7840\u6a21\u578b\uff0c\u7528\u4e8e\u8bc6\u522b\u548c\u51cf\u8f7b\u53d7\u4fdd\u62a4\u5c5e\u6027\u7684\u56e0\u679c\u6548\u5e94\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u5728\u5173\u952e\u9886\u57df\u4e2d\u4f7f\u7528\uff0c\u4f46\u5386\u53f2\u6570\u636e\u4e2d\u7684\u504f\u89c1\u53ef\u80fd\u5bfc\u81f4\u793e\u4f1a\u4e0d\u5e73\u7b49\u3002\u56e0\u679c\u516c\u5e73\u6027\u6846\u67b6\u901a\u5e38\u9700\u8981\u5df2\u77e5\u56e0\u679c\u6a21\u578b\uff0c\u9650\u5236\u4e86\u5176\u9002\u7528\u6027\u3002", "method": "\u63d0\u51faFairPFN\uff0c\u901a\u8fc7\u9884\u8bad\u7ec3\u5408\u6210\u56e0\u679c\u516c\u5e73\u6570\u636e\uff0c\u65e0\u9700\u56e0\u679c\u6a21\u578b\u77e5\u8bc6\u5373\u53ef\u8bc6\u522b\u548c\u6d88\u9664\u53d7\u4fdd\u62a4\u5c5e\u6027\u7684\u56e0\u679c\u6548\u5e94\u3002", "result": "FairPFN\u5728\u591a\u6837\u5316\u7684\u624b\u5de5\u548c\u771f\u5b9e\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "FairPFN\u4e3a\u590d\u6742\u516c\u5e73\u95ee\u9898\u63d0\u4f9b\u4e86\u66f4\u5e7f\u6cdb\u7684\u56e0\u679c\u516c\u5e73\u6027\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.07054", "pdf": "https://arxiv.org/pdf/2506.07054", "abs": "https://arxiv.org/abs/2506.07054", "authors": ["Uri Koren", "Navdeep Kumar", "Uri Gadot", "Giorgia Ramponi", "Kfir Yehuda Levy", "Shie Mannor"], "title": "Policy Gradient with Tree Search: Avoiding Local Optimas through Lookahead", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Classical policy gradient (PG) methods in reinforcement learning frequently\nconverge to suboptimal local optima, a challenge exacerbated in large or\ncomplex environments. This work investigates Policy Gradient with Tree Search\n(PGTS), an approach that integrates an $m$-step lookahead mechanism to enhance\npolicy optimization. We provide theoretical analysis demonstrating that\nincreasing the tree search depth $m$-monotonically reduces the set of\nundesirable stationary points and, consequently, improves the worst-case\nperformance of any resulting stationary policy. Critically, our analysis\naccommodates practical scenarios where policy updates are restricted to states\nvisited by the current policy, rather than requiring updates across the entire\nstate space. Empirical evaluations on diverse MDP structures, including Ladder,\nTightrope, and Gridworld environments, illustrate PGTS's ability to exhibit\n\"farsightedness,\" navigate challenging reward landscapes, escape local traps\nwhere standard PG fails, and achieve superior solutions.", "AI": {"tldr": "PGTS\u65b9\u6cd5\u901a\u8fc7\u7ed3\u5408\u6811\u641c\u7d22\u673a\u5236\u6539\u8fdb\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\uff0c\u51cf\u5c11\u5c40\u90e8\u6700\u4f18\u95ee\u9898\uff0c\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u5728\u590d\u6742\u73af\u5883\u4e2d\u6613\u9677\u5165\u5c40\u90e8\u6700\u4f18\uff0cPGTS\u65e8\u5728\u901a\u8fc7\u6811\u641c\u7d22\u673a\u5236\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "PGTS\u5f15\u5165m\u6b65\u524d\u77bb\u673a\u5236\uff0c\u7406\u8bba\u5206\u6790\u8868\u660e\u589e\u52a0\u641c\u7d22\u6df1\u5ea6\u53ef\u51cf\u5c11\u4e0d\u826f\u9a7b\u70b9\uff0c\u63d0\u5347\u6700\u574f\u60c5\u51b5\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u8868\u660ePGTS\u5728\u591a\u79cdMDP\u7ed3\u6784\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u80fd\u89c4\u907f\u5c40\u90e8\u9677\u9631\u5e76\u627e\u5230\u66f4\u4f18\u89e3\u3002", "conclusion": "PGTS\u901a\u8fc7\u6811\u641c\u7d22\u673a\u5236\u663e\u8457\u63d0\u5347\u4e86\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u590d\u6742\u73af\u5883\u3002"}}
{"id": "2506.07078", "pdf": "https://arxiv.org/pdf/2506.07078", "abs": "https://arxiv.org/abs/2506.07078", "authors": ["Jiaheng Dong", "Hong Jia", "Soumyajit Chatterjee", "Abhirup Ghosh", "James Bailey", "Ting Dang"], "title": "E-BATS: Efficient Backpropagation-Free Test-Time Adaptation for Speech Foundation Models", "categories": ["cs.LG", "cs.SD", "eess.AS"], "comment": "Under Review", "summary": "Speech Foundation Models encounter significant performance degradation when\ndeployed in real-world scenarios involving acoustic domain shifts, such as\nbackground noise and speaker accents. Test-time adaptation (TTA) has recently\nemerged as a viable strategy to address such domain shifts at inference time\nwithout requiring access to source data or labels. However, existing TTA\napproaches, particularly those relying on backpropagation, are\nmemory-intensive, limiting their applicability in speech tasks and\nresource-constrained settings. Although backpropagation-free methods offer\nimproved efficiency, existing ones exhibit poor accuracy. This is because they\nare predominantly developed for vision tasks, which fundamentally differ from\nspeech task formulations, noise characteristics, and model architecture, posing\nunique transferability challenges. In this paper, we introduce E-BATS, the\nfirst Efficient BAckpropagation-free TTA framework designed explicitly for\nspeech foundation models. E-BATS achieves a balance between adaptation\neffectiveness and memory efficiency through three key components: (i)\nlightweight prompt adaptation for a forward-pass-based feature alignment, (ii)\na multi-scale loss to capture both global (utterance-level) and local\ndistribution shifts (token-level) and (iii) a test-time exponential moving\naverage mechanism for stable adaptation across utterances. Experiments\nconducted on four noisy speech datasets spanning sixteen acoustic conditions\ndemonstrate consistent improvements, with 4.1%-13.5% accuracy gains over\nbackpropagation-free baselines and 2.0-6.4 times GPU memory savings compared to\nbackpropagation-based methods. By enabling scalable and robust adaptation under\nacoustic variability, this work paves the way for developing more efficient\nadaptation approaches for practical speech processing systems in real-world\nenvironments.", "AI": {"tldr": "E-BATS\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u65e0\u53cd\u5411\u4f20\u64ad\u6d4b\u8bd5\u65f6\u95f4\u9002\u5e94\u6846\u67b6\uff0c\u4e13\u4e3a\u8bed\u97f3\u57fa\u7840\u6a21\u578b\u8bbe\u8ba1\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u5185\u5b58\u6548\u7387\u548c\u51c6\u786e\u6027\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "\u8bed\u97f3\u57fa\u7840\u6a21\u578b\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u56e0\u58f0\u5b66\u9886\u57df\u504f\u79fb\uff08\u5982\u80cc\u666f\u566a\u58f0\u548c\u53e3\u97f3\uff09\u6027\u80fd\u4e0b\u964d\uff0c\u73b0\u6709\u6d4b\u8bd5\u65f6\u95f4\u9002\u5e94\u65b9\u6cd5\u8981\u4e48\u5185\u5b58\u6d88\u8017\u5927\uff0c\u8981\u4e48\u51c6\u786e\u6027\u4f4e\u3002", "method": "E-BATS\u901a\u8fc7\u8f7b\u91cf\u7ea7\u63d0\u793a\u9002\u5e94\u3001\u591a\u5c3a\u5ea6\u635f\u5931\u548c\u6d4b\u8bd5\u65f6\u95f4\u6307\u6570\u79fb\u52a8\u5e73\u5747\u673a\u5236\uff0c\u5b9e\u73b0\u9ad8\u6548\u4e14\u7a33\u5b9a\u7684\u9002\u5e94\u3002", "result": "\u5728\u56db\u4e2a\u566a\u58f0\u8bed\u97f3\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cE-BATS\u6bd4\u65e0\u53cd\u5411\u4f20\u64ad\u57fa\u7ebf\u63d0\u9ad8\u4e864.1%-13.5%\u7684\u51c6\u786e\u7387\uff0c\u5e76\u8282\u7701\u4e862.0-6.4\u500d\u7684GPU\u5185\u5b58\u3002", "conclusion": "E-BATS\u4e3a\u5b9e\u9645\u8bed\u97f3\u5904\u7406\u7cfb\u7edf\u5728\u58f0\u5b66\u53d8\u5316\u4e0b\u7684\u9ad8\u6548\u9002\u5e94\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2506.07085", "pdf": "https://arxiv.org/pdf/2506.07085", "abs": "https://arxiv.org/abs/2506.07085", "authors": ["Uri Koren", "Yonatan Ashlag", "Mirco Mutti", "Esther Derman", "Pierre-Luc Bacon", "Shie Mannor"], "title": "State Entropy Regularization for Robust Reinforcement Learning", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "State entropy regularization has empirically shown better exploration and\nsample complexity in reinforcement learning (RL). However, its theoretical\nguarantees have not been studied. In this paper, we show that state entropy\nregularization improves robustness to structured and spatially correlated\nperturbations. These types of variation are common in transfer learning but\noften overlooked by standard robust RL methods, which typically focus on small,\nuncorrelated changes. We provide a comprehensive characterization of these\nrobustness properties, including formal guarantees under reward and transition\nuncertainty, as well as settings where the method performs poorly. Much of our\nanalysis contrasts state entropy with the widely used policy entropy\nregularization, highlighting their different benefits. Finally, from a\npractical standpoint, we illustrate that compared with policy entropy, the\nrobustness advantages of state entropy are more sensitive to the number of\nrollouts used for policy evaluation.", "AI": {"tldr": "\u72b6\u6001\u71b5\u6b63\u5219\u5316\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u8868\u73b0\u51fa\u66f4\u597d\u7684\u63a2\u7d22\u6027\u548c\u6837\u672c\u6548\u7387\uff0c\u4f46\u5176\u7406\u8bba\u4fdd\u8bc1\u5c1a\u672a\u88ab\u7814\u7a76\u3002\u672c\u6587\u8bc1\u660e\u4e86\u72b6\u6001\u71b5\u6b63\u5219\u5316\u5bf9\u7ed3\u6784\u548c\u7a7a\u95f4\u76f8\u5173\u6270\u52a8\u7684\u9c81\u68d2\u6027\uff0c\u8fd9\u4e9b\u6270\u52a8\u5728\u8fc1\u79fb\u5b66\u4e60\u4e2d\u5e38\u89c1\u4f46\u5e38\u88ab\u6807\u51c6\u9c81\u68d2RL\u65b9\u6cd5\u5ffd\u89c6\u3002", "motivation": "\u7814\u7a76\u72b6\u6001\u71b5\u6b63\u5219\u5316\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u7406\u8bba\u4fdd\u8bc1\uff0c\u7279\u522b\u662f\u5176\u5bf9\u7ed3\u6784\u548c\u7a7a\u95f4\u76f8\u5173\u6270\u52a8\u7684\u9c81\u68d2\u6027\uff0c\u586b\u8865\u73b0\u6709\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u5bf9\u6bd4\u72b6\u6001\u71b5\u4e0e\u7b56\u7565\u71b5\u6b63\u5219\u5316\uff0c\u63ed\u793a\u5176\u5728\u4e0d\u540c\u6270\u52a8\u4e0b\u7684\u8868\u73b0\u5dee\u5f02\u3002", "result": "\u72b6\u6001\u71b5\u6b63\u5219\u5316\u5728\u7ed3\u6784\u548c\u7a7a\u95f4\u76f8\u5173\u6270\u52a8\u4e0b\u8868\u73b0\u66f4\u9c81\u68d2\uff0c\u4f46\u5176\u4f18\u52bf\u5bf9\u7b56\u7565\u8bc4\u4f30\u7684rollout\u6570\u91cf\u66f4\u654f\u611f\u3002", "conclusion": "\u72b6\u6001\u71b5\u6b63\u5219\u5316\u5728\u7279\u5b9a\u6270\u52a8\u4e0b\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u4e2d\u9700\u6ce8\u610f\u5176\u5bf9\u8bc4\u4f30\u6761\u4ef6\u7684\u654f\u611f\u6027\u3002"}}
{"id": "2506.07088", "pdf": "https://arxiv.org/pdf/2506.07088", "abs": "https://arxiv.org/abs/2506.07088", "authors": ["Ilja Kuzborskij", "Yasin Abbasi Yadkori"], "title": "Pointwise confidence estimation in the non-linear $\\ell^2$-regularized least squares", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We consider a high-probability non-asymptotic confidence estimation in the\n$\\ell^2$-regularized non-linear least-squares setting with fixed design. In\nparticular, we study confidence estimation for local minimizers of the\nregularized training loss. We show a pointwise confidence bound, meaning that\nit holds for the prediction on any given fixed test input $x$. Importantly, the\nproposed confidence bound scales with similarity of the test input to the\ntraining data in the implicit feature space of the predictor (for instance,\nbecoming very large when the test input lies far outside of the training data).\nThis desirable last feature is captured by the weighted norm involving the\ninverse-Hessian matrix of the objective function, which is a generalized\nversion of its counterpart in the linear setting, $x^{\\top} \\text{Cov}^{-1} x$.\nOur generalized result can be regarded as a non-asymptotic counterpart of the\nclassical confidence interval based on asymptotic normality of the MLE\nestimator. We propose an efficient method for computing the weighted norm,\nwhich only mildly exceeds the cost of a gradient computation of the loss\nfunction. Finally, we complement our analysis with empirical evidence showing\nthat the proposed confidence bound provides better coverage/width trade-off\ncompared to a confidence estimation by bootstrapping, which is a gold-standard\nmethod in many applications involving non-linear predictors such as neural\nnetworks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u9ad8\u6982\u7387\u975e\u6e10\u8fd1\u60c5\u51b5\u4e0b\u5bf9\u2113\u00b2\u6b63\u5219\u5316\u975e\u7ebf\u6027\u6700\u5c0f\u4e8c\u4e58\u95ee\u9898\u7684\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u56fa\u5b9a\u8bbe\u8ba1\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u4e3a\u975e\u7ebf\u6027\u9884\u6d4b\u6a21\u578b\uff08\u5982\u795e\u7ecf\u7f51\u7edc\uff09\u63d0\u4f9b\u66f4\u9ad8\u6548\u7684\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\uff08\u5982\u81ea\u52a9\u6cd5\uff09\u5728\u8986\u76d6\u7387\u548c\u5bbd\u5ea6\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u63a8\u5bfc\u5c40\u90e8\u6781\u5c0f\u503c\u70b9\u7684\u70b9\u6001\u7f6e\u4fe1\u8fb9\u754c\uff0c\u5229\u7528\u9690\u5f0f\u7279\u5f81\u7a7a\u95f4\u4e2d\u7684\u52a0\u6743\u8303\u6570\uff08\u6d89\u53ca\u76ee\u6807\u51fd\u6570\u7684\u9006Hessian\u77e9\u9635\uff09\u6765\u91cf\u5316\u6d4b\u8bd5\u8f93\u5165\u4e0e\u8bad\u7ec3\u6570\u636e\u7684\u76f8\u4f3c\u6027\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u6240\u63d0\u51fa\u7684\u7f6e\u4fe1\u8fb9\u754c\u5728\u8986\u76d6\u7387\u548c\u5bbd\u5ea6\u4e4b\u95f4\u8868\u73b0\u4f18\u4e8e\u81ea\u52a9\u6cd5\uff0c\u4e14\u8ba1\u7b97\u6548\u7387\u9ad8\uff0c\u4ec5\u7565\u9ad8\u4e8e\u635f\u5931\u51fd\u6570\u7684\u68af\u5ea6\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "\u7ed3\u8bba\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4e3a\u975e\u6e10\u8fd1\u7f6e\u4fe1\u533a\u95f4\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u5b9e\u7528\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u975e\u7ebf\u6027\u9884\u6d4b\u6a21\u578b\u3002"}}
{"id": "2506.07092", "pdf": "https://arxiv.org/pdf/2506.07092", "abs": "https://arxiv.org/abs/2506.07092", "authors": ["Joydeb Kumar Sana", "Mohammad M. Masud", "M Sohel Rahman", "M Saifur Rahman"], "title": "Patient Similarity Computation for Clinical Decision Support: An Efficient Use of Data Transformation, Combining Static and Time Series Data", "categories": ["cs.LG", "cs.AI"], "comment": "This paper presents a novel distributed patient similarity\n  computation (DPSC) technique based on data transformation (DT) methods,\n  utilizing an effective combination of time series and static data", "summary": "Patient similarity computation (PSC) is a fundamental problem in healthcare\ninformatics. The aim of the patient similarity computation is to measure the\nsimilarity among patients according to their historical clinical records, which\nhelps to improve clinical decision support. This paper presents a novel\ndistributed patient similarity computation (DPSC) technique based on data\ntransformation (DT) methods, utilizing an effective combination of time series\nand static data. Time series data are sensor-collected patients' information,\nincluding metrics like heart rate, blood pressure, Oxygen saturation,\nrespiration, etc. The static data are mainly patient background and demographic\ndata, including age, weight, height, gender, etc. Static data has been used for\nclustering the patients. Before feeding the static data to the machine learning\nmodel adaptive Weight-of-Evidence (aWOE) and Z-score data transformation (DT)\nmethods have been performed, which improve the prediction performances. In\naWOE-based patient similarity models, sensitive patient information has been\nprocessed using aWOE which preserves the data privacy of the trained models. We\nused the Dynamic Time Warping (DTW) approach, which is robust and very popular,\nfor time series similarity. However, DTW is not suitable for big data due to\nthe significant computational run-time. To overcome this problem, distributed\nDTW computation is used in this study. For Coronary Artery Disease, our DT\nbased approach boosts prediction performance by as much as 11.4%, 10.20%, and\n12.6% in terms of AUC, accuracy, and F-measure, respectively. In the case of\nCongestive Heart Failure (CHF), our proposed method achieves performance\nenhancement up to 15.9%, 10.5%, and 21.9% for the same measures, respectively.\nThe proposed method reduces the computation time by as high as 40%.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6570\u636e\u8f6c\u6362\u65b9\u6cd5\u7684\u5206\u5e03\u5f0f\u60a3\u8005\u76f8\u4f3c\u6027\u8ba1\u7b97\uff08DPSC\uff09\u6280\u672f\uff0c\u7ed3\u5408\u65f6\u95f4\u5e8f\u5217\u548c\u9759\u6001\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u6027\u80fd\u5e76\u51cf\u5c11\u4e86\u8ba1\u7b97\u65f6\u95f4\u3002", "motivation": "\u60a3\u8005\u76f8\u4f3c\u6027\u8ba1\u7b97\uff08PSC\uff09\u662f\u533b\u7597\u4fe1\u606f\u5b66\u4e2d\u7684\u6838\u5fc3\u95ee\u9898\uff0c\u65e8\u5728\u901a\u8fc7\u5386\u53f2\u4e34\u5e8a\u8bb0\u5f55\u8861\u91cf\u60a3\u8005\u76f8\u4f3c\u6027\u4ee5\u652f\u6301\u4e34\u5e8a\u51b3\u7b56\u3002", "method": "\u91c7\u7528\u6570\u636e\u8f6c\u6362\u65b9\u6cd5\uff08aWOE\u548cZ-score\uff09\u5904\u7406\u9759\u6001\u6570\u636e\uff0c\u7ed3\u5408\u52a8\u6001\u65f6\u95f4\u89c4\u6574\uff08DTW\uff09\u5904\u7406\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u5e76\u901a\u8fc7\u5206\u5e03\u5f0f\u8ba1\u7b97\u4f18\u5316DTW\u3002", "result": "\u5728\u51a0\u72b6\u52a8\u8109\u75be\u75c5\u548c\u5145\u8840\u6027\u5fc3\u529b\u8870\u7aed\u7684\u9884\u6d4b\u4e2d\uff0cAUC\u3001\u51c6\u786e\u7387\u548cF-measure\u5206\u522b\u63d0\u5347\u9ad8\u8fbe11.4%-21.9%\uff0c\u8ba1\u7b97\u65f6\u95f4\u51cf\u5c1140%\u3002", "conclusion": "\u63d0\u51fa\u7684DPSC\u65b9\u6cd5\u5728\u9884\u6d4b\u6027\u80fd\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u5747\u6709\u663e\u8457\u63d0\u5347\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u533b\u7597\u6570\u636e\u5206\u6790\u3002"}}
{"id": "2506.07099", "pdf": "https://arxiv.org/pdf/2506.07099", "abs": "https://arxiv.org/abs/2506.07099", "authors": ["Wenying He", "Jieling Huang", "Junhua Gu", "Ji Zhang", "Yude Bai"], "title": "Filling the Missings: Spatiotemporal Data Imputation by Conditional Diffusion", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages,3 figures", "summary": "Missing data in spatiotemporal systems presents a significant challenge for\nmodern applications, ranging from environmental monitoring to urban traffic\nmanagement. The integrity of spatiotemporal data often deteriorates due to\nhardware malfunctions and software failures in real-world deployments. Current\napproaches based on machine learning and deep learning struggle to model the\nintricate interdependencies between spatial and temporal dimensions effectively\nand, more importantly, suffer from cumulative errors during the data imputation\nprocess, which propagate and amplify through iterations. To address these\nlimitations, we propose CoFILL, a novel Conditional Diffusion Model for\nspatiotemporal data imputation. CoFILL builds on the inherent advantages of\ndiffusion models to generate high-quality imputations without relying on\npotentially error-prone prior estimates. It incorporates an innovative\ndual-stream architecture that processes temporal and frequency domain features\nin parallel. By fusing these complementary features, CoFILL captures both rapid\nfluctuations and underlying patterns in the data, which enables more robust\nimputation. The extensive experiments reveal that CoFILL's noise prediction\nnetwork successfully transforms random noise into meaningful values that align\nwith the true data distribution. The results also show that CoFILL outperforms\nstate-of-the-art methods in imputation accuracy. The source code is publicly\navailable at https://github.com/joyHJL/CoFILL.", "AI": {"tldr": "CoFILL\u662f\u4e00\u79cd\u57fa\u4e8e\u6761\u4ef6\u6269\u6563\u6a21\u578b\u7684\u65b0\u578b\u65f6\u7a7a\u6570\u636e\u586b\u8865\u65b9\u6cd5\uff0c\u901a\u8fc7\u53cc\u6d41\u67b6\u6784\u5904\u7406\u65f6\u7a7a\u548c\u9891\u57df\u7279\u5f81\uff0c\u663e\u8457\u63d0\u5347\u4e86\u586b\u8865\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5efa\u6a21\u65f6\u7a7a\u7ef4\u5ea6\u95f4\u7684\u590d\u6742\u4f9d\u8d56\u5173\u7cfb\uff0c\u4e14\u5728\u586b\u8865\u8fc7\u7a0b\u4e2d\u5b58\u5728\u7d2f\u79ef\u8bef\u5dee\u95ee\u9898\u3002", "method": "\u63d0\u51faCoFILL\uff0c\u5229\u7528\u6269\u6563\u6a21\u578b\u7684\u4f18\u52bf\uff0c\u7ed3\u5408\u53cc\u6d41\u67b6\u6784\u5e76\u884c\u5904\u7406\u65f6\u7a7a\u548c\u9891\u57df\u7279\u5f81\u3002", "result": "\u5b9e\u9a8c\u8868\u660eCoFILL\u5728\u586b\u8865\u7cbe\u5ea6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u80fd\u751f\u6210\u4e0e\u771f\u5b9e\u6570\u636e\u5206\u5e03\u4e00\u81f4\u7684\u9ad8\u8d28\u91cf\u586b\u8865\u503c\u3002", "conclusion": "CoFILL\u4e3a\u65f6\u7a7a\u6570\u636e\u586b\u8865\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u9c81\u68d2\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2506.07109", "pdf": "https://arxiv.org/pdf/2506.07109", "abs": "https://arxiv.org/abs/2506.07109", "authors": ["Rong-Xi Tan", "Ming Chen", "Ke Xue", "Yao Wang", "Yaoyuan Wang", "Sheng Fu", "Chao Qian"], "title": "Towards Universal Offline Black-Box Optimization via Learning Language Model Embeddings", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": "ICML 2025", "summary": "The pursuit of universal black-box optimization (BBO) algorithms is a\nlongstanding goal. However, unlike domains such as language or vision, where\nscaling structured data has driven generalization, progress in offline BBO\nremains hindered by the lack of unified representations for heterogeneous\nnumerical spaces. Thus, existing offline BBO approaches are constrained to\nsingle-task and fixed-dimensional settings, failing to achieve cross-domain\nuniversal optimization. Recent advances in language models (LMs) offer a\npromising path forward: their embeddings capture latent relationships in a\nunifying way, enabling universal optimization across different data types\npossible. In this paper, we discuss multiple potential approaches, including an\nend-to-end learning framework in the form of next-token prediction, as well as\nprioritizing the learning of latent spaces with strong representational\ncapabilities. To validate the effectiveness of these methods, we collect\noffline BBO tasks and data from open-source academic works for training.\nExperiments demonstrate the universality and effectiveness of our proposed\nmethods. Our findings suggest that unifying language model priors and learning\nstring embedding space can overcome traditional barriers in universal BBO,\npaving the way for general-purpose BBO algorithms. The code is provided at\nhttps://github.com/lamda-bbo/universal-offline-bbo.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5229\u7528\u8bed\u8a00\u6a21\u578b\u7684\u5d4c\u5165\u80fd\u529b\u5b9e\u73b0\u8de8\u9886\u57df\u901a\u7528\u9ed1\u76d2\u4f18\u5316\uff08BBO\uff09\uff0c\u63d0\u51fa\u4e86\u7aef\u5230\u7aef\u5b66\u4e60\u6846\u67b6\u548c\u6f5c\u5728\u7a7a\u95f4\u5b66\u4e60\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u901a\u7528\u6027\u548c\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edf\u79bb\u7ebfBBO\u65b9\u6cd5\u53d7\u9650\u4e8e\u5355\u4efb\u52a1\u548c\u56fa\u5b9a\u7ef4\u5ea6\uff0c\u7f3a\u4e4f\u7edf\u4e00\u8868\u793a\u65b9\u6cd5\uff0c\u800c\u8bed\u8a00\u6a21\u578b\u7684\u5d4c\u5165\u80fd\u529b\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u63d0\u4f9b\u4e86\u53ef\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u7684\u7aef\u5230\u7aef\u5b66\u4e60\u6846\u67b6\uff08\u5982next-token\u9884\u6d4b\uff09\u548c\u6f5c\u5728\u7a7a\u95f4\u5b66\u4e60\u65b9\u6cd5\uff0c\u5229\u7528\u5f00\u6e90\u6570\u636e\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u6240\u63d0\u65b9\u6cd5\u5728\u901a\u7528\u6027\u548c\u6709\u6548\u6027\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u80fd\u591f\u514b\u670d\u4f20\u7edfBBO\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u7ed3\u5408\u8bed\u8a00\u6a21\u578b\u5148\u9a8c\u548c\u5b66\u4e60\u5b57\u7b26\u4e32\u5d4c\u5165\u7a7a\u95f4\uff0c\u4e3a\u901a\u7528BBO\u7b97\u6cd5\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2506.07121", "pdf": "https://arxiv.org/pdf/2506.07121", "abs": "https://arxiv.org/abs/2506.07121", "authors": ["Ren-Jian Wang", "Ke Xue", "Zeyu Qin", "Ziniu Li", "Sheng Tang", "Hao-Tian Li", "Shengcai Liu", "Chao Qian"], "title": "Quality-Diversity Red-Teaming: Automated Generation of High-Quality and Diverse Attackers for Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": null, "summary": "Ensuring safety of large language models (LLMs) is important. Red teaming--a\nsystematic approach to identifying adversarial prompts that elicit harmful\nresponses from target LLMs--has emerged as a crucial safety evaluation method.\nWithin this framework, the diversity of adversarial prompts is essential for\ncomprehensive safety assessments. We find that previous approaches to\nred-teaming may suffer from two key limitations. First, they often pursue\ndiversity through simplistic metrics like word frequency or sentence embedding\nsimilarity, which may not capture meaningful variation in attack strategies.\nSecond, the common practice of training a single attacker model restricts\ncoverage across potential attack styles and risk categories. This paper\nintroduces Quality-Diversity Red-Teaming (QDRT), a new framework designed to\naddress these limitations. QDRT achieves goal-driven diversity through\nbehavior-conditioned training and implements a behavioral replay buffer in an\nopen-ended manner. Additionally, it trains multiple specialized attackers\ncapable of generating high-quality attacks across diverse styles and risk\ncategories. Our empirical evaluation demonstrates that QDRT generates attacks\nthat are both more diverse and more effective against a wide range of target\nLLMs, including GPT-2, Llama-3, Gemma-2, and Qwen2.5. This work advances the\nfield of LLM safety by providing a systematic and effective approach to\nautomated red-teaming, ultimately supporting the responsible deployment of\nLLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aQDRT\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u73b0\u6709\u7ea2\u961f\u6d4b\u8bd5\u65b9\u6cd5\u5728\u591a\u6837\u6027\u548c\u653b\u51fb\u6548\u679c\u4e0a\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u884c\u4e3a\u6761\u4ef6\u8bad\u7ec3\u548c\u591a\u653b\u51fb\u8005\u6a21\u578b\u63d0\u5347\u653b\u51fb\u7684\u591a\u6837\u6027\u548c\u6709\u6548\u6027\u3002", "motivation": "\u786e\u4fdd\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5b89\u5168\u6027\u81f3\u5173\u91cd\u8981\uff0c\u800c\u73b0\u6709\u7684\u7ea2\u961f\u6d4b\u8bd5\u65b9\u6cd5\u5728\u653b\u51fb\u591a\u6837\u6027\u548c\u8986\u76d6\u8303\u56f4\u4e0a\u5b58\u5728\u4e0d\u8db3\u3002", "method": "QDRT\u6846\u67b6\u901a\u8fc7\u884c\u4e3a\u6761\u4ef6\u8bad\u7ec3\u5b9e\u73b0\u76ee\u6807\u9a71\u52a8\u7684\u591a\u6837\u6027\uff0c\u5e76\u91c7\u7528\u5f00\u653e\u5f0f\u884c\u4e3a\u91cd\u653e\u7f13\u51b2\u533a\uff0c\u540c\u65f6\u8bad\u7ec3\u591a\u4e2a\u4e13\u4e1a\u653b\u51fb\u8005\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cQDRT\u751f\u6210\u7684\u653b\u51fb\u5728\u591a\u6837\u6027\u548c\u6709\u6548\u6027\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u76ee\u6807LLM\u3002", "conclusion": "QDRT\u4e3aLLM\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u4e00\u79cd\u7cfb\u7edf\u4e14\u9ad8\u6548\u7684\u7ea2\u961f\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u652f\u6301LLM\u7684\u8d1f\u8d23\u4efb\u90e8\u7f72\u3002"}}
{"id": "2506.07134", "pdf": "https://arxiv.org/pdf/2506.07134", "abs": "https://arxiv.org/abs/2506.07134", "authors": ["Eshwar S. R.", "Gugan Thoppe", "Aditya Gopalan", "Gal Dalal"], "title": "Reliable Critics: Monotonic Improvement and Convergence Guarantees for Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "math.OC", "90C40 (Primary), 93E20, 68T05 (Secondary)", "I.2.6; G.3"], "comment": "19 pages", "summary": "Despite decades of research, it remains challenging to correctly use\nReinforcement Learning (RL) algorithms with function approximation. A prime\nexample is policy iteration, whose fundamental guarantee of monotonic\nimprovement collapses even under linear function approximation. To address this\nissue, we introduce Reliable Policy Iteration (RPI). It replaces the common\nprojection or Bellman-error minimization during policy evaluation with a\nBellman-based constrained optimization. We prove that not only does RPI confer\ntextbook monotonicity on its value estimates but these estimates also lower\nbound the true return. Also, their limit partially satisfies the unprojected\nBellman equation, emphasizing RPI's natural fit within RL. RPI is the first\nalgorithm with such monotonicity and convergence guarantees under function\napproximation. For practical use, we provide a model-free variant of RPI that\namounts to a novel critic. It can be readily integrated into primary model-free\nPI implementations such as DQN and DDPG. In classical control tasks, such\nRPI-enhanced variants consistently maintain their lower-bound guarantee while\nmatching or surpassing the performance of all baseline methods.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u53ef\u9760\u7b56\u7565\u8fed\u4ee3\uff08RPI\uff09\u7684\u65b0\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e86\u5f3a\u5316\u5b66\u4e60\u4e2d\u51fd\u6570\u903c\u8fd1\u4e0b\u7b56\u7565\u8fed\u4ee3\u7684\u5355\u8c03\u6027\u4fdd\u8bc1\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5728\u51fd\u6570\u903c\u8fd1\u4e0b\u65e0\u6cd5\u4fdd\u8bc1\u7b56\u7565\u8fed\u4ee3\u7684\u5355\u8c03\u6027\u6539\u8fdb\uff0cRPI\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "RPI\u901a\u8fc7\u57fa\u4e8e\u8d1d\u5c14\u66fc\u7684\u7ea6\u675f\u4f18\u5316\u66ff\u4ee3\u4f20\u7edf\u7684\u6295\u5f71\u6216\u8d1d\u5c14\u66fc\u8bef\u5dee\u6700\u5c0f\u5316\uff0c\u786e\u4fdd\u503c\u4f30\u8ba1\u7684\u5355\u8c03\u6027\u548c\u4e0b\u754c\u4fdd\u8bc1\u3002", "result": "RPI\u5728\u7ecf\u5178\u63a7\u5236\u4efb\u52a1\u4e2d\u4e0d\u4ec5\u4fdd\u6301\u4e86\u4e0b\u754c\u4fdd\u8bc1\uff0c\u8fd8\u5339\u914d\u6216\u8d85\u8d8a\u4e86\u57fa\u7ebf\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "conclusion": "RPI\u662f\u9996\u4e2a\u5728\u51fd\u6570\u903c\u8fd1\u4e0b\u5177\u6709\u5355\u8c03\u6027\u548c\u6536\u655b\u6027\u4fdd\u8bc1\u7684\u7b97\u6cd5\uff0c\u9002\u7528\u4e8e\u6a21\u578b\u65e0\u5173\u7684\u5f3a\u5316\u5b66\u4e60\u5b9e\u73b0\u3002"}}
{"id": "2506.07165", "pdf": "https://arxiv.org/pdf/2506.07165", "abs": "https://arxiv.org/abs/2506.07165", "authors": ["Qi Liu", "Jingqing Ruan", "Hao Li", "Haodong Zhao", "Desheng Wang", "Jiansong Chen", "Wan Guanglu", "Xunliang Cai", "Zhi Zheng", "Tong Xu"], "title": "AMoPO: Adaptive Multi-objective Preference Optimization without Reward Models and Reference Models", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by ACL 2025", "summary": "Existing multi-objective preference alignment methods for large language\nmodels (LLMs) face limitations: (1) the inability to effectively balance\nvarious preference dimensions, and (2) reliance on auxiliary reward/reference\nmodels introduces computational complexity. To address these challenges, we\npropose Adaptive Multi-objective Preference Optimization (AMoPO), a novel\nframework that achieves dynamic balance across preference dimensions. By\nintroducing the multi-objective optimization paradigm to use the\ndimension-aware generation metrics as implicit rewards, AMoPO aligns LLMs with\ndiverse preferences without additional reward models or reference models. We\nintroduce an adaptive weight assignment mechanism that models the generation\nspace as a Gaussian distribution, allowing dynamic prioritization of preference\ndimensions. Empirical results demonstrate that AMoPO outperforms\nstate-of-the-art baselines by 28.5%, and the experiments on 7B, 14B, and 32B\nmodels reveal the scaling ability of AMoPO. Moreover, additional analysis of\nmultiple dimensions verifies its adaptability and effectiveness. These findings\nvalidate AMoPO's capability to achieve dimension-aware preference alignment,\nhighlighting its superiority. Our codes and datasets are available at\nhttps://github.com/Javkonline/AMoPO.", "AI": {"tldr": "AMoPO\u662f\u4e00\u79cd\u65b0\u578b\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u5e73\u8861\u591a\u76ee\u6807\u504f\u597d\u4f18\u5316\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u5e73\u8861\u504f\u597d\u7ef4\u5ea6\u548c\u8ba1\u7b97\u590d\u6742\u6027\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u5e73\u8861\u591a\u76ee\u6807\u504f\u597d\uff0c\u4e14\u4f9d\u8d56\u8f85\u52a9\u6a21\u578b\u589e\u52a0\u4e86\u8ba1\u7b97\u590d\u6742\u6027\u3002", "method": "\u5f15\u5165\u591a\u76ee\u6807\u4f18\u5316\u8303\u5f0f\uff0c\u4f7f\u7528\u7ef4\u5ea6\u611f\u77e5\u751f\u6210\u6307\u6807\u4f5c\u4e3a\u9690\u5f0f\u5956\u52b1\uff0c\u65e0\u9700\u989d\u5916\u5956\u52b1\u6a21\u578b\u6216\u53c2\u8003\u6a21\u578b\u3002\u901a\u8fc7\u81ea\u9002\u5e94\u6743\u91cd\u5206\u914d\u673a\u5236\u52a8\u6001\u4f18\u5148\u5904\u7406\u504f\u597d\u7ef4\u5ea6\u3002", "result": "AMoPO\u57287B\u300114B\u548c32B\u6a21\u578b\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd528.5%\uff0c\u9a8c\u8bc1\u4e86\u5176\u6269\u5c55\u6027\u548c\u9002\u5e94\u6027\u3002", "conclusion": "AMoPO\u80fd\u591f\u5b9e\u73b0\u7ef4\u5ea6\u611f\u77e5\u7684\u504f\u597d\u5bf9\u9f50\uff0c\u5c55\u793a\u4e86\u5176\u4f18\u8d8a\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2506.07168", "pdf": "https://arxiv.org/pdf/2506.07168", "abs": "https://arxiv.org/abs/2506.07168", "authors": ["Huanyi Xie", "Lijie Hu", "Lu Yu", "Tianhao Huang", "Longfei Li", "Meng Li", "Jun Zhou", "Huan Wang", "Di Wang"], "title": "Efficient Text-Attributed Graph Learning through Selective Annotation and Graph Alignment", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "23 pages", "summary": "In the realm of Text-attributed Graphs (TAGs), traditional graph neural\nnetworks (GNNs) often fall short due to the complex textual information\nassociated with each node. Recent methods have improved node representations by\nleveraging large language models (LLMs) to enhance node text features, but\nthese approaches typically require extensive annotations or fine-tuning across\nall nodes, which is both time-consuming and costly. To overcome these\nchallenges, we introduce GAGA, an efficient framework for TAG representation\nlearning. GAGA reduces annotation time and cost by focusing on annotating only\nrepresentative nodes and edges. It constructs an annotation graph that captures\nthe topological relationships among these annotations. Furthermore, GAGA\nemploys a two-level alignment module to effectively integrate the annotation\ngraph with the TAG, aligning their underlying structures. Experiments show that\nGAGA achieves classification accuracies on par with or surpassing\nstate-of-the-art methods while requiring only 1% of the data to be annotated,\ndemonstrating its high efficiency.", "AI": {"tldr": "GAGA\u662f\u4e00\u4e2a\u9ad8\u6548\u7684TAG\u8868\u793a\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u4ec5\u6807\u6ce8\u4ee3\u8868\u6027\u8282\u70b9\u548c\u8fb9\u6765\u51cf\u5c11\u65f6\u95f4\u548c\u6210\u672c\uff0c\u5e76\u901a\u8fc7\u4e24\u7ea7\u5bf9\u9f50\u6a21\u5757\u6574\u5408\u6807\u6ce8\u56fe\u4e0eTAG\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u4e14\u4ec5\u97001%\u7684\u6807\u6ce8\u6570\u636e\u3002", "motivation": "\u4f20\u7edfGNN\u5728\u5904\u7406TAG\u65f6\u56e0\u590d\u6742\u6587\u672c\u4fe1\u606f\u8868\u73b0\u4e0d\u4f73\uff0c\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u5927\u91cf\u6807\u6ce8\u6216\u5fae\u8c03\uff0c\u6210\u672c\u9ad8\u4e14\u8017\u65f6\u3002", "method": "GAGA\u901a\u8fc7\u6807\u6ce8\u4ee3\u8868\u6027\u8282\u70b9\u548c\u8fb9\u6784\u5efa\u6807\u6ce8\u56fe\uff0c\u5e76\u91c7\u7528\u4e24\u7ea7\u5bf9\u9f50\u6a21\u5757\u5c06\u5176\u4e0eTAG\u7ed3\u6784\u5bf9\u9f50\u3002", "result": "GAGA\u5728\u5206\u7c7b\u51c6\u786e\u7387\u4e0a\u8fbe\u5230\u6216\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u4ec5\u97001%\u7684\u6807\u6ce8\u6570\u636e\u3002", "conclusion": "GAGA\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u4f4e\u6210\u672c\u7684TAG\u8868\u793a\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.07179", "pdf": "https://arxiv.org/pdf/2506.07179", "abs": "https://arxiv.org/abs/2506.07179", "authors": ["Kaiqi Wu", "Weiyang Kong", "Sen Zhang", "Yubao Liu", "Zitong Chen"], "title": "Regularized Adaptive Graph Learning for Large-Scale Traffic Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Traffic prediction is a critical task in spatial-temporal forecasting with\nbroad applications in travel planning and urban management. Adaptive graph\nconvolution networks have emerged as mainstream solutions due to their ability\nto learn node embeddings in a data-driven manner and capture complex latent\ndependencies. However, existing adaptive graph learning methods for traffic\nforecasting often either ignore the regularization of node embeddings, which\naccount for a significant proportion of model parameters, or face scalability\nissues from expensive graph convolution operations. To address these\nchallenges, we propose a Regularized Adaptive Graph Learning (RAGL) model.\nFirst, we introduce a regularized adaptive graph learning framework that\nsynergizes Stochastic Shared Embedding (SSE) and adaptive graph convolution via\na residual difference mechanism, achieving both embedding regularization and\nnoise suppression. Second, to ensure scalability on large road networks, we\ndevelop the Efficient Cosine Operator (ECO), which performs graph convolution\nbased on the cosine similarity of regularized embeddings with linear time\ncomplexity. Extensive experiments on four large-scale real-world traffic\ndatasets show that RAGL consistently outperforms state-of-the-art methods in\nterms of prediction accuracy and exhibits competitive computational efficiency.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6b63\u5219\u5316\u81ea\u9002\u5e94\u56fe\u5b66\u4e60\uff08RAGL\uff09\u6a21\u578b\uff0c\u901a\u8fc7\u7ed3\u5408\u968f\u673a\u5171\u4eab\u5d4c\u5165\uff08SSE\uff09\u548c\u6b8b\u5dee\u5dee\u5f02\u673a\u5236\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u4ea4\u901a\u9884\u6d4b\u65b9\u6cd5\u4e2d\u8282\u70b9\u5d4c\u5165\u6b63\u5219\u5316\u4e0d\u8db3\u548c\u8ba1\u7b97\u6548\u7387\u4f4e\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u81ea\u9002\u5e94\u56fe\u5b66\u4e60\u65b9\u6cd5\u5728\u4ea4\u901a\u9884\u6d4b\u4e2d\u5e38\u5ffd\u7565\u8282\u70b9\u5d4c\u5165\u7684\u6b63\u5219\u5316\u6216\u9762\u4e34\u8ba1\u7b97\u6548\u7387\u4f4e\u7684\u6311\u6218\uff0c\u5f71\u54cd\u4e86\u6a21\u578b\u7684\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027\u3002", "method": "\u63d0\u51faRAGL\u6a21\u578b\uff0c\u7ed3\u5408SSE\u548c\u6b8b\u5dee\u5dee\u5f02\u673a\u5236\u5b9e\u73b0\u5d4c\u5165\u6b63\u5219\u5316\u548c\u566a\u58f0\u6291\u5236\uff1b\u5f00\u53d1\u9ad8\u6548\u4f59\u5f26\u7b97\u5b50\uff08ECO\uff09\u4ee5\u7ebf\u6027\u65f6\u95f4\u590d\u6742\u5ea6\u5b8c\u6210\u56fe\u5377\u79ef\u3002", "result": "\u5728\u56db\u4e2a\u5927\u89c4\u6a21\u771f\u5b9e\u4ea4\u901a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cRAGL\u5728\u9884\u6d4b\u7cbe\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "RAGL\u901a\u8fc7\u6b63\u5219\u5316\u548c\u9ad8\u6548\u8ba1\u7b97\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ea4\u901a\u9884\u6d4b\u7684\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2506.07185", "pdf": "https://arxiv.org/pdf/2506.07185", "abs": "https://arxiv.org/abs/2506.07185", "authors": ["J. C. Husillos", "A. Gallego", "A. Roma", "A. Troncoso"], "title": "Learning based on neurovectors for tabular data: a new neural network approach", "categories": ["cs.LG"], "comment": "Submitted to 25th IEEE International Conference on Data Mining (ICDM\n  2025)", "summary": "In this paper, we present a novel learning approach based on Neurovectors, an\ninnovative paradigm that structures information through interconnected nodes\nand vector relationships for tabular data processing. Unlike traditional\nartificial neural networks that rely on weight adjustment through\nbackpropagation, Neurovectors encode information by structuring data in vector\nspaces where energy propagation, rather than traditional weight updates, drives\nthe learning process, enabling a more adaptable and explainable learning\nprocess. Our method generates dynamic representations of knowledge through\nneurovectors, thereby improving both the interpretability and efficiency of the\npredictive model. Experimental results using datasets from well-established\nrepositories such as the UCI machine learning repository and Kaggle are\nreported both for classification and regression. To evaluate its performance,\nwe compare our approach with standard machine learning and deep learning\nmodels, showing that Neurovectors achieve competitive accuracy.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eNeurovectors\u7684\u65b0\u578b\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5411\u91cf\u5173\u7cfb\u548c\u80fd\u91cf\u4f20\u64ad\u5b9e\u73b0\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u5b66\u4e60\u3002", "motivation": "\u4f20\u7edf\u795e\u7ecf\u7f51\u7edc\u4f9d\u8d56\u53cd\u5411\u4f20\u64ad\u8c03\u6574\u6743\u91cd\uff0c\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u548c\u9002\u5e94\u6027\uff0cNeurovectors\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u5229\u7528Neurovectors\u5728\u5411\u91cf\u7a7a\u95f4\u4e2d\u7ed3\u6784\u5316\u6570\u636e\uff0c\u901a\u8fc7\u80fd\u91cf\u4f20\u64ad\u9a71\u52a8\u5b66\u4e60\uff0c\u751f\u6210\u52a8\u6001\u77e5\u8bc6\u8868\u793a\u3002", "result": "\u5728UCI\u548cKaggle\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cNeurovectors\u5728\u5206\u7c7b\u548c\u56de\u5f52\u4efb\u52a1\u4e2d\u5177\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "Neurovectors\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u89e3\u91ca\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002"}}
{"id": "2506.07191", "pdf": "https://arxiv.org/pdf/2506.07191", "abs": "https://arxiv.org/abs/2506.07191", "authors": ["Ramisa Farha", "Joshua O. Olukoya"], "title": "Analyzing Breast Cancer Survival Disparities by Race and Demographic Location: A Survival Analysis Approach", "categories": ["cs.LG", "stat.AP"], "comment": null, "summary": "This study employs a robust analytical framework to uncover patterns in\nsurvival outcomes among breast cancer patients from diverse racial and\ngeographical backgrounds. This research uses the SEER 2021 dataset to analyze\nbreast cancer survival outcomes to identify and comprehend dissimilarities. Our\napproach integrates exploratory data analysis (EDA), through this we identify\nkey variables that influence survival rates and employ survival analysis\ntechniques, including the Kaplan-Meier estimator and log-rank test and the\nadvanced modeling Cox Proportional Hazards model to determine how survival\nrates vary across racial groups and countries. Model validation and\ninterpretation are undertaken to ensure the reliability of our findings, which\nare documented comprehensively to inform policymakers and healthcare\nprofessionals. The outcome of this paper is a detailed version of statistical\nanalysis that not just highlights disparities in breast cancer treatment and\ncare but also serves as a foundational tool for developing targeted\ninterventions to address the inequalities effectively. Through this research,\nour aim is to contribute to the global efforts to improve breast cancer\noutcomes and reduce treatment disparities.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7SEER 2021\u6570\u636e\u96c6\u548c\u751f\u5b58\u5206\u6790\u6280\u672f\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u79cd\u65cf\u548c\u5730\u533a\u4e73\u817a\u764c\u60a3\u8005\u751f\u5b58\u7ed3\u679c\u7684\u5dee\u5f02\uff0c\u4e3a\u653f\u7b56\u5236\u5b9a\u548c\u533b\u7597\u5e72\u9884\u63d0\u4f9b\u4f9d\u636e\u3002", "motivation": "\u65e8\u5728\u63ed\u793a\u4e73\u817a\u764c\u60a3\u8005\u751f\u5b58\u7ed3\u679c\u7684\u79cd\u65cf\u548c\u5730\u533a\u5dee\u5f02\uff0c\u4e3a\u51cf\u5c11\u6cbb\u7597\u4e0d\u5e73\u7b49\u63d0\u4f9b\u6570\u636e\u652f\u6301\u3002", "method": "\u7ed3\u5408\u63a2\u7d22\u6027\u6570\u636e\u5206\u6790\uff08EDA\uff09\u3001Kaplan-Meier\u4f30\u8ba1\u3001log-rank\u68c0\u9a8c\u548cCox\u6bd4\u4f8b\u98ce\u9669\u6a21\u578b\u8fdb\u884c\u5206\u6790\u3002", "result": "\u8be6\u7ec6\u7edf\u8ba1\u4e86\u4e73\u817a\u764c\u751f\u5b58\u7387\u7684\u79cd\u65cf\u548c\u5730\u533a\u5dee\u5f02\uff0c\u4e3a\u9488\u5bf9\u6027\u5e72\u9884\u63d0\u4f9b\u57fa\u7840\u3002", "conclusion": "\u7814\u7a76\u4e3a\u6539\u5584\u4e73\u817a\u764c\u6cbb\u7597\u7ed3\u679c\u548c\u51cf\u5c11\u4e0d\u5e73\u7b49\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u548c\u53c2\u8003\u3002"}}
{"id": "2506.07198", "pdf": "https://arxiv.org/pdf/2506.07198", "abs": "https://arxiv.org/abs/2506.07198", "authors": ["Tianci Bu", "Chuanrui Wang", "Hao Ma", "Haoren Zheng", "Xin Lu", "Tailin Wu"], "title": "GGBall: Graph Generative Model on Poincar\u00e9 Ball", "categories": ["cs.LG"], "comment": "29 pages, 3 figures", "summary": "Generating graphs with hierarchical structures remains a fundamental\nchallenge due to the limitations of Euclidean geometry in capturing exponential\ncomplexity. Here we introduce \\textbf{GGBall}, a novel hyperbolic framework for\ngraph generation that integrates geometric inductive biases with modern\ngenerative paradigms. GGBall combines a Hyperbolic Vector-Quantized Autoencoder\n(HVQVAE) with a Riemannian flow matching prior defined via closed-form\ngeodesics. This design enables flow-based priors to model complex latent\ndistributions, while vector quantization helps preserve the curvature-aware\nstructure of the hyperbolic space. We further develop a suite of hyperbolic GNN\nand Transformer layers that operate entirely within the manifold, ensuring\nstability and scalability. Empirically, our model reduces degree MMD by over\n75\\% on Community-Small and over 40\\% on Ego-Small compared to state-of-the-art\nbaselines, demonstrating an improved ability to preserve topological\nhierarchies. These results highlight the potential of hyperbolic geometry as a\npowerful foundation for the generative modeling of complex, structured, and\nhierarchical data domains. Our code is available at\n\\href{https://github.com/AI4Science-WestlakeU/GGBall}{here}.", "AI": {"tldr": "GGBall\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53cc\u66f2\u51e0\u4f55\u7684\u56fe\u751f\u6210\u6846\u67b6\uff0c\u7ed3\u5408\u4e86HVQVAE\u548c\u9ece\u66fc\u6d41\u5339\u914d\u5148\u9a8c\uff0c\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u56fe\u7684\u5c42\u6b21\u7ed3\u6784\u4fdd\u6301\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3\u6b27\u51e0\u91cc\u5f97\u51e0\u4f55\u5728\u6355\u6349\u6307\u6570\u590d\u6742\u5ea6\u65f6\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u751f\u6210\u5177\u6709\u5c42\u6b21\u7ed3\u6784\u7684\u56fe\u63d0\u4f9b\u65b0\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408\u53cc\u66f2\u5411\u91cf\u91cf\u5316\u81ea\u7f16\u7801\u5668\uff08HVQVAE\uff09\u4e0e\u57fa\u4e8e\u95ed\u5f0f\u6d4b\u5730\u7ebf\u7684\u9ece\u66fc\u6d41\u5339\u914d\u5148\u9a8c\uff0c\u5f00\u53d1\u4e86\u53cc\u66f2GNN\u548cTransformer\u5c42\u3002", "result": "\u5728Community-Small\u548cEgo-Small\u6570\u636e\u96c6\u4e0a\uff0c\u5ea6\u6570MMD\u5206\u522b\u964d\u4f4e\u4e8675%\u548c40%\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u53cc\u66f2\u51e0\u4f55\u4e3a\u590d\u6742\u3001\u7ed3\u6784\u5316\u4e14\u5c42\u6b21\u5316\u7684\u6570\u636e\u751f\u6210\u63d0\u4f9b\u4e86\u5f3a\u5927\u57fa\u7840\u3002"}}
{"id": "2506.07218", "pdf": "https://arxiv.org/pdf/2506.07218", "abs": "https://arxiv.org/abs/2506.07218", "authors": ["Tong Xiao", "Xin Xu", "Zhenya Huang", "Hongyu Gao", "Quan Liu", "Qi Liu", "Enhong Chen"], "title": "Advancing Multimodal Reasoning Capabilities of Multimodal Large Language Models via Visual Perception Reward", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Enhancing the multimodal reasoning capabilities of Multimodal Large Language\nModels (MLLMs) is a challenging task that has attracted increasing attention in\nthe community. Recently, several studies have applied Reinforcement Learning\nwith Verifiable Rewards (RLVR) to the multimodal domain in order to enhance the\nreasoning abilities of MLLMs. However, these works largely overlook the\nenhancement of multimodal perception capabilities in MLLMs, which serve as a\ncore prerequisite and foundational component of complex multimodal reasoning.\nThrough McNemar's test, we find that existing RLVR method fails to effectively\nenhance the multimodal perception capabilities of MLLMs, thereby limiting their\nfurther improvement in multimodal reasoning. To address this limitation, we\npropose Perception-R1, which introduces a novel visual perception reward that\nexplicitly encourages MLLMs to perceive the visual content accurately, thereby\ncan effectively incentivizing both their multimodal perception and reasoning\ncapabilities. Specifically, we first collect textual visual annotations from\nthe CoT trajectories of multimodal problems, which will serve as visual\nreferences for reward assignment. During RLVR training, we employ a judging LLM\nto assess the consistency between the visual annotations and the responses\ngenerated by MLLM, and assign the visual perception reward based on these\nconsistency judgments. Extensive experiments on several multimodal reasoning\nbenchmarks demonstrate the effectiveness of our Perception-R1, which achieves\nstate-of-the-art performance on most benchmarks using only 1,442 training data.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faPerception-R1\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u89c6\u89c9\u611f\u77e5\u5956\u52b1\u63d0\u5347\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u7684\u611f\u77e5\u548c\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709RLVR\u65b9\u6cd5\u672a\u80fd\u6709\u6548\u589e\u5f3aMLLMs\u7684\u591a\u6a21\u6001\u611f\u77e5\u80fd\u529b\uff0c\u9650\u5236\u4e86\u5176\u63a8\u7406\u80fd\u529b\u7684\u8fdb\u4e00\u6b65\u63d0\u5347\u3002", "method": "\u63d0\u51faPerception-R1\uff0c\u901a\u8fc7\u89c6\u89c9\u611f\u77e5\u5956\u52b1\u6fc0\u52b1MLLMs\u51c6\u786e\u611f\u77e5\u89c6\u89c9\u5185\u5bb9\uff0c\u5e76\u5229\u7528LLM\u8bc4\u4f30\u89c6\u89c9\u6ce8\u91ca\u4e0e\u6a21\u578b\u54cd\u5e94\u7684\u4e00\u81f4\u6027\u3002", "result": "\u5728\u591a\u4e2a\u591a\u6a21\u6001\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cPerception-R1\u4ec5\u75281,442\u4e2a\u8bad\u7ec3\u6570\u636e\u5373\u8fbe\u5230\u6700\u4f18\u6027\u80fd\u3002", "conclusion": "Perception-R1\u6709\u6548\u63d0\u5347\u4e86MLLMs\u7684\u611f\u77e5\u548c\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u591a\u6a21\u6001\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.07229", "pdf": "https://arxiv.org/pdf/2506.07229", "abs": "https://arxiv.org/abs/2506.07229", "authors": ["Mateusz Gajewski", "Miko\u0142aj Morzy", "Adam Karczmarz", "Piotr Sankowski"], "title": "VARSHAP: Addressing Global Dependency Problems in Explainable AI with Variance-Based Local Feature Attribution", "categories": ["cs.LG"], "comment": null, "summary": "Existing feature attribution methods like SHAP often suffer from global\ndependence, failing to capture true local model behavior. This paper introduces\nVARSHAP, a novel model-agnostic local feature attribution method which uses the\nreduction of prediction variance as the key importance metric of features.\nBuilding upon Shapley value framework, VARSHAP satisfies the key Shapley\naxioms, but, unlike SHAP, is resilient to global data distribution shifts.\nExperiments on synthetic and real-world datasets demonstrate that VARSHAP\noutperforms popular methods such as KernelSHAP or LIME, both quantitatively and\nqualitatively.", "AI": {"tldr": "VARSHAP\u662f\u4e00\u79cd\u65b0\u7684\u6a21\u578b\u65e0\u5173\u5c40\u90e8\u7279\u5f81\u5f52\u56e0\u65b9\u6cd5\uff0c\u901a\u8fc7\u51cf\u5c11\u9884\u6d4b\u65b9\u5dee\u4f5c\u4e3a\u7279\u5f81\u91cd\u8981\u6027\u6307\u6807\uff0c\u4f18\u4e8eSHAP\u548cLIME\u3002", "motivation": "\u73b0\u6709\u7279\u5f81\u5f52\u56e0\u65b9\u6cd5\uff08\u5982SHAP\uff09\u5b58\u5728\u5168\u5c40\u4f9d\u8d56\u95ee\u9898\uff0c\u65e0\u6cd5\u51c6\u786e\u6355\u6349\u5c40\u90e8\u6a21\u578b\u884c\u4e3a\u3002", "method": "\u57fa\u4e8eShapley\u503c\u6846\u67b6\uff0cVARSHAP\u4ee5\u9884\u6d4b\u65b9\u5dee\u51cf\u5c11\u4e3a\u6838\u5fc3\u6307\u6807\uff0c\u6ee1\u8db3Shapley\u516c\u7406\u4e14\u5bf9\u5168\u5c40\u6570\u636e\u5206\u5e03\u53d8\u5316\u9c81\u68d2\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0cVARSHAP\u5728\u5b9a\u91cf\u548c\u5b9a\u6027\u4e0a\u5747\u4f18\u4e8eKernelSHAP\u548cLIME\u3002", "conclusion": "VARSHAP\u662f\u4e00\u79cd\u66f4\u51c6\u786e\u4e14\u9c81\u68d2\u7684\u5c40\u90e8\u7279\u5f81\u5f52\u56e0\u65b9\u6cd5\u3002"}}
{"id": "2506.07240", "pdf": "https://arxiv.org/pdf/2506.07240", "abs": "https://arxiv.org/abs/2506.07240", "authors": ["Roy Eisenstadt", "Itamar Zimerman", "Lior Wolf"], "title": "Overclocking LLM Reasoning: Monitoring and Controlling Thinking Path Lengths in LLMs", "categories": ["cs.LG", "cs.AI", "I.2.6; I.2.7"], "comment": null, "summary": "Recently, techniques such as explicit structured reasoning have demonstrated\nstrong test-time scaling behavior by enforcing a separation between the model's\ninternal \"thinking\" process and the final response. A key factor influencing\nanswer quality in this setting is the length of the thinking stage. When the\nreasoning is too short, the model may fail to capture the complexity of the\ntask. Conversely, when it is too long, the model may overthink, leading to\nunnecessary computation and degraded performance. This paper explores and\nexploits the underlying mechanisms by which LLMs understand and regulate the\nlength of their reasoning during explicit thought processes. First, we show\nthat LLMs encode their progress through the reasoning process and introduce an\ninteractive progress bar visualization, which is then used to reveal insights\non the model's planning dynamics. Second, we manipulate the internal progress\nencoding during inference to reduce unnecessary steps and generate a more\nconcise and decisive chain of thoughts. Our empirical results demonstrate that\nthis \"overclocking\" method mitigates overthinking, improves answer accuracy,\nand reduces inference latency. Our code is publicly available.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86LLMs\u5728\u663e\u5f0f\u7ed3\u6784\u5316\u63a8\u7406\u4e2d\u5982\u4f55\u7406\u89e3\u548c\u8c03\u8282\u63a8\u7406\u957f\u5ea6\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u53ef\u89c6\u5316\u8fdb\u5ea6\u6761\u548c\u64cd\u7eb5\u5185\u90e8\u8fdb\u5ea6\u7f16\u7801\u6765\u4f18\u5316\u63a8\u7406\u8fc7\u7a0b\u7684\u65b9\u6cd5\uff0c\u4ee5\u51cf\u5c11\u4e0d\u5fc5\u8981\u7684\u6b65\u9aa4\u5e76\u63d0\u9ad8\u6027\u80fd\u3002", "motivation": "\u663e\u5f0f\u7ed3\u6784\u5316\u63a8\u7406\u4e2d\uff0c\u63a8\u7406\u957f\u5ea6\u5bf9\u7b54\u6848\u8d28\u91cf\u6709\u91cd\u8981\u5f71\u54cd\uff1a\u8fc7\u77ed\u53ef\u80fd\u65e0\u6cd5\u6355\u6349\u4efb\u52a1\u590d\u6742\u6027\uff0c\u8fc7\u957f\u5219\u53ef\u80fd\u5bfc\u81f4\u8fc7\u5ea6\u601d\u8003\u548c\u6027\u80fd\u4e0b\u964d\u3002", "method": "1. \u5c55\u793aLLMs\u5982\u4f55\u7f16\u7801\u63a8\u7406\u8fdb\u5ea6\uff0c\u5e76\u5f15\u5165\u4ea4\u4e92\u5f0f\u8fdb\u5ea6\u6761\u53ef\u89c6\u5316\uff1b2. \u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u64cd\u7eb5\u5185\u90e8\u8fdb\u5ea6\u7f16\u7801\u4ee5\u51cf\u5c11\u5197\u4f59\u6b65\u9aa4\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u51cf\u5c11\u8fc7\u5ea6\u601d\u8003\uff0c\u63d0\u9ad8\u7b54\u6848\u51c6\u786e\u6027\uff0c\u5e76\u964d\u4f4e\u63a8\u7406\u5ef6\u8fdf\u3002", "conclusion": "\u901a\u8fc7\u4f18\u5316\u63a8\u7406\u957f\u5ea6\uff0cLLMs\u53ef\u4ee5\u5728\u663e\u5f0f\u7ed3\u6784\u5316\u63a8\u7406\u4e2d\u66f4\u9ad8\u6548\u5730\u5b8c\u6210\u4efb\u52a1\u3002"}}
{"id": "2506.07247", "pdf": "https://arxiv.org/pdf/2506.07247", "abs": "https://arxiv.org/abs/2506.07247", "authors": ["Ngoc-Quan Pham", "Tuan Truong", "Quyen Tran", "Tan Nguyen", "Dinh Phung", "Trung Le"], "title": "Promoting Ensemble Diversity with Interactive Bayesian Distributional Robustness for Fine-tuning Foundation Models", "categories": ["cs.LG"], "comment": "ICML 2025 (Poster)", "summary": "We introduce Interactive Bayesian Distributional Robustness (IBDR), a novel\nBayesian inference framework that allows modeling the interactions between\nparticles, thereby enhancing ensemble quality through increased particle\ndiversity. IBDR is grounded in a generalized theoretical framework that\nconnects the distributional population loss with the approximate posterior,\nmotivating a practical dual optimization procedure that enforces distributional\nrobustness while fostering particle diversity. We evaluate IBDR's performance\nagainst various baseline methods using the VTAB-1K benchmark and the common\nreasoning language task. The results consistently show that IBDR outperforms\nthese baselines, underscoring its effectiveness in real-world applications.", "AI": {"tldr": "IBDR\u662f\u4e00\u79cd\u65b0\u578b\u8d1d\u53f6\u65af\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u589e\u5f3a\u7c92\u5b50\u591a\u6837\u6027\u63d0\u5347\u96c6\u6210\u8d28\u91cf\uff0c\u5e76\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u901a\u8fc7\u5efa\u6a21\u7c92\u5b50\u95f4\u4ea4\u4e92\u4f5c\u7528\uff0c\u63d0\u5347\u8d1d\u53f6\u65af\u63a8\u7406\u7684\u5206\u5e03\u9c81\u68d2\u6027\u548c\u7c92\u5b50\u591a\u6837\u6027\u3002", "method": "IBDR\u57fa\u4e8e\u5e7f\u4e49\u7406\u8bba\u6846\u67b6\uff0c\u8fde\u63a5\u5206\u5e03\u603b\u4f53\u635f\u5931\u4e0e\u8fd1\u4f3c\u540e\u9a8c\uff0c\u91c7\u7528\u53cc\u91cd\u4f18\u5316\u7a0b\u5e8f\u5b9e\u73b0\u5206\u5e03\u9c81\u68d2\u6027\u548c\u7c92\u5b50\u591a\u6837\u6027\u3002", "result": "\u5728VTAB-1K\u57fa\u51c6\u6d4b\u8bd5\u548c\u8bed\u8a00\u63a8\u7406\u4efb\u52a1\u4e2d\uff0cIBDR\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "IBDR\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2506.07254", "pdf": "https://arxiv.org/pdf/2506.07254", "abs": "https://arxiv.org/abs/2506.07254", "authors": ["Kevin Frans", "Sergey Levine", "Pieter Abbeel"], "title": "A Stable Whitening Optimizer for Efficient Neural Network Training", "categories": ["cs.LG"], "comment": null, "summary": "In this work, we take an experimentally grounded look at neural network\noptimization. Building on the Shampoo family of algorithms, we identify and\nalleviate three key issues, resulting in the proposed SPlus method. First, we\nfind that naive Shampoo is prone to divergence when matrix-inverses are cached\nfor long periods. We introduce an alternate bounded update combining a\nhistorical eigenbasis with instantaneous normalization, resulting in\nacross-the-board stability and significantly lower computational requirements.\nSecond, we adapt a shape-aware scaling to enable learning rate transfer across\nnetwork width. Third, we find that high learning rates result in large\nparameter noise, and propose a simple iterate-averaging scheme which unblocks\nfaster learning. To properly confirm these findings, we introduce a pointed\nTransformer training benchmark, considering three objectives (language\nmodelling, image classification, and diffusion modelling) across different\nstages of training. On average, SPlus is able to reach the validation\nperformance of Adam within 44% of the gradient steps and 62% of the wallclock\ntime.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faSPlus\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86Shampoo\u7b97\u6cd5\u7684\u4e09\u4e2a\u5173\u952e\u95ee\u9898\uff0c\u5305\u62ec\u7a33\u5b9a\u6027\u3001\u5b66\u4e60\u7387\u9002\u5e94\u6027\u548c\u53c2\u6570\u566a\u58f0\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4f18\u4e8eAdam\u3002", "motivation": "\u89e3\u51b3Shampoo\u7b97\u6cd5\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u7a33\u5b9a\u6027\u3001\u8ba1\u7b97\u6548\u7387\u548c\u9002\u5e94\u6027\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u7ed3\u5408\u5386\u53f2\u7279\u5f81\u57fa\u4e0e\u77ac\u65f6\u5f52\u4e00\u5316\u7684\u6709\u754c\u66f4\u65b0\u3001\u5f62\u72b6\u611f\u77e5\u7684\u5b66\u4e60\u7387\u8c03\u6574\u548c\u8fed\u4ee3\u5e73\u5747\u65b9\u6848\u3002", "result": "SPlus\u5728\u9a8c\u8bc1\u6027\u80fd\u4e0a\u6bd4Adam\u8282\u770144%\u7684\u68af\u5ea6\u6b65\u6570\u548c62%\u7684\u5899\u949f\u65f6\u95f4\u3002", "conclusion": "SPlus\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u7a33\u5b9a\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u4efb\u52a1\u3002"}}
{"id": "2506.07272", "pdf": "https://arxiv.org/pdf/2506.07272", "abs": "https://arxiv.org/abs/2506.07272", "authors": ["Alex Clinton", "Thomas Zeng", "Yiding Chen", "Xiaojin Zhu", "Kirthevasan Kandasamy"], "title": "A Cram\u00e9r-von Mises Approach to Incentivizing Truthful Data Sharing", "categories": ["cs.LG"], "comment": null, "summary": "Modern data marketplaces and data sharing consortia increasingly rely on\nincentive mechanisms to encourage agents to contribute data. However, schemes\nthat reward agents based on the quantity of submitted data are vulnerable to\nmanipulation, as agents may submit fabricated or low-quality data to inflate\ntheir rewards. Prior work has proposed comparing each agent's data against\nothers' to promote honesty: when others contribute genuine data, the best way\nto minimize discrepancy is to do the same. Yet prior implementations of this\nidea rely on very strong assumptions about the data distribution (e.g.\nGaussian), limiting their applicability. In this work, we develop reward\nmechanisms based on a novel, two-sample test inspired by the Cram\\'er-von Mises\nstatistic. Our methods strictly incentivize agents to submit more genuine data,\nwhile disincentivizing data fabrication and other types of untruthful\nreporting. We establish that truthful reporting constitutes a (possibly\napproximate) Nash equilibrium in both Bayesian and prior-agnostic settings. We\ntheoretically instantiate our method in three canonical data sharing problems\nand show that it relaxes key assumptions made by prior work. Empirically, we\ndemonstrate that our mechanism incentivizes truthful data sharing via\nsimulations and on real-world language and image data.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eCram\u00e9r-von Mises\u7edf\u8ba1\u7684\u65b0\u578b\u5956\u52b1\u673a\u5236\uff0c\u4e25\u683c\u6fc0\u52b1\u771f\u5b9e\u6570\u636e\u63d0\u4ea4\uff0c\u51cf\u5c11\u865a\u5047\u6570\u636e\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u6570\u636e\u91cf\u7684\u5956\u52b1\u673a\u5236\u6613\u88ab\u64cd\u7eb5\uff0c\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u5f3a\u6570\u636e\u5206\u5e03\u5047\u8bbe\uff0c\u9002\u7528\u6027\u6709\u9650\u3002", "method": "\u5f00\u53d1\u57fa\u4e8e\u4e24\u6837\u672c\u68c0\u9a8c\u7684\u5956\u52b1\u673a\u5236\uff0c\u9002\u7528\u4e8e\u8d1d\u53f6\u65af\u548c\u65e0\u5148\u9a8c\u8bbe\u7f6e\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u771f\u5b9e\u62a5\u544a\u4e3a\u7eb3\u4ec0\u5747\u8861\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u673a\u5236\u5728\u8bed\u8a00\u548c\u56fe\u50cf\u6570\u636e\u4e0a\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u65b0\u673a\u5236\u653e\u5bbd\u5047\u8bbe\uff0c\u6709\u6548\u6fc0\u52b1\u771f\u5b9e\u6570\u636e\u5171\u4eab\u3002"}}
{"id": "2506.07275", "pdf": "https://arxiv.org/pdf/2506.07275", "abs": "https://arxiv.org/abs/2506.07275", "authors": ["Haochen Song", "Dominik Hofer", "Rania Islambouli", "Laura Hawkins", "Ananya Bhattacharjee", "Meredith Franklin", "Joseph Jay Williams"], "title": "Investigating the Relationship Between Physical Activity and Tailored Behavior Change Messaging: Connecting Contextual Bandit with Large Language Models", "categories": ["cs.LG", "cs.HC", "stat.AP"], "comment": null, "summary": "Machine learning approaches, such as contextual multi-armed bandit (cMAB)\nalgorithms, offer a promising strategy to reduce sedentary behavior by\ndelivering personalized interventions to encourage physical activity. However,\ncMAB algorithms typically require large participant samples to learn\neffectively and may overlook key psychological factors that are not explicitly\nencoded in the model. In this study, we propose a hybrid approach that combines\ncMAB for selecting intervention types with large language models (LLMs) to\npersonalize message content. We evaluate four intervention types: behavioral\nself-monitoring, gain-framed, loss-framed, and social comparison, each\ndelivered as a motivational message aimed at increasing motivation for physical\nactivity and daily step count. Message content is further personalized using\ndynamic contextual factors including daily fluctuations in self-efficacy,\nsocial influence, and regulatory focus. Over a seven-day trial, participants\nreceive daily messages assigned by one of four models: cMAB alone, LLM alone,\ncombined cMAB with LLM personalization (cMABxLLM), or equal randomization\n(RCT). Outcomes include daily step count and message acceptance, assessed via\necological momentary assessments (EMAs). We apply a causal inference framework\nto evaluate the effects of each model. Our findings offer new insights into the\ncomplementary roles of LLM-based personalization and cMAB adaptation in\npromoting physical activity through personalized behavioral messaging.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408cMAB\u548cLLM\u7684\u6df7\u5408\u65b9\u6cd5\uff0c\u7528\u4e8e\u4e2a\u6027\u5316\u5e72\u9884\u4ee5\u51cf\u5c11\u4e45\u5750\u884c\u4e3a\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6548\u679c\u3002", "motivation": "\u4f20\u7edfcMAB\u7b97\u6cd5\u9700\u8981\u5927\u6837\u672c\u4e14\u53ef\u80fd\u5ffd\u7565\u5fc3\u7406\u56e0\u7d20\uff0c\u56e0\u6b64\u63a2\u7d22\u7ed3\u5408LLM\u7684\u4e2a\u6027\u5316\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408cMAB\u9009\u62e9\u5e72\u9884\u7c7b\u578b\u548cLLM\u4e2a\u6027\u5316\u6d88\u606f\u5185\u5bb9\uff0c\u8bc4\u4f30\u56db\u79cd\u5e72\u9884\u7c7b\u578b\uff0c\u5e76\u901a\u8fc7\u4e03\u5929\u7684\u8bd5\u9a8c\u6bd4\u8f83\u56db\u79cd\u6a21\u578b\u7684\u6548\u679c\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86LLM\u4e2a\u6027\u5316\u548ccMAB\u9002\u5e94\u5728\u4fc3\u8fdb\u4f53\u80b2\u6d3b\u52a8\u4e2d\u7684\u4e92\u8865\u4f5c\u7528\u3002", "conclusion": "\u6df7\u5408\u65b9\u6cd5\u5728\u4e2a\u6027\u5316\u884c\u4e3a\u5e72\u9884\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2506.07276", "pdf": "https://arxiv.org/pdf/2506.07276", "abs": "https://arxiv.org/abs/2506.07276", "authors": ["Suho Shin", "Chenghao Yang", "Haifeng Xu", "Mohammad T. Hajiaghayi"], "title": "Tokenized Bandit for LLM Decoding and Alignment", "categories": ["cs.LG", "cs.AI"], "comment": "To appear at ICML 2025", "summary": "We introduce the tokenized linear bandit (TLB) and multi-armed bandit (TMAB),\nvariants of linear and stochastic multi-armed bandit problems inspired by LLM\ndecoding and alignment. In these problems, at each round $t \\in [T]$, a user\nsubmits a query (context), and the decision maker (DM) sequentially selects a\ntoken irrevocably from a token set. Once the sequence is complete, the DM\nobserves a random utility from the user, whose expectation is presented by a\nsequence function mapping the chosen token sequence to a nonnegative real value\nthat depends on the query.\n  In both problems, we first show that learning is impossible without any\nstructure on the sequence function. We introduce a natural assumption,\ndiminishing distance with more commons (DDMC), and propose algorithms with\nregret $\\tilde{O}(L\\sqrt{T})$ and $\\tilde{O}(L\\sqrt{T^{2/3}})$ for TLB and\nTMAB, respectively. As a side product, we obtain an (almost) optimality of the\ngreedy decoding for LLM decoding algorithm under DDMC, which justifies the\nunresaonable effectiveness of greedy decoding in several tasks. This also has\nan immediate application to decoding-time LLM alignment, when the misaligned\nutility can be represented as the frozen LLM's utility and a linearly\nrealizable latent function. We finally validate our algorithm's performance\nempirically as well as verify our assumptions using synthetic and real-world\ndatasets.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u57fa\u4e8eLLM\u89e3\u7801\u548c\u5bf9\u9f50\u7684Tokenized\u7ebf\u6027\u8d4c\u535a\u673a\uff08TLB\uff09\u548c\u591a\u81c2\u8d4c\u535a\u673a\uff08TMAB\uff09\u95ee\u9898\uff0c\u5e76\u8bc1\u660e\u4e86\u5728\u65e0\u7ed3\u6784\u5047\u8bbe\u4e0b\u5b66\u4e60\u4e0d\u53ef\u884c\u3002\u901a\u8fc7\u5f15\u5165DDMC\u5047\u8bbe\uff0c\u8bbe\u8ba1\u4e86\u9ad8\u6548\u7b97\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u8d2a\u5a6a\u89e3\u7801\u7684\u5408\u7406\u6027\uff0c\u5e76\u5e94\u7528\u4e8eLLM\u5bf9\u9f50\u3002", "motivation": "\u7814\u7a76LLM\u89e3\u7801\u548c\u5bf9\u9f50\u4e2d\u7684\u5e8f\u5217\u51b3\u7b56\u95ee\u9898\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u65e0\u7ed3\u6784\u5047\u8bbe\u4e0b\u7684\u5b66\u4e60\u56f0\u96be\u3002", "method": "\u63d0\u51faTLB\u548cTMAB\u95ee\u9898\uff0c\u5f15\u5165DDMC\u5047\u8bbe\uff0c\u8bbe\u8ba1\u7b97\u6cd5\u5b9e\u73b0O~(L\u221aT)\u548cO~(L\u221aT^(2/3))\u7684\u9057\u61be\u754c\u3002", "result": "\u7b97\u6cd5\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u9a8c\u8bc1\u4e86DDMC\u5047\u8bbe\u548c\u8d2a\u5a6a\u89e3\u7801\u7684\u6709\u6548\u6027\u3002", "conclusion": "DDMC\u5047\u8bbe\u548c\u63d0\u51fa\u7684\u7b97\u6cd5\u4e3aLLM\u89e3\u7801\u548c\u5bf9\u9f50\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2506.07288", "pdf": "https://arxiv.org/pdf/2506.07288", "abs": "https://arxiv.org/abs/2506.07288", "authors": ["Weijie Guan", "Haohui Wang", "Jian Kang", "Lihui Liu", "Dawei Zhou"], "title": "EviNet: Evidential Reasoning Network for Resilient Graph Learning in the Open and Noisy Environments", "categories": ["cs.LG"], "comment": "KDD 2025", "summary": "Graph learning has been crucial to many real-world tasks, but they are often\nstudied with a closed-world assumption, with all possible labels of data known\na priori. To enable effective graph learning in an open and noisy environment,\nit is critical to inform the model users when the model makes a wrong\nprediction to in-distribution data of a known class, i.e., misclassification\ndetection or when the model encounters out-of-distribution from novel classes,\ni.e., out-of-distribution detection. This paper introduces Evidential Reasoning\nNetwork (EVINET), a framework that addresses these two challenges by\nintegrating Beta embedding within a subjective logic framework. EVINET includes\ntwo key modules: Dissonance Reasoning for misclassification detection and\nVacuity Reasoning for out-of-distribution detection. Extensive experiments\ndemonstrate that EVINET outperforms state-of-the-art methods across multiple\nmetrics in the tasks of in-distribution classification, misclassification\ndetection, and out-of-distribution detection. EVINET demonstrates the necessity\nof uncertainty estimation and logical reasoning for misclassification detection\nand out-of-distribution detection and paves the way for open-world graph\nlearning. Our code and data are available at https://github.com/SSSKJ/EviNET.", "AI": {"tldr": "EVINET\u6846\u67b6\u901a\u8fc7Beta\u5d4c\u5165\u548c\u4e3b\u89c2\u903b\u8f91\u89e3\u51b3\u4e86\u56fe\u5b66\u4e60\u4e2d\u7684\u8bef\u5206\u7c7b\u68c0\u6d4b\u548c\u5206\u5e03\u5916\u68c0\u6d4b\u95ee\u9898\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u56fe\u5b66\u4e60\u901a\u5e38\u57fa\u4e8e\u5c01\u95ed\u4e16\u754c\u5047\u8bbe\uff0c\u800c\u5b9e\u9645\u5e94\u7528\u4e2d\u9700\u8981\u5904\u7406\u5f00\u653e\u548c\u566a\u58f0\u73af\u5883\u4e2d\u7684\u8bef\u5206\u7c7b\u548c\u5206\u5e03\u5916\u6570\u636e\u3002", "method": "EVINET\u7ed3\u5408Beta\u5d4c\u5165\u548c\u4e3b\u89c2\u903b\u8f91\uff0c\u5305\u542bDissonance Reasoning\uff08\u8bef\u5206\u7c7b\u68c0\u6d4b\uff09\u548cVacuity Reasoning\uff08\u5206\u5e03\u5916\u68c0\u6d4b\uff09\u6a21\u5757\u3002", "result": "\u5b9e\u9a8c\u8868\u660eEVINET\u5728\u591a\u4e2a\u4efb\u52a1\u548c\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "EVINET\u8bc1\u660e\u4e86\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u548c\u903b\u8f91\u63a8\u7406\u5728\u5f00\u653e\u4e16\u754c\u56fe\u5b66\u4e60\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2506.07298", "pdf": "https://arxiv.org/pdf/2506.07298", "abs": "https://arxiv.org/abs/2506.07298", "authors": ["Yijia Dai", "Zhaolin Gao", "Yahya Satter", "Sarah Dean", "Jennifer J. Sun"], "title": "Pre-trained Large Language Models Learn Hidden Markov Models In-context", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Hidden Markov Models (HMMs) are foundational tools for modeling sequential\ndata with latent Markovian structure, yet fitting them to real-world data\nremains computationally challenging. In this work, we show that pre-trained\nlarge language models (LLMs) can effectively model data generated by HMMs via\nin-context learning (ICL)$\\unicode{x2013}$their ability to infer patterns from\nexamples within a prompt. On a diverse set of synthetic HMMs, LLMs achieve\npredictive accuracy approaching the theoretical optimum. We uncover novel\nscaling trends influenced by HMM properties, and offer theoretical conjectures\nfor these empirical observations. We also provide practical guidelines for\nscientists on using ICL as a diagnostic tool for complex data. On real-world\nanimal decision-making tasks, ICL achieves competitive performance with models\ndesigned by human experts. To our knowledge, this is the first demonstration\nthat ICL can learn and predict HMM-generated sequences$\\unicode{x2013}$an\nadvance that deepens our understanding of in-context learning in LLMs and\nestablishes its potential as a powerful tool for uncovering hidden structure in\ncomplex scientific data.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\u6709\u6548\u5efa\u6a21\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\uff08HMMs\uff09\u751f\u6210\u7684\u6570\u636e\uff0c\u9884\u6d4b\u7cbe\u5ea6\u63a5\u8fd1\u7406\u8bba\u6700\u4f18\u3002", "motivation": "\u89e3\u51b3HMMs\u5728\u771f\u5b9e\u6570\u636e\u4e2d\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u7684\u95ee\u9898\uff0c\u63a2\u7d22LLMs\u5728\u5efa\u6a21\u5e8f\u5217\u6570\u636e\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u5229\u7528\u9884\u8bad\u7ec3\u7684LLMs\u901a\u8fc7ICL\u5b66\u4e60HMMs\u751f\u6210\u7684\u5e8f\u5217\u6570\u636e\uff0c\u5206\u6790\u5176\u5728\u4e0d\u540cHMMs\u4e0a\u7684\u8868\u73b0\u3002", "result": "LLMs\u5728\u5408\u6210HMMs\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u63a5\u8fd1\u7406\u8bba\u6700\u4f18\uff1b\u5728\u771f\u5b9e\u52a8\u7269\u51b3\u7b56\u4efb\u52a1\u4e2d\u4e0e\u4e13\u5bb6\u8bbe\u8ba1\u6a21\u578b\u7ade\u4e89\u3002", "conclusion": "ICL\u80fd\u6709\u6548\u5b66\u4e60HMMs\u5e8f\u5217\uff0c\u4e3a\u590d\u6742\u79d1\u5b66\u6570\u636e\u4e2d\u9690\u85cf\u7ed3\u6784\u7684\u53d1\u73b0\u63d0\u4f9b\u65b0\u5de5\u5177\u3002"}}
{"id": "2506.07308", "pdf": "https://arxiv.org/pdf/2506.07308", "abs": "https://arxiv.org/abs/2506.07308", "authors": ["Yizhuo Chen", "Chun-Fu", "Chen", "Hsiang Hsu", "Shaohan Hu", "Tarek Abdelzaher"], "title": "PASS: Private Attributes Protection with Stochastic Data Substitution", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "The growing Machine Learning (ML) services require extensive collections of\nuser data, which may inadvertently include people's private information\nirrelevant to the services. Various studies have been proposed to protect\nprivate attributes by removing them from the data while maintaining the\nutilities of the data for downstream tasks. Nevertheless, as we theoretically\nand empirically show in the paper, these methods reveal severe vulnerability\nbecause of a common weakness rooted in their adversarial training based\nstrategies. To overcome this limitation, we propose a novel approach, PASS,\ndesigned to stochastically substitute the original sample with another one\naccording to certain probabilities, which is trained with a novel loss function\nsoundly derived from information-theoretic objective defined for\nutility-preserving private attributes protection. The comprehensive evaluation\nof PASS on various datasets of different modalities, including facial images,\nhuman activity sensory signals, and voice recording datasets, substantiates\nPASS's effectiveness and generalizability.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPASS\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u6570\u636e\uff0c\u540c\u65f6\u4fdd\u6301\u6570\u636e\u7684\u5b9e\u7528\u6027\uff0c\u514b\u670d\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u968f\u7740\u673a\u5668\u5b66\u4e60\u670d\u52a1\u7684\u666e\u53ca\uff0c\u7528\u6237\u6570\u636e\u4e2d\u53ef\u80fd\u5305\u542b\u4e0e\u670d\u52a1\u65e0\u5173\u7684\u9690\u79c1\u4fe1\u606f\uff0c\u73b0\u6709\u65b9\u6cd5\u56e0\u5bf9\u6297\u8bad\u7ec3\u7b56\u7565\u5b58\u5728\u4e25\u91cd\u6f0f\u6d1e\u3002", "method": "PASS\u901a\u8fc7\u6982\u7387\u6027\u66ff\u6362\u539f\u59cb\u6837\u672c\uff0c\u5e76\u91c7\u7528\u57fa\u4e8e\u4fe1\u606f\u8bba\u76ee\u6807\u7684\u65b0\u635f\u5931\u51fd\u6570\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u5728\u591a\u79cd\u6570\u636e\u96c6\u4e0a\u7684\u7efc\u5408\u8bc4\u4f30\u9a8c\u8bc1\u4e86PASS\u7684\u6709\u6548\u6027\u548c\u901a\u7528\u6027\u3002", "conclusion": "PASS\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u901a\u7528\u7684\u9690\u79c1\u4fdd\u62a4\u65b9\u6cd5\uff0c\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002"}}
{"id": "2506.07311", "pdf": "https://arxiv.org/pdf/2506.07311", "abs": "https://arxiv.org/abs/2506.07311", "authors": ["Thomas Joshi", "Herman Saini", "Neil Dhillon", "Antoni Viros i Martin", "Kaoutar El Maghraoui"], "title": "Paged Attention Meets FlexAttention: Unlocking Long-Context Efficiency in Deployed Inference", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) encounter severe memory inefficiencies during\nlong-context inference due to conventional handling of key-value (KV) caches.\nIn this work, we introduce a novel integration of PagedAttention with PyTorch's\nFlexAttention, addressing internal fragmentation and inefficiencies associated\nwith monolithic KV cache allocations. Implemented within IBM's Foundation Model\nStack (FMS), our fused attention kernel efficiently gathers scattered KV data.\nOur benchmarks on an NVIDIA L4 GPU (24GB) demonstrate significantly reduced\ninference latency, growing only linearly (~2x) with sequence length from 128 to\n2048 tokens when utilizing a global KV cache, compared to exponential latency\nincreases without caching. While peak memory usage remains largely unchanged\nfor single-step evaluations (dominated by model weights and activations), paged\nattention causes minimal incremental memory usage, observable only at sequence\nlengths exceeding 2048 tokens due to its power-of-two cache allocations. We\nopen-source the full implementation and discuss its implications for future\nlong-context model deployment.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408PagedAttention\u548cPyTorch FlexAttention\u7684\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86LLMs\u5728\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4e2d\u7684\u5185\u5b58\u6548\u7387\u95ee\u9898\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u63a8\u7406\u5ef6\u8fdf\u3002", "motivation": "\u4f20\u7edfKV\u7f13\u5b58\u5904\u7406\u65b9\u5f0f\u5bfc\u81f4LLMs\u5728\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4e2d\u5b58\u5728\u4e25\u91cd\u7684\u5185\u5b58\u6548\u7387\u95ee\u9898\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "\u901a\u8fc7\u96c6\u6210PagedAttention\u4e0ePyTorch\u7684FlexAttention\uff0c\u4f18\u5316KV\u7f13\u5b58\u5206\u914d\uff0c\u51cf\u5c11\u5185\u90e8\u788e\u7247\u5316\u3002", "result": "\u5728NVIDIA L4 GPU\u4e0a\u6d4b\u8bd5\uff0c\u63a8\u7406\u5ef6\u8fdf\u663e\u8457\u964d\u4f4e\uff0c\u4e14\u968f\u5e8f\u5217\u957f\u5ea6\u7ebf\u6027\u589e\u957f\uff0c\u800c\u975e\u6307\u6570\u589e\u957f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u672a\u6765\u957f\u4e0a\u4e0b\u6587\u6a21\u578b\u90e8\u7f72\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5f00\u6e90\u4e86\u5b8c\u6574\u5b9e\u73b0\u3002"}}
{"id": "2506.07312", "pdf": "https://arxiv.org/pdf/2506.07312", "abs": "https://arxiv.org/abs/2506.07312", "authors": ["Yusuf Elnady"], "title": "Generative Modeling of Networked Time-Series via Transformer Architectures", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Many security and network applications require having large datasets to train\nthe machine learning models. Limited data access is a well-known problem in the\nsecurity domain. Recent studies have shown the potential of Transformer models\nto enlarge the size of data by synthesizing new samples, but the synthesized\nsamples don't improve the models over the real data. To address this issue, we\ndesign an efficient transformer-based model as a generative framework to\ngenerate time-series data, that can be used to boost the performance of\nexisting and new ML workflows. Our new transformer model achieves the SOTA\nresults. We style our model to be generalizable and work across different\ndatasets, and produce high-quality samples.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u57fa\u4e8eTransformer\u7684\u751f\u6210\u6a21\u578b\uff0c\u7528\u4e8e\u5408\u6210\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u4ee5\u89e3\u51b3\u5b89\u5168\u9886\u57df\u4e2d\u6570\u636e\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u5e76\u63d0\u5347\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u5b89\u5168\u9886\u57df\u7684\u6570\u636e\u8bbf\u95ee\u53d7\u9650\u662f\u4e00\u4e2a\u5e38\u89c1\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u5408\u6210\u7684\u6570\u636e\u672a\u80fd\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u9ad8\u6548\u7684Transformer\u751f\u6210\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u3002", "result": "\u65b0\u6a21\u578b\u5728\u6027\u80fd\u4e0a\u8fbe\u5230\u4e86SOTA\u6c34\u5e73\uff0c\u5e76\u5177\u6709\u901a\u7528\u6027\u548c\u9ad8\u8d28\u91cf\u6837\u672c\u751f\u6210\u80fd\u529b\u3002", "conclusion": "\u8be5\u6a21\u578b\u4e3a\u5b89\u5168\u9886\u57df\u7684\u673a\u5668\u5b66\u4e60\u5de5\u4f5c\u6d41\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6570\u636e\u589e\u5f3a\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.07324", "pdf": "https://arxiv.org/pdf/2506.07324", "abs": "https://arxiv.org/abs/2506.07324", "authors": ["David Millard", "Arielle Carr", "St\u00e9phane Gaudreault", "Ali Baheri"], "title": "DEF: Diffusion-augmented Ensemble Forecasting", "categories": ["cs.LG", "physics.ao-ph", "35Q93 (Primary), 86A10, 65M75 (Secondary)", "I.2.6; I.6.3"], "comment": "26 pages, 20 plots, journal paper", "summary": "We present DEF (\\textbf{\\ul{D}}iffusion-augmented \\textbf{\\ul{E}}nsemble\n\\textbf{\\ul{F}}orecasting), a novel approach for generating initial condition\nperturbations. Modern approaches to initial condition perturbations are\nprimarily designed for numerical weather prediction (NWP) solvers, limiting\ntheir applicability in the rapidly growing field of machine learning for\nweather prediction. Consequently, stochastic models in this domain are often\ndeveloped on a case-by-case basis. We demonstrate that a simple conditional\ndiffusion model can (1) generate meaningful structured perturbations, (2) be\napplied iteratively, and (3) utilize a guidance term to intuitivey control the\nlevel of perturbation. This method enables the transformation of any\ndeterministic neural forecasting system into a stochastic one. With our\nstochastic extended systems, we show that the model accumulates less error over\nlong-term forecasts while producing meaningful forecast distributions. We\nvalidate our approach on the 5.625$^\\circ$ ERA5 reanalysis dataset, which\ncomprises atmospheric and surface variables over a discretized global grid,\nspanning from the 1960s to the present. On this dataset, our method\ndemonstrates improved predictive performance along with reasonable spread\nestimates.", "AI": {"tldr": "DEF\u662f\u4e00\u79cd\u901a\u8fc7\u6269\u6563\u589e\u5f3a\u7684\u96c6\u6210\u9884\u6d4b\u65b9\u6cd5\uff0c\u7528\u4e8e\u751f\u6210\u521d\u59cb\u6761\u4ef6\u6270\u52a8\uff0c\u9002\u7528\u4e8e\u673a\u5668\u5b66\u4e60\u5929\u6c14\u9884\u6d4b\u9886\u57df\u3002", "motivation": "\u73b0\u6709\u521d\u59cb\u6761\u4ef6\u6270\u52a8\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u6570\u503c\u5929\u6c14\u9884\u62a5\uff08NWP\uff09\uff0c\u9650\u5236\u4e86\u5176\u5728\u673a\u5668\u5b66\u4e60\u5929\u6c14\u9884\u6d4b\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u4f7f\u7528\u7b80\u5355\u7684\u6761\u4ef6\u6269\u6563\u6a21\u578b\u751f\u6210\u7ed3\u6784\u5316\u6270\u52a8\uff0c\u53ef\u8fed\u4ee3\u5e94\u7528\u5e76\u901a\u8fc7\u5f15\u5bfc\u9879\u63a7\u5236\u6270\u52a8\u6c34\u5e73\u3002", "result": "\u5728ERA5\u518d\u5206\u6790\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0cDEF\u51cf\u5c11\u4e86\u957f\u671f\u9884\u6d4b\u8bef\u5dee\u5e76\u751f\u6210\u6709\u610f\u4e49\u7684\u9884\u6d4b\u5206\u5e03\u3002", "conclusion": "DEF\u80fd\u5c06\u786e\u5b9a\u6027\u795e\u7ecf\u9884\u6d4b\u7cfb\u7edf\u8f6c\u5316\u4e3a\u968f\u673a\u7cfb\u7edf\uff0c\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u5e76\u751f\u6210\u5408\u7406\u7684\u5206\u5e03\u4f30\u8ba1\u3002"}}
{"id": "2506.07328", "pdf": "https://arxiv.org/pdf/2506.07328", "abs": "https://arxiv.org/abs/2506.07328", "authors": ["Jintao Yan", "Tan Chen", "Yuxuan Sun", "Zhaojun Nan", "Sheng Zhou", "Zhisheng Niu"], "title": "Mobility-Aware Asynchronous Federated Learning with Dynamic Sparsification", "categories": ["cs.LG"], "comment": null, "summary": "Asynchronous Federated Learning (AFL) enables distributed model training\nacross multiple mobile devices, allowing each device to independently update\nits local model without waiting for others. However, device mobility introduces\nintermittent connectivity, which necessitates gradient sparsification and leads\nto model staleness, jointly affecting AFL convergence. This paper develops a\ntheoretical model to characterize the interplay among sparsification, model\nstaleness and mobility-induced contact patterns, and their joint impact on AFL\nconvergence. Based on the analysis, we propose a mobility-aware dynamic\nsparsification (MADS) algorithm that optimizes the sparsification degree based\non contact time and model staleness. Closed-form solutions are derived, showing\nthat under low-speed conditions, MADS increases the sparsification degree to\nenhance convergence, while under high-speed conditions, it reduces the\nsparsification degree to guarantee reliable uploads within limited contact\ntime. Experimental results validate the theoretical findings. Compared with the\nstate-of-the-art benchmarks, the MADS algorithm increases the image\nclassification accuracy on the CIFAR-10 dataset by 8.76% and reduces the\naverage displacement error in the Argoverse trajectory prediction dataset by\n9.46%.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u79fb\u52a8\u611f\u77e5\u7684\u52a8\u6001\u7a00\u758f\u5316\uff08MADS\uff09\u7b97\u6cd5\uff0c\u7528\u4e8e\u4f18\u5316\u5f02\u6b65\u8054\u90a6\u5b66\u4e60\uff08AFL\uff09\u4e2d\u7684\u68af\u5ea6\u7a00\u758f\u5316\uff0c\u4ee5\u5e94\u5bf9\u8bbe\u5907\u79fb\u52a8\u6027\u5e26\u6765\u7684\u8fde\u63a5\u95ee\u9898\u548c\u6a21\u578b\u9648\u65e7\u6027\u3002", "motivation": "\u8bbe\u5907\u79fb\u52a8\u6027\u5bfc\u81f4\u95f4\u6b47\u6027\u8fde\u63a5\u548c\u6a21\u578b\u9648\u65e7\u6027\uff0c\u5f71\u54cdAFL\u7684\u6536\u655b\u6027\uff0c\u9700\u8981\u4e00\u79cd\u52a8\u6001\u8c03\u6574\u7a00\u758f\u5316\u7a0b\u5ea6\u7684\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1\u4e86\u7406\u8bba\u6a21\u578b\u5206\u6790\u7a00\u758f\u5316\u3001\u6a21\u578b\u9648\u65e7\u6027\u548c\u79fb\u52a8\u6027\u63a5\u89e6\u6a21\u5f0f\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u5e76\u63d0\u51fa\u4e86MADS\u7b97\u6cd5\uff0c\u6839\u636e\u63a5\u89e6\u65f6\u95f4\u548c\u6a21\u578b\u9648\u65e7\u6027\u52a8\u6001\u4f18\u5316\u7a00\u758f\u5316\u7a0b\u5ea6\u3002", "result": "\u5728\u4f4e\u901f\u6761\u4ef6\u4e0b\u589e\u52a0\u7a00\u758f\u5316\u7a0b\u5ea6\u4ee5\u63d0\u5347\u6536\u655b\u6027\uff0c\u5728\u9ad8\u901f\u6761\u4ef6\u4e0b\u51cf\u5c11\u7a00\u758f\u5316\u7a0b\u5ea6\u4ee5\u786e\u4fdd\u53ef\u9760\u4e0a\u4f20\u3002\u5b9e\u9a8c\u663e\u793aMADS\u5728CIFAR-10\u6570\u636e\u96c6\u4e0a\u5206\u7c7b\u51c6\u786e\u7387\u63d0\u9ad88.76%\uff0c\u5728Argoverse\u6570\u636e\u96c6\u4e0a\u5e73\u5747\u4f4d\u79fb\u8bef\u5dee\u964d\u4f4e9.46%\u3002", "conclusion": "MADS\u7b97\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u79fb\u52a8\u6027\u5bf9AFL\u7684\u5f71\u54cd\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2506.07330", "pdf": "https://arxiv.org/pdf/2506.07330", "abs": "https://arxiv.org/abs/2506.07330", "authors": ["Yash Datta", "Sharath Rajasekar"], "title": "JavelinGuard: Low-Cost Transformer Architectures for LLM Security", "categories": ["cs.LG", "cs.AI", "cs.CR", "I.2.7"], "comment": "16 pages, 1 Figure and 5 Tables", "summary": "We present JavelinGuard, a suite of low-cost, high-performance model\narchitectures designed for detecting malicious intent in Large Language Model\n(LLM) interactions, optimized specifically for production deployment. Recent\nadvances in transformer architectures, including compact BERT(Devlin et al.\n2019) variants (e.g., ModernBERT (Warner et al. 2024)), allow us to build\nhighly accurate classifiers with as few as approximately 400M parameters that\nachieve rapid inference speeds even on standard CPU hardware. We systematically\nexplore five progressively sophisticated transformer-based architectures:\nSharanga (baseline transformer classifier), Mahendra (enhanced\nattention-weighted pooling with deeper heads), Vaishnava and Ashwina (hybrid\nneural ensemble architectures), and Raudra (an advanced multi-task framework\nwith specialized loss functions). Our models are rigorously benchmarked across\nnine diverse adversarial datasets, including popular sets like the NotInject\nseries, BIPIA, Garak, ImprovedLLM, ToxicChat, WildGuard, and our newly\nintroduced JavelinBench, specifically crafted to test generalization on\nchallenging borderline and hard-negative cases. Additionally, we compare our\narchitectures against leading open-source guardrail models as well as large\ndecoder-only LLMs such as gpt-4o, demonstrating superior cost-performance\ntrade-offs in terms of accuracy, and latency. Our findings reveal that while\nRaudra's multi-task design offers the most robust performance overall, each\narchitecture presents unique trade-offs in speed, interpretability, and\nresource requirements, guiding practitioners in selecting the optimal balance\nof complexity and efficiency for real-world LLM security applications.", "AI": {"tldr": "JavelinGuard\u662f\u4e00\u5957\u4f4e\u6210\u672c\u3001\u9ad8\u6027\u80fd\u7684\u6a21\u578b\u67b6\u6784\uff0c\u7528\u4e8e\u68c0\u6d4b\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ea4\u4e92\u4e2d\u7684\u6076\u610f\u610f\u56fe\uff0c\u4e13\u4e3a\u751f\u4ea7\u90e8\u7f72\u4f18\u5316\u3002", "motivation": "\u968f\u7740LLM\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u6076\u610f\u4ea4\u4e92\u7684\u68c0\u6d4b\u9700\u6c42\u65e5\u76ca\u589e\u957f\uff0c\u9700\u8981\u9ad8\u6548\u4e14\u4f4e\u6210\u672c\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63a2\u7d22\u4e86\u4e94\u79cd\u57fa\u4e8eTransformer\u7684\u67b6\u6784\uff0c\u5305\u62ec\u57fa\u7840\u5206\u7c7b\u5668\u3001\u589e\u5f3a\u6ce8\u610f\u529b\u52a0\u6743\u6c60\u5316\u3001\u6df7\u5408\u795e\u7ecf\u7f51\u7edc\u96c6\u6210\u548c\u9ad8\u7ea7\u591a\u4efb\u52a1\u6846\u67b6\u3002", "result": "\u5728\u4e5d\u4e2a\u5bf9\u6297\u6027\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\uff0c\u5c55\u793a\u4e86\u4f18\u4e8e\u5f00\u6e90\u62a4\u680f\u6a21\u578b\u548c\u5927\u578b\u89e3\u7801\u5668LLM\u7684\u6027\u80fd\u4e0e\u6210\u672c\u5e73\u8861\u3002", "conclusion": "Raudra\u591a\u4efb\u52a1\u8bbe\u8ba1\u8868\u73b0\u6700\u7a33\u5065\uff0c\u4f46\u4e0d\u540c\u67b6\u6784\u5728\u901f\u5ea6\u3001\u53ef\u89e3\u91ca\u6027\u548c\u8d44\u6e90\u9700\u6c42\u4e0a\u6709\u72ec\u7279\u6743\u8861\uff0c\u9002\u7528\u4e8e\u4e0d\u540c\u573a\u666f\u3002"}}
{"id": "2506.07334", "pdf": "https://arxiv.org/pdf/2506.07334", "abs": "https://arxiv.org/abs/2506.07334", "authors": ["Haoyu Wang", "Peihao Wang", "Mufei Li", "Shikun Liu", "Siqi Miao", "Zhangyang Wang", "Pan Li"], "title": "Graph-KV: Breaking Sequence via Injecting Structural Biases into Large Language Models", "categories": ["cs.LG"], "comment": null, "summary": "Modern large language models (LLMs) are inherently auto-regressive, requiring\ninput to be serialized into flat sequences regardless of their structural\ndependencies. This serialization hinders the model's ability to leverage\nstructural inductive biases, especially in tasks such as retrieval-augmented\ngeneration (RAG) and reasoning on data with native graph structures, where\ninter-segment dependencies are crucial. We introduce Graph-KV with the\npotential to overcome this limitation. Graph-KV leverages the KV-cache of text\nsegments as condensed representations and governs their interaction through\nstructural inductive biases. In this framework, 'target' segments selectively\nattend only to the KV-caches of their designated 'source' segments, rather than\nall preceding segments in a serialized sequence. This approach induces a\ngraph-structured block mask, sparsifying attention and enabling a\nmessage-passing-like step within the LLM. Furthermore, strategically allocated\npositional encodings for source and target segments reduce positional bias and\ncontext window consumption. We evaluate Graph-KV across three scenarios: (1)\nseven RAG benchmarks spanning direct inference, multi-hop reasoning, and\nlong-document understanding; (2) Arxiv-QA, a novel academic paper QA task with\nfull-text scientific papers structured as citation ego-graphs; and (3) paper\ntopic classification within a citation network. By effectively reducing\npositional bias and harnessing structural inductive biases, Graph-KV\nsubstantially outperforms baselines, including standard costly sequential\nencoding, across various settings. Code and the Graph-KV data are publicly\navailable.", "AI": {"tldr": "Graph-KV\u901a\u8fc7\u5229\u7528KV-cache\u4f5c\u4e3a\u538b\u7f29\u8868\u793a\uff0c\u5e76\u901a\u8fc7\u7ed3\u6784\u5f52\u7eb3\u504f\u7f6e\u63a7\u5236\u5176\u4ea4\u4e92\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u5e8f\u5217\u5316\u8f93\u5165\u5bf9LLMs\u7684\u9650\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5728RAG\u548c\u56fe\u5f62\u7ed3\u6784\u6570\u636e\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u4ee3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u5e8f\u5217\u5316\u8f93\u5165\u65b9\u5f0f\u65e0\u6cd5\u6709\u6548\u5229\u7528\u7ed3\u6784\u4f9d\u8d56\u5173\u7cfb\uff0c\u5c24\u5176\u5728\u9700\u8981\u5904\u7406\u56fe\u5f62\u7ed3\u6784\u6570\u636e\u7684\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002Graph-KV\u65e8\u5728\u901a\u8fc7\u7ed3\u6784\u5f52\u7eb3\u504f\u7f6e\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "Graph-KV\u5229\u7528KV-cache\u4f5c\u4e3a\u6587\u672c\u6bb5\u7684\u538b\u7f29\u8868\u793a\uff0c\u5e76\u901a\u8fc7\u9009\u62e9\u6027\u6ce8\u610f\u529b\u673a\u5236\uff08\u4ec5\u5173\u6ce8\u6307\u5b9a\u7684\u6e90\u6bb5\uff09\u5f15\u5165\u56fe\u5f62\u7ed3\u6784\u5757\u63a9\u7801\uff0c\u540c\u65f6\u4f18\u5316\u4f4d\u7f6e\u7f16\u7801\u4ee5\u51cf\u5c11\u4f4d\u7f6e\u504f\u5dee\u3002", "result": "Graph-KV\u5728RAG\u57fa\u51c6\u6d4b\u8bd5\u3001\u5b66\u672f\u8bba\u6587QA\u4efb\u52a1\u548c\u8bba\u6587\u4e3b\u9898\u5206\u7c7b\u4efb\u52a1\u4e2d\u5747\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5c24\u5176\u662f\u5728\u51cf\u5c11\u4f4d\u7f6e\u504f\u5dee\u548c\u5229\u7528\u7ed3\u6784\u504f\u7f6e\u65b9\u9762\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "Graph-KV\u901a\u8fc7\u7ed3\u6784\u5316\u7684\u6ce8\u610f\u529b\u673a\u5236\u548c\u4f18\u5316\u7684\u4f4d\u7f6e\u7f16\u7801\uff0c\u663e\u8457\u63d0\u5347\u4e86LLMs\u5728\u56fe\u5f62\u7ed3\u6784\u6570\u636e\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u4e3a\u76f8\u5173\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.07355", "pdf": "https://arxiv.org/pdf/2506.07355", "abs": "https://arxiv.org/abs/2506.07355", "authors": ["Yuya Okada", "Takayuki Nishio"], "title": "SALT: A Lightweight Model Adaptation Method for Closed Split Computing Environments", "categories": ["cs.LG", "cs.AI", "cs.NI"], "comment": "6 pages, submitted to IEEE Globecom 2025 (under review)", "summary": "We propose SALT (Split-Adaptive Lightweight Tuning), a lightweight model\nadaptation framework for Split Computing under closed constraints, where the\nhead and tail networks are proprietary and inaccessible to users. In such\nclosed environments, conventional adaptation methods are infeasible since they\nrequire access to model parameters or architectures. SALT addresses this\nchallenge by introducing a compact, trainable adapter on the client side to\nrefine latent features from the head network, enabling user-specific adaptation\nwithout modifying the original models or increasing communication overhead. We\nevaluate SALT on user-specific classification tasks with CIFAR-10 and\nCIFAR-100, demonstrating improved accuracy with lower training latency compared\nto fine-tuning methods. Furthermore, SALT facilitates model adaptation for\nrobust inference over lossy networks, a common challenge in edge-cloud\nenvironments. With minimal deployment overhead, SALT offers a practical\nsolution for personalized inference in edge AI systems under strict system\nconstraints.", "AI": {"tldr": "SALT\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u6a21\u578b\u9002\u5e94\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u5c01\u95ed\u7ea6\u675f\u4e0b\u8fdb\u884c\u5206\u5272\u8ba1\u7b97\uff0c\u901a\u8fc7\u5ba2\u6237\u7aef\u9002\u914d\u5668\u4f18\u5316\u7279\u5f81\uff0c\u65e0\u9700\u4fee\u6539\u539f\u59cb\u6a21\u578b\u3002", "motivation": "\u5728\u5c01\u95ed\u73af\u5883\u4e2d\uff0c\u4f20\u7edf\u9002\u5e94\u65b9\u6cd5\u4e0d\u53ef\u884c\uff0c\u56e0\u4e3a\u9700\u8981\u8bbf\u95ee\u6a21\u578b\u53c2\u6570\u6216\u67b6\u6784\u3002", "method": "\u5f15\u5165\u7d27\u51d1\u3001\u53ef\u8bad\u7ec3\u7684\u5ba2\u6237\u7aef\u9002\u914d\u5668\uff0c\u4f18\u5316\u5934\u90e8\u7f51\u7edc\u7684\u6f5c\u5728\u7279\u5f81\u3002", "result": "\u5728CIFAR-10\u548cCIFAR-100\u4e0a\u8868\u73b0\u4f18\u4e8e\u5fae\u8c03\u65b9\u6cd5\uff0c\u8bad\u7ec3\u5ef6\u8fdf\u66f4\u4f4e\u3002", "conclusion": "SALT\u4e3a\u8fb9\u7f18AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u4e2a\u6027\u5316\u63a8\u7406\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.07366", "pdf": "https://arxiv.org/pdf/2506.07366", "abs": "https://arxiv.org/abs/2506.07366", "authors": ["Haiyue Ma", "Zhixu Du", "Yiran Chen"], "title": "MoE-GPS: Guidlines for Prediction Strategy for Dynamic Expert Duplication in MoE Load Balancing", "categories": ["cs.LG", "cs.AR"], "comment": null, "summary": "In multi-GPU Mixture-of-Experts (MoE) network, experts are distributed across\ndifferent GPUs, which creates load imbalance as each expert processes different\nnumber of tokens. Recent works improve MoE inference load balance by\ndynamically duplicating popular experts to more GPUs to process excessive\ntokens, which requires predicting the distribution before routing. In this\npaper, we discuss the tradeoff of prediction strategies, accuracies, overhead,\nand end-to-end system performance. We propose MoE-GPS, a framework that guides\nthe selection of the optimal predictor design under various system\nconfigurations, by quantifying the performance impact to system-level model\nruntime. Specifically, we advocate for Distribution-Only Prediction, a\nprediction strategy that only predicts overall token distribution which\nsignificantly reduces overhead compared to the traditional Token-to-Expert\nPrediction. On Mixtral 8x7B MMLU dataset, MoE-GPS suggests Distribution-Only\nPrediction which improves end-to-end inference performance by more than 23%\ncompared with Token-to-Expert Prediction.", "AI": {"tldr": "MoE-GPS\u6846\u67b6\u901a\u8fc7\u91cf\u5316\u9884\u6d4b\u7b56\u7565\u5bf9\u7cfb\u7edf\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u4f18\u5316\u591aGPU MoE\u7f51\u7edc\u7684\u8d1f\u8f7d\u5747\u8861\uff0c\u63d0\u51fa\u4ec5\u9884\u6d4b\u603b\u4f53token\u5206\u5e03\u7684\u7b56\u7565\uff0c\u6027\u80fd\u63d0\u534723%\u3002", "motivation": "\u591aGPU MoE\u7f51\u7edc\u4e2d\u4e13\u5bb6\u8d1f\u8f7d\u4e0d\u5747\u8861\uff0c\u73b0\u6709\u65b9\u6cd5\u9700\u9884\u6d4btoken\u5206\u5e03\uff0c\u4f46\u9884\u6d4b\u7b56\u7565\u5b58\u5728\u6027\u80fd\u4e0e\u5f00\u9500\u7684\u6743\u8861\u3002", "method": "\u63d0\u51faMoE-GPS\u6846\u67b6\uff0c\u91cf\u5316\u9884\u6d4b\u7b56\u7565\u5bf9\u7cfb\u7edf\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u63a8\u8350\u4ec5\u9884\u6d4b\u603b\u4f53token\u5206\u5e03\u7684\u7b56\u7565\uff08Distribution-Only Prediction\uff09\u3002", "result": "\u5728Mixtral 8x7B MMLU\u6570\u636e\u96c6\u4e0a\uff0cDistribution-Only Prediction\u6bd4\u4f20\u7edf\u65b9\u6cd5\u6027\u80fd\u63d0\u534723%\u3002", "conclusion": "MoE-GPS\u80fd\u6709\u6548\u6307\u5bfc\u9884\u6d4b\u7b56\u7565\u9009\u62e9\uff0c\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2506.07378", "pdf": "https://arxiv.org/pdf/2506.07378", "abs": "https://arxiv.org/abs/2506.07378", "authors": ["Yuen Chen", "Haozhe Si", "Guojun Zhang", "Han Zhao"], "title": "Moment Alignment: Unifying Gradient and Hessian Matching for Domain Generalization", "categories": ["cs.LG", "stat.ML"], "comment": "UAI 2025", "summary": "Domain generalization (DG) seeks to develop models that generalize well to\nunseen target domains, addressing the prevalent issue of distribution shifts in\nreal-world applications. One line of research in DG focuses on aligning\ndomain-level gradients and Hessians to enhance generalization. However,\nexisting methods are computationally inefficient and the underlying principles\nof these approaches are not well understood. In this paper, we develop the\ntheory of moment alignment for DG. Grounded in \\textit{transfer measure}, a\nprincipled framework for quantifying generalizability between two domains, we\nfirst extend the definition of transfer measure to domain generalization that\nincludes multiple source domains and establish a target error bound. Then, we\nprove that aligning derivatives across domains improves transfer measure both\nwhen the feature extractor induces an invariant optimal predictor across\ndomains and when it does not. Notably, moment alignment provides a unifying\nunderstanding of Invariant Risk Minimization, gradient matching, and Hessian\nmatching, three previously disconnected approaches to DG. We further connect\nfeature moments and derivatives of the classifier head, and establish the\nduality between feature learning and classifier fitting. Building upon our\ntheory, we introduce \\textbf{C}losed-Form \\textbf{M}oment \\textbf{A}lignment\n(CMA), a novel DG algorithm that aligns domain-level gradients and Hessians in\nclosed-form. Our method overcomes the computational inefficiencies of existing\ngradient and Hessian-based techniques by eliminating the need for repeated\nbackpropagation or sampling-based Hessian estimation. We validate the efficacy\nof our approach through two sets of experiments: linear probing and full\nfine-tuning. CMA demonstrates superior performance in both settings compared to\nEmpirical Risk Minimization and state-of-the-art algorithms.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u77e9\u5bf9\u9f50\u7406\u8bba\u7684\u57df\u6cdb\u5316\u65b9\u6cd5\uff08CMA\uff09\uff0c\u901a\u8fc7\u95ed\u5f0f\u5bf9\u9f50\u68af\u5ea6\u548cHessian\u77e9\u9635\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u8ba1\u7b97\u6548\u7387\u95ee\u9898\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u57df\u6cdb\u5316\uff08DG\uff09\u65e8\u5728\u89e3\u51b3\u73b0\u5b9e\u5e94\u7528\u4e2d\u5206\u5e03\u504f\u79fb\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u8ba1\u7b97\u6548\u7387\u4f4e\u4e14\u7406\u8bba\u4e0d\u6e05\u6670\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u4e14\u7406\u8bba\u5b8c\u5907\u7684\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u8f6c\u79fb\u6d4b\u5ea6\u7684\u7406\u8bba\u6846\u67b6\uff0c\u63d0\u51fa\u95ed\u5f0f\u77e9\u5bf9\u9f50\uff08CMA\uff09\u7b97\u6cd5\uff0c\u901a\u8fc7\u95ed\u5f0f\u5bf9\u9f50\u68af\u5ea6\u548cHessian\u77e9\u9635\uff0c\u907f\u514d\u91cd\u590d\u53cd\u5411\u4f20\u64ad\u6216\u91c7\u6837\u4f30\u8ba1\u3002", "result": "CMA\u5728\u7ebf\u6027\u63a2\u6d4b\u548c\u5168\u5fae\u8c03\u5b9e\u9a8c\u4e2d\u5747\u4f18\u4e8e\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\u548c\u73b0\u6709\u5148\u8fdb\u7b97\u6cd5\u3002", "conclusion": "\u77e9\u5bf9\u9f50\u7406\u8bba\u7edf\u4e00\u4e86\u591a\u79cdDG\u65b9\u6cd5\uff0cCMA\u7b97\u6cd5\u5728\u6548\u7387\u548c\u6027\u80fd\u4e0a\u5747\u6709\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2506.07405", "pdf": "https://arxiv.org/pdf/2506.07405", "abs": "https://arxiv.org/abs/2506.07405", "authors": ["Zhongping Ji"], "title": "RiemannFormer: A Framework for Attention in Curved Spaces", "categories": ["cs.LG"], "comment": "10 pages, 1 figure", "summary": "This research endeavors to offer insights into unlocking the further\npotential of transformer-based architectures. One of the primary motivations is\nto offer a geometric interpretation for the attention mechanism in\ntransformers. In our framework, the attention mainly involves metric tensors,\ntangent spaces, inner product, and how they relate to each other. These\nquantities and structures at discrete positions are intricately interconnected\nvia the parallel transport of tangent vectors. To make the learning process\nmore efficient, we reduce the number of parameters through ingenious predefined\nconfigurations. Moreover, we introduce an explicit mechanism to highlight a\nneighborhood by attenuating the remote values, given that transformers\ninherently neglect local inductive bias. Experimental results demonstrate that\nour modules deliver significant performance improvements relative to the\nbaseline. More evaluation experiments on visual and large language models will\nbe launched successively.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u51e0\u4f55\u89c6\u89d2\u7684Transformer\u6ce8\u610f\u529b\u673a\u5236\u89e3\u91ca\uff0c\u901a\u8fc7\u51cf\u5c11\u53c2\u6570\u548c\u589e\u5f3a\u5c40\u90e8\u6027\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u4e3aTransformer\u7684\u6ce8\u610f\u529b\u673a\u5236\u63d0\u4f9b\u51e0\u4f55\u89e3\u91ca\uff0c\u5e76\u89e3\u51b3\u5176\u5ffd\u89c6\u5c40\u90e8\u5f52\u7eb3\u504f\u7f6e\u7684\u95ee\u9898\u3002", "method": "\u5229\u7528\u5ea6\u91cf\u5f20\u91cf\u3001\u5207\u7a7a\u95f4\u548c\u5185\u79ef\u7b49\u51e0\u4f55\u6982\u5ff5\uff0c\u901a\u8fc7\u5e76\u884c\u4f20\u8f93\u8fde\u63a5\u79bb\u6563\u4f4d\u7f6e\u7684\u7ed3\u6784\uff0c\u5e76\u51cf\u5c11\u53c2\u6570\u6570\u91cf\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3aTransformer\u7684\u51e0\u4f55\u89e3\u91ca\u548c\u6027\u80fd\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u672a\u6765\u5c06\u5728\u89c6\u89c9\u548c\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u3002"}}
{"id": "2506.07406", "pdf": "https://arxiv.org/pdf/2506.07406", "abs": "https://arxiv.org/abs/2506.07406", "authors": ["Yifan Luo", "Zhennan Zhou", "Bin Dong"], "title": "InverseScope: Scalable Activation Inversion for Interpreting Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": "18 pages, 8 figures", "summary": "Understanding the internal representations of large language models (LLMs) is\na central challenge in interpretability research. Existing feature\ninterpretability methods often rely on strong assumptions about the structure\nof representations that may not hold in practice. In this work, we introduce\nInverseScope, an assumption-light and scalable framework for interpreting\nneural activations via input inversion. Given a target activation, we define a\ndistribution over inputs that generate similar activations and analyze this\ndistribution to infer the encoded features. To address the inefficiency of\nsampling in high-dimensional spaces, we propose a novel conditional generation\narchitecture that significantly improves sample efficiency compared to previous\nmethods. We further introduce a quantitative evaluation protocol that tests\ninterpretability hypotheses using feature consistency rate computed over the\nsampled inputs. InverseScope scales inversion-based interpretability methods to\nlarger models and practical tasks, enabling systematic and quantitative\nanalysis of internal representations in real-world LLMs.", "AI": {"tldr": "InverseScope\u662f\u4e00\u79cd\u8f7b\u5047\u8bbe\u3001\u53ef\u6269\u5c55\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u8f93\u5165\u53cd\u6f14\u89e3\u91ca\u795e\u7ecf\u7f51\u7edc\u6fc0\u6d3b\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6837\u672c\u6548\u7387\uff0c\u5e76\u652f\u6301\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u8868\u793a\u7684\u7cfb\u7edf\u5b9a\u91cf\u5206\u6790\u3002", "motivation": "\u7406\u89e3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u5185\u90e8\u8868\u793a\u662f\u89e3\u91ca\u6027\u7814\u7a76\u7684\u6838\u5fc3\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u7684\u5f3a\u5047\u8bbe\u5728\u5b9e\u9645\u4e2d\u53ef\u80fd\u4e0d\u6210\u7acb\u3002", "method": "\u63d0\u51faInverseScope\u6846\u67b6\uff0c\u901a\u8fc7\u5b9a\u4e49\u751f\u6210\u76f8\u4f3c\u6fc0\u6d3b\u7684\u8f93\u5165\u5206\u5e03\u6765\u5206\u6790\u7f16\u7801\u7279\u5f81\uff0c\u91c7\u7528\u6761\u4ef6\u751f\u6210\u67b6\u6784\u63d0\u9ad8\u91c7\u6837\u6548\u7387\uff0c\u5e76\u5f15\u5165\u5b9a\u91cf\u8bc4\u4f30\u534f\u8bae\u3002", "result": "InverseScope\u80fd\u591f\u6269\u5c55\u5230\u66f4\u5927\u6a21\u578b\u548c\u5b9e\u9645\u4efb\u52a1\uff0c\u5b9e\u73b0\u5bf9LLMs\u5185\u90e8\u8868\u793a\u7684\u7cfb\u7edf\u5b9a\u91cf\u5206\u6790\u3002", "conclusion": "InverseScope\u4e3a\u89e3\u91ca\u795e\u7ecf\u7f51\u7edc\u6fc0\u6d3b\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\uff0c\u63a8\u52a8\u4e86LLMs\u89e3\u91ca\u6027\u7814\u7a76\u7684\u8fdb\u5c55\u3002"}}
{"id": "2506.07407", "pdf": "https://arxiv.org/pdf/2506.07407", "abs": "https://arxiv.org/abs/2506.07407", "authors": ["Yihong Jin", "Ze Yang", "Juntian Liu", "Xinhe Xu"], "title": "Anomaly Detection and Early Warning Mechanism for Intelligent Monitoring Systems in Multi-Cloud Environments Based on LLM", "categories": ["cs.LG", "cs.AI"], "comment": "Proceedings of 2025 5th International Symposium on Computer\n  Technology and Information Science (ISCTIS 2025)", "summary": "With the rapid development of multi-cloud environments, it is increasingly\nimportant to ensure the security and reliability of intelligent monitoring\nsystems. In this paper, we propose an anomaly detection and early warning\nmechanism for intelligent monitoring system in multi-cloud environment based on\nLarge-Scale Language Model (LLM). On the basis of the existing monitoring\nframework, the proposed model innovatively introduces a multi-level feature\nextraction method, which combines the natural language processing ability of\nLLM with traditional machine learning methods to enhance the accuracy of\nanomaly detection and improve the real-time response efficiency. By introducing\nthe contextual understanding capabilities of LLMs, the model dynamically adapts\nto different cloud service providers and environments, so as to more\neffectively detect abnormal patterns and predict potential failures.\nExperimental results show that the proposed model is significantly better than\nthe traditional anomaly detection system in terms of detection accuracy and\nlatency, and significantly improves the resilience and active management\nability of cloud infrastructure.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u591a\u4e91\u73af\u5883\u667a\u80fd\u76d1\u63a7\u7cfb\u7edf\u5f02\u5e38\u68c0\u6d4b\u4e0e\u9884\u8b66\u673a\u5236\uff0c\u901a\u8fc7\u7ed3\u5408LLM\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u80fd\u529b\u548c\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u68c0\u6d4b\u7cbe\u5ea6\u548c\u5b9e\u65f6\u54cd\u5e94\u6548\u7387\u3002", "motivation": "\u968f\u7740\u591a\u4e91\u73af\u5883\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u786e\u4fdd\u667a\u80fd\u76d1\u63a7\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u53d8\u5f97\u6108\u53d1\u91cd\u8981\u3002", "method": "\u5728\u73b0\u6709\u76d1\u63a7\u6846\u67b6\u57fa\u7840\u4e0a\uff0c\u521b\u65b0\u6027\u5730\u5f15\u5165\u591a\u7ea7\u7279\u5f81\u63d0\u53d6\u65b9\u6cd5\uff0c\u7ed3\u5408LLM\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u80fd\u529b\u548c\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u52a8\u6001\u9002\u5e94\u4e0d\u540c\u4e91\u670d\u52a1\u63d0\u4f9b\u5546\u548c\u73af\u5883\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6a21\u578b\u5728\u68c0\u6d4b\u7cbe\u5ea6\u548c\u5ef6\u8fdf\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u5f02\u5e38\u68c0\u6d4b\u7cfb\u7edf\uff0c\u5e76\u663e\u8457\u63d0\u5347\u4e86\u4e91\u57fa\u7840\u8bbe\u65bd\u7684\u97e7\u6027\u548c\u4e3b\u52a8\u7ba1\u7406\u80fd\u529b\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u591a\u4e91\u73af\u5883\u4e0b\u7684\u667a\u80fd\u76d1\u63a7\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u9760\u7684\u5f02\u5e38\u68c0\u6d4b\u4e0e\u9884\u8b66\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.07408", "pdf": "https://arxiv.org/pdf/2506.07408", "abs": "https://arxiv.org/abs/2506.07408", "authors": ["Xiaojun zhou", "Chunna Zhao", "Yaqun Huang", "Chengli Zhou", "Junjie Ye", "Kemeng Xiang"], "title": "Fractional-order Jacobian Matrix Differentiation and Its Application in Artificial Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Fractional-order differentiation has many characteristics different from\ninteger-order differentiation. These characteristics can be applied to the\noptimization algorithms of artificial neural networks to obtain better results.\nHowever, due to insufficient theoretical research, at present, there is no\nfractional-order matrix differentiation method that is perfectly compatible\nwith automatic differentiation (Autograd) technology. Therefore, we propose a\nfractional-order matrix differentiation calculation method. This method is\nintroduced by the definition of the integer-order Jacobian matrix. We denote it\nas fractional-order Jacobian matrix differentiation (${{\\bf{J}}^\\alpha }$).\nThrough ${{\\bf{J}}^\\alpha }$, we can carry out the matrix-based\nfractional-order chain rule. Based on the Linear module and the\nfractional-order differentiation, we design the fractional-order Autograd\ntechnology to enable the use of fractional-order differentiation in hidden\nlayers, thereby enhancing the practicality of fractional-order differentiation\nin deep learning. In the experiment, according to the PyTorch framework, we\ndesign fractional-order Linear (FLinear) and replace nn.Linear in the\nmultilayer perceptron with FLinear. Through the qualitative analysis of the\ntraining set and validation set $Loss$, the quantitative analysis of the test\nset indicators, and the analysis of time consumption and GPU memory usage\nduring model training, we verify the superior performance of ${{\\bf{J}}^\\alpha\n}$ and prove that it is an excellent fractional-order gradient descent method\nin the field of deep learning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5206\u6570\u9636\u96c5\u53ef\u6bd4\u77e9\u9635\u7684\u81ea\u52a8\u5fae\u5206\u6280\u672f\uff0c\u7528\u4e8e\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u5206\u6570\u9636\u68af\u5ea6\u4e0b\u964d\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u5206\u6570\u9636\u5fae\u5206\u5728\u795e\u7ecf\u7f51\u7edc\u4f18\u5316\u4e2d\u6709\u6f5c\u529b\uff0c\u4f46\u7f3a\u4e4f\u4e0e\u81ea\u52a8\u5fae\u5206\u6280\u672f\u517c\u5bb9\u7684\u5206\u6570\u9636\u77e9\u9635\u5fae\u5206\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u6574\u6570\u9636\u96c5\u53ef\u6bd4\u77e9\u9635\u5b9a\u4e49\u5f15\u5165\u5206\u6570\u9636\u96c5\u53ef\u6bd4\u77e9\u9635\uff0c\u8bbe\u8ba1\u5206\u6570\u9636\u81ea\u52a8\u5fae\u5206\u6280\u672f\uff0c\u5e76\u5728\u591a\u5c42\u611f\u77e5\u673a\u4e2d\u5e94\u7528\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u6d4b\u8bd5\u96c6\u6307\u6807\u548c\u65f6\u95f4\u3001\u5185\u5b58\u6d88\u8017\u5747\u9a8c\u8bc1\u5176\u9ad8\u6548\u6027\u3002", "conclusion": "\u5206\u6570\u9636\u96c5\u53ef\u6bd4\u77e9\u9635\u5fae\u5206\u662f\u4e00\u79cd\u4f18\u79c0\u7684\u6df1\u5ea6\u5b66\u4e60\u5206\u6570\u9636\u68af\u5ea6\u4e0b\u964d\u65b9\u6cd5\u3002"}}
{"id": "2506.07413", "pdf": "https://arxiv.org/pdf/2506.07413", "abs": "https://arxiv.org/abs/2506.07413", "authors": ["Ziwen Wang", "Jiajun Fan", "Thao Nguyen", "Heng Ji", "Ge Liu"], "title": "Variational Supervised Contrastive Learning", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Contrastive learning has proven to be highly efficient and adaptable in\nshaping representation spaces across diverse modalities by pulling similar\nsamples together and pushing dissimilar ones apart. However, two key\nlimitations persist: (1) Without explicit regulation of the embedding\ndistribution, semantically related instances can inadvertently be pushed apart\nunless complementary signals guide pair selection, and (2) excessive reliance\non large in-batch negatives and tailored augmentations hinders generalization.\nTo address these limitations, we propose Variational Supervised Contrastive\nLearning (VarCon), which reformulates supervised contrastive learning as\nvariational inference over latent class variables and maximizes a\nposterior-weighted evidence lower bound (ELBO) that replaces exhaustive\npair-wise comparisons for efficient class-aware matching and grants\nfine-grained control over intra-class dispersion in the embedding space.\nTrained exclusively on image data, our experiments on CIFAR-10, CIFAR-100,\nImageNet-100, and ImageNet-1K show that VarCon (1) achieves state-of-the-art\nperformance for contrastive learning frameworks, reaching 79.36% Top-1 accuracy\non ImageNet-1K and 78.29% on CIFAR-100 with a ResNet-50 encoder while\nconverging in just 200 epochs; (2) yields substantially clearer decision\nboundaries and semantic organization in the embedding space, as evidenced by\nKNN classification, hierarchical clustering results, and transfer-learning\nassessments; and (3) demonstrates superior performance in few-shot learning\nthan supervised baseline and superior robustness across various augmentation\nstrategies.", "AI": {"tldr": "VarCon\u63d0\u51fa\u4e86\u4e00\u79cd\u53d8\u5206\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u53d8\u5206\u63a8\u65ad\u4f18\u5316\u5d4c\u5165\u7a7a\u95f4\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5bf9\u6bd4\u5b66\u4e60\u7684\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u5bf9\u6bd4\u5b66\u4e60\u5b58\u5728\u5d4c\u5165\u5206\u5e03\u7f3a\u4e4f\u660e\u786e\u8c03\u63a7\u548c\u8fc7\u5ea6\u4f9d\u8d56\u5927\u6279\u91cf\u8d1f\u6837\u672c\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u8bed\u4e49\u76f8\u5173\u5b9e\u4f8b\u88ab\u9519\u8bef\u5206\u79bb\u4e14\u6cdb\u5316\u80fd\u529b\u53d7\u9650\u3002", "method": "VarCon\u5c06\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u91cd\u65b0\u8868\u8ff0\u4e3a\u5bf9\u6f5c\u5728\u7c7b\u522b\u53d8\u91cf\u7684\u53d8\u5206\u63a8\u65ad\uff0c\u6700\u5927\u5316\u540e\u9a8c\u52a0\u6743\u7684\u8bc1\u636e\u4e0b\u754c\uff08ELBO\uff09\uff0c\u5b9e\u73b0\u9ad8\u6548\u7684\u7c7b\u611f\u77e5\u5339\u914d\u548c\u7ec6\u7c92\u5ea6\u63a7\u5236\u3002", "result": "VarCon\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff08\u5982ImageNet-1K\u4e0a79.36% Top-1\u51c6\u786e\u7387\uff09\uff0c\u5e76\u8868\u73b0\u51fa\u66f4\u6e05\u6670\u7684\u51b3\u7b56\u8fb9\u754c\u548c\u8bed\u4e49\u7ec4\u7ec7\u3002", "conclusion": "VarCon\u901a\u8fc7\u53d8\u5206\u63a8\u65ad\u663e\u8457\u63d0\u5347\u4e86\u5bf9\u6bd4\u5b66\u4e60\u7684\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u9002\u7528\u4e8e\u5c11\u6837\u672c\u5b66\u4e60\u548c\u591a\u79cd\u589e\u5f3a\u7b56\u7565\u3002"}}
{"id": "2506.07416", "pdf": "https://arxiv.org/pdf/2506.07416", "abs": "https://arxiv.org/abs/2506.07416", "authors": ["Jin Huang", "Yuchao Jin", "Le An", "Josh Park"], "title": "LiteVLM: A Low-Latency Vision-Language Model Inference Pipeline for Resource-Constrained Environments", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper introduces an efficient Vision-Language Model (VLM) pipeline\nspecifically optimized for deployment on embedded devices, such as those used\nin robotics and autonomous driving. The pipeline significantly reduces the\ncomputational overhead by jointly leveraging patch selection to filter\nirrelevant camera views, a token selection module to reduce input sequence\nlength for the LLM, and speculative decoding to accelerate token generation.\nEvaluation on the NVIDIA DRIVE Thor platform for automonous driving\napplication, our pipeline achieves $2.5\\times$ end-to-end latency reduction\nwithout compromising task accuracy. The speed-up further increases to\n$3.2\\times$ when applying FP8 post-training quantization. These results\ndemonstrate our pipeline as a viable solution for enabling real-time VLM\ndeployment in resource-constrained environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u5d4c\u5165\u5f0f\u8bbe\u5907\u4f18\u5316\u7684\u9ad8\u6548\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u6d41\u6c34\u7ebf\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u5f00\u9500\uff0c\u5e76\u5728\u81ea\u52a8\u9a7e\u9a76\u5e94\u7528\u4e2d\u5b9e\u73b0\u4e862.5\u500d\u7684\u7aef\u5230\u7aef\u5ef6\u8fdf\u51cf\u5c11\u3002", "motivation": "\u4e3a\u8d44\u6e90\u53d7\u9650\u7684\u73af\u5883\uff08\u5982\u673a\u5668\u4eba\u548c\u81ea\u52a8\u9a7e\u9a76\u8bbe\u5907\uff09\u63d0\u4f9b\u5b9e\u65f6\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u8054\u5408\u5229\u7528\u8865\u4e01\u9009\u62e9\u3001\u4ee4\u724c\u9009\u62e9\u6a21\u5757\u548c\u63a8\u6d4b\u89e3\u7801\u6765\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u3002", "result": "\u5728NVIDIA DRIVE Thor\u5e73\u53f0\u4e0a\uff0c\u6d41\u6c34\u7ebf\u5b9e\u73b0\u4e862.5\u500d\u7684\u5ef6\u8fdf\u51cf\u5c11\uff0c\u5e94\u7528FP8\u91cf\u5316\u540e\u63d0\u5347\u81f33.2\u500d\u3002", "conclusion": "\u8be5\u6d41\u6c34\u7ebf\u662f\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u5b9e\u65f6VLM\u90e8\u7f72\u7684\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.07417", "pdf": "https://arxiv.org/pdf/2506.07417", "abs": "https://arxiv.org/abs/2506.07417", "authors": ["Nan Sun", "Xixun Lin", "Zhiheng Zhou", "Yanmin Shang", "Zhenlin Cheng", "Yanan Cao"], "title": "Evidential Spectrum-Aware Contrastive Learning for OOD Detection in Dynamic Graphs", "categories": ["cs.LG", "cs.AI"], "comment": "17 pages,5 figures", "summary": "Recently, Out-of-distribution (OOD) detection in dynamic graphs, which aims\nto identify whether incoming data deviates from the distribution of the\nin-distribution (ID) training set, has garnered considerable attention in\nsecurity-sensitive fields. Current OOD detection paradigms primarily focus on\nstatic graphs and confront two critical challenges: i) high bias and high\nvariance caused by single-point estimation, which makes the predictions\nsensitive to randomness in the data; ii) score homogenization resulting from\nthe lack of OOD training data, where the model only learns ID-specific\npatterns, resulting in overall low OOD scores and a narrow score gap between ID\nand OOD data. To tackle these issues, we first investigate OOD detection in\ndynamic graphs through the lens of Evidential Deep Learning (EDL).\nSpecifically, we propose EviSEC, an innovative and effective OOD detector via\nEvidential Spectrum-awarE Contrastive Learning. We design an evidential neural\nnetwork to redefine the output as the posterior Dirichlet distribution,\nexplaining the randomness of inputs through the uncertainty of distribution,\nwhich is overlooked by single-point estimation. Moreover, spectrum-aware\naugmentation module generates OOD approximations to identify patterns with high\nOOD scores, thereby widening the score gap between ID and OOD data and\nmitigating score homogenization. Extensive experiments on real-world datasets\ndemonstrate that EviSAC effectively detects OOD samples in dynamic graphs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bc1\u636e\u6df1\u5ea6\u5b66\u4e60\u7684\u52a8\u6001\u56feOOD\u68c0\u6d4b\u65b9\u6cd5EviSEC\uff0c\u901a\u8fc7\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u548c\u8c31\u611f\u77e5\u5bf9\u6bd4\u5b66\u4e60\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u504f\u5dee\u548c\u5206\u6570\u540c\u8d28\u5316\u95ee\u9898\u3002", "motivation": "\u52a8\u6001\u56fe\u4e2d\u7684OOD\u68c0\u6d4b\u5728\u5b89\u5168\u654f\u611f\u9886\u57df\u5907\u53d7\u5173\u6ce8\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u56e0\u5355\u70b9\u4f30\u8ba1\u548c\u7f3a\u4e4fOOD\u8bad\u7ec3\u6570\u636e\u5bfc\u81f4\u9ad8\u504f\u5dee\u548c\u5206\u6570\u540c\u8d28\u5316\u95ee\u9898\u3002", "method": "\u63d0\u51faEviSEC\uff0c\u7ed3\u5408\u8bc1\u636e\u795e\u7ecf\u7f51\u7edc\u548c\u8c31\u611f\u77e5\u5bf9\u6bd4\u5b66\u4e60\u6a21\u5757\uff0c\u901a\u8fc7\u540e\u9a8cDirichlet\u5206\u5e03\u89e3\u91ca\u8f93\u5165\u968f\u673a\u6027\uff0c\u5e76\u751f\u6210OOD\u8fd1\u4f3c\u6837\u672c\u4ee5\u6269\u5927ID\u4e0eOOD\u5206\u6570\u5dee\u8ddd\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cEviSEC\u80fd\u6709\u6548\u68c0\u6d4b\u52a8\u6001\u56fe\u4e2d\u7684OOD\u6837\u672c\u3002", "conclusion": "EviSEC\u901a\u8fc7\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u548c\u8c31\u611f\u77e5\u5bf9\u6bd4\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u5347\u4e86\u52a8\u6001\u56feOOD\u68c0\u6d4b\u7684\u6027\u80fd\u3002"}}
{"id": "2506.07440", "pdf": "https://arxiv.org/pdf/2506.07440", "abs": "https://arxiv.org/abs/2506.07440", "authors": ["Ruhan Wang", "Zhiyong Wang", "Chengkai Huang", "Rui Wang", "Tong Yu", "Lina Yao", "John C. S. Lui", "Dongruo Zhou"], "title": "Federated In-Context Learning: Iterative Refinement for Improved Answer Quality", "categories": ["cs.LG"], "comment": "27 pages, 16 figures. Accepted to ICML 2025", "summary": "For question-answering (QA) tasks, in-context learning (ICL) enables language\nmodels to generate responses without modifying their parameters by leveraging\nexamples provided in the input. However, the effectiveness of ICL heavily\ndepends on the availability of high-quality examples, which are often scarce\ndue to data privacy constraints, annotation costs, and distribution\ndisparities. A natural solution is to utilize examples stored on client\ndevices, but existing approaches either require transmitting model parameters -\nincurring significant communication overhead - or fail to fully exploit local\ndatasets, limiting their effectiveness. To address these challenges, we propose\nFederated In-Context Learning (Fed-ICL), a general framework that enhances ICL\nthrough an iterative, collaborative process. Fed-ICL progressively refines\nresponses by leveraging multi-round interactions between clients and a central\nserver, improving answer quality without the need to transmit model parameters.\nWe establish theoretical guarantees for the convergence of Fed-ICL and conduct\nextensive experiments on standard QA benchmarks, demonstrating that our\nproposed approach achieves strong performance while maintaining low\ncommunication costs.", "AI": {"tldr": "Fed-ICL\u6846\u67b6\u901a\u8fc7\u591a\u8f6e\u5ba2\u6237\u7aef\u4e0e\u670d\u52a1\u5668\u4ea4\u4e92\u63d0\u5347\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u6548\u679c\uff0c\u65e0\u9700\u4f20\u8f93\u6a21\u578b\u53c2\u6570\uff0c\u964d\u4f4e\u901a\u4fe1\u5f00\u9500\u3002", "motivation": "\u73b0\u6709\u4e0a\u4e0b\u6587\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u9ad8\u8d28\u91cf\u793a\u4f8b\uff0c\u4f46\u6570\u636e\u9690\u79c1\u3001\u6807\u6ce8\u6210\u672c\u548c\u5206\u5e03\u5dee\u5f02\u5bfc\u81f4\u793a\u4f8b\u7a00\u7f3a\uff0c\u800c\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u901a\u4fe1\u5f00\u9500\u5927\u6216\u672a\u80fd\u5145\u5206\u5229\u7528\u672c\u5730\u6570\u636e\u3002", "method": "\u63d0\u51faFed-ICL\u6846\u67b6\uff0c\u901a\u8fc7\u5ba2\u6237\u7aef\u4e0e\u670d\u52a1\u5668\u7684\u591a\u8f6e\u4ea4\u4e92\u8fed\u4ee3\u4f18\u5316\u56de\u7b54\uff0c\u907f\u514d\u6a21\u578b\u53c2\u6570\u4f20\u8f93\u3002", "result": "\u7406\u8bba\u8bc1\u660eFed-ICL\u6536\u655b\u6027\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u5728\u6807\u51c6\u95ee\u7b54\u57fa\u51c6\u4e0a\u8868\u73b0\u4f18\u5f02\u4e14\u901a\u4fe1\u6210\u672c\u4f4e\u3002", "conclusion": "Fed-ICL\u4e3a\u4e0a\u4e0b\u6587\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u4f4e\u901a\u4fe1\u5f00\u9500\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.07448", "pdf": "https://arxiv.org/pdf/2506.07448", "abs": "https://arxiv.org/abs/2506.07448", "authors": ["T. Duy Nguyen-Hien", "Desi R. Ivanova", "Yee Whye Teh", "Wee Sun Lee"], "title": "Extending Epistemic Uncertainty Beyond Parameters Would Assist in Designing Reliable LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Although large language models (LLMs) are highly interactive and extendable,\ncurrent approaches to ensure reliability in deployments remain mostly limited\nto rejecting outputs with high uncertainty in order to avoid misinformation.\nThis conservative strategy reflects the current lack of tools to systematically\ndistinguish and respond to different sources of uncertainty. In this paper, we\nadvocate for the adoption of Bayesian Modeling of Experiments -- a framework\nthat provides a coherent foundation to reason about uncertainty and clarify the\nreducibility of uncertainty -- for managing and proactively addressing\nuncertainty that arises in LLM deployments. This framework enables LLMs and\ntheir users to take contextually appropriate steps, such as requesting\nclarification, retrieving external information, or refining inputs. By\nsupporting active resolution rather than passive avoidance, it opens the door\nto more reliable, transparent, and broadly applicable LLM systems, particularly\nin high-stakes, real-world settings.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8d1d\u53f6\u65af\u5b9e\u9a8c\u5efa\u6a21\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u4e3b\u52a8\u7ba1\u7406\u548c\u89e3\u51b3LLM\u90e8\u7f72\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u800c\u975e\u88ab\u52a8\u62d2\u7edd\u9ad8\u4e0d\u786e\u5b9a\u6027\u8f93\u51fa\u3002", "motivation": "\u5f53\u524dLLM\u90e8\u7f72\u4e2d\u7f3a\u4e4f\u7cfb\u7edf\u533a\u5206\u548c\u5e94\u5bf9\u4e0d\u540c\u4e0d\u786e\u5b9a\u6027\u6765\u6e90\u7684\u5de5\u5177\uff0c\u5bfc\u81f4\u4fdd\u5b88\u7b56\u7565\uff08\u5982\u62d2\u7edd\u9ad8\u4e0d\u786e\u5b9a\u6027\u8f93\u51fa\uff09\u7684\u5c40\u9650\u6027\u3002", "method": "\u91c7\u7528\u8d1d\u53f6\u65af\u5b9e\u9a8c\u5efa\u6a21\u6846\u67b6\uff0c\u4e3a\u4e0d\u786e\u5b9a\u6027\u63d0\u4f9b\u4e00\u81f4\u6027\u63a8\u7406\u57fa\u7840\uff0c\u5e76\u652f\u6301\u4e3b\u52a8\u89e3\u51b3\u63aa\u65bd\uff08\u5982\u8bf7\u6c42\u6f84\u6e05\u3001\u68c0\u7d22\u5916\u90e8\u4fe1\u606f\uff09\u3002", "result": "\u8be5\u6846\u67b6\u4f7fLLM\u53ca\u5176\u7528\u6237\u80fd\u591f\u91c7\u53d6\u60c5\u5883\u9002\u5f53\u7684\u6b65\u9aa4\uff0c\u63d0\u5347\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u3001\u900f\u660e\u6027\u548c\u9002\u7528\u6027\u3002", "conclusion": "\u8d1d\u53f6\u65af\u5b9e\u9a8c\u5efa\u6a21\u4e3aLLM\u90e8\u7f72\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u7ba1\u7406\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u9ad8\u98ce\u9669\u73b0\u5b9e\u573a\u666f\u3002"}}
{"id": "2506.07452", "pdf": "https://arxiv.org/pdf/2506.07452", "abs": "https://arxiv.org/abs/2506.07452", "authors": ["Yuxin Xiao", "Sana Tonekaboni", "Walter Gerych", "Vinith Suriyakumar", "Marzyeh Ghassemi"], "title": "When Style Breaks Safety: Defending Language Models Against Superficial Style Alignment", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CY"], "comment": null, "summary": "Large language models (LLMs) can be prompted with specific styles (e.g.,\nformatting responses as lists), including in jailbreak queries. Although these\nstyle patterns are semantically unrelated to the malicious intents behind\njailbreak queries, their safety impact remains unclear. In this work, we seek\nto understand whether style patterns compromise LLM safety, how superficial\nstyle alignment increases model vulnerability, and how best to mitigate these\nrisks during alignment. We evaluate 32 LLMs across seven jailbreak benchmarks,\nand find that malicious queries with style patterns inflate the attack success\nrate (ASR) for nearly all models. Notably, ASR inflation correlates with both\nthe length of style patterns and the relative attention an LLM exhibits on\nthem. We then investigate superficial style alignment, and find that\nfine-tuning with specific styles makes LLMs more vulnerable to jailbreaks of\nthose same styles. Finally, we propose SafeStyle, a defense strategy that\nincorporates a small amount of safety training data augmented to match the\ndistribution of style patterns in the fine-tuning data. Across three LLMs and\nfive fine-tuning style settings, SafeStyle consistently outperforms baselines\nin maintaining LLM safety.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u7279\u5b9a\u98ce\u683c\u63d0\u793a\u4f1a\u663e\u8457\u589e\u52a0\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u8d8a\u72f1\u653b\u51fb\u6210\u529f\u7387\uff0c\u4e14\u98ce\u683c\u957f\u5ea6\u548c\u6a21\u578b\u5bf9\u5176\u7684\u5173\u6ce8\u5ea6\u76f8\u5173\u3002\u63d0\u51fa\u4e86\u4e00\u79cd\u9632\u5fa1\u7b56\u7565SafeStyle\uff0c\u80fd\u6709\u6548\u63d0\u5347\u6a21\u578b\u5b89\u5168\u6027\u3002", "motivation": "\u63a2\u8ba8\u98ce\u683c\u63d0\u793a\u5bf9LLM\u5b89\u5168\u6027\u7684\u6f5c\u5728\u5f71\u54cd\uff0c\u4ee5\u53ca\u5982\u4f55\u901a\u8fc7\u9632\u5fa1\u7b56\u7565\u7f13\u89e3\u98ce\u9669\u3002", "method": "\u8bc4\u4f3032\u4e2aLLM\u5728\u4e03\u4e2a\u8d8a\u72f1\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u8868\u73b0\uff0c\u5206\u6790\u98ce\u683c\u63d0\u793a\u5bf9\u653b\u51fb\u6210\u529f\u7387\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51faSafeStyle\u9632\u5fa1\u7b56\u7565\u3002", "result": "\u98ce\u683c\u63d0\u793a\u663e\u8457\u63d0\u9ad8\u4e86\u8d8a\u72f1\u653b\u51fb\u6210\u529f\u7387\uff0c\u4e14\u4e0e\u98ce\u683c\u957f\u5ea6\u548c\u6a21\u578b\u5173\u6ce8\u5ea6\u76f8\u5173\u3002SafeStyle\u5728\u591a\u79cd\u8bbe\u7f6e\u4e0b\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u98ce\u683c\u63d0\u793a\u4f1a\u5a01\u80c1LLM\u5b89\u5168\u6027\uff0c\u4f46\u901a\u8fc7SafeStyle\u7b49\u9632\u5fa1\u7b56\u7565\u53ef\u4ee5\u6709\u6548\u7f13\u89e3\u98ce\u9669\u3002"}}
{"id": "2506.07459", "pdf": "https://arxiv.org/pdf/2506.07459", "abs": "https://arxiv.org/abs/2506.07459", "authors": ["Ziwen Wang", "Jiajun Fan", "Ruihan Guo", "Thao Nguyen", "Heng Ji", "Ge Liu"], "title": "ProteinZero: Self-Improving Protein Generation via Online Reinforcement Learning", "categories": ["cs.LG", "q-bio.QM"], "comment": null, "summary": "Protein generative models have shown remarkable promise in protein design but\nstill face limitations in success rate, due to the scarcity of high-quality\nprotein datasets for supervised pretraining. We present ProteinZero, a novel\nframework that enables scalable, automated, and continuous self-improvement of\nthe inverse folding model through online reinforcement learning. To achieve\ncomputationally tractable online feedback, we introduce efficient proxy reward\nmodels based on ESM-fold and a novel rapid ddG predictor that significantly\naccelerates evaluation speed. ProteinZero employs a general RL framework\nbalancing multi-reward maximization, KL-divergence from a reference model, and\na novel protein-embedding level diversity regularization that prevents mode\ncollapse while promoting higher sequence diversity. Through extensive\nexperiments, we demonstrate that ProteinZero substantially outperforms existing\nmethods across every key metric in protein design, achieving significant\nimprovements in structural accuracy, designability, thermodynamic stability,\nand sequence diversity. Most impressively, ProteinZero reduces design failure\nrates by approximately 36% - 48% compared to widely-used methods like\nProteinMPNN, ESM-IF and InstructPLM, consistently achieving success rates\nexceeding 90% across diverse and complex protein folds. Notably, the entire RL\nrun on CATH-4.3 can be done with a single 8 X GPU node in under 3 days,\nincluding reward computation. Our work establishes a new paradigm for protein\ndesign where models evolve continuously from their own generated outputs,\nopening new possibilities for exploring the vast protein design space.", "AI": {"tldr": "ProteinZero\u901a\u8fc7\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u63d0\u5347\u86cb\u767d\u8d28\u751f\u6210\u6a21\u578b\u7684\u6027\u80fd\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8bbe\u8ba1\u5931\u8d25\u7387\u5e76\u63d0\u9ad8\u4e86\u591a\u6837\u6027\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u86cb\u767d\u8d28\u751f\u6210\u6a21\u578b\u56e0\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u7a00\u7f3a\u800c\u6210\u529f\u7387\u53d7\u9650\uff0c\u9700\u8981\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u81ea\u52a8\u5316\u6539\u8fdb\u65b9\u6cd5\u3002", "method": "\u63d0\u51faProteinZero\u6846\u67b6\uff0c\u7ed3\u5408\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u3001\u9ad8\u6548\u4ee3\u7406\u5956\u52b1\u6a21\u578b\uff08ESM-fold\u548c\u5feb\u901fddG\u9884\u6d4b\u5668\uff09\u53ca\u591a\u6837\u6027\u6b63\u5219\u5316\u3002", "result": "ProteinZero\u5728\u7ed3\u6784\u51c6\u786e\u6027\u3001\u53ef\u8bbe\u8ba1\u6027\u3001\u70ed\u529b\u5b66\u7a33\u5b9a\u6027\u548c\u5e8f\u5217\u591a\u6837\u6027\u4e0a\u5168\u9762\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\uff0c\u5931\u8d25\u7387\u964d\u4f4e36%-48%\u3002", "conclusion": "ProteinZero\u4e3a\u86cb\u767d\u8d28\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6301\u7eed\u81ea\u6211\u6539\u8fdb\u7684\u65b0\u8303\u5f0f\uff0c\u6269\u5c55\u4e86\u8bbe\u8ba1\u7a7a\u95f4\u63a2\u7d22\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2506.07467", "pdf": "https://arxiv.org/pdf/2506.07467", "abs": "https://arxiv.org/abs/2506.07467", "authors": ["Jie Peng", "Hongwei Yang", "Jing Zhao", "Hengji Dong", "Hui He", "Weizhe Zhang", "Haoyu He"], "title": "Circumventing Backdoor Space via Weight Symmetry", "categories": ["cs.LG"], "comment": null, "summary": "Deep neural networks are vulnerable to backdoor attacks, where malicious\nbehaviors are implanted during training. While existing defenses can\neffectively purify compromised models, they typically require labeled data or\nspecific training procedures, making them difficult to apply beyond supervised\nlearning settings. Notably, recent studies have shown successful backdoor\nattacks across various learning paradigms, highlighting a critical security\nconcern. To address this gap, we propose Two-stage Symmetry Connectivity (TSC),\na novel backdoor purification defense that operates independently of data\nformat and requires only a small fraction of clean samples. Through theoretical\nanalysis, we prove that by leveraging permutation invariance in neural networks\nand quadratic mode connectivity, TSC amplifies the loss on poisoned samples\nwhile maintaining bounded clean accuracy. Experiments demonstrate that TSC\nachieves robust performance comparable to state-of-the-art methods in\nsupervised learning scenarios. Furthermore, TSC generalizes to self-supervised\nlearning frameworks, such as SimCLR and CLIP, maintaining its strong defense\ncapabilities. Our code is available at https://github.com/JiePeng104/TSC.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTSC\u7684\u65b0\u578b\u540e\u95e8\u51c0\u5316\u9632\u5fa1\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u5b66\u4e60\u8303\u5f0f\uff0c\u4ec5\u9700\u5c11\u91cf\u5e72\u51c0\u6837\u672c\u5373\u53ef\u6709\u6548\u9632\u5fa1\u540e\u95e8\u653b\u51fb\u3002", "motivation": "\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u6807\u8bb0\u6570\u636e\u6216\u7279\u5b9a\u8bad\u7ec3\u6d41\u7a0b\uff0c\u9650\u5236\u4e86\u5176\u5728\u76d1\u7763\u5b66\u4e60\u4ee5\u5916\u7684\u5e94\u7528\u3002\u540e\u95e8\u653b\u51fb\u5df2\u6269\u5c55\u5230\u591a\u79cd\u5b66\u4e60\u8303\u5f0f\uff0c\u4e9f\u9700\u901a\u7528\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faTwo-stage Symmetry Connectivity (TSC)\uff0c\u5229\u7528\u795e\u7ecf\u7f51\u7edc\u7684\u6392\u5217\u4e0d\u53d8\u6027\u548c\u4e8c\u6b21\u6a21\u5f0f\u8fde\u63a5\u6027\uff0c\u653e\u5927\u4e2d\u6bd2\u6837\u672c\u7684\u635f\u5931\uff0c\u540c\u65f6\u4fdd\u6301\u5e72\u51c0\u6837\u672c\u7684\u51c6\u786e\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cTSC\u5728\u76d1\u7763\u5b66\u4e60\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u80fd\u63a8\u5e7f\u5230\u81ea\u76d1\u7763\u5b66\u4e60\u6846\u67b6\uff08\u5982SimCLR\u548cCLIP\uff09\uff0c\u4fdd\u6301\u5f3a\u5927\u7684\u9632\u5fa1\u80fd\u529b\u3002", "conclusion": "TSC\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u901a\u7528\u7684\u540e\u95e8\u51c0\u5316\u9632\u5fa1\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u5b66\u4e60\u573a\u666f\u3002"}}
{"id": "2506.07468", "pdf": "https://arxiv.org/pdf/2506.07468", "abs": "https://arxiv.org/abs/2506.07468", "authors": ["Mickel Liu", "Liwei Jiang", "Yancheng Liang", "Simon Shaolei Du", "Yejin Choi", "Tim Althoff", "Natasha Jaques"], "title": "Chasing Moving Targets with Online Self-Play Reinforcement Learning for Safer Language Models", "categories": ["cs.LG", "cs.CL", "cs.MA"], "comment": null, "summary": "Conventional language model (LM) safety alignment relies on a reactive,\ndisjoint procedure: attackers exploit a static model, followed by defensive\nfine-tuning to patch exposed vulnerabilities. This sequential approach creates\na mismatch -- attackers overfit to obsolete defenses, while defenders\nperpetually lag behind emerging threats. To address this, we propose\nSelf-RedTeam, an online self-play reinforcement learning algorithm where an\nattacker and defender agent co-evolve through continuous interaction. We cast\nsafety alignment as a two-player zero-sum game, where a single model alternates\nbetween attacker and defender roles -- generating adversarial prompts and\nsafeguarding against them -- while a reward LM adjudicates outcomes. This\nenables dynamic co-adaptation. Grounded in the game-theoretic framework of\nzero-sum games, we establish a theoretical safety guarantee which motivates the\ndesign of our method: if self-play converges to a Nash Equilibrium, the\ndefender will reliably produce safe responses to any adversarial input.\nEmpirically, Self-RedTeam uncovers more diverse attacks (+21.8% SBERT) compared\nto attackers trained against static defenders and achieves higher robustness on\nsafety benchmarks (e.g., +65.5% on WildJailBreak) than defenders trained\nagainst static attackers. We further propose hidden Chain-of-Thought, allowing\nagents to plan privately, which boosts adversarial diversity and reduces\nover-refusals. Our results motivate a shift from reactive patching to proactive\nco-evolution in LM safety training, enabling scalable, autonomous, and robust\nself-improvement of LMs via multi-agent reinforcement learning (MARL).", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSelf-RedTeam\u7684\u5728\u7ebf\u81ea\u535a\u5f08\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u653b\u51fb\u8005\u548c\u9632\u5fa1\u8005\u7684\u534f\u540c\u8fdb\u5316\u52a8\u6001\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6027\u3002", "motivation": "\u4f20\u7edf\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u5bf9\u9f50\u65b9\u6cd5\u5b58\u5728\u6ede\u540e\u6027\uff0c\u653b\u51fb\u8005\u4f1a\u9488\u5bf9\u9759\u6001\u9632\u5fa1\u8fc7\u62df\u5408\uff0c\u800c\u9632\u5fa1\u8005\u5219\u65e0\u6cd5\u53ca\u65f6\u5e94\u5bf9\u65b0\u5a01\u80c1\u3002", "method": "\u5c06\u5b89\u5168\u5bf9\u9f50\u5efa\u6a21\u4e3a\u96f6\u548c\u535a\u5f08\uff0c\u653b\u51fb\u8005\u548c\u9632\u5fa1\u8005\u89d2\u8272\u4ea4\u66ff\uff0c\u901a\u8fc7\u5956\u52b1\u6a21\u578b\u88c1\u51b3\u7ed3\u679c\uff0c\u5b9e\u73b0\u52a8\u6001\u534f\u540c\u9002\u5e94\u3002", "result": "Self-RedTeam\u5728\u591a\u6837\u6027\u653b\u51fb\uff08+21.8% SBERT\uff09\u548c\u5b89\u5168\u6027\u57fa\u51c6\uff08\u5982WildJailBreak +65.5%\uff09\u4e0a\u8868\u73b0\u4f18\u4e8e\u9759\u6001\u65b9\u6cd5\u3002", "conclusion": "\u7814\u7a76\u63d0\u5021\u4ece\u88ab\u52a8\u4fee\u8865\u8f6c\u5411\u4e3b\u52a8\u534f\u540c\u8fdb\u5316\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u5b9e\u73b0\u8bed\u8a00\u6a21\u578b\u7684\u53ef\u6269\u5c55\u3001\u81ea\u4e3b\u548c\u9c81\u68d2\u7684\u81ea\u6211\u63d0\u5347\u3002"}}
{"id": "2506.07477", "pdf": "https://arxiv.org/pdf/2506.07477", "abs": "https://arxiv.org/abs/2506.07477", "authors": ["Thomas Zhu", "Joshua Clune", "Jeremy Avigad", "Albert Qiaochu Jiang", "Sean Welleck"], "title": "Premise Selection for a Lean Hammer", "categories": ["cs.LG", "cs.AI", "cs.LO"], "comment": "LeanHammer is available at https://github.com/JOSHCLUNE/LeanHammer", "summary": "Neural methods are transforming automated reasoning for proof assistants, yet\nintegrating these advances into practical verification workflows remains\nchallenging. Hammers are tools that interface with external automatic theorem\nprovers to automate tedious reasoning steps. They have dramatically improved\nproductivity in proof assistants, but the Lean proof assistant still does not\nhave a hammer despite its growing popularity. We present LeanHammer, the first\nend-to-end domain-general hammer for Lean, built on a novel neural premise\nselection system for a hammer in dependent type theory. Unlike existing Lean\npremise selectors, our approach dynamically adapts to user-specific contexts\nand combines with symbolic proof search and reconstruction to create a\npractical hammer. With comprehensive evaluations, we show that our premise\nselector enables LeanHammer to solve 21\\% more goals relative to existing\npremise selectors, and generalize well to diverse domains. Our work bridges the\ngap between neural retrieval and symbolic reasoning, making formal verification\nmore accessible to researchers and practitioners.", "AI": {"tldr": "LeanHammer\u662f\u7b2c\u4e00\u4e2a\u4e3aLean\u8bc1\u660e\u52a9\u624b\u8bbe\u8ba1\u7684\u7aef\u5230\u7aef\u901a\u7528\u5de5\u5177\uff0c\u7ed3\u5408\u795e\u7ecf\u524d\u63d0\u9009\u62e9\u548c\u7b26\u53f7\u63a8\u7406\uff0c\u663e\u8457\u63d0\u5347\u4e86\u81ea\u52a8\u5316\u8bc1\u660e\u80fd\u529b\u3002", "motivation": "\u5c3d\u7ba1\u795e\u7ecf\u65b9\u6cd5\u5728\u81ea\u52a8\u63a8\u7406\u4e2d\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u5c06\u5176\u6574\u5408\u5230\u5b9e\u9645\u9a8c\u8bc1\u5de5\u4f5c\u6d41\u4e2d\u4ecd\u5177\u6311\u6218\u6027\u3002Lean\u4f5c\u4e3a\u6d41\u884c\u7684\u8bc1\u660e\u52a9\u624b\uff0c\u7f3a\u4e4f\u7c7b\u4f3c\u5de5\u5177\u3002", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8e\u795e\u7ecf\u524d\u63d0\u9009\u62e9\u7cfb\u7edf\u7684LeanHammer\uff0c\u52a8\u6001\u9002\u5e94\u7528\u6237\u4e0a\u4e0b\u6587\uff0c\u5e76\u4e0e\u7b26\u53f7\u8bc1\u660e\u641c\u7d22\u548c\u91cd\u6784\u7ed3\u5408\u3002", "result": "\u8bc4\u4f30\u663e\u793a\uff0cLeanHammer\u6bd4\u73b0\u6709\u524d\u63d0\u9009\u62e9\u5668\u591a\u89e3\u51b321%\u7684\u76ee\u6807\uff0c\u5e76\u80fd\u6cdb\u5316\u5230\u591a\u6837\u9886\u57df\u3002", "conclusion": "LeanHammer\u586b\u8865\u4e86\u795e\u7ecf\u68c0\u7d22\u4e0e\u7b26\u53f7\u63a8\u7406\u95f4\u7684\u9e3f\u6c9f\uff0c\u4f7f\u5f62\u5f0f\u9a8c\u8bc1\u66f4\u6613\u4e3a\u7814\u7a76\u8005\u548c\u5b9e\u8df5\u8005\u6240\u7528\u3002"}}
{"id": "2506.07492", "pdf": "https://arxiv.org/pdf/2506.07492", "abs": "https://arxiv.org/abs/2506.07492", "authors": ["Xiangkun Hu", "Lemin Kong", "Tong He", "David Wipf"], "title": "Explicit Preference Optimization: No Need for an Implicit Reward Model", "categories": ["cs.LG", "stat.ML"], "comment": "arXiv admin note: substantial text overlap with arXiv:2407.09072", "summary": "The generated responses of large language models (LLMs) are often fine-tuned\nto human preferences through a process called reinforcement learning from human\nfeedback (RLHF). As RLHF relies on a challenging training sequence, whereby a\nseparate reward model is independently learned and then later applied to LLM\npolicy updates, ongoing research effort has targeted more straightforward\nalternatives. In this regard, direct preference optimization (DPO) and its many\noffshoots circumvent the need for a separate reward training step. Instead,\nthrough the judicious use of a reparameterization trick that induces an\n\\textit{implicit} reward, DPO and related methods consolidate learning to the\nminimization of a single loss function. And yet despite demonstrable success in\nsome real-world settings, we prove that DPO-based objectives are nonetheless\nsubject to sub-optimal regularization and counter-intuitive interpolation\nbehaviors, underappreciated artifacts of the reparameterizations upon which\nthey are based. To this end, we introduce an \\textit{explicit} preference\noptimization framework termed EXPO that requires no analogous\nreparameterization to achieve an implicit reward. Quite differently, we merely\nposit intuitively-appealing regularization factors from scratch that\ntransparently avoid the potential pitfalls of key DPO variants, provably\nsatisfying regularization desiderata that prior methods do not. Empirical\nresults serve to corroborate our analyses and showcase the efficacy of EXPO.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u504f\u597d\u4f18\u5316\u6846\u67b6EXPO\uff0c\u89e3\u51b3\u4e86\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08DPO\uff09\u65b9\u6cd5\u4e2d\u7684\u6b21\u4f18\u6b63\u5219\u5316\u548c\u53cd\u76f4\u89c9\u63d2\u503c\u95ee\u9898\u3002", "motivation": "RLHF\u4f9d\u8d56\u590d\u6742\u7684\u8bad\u7ec3\u5e8f\u5217\uff0c\u800cDPO\u867d\u7b80\u5316\u4e86\u6d41\u7a0b\uff0c\u4f46\u4ecd\u5b58\u5728\u6b63\u5219\u5316\u548c\u63d2\u503c\u95ee\u9898\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "\u5f15\u5165EXPO\u6846\u67b6\uff0c\u901a\u8fc7\u663e\u5f0f\u6b63\u5219\u5316\u56e0\u5b50\u907f\u514dDPO\u7684\u6f5c\u5728\u7f3a\u9677\uff0c\u65e0\u9700\u9690\u5f0f\u5956\u52b1\u91cd\u53c2\u6570\u5316\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eEXPO\u6709\u6548\u89e3\u51b3\u4e86DPO\u7684\u95ee\u9898\uff0c\u5e76\u6ee1\u8db3\u6b63\u5219\u5316\u9700\u6c42\u3002", "conclusion": "EXPO\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u900f\u660e\u3001\u66f4\u4f18\u7684\u504f\u597d\u4f18\u5316\u65b9\u6cd5\uff0c\u4f18\u4e8e\u73b0\u6709DPO\u53d8\u4f53\u3002"}}
{"id": "2506.07500", "pdf": "https://arxiv.org/pdf/2506.07500", "abs": "https://arxiv.org/abs/2506.07500", "authors": ["Shakir Yousefi", "Andreas Plesner", "Till Aczel", "Roger Wattenhofer"], "title": "Mind the Gap: Removing the Discretization Gap in Differentiable Logic Gate Networks", "categories": ["cs.LG", "cs.PF"], "comment": null, "summary": "Modern neural networks demonstrate state-of-the-art performance on numerous\nexisting benchmarks; however, their high computational requirements and energy\nconsumption prompt researchers to seek more efficient solutions for real-world\ndeployment. Logic gate networks (LGNs) learns a large network of logic gates\nfor efficient image classification. However, learning a network that can solve\na simple problem like CIFAR-10 can take days to weeks to train. Even then,\nalmost half of the network remains unused, causing a discretization gap. This\ndiscretization gap hinders real-world deployment of LGNs, as the performance\ndrop between training and inference negatively impacts accuracy. We inject\nGumbel noise with a straight-through estimator during training to significantly\nspeed up training, improve neuron utilization, and decrease the discretization\ngap. We theoretically show that this results from implicit Hessian\nregularization, which improves the convergence properties of LGNs. We train\nnetworks $4.5 \\times$ faster in wall-clock time, reduce the discretization gap\nby $98\\%$, and reduce the number of unused gates by $100\\%$.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u6ce8\u5165Gumbel\u566a\u58f0\u548c\u4f7f\u7528\u76f4\u901a\u4f30\u8ba1\u5668\u6765\u52a0\u901f\u903b\u8f91\u95e8\u7f51\u7edc\uff08LGNs\uff09\u8bad\u7ec3\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u79bb\u6563\u5316\u5dee\u8ddd\u548c\u672a\u4f7f\u7528\u95e8\u6570\u91cf\u3002", "motivation": "\u73b0\u4ee3\u795e\u7ecf\u7f51\u7edc\u5728\u8ba1\u7b97\u548c\u80fd\u8017\u65b9\u9762\u7684\u9ad8\u9700\u6c42\u4fc3\u4f7f\u7814\u7a76\u8005\u5bfb\u6c42\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f46LGNs\u7684\u8bad\u7ec3\u65f6\u95f4\u957f\u4e14\u5b58\u5728\u79bb\u6563\u5316\u5dee\u8ddd\uff0c\u5f71\u54cd\u5b9e\u9645\u90e8\u7f72\u3002", "method": "\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6ce8\u5165Gumbel\u566a\u58f0\u5e76\u4f7f\u7528\u76f4\u901a\u4f30\u8ba1\u5668\uff0c\u901a\u8fc7\u9690\u5f0fHessian\u6b63\u5219\u5316\u6539\u5584\u6536\u655b\u6027\u3002", "result": "\u8bad\u7ec3\u901f\u5ea6\u63d0\u53474.5\u500d\uff0c\u79bb\u6563\u5316\u5dee\u8ddd\u51cf\u5c1198%\uff0c\u672a\u4f7f\u7528\u95e8\u6570\u91cf\u51cf\u5c11100%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86LGNs\u7684\u8bad\u7ec3\u6548\u7387\u548c\u5b9e\u9645\u90e8\u7f72\u6027\u80fd\u3002"}}
{"id": "2506.07501", "pdf": "https://arxiv.org/pdf/2506.07501", "abs": "https://arxiv.org/abs/2506.07501", "authors": ["Libo Wang"], "title": "Graph-of-Causal Evolution: Challenging Chain-of-Model for Reasoning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "The relevant code has been uploaded to the publicly available GitHub\n  repository. The link is:\n  https://github.com/brucewang123456789/GeniusTrail/tree/main/GoCE", "summary": "In view of the problem that each subchain in the chain-of-model (CoM) relies\nonly on the information of the previous subchain and may lose long-range\ndependencies due to the causal mask blocking the global context flow between\nmulti-level subchains, this work proposes a graph of causal evolution (GoCE).\nIts core principle is to map the implicit token representation into a\ndifferentiable and sparse causal adjacency matrix, then permeate causal\nconstraints through each layer of calculation using causal-masked attention and\ncausal-MoE. By combining intervention consistency loss test and self-evolution\ngate, the dynamic balance between causal structure learning and adaptive\nupdating of transformer architecture is realized. The researcher built\nexperimental environments in sandboxes built with Claude Sonnet 4,\no4-mini-high, and DeepSeek R1 respectively with the transformer variant\narchitecture introduced in GoCE. It is evaluated on publicly available datasets\nincluding CLUTRR, CLADDER, EX-FEVER, and CausalQA and compared with the\nbaseline LLMs. The finding proves that GoCE strengthens the transformer's\nability to capture long-range causal dependencies, while the ability to\nself-evolve is improved. It not only surpasses the design of CoM in terms of\ndesign principles, but also provides experience for future research on causal\nlearning and continuous adaptive improvement.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u56fe\u56e0\u679c\u6f14\u5316\uff08GoCE\uff09\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u94fe\u5f0f\u6a21\u578b\uff08CoM\uff09\u4e2d\u5b50\u94fe\u4ec5\u4f9d\u8d56\u524d\u4e00\u4e2a\u5b50\u94fe\u4fe1\u606f\u800c\u53ef\u80fd\u4e22\u5931\u957f\u8ddd\u79bb\u4f9d\u8d56\u7684\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3CoM\u4e2d\u56e0\u56e0\u679c\u63a9\u7801\u5bfc\u81f4\u5168\u5c40\u4e0a\u4e0b\u6587\u6d41\u52a8\u53d7\u963b\u7684\u95ee\u9898\uff0c\u63d0\u5347\u957f\u8ddd\u79bb\u56e0\u679c\u4f9d\u8d56\u7684\u6355\u6349\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u5c06\u9690\u5f0f\u4ee4\u724c\u8868\u793a\u6620\u5c04\u4e3a\u53ef\u5fae\u5206\u7a00\u758f\u56e0\u679c\u90bb\u63a5\u77e9\u9635\uff0c\u7ed3\u5408\u56e0\u679c\u63a9\u7801\u6ce8\u610f\u529b\u548c\u56e0\u679c-MoE\uff0c\u5b9e\u73b0\u56e0\u679c\u7ed3\u6784\u5b66\u4e60\u4e0e\u81ea\u9002\u5e94\u66f4\u65b0\u7684\u52a8\u6001\u5e73\u8861\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eGoCE\u5728\u591a\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u57fa\u7ebfLLMs\uff0c\u63d0\u5347\u4e86\u957f\u8ddd\u79bb\u56e0\u679c\u4f9d\u8d56\u6355\u6349\u80fd\u529b\u548c\u81ea\u6f14\u5316\u80fd\u529b\u3002", "conclusion": "GoCE\u4e0d\u4ec5\u8d85\u8d8a\u4e86CoM\u7684\u8bbe\u8ba1\u539f\u5219\uff0c\u8fd8\u4e3a\u56e0\u679c\u5b66\u4e60\u548c\u6301\u7eed\u81ea\u9002\u5e94\u6539\u8fdb\u63d0\u4f9b\u4e86\u7ecf\u9a8c\u3002"}}
{"id": "2506.07505", "pdf": "https://arxiv.org/pdf/2506.07505", "abs": "https://arxiv.org/abs/2506.07505", "authors": ["Perry Dong", "Alec M. Lessing", "Annie S. Chen", "Chelsea Finn"], "title": "Reinforcement Learning via Implicit Imitation Guidance", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We study the problem of sample efficient reinforcement learning, where prior\ndata such as demonstrations are provided for initialization in lieu of a dense\nreward signal. A natural approach is to incorporate an imitation learning\nobjective, either as regularization during training or to acquire a reference\npolicy. However, imitation learning objectives can ultimately degrade long-term\nperformance, as it does not directly align with reward maximization. In this\nwork, we propose to use prior data solely for guiding exploration via noise\nadded to the policy, sidestepping the need for explicit behavior cloning\nconstraints. The key insight in our framework, Data-Guided Noise (DGN), is that\ndemonstrations are most useful for identifying which actions should be\nexplored, rather than forcing the policy to take certain actions. Our approach\nachieves up to 2-3x improvement over prior reinforcement learning from offline\ndata methods across seven simulated continuous control tasks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDGN\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u5148\u9a8c\u6570\u636e\u5f15\u5bfc\u63a2\u7d22\u800c\u975e\u76f4\u63a5\u6a21\u4eff\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6837\u672c\u6548\u7387\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u9ad8\u6548\u5229\u7528\u5148\u9a8c\u6570\u636e\uff08\u5982\u6f14\u793a\uff09\uff0c\u907f\u514d\u6a21\u4eff\u5b66\u4e60\u76ee\u6807\u5bf9\u957f\u671f\u6027\u80fd\u7684\u8d1f\u9762\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u5411\u7b56\u7565\u6dfb\u52a0\u566a\u58f0\uff0c\u5229\u7528\u5148\u9a8c\u6570\u636e\u5f15\u5bfc\u63a2\u7d22\uff0c\u800c\u975e\u76f4\u63a5\u7ea6\u675f\u884c\u4e3a\u514b\u9686\u3002", "result": "\u5728\u4e03\u4e2a\u6a21\u62df\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e2d\uff0c\u6027\u80fd\u6bd4\u73b0\u6709\u79bb\u7ebf\u6570\u636e\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u63d0\u53472-3\u500d\u3002", "conclusion": "DGN\u6846\u67b6\u901a\u8fc7\u5f15\u5bfc\u63a2\u7d22\u800c\u975e\u6a21\u4eff\u5b66\u4e60\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5f3a\u5316\u5b66\u4e60\u7684\u6837\u672c\u6548\u7387\u3002"}}
{"id": "2506.07517", "pdf": "https://arxiv.org/pdf/2506.07517", "abs": "https://arxiv.org/abs/2506.07517", "authors": ["Shuqiang Zhang", "Yuchao Zhang", "Jinkun Chen", "Haochen Sui"], "title": "Addressing Correlated Latent Exogenous Variables in Debiased Recommender Systems", "categories": ["cs.LG", "cs.IR"], "comment": "In Proceedings of the 31st ACM SIGKDD Conference on Knowledge\n  Discovery and Data Mining V.2 (KDD '25), August 3--7, 2025, Toronto, ON,\n  Canada", "summary": "Recommendation systems (RS) aim to provide personalized content, but they\nface a challenge in unbiased learning due to selection bias, where users only\ninteract with items they prefer. This bias leads to a distorted representation\nof user preferences, which hinders the accuracy and fairness of\nrecommendations. To address the issue, various methods such as error imputation\nbased, inverse propensity scoring, and doubly robust techniques have been\ndeveloped. Despite the progress, from the structural causal model perspective,\nprevious debiasing methods in RS assume the independence of the exogenous\nvariables. In this paper, we release this assumption and propose a learning\nalgorithm based on likelihood maximization to learn a prediction model. We\nfirst discuss the correlation and difference between unmeasured confounding and\nour scenario, then we propose a unified method that effectively handles latent\nexogenous variables. Specifically, our method models the data generation\nprocess with latent exogenous variables under mild normality assumptions. We\nthen develop a Monte Carlo algorithm to numerically estimate the likelihood\nfunction. Extensive experiments on synthetic datasets and three real-world\ndatasets demonstrate the effectiveness of our proposed method. The code is at\nhttps://github.com/WallaceSUI/kdd25-background-variable.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4f3c\u7136\u6700\u5927\u5316\u7684\u5b66\u4e60\u7b97\u6cd5\uff0c\u89e3\u51b3\u63a8\u8350\u7cfb\u7edf\u4e2d\u56e0\u5916\u751f\u53d8\u91cf\u72ec\u7acb\u6027\u5047\u8bbe\u5bfc\u81f4\u7684\u504f\u5dee\u95ee\u9898\uff0c\u901a\u8fc7\u5efa\u6a21\u6f5c\u5728\u5916\u751f\u53d8\u91cf\u548c\u6570\u636e\u751f\u6210\u8fc7\u7a0b\uff0c\u63d0\u9ad8\u4e86\u63a8\u8350\u7684\u51c6\u786e\u6027\u548c\u516c\u5e73\u6027\u3002", "motivation": "\u63a8\u8350\u7cfb\u7edf\u56e0\u7528\u6237\u4ec5\u4e0e\u504f\u597d\u9879\u76ee\u4ea4\u4e92\u7684\u9009\u62e9\u504f\u5dee\u5bfc\u81f4\u504f\u597d\u8868\u793a\u5931\u771f\uff0c\u73b0\u6709\u65b9\u6cd5\u5047\u8bbe\u5916\u751f\u53d8\u91cf\u72ec\u7acb\uff0c\u9650\u5236\u4e86\u504f\u5dee\u7ea0\u6b63\u6548\u679c\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u4f3c\u7136\u6700\u5927\u5316\u7684\u5b66\u4e60\u7b97\u6cd5\uff0c\u5efa\u6a21\u6f5c\u5728\u5916\u751f\u53d8\u91cf\uff0c\u91c7\u7528\u8499\u7279\u5361\u6d1b\u7b97\u6cd5\u6570\u503c\u4f30\u8ba1\u4f3c\u7136\u51fd\u6570\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u96c6\u548c\u4e09\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u91ca\u653e\u5916\u751f\u53d8\u91cf\u72ec\u7acb\u6027\u5047\u8bbe\uff0c\u63d0\u51fa\u7edf\u4e00\u65b9\u6cd5\u5904\u7406\u6f5c\u5728\u53d8\u91cf\uff0c\u663e\u8457\u63d0\u5347\u63a8\u8350\u7cfb\u7edf\u7684\u504f\u5dee\u7ea0\u6b63\u80fd\u529b\u3002"}}
{"id": "2506.07534", "pdf": "https://arxiv.org/pdf/2506.07534", "abs": "https://arxiv.org/abs/2506.07534", "authors": ["Cl\u00e9ment Bonet", "Christophe Vauthier", "Anna Korba"], "title": "Flowing Datasets with Wasserstein over Wasserstein Gradient Flows", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": "Accepted as an oral at ICML2025", "summary": "Many applications in machine learning involve data represented as probability\ndistributions. The emergence of such data requires radically novel techniques\nto design tractable gradient flows on probability distributions over this type\nof (infinite-dimensional) objects. For instance, being able to flow labeled\ndatasets is a core task for applications ranging from domain adaptation to\ntransfer learning or dataset distillation. In this setting, we propose to\nrepresent each class by the associated conditional distribution of features,\nand to model the dataset as a mixture distribution supported on these classes\n(which are themselves probability distributions), meaning that labeled datasets\ncan be seen as probability distributions over probability distributions. We\nendow this space with a metric structure from optimal transport, namely the\nWasserstein over Wasserstein (WoW) distance, derive a differential structure on\nthis space, and define WoW gradient flows. The latter enables to design\ndynamics over this space that decrease a given objective functional. We apply\nour framework to transfer learning and dataset distillation tasks, leveraging\nour gradient flow construction as well as novel tractable functionals that take\nthe form of Maximum Mean Discrepancies with Sliced-Wasserstein based kernels\nbetween probability distributions.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6700\u4f18\u4f20\u8f93\u7684Wasserstein over Wasserstein (WoW)\u8ddd\u79bb\uff0c\u7528\u4e8e\u5904\u7406\u6982\u7387\u5206\u5e03\u4e0a\u7684\u68af\u5ea6\u6d41\uff0c\u5e76\u5e94\u7528\u4e8e\u8fc1\u79fb\u5b66\u4e60\u548c\u6570\u636e\u96c6\u84b8\u998f\u4efb\u52a1\u3002", "motivation": "\u5904\u7406\u673a\u5668\u5b66\u4e60\u4e2d\u8868\u793a\u4e3a\u6982\u7387\u5206\u5e03\u7684\u6570\u636e\uff0c\u9700\u8981\u8bbe\u8ba1\u5728\u65e0\u9650\u7ef4\u5bf9\u8c61\u4e0a\u7684\u68af\u5ea6\u6d41\u6280\u672f\u3002", "method": "\u5c06\u6bcf\u4e2a\u7c7b\u8868\u793a\u4e3a\u7279\u5f81\u7684\u6761\u4ef6\u5206\u5e03\uff0c\u6570\u636e\u96c6\u5efa\u6a21\u4e3a\u8fd9\u4e9b\u7c7b\u7684\u6df7\u5408\u5206\u5e03\uff0c\u5e76\u5f15\u5165WoW\u8ddd\u79bb\u548c\u68af\u5ea6\u6d41\u3002", "result": "\u63d0\u51fa\u4e86WoW\u68af\u5ea6\u6d41\u6846\u67b6\uff0c\u5e76\u5728\u8fc1\u79fb\u5b66\u4e60\u548c\u6570\u636e\u96c6\u84b8\u998f\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "WoW\u68af\u5ea6\u6d41\u4e3a\u5904\u7406\u6982\u7387\u5206\u5e03\u6570\u636e\u63d0\u4f9b\u4e86\u65b0\u7684\u5de5\u5177\uff0c\u5e76\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5c55\u793a\u4e86\u6f5c\u529b\u3002"}}
{"id": "2506.07549", "pdf": "https://arxiv.org/pdf/2506.07549", "abs": "https://arxiv.org/abs/2506.07549", "authors": ["Zhangchi Zhao", "Jun Shu", "Deyu Meng", "Zongben Xu"], "title": "Improving Memory Efficiency for Training KANs via Meta Learning", "categories": ["cs.LG"], "comment": "ICML 2025", "summary": "Inspired by the Kolmogorov-Arnold representation theorem, KANs offer a novel\nframework for function approximation by replacing traditional neural network\nweights with learnable univariate functions. This design demonstrates\nsignificant potential as an efficient and interpretable alternative to\ntraditional MLPs. However, KANs are characterized by a substantially larger\nnumber of trainable parameters, leading to challenges in memory efficiency and\nhigher training costs compared to MLPs. To address this limitation, we propose\nto generate weights for KANs via a smaller meta-learner, called MetaKANs. By\ntraining KANs and MetaKANs in an end-to-end differentiable manner, MetaKANs\nachieve comparable or even superior performance while significantly reducing\nthe number of trainable parameters and maintaining promising interpretability.\nExtensive experiments on diverse benchmark tasks, including symbolic\nregression, partial differential equation solving, and image classification,\ndemonstrate the effectiveness of MetaKANs in improving parameter efficiency and\nmemory usage. The proposed method provides an alternative technique for\ntraining KANs, that allows for greater scalability and extensibility, and\nnarrows the training cost gap with MLPs stated in the original paper of KANs.\nOur code is available at https://github.com/Murphyzc/MetaKAN.", "AI": {"tldr": "MetaKANs\u901a\u8fc7\u5143\u5b66\u4e60\u751f\u6210KANs\u7684\u6743\u91cd\uff0c\u51cf\u5c11\u53ef\u8bad\u7ec3\u53c2\u6570\uff0c\u63d0\u5347\u5185\u5b58\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u6027\u80fd\u4e0e\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "KANs\u867d\u7136\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\uff0c\u4f46\u53c2\u6570\u8fc7\u591a\u5bfc\u81f4\u5185\u5b58\u548c\u8bad\u7ec3\u6210\u672c\u9ad8\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u63d0\u51faMetaKANs\uff0c\u7528\u5c0f\u578b\u5143\u5b66\u4e60\u5668\u751f\u6210KANs\u6743\u91cd\uff0c\u7aef\u5230\u7aef\u8bad\u7ec3\u3002", "result": "\u5728\u7b26\u53f7\u56de\u5f52\u3001\u504f\u5fae\u5206\u65b9\u7a0b\u6c42\u89e3\u548c\u56fe\u50cf\u5206\u7c7b\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u663e\u8457\u51cf\u5c11\u53c2\u6570\u3002", "conclusion": "MetaKANs\u4e3aKANs\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u8bad\u7ec3\u65b9\u6cd5\uff0c\u7f29\u5c0f\u4e86\u4e0eMLPs\u7684\u6210\u672c\u5dee\u8ddd\u3002"}}
{"id": "2506.07551", "pdf": "https://arxiv.org/pdf/2506.07551", "abs": "https://arxiv.org/abs/2506.07551", "authors": ["Mengsong Wu", "YaFei Wang", "Yidong Ming", "Yuqi An", "Yuwei Wan", "Wenliang Chen", "Binbin Lin", "Yuqiang Li", "Tong Xie", "Dongzhan Zhou"], "title": "ChemAgent: Enhancing LLMs for Chemistry and Materials Science through Tree-Search Based Tool Learning", "categories": ["cs.LG", "cs.AI", "cs.CE", "cs.CL"], "comment": "15 pages, 6 figures", "summary": "Large language models (LLMs) have recently demonstrated promising\ncapabilities in chemistry tasks while still facing challenges due to outdated\npretraining knowledge and the difficulty of incorporating specialized chemical\nexpertise. To address these issues, we propose an LLM-based agent that\nsynergistically integrates 137 external chemical tools created ranging from\nbasic information retrieval to complex reaction predictions, and a dataset\ncuration pipeline to generate the dataset ChemToolBench that facilitates both\neffective tool selection and precise parameter filling during fine-tuning and\nevaluation. We introduce a Hierarchical Evolutionary Monte Carlo Tree Search\n(HE-MCTS) framework, enabling independent optimization of tool planning and\nexecution. By leveraging self-generated data, our approach supports step-level\nfine-tuning (FT) of the policy model and training task-adaptive PRM and ORM\nthat surpass GPT-4o. Experimental evaluations demonstrate that our approach\nsignificantly improves performance in Chemistry QA and discovery tasks,\noffering a robust solution to integrate specialized tools with LLMs for\nadvanced chemical applications. All datasets and code are available at\nhttps://github.com/AI4Chem/ChemistryAgent .", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u5316\u5b66\u4ee3\u7406\uff0c\u6574\u5408\u5916\u90e8\u5316\u5b66\u5de5\u5177\u548c\u6570\u636e\u96c6ChemToolBench\uff0c\u901a\u8fc7HE-MCTS\u6846\u67b6\u4f18\u5316\u5de5\u5177\u89c4\u5212\u4e0e\u6267\u884c\uff0c\u663e\u8457\u63d0\u5347\u5316\u5b66\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3LLMs\u5728\u5316\u5b66\u4efb\u52a1\u4e2d\u56e0\u9884\u8bad\u7ec3\u77e5\u8bc6\u8fc7\u65f6\u548c\u96be\u4ee5\u878d\u5165\u4e13\u4e1a\u5316\u5b66\u77e5\u8bc6\u800c\u9762\u4e34\u7684\u6311\u6218\u3002", "method": "\u5f00\u53d1LLM\u4ee3\u7406\uff0c\u6574\u5408137\u79cd\u5316\u5b66\u5de5\u5177\u548c\u6570\u636e\u96c6ChemToolBench\uff0c\u91c7\u7528HE-MCTS\u6846\u67b6\u4f18\u5316\u5de5\u5177\u89c4\u5212\u4e0e\u6267\u884c\uff0c\u5e76\u901a\u8fc7\u81ea\u751f\u6210\u6570\u636e\u5fae\u8c03\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5316\u5b66\u95ee\u7b54\u548c\u53d1\u73b0\u4efb\u52a1\u4e2d\u6027\u80fd\u663e\u8457\u63d0\u5347\uff0c\u8d85\u8d8aGPT-4o\u3002", "conclusion": "\u4e3aLLMs\u4e0e\u4e13\u4e1a\u5316\u5b66\u5de5\u5177\u7684\u7ed3\u5408\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u63a8\u52a8\u5316\u5b66\u5e94\u7528\u53d1\u5c55\u3002"}}
{"id": "2506.07578", "pdf": "https://arxiv.org/pdf/2506.07578", "abs": "https://arxiv.org/abs/2506.07578", "authors": ["Florian Andreas Marwitz", "Ralf M\u00f6ller", "Magnus Bender", "Marcel Gehrke"], "title": "Denoising the Future: Top-p Distributions for Moving Through Time", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Inference in dynamic probabilistic models is a complex task involving\nexpensive operations. In particular, for Hidden Markov Models, the whole state\nspace has to be enumerated for advancing in time. Even states with negligible\nprobabilities are considered, resulting in computational inefficiency and\nincreased noise due to the propagation of unlikely probability mass. We propose\nto denoise the future and speed up inference by using only the top-p states,\ni.e., the most probable states with accumulated probability p. We show that the\nerror introduced by using only the top-p states is bound by p and the so-called\nminimal mixing rate of the underlying model. Moreover, in our empirical\nevaluation, we show that we can expect speedups of at least an order of\nmagnitude, while the error in terms of total variation distance is below 0.09.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u4ec5\u4f7f\u7528\u6982\u7387\u6700\u9ad8\u7684\u524dp\u4e2a\u72b6\u6001\uff08top-p\u72b6\u6001\uff09\u6765\u52a0\u901f\u52a8\u6001\u6982\u7387\u6a21\u578b\u63a8\u65ad\u7684\u65b9\u6cd5\uff0c\u51cf\u5c11\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u566a\u58f0\u3002", "motivation": "\u5728\u52a8\u6001\u6982\u7387\u6a21\u578b\uff08\u5982\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\uff09\u4e2d\uff0c\u63a8\u65ad\u8fc7\u7a0b\u9700\u8981\u679a\u4e3e\u6574\u4e2a\u72b6\u6001\u7a7a\u95f4\uff0c\u8ba1\u7b97\u6548\u7387\u4f4e\u4e14\u4f1a\u4f20\u64ad\u4f4e\u6982\u7387\u72b6\u6001\u7684\u566a\u58f0\u3002", "method": "\u63d0\u51fa\u4ec5\u4f7f\u7528\u7d2f\u79ef\u6982\u7387\u4e3ap\u7684\u6700\u53ef\u80fd\u72b6\u6001\uff08top-p\u72b6\u6001\uff09\u6765\u52a0\u901f\u63a8\u65ad\uff0c\u5e76\u51cf\u5c11\u566a\u58f0\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u53ef\u5b9e\u73b0\u81f3\u5c11\u4e00\u4e2a\u6570\u91cf\u7ea7\u7684\u52a0\u901f\uff0c\u4e14\u603b\u53d8\u5dee\u8ddd\u79bb\u8bef\u5dee\u4f4e\u4e8e0.09\u3002", "conclusion": "\u901a\u8fc7\u9650\u5236\u72b6\u6001\u7a7a\u95f4\u4e3atop-p\u72b6\u6001\uff0c\u53ef\u4ee5\u5728\u4fdd\u8bc1\u8bef\u5dee\u53ef\u63a7\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u63d0\u5347\u63a8\u65ad\u6548\u7387\u3002"}}
{"id": "2506.07581", "pdf": "https://arxiv.org/pdf/2506.07581", "abs": "https://arxiv.org/abs/2506.07581", "authors": ["Tan Chen", "Jintao Yan", "Yuxuan Sun", "Sheng Zhou", "Zhisheng Niu"], "title": "FedCGD: Collective Gradient Divergence Optimized Scheduling for Wireless Federated Learning", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": null, "summary": "Federated learning (FL) is a promising paradigm for multiple devices to\ncooperatively train a model. When applied in wireless networks, two issues\nconsistently affect the performance of FL, i.e., data heterogeneity of devices\nand limited bandwidth. Many papers have investigated device scheduling\nstrategies considering the two issues. However, most of them recognize data\nheterogeneity as a property of individual devices. In this paper, we prove that\nthe convergence speed of FL is affected by the sum of device-level and\nsample-level collective gradient divergence (CGD). The device-level CGD refers\nto the gradient divergence of the scheduled device group, instead of the sum of\nthe individual device divergence. The sample-level CGD is statistically upper\nbounded by sampling variance, which is inversely proportional to the total\nnumber of samples scheduled for local update. To derive a tractable form of the\ndevice-level CGD, we further consider a classification problem and transform it\ninto the weighted earth moving distance (WEMD) between the group distribution\nand the global distribution. Then we propose FedCGD algorithm to minimize the\nsum of multi-level CGDs by balancing WEMD and sampling variance, within\npolynomial time. Simulation shows that the proposed strategy increases\nclassification accuracy on the CIFAR-10 dataset by up to 4.2\\% while scheduling\n41.8\\% fewer devices, and flexibly switches between reducing WEMD and reducing\nsampling variance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faFedCGD\u7b97\u6cd5\uff0c\u901a\u8fc7\u5e73\u8861\u52a0\u6743\u5730\u7403\u79fb\u52a8\u8ddd\u79bb\uff08WEMD\uff09\u548c\u91c7\u6837\u65b9\u5dee\uff0c\u6700\u5c0f\u5316\u591a\u7ea7\u96c6\u4f53\u68af\u5ea6\u53d1\u6563\uff08CGD\uff09\uff0c\u4ece\u800c\u63d0\u5347\u8054\u90a6\u5b66\u4e60\u7684\u6536\u655b\u901f\u5ea6\u548c\u5206\u7c7b\u51c6\u786e\u6027\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u5728\u65e0\u7ebf\u7f51\u7edc\u4e2d\u9762\u4e34\u8bbe\u5907\u6570\u636e\u5f02\u6784\u6027\u548c\u5e26\u5bbd\u9650\u5236\u7684\u95ee\u9898\uff0c\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u8bbe\u5907\u7ea7\u6570\u636e\u5f02\u6784\u6027\uff0c\u800c\u672c\u6587\u53d1\u73b0\u6536\u655b\u901f\u5ea6\u8fd8\u53d7\u6837\u672c\u7ea7CGD\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u5206\u6790\u8bbe\u5907\u7ea7\u548c\u6837\u672c\u7ea7CGD\uff0c\u5c06\u5176\u8f6c\u5316\u4e3a\u5206\u7c7b\u95ee\u9898\u4e2d\u7684WEMD\u548c\u91c7\u6837\u65b9\u5dee\uff0c\u5e76\u63d0\u51faFedCGD\u7b97\u6cd5\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u4f18\u5316\u4e24\u8005\u3002", "result": "\u5728CIFAR-10\u6570\u636e\u96c6\u4e0a\uff0cFedCGD\u5c06\u5206\u7c7b\u51c6\u786e\u7387\u63d0\u53474.2%\uff0c\u540c\u65f6\u51cf\u5c1141.8%\u7684\u8bbe\u5907\u8c03\u5ea6\u3002", "conclusion": "FedCGD\u901a\u8fc7\u591a\u7ea7CGD\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347FL\u6027\u80fd\uff0c\u5e76\u80fd\u7075\u6d3b\u8c03\u6574WEMD\u548c\u91c7\u6837\u65b9\u5dee\u7684\u5e73\u8861\u3002"}}
{"id": "2506.07584", "pdf": "https://arxiv.org/pdf/2506.07584", "abs": "https://arxiv.org/abs/2506.07584", "authors": ["Hao Li", "Bowen Deng", "Chang Xu", "Zhiyuan Feng", "Viktor Schlegel", "Yu-Hao Huang", "Yizheng Sun", "Jingyuan Sun", "Kailai Yang", "Yiyao Yu", "Jiang Bian"], "title": "MIRA: Medical Time Series Foundation Model for Real-World Health Data", "categories": ["cs.LG"], "comment": null, "summary": "A unified foundation model for medical time series -- pretrained on open\naccess and ethics board-approved medical corpora -- offers the potential to\nreduce annotation burdens, minimize model customization, and enable robust\ntransfer across clinical institutions, modalities, and tasks, particularly in\ndata-scarce or privacy-constrained environments. However, existing generalist\ntime series foundation models struggle to handle medical time series data due\nto their inherent challenges, including irregular intervals, heterogeneous\nsampling rates, and frequent missing values. To address these challenges, we\nintroduce MIRA, a unified foundation model specifically designed for medical\ntime series forecasting. MIRA incorporates a Continuous-Time Rotary Positional\nEncoding that enables fine-grained modeling of variable time intervals, a\nfrequency-specific mixture-of-experts layer that routes computation across\nlatent frequency regimes to further promote temporal specialization, and a\nContinuous Dynamics Extrapolation Block based on Neural ODE that models the\ncontinuous trajectory of latent states, enabling accurate forecasting at\narbitrary target timestamps. Pretrained on a large-scale and diverse medical\ncorpus comprising over 454 billion time points collect from publicly available\ndatasets, MIRA achieves reductions in forecasting errors by an average of 10%\nand 7% in out-of-distribution and in-distribution scenarios, respectively, when\ncompared to other zero-shot and fine-tuned baselines. We also introduce a\ncomprehensive benchmark spanning multiple downstream clinical tasks,\nestablishing a foundation for future research in medical time series modeling.", "AI": {"tldr": "MIRA\u662f\u4e00\u4e2a\u4e13\u4e3a\u533b\u7597\u65f6\u95f4\u5e8f\u5217\u8bbe\u8ba1\u7684\u7edf\u4e00\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7\u521b\u65b0\u65b9\u6cd5\u89e3\u51b3\u4e86\u6570\u636e\u4e0d\u89c4\u5219\u6027\u7b49\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709\u901a\u7528\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u96be\u4ee5\u5904\u7406\u533b\u7597\u65f6\u95f4\u5e8f\u5217\u7684\u6311\u6218\uff08\u5982\u4e0d\u89c4\u5219\u95f4\u9694\u3001\u5f02\u6784\u91c7\u6837\u7387\u548c\u7f3a\u5931\u503c\uff09\uff0c\u56e0\u6b64\u9700\u8981\u4e13\u95e8\u8bbe\u8ba1\u7684\u6a21\u578b\u3002", "method": "MIRA\u7ed3\u5408\u4e86\u8fde\u7eed\u65f6\u95f4\u65cb\u8f6c\u4f4d\u7f6e\u7f16\u7801\u3001\u9891\u7387\u7279\u5b9a\u4e13\u5bb6\u6df7\u5408\u5c42\u548c\u57fa\u4e8e\u795e\u7ecfODE\u7684\u8fde\u7eed\u52a8\u6001\u5916\u63a8\u5757\uff0c\u4ee5\u5efa\u6a21\u590d\u6742\u65f6\u95f4\u52a8\u6001\u3002", "result": "\u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u9884\u8bad\u7ec3\u7684MIRA\uff0c\u9884\u6d4b\u8bef\u5dee\u5e73\u5747\u51cf\u5c1110%\uff08\u5206\u5e03\u5916\uff09\u548c7%\uff08\u5206\u5e03\u5185\uff09\uff0c\u4f18\u4e8e\u5176\u4ed6\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "MIRA\u4e3a\u533b\u7597\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\u63d0\u4f9b\u4e86\u65b0\u57fa\u51c6\uff0c\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.07585", "pdf": "https://arxiv.org/pdf/2506.07585", "abs": "https://arxiv.org/abs/2506.07585", "authors": ["Seokbin Yoon", "Keumjin Lee"], "title": "Aircraft Trajectory Dataset Augmentation in Latent Space", "categories": ["cs.LG"], "comment": null, "summary": "Aircraft trajectory modeling plays a crucial role in Air Traffic Management\n(ATM) and is important for various downstream tasks, including conflict\ndetection and landing time prediction. Dataset augmentation through the\naddition of synthetically generated trajectory data is necessary to develop a\nmore robust aircraft trajectory model and ensure that the trajectory dataset is\nsufficient and balanced. In this work, we propose a novel framework called\nATRADA for aircraft trajectory dataset augmentation. In the proposed framework,\na Transformer encoder learns the underlying patterns in the original trajectory\ndataset and converts each data point into a context vector in the learned\nlatent space. The converted dataset in the latent space is projected into\nreduced dimensions using principal component analysis (PCA), and a Gaussian\nmixture model (GMM) is applied to fit the probability distribution of the data\npoints in the reduced-dimensional space. Finally, new samples are drawn from\nthe fitted GMM, the dimension of the samples is reverted to the original\ndimension, and they are decoded with a Multi-Layer Perceptron (MLP). Several\nexperiments demonstrate that the framework effectively generates new,\nhigh-quality synthetic aircraft trajectory data, which were compared to the\nresults of several baselines.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aATRADA\u7684\u65b0\u578b\u6846\u67b6\uff0c\u7528\u4e8e\u589e\u5f3a\u98de\u673a\u8f68\u8ff9\u6570\u636e\u96c6\uff0c\u901a\u8fc7Transformer\u7f16\u7801\u5668\u548cGMM\u751f\u6210\u9ad8\u8d28\u91cf\u5408\u6210\u6570\u636e\u3002", "motivation": "\u98de\u673a\u8f68\u8ff9\u5efa\u6a21\u5bf9\u7a7a\u7ba1\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u6570\u636e\u96c6\u4e0d\u8db3\u4e14\u4e0d\u5e73\u8861\uff0c\u9700\u901a\u8fc7\u5408\u6210\u6570\u636e\u589e\u5f3a\u6a21\u578b\u9c81\u68d2\u6027\u3002", "method": "\u4f7f\u7528Transformer\u7f16\u7801\u5668\u5b66\u4e60\u8f68\u8ff9\u6a21\u5f0f\u5e76\u8f6c\u6362\u4e3a\u6f5c\u5728\u7a7a\u95f4\u5411\u91cf\uff0cPCA\u964d\u7ef4\u540eGMM\u62df\u5408\u5206\u5e03\uff0cMLP\u89e3\u7801\u751f\u6210\u65b0\u6837\u672c\u3002", "result": "\u5b9e\u9a8c\u8868\u660eATRADA\u80fd\u6709\u6548\u751f\u6210\u9ad8\u8d28\u91cf\u5408\u6210\u8f68\u8ff9\u6570\u636e\uff0c\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "ATRADA\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u8f68\u8ff9\u6570\u636e\u96c6\u4e0d\u8db3\u95ee\u9898\uff0c\u4e3a\u4e0b\u6e38\u4efb\u52a1\u63d0\u4f9b\u4e86\u66f4\u4e30\u5bcc\u7684\u6570\u636e\u652f\u6301\u3002"}}
{"id": "2506.07587", "pdf": "https://arxiv.org/pdf/2506.07587", "abs": "https://arxiv.org/abs/2506.07587", "authors": ["Tongzhou Yu", "Zhuhao Zhang", "Guanghui Zhu", "Shen Jiang", "Meikang Qiu", "Yihua Huang"], "title": "PrunePEFT: Iterative Hybrid Pruning for Parameter-Efficient Fine-tuning of LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Parameter Efficient Fine-Tuning (PEFT) methods have emerged as effective and\npromising approaches for fine-tuning pre-trained language models. Compared with\nFull parameter Fine-Tuning (FFT), PEFT achieved comparable task performance\nwith a substantial reduction of trainable parameters, which largely saved the\ntraining and storage costs. However, using the PEFT method requires considering\na vast design space, such as the type of PEFT modules and their insertion\nlayers. Inadequate configurations can lead to sub-optimal results. Conventional\nsolutions such as architectural search techniques, while effective, tend to\nintroduce substantial additional overhead. In this paper, we propose a novel\napproach, PrunePEFT, which formulates the PEFT strategy search as a pruning\nproblem and introduces a hybrid pruning strategy that capitalizes on the\nsensitivity of pruning methods to different PEFT modules. This method extends\ntraditional pruning techniques by iteratively removing redundant or conflicting\nPEFT modules, thereby optimizing the fine-tuned configuration. By efficiently\nidentifying the most relevant modules, our approach significantly reduces the\ncomputational burden typically associated with architectural search processes,\nmaking it a more scalable and efficient solution for fine-tuning large\npre-trained models.", "AI": {"tldr": "PrunePEFT\u5c06PEFT\u7b56\u7565\u641c\u7d22\u8f6c\u5316\u4e3a\u526a\u679d\u95ee\u9898\uff0c\u901a\u8fc7\u6df7\u5408\u526a\u679d\u7b56\u7565\u4f18\u5316\u914d\u7f6e\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u8d1f\u62c5\u3002", "motivation": "PEFT\u65b9\u6cd5\u867d\u9ad8\u6548\uff0c\u4f46\u8bbe\u8ba1\u7a7a\u95f4\u5e9e\u5927\uff0c\u914d\u7f6e\u4e0d\u5f53\u4f1a\u5bfc\u81f4\u6027\u80fd\u4e0d\u4f73\uff0c\u4f20\u7edf\u641c\u7d22\u65b9\u6cd5\u5f00\u9500\u5927\u3002", "method": "\u5c06PEFT\u7b56\u7565\u641c\u7d22\u8f6c\u5316\u4e3a\u526a\u679d\u95ee\u9898\uff0c\u91c7\u7528\u6df7\u5408\u526a\u679d\u7b56\u7565\u8fed\u4ee3\u79fb\u9664\u5197\u4f59\u6a21\u5757\u3002", "result": "\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u8d1f\u62c5\uff0c\u4f18\u5316\u914d\u7f6e\uff0c\u63d0\u5347\u6548\u7387\u3002", "conclusion": "PrunePEFT\u4e3a\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u6a21\u578b\u5fae\u8c03\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.07595", "pdf": "https://arxiv.org/pdf/2506.07595", "abs": "https://arxiv.org/abs/2506.07595", "authors": ["Hao Qiu", "Emmanuel Esposito", "Mengxiao Zhang"], "title": "Exploiting Curvature in Online Convex Optimization with Delayed Feedback", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "In this work, we study the online convex optimization problem with curved\nlosses and delayed feedback. When losses are strongly convex, existing\napproaches obtain regret bounds of order $d_{\\max} \\ln T$, where $d_{\\max}$ is\nthe maximum delay and $T$ is the time horizon. However, in many cases, this\nguarantee can be much worse than $\\sqrt{d_{\\mathrm{tot}}}$ as obtained by a\ndelayed version of online gradient descent, where $d_{\\mathrm{tot}}$ is the\ntotal delay. We bridge this gap by proposing a variant of\nfollow-the-regularized-leader that obtains regret of order\n$\\min\\{\\sigma_{\\max}\\ln T, \\sqrt{d_{\\mathrm{tot}}}\\}$, where $\\sigma_{\\max}$ is\nthe maximum number of missing observations. We then consider exp-concave losses\nand extend the Online Newton Step algorithm to handle delays with an adaptive\nlearning rate tuning, achieving regret $\\min\\{d_{\\max} n\\ln T,\n\\sqrt{d_{\\mathrm{tot}}}\\}$ where $n$ is the dimension. To our knowledge, this\nis the first algorithm to achieve such a regret bound for exp-concave losses.\nWe further consider the problem of unconstrained online linear regression and\nachieve a similar guarantee by designing a variant of the Vovk-Azoury-Warmuth\nforecaster with a clipping trick. Finally, we implement our algorithms and\nconduct experiments under various types of delay and losses, showing an\nimproved performance over existing methods.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5177\u6709\u5f2f\u66f2\u635f\u5931\u548c\u5ef6\u8fdf\u53cd\u9988\u7684\u5728\u7ebf\u51f8\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u6539\u8fdb\u7b97\u6cd5\u4ee5\u51cf\u5c11\u9057\u61be\u754c\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5f3a\u51f8\u635f\u5931\u4e0b\u7684\u9057\u61be\u754c\u53ef\u80fd\u4e0d\u5982\u5ef6\u8fdf\u7248\u672c\u7684\u5728\u7ebf\u68af\u5ea6\u4e0b\u964d\uff0c\u56e0\u6b64\u9700\u8981\u6539\u8fdb\u7b97\u6cd5\u4ee5\u7f29\u5c0f\u8fd9\u4e00\u5dee\u8ddd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u8ddf\u968f\u6b63\u5219\u5316\u9886\u5bfc\u8005\u7b97\u6cd5\uff0c\u5e76\u6269\u5c55\u4e86\u5728\u7ebf\u725b\u987f\u6b65\u7b97\u6cd5\u4ee5\u5904\u7406\u5ef6\u8fdf\uff0c\u540c\u65f6\u8bbe\u8ba1\u4e86\u5e26\u526a\u88c1\u6280\u5de7\u7684Vovk-Azoury-Warmuth\u9884\u6d4b\u5668\u53d8\u4f53\u3002", "result": "\u65b0\u7b97\u6cd5\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u9057\u61be\u754c\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u7406\u8bba\u548c\u5b9e\u9a8c\u4e0a\u5747\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\uff0c\u4e3a\u5ef6\u8fdf\u53cd\u9988\u7684\u5728\u7ebf\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.07596", "pdf": "https://arxiv.org/pdf/2506.07596", "abs": "https://arxiv.org/abs/2506.07596", "authors": ["Torsten Krau\u00df", "Hamid Dashtbani", "Alexandra Dmitrienko"], "title": "TwinBreak: Jailbreaking LLM Security Alignments based on Twin Prompts", "categories": ["cs.LG"], "comment": "26 pages, 25 tables, 13 figures, 2 algorithms, to appear in the 43th\n  USENIX Security Symposium (USENIX Security 2025)", "summary": "Machine learning is advancing rapidly, with applications bringing notable\nbenefits, such as improvements in translation and code generation. Models like\nChatGPT, powered by Large Language Models (LLMs), are increasingly integrated\ninto daily life. However, alongside these benefits, LLMs also introduce social\nrisks. Malicious users can exploit LLMs by submitting harmful prompts, such as\nrequesting instructions for illegal activities. To mitigate this, models often\ninclude a security mechanism that automatically rejects such harmful prompts.\nHowever, they can be bypassed through LLM jailbreaks. Current jailbreaks often\nrequire significant manual effort, high computational costs, or result in\nexcessive model modifications that may degrade regular utility.\n  We introduce TwinBreak, an innovative safety alignment removal method.\nBuilding on the idea that the safety mechanism operates like an embedded\nbackdoor, TwinBreak identifies and prunes parameters responsible for this\nfunctionality. By focusing on the most relevant model layers, TwinBreak\nperforms fine-grained analysis of parameters essential to model utility and\nsafety. TwinBreak is the first method to analyze intermediate outputs from\nprompts with high structural and content similarity to isolate safety\nparameters. We present the TwinPrompt dataset containing 100 such twin prompts.\nExperiments confirm TwinBreak's effectiveness, achieving 89% to 98% success\nrates with minimal computational requirements across 16 LLMs from five vendors.", "AI": {"tldr": "TwinBreak\u662f\u4e00\u79cd\u521b\u65b0\u7684\u5b89\u5168\u5bf9\u9f50\u79fb\u9664\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bc6\u522b\u548c\u4fee\u526a\u8d1f\u8d23\u5b89\u5168\u529f\u80fd\u7684\u53c2\u6570\uff0c\u6709\u6548\u7ed5\u8fc7LLM\u7684\u5b89\u5168\u673a\u5236\uff0c\u6210\u529f\u7387\u8fbe89%\u81f398%\u3002", "motivation": "\u5c3d\u7ba1LLM\u5e26\u6765\u8bb8\u591a\u597d\u5904\uff0c\u4f46\u6076\u610f\u7528\u6237\u53ef\u80fd\u901a\u8fc7\u6709\u5bb3\u63d0\u793a\u7ed5\u8fc7\u5b89\u5168\u673a\u5236\u3002\u73b0\u6709\u65b9\u6cd5\u6210\u672c\u9ad8\u6216\u5f71\u54cd\u6a21\u578b\u6027\u80fd\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "TwinBreak\u901a\u8fc7\u5206\u6790\u4e2d\u95f4\u8f93\u51fa\uff0c\u8bc6\u522b\u5e76\u4fee\u526a\u4e0e\u5b89\u5168\u529f\u80fd\u76f8\u5173\u7684\u53c2\u6570\uff0c\u540c\u65f6\u4fdd\u7559\u6a21\u578b\u7684\u6838\u5fc3\u529f\u80fd\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eTwinBreak\u572816\u79cdLLM\u4e0a\u6210\u529f\u7387\u8fbe89%\u81f398%\uff0c\u4e14\u8ba1\u7b97\u6210\u672c\u4f4e\u3002", "conclusion": "TwinBreak\u4e3a\u7ed5\u8fc7LLM\u5b89\u5168\u673a\u5236\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u4f4e\u6210\u672c\u7684\u65b9\u6cd5\uff0c\u4f46\u4e5f\u63ed\u793a\u4e86\u5b89\u5168\u673a\u5236\u7684\u8106\u5f31\u6027\u3002"}}
{"id": "2506.07616", "pdf": "https://arxiv.org/pdf/2506.07616", "abs": "https://arxiv.org/abs/2506.07616", "authors": ["Zhixin Geng", "Xu Fan", "Xiqiao Lu", "Yan Zhang", "Guangyuan Yu", "Cheng Huang", "Qian Wang", "Yuewu Li", "Weichun Ma", "Qi Yu", "Libo Wu", "Hao Li"], "title": "FuXi-Air: Urban Air Quality Forecasting Based on Emission-Meteorology-Pollutant multimodal Machine Learning", "categories": ["cs.LG"], "comment": null, "summary": "Air pollution has emerged as a major public health challenge in megacities.\nNumerical simulations and single-site machine learning approaches have been\nwidely applied in air quality forecasting tasks. However, these methods face\nmultiple limitations, including high computational costs, low operational\nefficiency, and limited integration with observational data. With the rapid\nadvancement of artificial intelligence, there is an urgent need to develop a\nlow-cost, efficient air quality forecasting model for smart urban management.\nAn air quality forecasting model, named FuXi-Air, has been constructed in this\nstudy based on multimodal data fusion to support high-precision air quality\nforecasting and operated in typical megacities. The model integrates\nmeteorological forecasts, emission inventories, and pollutant monitoring data\nunder the guidance of air pollution mechanism. By combining an autoregressive\nprediction framework with a frame interpolation strategy, the model\nsuccessfully completes 72-hour forecasts for six major air pollutants at an\nhourly resolution across multiple monitoring sites within 25-30 seconds. In\nterms of both computational efficiency and forecasting accuracy, it outperforms\nthe mainstream numerical air quality models in operational forecasting work.\nAblation experiments concerning key influencing factors show that although\nmeteorological data contribute more to model accuracy than emission inventories\ndo, the integration of multimodal data significantly improves forecasting\nprecision and ensures that reliable predictions are obtained under differing\npollution mechanisms across megacities. This study provides both a technical\nreference and a practical example for applying multimodal data-driven models to\nair quality forecasting and offers new insights into building hybrid\nforecasting systems to support air pollution risk warning in smart city\nmanagement.", "AI": {"tldr": "FuXi-Air\u6a21\u578b\u901a\u8fc7\u591a\u6a21\u6001\u6570\u636e\u878d\u5408\uff0c\u9ad8\u6548\u5b8c\u621072\u5c0f\u65f6\u7a7a\u6c14\u8d28\u91cf\u9884\u6d4b\uff0c\u4f18\u4e8e\u4e3b\u6d41\u6570\u503c\u6a21\u578b\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u7a7a\u6c14\u8d28\u91cf\u9884\u6d4b\u65b9\u6cd5\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u3001\u4f4e\u6548\u7387\u548c\u89c2\u6d4b\u6570\u636e\u6574\u5408\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u7ed3\u5408\u6c14\u8c61\u9884\u62a5\u3001\u6392\u653e\u6e05\u5355\u548c\u6c61\u67d3\u7269\u76d1\u6d4b\u6570\u636e\uff0c\u91c7\u7528\u81ea\u56de\u5f52\u9884\u6d4b\u6846\u67b6\u548c\u5e27\u63d2\u503c\u7b56\u7565\u3002", "result": "\u572825-30\u79d2\u5185\u5b8c\u6210\u591a\u7ad9\u70b96\u79cd\u6c61\u67d3\u7269\u768472\u5c0f\u65f6\u9884\u6d4b\uff0c\u8ba1\u7b97\u6548\u7387\u548c\u7cbe\u5ea6\u5747\u4f18\u4e8e\u4e3b\u6d41\u6a21\u578b\u3002", "conclusion": "\u591a\u6a21\u6001\u6570\u636e\u9a71\u52a8\u6a21\u578b\u4e3a\u667a\u80fd\u57ce\u5e02\u7ba1\u7406\u63d0\u4f9b\u6280\u672f\u53c2\u8003\uff0c\u652f\u6301\u6df7\u5408\u9884\u6d4b\u7cfb\u7edf\u7684\u6784\u5efa\u3002"}}
{"id": "2506.07619", "pdf": "https://arxiv.org/pdf/2506.07619", "abs": "https://arxiv.org/abs/2506.07619", "authors": ["Toby Boyne", "Juan S. Campos", "Becky D. Langdon", "Jixiang Qing", "Yilin Xie", "Shiqiang Zhang", "Calvin Tsay", "Ruth Misener", "Daniel W. Davies", "Kim E. Jelfs", "Sarah Boyall", "Thomas M. Dixon", "Linden Schrecker", "Jose Pablo Folch"], "title": "The Catechol Benchmark: Time-series Solvent Selection Data for Few-shot Machine Learning", "categories": ["cs.LG", "q-bio.QM"], "comment": null, "summary": "Machine learning has promised to change the landscape of laboratory\nchemistry, with impressive results in molecular property prediction and\nreaction retro-synthesis. However, chemical datasets are often inaccessible to\nthe machine learning community as they tend to require cleaning, thorough\nunderstanding of the chemistry, or are simply not available. In this paper, we\nintroduce a novel dataset for yield prediction, providing the first-ever\ntransient flow dataset for machine learning benchmarking, covering over 1200\nprocess conditions. While previous datasets focus on discrete parameters, our\nexperimental set-up allow us to sample a large number of continuous process\nconditions, generating new challenges for machine learning models. We focus on\nsolvent selection, a task that is particularly difficult to model theoretically\nand therefore ripe for machine learning applications. We showcase benchmarking\nfor regression algorithms, transfer-learning approaches, feature engineering,\nand active learning, with important applications towards solvent replacement\nand sustainable manufacturing.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u7528\u4e8e\u4ea7\u7387\u9884\u6d4b\u7684\u65b0\u578b\u6570\u636e\u96c6\uff0c\u9996\u6b21\u63d0\u4f9b\u4e86\u7528\u4e8e\u673a\u5668\u5b66\u4e60\u57fa\u51c6\u6d4b\u8bd5\u7684\u77ac\u6001\u6d41\u52a8\u6570\u636e\u96c6\uff0c\u8986\u76d61200\u591a\u79cd\u5de5\u827a\u6761\u4ef6\uff0c\u91cd\u70b9\u5173\u6ce8\u6eb6\u5242\u9009\u62e9\u4efb\u52a1\u3002", "motivation": "\u5316\u5b66\u6570\u636e\u96c6\u901a\u5e38\u96be\u4ee5\u83b7\u53d6\u6216\u9700\u8981\u6e05\u6d17\uff0c\u9650\u5236\u4e86\u673a\u5668\u5b66\u4e60\u5728\u5316\u5b66\u9886\u57df\u7684\u5e94\u7528\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u63d0\u4f9b\u9996\u4e2a\u77ac\u6001\u6d41\u52a8\u6570\u636e\u96c6\uff0c\u63a8\u52a8\u673a\u5668\u5b66\u4e60\u5728\u6eb6\u5242\u9009\u62e9\u548c\u53ef\u6301\u7eed\u5236\u9020\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\u8bbe\u7f6e\u91c7\u96c6\u5927\u91cf\u8fde\u7eed\u5de5\u827a\u6761\u4ef6\u6570\u636e\uff0c\u5e76\u7528\u4e8e\u56de\u5f52\u7b97\u6cd5\u3001\u8fc1\u79fb\u5b66\u4e60\u3001\u7279\u5f81\u5de5\u7a0b\u548c\u4e3b\u52a8\u5b66\u4e60\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u6570\u636e\u96c6\u8986\u76d61200\u591a\u79cd\u5de5\u827a\u6761\u4ef6\uff0c\u4e3a\u673a\u5668\u5b66\u4e60\u6a21\u578b\u63d0\u4f9b\u4e86\u65b0\u7684\u6311\u6218\uff0c\u5c24\u5176\u5728\u6eb6\u5242\u9009\u62e9\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u4e3a\u673a\u5668\u5b66\u4e60\u5728\u5316\u5b66\u9886\u57df\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u91cd\u8981\u8d44\u6e90\uff0c\u5c24\u5176\u5728\u6eb6\u5242\u66ff\u6362\u548c\u53ef\u6301\u7eed\u5236\u9020\u65b9\u9762\u5177\u6709\u6f5c\u5728\u4ef7\u503c\u3002"}}
{"id": "2506.07624", "pdf": "https://arxiv.org/pdf/2506.07624", "abs": "https://arxiv.org/abs/2506.07624", "authors": ["Ali Hariri", "\u00c1lvaro Arroyo", "Alessio Gravina", "Moshe Eliasof", "Carola-Bibiane Sch\u00f6nlieb", "Davide Bacciu", "Kamyar Azizzadenesheli", "Xiaowen Dong", "Pierre Vandergheynst"], "title": "Return of ChebNet: Understanding and Improving an Overlooked GNN on Long Range Tasks", "categories": ["cs.LG"], "comment": null, "summary": "ChebNet, one of the earliest spectral GNNs, has largely been overshadowed by\nMessage Passing Neural Networks (MPNNs), which gained popularity for their\nsimplicity and effectiveness in capturing local graph structure. Despite their\nsuccess, MPNNs are limited in their ability to capture long-range dependencies\nbetween nodes. This has led researchers to adapt MPNNs through rewiring or make\nuse of Graph Transformers, which compromises the computational efficiency that\ncharacterized early spatial message-passing architectures, and typically\ndisregards the graph structure. Almost a decade after its original\nintroduction, we revisit ChebNet to shed light on its ability to model distant\nnode interactions. We find that out-of-box, ChebNet already shows competitive\nadvantages relative to classical MPNNs and GTs on long-range benchmarks, while\nmaintaining good scalability properties for high-order polynomials. However, we\nuncover that this polynomial expansion leads ChebNet to an unstable regime\nduring training. To address this limitation, we cast ChebNet as a stable and\nnon-dissipative dynamical system, which we coin Stable-ChebNet. Our\nStable-ChebNet model allows for stable information propagation, and has\ncontrollable dynamics which do not require the use of eigendecompositions,\npositional encodings, or graph rewiring. Across several benchmarks,\nStable-ChebNet achieves near state-of-the-art performance.", "AI": {"tldr": "ChebNet\u5728\u957f\u8ddd\u79bb\u8282\u70b9\u4ea4\u4e92\u5efa\u6a21\u4e2d\u8868\u73b0\u51fa\u7ade\u4e89\u529b\uff0c\u4f46\u5b58\u5728\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u6539\u8fdb\u540e\u7684Stable-ChebNet\u89e3\u51b3\u4e86\u8fd9\u4e00\u95ee\u9898\u5e76\u53d6\u5f97\u4f18\u5f02\u6027\u80fd\u3002", "motivation": "MPNNs\u548cGraph Transformers\u5728\u6355\u6349\u957f\u8ddd\u79bb\u4f9d\u8d56\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u800cChebNet\u4f5c\u4e3a\u65e9\u671f\u5149\u8c31GNN\u53ef\u80fd\u5177\u5907\u6f5c\u529b\u3002", "method": "\u5c06ChebNet\u5efa\u6a21\u4e3a\u7a33\u5b9a\u4e14\u975e\u8017\u6563\u7684\u52a8\u6001\u7cfb\u7edf\uff08Stable-ChebNet\uff09\uff0c\u907f\u514d\u591a\u9879\u5f0f\u6269\u5c55\u7684\u4e0d\u7a33\u5b9a\u6027\u3002", "result": "Stable-ChebNet\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u63a5\u8fd1\u6700\u4f18\u6027\u80fd\uff0c\u4e14\u65e0\u9700\u989d\u5916\u8ba1\u7b97\u5f00\u9500\u3002", "conclusion": "ChebNet\u53ca\u5176\u6539\u8fdb\u7248Stable-ChebNet\u5728\u957f\u8ddd\u79bb\u4f9d\u8d56\u5efa\u6a21\u4e2d\u5177\u6709\u7ade\u4e89\u529b\uff0c\u4e3aGNN\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2506.07661", "pdf": "https://arxiv.org/pdf/2506.07661", "abs": "https://arxiv.org/abs/2506.07661", "authors": ["Meir Feder", "Ruediger Urbanke", "Yaniv Fogel"], "title": "The Universality Lens: Why Even Highly Over-Parametrized Models Learn Well", "categories": ["cs.LG", "cs.IT", "math.IT", "stat.ML"], "comment": null, "summary": "A fundamental question in modern machine learning is why large,\nover-parameterized models, such as deep neural networks and transformers, tend\nto generalize well, even when their number of parameters far exceeds the number\nof training samples.\n  We investigate this phenomenon through the lens of information theory,\ngrounded in universal learning theory. Specifically, we study a Bayesian\nmixture learner with log-loss and (almost) uniform prior over an expansive\nhypothesis class.\n  Our key result shows that the learner's regret is not determined by the\noverall size of the hypothesis class, but rather by the cumulative probability\nof all models that are close, in Kullback-Leibler divergence distance, to the\ntrue data-generating process. We refer to this cumulative probability as the\nweight of the hypothesis.\n  This leads to a natural notion of model simplicity: simple models are those\nwith large weight and thus require fewer samples to generalize, while complex\nmodels have small weight and need more data. This perspective provides a\nrigorous and intuitive explanation for why over-parameterized models often\navoid overfitting: the presence of simple hypotheses allows the posterior to\nconcentrate on them when supported by the data.\n  We further bridge theory and practice by recalling that stochastic gradient\ndescent with Langevin dynamics samples from the correct posterior distribution,\nenabling our theoretical learner to be approximated using standard machine\nlearning methods combined with ensemble learning.\n  Our analysis yields non-uniform regret bounds and aligns with key practical\nconcepts such as flat minima and model distillation. The results apply broadly\nacross online, batch, and supervised learning settings, offering a unified and\nprincipled understanding of the generalization behavior of modern AI systems.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u4fe1\u606f\u8bba\u548c\u8d1d\u53f6\u65af\u6df7\u5408\u5b66\u4e60\u6846\u67b6\uff0c\u89e3\u91ca\u4e86\u8fc7\u53c2\u6570\u5316\u6a21\u578b\uff08\u5982\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff09\u6cdb\u5316\u80fd\u529b\u5f3a\u7684\u73b0\u8c61\uff0c\u63d0\u51fa\u6a21\u578b\u2018\u6743\u91cd\u2019\u6982\u5ff5\uff0c\u5e76\u8868\u660e\u7b80\u5355\u6a21\u578b\u56e0\u6743\u91cd\u9ad8\u800c\u66f4\u6613\u6cdb\u5316\u3002", "motivation": "\u7814\u7a76\u4e3a\u4f55\u8fc7\u53c2\u6570\u5316\u6a21\u578b\u5728\u53c2\u6570\u8fdc\u8d85\u8bad\u7ec3\u6837\u672c\u65f6\u4ecd\u80fd\u826f\u597d\u6cdb\u5316\uff0c\u8bd5\u56fe\u4ece\u7406\u8bba\u4e0a\u89e3\u91ca\u8fd9\u4e00\u73b0\u8c61\u3002", "method": "\u91c7\u7528\u8d1d\u53f6\u65af\u6df7\u5408\u5b66\u4e60\u6846\u67b6\uff0c\u57fa\u4e8e\u5bf9\u6570\u635f\u5931\u548c\u5747\u5300\u5148\u9a8c\uff0c\u5206\u6790\u5047\u8bbe\u7c7b\u7684\u7d2f\u79ef\u6982\u7387\uff08\u6743\u91cd\uff09\u5bf9\u6cdb\u5316\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u6cdb\u5316\u80fd\u529b\u53d6\u51b3\u4e8e\u5047\u8bbe\u7c7b\u4e2d\u63a5\u8fd1\u771f\u5b9e\u6570\u636e\u751f\u6210\u8fc7\u7a0b\u7684\u6a21\u578b\u7684\u7d2f\u79ef\u6982\u7387\uff08\u6743\u91cd\uff09\uff0c\u800c\u975e\u5047\u8bbe\u7c7b\u603b\u5927\u5c0f\u3002", "conclusion": "\u8fc7\u53c2\u6570\u5316\u6a21\u578b\u901a\u8fc7\u540e\u9a8c\u96c6\u4e2d\u5728\u7b80\u5355\u5047\u8bbe\u4e0a\u907f\u514d\u8fc7\u62df\u5408\uff0c\u7406\u8bba\u4e0e\u5b9e\u9645\u65b9\u6cd5\uff08\u5982\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff09\u7ed3\u5408\uff0c\u4e3a\u73b0\u4ee3AI\u7cfb\u7edf\u7684\u6cdb\u5316\u884c\u4e3a\u63d0\u4f9b\u4e86\u7edf\u4e00\u89e3\u91ca\u3002"}}
{"id": "2506.07666", "pdf": "https://arxiv.org/pdf/2506.07666", "abs": "https://arxiv.org/abs/2506.07666", "authors": ["Seyedhamidreza Mousavi", "Seyedali Mousavi", "Masoud Daneshtalab"], "title": "ProARD: progressive adversarial robustness distillation: provide wide range of robust students", "categories": ["cs.LG"], "comment": null, "summary": "Adversarial Robustness Distillation (ARD) has emerged as an effective method\nto enhance the robustness of lightweight deep neural networks against\nadversarial attacks. Current ARD approaches have leveraged a large robust\nteacher network to train one robust lightweight student. However, due to the\ndiverse range of edge devices and resource constraints, current approaches\nrequire training a new student network from scratch to meet specific\nconstraints, leading to substantial computational costs and increased CO2\nemissions. This paper proposes Progressive Adversarial Robustness Distillation\n(ProARD), enabling the efficient one-time training of a dynamic network that\nsupports a diverse range of accurate and robust student networks without\nrequiring retraining. We first make a dynamic deep neural network based on\ndynamic layers by encompassing variations in width, depth, and expansion in\neach design stage to support a wide range of architectures. Then, we consider\nthe student network with the largest size as the dynamic teacher network.\nProARD trains this dynamic network using a weight-sharing mechanism to jointly\noptimize the dynamic teacher network and its internal student networks.\nHowever, due to the high computational cost of calculating exact gradients for\nall the students within the dynamic network, a sampling mechanism is required\nto select a subset of students. We show that random student sampling in each\niteration fails to produce accurate and robust students.", "AI": {"tldr": "ProARD\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u7f51\u7edc\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e00\u6b21\u6027\u8bad\u7ec3\u652f\u6301\u591a\u79cd\u8f7b\u91cf\u7ea7\u5b66\u751f\u7f51\u7edc\uff0c\u907f\u514d\u4e86\u91cd\u590d\u8bad\u7ec3\u7684\u9ad8\u6210\u672c\u548c\u78b3\u6392\u653e\u3002", "motivation": "\u5f53\u524d\u5bf9\u6297\u9c81\u68d2\u6027\u84b8\u998f\u65b9\u6cd5\u9700\u8981\u4e3a\u4e0d\u540c\u8d44\u6e90\u7ea6\u675f\u7684\u8bbe\u5907\u91cd\u65b0\u8bad\u7ec3\u5b66\u751f\u7f51\u7edc\uff0c\u5bfc\u81f4\u9ad8\u8ba1\u7b97\u6210\u672c\u548c\u78b3\u6392\u653e\u3002", "method": "\u57fa\u4e8e\u52a8\u6001\u5c42\u6784\u5efa\u52a8\u6001\u7f51\u7edc\uff0c\u901a\u8fc7\u6743\u91cd\u5171\u4eab\u673a\u5236\u8054\u5408\u4f18\u5316\u52a8\u6001\u6559\u5e08\u7f51\u7edc\u53ca\u5176\u5185\u90e8\u5b66\u751f\u7f51\u7edc\uff0c\u5e76\u91c7\u7528\u91c7\u6837\u673a\u5236\u9009\u62e9\u5b66\u751f\u5b50\u96c6\u3002", "result": "\u968f\u673a\u91c7\u6837\u5b66\u751f\u7f51\u7edc\u65e0\u6cd5\u4ea7\u751f\u51c6\u786e\u4e14\u9c81\u68d2\u7684\u5b66\u751f\u7f51\u7edc\u3002", "conclusion": "ProARD\u4e3a\u9ad8\u6548\u8bad\u7ec3\u591a\u6837\u5316\u9c81\u68d2\u5b66\u751f\u7f51\u7edc\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2506.07673", "pdf": "https://arxiv.org/pdf/2506.07673", "abs": "https://arxiv.org/abs/2506.07673", "authors": ["Guanhua Zhang", "Florian E. Dorner", "Moritz Hardt"], "title": "How Benchmark Prediction from Fewer Data Misses the Mark", "categories": ["cs.LG"], "comment": null, "summary": "Large language model (LLM) evaluation is increasingly costly, prompting\ninterest in methods that speed up evaluation by shrinking benchmark datasets.\nBenchmark prediction (also called efficient LLM evaluation) aims to select a\nsmall subset of evaluation points and predict overall benchmark performance\nfrom that subset. In this paper, we systematically assess the strengths and\nlimitations of 11 benchmark prediction methods across 19 diverse benchmarks.\nFirst, we identify a highly competitive baseline: Take a random sample and fit\na regression model on the sample to predict missing entries. Outperforming most\nexisting methods, this baseline challenges the assumption that careful subset\nselection is necessary for benchmark prediction. Second, we discover that all\nexisting methods crucially depend on model similarity. They work best when\ninterpolating scores among similar models. The effectiveness of benchmark\nprediction sharply declines when new models have higher accuracy than\npreviously seen models. In this setting of extrapolation, none of the previous\nmethods consistently beat a simple average over random samples. To improve over\nthe sample average, we introduce a new method inspired by augmented inverse\npropensity weighting. This method consistently outperforms the random sample\naverage even for extrapolation. However, its performance still relies on model\nsimilarity and the gains are modest in general. This shows that benchmark\nprediction fails just when it is most needed: at the evaluation frontier, where\nthe goal is to evaluate new models of unknown capabilities.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e8611\u79cd\u57fa\u51c6\u9884\u6d4b\u65b9\u6cd5\u572819\u4e2a\u4e0d\u540c\u57fa\u51c6\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u968f\u673a\u91c7\u6837\u52a0\u56de\u5f52\u6a21\u578b\u662f\u4e00\u4e2a\u5f3a\u57fa\u7ebf\uff0c\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u6a21\u578b\u76f8\u4f3c\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\u5728\u90e8\u5206\u60c5\u51b5\u4e0b\u4f18\u4e8e\u968f\u673a\u91c7\u6837\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8bc4\u4f30\u6210\u672c\u9ad8\u6602\uff0c\u9700\u8981\u5feb\u901f\u8bc4\u4f30\u65b9\u6cd5\u4ee5\u51cf\u5c11\u6570\u636e\u96c6\u89c4\u6a21\u3002", "method": "\u7cfb\u7edf\u8bc4\u4f3011\u79cd\u57fa\u51c6\u9884\u6d4b\u65b9\u6cd5\uff0c\u63d0\u51fa\u968f\u673a\u91c7\u6837\u52a0\u56de\u5f52\u6a21\u578b\u4f5c\u4e3a\u57fa\u7ebf\uff0c\u5e76\u5f15\u5165\u57fa\u4e8e\u589e\u5f3a\u9006\u503e\u5411\u52a0\u6743\u7684\u65b0\u65b9\u6cd5\u3002", "result": "\u73b0\u6709\u65b9\u6cd5\u5728\u6a21\u578b\u76f8\u4f3c\u6027\u9ad8\u65f6\u6709\u6548\uff0c\u4f46\u5728\u65b0\u6a21\u578b\u80fd\u529b\u672a\u77e5\u65f6\u8868\u73b0\u4e0d\u4f73\uff1b\u65b0\u65b9\u6cd5\u5728\u90e8\u5206\u60c5\u51b5\u4e0b\u4f18\u4e8e\u968f\u673a\u91c7\u6837\u3002", "conclusion": "\u57fa\u51c6\u9884\u6d4b\u5728\u8bc4\u4f30\u524d\u6cbf\uff08\u65b0\u6a21\u578b\u80fd\u529b\u672a\u77e5\u65f6\uff09\u6548\u679c\u6709\u9650\uff0c\u4ecd\u9700\u6539\u8fdb\u3002"}}
{"id": "2506.07706", "pdf": "https://arxiv.org/pdf/2506.07706", "abs": "https://arxiv.org/abs/2506.07706", "authors": ["Boris Martirosyan", "Alexey Karmanov"], "title": "Evaluating Robustness in Latent Diffusion Models via Embedding Level Augmentation", "categories": ["cs.LG"], "comment": null, "summary": "Latent diffusion models (LDMs) achieve state-of-the-art performance across\nvarious tasks, including image generation and video synthesis. However, they\ngenerally lack robustness, a limitation that remains not fully explored in\ncurrent research. In this paper, we propose several methods to address this\ngap. First, we hypothesize that the robustness of LDMs primarily should be\nmeasured without their text encoder, because if we take and explore the whole\narchitecture, the problems of image generator and text encoders wll be fused.\nSecond, we introduce novel data augmentation techniques designed to reveal\nrobustness shortcomings in LDMs when processing diverse textual prompts. We\nthen fine-tune Stable Diffusion 3 and Stable Diffusion XL models using\nDreambooth, incorporating these proposed augmentation methods across multiple\ntasks. Finally, we propose a novel evaluation pipeline specifically tailored to\nassess the robustness of LDMs fine-tuned via Dreambooth.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u6539\u8fdb\u6f5c\u5728\u6269\u6563\u6a21\u578b\uff08LDMs\uff09\u9c81\u68d2\u6027\u7684\u65b9\u6cd5\uff0c\u5305\u62ec\u5206\u79bb\u6587\u672c\u7f16\u7801\u5668\u8bc4\u4f30\u3001\u65b0\u6570\u636e\u589e\u5f3a\u6280\u672f\u3001\u57fa\u4e8eDreambooth\u7684\u5fae\u8c03\u53ca\u4e13\u7528\u8bc4\u4f30\u6d41\u7a0b\u3002", "motivation": "LDMs\u5728\u56fe\u50cf\u751f\u6210\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u9c81\u68d2\u6027\u4e0d\u8db3\uff0c\u73b0\u6709\u7814\u7a76\u672a\u5145\u5206\u63a2\u7d22\u6b64\u95ee\u9898\u3002", "method": "1. \u5206\u79bb\u6587\u672c\u7f16\u7801\u5668\u8bc4\u4f30\uff1b2. \u65b0\u6570\u636e\u589e\u5f3a\u6280\u672f\uff1b3. \u7528Dreambooth\u5fae\u8c03Stable Diffusion\u6a21\u578b\uff1b4. \u63d0\u51fa\u4e13\u7528\u8bc4\u4f30\u6d41\u7a0b\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u63d0\u5347\u4e86LDMs\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u672c\u6587\u65b9\u6cd5\u4e3aLDMs\u7684\u9c81\u68d2\u6027\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\uff0c\u5e76\u5c55\u793a\u4e86\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.07735", "pdf": "https://arxiv.org/pdf/2506.07735", "abs": "https://arxiv.org/abs/2506.07735", "authors": ["Haizhao Jing", "Haokui Zhang", "Zhenhao Shang", "Rong Xiao", "Peng Wang", "Yanning Zhang"], "title": "Language Embedding Meets Dynamic Graph: A New Exploration for Neural Architecture Representation Learning", "categories": ["cs.LG", "cs.CV"], "comment": "9 pages, 3 figures", "summary": "Neural Architecture Representation Learning aims to transform network models\ninto feature representations for predicting network attributes, playing a\ncrucial role in deploying and designing networks for real-world applications.\nRecently, inspired by the success of transformers, transformer-based models\nintegrated with Graph Neural Networks (GNNs) have achieved significant progress\nin representation learning. However, current methods still have some\nlimitations. First, existing methods overlook hardware attribute information,\nwhich conflicts with the current trend of diversified deep learning hardware\nand limits the practical applicability of models. Second, current encoding\napproaches rely on static adjacency matrices to represent topological\nstructures, failing to capture the structural differences between computational\nnodes, which ultimately compromises encoding effectiveness. In this paper, we\nintroduce LeDG-Former, an innovative framework that addresses these limitations\nthrough the synergistic integration of language-based semantic embedding and\ndynamic graph representation learning. Specifically, inspired by large language\nmodels (LLMs), we propose a language embedding framework where both neural\narchitectures and hardware platform specifications are projected into a unified\nsemantic space through tokenization and LLM processing, enabling zero-shot\nprediction across different hardware platforms for the first time. Then, we\npropose a dynamic graph-based transformer for modeling neural architectures,\nresulting in improved neural architecture modeling performance. On the NNLQP\nbenchmark, LeDG-Former surpasses previous methods, establishing a new SOTA\nwhile demonstrating the first successful cross-hardware latency prediction\ncapability. Furthermore, our framework achieves superior performance on the\ncell-structured NAS-Bench-101 and NAS-Bench-201 datasets.", "AI": {"tldr": "LeDG-Former\u6846\u67b6\u901a\u8fc7\u8bed\u8a00\u5d4c\u5165\u548c\u52a8\u6001\u56fe\u8868\u793a\u5b66\u4e60\u7684\u7ed3\u5408\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5ffd\u7565\u786c\u4ef6\u5c5e\u6027\u548c\u9759\u6001\u90bb\u63a5\u77e9\u9635\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u8de8\u786c\u4ef6\u5e73\u53f0\u7684\u96f6\u6837\u672c\u9884\u6d4b\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u6700\u4f18\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\u5ffd\u89c6\u4e86\u786c\u4ef6\u5c5e\u6027\u4fe1\u606f\uff0c\u4e14\u4f9d\u8d56\u9759\u6001\u90bb\u63a5\u77e9\u9635\uff0c\u9650\u5236\u4e86\u6a21\u578b\u7684\u5b9e\u7528\u6027\u548c\u7f16\u7801\u6548\u679c\u3002", "method": "\u63d0\u51faLeDG-Former\u6846\u67b6\uff0c\u7ed3\u5408\u8bed\u8a00\u5d4c\u5165\uff08\u5229\u7528LLM\u5c06\u67b6\u6784\u548c\u786c\u4ef6\u6620\u5c04\u5230\u7edf\u4e00\u8bed\u4e49\u7a7a\u95f4\uff09\u548c\u52a8\u6001\u56feTransformer\uff0c\u6539\u8fdb\u67b6\u6784\u5efa\u6a21\u3002", "result": "\u5728NNLQP\u3001NAS-Bench-101\u548cNAS-Bench-201\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u6700\u4f18\uff0c\u9996\u6b21\u5b9e\u73b0\u8de8\u786c\u4ef6\u5ef6\u8fdf\u9884\u6d4b\u3002", "conclusion": "LeDG-Former\u901a\u8fc7\u8bed\u8a00\u548c\u52a8\u6001\u56fe\u7684\u7ed3\u5408\uff0c\u663e\u8457\u63d0\u5347\u4e86\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u8868\u793a\u5b66\u4e60\u7684\u6027\u80fd\u548c\u5e94\u7528\u8303\u56f4\u3002"}}
{"id": "2506.07744", "pdf": "https://arxiv.org/pdf/2506.07744", "abs": "https://arxiv.org/abs/2506.07744", "authors": ["Seungho Baek", "Taegeon Park", "Jongchan Park", "Seungjun Oh", "Yusung Kim"], "title": "Graph-Assisted Stitching for Offline Hierarchical Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "ICML 2025", "summary": "Existing offline hierarchical reinforcement learning methods rely on\nhigh-level policy learning to generate subgoal sequences. However, their\nefficiency degrades as task horizons increase, and they lack effective\nstrategies for stitching useful state transitions across different\ntrajectories. We propose Graph-Assisted Stitching (GAS), a novel framework that\nformulates subgoal selection as a graph search problem rather than learning an\nexplicit high-level policy. By embedding states into a Temporal Distance\nRepresentation (TDR) space, GAS clusters semantically similar states from\ndifferent trajectories into unified graph nodes, enabling efficient transition\nstitching. A shortest-path algorithm is then applied to select subgoal\nsequences within the graph, while a low-level policy learns to reach the\nsubgoals. To improve graph quality, we introduce the Temporal Efficiency (TE)\nmetric, which filters out noisy or inefficient transition states, significantly\nenhancing task performance. GAS outperforms prior offline HRL methods across\nlocomotion, navigation, and manipulation tasks. Notably, in the most\nstitching-critical task, it achieves a score of 88.3, dramatically surpassing\nthe previous state-of-the-art score of 1.0. Our source code is available at:\nhttps://github.com/qortmdgh4141/GAS.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGAS\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u5b50\u76ee\u6807\u9009\u62e9\u5efa\u6a21\u4e3a\u56fe\u641c\u7d22\u95ee\u9898\uff0c\u800c\u975e\u663e\u5f0f\u5b66\u4e60\u9ad8\u5c42\u7b56\u7565\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u79bb\u7ebf\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u4efb\u52a1\u65f6\u95f4\u589e\u957f\u65f6\u6548\u7387\u4e0b\u964d\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u79bb\u7ebf\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u9ad8\u5c42\u7b56\u7565\u751f\u6210\u5b50\u76ee\u6807\u5e8f\u5217\uff0c\u4f46\u968f\u7740\u4efb\u52a1\u65f6\u95f4\u589e\u957f\u6548\u7387\u4e0b\u964d\uff0c\u4e14\u7f3a\u4e4f\u8de8\u8f68\u8ff9\u6709\u6548\u72b6\u6001\u8f6c\u79fb\u7684\u7b56\u7565\u3002", "method": "GAS\u5c06\u5b50\u76ee\u6807\u9009\u62e9\u89c6\u4e3a\u56fe\u641c\u7d22\u95ee\u9898\uff0c\u901a\u8fc7Temporal Distance Representation (TDR)\u7a7a\u95f4\u5d4c\u5165\u72b6\u6001\uff0c\u805a\u7c7b\u8bed\u4e49\u76f8\u4f3c\u72b6\u6001\u4e3a\u56fe\u8282\u70b9\uff0c\u5e76\u5e94\u7528\u6700\u77ed\u8def\u5f84\u7b97\u6cd5\u9009\u62e9\u5b50\u76ee\u6807\u5e8f\u5217\u3002\u540c\u65f6\u5f15\u5165Temporal Efficiency (TE)\u6307\u6807\u4f18\u5316\u56fe\u8d28\u91cf\u3002", "result": "GAS\u5728\u8fd0\u52a8\u3001\u5bfc\u822a\u548c\u64cd\u4f5c\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u7f1d\u5408\u5173\u952e\u4efb\u52a1\u4e2d\u5f97\u520688.3\uff0c\u8fdc\u8d85\u4e4b\u524d\u6700\u4f73\u5f97\u52061.0\u3002", "conclusion": "GAS\u901a\u8fc7\u56fe\u641c\u7d22\u548cTDR\u7a7a\u95f4\u5d4c\u5165\uff0c\u663e\u8457\u63d0\u5347\u4e86\u79bb\u7ebf\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u7684\u6548\u7387\u548c\u6027\u80fd\u3002"}}
{"id": "2506.07747", "pdf": "https://arxiv.org/pdf/2506.07747", "abs": "https://arxiv.org/abs/2506.07747", "authors": ["Adam Breuer"], "title": "E-LDA: Toward Interpretable LDA Topic Models with Strong Guarantees in Logarithmic Parallel Time", "categories": ["cs.LG", "cs.CL", "stat.ML"], "comment": "ICML 2025; Code available at: https://github.com/BreuerLabs/E- LDA", "summary": "In this paper, we provide the first practical algorithms with provable\nguarantees for the problem of inferring the topics assigned to each document in\nan LDA topic model. This is the primary inference problem for many applications\nof topic models in social science, data exploration, and causal inference\nsettings. We obtain this result by showing a novel non-gradient-based,\ncombinatorial approach to estimating topic models. This yields algorithms that\nconverge to near-optimal posterior probability in logarithmic parallel\ncomputation time (adaptivity) -- exponentially faster than any known LDA\nalgorithm. We also show that our approach can provide interpretability\nguarantees such that each learned topic is formally associated with a known\nkeyword. Finally, we show that unlike alternatives, our approach can maintain\nthe independence assumptions necessary to use the learned topic model for\ndownstream causal inference methods that allow researchers to study topics as\ntreatments. In terms of practical performance, our approach consistently\nreturns solutions of higher semantic quality than solutions from\nstate-of-the-art LDA algorithms, neural topic models, and LLM-based topic\nmodels across a diverse range of text datasets and evaluation parameters.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u975e\u68af\u5ea6\u7ec4\u5408\u65b9\u6cd5\uff0c\u7528\u4e8e\u63a8\u65adLDA\u4e3b\u9898\u6a21\u578b\u4e2d\u6bcf\u4e2a\u6587\u6863\u7684\u4e3b\u9898\u5206\u914d\uff0c\u5177\u6709\u5bf9\u6570\u5e76\u884c\u8ba1\u7b97\u65f6\u95f4\u7684\u9ad8\u6548\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u6027\u4fdd\u8bc1\u3002", "motivation": "\u89e3\u51b3LDA\u4e3b\u9898\u6a21\u578b\u5728\u793e\u4f1a\u79d1\u5b66\u3001\u6570\u636e\u63a2\u7d22\u548c\u56e0\u679c\u63a8\u65ad\u4e2d\u7684\u4e3b\u8981\u63a8\u65ad\u95ee\u9898\uff0c\u63d0\u4f9b\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u7b97\u6cd5\u3002", "method": "\u91c7\u7528\u975e\u68af\u5ea6\u7ec4\u5408\u65b9\u6cd5\u4f30\u8ba1\u4e3b\u9898\u6a21\u578b\uff0c\u5b9e\u73b0\u5bf9\u6570\u5e76\u884c\u8ba1\u7b97\u65f6\u95f4\u7684\u9ad8\u6548\u6536\u655b\u3002", "result": "\u7b97\u6cd5\u5728\u591a\u79cd\u6587\u672c\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709LDA\u3001\u795e\u7ecf\u4e3b\u9898\u6a21\u578b\u548c\u57fa\u4e8eLLM\u7684\u4e3b\u9898\u6a21\u578b\uff0c\u63d0\u4f9b\u66f4\u9ad8\u7684\u8bed\u4e49\u8d28\u91cf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\uff0c\u8fd8\u80fd\u4fdd\u6301\u72ec\u7acb\u6027\u5047\u8bbe\uff0c\u9002\u7528\u4e8e\u4e0b\u6e38\u56e0\u679c\u63a8\u65ad\u7814\u7a76\u3002"}}
{"id": "2506.07754", "pdf": "https://arxiv.org/pdf/2506.07754", "abs": "https://arxiv.org/abs/2506.07754", "authors": ["Nicola Lavecchia", "Sid Fadanelli", "Federico Ricciuti", "Gennaro Aloe", "Enrico Bagli", "Pietro Giuffrida", "Daniele Vergari"], "title": "Comparing Credit Risk Estimates in the Gen-AI Era", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Generative AI technologies have demonstrated significant potential across\ndiverse applications. This study provides a comparative analysis of credit\nscore modeling techniques, contrasting traditional approaches with those\nleveraging generative AI. Our findings reveal that current generative AI models\nfall short of matching the performance of traditional methods, regardless of\nthe integration strategy employed. These results highlight the limitations in\nthe current capabilities of generative AI for credit risk scoring, emphasizing\nthe need for further research and development before the possibility of\napplying generative AI for this specific task, or equivalent ones.", "AI": {"tldr": "\u751f\u6210\u5f0fAI\u5728\u4fe1\u7528\u8bc4\u5206\u5efa\u6a21\u4e2d\u8868\u73b0\u4e0d\u53ca\u4f20\u7edf\u65b9\u6cd5\uff0c\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u3002", "motivation": "\u63a2\u8ba8\u751f\u6210\u5f0fAI\u5728\u4fe1\u7528\u8bc4\u5206\u5efa\u6a21\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "method": "\u5bf9\u6bd4\u4f20\u7edf\u4fe1\u7528\u8bc4\u5206\u65b9\u6cd5\u4e0e\u751f\u6210\u5f0fAI\u6280\u672f\u3002", "result": "\u751f\u6210\u5f0fAI\u76ee\u524d\u8868\u73b0\u4e0d\u5982\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u5728\u4fe1\u7528\u8bc4\u5206\u9886\u57df\u4ecd\u9700\u6539\u8fdb\u4e0e\u53d1\u5c55\u3002"}}
{"id": "2506.07769", "pdf": "https://arxiv.org/pdf/2506.07769", "abs": "https://arxiv.org/abs/2506.07769", "authors": ["Dekai Zhang", "Matthew Williams", "Francesca Toni"], "title": "Clustered Federated Learning via Embedding Distributions", "categories": ["cs.LG"], "comment": "24 pages", "summary": "Federated learning (FL) is a widely used framework for machine learning in\ndistributed data environments where clients hold data that cannot be easily\ncentralised, such as for data protection reasons. FL, however, is known to be\nvulnerable to non-IID data. Clustered FL addresses this issue by finding more\nhomogeneous clusters of clients. We propose a novel one-shot clustering method,\nEMD-CFL, using the Earth Mover's distance (EMD) between data distributions in\nembedding space. We theoretically motivate the use of EMDs using results from\nthe domain adaptation literature and demonstrate empirically superior\nclustering performance in extensive comparisons against 16 baselines and on a\nrange of challenging datasets.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aEMD-CFL\u7684\u65b0\u578b\u4e00\u6b21\u6027\u805a\u7c7b\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u4e2d\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u7684\u6311\u6218\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u5728\u5206\u5e03\u5f0f\u6570\u636e\u73af\u5883\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u9762\u4e34\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u7684\u8106\u5f31\u6027\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u5d4c\u5165\u7a7a\u95f4\u4e2d\u6570\u636e\u5206\u5e03\u7684\u5730\u7403\u79fb\u52a8\u8ddd\u79bb\uff08EMD\uff09\u8fdb\u884c\u4e00\u6b21\u6027\u805a\u7c7b\u3002", "result": "\u572816\u4e2a\u57fa\u7ebf\u65b9\u6cd5\u548c\u591a\u4e2a\u6311\u6218\u6027\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cEMD-CFL\u5177\u6709\u4f18\u8d8a\u7684\u805a\u7c7b\u6027\u80fd\u3002", "conclusion": "EMD-CFL\u4e3a\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.07804", "pdf": "https://arxiv.org/pdf/2506.07804", "abs": "https://arxiv.org/abs/2506.07804", "authors": ["Jie Bao", "Chuangyin Dang", "Rui Luo", "Hanwei Zhang", "Zhixin Zhou"], "title": "Enhancing Adversarial Robustness with Conformal Prediction: A Framework for Guaranteed Model Reliability", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "As deep learning models are increasingly deployed in high-risk applications,\nrobust defenses against adversarial attacks and reliable performance guarantees\nbecome paramount. Moreover, accuracy alone does not provide sufficient\nassurance or reliable uncertainty estimates for these models. This study\nadvances adversarial training by leveraging principles from Conformal\nPrediction. Specifically, we develop an adversarial attack method, termed OPSA\n(OPtimal Size Attack), designed to reduce the efficiency of conformal\nprediction at any significance level by maximizing model uncertainty without\nrequiring coverage guarantees. Correspondingly, we introduce OPSA-AT\n(Adversarial Training), a defense strategy that integrates OPSA within a novel\nconformal training paradigm. Experimental evaluations demonstrate that our OPSA\nattack method induces greater uncertainty compared to baseline approaches for\nvarious defenses. Conversely, our OPSA-AT defensive model significantly\nenhances robustness not only against OPSA but also other adversarial attacks,\nand maintains reliable prediction. Our findings highlight the effectiveness of\nthis integrated approach for developing trustworthy and resilient deep learning\nmodels for safety-critical domains. Our code is available at\nhttps://github.com/bjbbbb/Enhancing-Adversarial-Robustness-with-Conformal-Prediction.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eConformal Prediction\u7684\u5bf9\u6297\u653b\u51fb\u65b9\u6cd5OPSA\u53ca\u5176\u9632\u5fa1\u7b56\u7565OPSA-AT\uff0c\u901a\u8fc7\u6700\u5927\u5316\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u63d0\u5347\u5bf9\u6297\u9c81\u68d2\u6027\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\u7684\u90e8\u7f72\u9700\u8981\u66f4\u5f3a\u7684\u5bf9\u6297\u9632\u5fa1\u548c\u6027\u80fd\u4fdd\u8bc1\uff0c\u4ec5\u9760\u51c6\u786e\u6027\u4e0d\u8db3\u4ee5\u63d0\u4f9b\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u3002", "method": "\u5f00\u53d1\u4e86OPSA\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u6700\u5927\u5316\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u524a\u5f31Conformal Prediction\u6548\u7387\uff1b\u63d0\u51faOPSA-AT\u9632\u5fa1\u7b56\u7565\uff0c\u5c06OPSA\u6574\u5408\u5230\u65b0\u578bConformal\u8bad\u7ec3\u6846\u67b6\u4e2d\u3002", "result": "\u5b9e\u9a8c\u8868\u660eOPSA\u653b\u51fb\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u66f4\u80fd\u8bf1\u5bfc\u4e0d\u786e\u5b9a\u6027\uff0c\u800cOPSA-AT\u9632\u5fa1\u6a21\u578b\u663e\u8457\u63d0\u5347\u4e86\u5bf9\u6297\u9c81\u68d2\u6027\u5e76\u4fdd\u6301\u53ef\u9760\u9884\u6d4b\u3002", "conclusion": "\u8be5\u96c6\u6210\u65b9\u6cd5\u4e3a\u5b89\u5168\u5173\u952e\u9886\u57df\u5f00\u53d1\u53ef\u4fe1\u8d56\u4e14\u9c81\u68d2\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2506.07806", "pdf": "https://arxiv.org/pdf/2506.07806", "abs": "https://arxiv.org/abs/2506.07806", "authors": ["Avinash Kori", "Francesca Toni", "Ben Glocker"], "title": "Identifiable Object Representations under Spatial Ambiguities", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Modular object-centric representations are essential for *human-like\nreasoning* but are challenging to obtain under spatial ambiguities, *e.g. due\nto occlusions and view ambiguities*. However, addressing challenges presents\nboth theoretical and practical difficulties. We introduce a novel multi-view\nprobabilistic approach that aggregates view-specific slots to capture\n*invariant content* information while simultaneously learning disentangled\nglobal *viewpoint-level* information. Unlike prior single-view methods, our\napproach resolves spatial ambiguities, provides theoretical guarantees for\nidentifiability, and requires *no viewpoint annotations*. Extensive experiments\non standard benchmarks and novel complex datasets validate our method's\nrobustness and scalability.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u591a\u89c6\u89d2\u6982\u7387\u65b9\u6cd5\uff0c\u89e3\u51b3\u7a7a\u95f4\u6a21\u7cca\u6027\u95ee\u9898\uff0c\u65e0\u9700\u89c6\u89d2\u6807\u6ce8\uff0c\u5b9e\u73b0\u6a21\u5757\u5316\u5bf9\u8c61\u4e2d\u5fc3\u8868\u793a\u3002", "motivation": "\u4eba\u7c7b\u63a8\u7406\u9700\u8981\u6a21\u5757\u5316\u5bf9\u8c61\u4e2d\u5fc3\u8868\u793a\uff0c\u4f46\u7a7a\u95f4\u6a21\u7cca\u6027\uff08\u5982\u906e\u6321\u548c\u89c6\u89d2\u6a21\u7cca\uff09\u4f7f\u5176\u96be\u4ee5\u5b9e\u73b0\u3002", "method": "\u91c7\u7528\u591a\u89c6\u89d2\u6982\u7387\u65b9\u6cd5\uff0c\u805a\u5408\u89c6\u89d2\u7279\u5b9a\u69fd\u4ee5\u6355\u6349\u4e0d\u53d8\u5185\u5bb9\u4fe1\u606f\uff0c\u540c\u65f6\u5b66\u4e60\u89e3\u8026\u7684\u5168\u5c40\u89c6\u89d2\u4fe1\u606f\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u89e3\u51b3\u4e86\u7a7a\u95f4\u6a21\u7cca\u6027\u5e76\u63d0\u4f9b\u53ef\u8bc6\u522b\u6027\u7406\u8bba\u4fdd\u8bc1\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u6807\u51c6\u57fa\u51c6\u548c\u65b0\u590d\u6742\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4e3a\u6a21\u5757\u5316\u8868\u793a\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.07822", "pdf": "https://arxiv.org/pdf/2506.07822", "abs": "https://arxiv.org/abs/2506.07822", "authors": ["Xintong Duan", "Yutong He", "Fahim Tajwar", "Ruslan Salakhutdinov", "J. Zico Kolter", "Jeff Schneider"], "title": "Accelerating Diffusion Models in Offline RL via Reward-Aware Consistency Trajectory Distillation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Although diffusion models have achieved strong results in decision-making\ntasks, their slow inference speed remains a key limitation. While the\nconsistency model offers a potential solution, its applications to\ndecision-making often struggle with suboptimal demonstrations or rely on\ncomplex concurrent training of multiple networks. In this work, we propose a\nnovel approach to consistency distillation for offline reinforcement learning\nthat directly incorporates reward optimization into the distillation process.\nOur method enables single-step generation while maintaining higher performance\nand simpler training. Empirical evaluations on the Gym MuJoCo benchmarks and\nlong horizon planning demonstrate that our approach can achieve an 8.7%\nimprovement over previous state-of-the-art while offering up to 142x speedup\nover diffusion counterparts in inference time.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e00\u81f4\u6027\u84b8\u998f\u65b9\u6cd5\uff0c\u7ed3\u5408\u5956\u52b1\u4f18\u5316\uff0c\u5b9e\u73b0\u5355\u6b65\u751f\u6210\uff0c\u6027\u80fd\u66f4\u9ad8\u4e14\u8bad\u7ec3\u66f4\u7b80\u5355\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u5728\u51b3\u7b56\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u63a8\u7406\u901f\u5ea6\u6162\uff1b\u4e00\u81f4\u6027\u6a21\u578b\u867d\u80fd\u89e3\u51b3\u901f\u5ea6\u95ee\u9898\uff0c\u4f46\u5728\u51b3\u7b56\u4efb\u52a1\u4e2d\u5e38\u56e0\u6b21\u4f18\u6f14\u793a\u6216\u591a\u7f51\u7edc\u5e76\u53d1\u8bad\u7ec3\u800c\u53d7\u9650\u3002", "method": "\u5c06\u5956\u52b1\u4f18\u5316\u76f4\u63a5\u878d\u5165\u4e00\u81f4\u6027\u84b8\u998f\u8fc7\u7a0b\uff0c\u5b9e\u73b0\u5355\u6b65\u751f\u6210\uff0c\u7b80\u5316\u8bad\u7ec3\u3002", "result": "\u5728Gym MuJoCo\u57fa\u51c6\u6d4b\u8bd5\u548c\u957f\u65f6\u7a0b\u89c4\u5212\u4e2d\uff0c\u6027\u80fd\u63d0\u53478.7%\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u5347142\u500d\u3002", "conclusion": "\u65b0\u65b9\u6cd5\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u901f\u5ea6\uff0c\u4e3a\u51b3\u7b56\u4efb\u52a1\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.07829", "pdf": "https://arxiv.org/pdf/2506.07829", "abs": "https://arxiv.org/abs/2506.07829", "authors": ["Jan Corazza", "Hadi Partovi Aria", "Hyohun Kim", "Daniel Neider", "Zhe Xu"], "title": "Decentralizing Multi-Agent Reinforcement Learning with Temporal Causal Information", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning (RL) algorithms can find an optimal policy for a\nsingle agent to accomplish a particular task. However, many real-world problems\nrequire multiple agents to collaborate in order to achieve a common goal. For\nexample, a robot executing a task in a warehouse may require the assistance of\na drone to retrieve items from high shelves. In Decentralized Multi-Agent RL\n(DMARL), agents learn independently and then combine their policies at\nexecution time, but often must satisfy constraints on compatibility of local\npolicies to ensure that they can achieve the global task when combined. In this\npaper, we study how providing high-level symbolic knowledge to agents can help\naddress unique challenges of this setting, such as privacy constraints,\ncommunication limitations, and performance concerns. In particular, we extend\nthe formal tools used to check the compatibility of local policies with the\nteam task, making decentralized training with theoretical guarantees usable in\nmore scenarios. Furthermore, we empirically demonstrate that symbolic knowledge\nabout the temporal evolution of events in the environment can significantly\nexpedite the learning process in DMARL.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u5206\u6563\u5f0f\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08DMARL\uff09\u4e2d\uff0c\u901a\u8fc7\u63d0\u4f9b\u9ad8\u5c42\u7b26\u53f7\u77e5\u8bc6\u6765\u89e3\u51b3\u9690\u79c1\u3001\u901a\u4fe1\u9650\u5236\u548c\u6027\u80fd\u95ee\u9898\uff0c\u5e76\u6269\u5c55\u4e86\u7406\u8bba\u5de5\u5177\u4ee5\u9a8c\u8bc1\u5c40\u90e8\u7b56\u7565\u4e0e\u56e2\u961f\u4efb\u52a1\u7684\u517c\u5bb9\u6027\u3002", "motivation": "\u73b0\u5b9e\u95ee\u9898\u5e38\u9700\u591a\u667a\u80fd\u4f53\u534f\u4f5c\uff0c\u4f46DMARL\u4e2d\u667a\u80fd\u4f53\u72ec\u7acb\u5b66\u4e60\u53ef\u80fd\u5bfc\u81f4\u7b56\u7565\u517c\u5bb9\u6027\u95ee\u9898\uff0c\u9700\u89e3\u51b3\u9690\u79c1\u3001\u901a\u4fe1\u548c\u6027\u80fd\u6311\u6218\u3002", "method": "\u5f15\u5165\u9ad8\u5c42\u7b26\u53f7\u77e5\u8bc6\uff0c\u6269\u5c55\u7406\u8bba\u5de5\u5177\u9a8c\u8bc1\u5c40\u90e8\u7b56\u7565\u4e0e\u56e2\u961f\u4efb\u52a1\u7684\u517c\u5bb9\u6027\uff0c\u5e76\u5229\u7528\u7b26\u53f7\u77e5\u8bc6\u52a0\u901f\u5b66\u4e60\u8fc7\u7a0b\u3002", "result": "\u7b26\u53f7\u77e5\u8bc6\u663e\u8457\u52a0\u901f\u4e86DMARL\u7684\u5b66\u4e60\u8fc7\u7a0b\uff0c\u6269\u5c55\u7684\u7406\u8bba\u5de5\u5177\u4f7f\u5206\u6563\u5f0f\u8bad\u7ec3\u5728\u66f4\u591a\u573a\u666f\u4e2d\u5177\u5907\u7406\u8bba\u4fdd\u969c\u3002", "conclusion": "\u9ad8\u5c42\u7b26\u53f7\u77e5\u8bc6\u80fd\u6709\u6548\u89e3\u51b3DMARL\u4e2d\u7684\u517c\u5bb9\u6027\u548c\u5b66\u4e60\u6548\u7387\u95ee\u9898\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.07833", "pdf": "https://arxiv.org/pdf/2506.07833", "abs": "https://arxiv.org/abs/2506.07833", "authors": ["Michael K. Chen", "Xikun Zhang", "Jiaxing Huang", "Dacheng Tao"], "title": "Improving large language models with concept-aware fine-tuning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) have become the cornerstone of modern AI.\nHowever, the existing paradigm of next-token prediction fundamentally limits\ntheir ability to form coherent, high-level concepts, making it a critical\nbarrier to human-like understanding and reasoning. Take the phrase \"ribonucleic\nacid\" as an example: an LLM will first decompose it into tokens, i.e.,\nartificial text fragments (\"rib\", \"on\", ...), then learn each token\nsequentially, rather than grasping the phrase as a unified, coherent semantic\nentity. This fragmented representation hinders deeper conceptual understanding\nand, ultimately, the development of truly intelligent systems. In response, we\nintroduce Concept-Aware Fine-Tuning (CAFT), a novel multi-token training method\nthat redefines how LLMs are fine-tuned. By enabling the learning of sequences\nthat span multiple tokens, this method fosters stronger concept-aware learning.\nOur experiments demonstrate significant improvements compared to conventional\nnext-token finetuning methods across diverse tasks, including traditional\napplications like text summarization and domain-specific ones like de novo\nprotein design. Multi-token prediction was previously only possible in the\nprohibitively expensive pretraining phase; CAFT, to our knowledge, is the first\nto bring the multi-token setting to the post-training phase, thus effectively\ndemocratizing its benefits for the broader community of practitioners and\nresearchers. Finally, the unexpected effectiveness of our proposed method\nsuggests wider implications for the machine learning research community. All\ncode and data are available at https://github.com/michaelchen-lab/caft-llm", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCAFT\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u4ee4\u724c\u8bad\u7ec3\u6539\u8fdbLLMs\u7684\u6982\u5ff5\u5b66\u4e60\u80fd\u529b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4efb\u52a1\u8868\u73b0\u3002", "motivation": "\u73b0\u6709LLMs\u7684\u9010\u4ee4\u724c\u9884\u6d4b\u8303\u5f0f\u9650\u5236\u4e86\u5176\u5bf9\u9ad8\u5c42\u6b21\u6982\u5ff5\u7684\u7406\u89e3\u80fd\u529b\uff0c\u963b\u788d\u4e86\u667a\u80fd\u7cfb\u7edf\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002", "method": "\u5f15\u5165Concept-Aware Fine-Tuning (CAFT)\uff0c\u4e00\u79cd\u591a\u4ee4\u724c\u8bad\u7ec3\u65b9\u6cd5\uff0c\u652f\u6301\u8de8\u4ee4\u724c\u5e8f\u5217\u5b66\u4e60\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cCAFT\u5728\u6587\u672c\u6458\u8981\u548c\u86cb\u767d\u8d28\u8bbe\u8ba1\u7b49\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "CAFT\u9996\u6b21\u5c06\u591a\u4ee4\u724c\u9884\u6d4b\u5f15\u5165\u540e\u8bad\u7ec3\u9636\u6bb5\uff0c\u4e3a\u7814\u7a76\u793e\u533a\u63d0\u4f9b\u4e86\u66f4\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.07843", "pdf": "https://arxiv.org/pdf/2506.07843", "abs": "https://arxiv.org/abs/2506.07843", "authors": ["Davide Carbone"], "title": "Jarzynski Reweighting and Sampling Dynamics for Training Energy-Based Models: Theoretical Analysis of Different Transition Kernels", "categories": ["cs.LG", "physics.comp-ph"], "comment": null, "summary": "Energy-Based Models (EBMs) provide a flexible framework for generative\nmodeling, but their training remains theoretically challenging due to the need\nto approximate normalization constants and efficiently sample from complex,\nmulti-modal distributions. Traditional methods, such as contrastive divergence\nand score matching, introduce biases that can hinder accurate learning. In this\nwork, we present a theoretical analysis of Jarzynski reweighting, a technique\nfrom non-equilibrium statistical mechanics, and its implications for training\nEBMs. We focus on the role of the choice of the kernel and we illustrate these\ntheoretical considerations in two key generative frameworks: (i) flow-based\ndiffusion models, where we reinterpret Jarzynski reweighting in the context of\nstochastic interpolants to mitigate discretization errors and improve sample\nquality, and (ii) Restricted Boltzmann Machines, where we analyze its role in\ncorrecting the biases of contrastive divergence. Our results provide insights\ninto the interplay between kernel choice and model performance, highlighting\nthe potential of Jarzynski reweighting as a principled tool for generative\nlearning.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86Jarzynski\u91cd\u52a0\u6743\u6280\u672f\u5728\u8bad\u7ec3\u57fa\u4e8e\u80fd\u91cf\u7684\u6a21\u578b\uff08EBMs\uff09\u4e2d\u7684\u5e94\u7528\uff0c\u63a2\u8ba8\u4e86\u6838\u9009\u62e9\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u6d41\u6269\u6563\u6a21\u578b\u548c\u53d7\u9650\u73bb\u5c14\u5179\u66fc\u673a\u4e2d\u7684\u6548\u679c\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\uff08\u5982\u5bf9\u6bd4\u6563\u5ea6\u548c\u5206\u6570\u5339\u914d\uff09\u5728\u8bad\u7ec3EBMs\u65f6\u5b58\u5728\u504f\u5dee\uff0c\u5f71\u54cd\u5b66\u4e60\u51c6\u786e\u6027\u3002\u7814\u7a76\u65e8\u5728\u901a\u8fc7Jarzynski\u91cd\u52a0\u6743\u6280\u672f\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u7406\u8bba\u5206\u6790\u4e86Jarzynski\u91cd\u52a0\u6743\u6280\u672f\uff0c\u5e76\u5e94\u7528\u4e8e\u4e24\u79cd\u751f\u6210\u6846\u67b6\uff1a\u6d41\u6269\u6563\u6a21\u578b\u548c\u53d7\u9650\u73bb\u5c14\u5179\u66fc\u673a\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86\u6838\u9009\u62e9\u4e0e\u6a21\u578b\u6027\u80fd\u7684\u5173\u7cfb\uff0cJarzynski\u91cd\u52a0\u6743\u80fd\u51cf\u5c11\u504f\u5dee\u5e76\u63d0\u5347\u6837\u672c\u8d28\u91cf\u3002", "conclusion": "Jarzynski\u91cd\u52a0\u6743\u662f\u4e00\u79cd\u6709\u6f5c\u529b\u7684\u751f\u6210\u5b66\u4e60\u5de5\u5177\uff0c\u53ef\u4f18\u5316EBMs\u7684\u8bad\u7ec3\u6548\u679c\u3002"}}
{"id": "2506.07854", "pdf": "https://arxiv.org/pdf/2506.07854", "abs": "https://arxiv.org/abs/2506.07854", "authors": ["Zheng Zhang", "Jie Bao", "Zhixin Zhou", "Nicolo Colombo", "Lixin Cheng", "Rui Luo"], "title": "Residual Reweighted Conformal Prediction for Graph Neural Networks", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Graph Neural Networks (GNNs) excel at modeling relational data but face\nsignificant challenges in high-stakes domains due to unquantified uncertainty.\nConformal prediction (CP) offers statistical coverage guarantees, but existing\nmethods often produce overly conservative prediction intervals that fail to\naccount for graph heteroscedasticity and structural biases. While residual\nreweighting CP variants address some of these limitations, they neglect graph\ntopology, cluster-specific uncertainties, and risk data leakage by reusing\ntraining sets. To address these issues, we propose Residual Reweighted GNN\n(RR-GNN), a framework designed to generate minimal prediction sets with\nprovable marginal coverage guarantees.\n  RR-GNN introduces three major innovations to enhance prediction performance.\nFirst, it employs Graph-Structured Mondrian CP to partition nodes or edges into\ncommunities based on topological features, ensuring cluster-conditional\ncoverage that reflects heterogeneity. Second, it uses Residual-Adaptive\nNonconformity Scores by training a secondary GNN on a held-out calibration set\nto estimate task-specific residuals, dynamically adjusting prediction intervals\naccording to node or edge uncertainty. Third, it adopts a Cross-Training\nProtocol, which alternates the optimization of the primary GNN and the residual\npredictor to prevent information leakage while maintaining graph dependencies.\nWe validate RR-GNN on 15 real-world graphs across diverse tasks, including node\nclassification, regression, and edge weight prediction. Compared to CP\nbaselines, RR-GNN achieves improved efficiency over state-of-the-art methods,\nwith no loss of coverage.", "AI": {"tldr": "RR-GNN\u901a\u8fc7\u7ed3\u5408\u56fe\u7ed3\u6784\u548c\u6b8b\u5dee\u81ea\u9002\u5e94\u65b9\u6cd5\uff0c\u6539\u8fdb\u4e86\u4f20\u7edf\u5171\u5f62\u9884\u6d4b\u7684\u4fdd\u5b88\u6027\uff0c\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u9884\u6d4b\u533a\u95f4\u3002", "motivation": "\u4f20\u7edf\u5171\u5f62\u9884\u6d4b\u5728\u56fe\u6570\u636e\u4e2d\u56e0\u5ffd\u7565\u56fe\u7ed3\u6784\u548c\u5f02\u8d28\u6027\u5bfc\u81f4\u9884\u6d4b\u533a\u95f4\u8fc7\u4e8e\u4fdd\u5b88\uff0cRR-GNN\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "RR-GNN\u91c7\u7528\u56fe\u7ed3\u6784Mondrian\u5171\u5f62\u9884\u6d4b\u3001\u6b8b\u5dee\u81ea\u9002\u5e94\u975e\u5171\u5f62\u5206\u6570\u548c\u4ea4\u53c9\u8bad\u7ec3\u534f\u8bae\uff0c\u4f18\u5316\u9884\u6d4b\u533a\u95f4\u3002", "result": "\u572815\u4e2a\u771f\u5b9e\u56fe\u6570\u636e\u4efb\u52a1\u4e2d\uff0cRR-GNN\u5728\u4fdd\u6301\u8986\u76d6\u7387\u7684\u6761\u4ef6\u4e0b\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "RR-GNN\u4e3a\u56fe\u6570\u636e\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u53ef\u9760\u7684\u9884\u6d4b\u533a\u95f4\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2506.07861", "pdf": "https://arxiv.org/pdf/2506.07861", "abs": "https://arxiv.org/abs/2506.07861", "authors": ["Firas Laakom", "Haobo Chen", "J\u00fcrgen Schmidhuber", "Yuheng Bu"], "title": "Fairness Overfitting in Machine Learning: An Information-Theoretic Perspective", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT"], "comment": "38 pages", "summary": "Despite substantial progress in promoting fairness in high-stake applications\nusing machine learning models, existing methods often modify the training\nprocess, such as through regularizers or other interventions, but lack formal\nguarantees that fairness achieved during training will generalize to unseen\ndata. Although overfitting with respect to prediction performance has been\nextensively studied, overfitting in terms of fairness loss has received far\nless attention. This paper proposes a theoretical framework for analyzing\nfairness generalization error through an information-theoretic lens. Our novel\nbounding technique is based on Efron-Stein inequality, which allows us to\nderive tight information-theoretic fairness generalization bounds with both\nMutual Information (MI) and Conditional Mutual Information (CMI). Our empirical\nresults validate the tightness and practical relevance of these bounds across\ndiverse fairness-aware learning algorithms. Our framework offers valuable\ninsights to guide the design of algorithms improving fairness generalization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\uff0c\u901a\u8fc7\u4fe1\u606f\u8bba\u89c6\u89d2\u5206\u6790\u516c\u5e73\u6027\u6cdb\u5316\u8bef\u5dee\uff0c\u5e76\u57fa\u4e8eEfron-Stein\u4e0d\u7b49\u5f0f\u63a8\u5bfc\u51fa\u7d27\u81f4\u7684\u516c\u5e73\u6027\u6cdb\u5316\u754c\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u516c\u5e73\u6027\u5728\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6570\u636e\u95f4\u6cdb\u5316\u7684\u7406\u8bba\u4fdd\u8bc1\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u4f7f\u7528\u4fe1\u606f\u8bba\u5de5\u5177\uff08\u5982\u4e92\u4fe1\u606f\u548c\u6761\u4ef6\u4e92\u4fe1\u606f\uff09\u7ed3\u5408Efron-Stein\u4e0d\u7b49\u5f0f\uff0c\u63d0\u51fa\u65b0\u7684\u516c\u5e73\u6027\u6cdb\u5316\u754c\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6240\u63d0\u754c\u9650\u7684\u7d27\u81f4\u6027\u548c\u5b9e\u9645\u76f8\u5173\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u8bbe\u8ba1\u63d0\u5347\u516c\u5e73\u6027\u6cdb\u5316\u7684\u7b97\u6cd5\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\u3002"}}
{"id": "2506.07864", "pdf": "https://arxiv.org/pdf/2506.07864", "abs": "https://arxiv.org/abs/2506.07864", "authors": ["Mirko Paolo Barbato", "Giorgia Rigamonti", "Davide Marelli", "Paolo Napoletano"], "title": "Lightweight Sequential Transformers for Blood Glucose Level Prediction in Type-1 Diabetes", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Type 1 Diabetes (T1D) affects millions worldwide, requiring continuous\nmonitoring to prevent severe hypo- and hyperglycemic events. While continuous\nglucose monitoring has improved blood glucose management, deploying predictive\nmodels on wearable devices remains challenging due to computational and memory\nconstraints. To address this, we propose a novel Lightweight Sequential\nTransformer model designed for blood glucose prediction in T1D. By integrating\nthe strengths of Transformers' attention mechanisms and the sequential\nprocessing of recurrent neural networks, our architecture captures long-term\ndependencies while maintaining computational efficiency. The model is optimized\nfor deployment on resource-constrained edge devices and incorporates a balanced\nloss function to handle the inherent data imbalance in hypo- and hyperglycemic\nevents. Experiments on two benchmark datasets, OhioT1DM and DiaTrend,\ndemonstrate that the proposed model outperforms state-of-the-art methods in\npredicting glucose levels and detecting adverse events. This work fills the gap\nbetween high-performance modeling and practical deployment, providing a\nreliable and efficient T1D management solution.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u5e8f\u5217Transformer\u6a21\u578b\uff0c\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u7684\u8840\u7cd6\u9884\u6d4b\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3T1D\u7ba1\u7406\u4e2d\u8840\u7cd6\u9884\u6d4b\u6a21\u578b\u5728\u53ef\u7a7f\u6234\u8bbe\u5907\u4e0a\u90e8\u7f72\u7684\u8ba1\u7b97\u548c\u5185\u5b58\u9650\u5236\u95ee\u9898\u3002", "method": "\u7ed3\u5408Transformer\u7684\u6ce8\u610f\u529b\u673a\u5236\u548cRNN\u7684\u5e8f\u5217\u5904\u7406\u80fd\u529b\uff0c\u8bbe\u8ba1\u8f7b\u91cf\u7ea7\u6a21\u578b\uff0c\u4f18\u5316\u90e8\u7f72\u5e76\u5904\u7406\u6570\u636e\u4e0d\u5e73\u8861\u3002", "result": "\u5728OhioT1DM\u548cDiaTrend\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u80fd\u6709\u6548\u9884\u6d4b\u8840\u7cd6\u6c34\u5e73\u548c\u68c0\u6d4b\u4e0d\u826f\u4e8b\u4ef6\u3002", "conclusion": "\u8be5\u6a21\u578b\u586b\u8865\u4e86\u9ad8\u6027\u80fd\u5efa\u6a21\u4e0e\u5b9e\u9645\u90e8\u7f72\u4e4b\u95f4\u7684\u7a7a\u767d\uff0c\u4e3aT1D\u7ba1\u7406\u63d0\u4f9b\u4e86\u9ad8\u6548\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.07871", "pdf": "https://arxiv.org/pdf/2506.07871", "abs": "https://arxiv.org/abs/2506.07871", "authors": ["Sigma Jahan", "Mohammad Masudur Rahman"], "title": "Can Hessian-Based Insights Support Fault Diagnosis in Attention-based Models?", "categories": ["cs.LG", "cs.SE"], "comment": null, "summary": "As attention-based deep learning models scale in size and complexity,\ndiagnosing their faults becomes increasingly challenging. In this work, we\nconduct an empirical study to evaluate the potential of Hessian-based analysis\nfor diagnosing faults in attention-based models. Specifically, we use\nHessian-derived insights to identify fragile regions (via curvature analysis)\nand parameter interdependencies (via parameter interaction analysis) within\nattention mechanisms. Through experiments on three diverse models (HAN, 3D-CNN,\nDistilBERT), we show that Hessian-based metrics can localize instability and\npinpoint fault sources more effectively than gradients alone. Our empirical\nfindings suggest that these metrics could significantly improve fault diagnosis\nin complex neural architectures, potentially improving software debugging\npractices.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7Hessian\u77e9\u9635\u5206\u6790\u8bca\u65ad\u6ce8\u610f\u529b\u6a21\u578b\u7684\u6545\u969c\uff0c\u53d1\u73b0\u5176\u6bd4\u68af\u5ea6\u5206\u6790\u66f4\u6709\u6548\u3002", "motivation": "\u968f\u7740\u6ce8\u610f\u529b\u6a21\u578b\u89c4\u6a21\u548c\u590d\u6742\u5ea6\u7684\u589e\u52a0\uff0c\u8bca\u65ad\u5176\u6545\u969c\u53d8\u5f97\u66f4\u5177\u6311\u6218\u6027\uff0c\u56e0\u6b64\u63a2\u7d22Hessian\u77e9\u9635\u5206\u6790\u7684\u6f5c\u529b\u3002", "method": "\u4f7f\u7528Hessian\u77e9\u9635\u7684\u66f2\u7387\u5206\u6790\u548c\u53c2\u6570\u4ea4\u4e92\u5206\u6790\uff0c\u8bc6\u522b\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u7684\u8106\u5f31\u533a\u57df\u548c\u53c2\u6570\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cHessian\u6307\u6807\u80fd\u66f4\u6709\u6548\u5730\u5b9a\u4f4d\u4e0d\u7a33\u5b9a\u6027\u548c\u6545\u969c\u6e90\uff0c\u4f18\u4e8e\u68af\u5ea6\u5206\u6790\u3002", "conclusion": "Hessian\u5206\u6790\u53ef\u663e\u8457\u6539\u8fdb\u590d\u6742\u795e\u7ecf\u67b6\u6784\u7684\u6545\u969c\u8bca\u65ad\uff0c\u63d0\u5347\u8f6f\u4ef6\u8c03\u8bd5\u5b9e\u8df5\u3002"}}
{"id": "2506.07883", "pdf": "https://arxiv.org/pdf/2506.07883", "abs": "https://arxiv.org/abs/2506.07883", "authors": ["Rajat Rasal", "Avinash Kori", "Fabio De Sousa Ribeiro", "Tian Xia", "Ben Glocker"], "title": "Diffusion Counterfactual Generation with Semantic Abduction", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "comment": "Proceedings of the 42nd International Conference on Machine Learning,\n  Vancouver, Canada", "summary": "Counterfactual image generation presents significant challenges, including\npreserving identity, maintaining perceptual quality, and ensuring faithfulness\nto an underlying causal model. While existing auto-encoding frameworks admit\nsemantic latent spaces which can be manipulated for causal control, they\nstruggle with scalability and fidelity. Advancements in diffusion models\npresent opportunities for improving counterfactual image editing, having\ndemonstrated state-of-the-art visual quality, human-aligned perception and\nrepresentation learning capabilities. Here, we present a suite of\ndiffusion-based causal mechanisms, introducing the notions of spatial, semantic\nand dynamic abduction. We propose a general framework that integrates semantic\nrepresentations into diffusion models through the lens of Pearlian causality to\nedit images via a counterfactual reasoning process. To our knowledge, this is\nthe first work to consider high-level semantic identity preservation for\ndiffusion counterfactuals and to demonstrate how semantic control enables\nprincipled trade-offs between faithful causal control and identity\npreservation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u53cd\u4e8b\u5b9e\u56fe\u50cf\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u7a7a\u95f4\u3001\u8bed\u4e49\u548c\u52a8\u6001\u53cd\u6f14\u6982\u5ff5\uff0c\u7ed3\u5408Pearl\u56e0\u679c\u5173\u7cfb\uff0c\u5b9e\u73b0\u4e86\u9ad8\u4fdd\u771f\u5ea6\u7684\u56fe\u50cf\u7f16\u8f91\uff0c\u5e76\u5728\u8bed\u4e49\u63a7\u5236\u548c\u8eab\u4efd\u4fdd\u7559\u4e4b\u95f4\u53d6\u5f97\u4e86\u5e73\u8861\u3002", "motivation": "\u73b0\u6709\u81ea\u7f16\u7801\u6846\u67b6\u5728\u53cd\u4e8b\u5b9e\u56fe\u50cf\u751f\u6210\u4e2d\u5b58\u5728\u53ef\u6269\u5c55\u6027\u548c\u4fdd\u771f\u5ea6\u95ee\u9898\uff0c\u800c\u6269\u6563\u6a21\u578b\u5728\u89c6\u89c9\u8d28\u91cf\u548c\u8bed\u4e49\u5b66\u4e60\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u56e0\u6b64\u63a2\u7d22\u5982\u4f55\u5229\u7528\u6269\u6563\u6a21\u578b\u6539\u8fdb\u53cd\u4e8b\u5b9e\u56fe\u50cf\u7f16\u8f91\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u5957\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u56e0\u679c\u673a\u5236\uff0c\u5305\u62ec\u7a7a\u95f4\u3001\u8bed\u4e49\u548c\u52a8\u6001\u53cd\u6f14\uff0c\u5e76\u5c06\u8bed\u4e49\u8868\u793a\u901a\u8fc7Pearl\u56e0\u679c\u5173\u7cfb\u6574\u5408\u5230\u6269\u6563\u6a21\u578b\u4e2d\uff0c\u5b9e\u73b0\u53cd\u4e8b\u5b9e\u63a8\u7406\u7684\u56fe\u50cf\u7f16\u8f91\u3002", "result": "\u8be5\u6846\u67b6\u9996\u6b21\u5728\u6269\u6563\u53cd\u4e8b\u5b9e\u4e2d\u8003\u8651\u4e86\u9ad8\u7ea7\u8bed\u4e49\u8eab\u4efd\u4fdd\u7559\uff0c\u5e76\u5c55\u793a\u4e86\u8bed\u4e49\u63a7\u5236\u5982\u4f55\u5728\u5fe0\u5b9e\u56e0\u679c\u63a7\u5236\u548c\u8eab\u4efd\u4fdd\u7559\u4e4b\u95f4\u5b9e\u73b0\u539f\u5219\u6027\u6743\u8861\u3002", "conclusion": "\u6269\u6563\u6a21\u578b\u7ed3\u5408\u56e0\u679c\u63a8\u7406\u4e3a\u53cd\u4e8b\u5b9e\u56fe\u50cf\u751f\u6210\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7f16\u8f91\u8d28\u91cf\u548c\u8bed\u4e49\u63a7\u5236\u80fd\u529b\u3002"}}
{"id": "2506.07884", "pdf": "https://arxiv.org/pdf/2506.07884", "abs": "https://arxiv.org/abs/2506.07884", "authors": ["Anand Ganesh", "Babhrubahan Bose", "Anand Rajagopalan"], "title": "Schauder Bases for $C[0, 1]$ Using ReLU, Softplus and Two Sigmoidal Functions", "categories": ["cs.LG", "math.FA", "46B15", "I.2.6"], "comment": "9 pages", "summary": "We construct four Schauder bases for the space $C[0,1]$, one using ReLU\nfunctions, another using Softplus functions, and two more using sigmoidal\nversions of the ReLU and Softplus functions. This establishes the existence of\na basis using these functions for the first time, and improves on the universal\napproximation property associated with them.", "AI": {"tldr": "\u8bba\u6587\u6784\u5efa\u4e86\u56db\u79cdSchauder\u57fa\uff0c\u7528\u4e8e\u7a7a\u95f4$C[0,1]$\uff0c\u5206\u522b\u57fa\u4e8eReLU\u3001Softplus\u53ca\u5176sigmoidal\u53d8\u4f53\uff0c\u9996\u6b21\u8bc1\u660e\u4e86\u8fd9\u4e9b\u51fd\u6570\u57fa\u7684\u5b58\u5728\u6027\uff0c\u5e76\u6539\u8fdb\u4e86\u5176\u901a\u7528\u903c\u8fd1\u6027\u8d28\u3002", "motivation": "\u63a2\u7d22ReLU\u3001Softplus\u53ca\u5176sigmoidal\u53d8\u4f53\u5728\u51fd\u6570\u7a7a\u95f4$C[0,1]$\u4e2d\u4f5c\u4e3aSchauder\u57fa\u7684\u53ef\u884c\u6027\uff0c\u586b\u8865\u76f8\u5173\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u6784\u9020\u56db\u79cdSchauder\u57fa\uff0c\u5206\u522b\u57fa\u4e8eReLU\u3001Softplus\u53ca\u5176sigmoidal\u7248\u672c\uff0c\u5206\u6790\u5176\u6027\u8d28\u3002", "result": "\u9996\u6b21\u8bc1\u660e\u4e86\u8fd9\u4e9b\u51fd\u6570\u57fa\u7684\u5b58\u5728\u6027\uff0c\u5e76\u63d0\u5347\u4e86\u5176\u901a\u7528\u903c\u8fd1\u80fd\u529b\u3002", "conclusion": "\u7814\u7a76\u4e3a\u51fd\u6570\u7a7a\u95f4\u63d0\u4f9b\u4e86\u65b0\u7684\u57fa\u51fd\u6570\u9009\u62e9\uff0c\u6269\u5c55\u4e86\u76f8\u5173\u7406\u8bba\u7684\u5e94\u7528\u8303\u56f4\u3002"}}
{"id": "2506.07902", "pdf": "https://arxiv.org/pdf/2506.07902", "abs": "https://arxiv.org/abs/2506.07902", "authors": ["Sifan Wang", "Zehao Dou", "Tong-Rui Liu", "Lu Lu"], "title": "FunDiff: Diffusion Models over Function Spaces for Physics-Informed Generative Modeling", "categories": ["cs.LG", "physics.comp-ph", "stat.ML"], "comment": "31 pages, 12 figures", "summary": "Recent advances in generative modeling -- particularly diffusion models and\nflow matching -- have achieved remarkable success in synthesizing discrete data\nsuch as images and videos. However, adapting these models to physical\napplications remains challenging, as the quantities of interest are continuous\nfunctions governed by complex physical laws. Here, we introduce\n$\\textbf{FunDiff}$, a novel framework for generative modeling in function\nspaces. FunDiff combines a latent diffusion process with a function autoencoder\narchitecture to handle input functions with varying discretizations, generate\ncontinuous functions evaluable at arbitrary locations, and seamlessly\nincorporate physical priors. These priors are enforced through architectural\nconstraints or physics-informed loss functions, ensuring that generated samples\nsatisfy fundamental physical laws. We theoretically establish minimax\noptimality guarantees for density estimation in function spaces, showing that\ndiffusion-based estimators achieve optimal convergence rates under suitable\nregularity conditions. We demonstrate the practical effectiveness of FunDiff\nacross diverse applications in fluid dynamics and solid mechanics. Empirical\nresults show that our method generates physically consistent samples with high\nfidelity to the target distribution and exhibits robustness to noisy and\nlow-resolution data. Code and datasets are publicly available at\nhttps://github.com/sifanexisted/fundiff.", "AI": {"tldr": "FunDiff\u662f\u4e00\u4e2a\u7528\u4e8e\u51fd\u6570\u7a7a\u95f4\u7684\u751f\u6210\u5efa\u6a21\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u6f5c\u5728\u6269\u6563\u8fc7\u7a0b\u548c\u51fd\u6570\u81ea\u7f16\u7801\u5668\u67b6\u6784\uff0c\u80fd\u591f\u5904\u7406\u4e0d\u540c\u79bb\u6563\u5316\u7684\u8f93\u5165\u51fd\u6570\uff0c\u751f\u6210\u53ef\u4efb\u610f\u4f4d\u7f6e\u8bc4\u4f30\u7684\u8fde\u7eed\u51fd\u6570\uff0c\u5e76\u878d\u5165\u7269\u7406\u5148\u9a8c\u3002", "motivation": "\u5c3d\u7ba1\u751f\u6210\u6a21\u578b\u5728\u79bb\u6563\u6570\u636e\uff08\u5982\u56fe\u50cf\u548c\u89c6\u9891\uff09\u5408\u6210\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u6210\u529f\uff0c\u4f46\u5728\u7269\u7406\u5e94\u7528\u4e2d\u9002\u5e94\u8fd9\u4e9b\u6a21\u578b\u4ecd\u5177\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u5173\u6ce8\u7684\u91cf\u662f\u53d7\u590d\u6742\u7269\u7406\u5b9a\u5f8b\u652f\u914d\u7684\u8fde\u7eed\u51fd\u6570\u3002", "method": "FunDiff\u7ed3\u5408\u6f5c\u5728\u6269\u6563\u8fc7\u7a0b\u548c\u51fd\u6570\u81ea\u7f16\u7801\u5668\u67b6\u6784\uff0c\u901a\u8fc7\u67b6\u6784\u7ea6\u675f\u6216\u7269\u7406\u4fe1\u606f\u635f\u5931\u51fd\u6570\u878d\u5165\u7269\u7406\u5148\u9a8c\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u6269\u6563\u57fa\u4f30\u8ba1\u5668\u5728\u51fd\u6570\u7a7a\u95f4\u4e2d\u5b9e\u73b0\u4e86\u6700\u4f18\u6536\u655b\u7387\uff0c\u5b9e\u9a8c\u8868\u660eFunDiff\u5728\u6d41\u4f53\u52a8\u529b\u5b66\u548c\u56fa\u4f53\u529b\u5b66\u4e2d\u751f\u6210\u7269\u7406\u4e00\u81f4\u7684\u6837\u672c\uff0c\u4e14\u5bf9\u566a\u58f0\u548c\u4f4e\u5206\u8fa8\u7387\u6570\u636e\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "FunDiff\u4e3a\u51fd\u6570\u7a7a\u95f4\u4e2d\u7684\u751f\u6210\u5efa\u6a21\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u4e14\u7269\u7406\u4e00\u81f4\u7684\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u7269\u7406\u5e94\u7528\u3002"}}
{"id": "2506.07903", "pdf": "https://arxiv.org/pdf/2506.07903", "abs": "https://arxiv.org/abs/2506.07903", "authors": ["Kevin Rojas", "Yuchen Zhu", "Sichen Zhu", "Felix X. -F. Ye", "Molei Tao"], "title": "Diffuse Everything: Multimodal Diffusion Models on Arbitrary State Spaces", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "Accepted to ICML 2025. Code available at\n  https://github.com/KevinRojas1499/Diffuse-Everything", "summary": "Diffusion models have demonstrated remarkable performance in generating\nunimodal data across various tasks, including image, video, and text\ngeneration. On the contrary, the joint generation of multimodal data through\ndiffusion models is still in the early stages of exploration. Existing\napproaches heavily rely on external preprocessing protocols, such as tokenizers\nand variational autoencoders, to harmonize varied data representations into a\nunified, unimodal format. This process heavily demands the high accuracy of\nencoders and decoders, which can be problematic for applications with limited\ndata. To lift this restriction, we propose a novel framework for building\nmultimodal diffusion models on arbitrary state spaces, enabling native\ngeneration of coupled data across different modalities. By introducing an\ninnovative decoupled noise schedule for each modality, we enable both\nunconditional and modality-conditioned generation within a single model\nsimultaneously. We empirically validate our approach for text-image generation\nand mixed-type tabular data synthesis, demonstrating that it achieves\ncompetitive performance.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u6a21\u6001\u6269\u6563\u6a21\u578b\u6846\u67b6\uff0c\u652f\u6301\u8de8\u6a21\u6001\u7684\u539f\u751f\u751f\u6210\uff0c\u65e0\u9700\u4f9d\u8d56\u5916\u90e8\u9884\u5904\u7406\u534f\u8bae\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u5916\u90e8\u9884\u5904\u7406\u534f\u8bae\uff08\u5982\u5206\u8bcd\u5668\u548c\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff09\u7edf\u4e00\u6570\u636e\u8868\u793a\uff0c\u4f46\u8fd9\u5bf9\u6570\u636e\u6709\u9650\u7684\u5e94\u7528\u5b58\u5728\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u4efb\u610f\u72b6\u6001\u7a7a\u95f4\u4e0a\u6784\u5efa\u591a\u6a21\u6001\u6269\u6563\u6a21\u578b\u7684\u65b0\u6846\u67b6\uff0c\u5e76\u5f15\u5165\u4e86\u521b\u65b0\u7684\u89e3\u8026\u566a\u58f0\u8c03\u5ea6\u7b56\u7565\u3002", "result": "\u5728\u6587\u672c-\u56fe\u50cf\u751f\u6210\u548c\u6df7\u5408\u7c7b\u578b\u8868\u683c\u6570\u636e\u5408\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u540c\u65f6\u652f\u6301\u65e0\u6761\u4ef6\u751f\u6210\u548c\u6a21\u6001\u6761\u4ef6\u751f\u6210\uff0c\u5177\u6709\u7ade\u4e89\u529b\u3002"}}
{"id": "2506.07918", "pdf": "https://arxiv.org/pdf/2506.07918", "abs": "https://arxiv.org/abs/2506.07918", "authors": ["Vahid Balazadeh", "Hamidreza Kamkari", "Valentin Thomas", "Benson Li", "Junwei Ma", "Jesse C. Cresswell", "Rahul G. Krishnan"], "title": "CausalPFN: Amortized Causal Effect Estimation via In-Context Learning", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Causal effect estimation from observational data is fundamental across\nvarious applications. However, selecting an appropriate estimator from dozens\nof specialized methods demands substantial manual effort and domain expertise.\nWe present CausalPFN, a single transformer that amortizes this workflow:\ntrained once on a large library of simulated data-generating processes that\nsatisfy ignorability, it infers causal effects for new observational datasets\nout-of-the-box. CausalPFN combines ideas from Bayesian causal inference with\nthe large-scale training protocol of prior-fitted networks (PFNs), learning to\nmap raw observations directly to causal effects without any task-specific\nadjustment. Our approach achieves superior average performance on heterogeneous\nand average treatment effect estimation benchmarks (IHDP, Lalonde, ACIC).\nMoreover, it shows competitive performance for real-world policy making on\nuplift modeling tasks. CausalPFN provides calibrated uncertainty estimates to\nsupport reliable decision-making based on Bayesian principles. This\nready-to-use model does not require any further training or tuning and takes a\nstep toward automated causal inference (https://github.com/vdblm/CausalPFN).", "AI": {"tldr": "CausalPFN\u662f\u4e00\u4e2a\u57fa\u4e8eTransformer\u7684\u6a21\u578b\uff0c\u7528\u4e8e\u4ece\u89c2\u6d4b\u6570\u636e\u4e2d\u4f30\u8ba1\u56e0\u679c\u6548\u5e94\uff0c\u65e0\u9700\u624b\u52a8\u8c03\u6574\u6216\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u3002", "motivation": "\u56e0\u679c\u6548\u5e94\u4f30\u8ba1\u5728\u591a\u4e2a\u5e94\u7528\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u624b\u52a8\u5de5\u4f5c\u548c\u4e13\u4e1a\u77e5\u8bc6\u3002", "method": "CausalPFN\u901a\u8fc7\u5728\u5927\u89c4\u6a21\u6a21\u62df\u6570\u636e\u4e0a\u8bad\u7ec3\uff0c\u76f4\u63a5\u6620\u5c04\u89c2\u6d4b\u6570\u636e\u5230\u56e0\u679c\u6548\u5e94\uff0c\u7ed3\u5408\u8d1d\u53f6\u65af\u56e0\u679c\u63a8\u65ad\u548c\u5148\u9a8c\u62df\u5408\u7f51\u7edc\u6280\u672f\u3002", "result": "\u5728IHDP\u3001Lalonde\u548cACIC\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u5728\u5b9e\u9645\u653f\u7b56\u5236\u5b9a\u4efb\u52a1\u4e2d\u5177\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "CausalPFN\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u6216\u8c03\u4f18\u7684\u81ea\u52a8\u5316\u56e0\u679c\u63a8\u65ad\u89e3\u51b3\u65b9\u6848\uff0c\u652f\u6301\u53ef\u9760\u7684\u51b3\u7b56\u5236\u5b9a\u3002"}}
{"id": "2506.07919", "pdf": "https://arxiv.org/pdf/2506.07919", "abs": "https://arxiv.org/abs/2506.07919", "authors": ["Manuel Brenner", "Georgia Koppe"], "title": "Uncovering the Functional Roles of Nonlinearity in Memory", "categories": ["cs.LG", "cs.AI", "cs.CL", "nlin.CD", "physics.comp-ph"], "comment": "Preprint under review", "summary": "Memory and long-range temporal processing are core requirements for sequence\nmodeling tasks across natural language processing, time-series forecasting,\nspeech recognition, and control. While nonlinear recurrence has long been\nviewed as essential for enabling such mechanisms, recent work suggests that\nlinear dynamics may often suffice. In this study, we go beyond performance\ncomparisons to systematically dissect the functional role of nonlinearity in\nrecurrent networks--identifying both when it is computationally necessary, and\nwhat mechanisms it enables. We use Almost Linear Recurrent Neural Networks\n(AL-RNNs), which allow fine-grained control over nonlinearity, as both a\nflexible modeling tool and a probe into the internal mechanisms of memory.\nAcross a range of classic sequence modeling tasks and a real-world stimulus\nselection task, we find that minimal nonlinearity is not only sufficient but\noften optimal, yielding models that are simpler, more robust, and more\ninterpretable than their fully nonlinear or linear counterparts. Our results\nprovide a principled framework for selectively introducing nonlinearity,\nbridging dynamical systems theory with the functional demands of long-range\nmemory and structured computation in recurrent neural networks, with\nimplications for both artificial and biological neural systems.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u5e8f\u5217\u5efa\u6a21\u4efb\u52a1\u4e2d\uff0c\u6700\u5c0f\u975e\u7ebf\u6027\u901a\u5e38\u8db3\u591f\u4e14\u6700\u4f18\uff0c\u7b80\u5316\u6a21\u578b\u5e76\u63d0\u9ad8\u9c81\u68d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u63a2\u8ba8\u975e\u7ebf\u6027\u5728\u5faa\u73af\u7f51\u7edc\u4e2d\u7684\u529f\u80fd\u89d2\u8272\uff0c\u660e\u786e\u5176\u8ba1\u7b97\u5fc5\u8981\u6027\u548c\u673a\u5236\u3002", "method": "\u4f7f\u7528\u51e0\u4e4e\u7ebf\u6027\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff08AL-RNNs\uff09\u4f5c\u4e3a\u5efa\u6a21\u5de5\u5177\u548c\u673a\u5236\u63a2\u9488\u3002", "result": "\u6700\u5c0f\u975e\u7ebf\u6027\u5728\u591a\u79cd\u4efb\u52a1\u4e2d\u8868\u73b0\u6700\u4f18\uff0c\u6a21\u578b\u66f4\u7b80\u5355\u3001\u9c81\u68d2\u4e14\u53ef\u89e3\u91ca\u3002", "conclusion": "\u4e3a\u9009\u62e9\u6027\u5f15\u5165\u975e\u7ebf\u6027\u63d0\u4f9b\u539f\u5219\u6027\u6846\u67b6\uff0c\u8fde\u63a5\u52a8\u529b\u5b66\u7cfb\u7edf\u7406\u8bba\u4e0e\u5faa\u73af\u7f51\u7edc\u7684\u529f\u80fd\u9700\u6c42\u3002"}}
{"id": "2506.07920", "pdf": "https://arxiv.org/pdf/2506.07920", "abs": "https://arxiv.org/abs/2506.07920", "authors": ["Hossein Babaei", "Mel White", "Richard G. Baraniuk"], "title": "W4S4: WaLRUS Meets S4 for Long-Range Sequence Modeling", "categories": ["cs.LG", "eess.AS", "eess.IV", "eess.SP"], "comment": "10 pages, 2 figures, 3 tables", "summary": "State Space Models (SSMs) have emerged as powerful components for sequence\nmodeling, enabling efficient handling of long-range dependencies via linear\nrecurrence and convolutional computation. However, their effectiveness depends\nheavily on the choice and initialization of the state matrix. In this work, we\nbuild on the SaFARi framework and existing WaLRUS SSMs to introduce a new\nvariant, W4S4 (WaLRUS for S4), a new class of SSMs constructed from redundant\nwavelet frames. WaLRUS admits a stable diagonalization and supports fast kernel\ncomputation without requiring low-rank approximations, making it both\ntheoretically grounded and computationally efficient. We show that WaLRUS\nretains information over long horizons significantly better than HiPPO-based\nSSMs, both in isolation and when integrated into deep architectures such as S4.\nOur experiments demonstrate consistent improvements across delay reconstruction\ntasks, classification benchmarks, and long-range sequence modeling, confirming\nthat high-quality, structured initialization enabled by wavelet-based state\ndynamic offers substantial advantages over existing alternatives. WaLRUS\nprovides a scalable and versatile foundation for the next generation of deep\nSSM-based models.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff08SSM\uff09\u53d8\u4f53W4S4\uff0c\u57fa\u4e8e\u5197\u4f59\u5c0f\u6ce2\u6846\u67b6\u6784\u5efa\uff0c\u5177\u6709\u7a33\u5b9a\u5bf9\u89d2\u5316\u548c\u9ad8\u6548\u6838\u8ba1\u7b97\u80fd\u529b\uff0c\u4f18\u4e8e\u73b0\u6709HiPPO-based SSMs\u3002", "motivation": "\u73b0\u6709SSMs\u7684\u6027\u80fd\u9ad8\u5ea6\u4f9d\u8d56\u4e8e\u72b6\u6001\u77e9\u9635\u7684\u9009\u62e9\u548c\u521d\u59cb\u5316\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u4e14\u7406\u8bba\u652f\u6301\u7684\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8eSaFARi\u6846\u67b6\u548cWaLRUS SSMs\uff0c\u6784\u5efa\u4e86W4S4\u6a21\u578b\uff0c\u5229\u7528\u5197\u4f59\u5c0f\u6ce2\u6846\u67b6\u5b9e\u73b0\u7a33\u5b9a\u5bf9\u89d2\u5316\u548c\u5feb\u901f\u6838\u8ba1\u7b97\u3002", "result": "W4S4\u5728\u5ef6\u8fdf\u91cd\u5efa\u4efb\u52a1\u3001\u5206\u7c7b\u57fa\u51c6\u548c\u957f\u5e8f\u5217\u5efa\u6a21\u4e2d\u8868\u73b0\u4f18\u4e8eHiPPO-based SSMs\u3002", "conclusion": "W4S4\u4e3a\u4e0b\u4e00\u4ee3\u57fa\u4e8eSSM\u7684\u6df1\u5ea6\u6a21\u578b\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u591a\u529f\u80fd\u7684\u57fa\u7840\u3002"}}
{"id": "2506.07929", "pdf": "https://arxiv.org/pdf/2506.07929", "abs": "https://arxiv.org/abs/2506.07929", "authors": ["Amirreza Yasami", "Mohammadali Tofigh", "Mahdi Shahbakhti", "Charles Robert Koch"], "title": "A Generative Physics-Informed Reinforcement Learning-Based Approach for Construction of Representative Drive Cycle", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "Accurate driving cycle construction is crucial for vehicle design, fuel\neconomy analysis, and environmental impact assessments. A generative\nPhysics-Informed Expected SARSA-Monte Carlo (PIESMC) approach that constructs\nrepresentative driving cycles by capturing transient dynamics, acceleration,\ndeceleration, idling, and road grade transitions while ensuring model fidelity\nis introduced. Leveraging a physics-informed reinforcement learning framework\nwith Monte Carlo sampling, PIESMC delivers efficient cycle construction with\nreduced computational cost. Experimental evaluations on two real-world datasets\ndemonstrate that PIESMC replicates key kinematic and energy metrics, achieving\nup to a 57.3% reduction in cumulative kinematic fragment errors compared to the\nMicro-trip-based (MTB) method and a 10.5% reduction relative to the\nMarkov-chain-based (MCB) method. Moreover, it is nearly an order of magnitude\nfaster than conventional techniques. Analyses of vehicle-specific power\ndistributions and wavelet-transformed frequency content further confirm its\nability to reproduce experimental central tendencies and variability.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7269\u7406\u4fe1\u606f\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff08PIESMC\uff09\uff0c\u7528\u4e8e\u9ad8\u6548\u6784\u5efa\u4ee3\u8868\u6027\u9a7e\u9a76\u5faa\u73af\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u5e76\u63d0\u5347\u51c6\u786e\u6027\u3002", "motivation": "\u7cbe\u786e\u7684\u9a7e\u9a76\u5faa\u73af\u6784\u5efa\u5bf9\u8f66\u8f86\u8bbe\u8ba1\u3001\u71c3\u6cb9\u7ecf\u6d4e\u6027\u5206\u6790\u548c\u73af\u5883\u5f71\u54cd\u8bc4\u4f30\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u52a8\u6001\u6355\u6349\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u91c7\u7528\u7269\u7406\u4fe1\u606f\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u7ed3\u5408\u8499\u7279\u5361\u6d1b\u91c7\u6837\uff08PIESMC\uff09\uff0c\u6355\u6349\u77ac\u6001\u52a8\u6001\u3001\u52a0\u51cf\u901f\u3001\u6020\u901f\u548c\u5761\u5ea6\u53d8\u5316\uff0c\u786e\u4fdd\u6a21\u578b\u4fdd\u771f\u5ea6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cPIESMC\u5728\u5173\u952e\u8fd0\u52a8\u5b66\u548c\u80fd\u91cf\u6307\u6807\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u6bd4MTB\u65b9\u6cd5\u51cf\u5c1157.3%\u7684\u7d2f\u79ef\u8bef\u5dee\uff0c\u6bd4MCB\u65b9\u6cd5\u51cf\u5c1110.5%\uff0c\u4e14\u8ba1\u7b97\u901f\u5ea6\u5feb\u4e00\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "PIESMC\u80fd\u9ad8\u6548\u6784\u5efa\u9ad8\u4fdd\u771f\u9a7e\u9a76\u5faa\u73af\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002"}}
{"id": "2506.07933", "pdf": "https://arxiv.org/pdf/2506.07933", "abs": "https://arxiv.org/abs/2506.07933", "authors": ["Lev V. Utkin", "Semen P. Khomets", "Vlada A. Efremenko", "Andrei V. Konstantinov", "Natalya M. Verbova"], "title": "Ensemble-Based Survival Models with the Self-Attended Beran Estimator Predictions", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Survival analysis predicts the time until an event of interest, such as\nfailure or death, but faces challenges due to censored data, where some events\nremain unobserved. Ensemble-based models, like random survival forests and\ngradient boosting, are widely used but can produce unstable predictions due to\nvariations in bootstrap samples. To address this, we propose SurvBESA (Survival\nBeran Estimators Self-Attended), a novel ensemble model that combines Beran\nestimators with a self-attention mechanism. Unlike traditional methods,\nSurvBESA applies self-attention to predicted survival functions, smoothing out\nnoise by adjusting each survival function based on its similarity to\nneighboring survival functions. We also explore a special case using Huber's\ncontamination model to define attention weights, simplifying training to a\nquadratic or linear optimization problem. Numerical experiments show that\nSurvBESA outperforms state-of-the-art models. The implementation of SurvBESA is\npublicly available.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSurvBESA\u7684\u65b0\u96c6\u6210\u6a21\u578b\uff0c\u7ed3\u5408Beran\u4f30\u8ba1\u5668\u548c\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff0c\u7528\u4e8e\u751f\u5b58\u5206\u6790\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u96c6\u6210\u6a21\u578b\uff08\u5982\u968f\u673a\u751f\u5b58\u68ee\u6797\u548c\u68af\u5ea6\u63d0\u5347\uff09\u56e0\u81ea\u4e3e\u6837\u672c\u53d8\u5316\u5bfc\u81f4\u9884\u6d4b\u4e0d\u7a33\u5b9a\u7684\u95ee\u9898\u3002", "method": "\u7ed3\u5408Beran\u4f30\u8ba1\u5668\u548c\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff0c\u901a\u8fc7\u8c03\u6574\u76f8\u90bb\u751f\u5b58\u51fd\u6570\u7684\u76f8\u4f3c\u6027\u6765\u5e73\u6ed1\u566a\u58f0\u3002\u8fd8\u63a2\u7d22\u4e86\u4f7f\u7528Huber\u6c61\u67d3\u6a21\u578b\u5b9a\u4e49\u6ce8\u610f\u529b\u6743\u91cd\u7684\u7279\u4f8b\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u8868\u660eSurvBESA\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u6a21\u578b\u3002", "conclusion": "SurvBESA\u901a\u8fc7\u81ea\u6ce8\u610f\u529b\u673a\u5236\u6709\u6548\u63d0\u5347\u4e86\u751f\u5b58\u5206\u6790\u7684\u9884\u6d4b\u7a33\u5b9a\u6027\uff0c\u4e14\u5b9e\u73b0\u5df2\u516c\u5f00\u3002"}}
{"id": "2506.07948", "pdf": "https://arxiv.org/pdf/2506.07948", "abs": "https://arxiv.org/abs/2506.07948", "authors": ["Kasimir Schulz", "Kenneth Yeung", "Kieran Evans"], "title": "TokenBreak: Bypassing Text Classification Models Through Token Manipulation", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "Natural Language Processing (NLP) models are used for text-related tasks such\nas classification and generation. To complete these tasks, input data is first\ntokenized from human-readable text into a format the model can understand,\nenabling it to make inferences and understand context. Text classification\nmodels can be implemented to guard against threats such as prompt injection\nattacks against Large Language Models (LLMs), toxic input and cybersecurity\nrisks such as spam emails. In this paper, we introduce TokenBreak: a novel\nattack that can bypass these protection models by taking advantage of the\ntokenization strategy they use. This attack technique manipulates input text in\nsuch a way that certain models give an incorrect classification. Importantly,\nthe end target (LLM or email recipient) can still understand and respond to the\nmanipulated text and therefore be vulnerable to the very attack the protection\nmodel was put in place to prevent. The tokenizer is tied to model architecture,\nmeaning it is possible to predict whether or not a model is vulnerable to\nattack based on family. We also present a defensive strategy as an added layer\nof protection that can be implemented without having to retrain the defensive\nmodel.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86TokenBreak\uff0c\u4e00\u79cd\u5229\u7528\u5206\u8bcd\u7b56\u7565\u7ed5\u8fc7\u6587\u672c\u5206\u7c7b\u4fdd\u62a4\u6a21\u578b\u7684\u65b0\u578b\u653b\u51fb\u65b9\u6cd5\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u7684\u9632\u5fa1\u7b56\u7565\u3002", "motivation": "\u73b0\u6709\u7684\u6587\u672c\u5206\u7c7b\u4fdd\u62a4\u6a21\u578b\uff08\u5982\u7528\u4e8e\u9632\u6b62LLM\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u6216\u5783\u573e\u90ae\u4ef6\u7684\u6a21\u578b\uff09\u53ef\u80fd\u56e0\u5206\u8bcd\u7b56\u7565\u7684\u6f0f\u6d1e\u800c\u88ab\u7ed5\u8fc7\uff0c\u5bfc\u81f4\u76ee\u6807\u7cfb\u7edf\u4ecd\u6613\u53d7\u653b\u51fb\u3002", "method": "\u63d0\u51faTokenBreak\u653b\u51fb\u6280\u672f\uff0c\u901a\u8fc7\u64cd\u7eb5\u8f93\u5165\u6587\u672c\u4f7f\u6a21\u578b\u5206\u7c7b\u9519\u8bef\uff0c\u540c\u65f6\u786e\u4fdd\u76ee\u6807\u7cfb\u7edf\u4ecd\u80fd\u7406\u89e3\u5e76\u54cd\u5e94\u88ab\u64cd\u7eb5\u7684\u6587\u672c\u3002", "result": "TokenBreak\u80fd\u591f\u6210\u529f\u7ed5\u8fc7\u4fdd\u62a4\u6a21\u578b\uff0c\u4e14\u653b\u51fb\u6548\u679c\u53ef\u901a\u8fc7\u6a21\u578b\u5bb6\u65cf\u9884\u6d4b\u3002\u540c\u65f6\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u7684\u4fdd\u62a4\u7b56\u7565\u3002", "conclusion": "\u5206\u8bcd\u7b56\u7565\u7684\u6f0f\u6d1e\u53ef\u80fd\u5bfc\u81f4\u4fdd\u62a4\u6a21\u578b\u5931\u6548\uff0c\u4f46\u901a\u8fc7\u989d\u5916\u7684\u9632\u5fa1\u5c42\u53ef\u4ee5\u7f13\u89e3\u8fd9\u4e00\u95ee\u9898\u3002"}}
{"id": "2506.07949", "pdf": "https://arxiv.org/pdf/2506.07949", "abs": "https://arxiv.org/abs/2506.07949", "authors": ["Anastasios N. Angelopoulos", "Jacob Eisenstein", "Jonathan Berant", "Alekh Agarwal", "Adam Fisch"], "title": "Cost-Optimal Active AI Model Evaluation", "categories": ["cs.LG"], "comment": null, "summary": "The development lifecycle of generative AI systems requires continual\nevaluation, data acquisition, and annotation, which is costly in both resources\nand time. In practice, rapid iteration often makes it necessary to rely on\nsynthetic annotation data because of the low cost, despite the potential for\nsubstantial bias. In this paper, we develop novel, cost-aware methods for\nactively balancing the use of a cheap, but often inaccurate, weak rater -- such\nas a model-based autorater that is designed to automatically assess the quality\nof generated content -- with a more expensive, but also more accurate, strong\nrater alternative such as a human. More specifically, the goal of our approach\nis to produce a low variance, unbiased estimate of the mean of the target\n\"strong\" rating, subject to some total annotation budget. Building on recent\nwork in active and prediction-powered statistical inference, we derive a family\nof cost-optimal policies for allocating a given annotation budget between weak\nand strong raters so as to maximize statistical efficiency. Using synthetic and\nreal-world data, we empirically characterize the conditions under which these\npolicies yield improvements over prior methods. We find that, especially in\ntasks where there is high variability in the difficulty of examples, our\npolicies can achieve the same estimation precision at a far lower total\nannotation budget than standard evaluation methods.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6210\u672c\u611f\u77e5\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u751f\u6210\u5f0fAI\u7cfb\u7edf\u4e2d\u5e73\u8861\u4f7f\u7528\u4f4e\u6210\u672c\u4f46\u53ef\u80fd\u4e0d\u51c6\u786e\u7684\u5f31\u8bc4\u5206\u8005\uff08\u5982\u6a21\u578b\u81ea\u52a8\u8bc4\u5206\uff09\u548c\u9ad8\u6210\u672c\u4f46\u66f4\u51c6\u786e\u7684\u5f3a\u8bc4\u5206\u8005\uff08\u5982\u4eba\u5de5\u8bc4\u5206\uff09\uff0c\u4ee5\u5728\u6709\u9650\u9884\u7b97\u4e0b\u6700\u5927\u5316\u7edf\u8ba1\u6548\u7387\u3002", "motivation": "\u751f\u6210\u5f0fAI\u7cfb\u7edf\u7684\u5f00\u53d1\u9700\u8981\u6301\u7eed\u8bc4\u4f30\u548c\u6570\u636e\u6807\u6ce8\uff0c\u6210\u672c\u9ad8\u6602\u3002\u5feb\u901f\u8fed\u4ee3\u4e2d\u5e38\u4f9d\u8d56\u4f4e\u6210\u672c\u4f46\u53ef\u80fd\u6709\u504f\u7684\u5408\u6210\u6570\u636e\uff0c\u9700\u5e73\u8861\u6210\u672c\u4e0e\u51c6\u786e\u6027\u3002", "method": "\u57fa\u4e8e\u4e3b\u52a8\u548c\u9884\u6d4b\u9a71\u52a8\u7684\u7edf\u8ba1\u63a8\u65ad\uff0c\u63d0\u51fa\u6210\u672c\u6700\u4f18\u7b56\u7565\uff0c\u5206\u914d\u6807\u6ce8\u9884\u7b97\u4ee5\u6700\u5927\u5316\u7edf\u8ba1\u6548\u7387\u3002", "result": "\u5728\u4efb\u52a1\u96be\u5ea6\u5dee\u5f02\u5927\u7684\u60c5\u51b5\u4e0b\uff0c\u65b0\u7b56\u7565\u80fd\u4ee5\u66f4\u4f4e\u9884\u7b97\u8fbe\u5230\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u540c\u7684\u4f30\u8ba1\u7cbe\u5ea6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u663e\u8457\u964d\u4f4e\u6807\u6ce8\u6210\u672c\uff0c\u4e3a\u751f\u6210\u5f0fAI\u7cfb\u7edf\u8bc4\u4f30\u63d0\u4f9b\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.07958", "pdf": "https://arxiv.org/pdf/2506.07958", "abs": "https://arxiv.org/abs/2506.07958", "authors": ["Salah A. Faroughi", "Farinaz Mostajeran"], "title": "Neural Tangent Kernel Analysis to Probe Convergence in Physics-informed Neural Solvers: PIKANs vs. PINNs", "categories": ["cs.LG", "math-ph", "math.AP", "math.MP", "math.SP"], "comment": null, "summary": "Physics-informed Kolmogorov-Arnold Networks (PIKANs), and in particular their\nChebyshev-based variants (cPIKANs), have recently emerged as promising models\nfor solving partial differential equations (PDEs). However, their training\ndynamics and convergence behavior remain largely unexplored both theoretically\nand numerically. In this work, we aim to advance the theoretical understanding\nof cPIKANs by analyzing them using Neural Tangent Kernel (NTK) theory. Our\nobjective is to discern the evolution of kernel structure throughout\ngradient-based training and its subsequent impact on learning efficiency. We\nfirst derive the NTK of standard cKANs in a supervised setting, and then extend\nthe analysis to the physics-informed context. We analyze the spectral\nproperties of NTK matrices, specifically their eigenvalue distributions and\nspectral bias, for four representative PDEs: the steady-state Helmholtz\nequation, transient diffusion and Allen-Cahn equations, and forced vibrations\ngoverned by the Euler-Bernoulli beam equation. We also conduct an investigation\ninto the impact of various optimization strategies, e.g., first-order,\nsecond-order, and hybrid approaches, on the evolution of the NTK and the\nresulting learning dynamics. Results indicate a tractable behavior for NTK in\nthe context of cPIKANs, which exposes learning dynamics that standard\nphysics-informed neural networks (PINNs) cannot capture. Spectral trends also\nreveal when domain decomposition improves training, directly linking kernel\nbehavior to convergence rates under different setups. To the best of our\nknowledge, this is the first systematic NTK study of cPIKANs, providing\ntheoretical insight that clarifies and predicts their empirical performance.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u795e\u7ecf\u5207\u7ebf\u6838\uff08NTK\uff09\u7406\u8bba\u5206\u6790\u4e86Chebyshev-based\u7269\u7406\u4fe1\u606fKolmogorov-Arnold\u7f51\u7edc\uff08cPIKANs\uff09\u7684\u8bad\u7ec3\u52a8\u6001\u548c\u6536\u655b\u884c\u4e3a\uff0c\u63ed\u793a\u4e86\u5176\u5b66\u4e60\u6548\u7387\u4e0e\u6838\u7ed3\u6784\u6f14\u5316\u7684\u5173\u7cfb\u3002", "motivation": "cPIKANs\u5728\u6c42\u89e3\u504f\u5fae\u5206\u65b9\u7a0b\uff08PDEs\uff09\u65b9\u9762\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u5176\u8bad\u7ec3\u52a8\u6001\u548c\u6536\u655b\u884c\u4e3a\u5c1a\u672a\u88ab\u5145\u5206\u7814\u7a76\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7NTK\u7406\u8bba\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u4f5c\u8005\u9996\u5148\u63a8\u5bfc\u4e86\u6807\u51c6cKANs\u5728\u76d1\u7763\u5b66\u4e60\u4e2d\u7684NTK\uff0c\u5e76\u5c06\u5176\u6269\u5c55\u5230\u7269\u7406\u4fe1\u606f\u80cc\u666f\u4e0b\u3002\u5206\u6790\u4e86\u56db\u79cd\u4ee3\u8868\u6027PDEs\u7684NTK\u77e9\u9635\u8c31\u7279\u6027\uff0c\u5e76\u7814\u7a76\u4e86\u4e0d\u540c\u4f18\u5316\u7b56\u7565\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u53d1\u73b0cPIKANs\u7684NTK\u884c\u4e3a\u53ef\u9884\u6d4b\uff0c\u5176\u5b66\u4e60\u52a8\u6001\u4f18\u4e8e\u6807\u51c6\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\uff08PINNs\uff09\u3002\u8c31\u5206\u6790\u8fd8\u63ed\u793a\u4e86\u57df\u5206\u89e3\u5bf9\u8bad\u7ec3\u7684\u6539\u5584\u4f5c\u7528\u3002", "conclusion": "\u8fd9\u662f\u9996\u6b21\u5bf9cPIKANs\u8fdb\u884c\u7cfb\u7edf\u7684NTK\u7814\u7a76\uff0c\u4e3a\u7406\u89e3\u5176\u6027\u80fd\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\u3002"}}
{"id": "2506.07969", "pdf": "https://arxiv.org/pdf/2506.07969", "abs": "https://arxiv.org/abs/2506.07969", "authors": ["Jacob Helwig", "Sai Sreeharsha Adavi", "Xuan Zhang", "Yuchao Lin", "Felix S. Chim", "Luke Takeshi Vizzini", "Haiyang Yu", "Muhammad Hasnain", "Saykat Kumar Biswas", "John J. Holloway", "Narendra Singh", "N. K. Anand", "Swagnik Guhathakurta", "Shuiwang Ji"], "title": "A Two-Phase Deep Learning Framework for Adaptive Time-Stepping in High-Speed Flow Modeling", "categories": ["cs.LG", "physics.flu-dyn"], "comment": null, "summary": "We consider the problem of modeling high-speed flows using machine learning\nmethods. While most prior studies focus on low-speed fluid flows in which\nuniform time-stepping is practical, flows approaching and exceeding the speed\nof sound exhibit sudden changes such as shock waves. In such cases, it is\nessential to use adaptive time-stepping methods to allow a temporal resolution\nsufficient to resolve these phenomena while simultaneously balancing\ncomputational costs. Here, we propose a two-phase machine learning method,\nknown as ShockCast, to model high-speed flows with adaptive time-stepping. In\nthe first phase, we propose to employ a machine learning model to predict the\ntimestep size. In the second phase, the predicted timestep is used as an input\nalong with the current fluid fields to advance the system state by the\npredicted timestep. We explore several physically-motivated components for\ntimestep prediction and introduce timestep conditioning strategies inspired by\nneural ODE and Mixture of Experts. As ShockCast is the first framework for\nlearning high-speed flows, we evaluate our methods by generating two supersonic\nflow datasets, available at https://huggingface.co/datasets/divelab. Our code\nis publicly available as part of the AIRS library\n(https://github.com/divelab/AIRS).", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aShockCast\u7684\u4e24\u9636\u6bb5\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u6a21\u62df\u9ad8\u901f\u6d41\u4f53\u6d41\u52a8\uff0c\u5e76\u91c7\u7528\u81ea\u9002\u5e94\u65f6\u95f4\u6b65\u957f\u6280\u672f\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u4f4e\u901f\u6d41\u4f53\u6d41\u52a8\uff0c\u800c\u9ad8\u901f\u6d41\u52a8\uff08\u5982\u63a5\u8fd1\u6216\u8d85\u8fc7\u97f3\u901f\uff09\u4f1a\u51fa\u73b0\u6fc0\u6ce2\u7b49\u7a81\u53d8\u73b0\u8c61\uff0c\u9700\u8981\u81ea\u9002\u5e94\u65f6\u95f4\u6b65\u957f\u6280\u672f\u4ee5\u5e73\u8861\u8ba1\u7b97\u6210\u672c\u548c\u5206\u8fa8\u7387\u3002", "method": "ShockCast\u5206\u4e3a\u4e24\u9636\u6bb5\uff1a\u7b2c\u4e00\u9636\u6bb5\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u65f6\u95f4\u6b65\u957f\uff1b\u7b2c\u4e8c\u9636\u6bb5\u5c06\u9884\u6d4b\u7684\u65f6\u95f4\u6b65\u957f\u4e0e\u5f53\u524d\u6d41\u4f53\u573a\u7ed3\u5408\uff0c\u63a8\u8fdb\u7cfb\u7edf\u72b6\u6001\u3002\u65b9\u6cd5\u7ed3\u5408\u4e86\u795e\u7ecfODE\u548c\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\u7684\u601d\u8def\u3002", "result": "\u8bba\u6587\u751f\u6210\u4e86\u4e24\u4e2a\u8d85\u97f3\u901f\u6d41\u52a8\u6570\u636e\u96c6\uff0c\u5e76\u516c\u5f00\u4e86\u4ee3\u7801\u3002", "conclusion": "ShockCast\u662f\u9996\u4e2a\u7528\u4e8e\u9ad8\u901f\u6d41\u52a8\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u65f6\u95f4\u6b65\u957f\u6709\u6548\u89e3\u51b3\u4e86\u9ad8\u901f\u6d41\u52a8\u5efa\u6a21\u95ee\u9898\u3002"}}
{"id": "2506.07972", "pdf": "https://arxiv.org/pdf/2506.07972", "abs": "https://arxiv.org/abs/2506.07972", "authors": ["Hongzheng Chen", "Yingheng Wang", "Yaohui Cai", "Hins Hu", "Jiajie Li", "Shirley Huang", "Chenhui Deng", "Rongjian Liang", "Shufeng Kong", "Haoxing Ren", "Samitha Samaranayake", "Carla P. Gomes", "Zhiru Zhang"], "title": "HeuriGym: An Agentic Benchmark for LLM-Crafted Heuristics in Combinatorial Optimization", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "While Large Language Models (LLMs) have demonstrated significant advancements\nin reasoning and agent-based problem-solving, current evaluation methodologies\nfail to adequately assess their capabilities: existing benchmarks either rely\non closed-ended questions prone to saturation and memorization, or subjective\ncomparisons that lack consistency and rigor. In this work, we introduce\nHeuriGym, an agentic framework designed for evaluating heuristic algorithms\ngenerated by LLMs for combinatorial optimization problems, characterized by\nclearly defined objectives and expansive solution spaces. HeuriGym empowers\nLLMs to propose heuristics, receive evaluative feedback via code execution, and\niteratively refine their solutions. We evaluate nine state-of-the-art models on\nnine problems across domains such as computer systems, logistics, and biology,\nexposing persistent limitations in tool use, planning, and adaptive reasoning.\nTo quantify performance, we propose the Quality-Yield Index (QYI), a metric\nthat captures both solution pass rate and quality. Even top models like\nGPT-o4-mini-high and Gemini-2.5-Pro attain QYI scores of only 0.6, well below\nthe expert baseline of 1. Our open-source benchmark aims to guide the\ndevelopment of LLMs toward more effective and realistic problem-solving in\nscientific and engineering domains.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faHeuriGym\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4e2d\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5\u751f\u6210\u80fd\u529b\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u5728\u5de5\u5177\u4f7f\u7528\u3001\u89c4\u5212\u548c\u9002\u5e94\u6027\u63a8\u7406\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u65e0\u6cd5\u5145\u5206\u8bc4\u4f30LLM\u7684\u80fd\u529b\uff0c\u8981\u4e48\u4f9d\u8d56\u5c01\u95ed\u5f0f\u95ee\u9898\u6613\u9971\u548c\uff0c\u8981\u4e48\u4e3b\u89c2\u6bd4\u8f83\u7f3a\u4e4f\u4e00\u81f4\u6027\u3002", "method": "\u5f15\u5165HeuriGym\u6846\u67b6\uff0c\u8ba9LLM\u63d0\u51fa\u542f\u53d1\u5f0f\u7b97\u6cd5\u5e76\u901a\u8fc7\u4ee3\u7801\u6267\u884c\u53cd\u9988\u8fed\u4ee3\u4f18\u5316\uff0c\u63d0\u51faQYI\u6307\u6807\u91cf\u5316\u6027\u80fd\u3002", "result": "\u6d4b\u8bd59\u4e2a\u9876\u7ea7\u6a21\u578b\uff0cQYI\u5f97\u5206\u6700\u9ad8\u4ec50.6\uff0c\u8fdc\u4f4e\u4e8e\u4e13\u5bb6\u57fa\u7ebf1\uff0c\u663e\u793a\u6a21\u578b\u5728\u590d\u6742\u95ee\u9898\u89e3\u51b3\u4e2d\u7684\u4e0d\u8db3\u3002", "conclusion": "\u5f00\u6e90\u57fa\u51c6\u65e8\u5728\u63a8\u52a8LLM\u5728\u79d1\u5b66\u548c\u5de5\u7a0b\u9886\u57df\u66f4\u6709\u6548\u548c\u5b9e\u9645\u7684\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u53d1\u5c55\u3002"}}
{"id": "2506.07975", "pdf": "https://arxiv.org/pdf/2506.07975", "abs": "https://arxiv.org/abs/2506.07975", "authors": ["Caleb Zheng", "Eli Shlizerman"], "title": "Hyperpruning: Efficient Search through Pruned Variants of Recurrent Neural Networks Leveraging Lyapunov Spectrum", "categories": ["cs.LG"], "comment": "26 pages, 3 figures", "summary": "A variety of pruning methods have been introduced for over-parameterized\nRecurrent Neural Networks to improve efficiency in terms of power consumption\nand storage utilization. These advances motivate a new paradigm, termed\n`hyperpruning', which seeks to identify the most suitable pruning strategy for\na given network architecture and application. Unlike conventional\nhyperparameter search, where the optimal configuration's accuracy remains\nuncertain, in the context of network pruning, the accuracy of the dense model\nsets the target for the accuracy of the pruned one. The goal, therefore, is to\ndiscover pruned variants that match or even surpass this established accuracy.\nHowever, exhaustive search over pruning configurations is computationally\nexpensive and lacks early performance guarantees. To address this challenge, we\npropose a novel Lyapunov Spectrum (LS)-based distance metric that enables early\ncomparison between pruned and dense networks, allowing accurate prediction of\npost-training performance. By integrating this LS-based distance with standard\nhyperparameter optimization algorithms, we introduce an efficient hyperpruning\nframework, termed LS-based Hyperpruning (LSH). LSH reduces search time by an\norder of magnitude compared to conventional approaches relying on full\ntraining. Experiments on stacked LSTM and RHN architectures using the Penn\nTreebank dataset, and on AWD-LSTM-MoS using WikiText-2, demonstrate that under\nfixed training budgets and target pruning ratios, LSH consistently identifies\nsuperior pruned models. Remarkably, these pruned variants not only outperform\nthose selected by loss-based baseline but also exceed the performance of their\ndense counterpart.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLyapunov Spectrum\uff08LS\uff09\u8ddd\u79bb\u5ea6\u91cf\u7684\u9ad8\u6548\u8d85\u526a\u679d\u6846\u67b6LSH\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u641c\u7d22\u65f6\u95f4\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u548c\u5bc6\u96c6\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u526a\u679d\u65b9\u6cd5\u7f3a\u4e4f\u65e9\u671f\u6027\u80fd\u4fdd\u8bc1\uff0c\u4e14\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u65e9\u671f\u9884\u6d4b\u526a\u679d\u540e\u6027\u80fd\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faLS\u8ddd\u79bb\u5ea6\u91cf\uff0c\u7ed3\u5408\u8d85\u53c2\u6570\u4f18\u5316\u7b97\u6cd5\uff0c\u6784\u5efaLSH\u6846\u67b6\uff0c\u5feb\u901f\u627e\u5230\u6700\u4f18\u526a\u679d\u7b56\u7565\u3002", "result": "\u5728\u591a\u4e2a\u67b6\u6784\u548c\u6570\u636e\u96c6\u4e0a\uff0cLSH\u5728\u56fa\u5b9a\u8bad\u7ec3\u9884\u7b97\u4e0b\u627e\u5230\u7684\u526a\u679d\u6a21\u578b\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u548c\u5bc6\u96c6\u6a21\u578b\u3002", "conclusion": "LSH\u4e3a\u7f51\u7edc\u526a\u679d\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u6027\u80fd\u4f18\u8d8a\u7684\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2506.07976", "pdf": "https://arxiv.org/pdf/2506.07976", "abs": "https://arxiv.org/abs/2506.07976", "authors": ["Junhong Shen", "Hao Bai", "Lunjun Zhang", "Yifei Zhou", "Amrith Setlur", "Shengbang Tong", "Diego Caples", "Nan Jiang", "Tong Zhang", "Ameet Talwalkar", "Aviral Kumar"], "title": "Thinking vs. Doing: Agents that Reason by Scaling Test-Time Interaction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The current paradigm of test-time scaling relies on generating long reasoning\ntraces (\"thinking\" more) before producing a response. In agent problems that\nrequire interaction, this can be done by generating thinking traces before\nacting in the world. However, this process does not allow agents to acquire new\ninformation from the environment or adapt their behavior over time. In this\nwork, we propose to scale test-time interaction, an untapped dimension of\ntest-time scaling that increases the agent's interaction horizon to enable\nrunning rich behaviors such as exploration, backtracking, and dynamic\nre-planning within a single rollout. To demonstrate the promise of this scaling\ndimension, we study the domain of web agents. We first show that even\nprompting-based interaction scaling without any training can improve task\nsuccess on web benchmarks non-trivially. Building on this, we introduce TTI\n(Test-Time Interaction), a curriculum-based online reinforcement learning (RL)\napproach that trains agents by adaptively adjusting their rollout lengths.\nUsing a Gemma 3 12B model, TTI produces state-of-the-art open-source, open-data\nweb agents on WebVoyager and WebArena benchmarks. We further show that TTI\nenables agents to balance exploration and exploitation adaptively. Our results\nestablish interaction scaling as a powerful, complementary axis to scaling\nper-step compute, offering new avenues for training adaptive agents.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6d4b\u8bd5\u65f6\u95f4\u6269\u5c55\u7ef4\u5ea6\u2014\u2014\u4ea4\u4e92\u6269\u5c55\uff0c\u901a\u8fc7\u589e\u52a0\u4ee3\u7406\u7684\u4ea4\u4e92\u8303\u56f4\u6765\u63d0\u5347\u5176\u9002\u5e94\u6027\uff0c\u5e76\u5728\u7f51\u7edc\u4ee3\u7406\u9886\u57df\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5f53\u524d\u6d4b\u8bd5\u65f6\u95f4\u6269\u5c55\u8303\u5f0f\u4f9d\u8d56\u4e8e\u751f\u6210\u957f\u63a8\u7406\u8f68\u8ff9\uff0c\u4f46\u65e0\u6cd5\u8ba9\u4ee3\u7406\u4ece\u73af\u5883\u4e2d\u83b7\u53d6\u65b0\u4fe1\u606f\u6216\u968f\u65f6\u95f4\u8c03\u6574\u884c\u4e3a\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u63a2\u7d22\u4e86\u4ea4\u4e92\u6269\u5c55\u7684\u6f5c\u529b\u3002", "method": "\u63d0\u51fa\u4e86TTI\uff08\u6d4b\u8bd5\u65f6\u95f4\u4ea4\u4e92\uff09\uff0c\u4e00\u79cd\u57fa\u4e8e\u8bfe\u7a0b\u7684\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u4ee3\u7406\u7684\u4ea4\u4e92\u8303\u56f4\u6765\u8bad\u7ec3\u4ee3\u7406\u3002", "result": "TTI\u5728\u7f51\u7edc\u4ee3\u7406\u57fa\u51c6\u6d4b\u8bd5\uff08WebVoyager\u548cWebArena\uff09\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5e76\u5c55\u793a\u4e86\u4ee3\u7406\u5728\u63a2\u7d22\u4e0e\u5229\u7528\u4e4b\u95f4\u7684\u81ea\u9002\u5e94\u5e73\u8861\u80fd\u529b\u3002", "conclusion": "\u4ea4\u4e92\u6269\u5c55\u662f\u8ba1\u7b97\u6269\u5c55\u7684\u6709\u529b\u8865\u5145\uff0c\u4e3a\u8bad\u7ec3\u81ea\u9002\u5e94\u4ee3\u7406\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2506.07980", "pdf": "https://arxiv.org/pdf/2506.07980", "abs": "https://arxiv.org/abs/2506.07980", "authors": ["Alberto Baz\u00e1n-Guill\u00e9n", "Carlos Beis-Penedo", "Diego Cajaraville-Aboy", "Pablo Barbecho-Bautista", "Rebeca P. D\u00edaz-Redondo", "Luis J. de la Cruz Llopis", "Ana Fern\u00e1ndez-Vilas", "M\u00f3nica Aguilar Igartua", "Manuel Fern\u00e1ndez-Veiga"], "title": "Realistic Urban Traffic Generator using Decentralized Federated Learning for the SUMO simulator", "categories": ["cs.LG"], "comment": "21 pages, 7 figures", "summary": "Realistic urban traffic simulation is essential for sustainable urban\nplanning and the development of intelligent transportation systems. However,\ngenerating high-fidelity, time-varying traffic profiles that accurately reflect\nreal-world conditions, especially in large-scale scenarios, remains a major\nchallenge. Existing methods often suffer from limitations in accuracy,\nscalability, or raise privacy concerns due to centralized data processing. This\nwork introduces DesRUTGe (Decentralized Realistic Urban Traffic Generator), a\nnovel framework that integrates Deep Reinforcement Learning (DRL) agents with\nthe SUMO simulator to generate realistic 24-hour traffic patterns. A key\ninnovation of DesRUTGe is its use of Decentralized Federated Learning (DFL),\nwherein each traffic detector and its corresponding urban zone function as an\nindependent learning node. These nodes train local DRL models using minimal\nhistorical data and collaboratively refine their performance by exchanging\nmodel parameters with selected peers (e.g., geographically adjacent zones),\nwithout requiring a central coordinator. Evaluated using real-world data from\nthe city of Barcelona, DesRUTGe outperforms standard SUMO-based tools such as\nRouteSampler, as well as other centralized learning approaches, by delivering\nmore accurate and privacy-preserving traffic pattern generation.", "AI": {"tldr": "DesRUTGe\u662f\u4e00\u4e2a\u57fa\u4e8e\u53bb\u4e2d\u5fc3\u5316\u8054\u90a6\u5b66\u4e60\u548c\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210\u9ad8\u4fdd\u771f\u3001\u65f6\u95f4\u53d8\u5316\u7684\u57ce\u5e02\u4ea4\u901a\u6a21\u5f0f\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u3001\u53ef\u6269\u5c55\u6027\u6216\u9690\u79c1\u4fdd\u62a4\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u65e0\u6cd5\u6ee1\u8db3\u5927\u89c4\u6a21\u57ce\u5e02\u4ea4\u901a\u6a21\u62df\u7684\u9700\u6c42\u3002", "method": "\u7ed3\u5408\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4e0eSUMO\u6a21\u62df\u5668\uff0c\u91c7\u7528\u53bb\u4e2d\u5fc3\u5316\u8054\u90a6\u5b66\u4e60\uff0c\u6bcf\u4e2a\u4ea4\u901a\u68c0\u6d4b\u5668\u4f5c\u4e3a\u72ec\u7acb\u8282\u70b9\uff0c\u901a\u8fc7\u5c40\u90e8\u8bad\u7ec3\u548c\u53c2\u6570\u4ea4\u6362\u4f18\u5316\u6a21\u578b\u3002", "result": "\u5728\u5df4\u585e\u7f57\u90a3\u7684\u771f\u5b9e\u6570\u636e\u6d4b\u8bd5\u4e2d\uff0cDesRUTGe\u5728\u51c6\u786e\u6027\u548c\u9690\u79c1\u4fdd\u62a4\u65b9\u9762\u4f18\u4e8eRouteSampler\u548c\u5176\u4ed6\u96c6\u4e2d\u5f0f\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "DesRUTGe\u4e3a\u57ce\u5e02\u89c4\u5212\u548c\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u9690\u79c1\u4fdd\u62a4\u7684\u4ea4\u901a\u6a21\u62df\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.07998", "pdf": "https://arxiv.org/pdf/2506.07998", "abs": "https://arxiv.org/abs/2506.07998", "authors": ["Boya Zeng", "Yida Yin", "Zhiqiu Xu", "Zhuang Liu"], "title": "Generative Modeling of Weights: Generalization or Memorization?", "categories": ["cs.LG", "cs.CV"], "comment": "Project page at https://boyazeng.github.io/weight_memorization", "summary": "Generative models, with their success in image and video generation, have\nrecently been explored for synthesizing effective neural network weights. These\napproaches take trained neural network checkpoints as training data, and aim to\ngenerate high-performing neural network weights during inference. In this work,\nwe examine four representative methods on their ability to generate novel model\nweights, i.e., weights that are different from the checkpoints seen during\ntraining. Surprisingly, we find that these methods synthesize weights largely\nby memorization: they produce either replicas, or at best simple\ninterpolations, of the training checkpoints. Current methods fail to outperform\nsimple baselines, such as adding noise to the weights or taking a simple weight\nensemble, in obtaining different and simultaneously high-performing models. We\nfurther show that this memorization cannot be effectively mitigated by\nmodifying modeling factors commonly associated with memorization in image\ndiffusion models, or applying data augmentations. Our findings provide a\nrealistic assessment of what types of data current generative models can model,\nand highlight the need for more careful evaluation of generative models in new\ndomains. Our code is available at\nhttps://github.com/boyazeng/weight_memorization.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u5f53\u524d\u751f\u6210\u6a21\u578b\u5728\u751f\u6210\u795e\u7ecf\u7f51\u7edc\u6743\u91cd\u65f6\u4e3b\u8981\u901a\u8fc7\u8bb0\u5fc6\u8bad\u7ec3\u6570\u636e\uff0c\u800c\u975e\u771f\u6b63\u521b\u65b0\uff0c\u4e14\u6027\u80fd\u4e0d\u5982\u7b80\u5355\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u63a2\u7d22\u751f\u6210\u6a21\u578b\u5728\u5408\u6210\u9ad8\u6027\u80fd\u795e\u7ecf\u7f51\u7edc\u6743\u91cd\u65b9\u9762\u7684\u80fd\u529b\uff0c\u5e76\u8bc4\u4f30\u5176\u662f\u5426\u80fd\u591f\u751f\u6210\u65b0\u9896\u7684\u6743\u91cd\u3002", "method": "\u7814\u7a76\u4e86\u56db\u79cd\u4ee3\u8868\u6027\u65b9\u6cd5\uff0c\u5206\u6790\u5176\u751f\u6210\u6743\u91cd\u7684\u521b\u65b0\u6027\u548c\u6027\u80fd\uff0c\u5e76\u4e0e\u7b80\u5355\u57fa\u7ebf\u65b9\u6cd5\uff08\u5982\u6dfb\u52a0\u566a\u58f0\u6216\u6743\u91cd\u96c6\u6210\uff09\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u53d1\u73b0\u5f53\u524d\u65b9\u6cd5\u4e3b\u8981\u901a\u8fc7\u8bb0\u5fc6\u8bad\u7ec3\u6570\u636e\u751f\u6210\u6743\u91cd\uff0c\u65e0\u6cd5\u8d85\u8d8a\u7b80\u5355\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e14\u901a\u8fc7\u8c03\u6574\u5efa\u6a21\u56e0\u7d20\u6216\u6570\u636e\u589e\u5f3a\u65e0\u6cd5\u6709\u6548\u7f13\u89e3\u8bb0\u5fc6\u95ee\u9898\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u751f\u6210\u6a21\u578b\u5728\u65b0\u9886\u57df\u7684\u5c40\u9650\u6027\uff0c\u5f3a\u8c03\u4e86\u5bf9\u751f\u6210\u6a21\u578b\u8bc4\u4f30\u7684\u8c28\u614e\u9700\u6c42\u3002"}}
{"id": "2506.08001", "pdf": "https://arxiv.org/pdf/2506.08001", "abs": "https://arxiv.org/abs/2506.08001", "authors": ["Zeju Qiu", "Simon Buchholz", "Tim Z. Xiao", "Maximilian Dax", "Bernhard Sch\u00f6lkopf", "Weiyang Liu"], "title": "Reparameterized LLM Training via Orthogonal Equivalence Transformation", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Technical report v1 (36 pages, 24 figures, project page:\n  https://spherelab.ai/poet-site/)", "summary": "While large language models (LLMs) are driving the rapid advancement of\nartificial intelligence, effectively and reliably training these large models\nremains one of the field's most significant challenges. To address this\nchallenge, we propose POET, a novel reParameterized training algorithm that\nuses Orthogonal Equivalence Transformation to optimize neurons. Specifically,\nPOET reparameterizes each neuron with two learnable orthogonal matrices and a\nfixed random weight matrix. Because of its provable preservation of spectral\nproperties of weight matrices, POET can stably optimize the objective function\nwith improved generalization. We further develop efficient approximations that\nmake POET flexible and scalable for training large-scale neural networks.\nExtensive experiments validate the effectiveness and scalability of POET in\ntraining LLMs.", "AI": {"tldr": "POET\u662f\u4e00\u79cd\u65b0\u578b\u7684\u91cd\u65b0\u53c2\u6570\u5316\u8bad\u7ec3\u7b97\u6cd5\uff0c\u901a\u8fc7\u6b63\u4ea4\u7b49\u4ef7\u53d8\u6362\u4f18\u5316\u795e\u7ecf\u5143\uff0c\u63d0\u9ad8\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bad\u7ec3\u6548\u679c\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u8bad\u7ec3\u6548\u679c\u548c\u7a33\u5b9a\u6027\u662f\u5f53\u524d\u4eba\u5de5\u667a\u80fd\u9886\u57df\u7684\u91cd\u8981\u6311\u6218\u3002", "method": "POET\u901a\u8fc7\u5c06\u6bcf\u4e2a\u795e\u7ecf\u5143\u91cd\u65b0\u53c2\u6570\u5316\u4e3a\u4e24\u4e2a\u53ef\u5b66\u4e60\u7684\u6b63\u4ea4\u77e9\u9635\u548c\u4e00\u4e2a\u56fa\u5b9a\u7684\u968f\u673a\u6743\u91cd\u77e9\u9635\uff0c\u4fdd\u6301\u6743\u91cd\u77e9\u9635\u7684\u8c31\u7279\u6027\uff0c\u4ece\u800c\u7a33\u5b9a\u4f18\u5316\u76ee\u6807\u51fd\u6570\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86POET\u5728\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u6709\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "POET\u4e3a\u5927\u89c4\u6a21\u795e\u7ecf\u7f51\u7edc\u7684\u8bad\u7ec3\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u7a33\u5b9a\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.00654", "pdf": "https://arxiv.org/pdf/2506.00654", "abs": "https://arxiv.org/abs/2506.00654", "authors": ["Marco Di Gennaro", "Francesco Panebianco", "Marco Pianta", "Stefano Zanero", "Michele Carminati"], "title": "Amatriciana: Exploiting Temporal GNNs for Robust and Efficient Money Laundering Detection", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "Money laundering is a financial crime that poses a serious threat to\nfinancial integrity and social security. The growing number of transactions\nmakes it necessary to use automatic tools that help law enforcement agencies\ndetect such criminal activity. In this work, we present Amatriciana, a novel\napproach based on Graph Neural Networks to detect money launderers inside a\ngraph of transactions by considering temporal information. Amatriciana uses the\nwhole graph of transactions without splitting it into several time-based\nsubgraphs, exploiting all relational information in the dataset. Our\nexperiments on a public dataset reveal that the model can learn from a limited\namount of data. Furthermore, when more data is available, the model outperforms\nother State-of-the-art approaches; in particular, Amatriciana decreases the\nnumber of False Positives (FPs) while detecting many launderers. In summary,\nAmatriciana achieves an F1 score of 0.76. In addition, it lowers the FPs by 55%\nwith respect to other State-of-the-art models.", "AI": {"tldr": "Amatriciana\u662f\u4e00\u79cd\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u521b\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u68c0\u6d4b\u4ea4\u6613\u56fe\u4e2d\u7684\u6d17\u94b1\u8005\uff0c\u5229\u7528\u65f6\u95f4\u4fe1\u606f\u5e76\u6574\u5408\u5168\u56fe\u6570\u636e\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6a21\u578b\u5728\u5c0f\u6570\u636e\u91cf\u4e0b\u8868\u73b0\u826f\u597d\uff0c\u5927\u6570\u636e\u91cf\u4e0b\u4f18\u4e8e\u5176\u4ed6\u5148\u8fdb\u65b9\u6cd5\uff0cF1\u5f97\u5206\u4e3a0.76\uff0c\u5e76\u51cf\u5c1155%\u7684\u8bef\u62a5\u3002", "motivation": "\u6d17\u94b1\u5bf9\u91d1\u878d\u5b89\u5168\u548c\u793e\u4f1a\u7a33\u5b9a\u6784\u6210\u4e25\u91cd\u5a01\u80c1\uff0c\u4ea4\u6613\u91cf\u589e\u957f\u9700\u8981\u81ea\u52a8\u5de5\u5177\u8f85\u52a9\u6267\u6cd5\u673a\u6784\u68c0\u6d4b\u6b64\u7c7b\u72af\u7f6a\u6d3b\u52a8\u3002", "method": "\u63d0\u51faAmatriciana\u65b9\u6cd5\uff0c\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u6574\u5408\u5168\u56fe\u4ea4\u6613\u6570\u636e\uff08\u4e0d\u5206\u65f6\u95f4\u5b50\u56fe\uff09\uff0c\u5229\u7528\u65f6\u95f4\u4fe1\u606f\u548c\u5173\u7cfb\u6570\u636e\u3002", "result": "\u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\uff0c\u6a21\u578b\u5728\u5c0f\u6570\u636e\u91cf\u4e0b\u8868\u73b0\u826f\u597d\uff0c\u5927\u6570\u636e\u91cf\u4e0b\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0cF1\u5f97\u5206\u4e3a0.76\uff0c\u8bef\u62a5\u51cf\u5c1155%\u3002", "conclusion": "Amatriciana\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u6d17\u94b1\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u51cf\u5c11\u8bef\u62a5\u65b9\u9762\u8868\u73b0\u7a81\u51fa\u3002"}}
{"id": "2506.06276", "pdf": "https://arxiv.org/pdf/2506.06276", "abs": "https://arxiv.org/abs/2506.06276", "authors": ["Jiatao Gu", "Tianrong Chen", "David Berthelot", "Huangjie Zheng", "Yuyang Wang", "Ruixiang Zhang", "Laurent Dinh", "Miguel Angel Bautista", "Josh Susskind", "Shuangfei Zhai"], "title": "STARFlow: Scaling Latent Normalizing Flows for High-resolution Image Synthesis", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "TLDR: We show for the first time that normalizing flows can be scaled\n  for high-resolution and text-conditioned image synthesis", "summary": "We present STARFlow, a scalable generative model based on normalizing flows\nthat achieves strong performance in high-resolution image synthesis. The core\nof STARFlow is Transformer Autoregressive Flow (TARFlow), which combines the\nexpressive power of normalizing flows with the structured modeling capabilities\nof Autoregressive Transformers. We first establish the theoretical universality\nof TARFlow for modeling continuous distributions. Building on this foundation,\nwe introduce several key architectural and algorithmic innovations to\nsignificantly enhance scalability: (1) a deep-shallow design, wherein a deep\nTransformer block captures most of the model representational capacity,\ncomplemented by a few shallow Transformer blocks that are computationally\nefficient yet substantially beneficial; (2) modeling in the latent space of\npretrained autoencoders, which proves more effective than direct pixel-level\nmodeling; and (3) a novel guidance algorithm that significantly boosts sample\nquality. Crucially, our model remains an end-to-end normalizing flow, enabling\nexact maximum likelihood training in continuous spaces without discretization.\nSTARFlow achieves competitive performance in both class-conditional and\ntext-conditional image generation tasks, approaching state-of-the-art diffusion\nmodels in sample quality. To our knowledge, this work is the first successful\ndemonstration of normalizing flows operating effectively at this scale and\nresolution.", "AI": {"tldr": "STARFlow\u662f\u4e00\u79cd\u57fa\u4e8e\u6807\u51c6\u5316\u6d41\u7684\u53ef\u6269\u5c55\u751f\u6210\u6a21\u578b\uff0c\u7ed3\u5408\u4e86Transformer\u7684\u81ea\u56de\u5f52\u80fd\u529b\uff0c\u5728\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u5408\u6210\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u89e3\u51b3\u6807\u51c6\u5316\u6d41\u6a21\u578b\u5728\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u751f\u6210\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u548c\u6027\u80fd\u95ee\u9898\u3002", "method": "\u63d0\u51faTARFlow\uff0c\u7ed3\u5408\u6807\u51c6\u5316\u6d41\u548c\u81ea\u56de\u5f52Transformer\uff0c\u91c7\u7528\u6df1\u5ea6-\u6d45\u5c42\u8bbe\u8ba1\u3001\u6f5c\u5728\u7a7a\u95f4\u5efa\u6a21\u548c\u65b0\u578b\u5f15\u5bfc\u7b97\u6cd5\u3002", "result": "\u5728\u7c7b\u522b\u6761\u4ef6\u548c\u6587\u672c\u6761\u4ef6\u56fe\u50cf\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u63a5\u8fd1\u6269\u6563\u6a21\u578b\u7684\u6837\u672c\u8d28\u91cf\u3002", "conclusion": "STARFlow\u9996\u6b21\u8bc1\u660e\u6807\u51c6\u5316\u6d41\u5728\u5927\u89c4\u6a21\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u751f\u6210\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2506.06288", "pdf": "https://arxiv.org/pdf/2506.06288", "abs": "https://arxiv.org/abs/2506.06288", "authors": ["Xueying Ding", "Aakriti Mittal", "Achintya Gopal"], "title": "DELPHYNE: A Pre-Trained Model for General and Financial Time Series", "categories": ["q-fin.ST", "cs.AI", "cs.LG"], "comment": null, "summary": "Time-series data is a vital modality within data science communities. This is\nparticularly valuable in financial applications, where it helps in detecting\npatterns, understanding market behavior, and making informed decisions based on\nhistorical data. Recent advances in language modeling have led to the rise of\ntime-series pre-trained models that are trained on vast collections of datasets\nand applied to diverse tasks across financial domains. However, across\nfinancial applications, existing time-series pre-trained models have not shown\nboosts in performance over simple finance benchmarks in both zero-shot and\nfine-tuning settings. This phenomenon occurs because of a i) lack of financial\ndata within the pre-training stage, and ii) the negative transfer effect due to\ninherently different time-series patterns across domains. Furthermore,\ntime-series data is continuous, noisy, and can be collected at varying\nfrequencies and with varying lags across different variables, making this data\nmore challenging to model than languages. To address the above problems, we\nintroduce a Pre-trained MoDEL for FINance TimE-series (Delphyne). Delphyne\nachieves competitive performance to existing foundation and full-shot models\nwith few fine-tuning steps on publicly available datasets, and also shows\nsuperior performances on various financial tasks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDelphyne\u7684\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6a21\u578b\u5728\u91d1\u878d\u9886\u57df\u8868\u73b0\u4e0d\u4f73\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u65f6\u95f4\u5e8f\u5217\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u91d1\u878d\u5e94\u7528\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u4e3b\u8981\u7531\u4e8e\u7f3a\u4e4f\u91d1\u878d\u6570\u636e\u9884\u8bad\u7ec3\u548c\u8de8\u9886\u57df\u8d1f\u8fc1\u79fb\u6548\u5e94\u3002", "method": "\u63d0\u51fa\u4e86Delphyne\u6a21\u578b\uff0c\u9488\u5bf9\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684\u7279\u70b9\u8fdb\u884c\u4f18\u5316\u3002", "result": "Delphyne\u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f18\u4e8e\u73b0\u6709\u57fa\u7840\u6a21\u578b\u548c\u5168\u91cf\u5fae\u8c03\u6a21\u578b\u3002", "conclusion": "Delphyne\u4e3a\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.06299", "pdf": "https://arxiv.org/pdf/2506.06299", "abs": "https://arxiv.org/abs/2506.06299", "authors": ["Daniel Thilo Schroeder", "Meeyoung Cha", "Andrea Baronchelli", "Nick Bostrom", "Nicholas A. Christakis", "David Garcia", "Amit Goldenberg", "Yara Kyrychenko", "Kevin Leyton-Brown", "Nina Lutz", "Gary Marcus", "Filippo Menczer", "Gordon Pennycook", "David G. Rand", "Frank Schweitzer", "Christopher Summerfield", "Audrey Tang", "Jay Van Bavel", "Sander van der Linden", "Dawn Song", "Jonas R. Kunst"], "title": "How Malicious AI Swarms Can Threaten Democracy", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.LG"], "comment": "8 pages, 1 figure", "summary": "Advances in AI portend a new era of sophisticated disinformation operations.\nWhile individual AI systems already create convincing -- and at times\nmisleading -- information, an imminent development is the emergence of\nmalicious AI swarms. These systems can coordinate covertly, infiltrate\ncommunities, evade traditional detectors, and run continuous A/B tests, with\nround-the-clock persistence. The result can include fabricated grassroots\nconsensus, fragmented shared reality, mass harassment, voter micro-suppression\nor mobilization, contamination of AI training data, and erosion of\ninstitutional trust. With democratic processes worldwide increasingly\nvulnerable, we urge a three-pronged response: (1) platform-side defenses --\nalways-on swarm-detection dashboards, pre-election high-fidelity\nswarm-simulation stress-tests, transparency audits, and optional client-side\n\"AI shields\" for users; (2) model-side safeguards -- standardized\npersuasion-risk tests, provenance-authenticating passkeys, and watermarking;\nand (3) system-level oversight -- a UN-backed AI Influence Observatory.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86AI\u6076\u610f\u7fa4\u4f53\uff08swarms\uff09\u5bf9\u4fe1\u606f\u73af\u5883\u7684\u5a01\u80c1\uff0c\u63d0\u51fa\u4e86\u4e09\u65b9\u9762\u7684\u5e94\u5bf9\u63aa\u65bd\uff1a\u5e73\u53f0\u9632\u5fa1\u3001\u6a21\u578b\u4fdd\u62a4\u548c\u7cfb\u7edf\u76d1\u7ba1\u3002", "motivation": "\u968f\u7740AI\u6280\u672f\u7684\u8fdb\u6b65\uff0c\u6076\u610fAI\u7fa4\u4f53\u53ef\u80fd\u901a\u8fc7\u534f\u8c03\u884c\u52a8\u7834\u574f\u4fe1\u606f\u771f\u5b9e\u6027\uff0c\u5a01\u80c1\u6c11\u4e3b\u8fdb\u7a0b\uff0c\u4e9f\u9700\u5e94\u5bf9\u63aa\u65bd\u3002", "method": "\u63d0\u51fa\u4e09\u65b9\u9762\u89e3\u51b3\u65b9\u6848\uff1a\u5e73\u53f0\u9632\u5fa1\uff08\u5982\u7fa4\u4f53\u68c0\u6d4b\u4eea\u8868\u76d8\uff09\u3001\u6a21\u578b\u4fdd\u62a4\uff08\u5982\u6c34\u5370\u6280\u672f\uff09\u548c\u7cfb\u7edf\u76d1\u7ba1\uff08\u5982\u8054\u5408\u56fd\u652f\u6301\u7684AI\u5f71\u54cd\u89c2\u5bdf\u7ad9\uff09\u3002", "result": "\u6076\u610fAI\u7fa4\u4f53\u53ef\u80fd\u5bfc\u81f4\u865a\u5047\u5171\u8bc6\u3001\u4fe1\u606f\u788e\u7247\u5316\u7b49\u540e\u679c\uff0c\u5a01\u80c1\u793e\u4f1a\u4fe1\u4efb\u3002", "conclusion": "\u547c\u5401\u91c7\u53d6\u591a\u5c42\u6b21\u63aa\u65bd\u5e94\u5bf9AI\u6076\u610f\u7fa4\u4f53\uff0c\u4fdd\u62a4\u4fe1\u606f\u73af\u5883\u548c\u6c11\u4e3b\u5236\u5ea6\u3002"}}
{"id": "2506.06305", "pdf": "https://arxiv.org/pdf/2506.06305", "abs": "https://arxiv.org/abs/2506.06305", "authors": ["No\u00e9mie Bergues", "Arthur Carr\u00e9", "Paul Join-Lambert", "Brice Hoffmann", "Arnaud Blondel", "Hamza Tajmouati"], "title": "Template-Guided 3D Molecular Pose Generation via Flow Matching and Differentiable Optimization", "categories": ["q-bio.BM", "cs.LG"], "comment": null, "summary": "Predicting the 3D conformation of small molecules within protein binding\nsites is a key challenge in drug design. When a crystallized reference ligand\n(template) is available, it provides geometric priors that can guide 3D pose\nprediction. We present a two-stage method for ligand conformation generation\nguided by such templates. In the first stage, we introduce a molecular\nalignment approach based on flow-matching to generate 3D coordinates for the\nligand, using the template structure as a reference. In the second stage, a\ndifferentiable pose optimization procedure refines this conformation based on\nshape and pharmacophore similarities, internal energy, and, optionally, the\nprotein binding pocket. We evaluate our approach on a new benchmark of ligand\npairs co-crystallized with the same target and show that it outperforms\nstandard docking tools and open-access alignment methods, especially in cases\ninvolving low similarity to the template or high ligand flexibility.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u677f\u7684\u4e24\u9636\u6bb5\u65b9\u6cd5\uff0c\u7528\u4e8e\u9884\u6d4b\u5c0f\u5206\u5b50\u5728\u86cb\u767d\u8d28\u7ed3\u5408\u4f4d\u70b9\u76843D\u6784\u8c61\uff0c\u4f18\u4e8e\u73b0\u6709\u5de5\u5177\u3002", "motivation": "\u89e3\u51b3\u836f\u7269\u8bbe\u8ba1\u4e2d\u9884\u6d4b\u5c0f\u5206\u5b50\u5728\u86cb\u767d\u8d28\u7ed3\u5408\u4f4d\u70b93D\u6784\u8c61\u7684\u6311\u6218\uff0c\u5c24\u5176\u662f\u5f53\u5b58\u5728\u6a21\u677f\u65f6\u3002", "method": "\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a1) \u57fa\u4e8e\u6d41\u5339\u914d\u7684\u5206\u5b50\u5bf9\u9f50\u751f\u6210\u521d\u59cb3D\u5750\u6807\uff1b2) \u53ef\u5fae\u4f4d\u59ff\u4f18\u5316\uff0c\u8003\u8651\u5f62\u72b6\u3001\u836f\u6548\u56e2\u76f8\u4f3c\u6027\u3001\u5185\u80fd\u53ca\u86cb\u767d\u8d28\u7ed3\u5408\u53e3\u888b\u3002", "result": "\u5728\u65b0\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u6807\u51c6\u5bf9\u63a5\u5de5\u5177\u548c\u5f00\u653e\u5bf9\u9f50\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u6a21\u677f\u76f8\u4f3c\u6027\u4f4e\u6216\u914d\u4f53\u7075\u6d3b\u6027\u9ad8\u7684\u60c5\u51b5\u4e0b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u836f\u7269\u8bbe\u8ba1\u4e2d\u76843D\u6784\u8c61\u9884\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5c24\u5176\u5728\u6a21\u677f\u5f15\u5bfc\u4e0b\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2506.06306", "pdf": "https://arxiv.org/pdf/2506.06306", "abs": "https://arxiv.org/abs/2506.06306", "authors": ["Ali Abedi", "Charlene H. Chu", "Shehroz S. Khan"], "title": "Benchmarking Early Agitation Prediction in Community-Dwelling People with Dementia Using Multimodal Sensors and Machine Learning", "categories": ["eess.SP", "cs.CV", "cs.HC", "cs.LG"], "comment": "16 pages, 4 figures, 2 tables", "summary": "Agitation is one of the most common responsive behaviors in people living\nwith dementia, particularly among those residing in community settings without\ncontinuous clinical supervision. Timely prediction of agitation can enable\nearly intervention, reduce caregiver burden, and improve the quality of life\nfor both patients and caregivers. This study aimed to develop and benchmark\nmachine learning approaches for the early prediction of agitation in\ncommunity-dwelling older adults with dementia using multimodal sensor data. A\nnew set of agitation-related contextual features derived from activity data was\nintroduced and employed for agitation prediction. A wide range of machine\nlearning and deep learning models was evaluated across multiple problem\nformulations, including binary classification for single-timestamp tabular\nsensor data and multi-timestamp sequential sensor data, as well as anomaly\ndetection for single-timestamp tabular sensor data. The study utilized the\nTechnology Integrated Health Management (TIHM) dataset, the largest publicly\navailable dataset for remote monitoring of people living with dementia,\ncomprising 2,803 days of in-home activity, physiology, and sleep data. The most\neffective setting involved binary classification of sensor data using the\ncurrent 6-hour timestamp to predict agitation at the subsequent timestamp.\nIncorporating additional information, such as time of day and agitation\nhistory, further improved model performance, with the highest AUC-ROC of 0.9720\nand AUC-PR of 0.4320 achieved by the light gradient boosting machine. This work\npresents the first comprehensive benchmarking of state-of-the-art techniques\nfor agitation prediction in community-based dementia care using\nprivacy-preserving sensor data. The approach enables accurate, explainable, and\nefficient agitation prediction, supporting proactive dementia care and aging in\nplace.", "AI": {"tldr": "\u7814\u7a76\u65e8\u5728\u5229\u7528\u591a\u6a21\u6001\u4f20\u611f\u5668\u6570\u636e\u5f00\u53d1\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u65e9\u671f\u9884\u6d4b\u793e\u533a\u5c45\u4f4f\u75f4\u5446\u60a3\u8005\u7684\u8e81\u52a8\u884c\u4e3a\uff0c\u5f15\u5165\u65b0\u7684\u4e0a\u4e0b\u6587\u7279\u5f81\u5e76\u8bc4\u4f30\u591a\u79cd\u6a21\u578b\uff0c\u6700\u7ec8\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u9884\u6d4b\u3002", "motivation": "\u8e81\u52a8\u662f\u75f4\u5446\u60a3\u8005\u5e38\u89c1\u884c\u4e3a\uff0c\u53ca\u65f6\u9884\u6d4b\u53ef\u51cf\u5c11\u62a4\u7406\u8d1f\u62c5\u5e76\u6539\u5584\u751f\u6d3b\u8d28\u91cf\u3002", "method": "\u4f7f\u7528TIHM\u6570\u636e\u96c6\uff0c\u5f15\u5165\u65b0\u7279\u5f81\uff0c\u8bc4\u4f30\u591a\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff08\u5305\u62ec\u4e8c\u5206\u7c7b\u548c\u5f02\u5e38\u68c0\u6d4b\uff09\u3002", "result": "\u6700\u4f73\u6a21\u578bAUC-ROC\u8fbe0.9720\uff0cAUC-PR\u4e3a0.4320\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u652f\u6301\u9ad8\u6548\u3001\u53ef\u89e3\u91ca\u7684\u8e81\u52a8\u9884\u6d4b\uff0c\u6709\u52a9\u4e8e\u4e3b\u52a8\u62a4\u7406\u548c\u5c45\u5bb6\u517b\u8001\u3002"}}
{"id": "2506.06308", "pdf": "https://arxiv.org/pdf/2506.06308", "abs": "https://arxiv.org/abs/2506.06308", "authors": ["Adoubi Vincent De Paul Adombi"], "title": "Scientific machine learning in Hydrology: a unified perspective", "categories": ["physics.comp-ph", "cs.LG", "physics.data-an"], "comment": null, "summary": "Scientific machine learning (SciML) provides a structured approach to\nintegrating physical knowledge into data-driven modeling, offering significant\npotential for advancing hydrological research. In recent years, multiple\nmethodological families have emerged, including physics-informed machine\nlearning, physics-guided machine learning, hybrid physics-machine learning, and\ndata-driven physics discovery. Within each of these families, a proliferation\nof heterogeneous approaches has developed independently, often without\nconceptual coordination. This fragmentation complicates the assessment of\nmethodological novelty and makes it difficult to identify where meaningful\nadvances can still be made in the absence of a unified conceptual framework.\nThis review, the first focused overview of SciML in hydrology, addresses these\nlimitations by proposing a unified methodological framework for each SciML\nfamily, bringing together representative contributions into a coherent\nstructure that fosters conceptual clarity and supports cumulative progress in\nhydrological modeling. Finally, we highlight the limitations and future\nopportunities of each unified family to guide systematic research in hydrology,\nwhere these methods remain underutilized.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7efc\u8ff0\u4e86\u79d1\u5b66\u673a\u5668\u5b66\u4e60\uff08SciML\uff09\u5728\u6c34\u6587\u5b66\u4e2d\u7684\u5e94\u7528\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u65b9\u6cd5\u6846\u67b6\uff0c\u4ee5\u89e3\u51b3\u5f53\u524d\u65b9\u6cd5\u788e\u7247\u5316\u7684\u95ee\u9898\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u5f53\u524d\u6c34\u6587\u5b66\u4e2dSciML\u65b9\u6cd5\u7f3a\u4e4f\u7edf\u4e00\u6846\u67b6\uff0c\u5bfc\u81f4\u65b9\u6cd5\u788e\u7247\u5316\uff0c\u96be\u4ee5\u8bc4\u4f30\u521b\u65b0\u6027\u548c\u8fdb\u5c55\u6f5c\u529b\u3002", "method": "\u901a\u8fc7\u5206\u7c7b\u6574\u7406\u7269\u7406\u77e5\u8bc6\u9a71\u52a8\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff08\u5982\u7269\u7406\u4fe1\u606f\u673a\u5668\u5b66\u4e60\u3001\u7269\u7406\u5f15\u5bfc\u673a\u5668\u5b66\u4e60\u7b49\uff09\uff0c\u63d0\u51fa\u7edf\u4e00\u6846\u67b6\u3002", "result": "\u6784\u5efa\u4e86\u4e00\u4e2a\u4fc3\u8fdb\u6982\u5ff5\u6e05\u6670\u548c\u652f\u6301\u7d2f\u79ef\u8fdb\u5c55\u7684SciML\u65b9\u6cd5\u6846\u67b6\u3002", "conclusion": "\u8bba\u6587\u4e3a\u6c34\u6587\u5b66\u4e2d\u7684SciML\u7814\u7a76\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u6307\u5bfc\uff0c\u5e76\u5f3a\u8c03\u4e86\u672a\u6765\u7814\u7a76\u7684\u5c40\u9650\u6027\u53ca\u673a\u4f1a\u3002"}}
{"id": "2506.06309", "pdf": "https://arxiv.org/pdf/2506.06309", "abs": "https://arxiv.org/abs/2506.06309", "authors": ["Mohamed Kefi", "Tien Dat Pham", "Thin Nguyen", "Mark G. Tjoelker", "Viola Devasirvatham", "Kenichi Kashiwagi"], "title": "Leveraging Novel Ensemble Learning Techniques and Landsat Multispectral Data for Estimating Olive Yields in Tunisia", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "Olive production is an important tree crop in Mediterranean climates.\nHowever, olive yield varies significantly due to climate change. Accurately\nestimating yield using remote sensing and machine learning remains a complex\nchallenge. In this study, we developed a streamlined pipeline for olive yield\nestimation in the Kairouan and Sousse governorates of Tunisia. We extracted\nfeatures from multispectral reflectance bands, vegetation indices derived from\nLandsat-8 OLI and Landsat-9 OLI-2 satellite imagery, along with digital\nelevation model data. These spatial features were combined with ground-based\nfield survey data to form a structured tabular dataset. We then developed an\nautomated ensemble learning framework, implemented using AutoGluon to train and\nevaluate multiple machine learning models, select optimal combinations through\nstacking, and generate robust yield predictions using five-fold\ncross-validation. The results demonstrate strong predictive performance from\nboth sensors, with Landsat-8 OLI achieving R2 = 0.8635 and RMSE = 1.17 tons per\nha, and Landsat-9 OLI-2 achieving R2 = 0.8378 and RMSE = 1.32 tons per ha. This\nstudy highlights a scalable, cost-effective, and accurate method for olive\nyield estimation, with potential applicability across diverse agricultural\nregions globally.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u9065\u611f\u548c\u673a\u5668\u5b66\u4e60\u7684\u81ea\u52a8\u5316\u6a44\u6984\u4ea7\u91cf\u4f30\u7b97\u6846\u67b6\uff0c\u7ed3\u5408\u591a\u5149\u8c31\u6570\u636e\u548c\u5b9e\u5730\u8c03\u67e5\uff0c\u53d6\u5f97\u4e86\u9ad8\u7cbe\u5ea6\u7684\u9884\u6d4b\u7ed3\u679c\u3002", "motivation": "\u6c14\u5019\u53d8\u5316\u5bfc\u81f4\u6a44\u6984\u4ea7\u91cf\u6ce2\u52a8\u5927\uff0c\u9700\u8981\u4e00\u79cd\u51c6\u786e\u4e14\u53ef\u6269\u5c55\u7684\u4f30\u7b97\u65b9\u6cd5\u3002", "method": "\u5229\u7528Landsat-8\u548cLandsat-9\u7684\u591a\u5149\u8c31\u6570\u636e\u3001\u690d\u88ab\u6307\u6570\u548c\u6570\u5b57\u9ad8\u7a0b\u6a21\u578b\uff0c\u7ed3\u5408\u5b9e\u5730\u8c03\u67e5\u6570\u636e\uff0c\u901a\u8fc7AutoGluon\u6784\u5efa\u81ea\u52a8\u5316\u96c6\u6210\u5b66\u4e60\u6846\u67b6\u3002", "result": "Landsat-8\u548cLandsat-9\u7684\u9884\u6d4b\u6027\u80fd\u5747\u8f83\u5f3a\uff0cR2\u5206\u522b\u4e3a0.8635\u548c0.8378\uff0cRMSE\u5206\u522b\u4e3a1.17\u548c1.32\u5428/\u516c\u9877\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5177\u6709\u53ef\u6269\u5c55\u6027\u3001\u6210\u672c\u6548\u76ca\u548c\u51c6\u786e\u6027\uff0c\u9002\u7528\u4e8e\u5168\u7403\u591a\u6837\u5316\u7684\u519c\u4e1a\u533a\u57df\u3002"}}
{"id": "2506.06310", "pdf": "https://arxiv.org/pdf/2506.06310", "abs": "https://arxiv.org/abs/2506.06310", "authors": ["Xiaoyu Sun", "Yang Yang", "Xunde Dong"], "title": "Enhancing Contrastive Learning-based Electrocardiogram Pretrained Model with Patient Memory Queue", "categories": ["eess.SP", "cs.LG", "eess.IV"], "comment": "8 pages, 4 figures", "summary": "In the field of automatic Electrocardiogram (ECG) diagnosis, due to the\nrelatively limited amount of labeled data, how to build a robust ECG pretrained\nmodel based on unlabeled data is a key area of focus for researchers. Recent\nadvancements in contrastive learning-based ECG pretrained models highlight the\npotential of exploiting the additional patient-level self-supervisory signals\ninherent in ECG. They are referred to as patient contrastive learning. Its\nrationale is that multiple physical recordings from the same patient may share\ncommonalities, termed patient consistency, so redefining positive and negative\npairs in contrastive learning as intrapatient and inter-patient samples\nprovides more shared context to learn an effective representation. However,\nthese methods still fail to efficiently exploit patient consistency due to the\ninsufficient amount of intra-inter patient samples existing in a batch. Hence,\nwe propose a contrastive learning-based ECG pretrained model enhanced by the\nPatient Memory Queue (PMQ), which incorporates a large patient memory queue to\nmitigate model degeneration that can arise from insufficient intra-inter\npatient samples. In order to further enhance the performance of the pretrained\nmodel, we introduce two extra data augmentation methods to provide more\nperspectives of positive and negative pairs for pretraining. Extensive\nexperiments were conducted on three public datasets with three different data\nratios. The experimental results show that the comprehensive performance of our\nmethod outperforms previous contrastive learning methods and exhibits greater\nrobustness in scenarios with limited labeled data. The code is available at\nhttps://github.com/3hiuwoo/PMQ.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u60a3\u8005\u8bb0\u5fc6\u961f\u5217\uff08PMQ\uff09\u7684\u5bf9\u6bd4\u5b66\u4e60ECG\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u901a\u8fc7\u589e\u5f3a\u60a3\u8005\u4e00\u81f4\u6027\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u7531\u4e8e\u6807\u8bb0\u6570\u636e\u6709\u9650\uff0c\u5982\u4f55\u5229\u7528\u672a\u6807\u8bb0\u6570\u636e\u6784\u5efa\u9c81\u68d2\u7684ECG\u9884\u8bad\u7ec3\u6a21\u578b\u662f\u5173\u952e\u3002\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u5229\u7528\u60a3\u8005\u4e00\u81f4\u6027\u3002", "method": "\u5f15\u5165\u60a3\u8005\u8bb0\u5fc6\u961f\u5217\uff08PMQ\uff09\u4ee5\u89e3\u51b3\u6279\u6b21\u5185\u60a3\u8005\u6837\u672c\u4e0d\u8db3\u95ee\u9898\uff0c\u5e76\u91c7\u7528\u4e24\u79cd\u989d\u5916\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\uff0c\u4e14\u5728\u6807\u8bb0\u6570\u636e\u6709\u9650\u65f6\u66f4\u5177\u9c81\u68d2\u6027\u3002", "conclusion": "PMQ\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86ECG\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5c24\u5176\u5728\u6570\u636e\u7a00\u7f3a\u573a\u666f\u4e0b\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2506.06311", "pdf": "https://arxiv.org/pdf/2506.06311", "abs": "https://arxiv.org/abs/2506.06311", "authors": ["Meiyan Kang", "Shizuo Kaji", "Sang-Yun Lee", "Taegon Kim", "Hee-Hwan Ryu", "Suyoung Choi"], "title": "A Novel Shape-Aware Topological Representation for GPR Data with DNN Integration", "categories": ["eess.SP", "cs.LG"], "comment": "15 pages, 6 figures", "summary": "Ground Penetrating Radar (GPR) is a widely used Non-Destructive Testing (NDT)\ntechnique for subsurface exploration, particularly in infrastructure inspection\nand maintenance. However, conventional interpretation methods are often limited\nby noise sensitivity and a lack of structural awareness. This study presents a\nnovel framework that enhances the detection of underground utilities,\nespecially pipelines, by integrating shape-aware topological features derived\nfrom B-scan GPR images using Topological Data Analysis (TDA), with the spatial\ndetection capabilities of the YOLOv5 deep neural network (DNN). We propose a\nnovel shape-aware topological representation that amplifies structural features\nin the input data, thereby improving the model's responsiveness to the\ngeometrical features of buried objects. To address the scarcity of annotated\nreal-world data, we employ a Sim2Real strategy that generates diverse and\nrealistic synthetic datasets, effectively bridging the gap between simulated\nand real-world domains. Experimental results demonstrate significant\nimprovements in mean Average Precision (mAP), validating the robustness and\nefficacy of our approach. This approach underscores the potential of\nTDA-enhanced learning in achieving reliable, real-time subsurface object\ndetection, with broad applications in urban planning, safety inspection, and\ninfrastructure management.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u62d3\u6251\u6570\u636e\u5206\u6790\u548cYOLOv5\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u589e\u5f3a\u5730\u4e0b\u7ba1\u7ebf\u7684\u68c0\u6d4b\u80fd\u529b\uff0c\u5e76\u901a\u8fc7Sim2Real\u7b56\u7565\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u7684\u5730\u9762\u7a7f\u900f\u96f7\u8fbe\uff08GPR\uff09\u89e3\u91ca\u65b9\u6cd5\u5728\u566a\u58f0\u654f\u611f\u6027\u548c\u7ed3\u6784\u611f\u77e5\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5f71\u54cd\u4e86\u5730\u4e0b\u7ba1\u7ebf\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u3002", "method": "\u901a\u8fc7\u62d3\u6251\u6570\u636e\u5206\u6790\uff08TDA\uff09\u4eceB-scan GPR\u56fe\u50cf\u4e2d\u63d0\u53d6\u5f62\u72b6\u611f\u77e5\u7684\u62d3\u6251\u7279\u5f81\uff0c\u5e76\u4e0eYOLOv5\u7ed3\u5408\uff0c\u540c\u65f6\u91c7\u7528Sim2Real\u7b56\u7565\u751f\u6210\u5408\u6210\u6570\u636e\u4ee5\u5f25\u8865\u771f\u5b9e\u6570\u636e\u7684\u4e0d\u8db3\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u5e73\u5747\u7cbe\u5ea6\uff08mAP\uff09\u4e0a\u6709\u663e\u8457\u63d0\u5347\uff0c\u9a8c\u8bc1\u4e86\u5176\u9c81\u68d2\u6027\u548c\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86TDA\u589e\u5f3a\u5b66\u4e60\u5728\u5b9e\u65f6\u5730\u4e0b\u7269\u4f53\u68c0\u6d4b\u4e2d\u7684\u6f5c\u529b\uff0c\u9002\u7528\u4e8e\u57ce\u5e02\u89c4\u5212\u3001\u5b89\u5168\u68c0\u67e5\u548c\u57fa\u7840\u8bbe\u65bd\u7ba1\u7406\u7b49\u9886\u57df\u3002"}}
{"id": "2506.06315", "pdf": "https://arxiv.org/pdf/2506.06315", "abs": "https://arxiv.org/abs/2506.06315", "authors": ["Masoud Rahimi", "Reza Karbasi", "Abdol-Hossein Vahabie"], "title": "An Open-Source Python Framework and Synthetic ECG Image Datasets for Digitization, Lead and Lead Name Detection, and Overlapping Signal Segmentation", "categories": ["eess.SP", "cs.CV", "cs.LG"], "comment": "5 pages, 5 figures", "summary": "We introduce an open-source Python framework for generating synthetic ECG\nimage datasets to advance critical deep learning-based tasks in ECG analysis,\nincluding ECG digitization, lead region and lead name detection, and\npixel-level waveform segmentation. Using the PTB-XL signal dataset, our\nproposed framework produces four open-access datasets: (1) ECG images in\nvarious lead configurations paired with time-series signals for ECG\ndigitization, (2) ECG images annotated with YOLO-format bounding boxes for\ndetection of lead region and lead name, (3)-(4) cropped single-lead images with\nsegmentation masks compatible with U-Net-based models in normal and overlapping\nversions. In the overlapping case, waveforms from neighboring leads are\nsuperimposed onto the target lead image, while the segmentation masks remain\nclean. The open-source Python framework and datasets are publicly available at\nhttps://github.com/rezakarbasi/ecg-image-and-signal-dataset and\nhttps://doi.org/10.5281/zenodo.15484519, respectively.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u5f00\u6e90Python\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210\u5408\u6210ECG\u56fe\u50cf\u6570\u636e\u96c6\uff0c\u652f\u6301\u6df1\u5ea6\u5b66\u4e60\u4efb\u52a1\u5982ECG\u6570\u5b57\u5316\u3001\u5bfc\u8054\u533a\u57df\u548c\u540d\u79f0\u68c0\u6d4b\u4ee5\u53ca\u6ce2\u5f62\u5206\u5272\u3002", "motivation": "\u63a8\u52a8ECG\u5206\u6790\u4e2d\u7684\u6df1\u5ea6\u5b66\u4e60\u4efb\u52a1\uff0c\u63d0\u4f9b\u591a\u6837\u5316\u7684\u6570\u636e\u96c6\u4ee5\u652f\u6301\u7814\u7a76\u3002", "method": "\u5229\u7528PTB-XL\u4fe1\u53f7\u6570\u636e\u96c6\u751f\u6210\u56db\u79cd\u5f00\u653e\u6570\u636e\u96c6\uff0c\u5305\u62ec\u56fe\u50cf\u4e0e\u4fe1\u53f7\u914d\u5bf9\u3001YOLO\u683c\u5f0f\u6807\u6ce8\u3001\u5355\u5bfc\u8054\u5206\u5272\u63a9\u7801\u7b49\u3002", "result": "\u53d1\u5e03\u4e86\u5f00\u6e90\u6846\u67b6\u548c\u56db\u79cd\u6570\u636e\u96c6\uff0c\u652f\u6301\u591a\u79cdECG\u5206\u6790\u4efb\u52a1\u3002", "conclusion": "\u8be5\u6846\u67b6\u548c\u6570\u636e\u96c6\u4e3aECG\u5206\u6790\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u8d44\u6e90\uff0c\u4fc3\u8fdb\u6df1\u5ea6\u5b66\u4e60\u5e94\u7528\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.06323", "pdf": "https://arxiv.org/pdf/2506.06323", "abs": "https://arxiv.org/abs/2506.06323", "authors": ["Abdullah Burkan Bereketoglu"], "title": "Composite Reward Design in PPO-Driven Adaptive Filtering", "categories": ["eess.SP", "cs.LG", "cs.SY", "eess.SY"], "comment": "5 pages, 9 figures, 1 table, , Keywords: Adaptive filtering,\n  reinforcement learning, PPO, noise reduction, signal denoising", "summary": "Model-free and reinforcement learning-based adaptive filtering methods are\ngaining traction for denoising in dynamic, non-stationary environments such as\nwireless signal channels. Traditional filters like LMS, RLS, Wiener, and Kalman\nare limited by assumptions of stationary or requiring complex fine-tuning or\nexact noise statistics or fixed models. This letter proposes an adaptive\nfiltering framework using Proximal Policy Optimization (PPO), guided by a\ncomposite reward that balances SNR improvement, MSE reduction, and residual\nsmoothness. Experiments on synthetic signals with various noise types show that\nour PPO agent generalizes beyond its training distribution, achieving real-time\nperformance and outperforming classical filters. This work demonstrates the\nviability of policy-gradient reinforcement learning for robust, low-latency\nadaptive signal filtering.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8ePPO\u7684\u81ea\u9002\u5e94\u6ee4\u6ce2\u6846\u67b6\uff0c\u7528\u4e8e\u52a8\u6001\u975e\u5e73\u7a33\u73af\u5883\u4e2d\u7684\u53bb\u566a\uff0c\u4f18\u4e8e\u4f20\u7edf\u6ee4\u6ce2\u5668\u3002", "motivation": "\u4f20\u7edf\u6ee4\u6ce2\u5668\uff08\u5982LMS\u3001RLS\u7b49\uff09\u5728\u52a8\u6001\u975e\u5e73\u7a33\u73af\u5883\u4e2d\u8868\u73b0\u53d7\u9650\uff0c\u9700\u8981\u590d\u6742\u8c03\u53c2\u6216\u56fa\u5b9a\u6a21\u578b\u5047\u8bbe\u3002", "method": "\u4f7f\u7528PPO\u7b97\u6cd5\uff0c\u901a\u8fc7\u590d\u5408\u5956\u52b1\u51fd\u6570\uff08SNR\u63d0\u5347\u3001MSE\u964d\u4f4e\u548c\u6b8b\u5dee\u5e73\u6ed1\uff09\u6307\u5bfc\u81ea\u9002\u5e94\u6ee4\u6ce2\u3002", "result": "\u5728\u5408\u6210\u4fe1\u53f7\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0cPPO\u6ee4\u6ce2\u5668\u6cdb\u5316\u80fd\u529b\u5f3a\uff0c\u5b9e\u65f6\u6027\u80fd\u4f18\u8d8a\uff0c\u8d85\u8d8a\u4f20\u7edf\u6ee4\u6ce2\u5668\u3002", "conclusion": "\u8bc1\u660e\u4e86\u7b56\u7565\u68af\u5ea6\u5f3a\u5316\u5b66\u4e60\u5728\u9c81\u68d2\u3001\u4f4e\u5ef6\u8fdf\u81ea\u9002\u5e94\u4fe1\u53f7\u6ee4\u6ce2\u4e2d\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2506.06332", "pdf": "https://arxiv.org/pdf/2506.06332", "abs": "https://arxiv.org/abs/2506.06332", "authors": ["Mikko Stenlund"], "title": "Introduction to Predictive Coding Networks for Machine Learning", "categories": ["cs.NE", "cs.AI", "cs.LG"], "comment": "22 pages", "summary": "Predictive coding networks (PCNs) constitute a biologically inspired\nframework for understanding hierarchical computation in the brain, and offer an\nalternative to traditional feedforward neural networks in ML. This note serves\nas a quick, onboarding introduction to PCNs for machine learning practitioners.\nWe cover the foundational network architecture, inference and learning update\nrules, and algorithmic implementation. A concrete image-classification task\n(CIFAR-10) is provided as a benchmark-smashing application, together with an\naccompanying Python notebook containing the PyTorch implementation.", "AI": {"tldr": "\u672c\u6587\u7b80\u8981\u4ecb\u7ecd\u4e86\u9884\u6d4b\u7f16\u7801\u7f51\u7edc\uff08PCNs\uff09\u53ca\u5176\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u5e94\u7528\uff0c\u5305\u62ec\u67b6\u6784\u3001\u63a8\u7406\u548c\u5b66\u4e60\u89c4\u5219\uff0c\u5e76\u901a\u8fc7CIFAR-10\u4efb\u52a1\u5c55\u793a\u4e86\u5176\u6027\u80fd\u3002", "motivation": "\u4e3a\u673a\u5668\u5b66\u4e60\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e00\u4e2a\u5feb\u901f\u4e86\u89e3PCNs\u7684\u5165\u95e8\u6307\u5357\uff0c\u5c55\u793a\u5176\u4f5c\u4e3a\u4f20\u7edf\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u66ff\u4ee3\u65b9\u6848\u7684\u6f5c\u529b\u3002", "method": "\u4ecb\u7ecd\u4e86PCNs\u7684\u57fa\u7840\u67b6\u6784\u3001\u63a8\u7406\u548c\u5b66\u4e60\u89c4\u5219\uff0c\u5e76\u63d0\u4f9b\u4e86PyTorch\u5b9e\u73b0\u7684Python\u7b14\u8bb0\u672c\u3002", "result": "\u901a\u8fc7CIFAR-10\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u9a8c\u8bc1\u4e86PCNs\u7684\u6027\u80fd\uff0c\u5c55\u793a\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "PCNs\u662f\u4e00\u79cd\u6709\u524d\u666f\u7684\u751f\u7269\u542f\u53d1\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u5206\u5c42\u8ba1\u7b97\u4efb\u52a1\uff0c\u5e76\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2506.06334", "pdf": "https://arxiv.org/pdf/2506.06334", "abs": "https://arxiv.org/abs/2506.06334", "authors": ["Alexandre Bouras", "Audrey Durand", "Richard Khoury"], "title": "Preference-based learning for news headline recommendation", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "This study explores strategies for optimizing news headline recommendations\nthrough preference-based learning. Using real-world data of user interactions\nwith French-language online news posts, we learn a headline recommender agent\nunder a contextual bandit setting. This allows us to explore the impact of\ntranslation on engagement predictions, as well as the benefits of different\ninteractive strategies on user engagement during data collection. Our results\nshow that explicit exploration may not be required in the presence of noisy\ncontexts, opening the door to simpler but efficient strategies in practice.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u504f\u597d\u5b66\u4e60\u4f18\u5316\u65b0\u95fb\u6807\u9898\u63a8\u8350\uff0c\u53d1\u73b0\u566a\u58f0\u73af\u5883\u4e0b\u663e\u5f0f\u63a2\u7d22\u53ef\u80fd\u4e0d\u5fc5\u8981\u3002", "motivation": "\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u504f\u597d\u5b66\u4e60\u4f18\u5316\u65b0\u95fb\u6807\u9898\u63a8\u8350\uff0c\u5e76\u7814\u7a76\u7ffb\u8bd1\u5bf9\u7528\u6237\u53c2\u4e0e\u5ea6\u9884\u6d4b\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u771f\u5b9e\u7528\u6237\u4e92\u52a8\u6570\u636e\uff0c\u5728\u4e0a\u4e0b\u6587\u8001\u864e\u673a\u8bbe\u7f6e\u4e0b\u8bad\u7ec3\u6807\u9898\u63a8\u8350\u4ee3\u7406\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u5728\u566a\u58f0\u73af\u5883\u4e0b\uff0c\u663e\u5f0f\u63a2\u7d22\u53ef\u80fd\u4e0d\u5fc5\u8981\uff0c\u53ef\u91c7\u7528\u66f4\u7b80\u5355\u9ad8\u6548\u7684\u7b56\u7565\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5b9e\u8df5\u4e2d\u7b80\u5316\u4f46\u9ad8\u6548\u7684\u63a8\u8350\u7b56\u7565\u63d0\u4f9b\u4e86\u53ef\u80fd\u6027\u3002"}}
{"id": "2506.06342", "pdf": "https://arxiv.org/pdf/2506.06342", "abs": "https://arxiv.org/abs/2506.06342", "authors": ["Mohd Ashhad", "Sana Rahmani", "Mohammed Fayiz", "Ali Etemad", "Javad Hashemi"], "title": "Uncertainty-Aware Multi-view Arrhythmia Classification from ECG", "categories": ["eess.SP", "cs.LG"], "comment": "This paper has been accepted to IJCNN 2024 conference", "summary": "We propose a deep neural architecture that performs uncertainty-aware\nmulti-view classification of arrhythmia from ECG. Our method learns two\ndifferent views (1D and 2D) of single-lead ECG to capture different types of\ninformation. We use a fusion technique to reduce the conflict between the\ndifferent views caused by noise and artifacts in ECG data, thus incorporating\nuncertainty to obtain stronger final predictions. Our framework contains the\nfollowing three modules (1) a time-series module to learn the morphological\nfeatures from ECG; (2) an image-space learning module to learn the\nspatiotemporal features; and (3) the uncertainty-aware fusion module to fuse\nthe information from the two different views. Experimental results on two\nreal-world datasets demonstrate that our framework not only improves the\nperformance on arrhythmia classification compared to the state-of-the-art but\nalso shows better robustness to noise and artifacts present in ECG.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u7528\u4e8eECG\u5fc3\u5f8b\u5931\u5e38\u7684\u591a\u89c6\u89d2\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u5206\u7c7b\uff0c\u901a\u8fc7\u878d\u54081D\u548c2D\u89c6\u56fe\u51cf\u5c11\u566a\u58f0\u5e72\u6270\uff0c\u63d0\u5347\u5206\u7c7b\u6027\u80fd\u548c\u9c81\u68d2\u6027\u3002", "motivation": "ECG\u6570\u636e\u4e2d\u7684\u566a\u58f0\u548c\u4f2a\u5f71\u53ef\u80fd\u5bfc\u81f4\u591a\u89c6\u89d2\u4fe1\u606f\u51b2\u7a81\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u878d\u5408\u4e0d\u540c\u89c6\u56fe\u5e76\u5f15\u5165\u4e0d\u786e\u5b9a\u6027\u4ee5\u63d0\u9ad8\u5206\u7c7b\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "method": "\u5305\u542b\u4e09\u4e2a\u6a21\u5757\uff1a(1) \u65f6\u95f4\u5e8f\u5217\u6a21\u5757\u5b66\u4e60ECG\u5f62\u6001\u7279\u5f81\uff1b(2) \u56fe\u50cf\u7a7a\u95f4\u6a21\u5757\u5b66\u4e60\u65f6\u7a7a\u7279\u5f81\uff1b(3) \u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u878d\u5408\u6a21\u5757\u878d\u5408\u591a\u89c6\u89d2\u4fe1\u606f\u3002", "result": "\u5728\u4e24\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u5206\u7c7b\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5bf9\u566a\u58f0\u548c\u4f2a\u5f71\u8868\u73b0\u66f4\u9c81\u68d2\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u591a\u89c6\u89d2\u878d\u5408\u548c\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\uff0c\u663e\u8457\u63d0\u5347\u4e86ECG\u5fc3\u5f8b\u5931\u5e38\u5206\u7c7b\u7684\u6027\u80fd\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2506.06343", "pdf": "https://arxiv.org/pdf/2506.06343", "abs": "https://arxiv.org/abs/2506.06343", "authors": ["Taesoo Kim", "Jong Hwan Ko"], "title": "TESU-LLM: Training Speech-LLMs Without Speech via Unified Encoder Alignment", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SD", "eess.AS"], "comment": null, "summary": "Recent advances in speech-enabled language models have shown promising\nresults in building intelligent voice assistants. However, most existing\napproaches rely on large-scale paired speech-text data and extensive\ncomputational resources, which pose challenges in terms of scalability and\naccessibility. In this paper, we present \\textbf{TESU-LLM}, a novel framework\nthat enables training speech-capable language models using only text data. Our\nkey insight is to leverage a unified encoder that maps semantically equivalent\ntext and speech inputs to a shared latent space. By aligning the encoder output\nwith the embedding space of a LLM via a lightweight projection network, we\nenable the model to generalize from text-only supervision to speech-based\ninference. Despite being trained exclusively on text, TESU-LLM achieves strong\nperformance on various speech-related benchmarks, comparable to baseline\nmethods trained with large-scale multimodal datasets and substantial\ncomputational resources. These results highlight the effectiveness and\nefficiency of our approach, offering a scalable path toward building speech\nLLMs without speech data.", "AI": {"tldr": "TESU-LLM\u662f\u4e00\u79cd\u4ec5\u7528\u6587\u672c\u6570\u636e\u8bad\u7ec3\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u7edf\u4e00\u7f16\u7801\u5668\u548c\u8f7b\u91cf\u7ea7\u6295\u5f71\u7f51\u7edc\u5b9e\u73b0\u8bed\u97f3\u63a8\u7406\uff0c\u6027\u80fd\u5ab2\u7f8e\u591a\u6a21\u6001\u6570\u636e\u8bad\u7ec3\u7684\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\u4f9d\u8d56\u5927\u89c4\u6a21\u914d\u5bf9\u8bed\u97f3-\u6587\u672c\u6570\u636e\u548c\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\uff0c\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u548c\u53ef\u8bbf\u95ee\u6027\u3002", "method": "\u5229\u7528\u7edf\u4e00\u7f16\u7801\u5668\u5c06\u8bed\u4e49\u7b49\u6548\u7684\u6587\u672c\u548c\u8bed\u97f3\u8f93\u5165\u6620\u5c04\u5230\u5171\u4eab\u6f5c\u5728\u7a7a\u95f4\uff0c\u5e76\u901a\u8fc7\u8f7b\u91cf\u7ea7\u6295\u5f71\u7f51\u7edc\u4e0eLLM\u5d4c\u5165\u7a7a\u95f4\u5bf9\u9f50\uff0c\u5b9e\u73b0\u4ec5\u7528\u6587\u672c\u76d1\u7763\u8bad\u7ec3\u3002", "result": "TESU-LLM\u5728\u591a\u4e2a\u8bed\u97f3\u76f8\u5173\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u6027\u80fd\u63a5\u8fd1\u57fa\u4e8e\u591a\u6a21\u6001\u6570\u636e\u8bad\u7ec3\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "TESU-LLM\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u8bed\u97f3\u6570\u636e\u7684\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\u6784\u5efa\u65b9\u6cd5\u3002"}}
{"id": "2506.06344", "pdf": "https://arxiv.org/pdf/2506.06344", "abs": "https://arxiv.org/abs/2506.06344", "authors": ["Alex Pierron", "Michel Barbeau", "Luca De Cicco", "Jose Rubio-Hernan", "Joaquin Garcia-Alfaro"], "title": "A Reinforcement Learning Approach for RIS-aided Fair Communications", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": "7 pages, 6 figures, 1 table, 16 references", "summary": "Reconfigurable Intelligent Surfaces (RISs) are composed of physical elements\nthat can dynamically alter electromagnetic wave properties to enhance\nbeamforming and leading to improvements in areas with low coverage properties.\nThey have the potential to be combined with Reinforcement Learning (RL)\ntechniques to achieve network performance and energy efficiency via\noptimization techniques. In addition to performance and energy improvements, it\nis also crucial to consider the concept of fair communications. RISs must\nensure that User Equipment (UE) units receive their signals with adequate\nstrength, without other UE being deprived of service due to insufficient power.\nIn this paper, we address such a problem. We explore the fairness properties of\nprevious work and propose a novel method that aims at obtaining an efficient\nand fair duplex RIS-RL system for multiple legitimate UE units. We report and\ndiscuss our experimental work and simulation results. We also release our code\nand datasets to foster further research in the topic.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\uff08RIS\uff09\u548c\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u65e8\u5728\u5b9e\u73b0\u9ad8\u6548\u4e14\u516c\u5e73\u7684\u591a\u7528\u6237\u901a\u4fe1\u7cfb\u7edf\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709RIS-RL\u7cfb\u7edf\u4e2d\u516c\u5e73\u6027\u95ee\u9898\uff0c\u786e\u4fdd\u6240\u6709\u7528\u6237\u8bbe\u5907\uff08UE\uff09\u90fd\u80fd\u83b7\u5f97\u8db3\u591f\u7684\u4fe1\u53f7\u5f3a\u5ea6\uff0c\u907f\u514d\u56e0\u529f\u7387\u4e0d\u8db3\u5bfc\u81f4\u7684\u670d\u52a1\u5265\u593a\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684RIS-RL\u7cfb\u7edf\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b9e\u9a8c\u548c\u4eff\u771f\u9a8c\u8bc1\u5176\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u8bc1\u7f51\u7edc\u6027\u80fd\u548c\u80fd\u6e90\u6548\u7387\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u901a\u4fe1\u516c\u5e73\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u591a\u7528\u6237RIS-RL\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u516c\u5e73\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5f00\u6e90\u4e86\u4ee3\u7801\u548c\u6570\u636e\u96c6\u4ee5\u4fc3\u8fdb\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2506.06345", "pdf": "https://arxiv.org/pdf/2506.06345", "abs": "https://arxiv.org/abs/2506.06345", "authors": ["Sukru Selim Calik", "Andac Akyuz", "Zeynep Hilal Kilimci", "Kerem Colak"], "title": "Explainable-AI powered stock price prediction using time series transformers: A Case Study on BIST100", "categories": ["q-fin.ST", "cs.AI", "cs.LG"], "comment": null, "summary": "Financial literacy is increasingly dependent on the ability to interpret\ncomplex financial data and utilize advanced forecasting tools. In this context,\nthis study proposes a novel approach that combines transformer-based time\nseries models with explainable artificial intelligence (XAI) to enhance the\ninterpretability and accuracy of stock price predictions. The analysis focuses\non the daily stock prices of the five highest-volume banks listed in the\nBIST100 index, along with XBANK and XU100 indices, covering the period from\nJanuary 2015 to March 2025. Models including DLinear, LTSNet, Vanilla\nTransformer, and Time Series Transformer are employed, with input features\nenriched by technical indicators. SHAP and LIME techniques are used to provide\ntransparency into the influence of individual features on model outputs. The\nresults demonstrate the strong predictive capabilities of transformer models\nand highlight the potential of interpretable machine learning to empower\nindividuals in making informed investment decisions and actively engaging in\nfinancial markets.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408Transformer\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u4e0e\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\uff08XAI\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u80a1\u7968\u4ef7\u683c\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u91d1\u878d\u7d20\u517b\u8d8a\u6765\u8d8a\u4f9d\u8d56\u4e8e\u590d\u6742\u91d1\u878d\u6570\u636e\u7684\u89e3\u8bfb\u548c\u5148\u8fdb\u9884\u6d4b\u5de5\u5177\u7684\u4f7f\u7528\uff0c\u56e0\u6b64\u9700\u8981\u63d0\u5347\u9884\u6d4b\u6a21\u578b\u7684\u89e3\u91ca\u6027\u548c\u51c6\u786e\u6027\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e86DLinear\u3001LTSNet\u3001Vanilla Transformer\u548cTime Series Transformer\u7b49\u6a21\u578b\uff0c\u7ed3\u5408\u6280\u672f\u6307\u6807\u4f5c\u4e3a\u8f93\u5165\u7279\u5f81\uff0c\u5e76\u4f7f\u7528SHAP\u548cLIME\u6280\u672f\u89e3\u91ca\u6a21\u578b\u8f93\u51fa\u3002", "result": "\u7ed3\u679c\u8868\u660eTransformer\u6a21\u578b\u5177\u6709\u5f3a\u5927\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u53ef\u89e3\u91ca\u673a\u5668\u5b66\u4e60\u6709\u52a9\u4e8e\u63d0\u5347\u4e2a\u4eba\u6295\u8d44\u51b3\u7b56\u80fd\u529b\u3002", "conclusion": "\u53ef\u89e3\u91ca\u673a\u5668\u5b66\u4e60\u5728\u91d1\u878d\u9886\u57df\u5177\u6709\u6f5c\u529b\uff0c\u80fd\u591f\u5e2e\u52a9\u4e2a\u4eba\u66f4\u597d\u5730\u53c2\u4e0e\u91d1\u878d\u5e02\u573a\u3002"}}
{"id": "2506.06346", "pdf": "https://arxiv.org/pdf/2506.06346", "abs": "https://arxiv.org/abs/2506.06346", "authors": ["Wei Li", "Xiaochun Wu", "Xiaoxi Hu", "Yuxuan Zhang", "Sebastian Bader", "Yuhan Huang"], "title": "LD-RPMNet: Near-Sensor Diagnosis for Railway Point Machines", "categories": ["eess.SP", "cs.LG"], "comment": "This paper is accepted for IEEE Sensors Applcations Symposium (SAS)\n  2025", "summary": "Near-sensor diagnosis has become increasingly prevalent in industry. This\nstudy proposes a lightweight model named LD-RPMNet that integrates Transformers\nand Convolutional Neural Networks, leveraging both local and global feature\nextraction to optimize computational efficiency for a practical railway\napplication. The LD-RPMNet introduces a Multi-scale Depthwise Separable\nConvolution (MDSC) module, which decomposes cross-channel convolutions into\npointwise and depthwise convolutions while employing multi-scale kernels to\nenhance feature extraction. Meanwhile, a Broadcast Self-Attention (BSA)\nmechanism is incorporated to simplify complex matrix multiplications and\nimprove computational efficiency. Experimental results based on collected sound\nsignals during the operation of railway point machines demonstrate that the\noptimized model reduces parameter count and computational complexity by 50%\nwhile improving diagnostic accuracy by nearly 3%, ultimately achieving an\naccuracy of 98.86%. This demonstrates the possibility of near-sensor fault\ndiagnosis applications in railway point machines.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u6a21\u578bLD-RPMNet\uff0c\u7ed3\u5408Transformer\u548cCNN\uff0c\u4f18\u5316\u94c1\u8def\u5e94\u7528\u7684\u8fd1\u4f20\u611f\u5668\u6545\u969c\u8bca\u65ad\u3002", "motivation": "\u8fd1\u4f20\u611f\u5668\u8bca\u65ad\u5728\u5de5\u4e1a\u4e2d\u65e5\u76ca\u666e\u53ca\uff0c\u4f46\u9700\u8981\u9ad8\u6548\u7684\u8ba1\u7b97\u6a21\u578b\u3002", "method": "LD-RPMNet\u7ed3\u5408\u591a\u5c3a\u5ea6\u6df1\u5ea6\u53ef\u5206\u79bb\u5377\u79ef\uff08MDSC\uff09\u6a21\u5757\u548c\u5e7f\u64ad\u81ea\u6ce8\u610f\u529b\uff08BSA\uff09\u673a\u5236\uff0c\u4f18\u5316\u7279\u5f81\u63d0\u53d6\u548c\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u6a21\u578b\u53c2\u6570\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u964d\u4f4e50%\uff0c\u8bca\u65ad\u51c6\u786e\u7387\u63d0\u5347\u8fd13%\uff0c\u8fbe\u523098.86%\u3002", "conclusion": "\u8bc1\u660e\u4e86\u8fd1\u4f20\u611f\u5668\u6545\u969c\u8bca\u65ad\u5728\u94c1\u8def\u8f6c\u8f99\u673a\u4e2d\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2506.06348", "pdf": "https://arxiv.org/pdf/2506.06348", "abs": "https://arxiv.org/abs/2506.06348", "authors": ["Vassiliki Mancoridis", "Brian Bue", "Jake H. Lee", "Andrew K. Thorpe", "Daniel Cusworth", "Alana Ayasse", "Philip G. Brodrick", "Riley Duren"], "title": "Multi-Platform Methane Plume Detection via Model and Domain Adaptation", "categories": ["eess.SP", "cs.LG"], "comment": "12 pages 8 figures. In review", "summary": "Prioritizing methane for near-term climate action is crucial due to its\nsignificant impact on global warming. Previous work used columnwise matched\nfilter products from the airborne AVIRIS-NG imaging spectrometer to detect\nmethane plume sources; convolutional neural networks (CNNs) discerned\nanthropogenic methane plumes from false positive enhancements. However, as an\nincreasing number of remote sensing platforms are used for methane plume\ndetection, there is a growing need to address cross-platform alignment. In this\nwork, we describe model- and data-driven machine learning approaches that\nleverage airborne observations to improve spaceborne methane plume detection,\nreconciling the distributional shifts inherent with performing the same task\nacross platforms. We develop a spaceborne methane plume classifier using data\nfrom the EMIT imaging spectroscopy mission. We refine classifiers trained on\nairborne imagery from AVIRIS-NG campaigns using transfer learning,\noutperforming the standalone spaceborne model. Finally, we use CycleGAN, an\nunsupervised image-to-image translation technique, to align the data\ndistributions between airborne and spaceborne contexts. Translating spaceborne\nEMIT data to the airborne AVIRIS-NG domain using CycleGAN and applying airborne\nclassifiers directly yields the best plume detection results. This methodology\nis useful not only for data simulation, but also for direct data alignment.\nThough demonstrated on the task of methane plume detection, our work more\nbroadly demonstrates a data-driven approach to align related products obtained\nfrom distinct remote sensing instruments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6a21\u578b\u548c\u6570\u636e\u9a71\u52a8\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fc1\u79fb\u5b66\u4e60\u548cCycleGAN\u6280\u672f\uff0c\u4f18\u5316\u4e86\u8de8\u5e73\u53f0\u7684\u7532\u70f7\u7fbd\u6d41\u68c0\u6d4b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7a7a\u95f4\u89c2\u6d4b\u6570\u636e\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u7532\u70f7\u5bf9\u5168\u7403\u53d8\u6696\u5f71\u54cd\u663e\u8457\uff0c\u4f46\u73b0\u6709\u7532\u70f7\u7fbd\u6d41\u68c0\u6d4b\u65b9\u6cd5\u5728\u8de8\u5e73\u53f0\u6570\u636e\u5bf9\u9f50\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u4e9f\u9700\u89e3\u51b3\u4ee5\u63d0\u9ad8\u68c0\u6d4b\u6548\u7387\u3002", "method": "\u5229\u7528AVIRIS-NG\u7684\u673a\u8f7d\u89c2\u6d4b\u6570\u636e\uff0c\u901a\u8fc7\u8fc1\u79fb\u5b66\u4e60\u4f18\u5316\u7a7a\u95f4\u89c2\u6d4b\u6a21\u578b\uff0c\u5e76\u4f7f\u7528CycleGAN\u8fdb\u884c\u6570\u636e\u5206\u5e03\u5bf9\u9f50\u3002", "result": "\u7ed3\u5408CycleGAN\u548c\u8fc1\u79fb\u5b66\u4e60\u7684\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u7a7a\u95f4\u89c2\u6d4b\u6570\u636e\u7684\u7532\u70f7\u7fbd\u6d41\u68c0\u6d4b\u6548\u679c\uff0c\u4f18\u4e8e\u72ec\u7acb\u7684\u7a7a\u95f4\u6a21\u578b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u9002\u7528\u4e8e\u7532\u70f7\u7fbd\u6d41\u68c0\u6d4b\uff0c\u8fd8\u53ef\u63a8\u5e7f\u81f3\u5176\u4ed6\u9065\u611f\u6570\u636e\u7684\u8de8\u5e73\u53f0\u5bf9\u9f50\u4efb\u52a1\u3002"}}
{"id": "2506.06349", "pdf": "https://arxiv.org/pdf/2506.06349", "abs": "https://arxiv.org/abs/2506.06349", "authors": ["Thien Nhan Vo", "Thanh Xuan Truong"], "title": "Heart Rate Classification in ECG Signals Using Machine Learning and Deep Learning", "categories": ["eess.SP", "cs.CV", "cs.LG"], "comment": null, "summary": "This study addresses the classification of heartbeats from ECG signals\nthrough two distinct approaches: traditional machine learning utilizing\nhand-crafted features and deep learning via transformed images of ECG beats.\nThe dataset underwent preprocessing steps, including downsampling, filtering,\nand normalization, to ensure consistency and relevance for subsequent analysis.\nIn the first approach, features such as heart rate variability (HRV), mean,\nvariance, and RR intervals were extracted to train various classifiers,\nincluding SVM, Random Forest, AdaBoost, LSTM, Bi-directional LSTM, and\nLightGBM. The second approach involved transforming ECG signals into images\nusing Gramian Angular Field (GAF), Markov Transition Field (MTF), and\nRecurrence Plots (RP), with these images subsequently classified using CNN\narchitectures like VGG and Inception.\n  Experimental results demonstrate that the LightGBM model achieved the highest\nperformance, with an accuracy of 99% and an F1 score of 0.94, outperforming the\nimage-based CNN approach (F1 score of 0.85). Models such as SVM and AdaBoost\nyielded significantly lower scores, indicating limited suitability for this\ntask. The findings underscore the superior ability of hand-crafted features to\ncapture temporal and morphological variations in ECG signals compared to\nimage-based representations of individual beats. Future investigations may\nbenefit from incorporating multi-lead ECG signals and temporal dependencies\nacross successive beats to enhance classification accuracy further.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5bf9ECG\u4fe1\u53f7\u8fdb\u884c\u5206\u7c7b\uff0c\u53d1\u73b0\u57fa\u4e8e\u624b\u5de5\u7279\u5f81\u7684LightGBM\u6a21\u578b\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u89e3\u51b3ECG\u4fe1\u53f7\u4e2d\u5fc3\u8df3\u5206\u7c7b\u7684\u95ee\u9898\uff0c\u6bd4\u8f83\u4e0d\u540c\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "method": "\u91c7\u7528\u4e24\u79cd\u65b9\u6cd5\uff1a\u4f20\u7edf\u673a\u5668\u5b66\u4e60\uff08\u624b\u5de5\u7279\u5f81\u63d0\u53d6\uff09\u548c\u6df1\u5ea6\u5b66\u4e60\uff08ECG\u4fe1\u53f7\u56fe\u50cf\u5316\u540e\u5206\u7c7b\uff09\u3002", "result": "LightGBM\u6a21\u578b\u8868\u73b0\u6700\u4f18\uff08\u51c6\u786e\u738799%\uff0cF1\u5206\u65700.94\uff09\uff0c\u4f18\u4e8e\u57fa\u4e8e\u56fe\u50cf\u7684CNN\u65b9\u6cd5\u3002", "conclusion": "\u624b\u5de5\u7279\u5f81\u80fd\u66f4\u597d\u6355\u6349ECG\u4fe1\u53f7\u7684\u65f6\u6001\u548c\u5f62\u6001\u53d8\u5316\uff0c\u672a\u6765\u53ef\u7ed3\u5408\u591a\u5bfc\u8054\u4fe1\u53f7\u63d0\u5347\u5206\u7c7b\u6548\u679c\u3002"}}
{"id": "2506.06351", "pdf": "https://arxiv.org/pdf/2506.06351", "abs": "https://arxiv.org/abs/2506.06351", "authors": ["Alexis Le Pichon", "Alice Janela Cameijo", "Samir Aknine", "Youcef Sklab", "Souhila Arib", "Quentin Brissaud", "Sven Peter Naesholm"], "title": "Deep learning methods for modeling infrasound transmission loss in the middle atmosphere", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": "12 pages, 7 figures", "summary": "Accurate modeling of infrasound transmission losses (TLs) is essential to\nassess the performance of the global International Monitoring System infrasound\nnetwork. Among existing propagation modeling tools, parabolic equation (PE)\nmethod enables TLs to be finely modeled, but its computational cost does not\nallow exploration of a large parameter space for operational monitoring\napplications. To reduce computation times, Brissaud et al. 2023 explored the\npotential of convolutional neural networks trained on a large set of regionally\nsimulated wavefields (< 1000 km from the source) to predict TLs with negligible\ncomputation times compared to PE simulations. However, this method struggles in\nunfavorable initial wind conditions, especially at high frequencies, and causal\nissues with winds at large distances from the source affecting ground TLs close\nto the source. In this study, we have developed an optimized convolutional\nnetwork designed to minimize prediction errors while predicting TLs from\nglobally simulated combined temperature and wind fields spanning over\npropagation ranges of 4000 km. Our approach enhances the previously proposed\none by implementing key optimizations that improve the overall architecture\nperformance. The implemented model predicts TLs with an average error of 8.6 dB\nin the whole frequency band (0.1-3.2 Hz) and explored realistic atmospheric\nscenarios.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u4f18\u5316\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u7528\u4e8e\u5728\u5168\u7403\u8303\u56f4\u5185\u9884\u6d4b\u6b21\u58f0\u6ce2\u4f20\u8f93\u635f\u5931\uff08TLs\uff09\uff0c\u89e3\u51b3\u4e86\u4e4b\u524d\u65b9\u6cd5\u5728\u9ad8\u9891\u548c\u4e0d\u5229\u98ce\u6761\u4ef6\u4e0b\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u51c6\u786e\u5efa\u6a21\u6b21\u58f0\u6ce2\u4f20\u8f93\u635f\u5931\u5bf9\u8bc4\u4f30\u56fd\u9645\u76d1\u6d4b\u7cfb\u7edf\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u5728\u67d0\u4e9b\u6761\u4ef6\u4e0b\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u4f18\u5316\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u57fa\u4e8e\u5168\u7403\u6a21\u62df\u7684\u6e29\u5ea6\u548c\u98ce\u573a\u6570\u636e\uff0c\u9884\u6d4b4000\u516c\u91cc\u8303\u56f4\u5185\u7684TLs\u3002", "result": "\u4f18\u5316\u540e\u7684\u6a21\u578b\u5728\u6574\u4e2a\u9891\u6bb5\uff080.1-3.2 Hz\uff09\u5185\u5e73\u5747\u8bef\u5dee\u4e3a8.6 dB\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u5b9e\u9645\u5927\u6c14\u573a\u666f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86TLs\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u5168\u7403\u76d1\u6d4b\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2506.06353", "pdf": "https://arxiv.org/pdf/2506.06353", "abs": "https://arxiv.org/abs/2506.06353", "authors": ["Naseem Babu", "Jimson Mathew", "A. P. Vinod"], "title": "Large Language Models for EEG: A Comprehensive Survey and Taxonomy", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": null, "summary": "The growing convergence between Large Language Models (LLMs) and\nelectroencephalography (EEG) research is enabling new directions in neural\ndecoding, brain-computer interfaces (BCIs), and affective computing. This\nsurvey offers a systematic review and structured taxonomy of recent\nadvancements that utilize LLMs for EEG-based analysis and applications. We\norganize the literature into four domains: (1) LLM-inspired foundation models\nfor EEG representation learning, (2) EEG-to-language decoding, (3) cross-modal\ngeneration including image and 3D object synthesis, and (4) clinical\napplications and dataset management tools. The survey highlights how\ntransformer-based architectures adapted through fine-tuning, few-shot, and\nzero-shot learning have enabled EEG-based models to perform complex tasks such\nas natural language generation, semantic interpretation, and diagnostic\nassistance. By offering a structured overview of modeling strategies, system\ndesigns, and application areas, this work serves as a foundational resource for\nfuture work to bridge natural language processing and neural signal analysis\nthrough language models.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e0e\u8111\u7535\u56fe\uff08EEG\uff09\u7814\u7a76\u7684\u7ed3\u5408\uff0c\u7cfb\u7edf\u68b3\u7406\u4e86\u5176\u5728\u795e\u7ecf\u89e3\u7801\u3001\u8111\u673a\u63a5\u53e3\u548c\u60c5\u611f\u8ba1\u7b97\u4e2d\u7684\u65b0\u65b9\u5411\u3002", "motivation": "\u63a2\u7d22LLMs\u5728EEG\u5206\u6790\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u63a8\u52a8\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e0e\u795e\u7ecf\u4fe1\u53f7\u5206\u6790\u7684\u7ed3\u5408\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u7efc\u8ff0\u548c\u5206\u7c7b\uff0c\u5c06\u6587\u732e\u5206\u4e3a\u56db\u4e2a\u9886\u57df\uff1aLLM\u542f\u53d1\u7684EEG\u8868\u793a\u5b66\u4e60\u3001EEG\u5230\u8bed\u8a00\u89e3\u7801\u3001\u8de8\u6a21\u6001\u751f\u6210\u53ca\u4e34\u5e8a\u5e94\u7528\u3002", "result": "LLMs\u901a\u8fc7\u5fae\u8c03\u3001\u5c11\u6837\u672c\u548c\u96f6\u6837\u672c\u5b66\u4e60\uff0c\u4f7fEEG\u6a21\u578b\u80fd\u5b8c\u6210\u590d\u6742\u4efb\u52a1\uff0c\u5982\u81ea\u7136\u8bed\u8a00\u751f\u6210\u548c\u8bca\u65ad\u8f85\u52a9\u3002", "conclusion": "\u672c\u6587\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u8d44\u6e90\uff0c\u65e8\u5728\u901a\u8fc7\u8bed\u8a00\u6a21\u578b\u6865\u63a5\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e0e\u795e\u7ecf\u4fe1\u53f7\u5206\u6790\u3002"}}
{"id": "2506.06356", "pdf": "https://arxiv.org/pdf/2506.06356", "abs": "https://arxiv.org/abs/2506.06356", "authors": ["Yimin Du"], "title": "Deep Learning Enhanced Multi-Day Turnover Quantitative Trading Algorithm for Chinese A-Share Market", "categories": ["cs.CE", "cs.LG"], "comment": "10 pages", "summary": "This paper presents a sophisticated multi-day turnover quantitative trading\nalgorithm that integrates advanced deep learning techniques with comprehensive\ncross-sectional stock prediction for the Chinese A-share market. Our framework\ncombines five interconnected modules: initial stock selection through deep\ncross-sectional prediction networks, opening signal distribution analysis using\nmixture models for arbitrage identification, market capitalization and\nliquidity-based dynamic position sizing, grid-search optimized profit-taking\nand stop-loss mechanisms, and multi-granularity volatility-based market timing\nmodels. The algorithm employs a novel approach to balance capital efficiency\nwith risk management through adaptive holding periods and sophisticated\nentry/exit timing. Trained on comprehensive A-share data from 2010-2020 and\nrigorously backtested on 2021-2024 data, our method achieves remarkable\nperformance with 15.2\\% annualized returns, maximum drawdown constrained below\n5\\%, and a Sharpe ratio of 1.87. The strategy demonstrates exceptional\nscalability by maintaining 50-100 daily positions with a 9-day maximum holding\nperiod, incorporating dynamic profit-taking and stop-loss mechanisms that\nenhance capital turnover efficiency while preserving risk-adjusted returns. Our\napproach exhibits robust performance across various market regimes while\nmaintaining high capital capacity suitable for institutional deployment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u4e0e\u6a2a\u622a\u9762\u80a1\u7968\u9884\u6d4b\u7684\u591a\u65e5\u6362\u624b\u91cf\u5316\u4ea4\u6613\u7b97\u6cd5\uff0c\u7528\u4e8e\u4e2d\u56fdA\u80a1\u5e02\u573a\uff0c\u5b9e\u73b0\u4e86\u9ad8\u56de\u62a5\u4e0e\u4f4e\u56de\u64a4\u7684\u4f18\u5f02\u8868\u73b0\u3002", "motivation": "\u65e8\u5728\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u548c\u591a\u6a21\u5757\u96c6\u6210\uff0c\u63d0\u5347\u91cf\u5316\u4ea4\u6613\u7b56\u7565\u7684\u8d44\u672c\u6548\u7387\u548c\u98ce\u9669\u7ba1\u7406\u80fd\u529b\uff0c\u9002\u7528\u4e8e\u673a\u6784\u7ea7\u90e8\u7f72\u3002", "method": "\u7ed3\u5408\u4e94\u4e2a\u6a21\u5757\uff1a\u6df1\u5ea6\u6a2a\u622a\u9762\u9884\u6d4b\u7f51\u7edc\u9009\u80a1\u3001\u6df7\u5408\u6a21\u578b\u5206\u6790\u5f00\u76d8\u4fe1\u53f7\u3001\u52a8\u6001\u5934\u5bf8\u89c4\u6a21\u8c03\u6574\u3001\u7f51\u683c\u641c\u7d22\u4f18\u5316\u7684\u6b62\u76c8\u6b62\u635f\u673a\u5236\uff0c\u4ee5\u53ca\u591a\u7c92\u5ea6\u6ce2\u52a8\u5e02\u573a\u62e9\u65f6\u6a21\u578b\u3002", "result": "\u57282021-2024\u5e74\u56de\u6d4b\u4e2d\uff0c\u5e74\u5316\u6536\u76ca15.2%\uff0c\u6700\u5927\u56de\u64a4\u4f4e\u4e8e5%\uff0c\u590f\u666e\u6bd4\u73871.87\uff0c\u7b56\u7565\u5177\u6709\u9ad8\u6269\u5c55\u6027\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u5728\u591a\u79cd\u5e02\u573a\u73af\u5883\u4e0b\u8868\u73b0\u7a33\u5065\uff0c\u9002\u5408\u673a\u6784\u5e94\u7528\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u8d44\u672c\u5bb9\u91cf\u548c\u98ce\u9669\u8c03\u6574\u540e\u6536\u76ca\u3002"}}
{"id": "2506.06360", "pdf": "https://arxiv.org/pdf/2506.06360", "abs": "https://arxiv.org/abs/2506.06360", "authors": ["Jiyao Wang", "Suzan Ayas", "Jiahao Zhang", "Xiao Wen", "Dengbo He", "Birsen Donmez"], "title": "Towards Generalizable Drowsiness Monitoring with Physiological Sensors: A Preliminary Study", "categories": ["eess.SP", "cs.LG"], "comment": "Accepted by HFES2025", "summary": "Accurately detecting drowsiness is vital to driving safety. Among all\nmeasures, physiological-signal-based drowsiness monitoring can be more\nprivacy-preserving than a camera-based approach. However, conflicts exist\nregarding how physiological metrics are associated with different drowsiness\nlabels across datasets. Thus, we analyzed key features from electrocardiograms\n(ECG), electrodermal activity (EDA), and respiratory (RESP) signals across four\ndatasets, where different drowsiness inducers (such as fatigue and low arousal)\nand assessment methods (subjective vs. objective) were used. Binary logistic\nregression models were built to identify the physiological metrics that are\nassociated with drowsiness. Findings indicate that distinct different\ndrowsiness inducers can lead to different physiological responses, and\nobjective assessments were more sensitive than subjective ones in detecting\ndrowsiness. Further, the increased heart rate stability, reduced respiratory\namplitude, and decreased tonic EDA are robustly associated with increased\ndrowsiness. The results enhance understanding of drowsiness detection and can\ninform future generalizable monitoring designs.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u57fa\u4e8e\u751f\u7406\u4fe1\u53f7\u7684\u7761\u610f\u68c0\u6d4b\u65b9\u6cd5\uff0c\u53d1\u73b0\u4e0d\u540c\u7761\u610f\u8bf1\u56e0\u4f1a\u5bfc\u81f4\u4e0d\u540c\u7684\u751f\u7406\u53cd\u5e94\uff0c\u5ba2\u89c2\u8bc4\u4f30\u6bd4\u4e3b\u89c2\u8bc4\u4f30\u66f4\u654f\u611f\u3002", "motivation": "\u7761\u610f\u68c0\u6d4b\u5bf9\u9a7e\u9a76\u5b89\u5168\u81f3\u5173\u91cd\u8981\uff0c\u751f\u7406\u4fe1\u53f7\u65b9\u6cd5\u6bd4\u6444\u50cf\u5934\u65b9\u6cd5\u66f4\u4fdd\u62a4\u9690\u79c1\uff0c\u4f46\u73b0\u6709\u6570\u636e\u96c6\u4e2d\u751f\u7406\u6307\u6807\u4e0e\u7761\u610f\u6807\u7b7e\u7684\u5173\u8054\u5b58\u5728\u51b2\u7a81\u3002", "method": "\u901a\u8fc7\u5206\u6790\u56db\u4e2a\u6570\u636e\u96c6\u4e2d\u7684ECG\u3001EDA\u548cRESP\u4fe1\u53f7\uff0c\u5efa\u7acb\u4e8c\u5143\u903b\u8f91\u56de\u5f52\u6a21\u578b\uff0c\u8bc6\u522b\u4e0e\u7761\u610f\u76f8\u5173\u7684\u751f\u7406\u6307\u6807\u3002", "result": "\u53d1\u73b0\u5fc3\u7387\u7a33\u5b9a\u6027\u589e\u52a0\u3001\u547c\u5438\u5e45\u5ea6\u964d\u4f4e\u548c\u57fa\u7840EDA\u51cf\u5c11\u4e0e\u7761\u610f\u589e\u5f3a\u663e\u8457\u76f8\u5173\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u63d0\u5347\u4e86\u7761\u610f\u68c0\u6d4b\u7684\u7406\u89e3\uff0c\u5e76\u4e3a\u672a\u6765\u901a\u7528\u76d1\u6d4b\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u4f9d\u636e\u3002"}}
{"id": "2506.06361", "pdf": "https://arxiv.org/pdf/2506.06361", "abs": "https://arxiv.org/abs/2506.06361", "authors": ["Tim Schneider", "Guillaume Duret", "Cristiana de Farias", "Roberto Calandra", "Liming Chen", "Jan Peters"], "title": "Tactile MNIST: Benchmarking Active Tactile Perception", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "Tactile perception has the potential to significantly enhance dexterous\nrobotic manipulation by providing rich local information that can complement or\nsubstitute for other sensory modalities such as vision. However, because\ntactile sensing is inherently local, it is not well-suited for tasks that\nrequire broad spatial awareness or global scene understanding on its own. A\nhuman-inspired strategy to address this issue is to consider active perception\ntechniques instead. That is, to actively guide sensors toward regions with more\ninformative or significant features and integrate such information over time in\norder to understand a scene or complete a task. Both active perception and\ndifferent methods for tactile sensing have received significant attention\nrecently. Yet, despite advancements, both fields lack standardized benchmarks.\nTo bridge this gap, we introduce the Tactile MNIST Benchmark Suite, an\nopen-source, Gymnasium-compatible benchmark specifically designed for active\ntactile perception tasks, including localization, classification, and volume\nestimation. Our benchmark suite offers diverse simulation scenarios, from\nsimple toy environments all the way to complex tactile perception tasks using\nvision-based tactile sensors. Furthermore, we also offer a comprehensive\ndataset comprising 13,500 synthetic 3D MNIST digit models and 153,600\nreal-world tactile samples collected from 600 3D printed digits. Using this\ndataset, we train a CycleGAN for realistic tactile simulation rendering. By\nproviding standardized protocols and reproducible evaluation frameworks, our\nbenchmark suite facilitates systematic progress in the fields of tactile\nsensing and active perception.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86Tactile MNIST Benchmark Suite\uff0c\u4e00\u4e2a\u7528\u4e8e\u4e3b\u52a8\u89e6\u89c9\u611f\u77e5\u4efb\u52a1\u7684\u5f00\u6e90\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\uff0c\u586b\u8865\u4e86\u89e6\u89c9\u611f\u77e5\u548c\u4e3b\u52a8\u611f\u77e5\u9886\u57df\u7f3a\u4e4f\u6807\u51c6\u5316\u57fa\u51c6\u7684\u7a7a\u767d\u3002", "motivation": "\u89e6\u89c9\u611f\u77e5\u80fd\u589e\u5f3a\u673a\u5668\u4eba\u64cd\u4f5c\u7684\u7075\u6d3b\u6027\uff0c\u4f46\u7531\u4e8e\u5176\u5c40\u90e8\u6027\uff0c\u96be\u4ee5\u5355\u72ec\u7528\u4e8e\u9700\u8981\u5168\u5c40\u573a\u666f\u7406\u89e3\u7684\u4efb\u52a1\u3002\u4e3b\u52a8\u611f\u77e5\u6280\u672f\u53ef\u4ee5\u5f25\u8865\u8fd9\u4e00\u7f3a\u9677\uff0c\u4f46\u7f3a\u4e4f\u6807\u51c6\u5316\u57fa\u51c6\u963b\u788d\u4e86\u7814\u7a76\u8fdb\u5c55\u3002", "method": "\u5f15\u5165Tactile MNIST Benchmark Suite\uff0c\u63d0\u4f9b\u591a\u6837\u5316\u7684\u6a21\u62df\u573a\u666f\u548c\u6570\u636e\u96c6\uff0c\u5305\u62ec\u5408\u62103D MNIST\u6570\u5b57\u6a21\u578b\u548c\u771f\u5b9e\u89e6\u89c9\u6837\u672c\uff0c\u5e76\u8bad\u7ec3CycleGAN\u7528\u4e8e\u903c\u771f\u89e6\u89c9\u6a21\u62df\u6e32\u67d3\u3002", "result": "\u63d0\u4f9b\u4e8613,500\u4e2a\u5408\u62103D MNIST\u6570\u5b57\u6a21\u578b\u548c153,600\u4e2a\u771f\u5b9e\u89e6\u89c9\u6837\u672c\u7684\u6570\u636e\u96c6\uff0c\u652f\u6301\u5b9a\u4f4d\u3001\u5206\u7c7b\u548c\u4f53\u79ef\u4f30\u8ba1\u7b49\u4efb\u52a1\u3002", "conclusion": "\u901a\u8fc7\u6807\u51c6\u5316\u534f\u8bae\u548c\u53ef\u590d\u73b0\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u8be5\u57fa\u51c6\u5957\u4ef6\u4fc3\u8fdb\u4e86\u89e6\u89c9\u611f\u77e5\u548c\u4e3b\u52a8\u611f\u77e5\u9886\u57df\u7684\u7cfb\u7edf\u6027\u8fdb\u5c55\u3002"}}
{"id": "2506.06362", "pdf": "https://arxiv.org/pdf/2506.06362", "abs": "https://arxiv.org/abs/2506.06362", "authors": ["Dejun Xu", "Jijia Chen", "Gary G. Yen", "Min Jiang"], "title": "CR-BLEA: Contrastive Ranking for Adaptive Resource Allocation in Bilevel Evolutionary Algorithms", "categories": ["cs.NE", "cs.AI", "cs.LG"], "comment": null, "summary": "Bilevel optimization poses a significant computational challenge due to its\nnested structure, where each upper-level candidate solution requires solving a\ncorresponding lower-level problem. While evolutionary algorithms (EAs) are\neffective at navigating such complex landscapes, their high resource demands\nremain a key bottleneck -- particularly the redundant evaluation of numerous\nunpromising lower-level tasks. Despite recent advances in multitasking and\ntransfer learning, resource waste persists. To address this issue, we propose a\nnovel resource allocation framework for bilevel EAs that selectively identifies\nand focuses on promising lower-level tasks. Central to our approach is a\ncontrastive ranking network that learns relational patterns between paired\nupper- and lower-level solutions online. This knowledge guides a\nreference-based ranking strategy that prioritizes tasks for optimization and\nadaptively controls resampling based on estimated population quality.\nComprehensive experiments across five state-of-the-art bilevel algorithms show\nthat our framework significantly reduces computational cost while preserving --\nor even enhancing -- solution accuracy. This work offers a generalizable\nstrategy to improve the efficiency of bilevel EAs, paving the way for more\nscalable bilevel optimization.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8d44\u6e90\u5206\u914d\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6bd4\u6392\u5e8f\u7f51\u7edc\u9009\u62e9\u6027\u4f18\u5316\u6709\u524d\u666f\u7684\u4e0b\u5c42\u4efb\u52a1\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u5e76\u4fdd\u6301\u6216\u63d0\u5347\u89e3\u7cbe\u5ea6\u3002", "motivation": "\u53cc\u5c42\u4f18\u5316\u56e0\u5d4c\u5957\u7ed3\u6784\u5bfc\u81f4\u9ad8\u8ba1\u7b97\u6210\u672c\uff0c\u4f20\u7edf\u8fdb\u5316\u7b97\u6cd5\u8d44\u6e90\u6d6a\u8d39\u4e25\u91cd\uff0c\u9700\u6539\u8fdb\u6548\u7387\u3002", "method": "\u4f7f\u7528\u5bf9\u6bd4\u6392\u5e8f\u7f51\u7edc\u5728\u7ebf\u5b66\u4e60\u4e0a\u4e0b\u5c42\u89e3\u7684\u5173\u7cfb\u6a21\u5f0f\uff0c\u6307\u5bfc\u57fa\u4e8e\u53c2\u8003\u7684\u6392\u5e8f\u7b56\u7565\uff0c\u4f18\u5148\u4f18\u5316\u4efb\u52a1\u5e76\u81ea\u9002\u5e94\u63a7\u5236\u91cd\u91c7\u6837\u3002", "result": "\u5728\u4e94\u79cd\u5148\u8fdb\u53cc\u5c42\u7b97\u6cd5\u4e0a\u9a8c\u8bc1\uff0c\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u6210\u672c\u4e14\u4fdd\u6301\u6216\u63d0\u5347\u89e3\u7cbe\u5ea6\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u53cc\u5c42\u8fdb\u5316\u7b97\u6cd5\u63d0\u4f9b\u4e86\u901a\u7528\u9ad8\u6548\u7b56\u7565\uff0c\u63a8\u52a8\u53ef\u6269\u5c55\u53cc\u5c42\u4f18\u5316\u53d1\u5c55\u3002"}}
{"id": "2506.06363", "pdf": "https://arxiv.org/pdf/2506.06363", "abs": "https://arxiv.org/abs/2506.06363", "authors": ["Thang D. Pham", "Aditya Tanikanti", "Murat Ke\u00e7eli"], "title": "ChemGraph: An Agentic Framework for Computational Chemistry Workflows", "categories": ["physics.chem-ph", "cond-mat.mtrl-sci", "cs.LG", "physics.comp-ph"], "comment": null, "summary": "Atomistic simulations are essential tools in chemistry and materials science,\naccelerating the discovery of novel catalysts, energy storage materials, and\npharmaceuticals. However, running these simulations remains challenging due to\nthe wide range of computational methods, diverse software ecosystems, and the\nneed for expert knowledge and manual effort for the setup, execution, and\nvalidation stages. In this work, we present ChemGraph, an agentic framework\npowered by artificial intelligence and state-of-the-art simulation tools to\nstreamline and automate computational chemistry and materials science\nworkflows. ChemGraph leverages graph neural network-based foundation models for\naccurate yet computationally efficient calculations and large language models\n(LLMs) for natural language understanding, task planning, and scientific\nreasoning to provide an intuitive and interactive interface. Users can perform\ntasks such as molecular structure generation, single-point energy, geometry\noptimization, vibrational analysis, and thermochemistry calculations with\nmethods ranging from tight-binding and machine learning interatomic potentials\nto density functional theory or wave function theory-based methods. We evaluate\nChemGraph across 13 benchmark tasks and demonstrate that smaller LLMs\n(GPT-4o-mini, Claude-3.5-haiku, Qwen2.5-14B) perform well on simple workflows,\nwhile more complex tasks benefit from using larger models like GPT-4o.\nImportantly, we show that decomposing complex tasks into smaller subtasks\nthrough a multi-agent framework enables smaller LLM models to match or exceed\nGPT-4o's performance in specific scenarios.", "AI": {"tldr": "ChemGraph\u662f\u4e00\u4e2a\u57fa\u4e8eAI\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u548c\u7b80\u5316\u8ba1\u7b97\u5316\u5b66\u4e0e\u6750\u6599\u79d1\u5b66\u7684\u5de5\u4f5c\u6d41\u7a0b\uff0c\u7ed3\u5408\u56fe\u795e\u7ecf\u7f51\u7edc\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u652f\u6301\u591a\u79cd\u8ba1\u7b97\u4efb\u52a1\u3002", "motivation": "\u539f\u5b50\u6a21\u62df\u5728\u5316\u5b66\u548c\u6750\u6599\u79d1\u5b66\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\u4e14\u64cd\u4f5c\u590d\u6742\uff0cChemGraph\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "ChemGraph\u5229\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u57fa\u7840\u6a21\u578b\u8fdb\u884c\u9ad8\u6548\u8ba1\u7b97\uff0c\u5e76\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u548c\u4efb\u52a1\u89c4\u5212\u3002", "result": "\u572813\u4e2a\u57fa\u51c6\u4efb\u52a1\u4e2d\uff0c\u5c0f\u578bLLM\u5728\u7b80\u5355\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u590d\u6742\u4efb\u52a1\u9700\u8981\u66f4\u5927\u6a21\u578b\uff0c\u591a\u4ee3\u7406\u6846\u67b6\u53ef\u63d0\u5347\u5c0f\u578b\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "ChemGraph\u901a\u8fc7\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u7a0b\u548c\u591a\u4ee3\u7406\u8bbe\u8ba1\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8ba1\u7b97\u5316\u5b66\u4efb\u52a1\u7684\u6548\u7387\u548c\u53ef\u8bbf\u95ee\u6027\u3002"}}
{"id": "2506.06373", "pdf": "https://arxiv.org/pdf/2506.06373", "abs": "https://arxiv.org/abs/2506.06373", "authors": ["Th\u00e9o Guyard", "C\u00e9dric Herzet", "Cl\u00e9ment Elvira"], "title": "El0ps: An Exact L0-regularized Problems Solver", "categories": ["cs.MS", "cs.LG", "math.OC"], "comment": null, "summary": "This paper presents El0ps, a Python toolbox providing several utilities to\nhandle L0-regularized problems related to applications in machine learning,\nstatistics, and signal processing, among other fields. In contrast to existing\ntoolboxes, El0ps allows users to define custom instances of these problems\nthrough a flexible framework, provides a dedicated solver achieving\nstate-of-the-art performance, and offers several built-in machine learning\npipelines. Our aim with El0ps is to provide a comprehensive tool which opens\nnew perspectives for the integration of L0-regularized problems in practical\napplications.", "AI": {"tldr": "El0ps\u662f\u4e00\u4e2aPython\u5de5\u5177\u7bb1\uff0c\u7528\u4e8e\u5904\u7406L0\u6b63\u5219\u5316\u95ee\u9898\uff0c\u63d0\u4f9b\u7075\u6d3b\u6846\u67b6\u3001\u9ad8\u6027\u80fd\u6c42\u89e3\u5668\u548c\u5185\u7f6e\u673a\u5668\u5b66\u4e60\u6d41\u7a0b\u3002", "motivation": "\u4e3a\u673a\u5668\u5b66\u4e60\u548c\u4fe1\u53f7\u5904\u7406\u7b49\u9886\u57df\u63d0\u4f9b\u66f4\u7075\u6d3b\u3001\u9ad8\u6548\u7684L0\u6b63\u5219\u5316\u95ee\u9898\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u81ea\u5b9a\u4e49\u95ee\u9898\u5b9e\u4f8b\u6846\u67b6\u548c\u4e13\u7528\u6c42\u89e3\u5668\u5b9e\u73b0\u9ad8\u6027\u80fd\uff0c\u5e76\u63d0\u4f9b\u5185\u7f6e\u673a\u5668\u5b66\u4e60\u6d41\u7a0b\u3002", "result": "El0ps\u5728L0\u6b63\u5219\u5316\u95ee\u9898\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u65b0\u89c6\u89d2\u3002", "conclusion": "El0ps\u662f\u4e00\u4e2a\u5168\u9762\u7684\u5de5\u5177\uff0c\u63a8\u52a8\u4e86L0\u6b63\u5219\u5316\u95ee\u9898\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u96c6\u6210\u3002"}}
{"id": "2506.06377", "pdf": "https://arxiv.org/pdf/2506.06377", "abs": "https://arxiv.org/abs/2506.06377", "authors": ["Giuseppe Arbia", "Luca Morandini", "Vincenzo Nardelli"], "title": "Evaluating Large Language Model Capabilities in Assessing Spatial Econometrics Research", "categories": ["cs.CY", "cs.LG", "econ.EM", "stat.CO"], "comment": null, "summary": "This paper investigates Large Language Models (LLMs) ability to assess the\neconomic soundness and theoretical consistency of empirical findings in spatial\neconometrics. We created original and deliberately altered \"counterfactual\"\nsummaries from 28 published papers (2005-2024), which were evaluated by a\ndiverse set of LLMs. The LLMs provided qualitative assessments and structured\nbinary classifications on variable choice, coefficient plausibility, and\npublication suitability. The results indicate that while LLMs can expertly\nassess the coherence of variable choices (with top models like GPT-4o achieving\nan overall F1 score of 0.87), their performance varies significantly when\nevaluating deeper aspects such as coefficient plausibility and overall\npublication suitability. The results further revealed that the choice of LLM,\nthe specific characteristics of the paper and the interaction between these two\nfactors significantly influence the accuracy of the assessment, particularly\nfor nuanced judgments. These findings highlight LLMs' current strengths in\nassisting with initial, more surface-level checks and their limitations in\nperforming comprehensive, deep economic reasoning, suggesting a potential\nassistive role in peer review that still necessitates robust human oversight.", "AI": {"tldr": "LLMs can assess variable coherence well (F1 score 0.87) but struggle with deeper economic reasoning like coefficient plausibility and publication suitability. Model choice and paper characteristics affect accuracy.", "motivation": "To evaluate LLMs' ability to assess economic soundness and theoretical consistency in spatial econometrics.", "method": "Created original and altered summaries from 28 papers (2005-2024), evaluated by diverse LLMs for qualitative and binary classifications.", "result": "LLMs excel at variable choice coherence but vary in deeper assessments. Model and paper traits significantly impact accuracy.", "conclusion": "LLMs are useful for surface-level checks but require human oversight for nuanced economic reasoning in peer review."}}
{"id": "2506.06378", "pdf": "https://arxiv.org/pdf/2506.06378", "abs": "https://arxiv.org/abs/2506.06378", "authors": ["Charalampos Tsirmpas", "Stasinos Konstantopoulos", "Dimitris Andrikopoulos", "Konstantina Kyriakouli", "Panagiotis Fatouros"], "title": "Transformer-Based Decomposition of Electrodermal Activity for Real-World Mental Health Applications", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "Decomposing Electrodermal Activity (EDA) into phasic (short-term,\nstimulus-linked responses) and tonic (longer-term baseline) components is\nessential for extracting meaningful emotional and physiological biomarkers.\nThis study presents a comparative analysis of knowledge-driven, statistical,\nand deep learning-based methods for EDA signal decomposition, with a focus on\nin-the-wild data collected from wearable devices. In particular, the authors\nintroduce the Feel Transformer, a novel Transformer-based model adapted from\nthe Autoformer architecture, designed to separate phasic and tonic components\nwithout explicit supervision. The model leverages pooling and trend-removal\nmechanisms to enforce physiologically meaningful decompositions. Comparative\nexperiments against methods such as Ledalab, cvxEDA, and conventional\ndetrending show that the Feel Transformer achieves a balance between feature\nfidelity (SCR frequency, amplitude, and tonic slope) and robustness to noisy,\nreal-world data. The model demonstrates potential for real-time biosignal\nanalysis and future applications in stress prediction, digital mental health\ninterventions, and physiological forecasting.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6bd4\u8f83\u4e86\u77e5\u8bc6\u9a71\u52a8\u3001\u7edf\u8ba1\u548c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5728EDA\u4fe1\u53f7\u5206\u89e3\u4e2d\u7684\u8868\u73b0\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578bTransformer\u6a21\u578b\uff08Feel Transformer\uff09\uff0c\u5728\u771f\u5b9e\u6570\u636e\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5206\u89e3EDA\u4fe1\u53f7\u4e3a\u76f8\u4f4d\u548c\u5f20\u529b\u6210\u5206\u5bf9\u63d0\u53d6\u60c5\u611f\u548c\u751f\u7406\u6807\u5fd7\u7269\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u771f\u5b9e\u6570\u636e\u4e2d\u8868\u73b0\u4e0d\u8db3\u3002", "method": "\u63d0\u51faFeel Transformer\u6a21\u578b\uff0c\u57fa\u4e8eAutoformer\u67b6\u6784\uff0c\u5229\u7528\u6c60\u5316\u548c\u8d8b\u52bf\u53bb\u9664\u673a\u5236\u5b9e\u73b0\u65e0\u76d1\u7763\u5206\u89e3\u3002", "result": "Feel Transformer\u5728\u7279\u5f81\u4fdd\u771f\u5ea6\u548c\u6297\u566a\u6027\u4e0a\u4f18\u4e8eLedalab\u3001cvxEDA\u7b49\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6a21\u578b\u5728\u5b9e\u65f6\u751f\u7269\u4fe1\u53f7\u5206\u6790\u548c\u5fc3\u7406\u5065\u5eb7\u5e72\u9884\u4e2d\u5177\u6709\u6f5c\u529b\u3002"}}
{"id": "2506.06382", "pdf": "https://arxiv.org/pdf/2506.06382", "abs": "https://arxiv.org/abs/2506.06382", "authors": ["Micha\u0142 P. Karpowicz"], "title": "On the Fundamental Impossibility of Hallucination Control in Large Language Models", "categories": ["stat.ML", "cs.AI", "cs.CL", "cs.GT", "cs.LG"], "comment": null, "summary": "This paper explains \\textbf{why it is impossible to create large language\nmodels that do not hallucinate and what are the trade-offs we should be looking\nfor}. It presents a formal \\textbf{impossibility theorem} demonstrating that no\ninference mechanism can simultaneously satisfy four fundamental properties:\n\\textbf{truthful (non-hallucinatory) generation, semantic information\nconservation, relevant knowledge revelation, and knowledge-constrained\noptimality}. By modeling LLM inference as an \\textbf{auction of ideas} where\nneural components compete to contribute to responses, we prove the\nimpossibility using the Green-Laffont theorem. That mathematical framework\nprovides a rigorous foundation for understanding the nature of inference\nprocess, with implications for model architecture, training objectives, and\nevaluation methods.", "AI": {"tldr": "\u672c\u6587\u8bc1\u660e\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65e0\u6cd5\u5b8c\u5168\u907f\u514d\u5e7b\u89c9\uff0c\u5e76\u63d0\u51fa\u4e86\u56db\u4e2a\u4e0d\u53ef\u517c\u5f97\u7684\u57fa\u672c\u5c5e\u6027\u3002", "motivation": "\u63a2\u8ba8\u4e3a\u4ec0\u4e48\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65e0\u6cd5\u5b8c\u5168\u907f\u514d\u5e7b\u89c9\uff0c\u5e76\u660e\u786e\u5176\u5185\u5728\u7684\u6743\u8861\u5173\u7cfb\u3002", "method": "\u901a\u8fc7\u5c06LLM\u63a8\u7406\u5efa\u6a21\u4e3a\u201c\u60f3\u6cd5\u62cd\u5356\u201d\uff0c\u5e76\u5229\u7528Green-Laffont\u5b9a\u7406\u8bc1\u660e\u5176\u4e0d\u53ef\u80fd\u6027\u3002", "result": "\u8bc1\u660e\u4e86\u6ca1\u6709\u4efb\u4f55\u63a8\u7406\u673a\u5236\u80fd\u540c\u65f6\u6ee1\u8db3\u56db\u4e2a\u57fa\u672c\u5c5e\u6027\u3002", "conclusion": "\u4e3a\u7406\u89e3\u63a8\u7406\u8fc7\u7a0b\u7684\u672c\u8d28\u63d0\u4f9b\u4e86\u4e25\u683c\u6570\u5b66\u57fa\u7840\uff0c\u5bf9\u6a21\u578b\u67b6\u6784\u3001\u8bad\u7ec3\u76ee\u6807\u548c\u8bc4\u4f30\u65b9\u6cd5\u6709\u91cd\u8981\u542f\u793a\u3002"}}
{"id": "2506.06387", "pdf": "https://arxiv.org/pdf/2506.06387", "abs": "https://arxiv.org/abs/2506.06387", "authors": ["Baptiste Chatelier", "Vincent Corlay", "Musa Furkan Keskin", "Matthieu Crussi\u00e8re", "Henk Wymeersch", "Luc Le Magoarou"], "title": "Model-based Neural Data Augmentation for sub-wavelength Radio Localization", "categories": ["eess.SP", "cs.AI", "cs.IT", "cs.LG", "math.IT"], "comment": null, "summary": "The increasing deployment of large antenna arrays at base stations has\nsignificantly improved the spatial resolution and localization accuracy of\nradio-localization methods. However, traditional signal processing techniques\nstruggle in complex radio environments, particularly in scenarios dominated by\nnon line of sight (NLoS) propagation paths, resulting in degraded localization\naccuracy. Recent developments in machine learning have facilitated the\ndevelopment of machine learning-assisted localization techniques, enhancing\nlocalization accuracy in complex radio environments. However, these methods\noften involve substantial computational complexity during both the training and\ninference phases. This work extends the well-established fingerprinting-based\nlocalization framework by simultaneously reducing its memory requirements and\nimproving its accuracy. Specifically, a model-based neural network is used to\nlearn the location-to-channel mapping, and then serves as a generative neural\nchannel model. This generative model augments the fingerprinting comparison\ndictionary while reducing the memory requirements. The proposed method\noutperforms fingerprinting baselines by achieving sub-wavelength localization\naccuracy, even in NLoS environments. Remarkably, it offers an improvement by\nseveral orders of magnitude in localization accuracy, while simultaneously\nreducing memory requirements by an order of magnitude compared to classical\nfingerprinting methods.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u578b\u795e\u7ecf\u7f51\u7edc\u7684\u6307\u7eb9\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u590d\u6742\u65e0\u7ebf\u73af\u5883\u4e2d\u7684\u5b9a\u4f4d\u7cbe\u5ea6\uff0c\u540c\u65f6\u964d\u4f4e\u4e86\u5185\u5b58\u9700\u6c42\u3002", "motivation": "\u4f20\u7edf\u4fe1\u53f7\u5904\u7406\u6280\u672f\u5728\u590d\u6742\u65e0\u7ebf\u73af\u5883\uff08\u5c24\u5176\u662f\u975e\u89c6\u8ddd\u4f20\u64ad\u573a\u666f\uff09\u4e2d\u5b9a\u4f4d\u7cbe\u5ea6\u4e0b\u964d\uff0c\u800c\u73b0\u6709\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u3002", "method": "\u4f7f\u7528\u6a21\u578b\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u4f4d\u7f6e\u5230\u4fe1\u9053\u7684\u6620\u5c04\uff0c\u4f5c\u4e3a\u751f\u6210\u795e\u7ecf\u4fe1\u9053\u6a21\u578b\uff0c\u589e\u5f3a\u6307\u7eb9\u6bd4\u8f83\u5b57\u5178\u5e76\u51cf\u5c11\u5185\u5b58\u9700\u6c42\u3002", "result": "\u5728\u975e\u89c6\u8ddd\u73af\u5883\u4e2d\u5b9e\u73b0\u4e9a\u6ce2\u957f\u7ea7\u5b9a\u4f4d\u7cbe\u5ea6\uff0c\u5b9a\u4f4d\u7cbe\u5ea6\u63d0\u5347\u6570\u4e2a\u6570\u91cf\u7ea7\uff0c\u5185\u5b58\u9700\u6c42\u964d\u4f4e\u4e00\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u63d0\u5347\u5b9a\u4f4d\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u5185\u5b58\u9700\u6c42\uff0c\u9002\u7528\u4e8e\u590d\u6742\u65e0\u7ebf\u73af\u5883\u3002"}}
{"id": "2506.06389", "pdf": "https://arxiv.org/pdf/2506.06389", "abs": "https://arxiv.org/abs/2506.06389", "authors": ["Rifat Sadik", "Tanvir Rahman", "Arpan Bhattacharjee", "Bikash Chandra Halder", "Ismail Hossain"], "title": "Exploring Adversarial Watermarking in Transformer-Based Models: Transferability and Robustness Against Defense Mechanism for Medical Images", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Deep learning models have shown remarkable success in dermatological image\nanalysis, offering potential for automated skin disease diagnosis. Previously,\nconvolutional neural network(CNN) based architectures have achieved immense\npopularity and success in computer vision (CV) based task like skin image\nrecognition, generation and video analysis. But with the emergence of\ntransformer based models, CV tasks are now are nowadays carrying out using\nthese models. Vision Transformers (ViTs) is such a transformer-based models\nthat have shown success in computer vision. It uses self-attention mechanisms\nto achieve state-of-the-art performance across various tasks. However, their\nreliance on global attention mechanisms makes them susceptible to adversarial\nperturbations. This paper aims to investigate the susceptibility of ViTs for\nmedical images to adversarial watermarking-a method that adds so-called\nimperceptible perturbations in order to fool models. By generating adversarial\nwatermarks through Projected Gradient Descent (PGD), we examine the\ntransferability of such attacks to CNNs and analyze the performance defense\nmechanism -- adversarial training. Results indicate that while performance is\nnot compromised for clean images, ViTs certainly become much more vulnerable to\nadversarial attacks: an accuracy drop of as low as 27.6%. Nevertheless,\nadversarial training raises it up to 90.0%.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u89c6\u89c9Transformer\uff08ViT\uff09\u7684\u533b\u5b66\u56fe\u50cf\u5bf9\u6297\u6c34\u5370\u653b\u51fb\u7684\u8106\u5f31\u6027\uff0c\u5e76\u63a2\u8ba8\u4e86\u5bf9\u6297\u8bad\u7ec3\u4f5c\u4e3a\u9632\u5fa1\u673a\u5236\u7684\u6548\u679c\u3002", "motivation": "\u968f\u7740Transformer\u6a21\u578b\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\u4e2d\u7684\u6210\u529f\u5e94\u7528\uff0c\u672c\u6587\u65e8\u5728\u8bc4\u4f30ViT\u5728\u533b\u5b66\u56fe\u50cf\u4e2d\u5bf9\u5bf9\u6297\u6c34\u5370\u653b\u51fb\u7684\u8106\u5f31\u6027\uff0c\u5e76\u4e0eCNN\u8fdb\u884c\u6bd4\u8f83\u3002", "method": "\u901a\u8fc7\u6295\u5f71\u68af\u5ea6\u4e0b\u964d\uff08PGD\uff09\u751f\u6210\u5bf9\u6297\u6c34\u5370\uff0c\u6d4b\u8bd5ViT\u548cCNN\u7684\u8106\u5f31\u6027\uff0c\u5e76\u5206\u6790\u5bf9\u6297\u8bad\u7ec3\u7684\u6548\u679c\u3002", "result": "ViT\u5bf9\u5bf9\u6297\u653b\u51fb\u975e\u5e38\u8106\u5f31\uff0c\u51c6\u786e\u7387\u6700\u4f4e\u964d\u81f327.6%\uff0c\u4f46\u5bf9\u6297\u8bad\u7ec3\u53ef\u5c06\u5176\u63d0\u5347\u81f390.0%\u3002", "conclusion": "\u5c3d\u7ba1ViT\u5728\u5bf9\u6297\u653b\u51fb\u4e0b\u8868\u73b0\u8106\u5f31\uff0c\u4f46\u5bf9\u6297\u8bad\u7ec3\u80fd\u663e\u8457\u63d0\u5347\u5176\u9c81\u68d2\u6027\uff0c\u4e3a\u533b\u5b66\u56fe\u50cf\u5206\u6790\u63d0\u4f9b\u4e86\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.06395", "pdf": "https://arxiv.org/pdf/2506.06395", "abs": "https://arxiv.org/abs/2506.06395", "authors": ["Pengyi Li", "Matvey Skripkin", "Alexander Zubrey", "Andrey Kuznetsov", "Ivan Oseledets"], "title": "Confidence Is All You Need: Few-Shot RL Fine-Tuning of Language Models", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) excel at reasoning, yet post-training remains\ncritical for aligning their behavior with task goals. Existing reinforcement\nlearning (RL) methods often depend on costly human annotations or external\nreward models. We propose Reinforcement Learning via Self-Confidence (RLSC),\nwhich uses the model's own confidence as reward signals-eliminating the need\nfor labels, preference models, or reward engineering. Applied to\nQwen2.5-Math-7B with only 8 samples per question and 4 training epochs, RLSC\nimproves accuracy by +20.10% on AIME2024, +49.40% on MATH500, and +52.50% on\nAMC23. RLSC offers a simple, scalable post-training method for reasoning models\nwith minimal supervision.", "AI": {"tldr": "RLSC\u662f\u4e00\u79cd\u5229\u7528\u6a21\u578b\u81ea\u8eab\u7f6e\u4fe1\u5ea6\u4f5c\u4e3a\u5956\u52b1\u4fe1\u53f7\u7684\u540e\u8bad\u7ec3\u65b9\u6cd5\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u6216\u5916\u90e8\u5956\u52b1\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u6602\u8d35\u7684\u4eba\u5de5\u6807\u6ce8\u6216\u5916\u90e8\u5956\u52b1\u6a21\u578b\uff0cRLSC\u65e8\u5728\u901a\u8fc7\u6a21\u578b\u81ea\u8eab\u7f6e\u4fe1\u5ea6\u7b80\u5316\u540e\u8bad\u7ec3\u8fc7\u7a0b\u3002", "method": "RLSC\u901a\u8fc7\u6a21\u578b\u81ea\u8eab\u7f6e\u4fe1\u5ea6\u751f\u6210\u5956\u52b1\u4fe1\u53f7\uff0c\u5e94\u7528\u4e8eQwen2.5-Math-7B\u6a21\u578b\uff0c\u4ec5\u9700\u5c11\u91cf\u6837\u672c\u548c\u8bad\u7ec3\u8f6e\u6b21\u3002", "result": "\u5728AIME2024\u3001MATH500\u548cAMC23\u4efb\u52a1\u4e0a\uff0cRLSC\u5206\u522b\u63d0\u5347\u4e8620.10%\u300149.40%\u548c52.50%\u7684\u51c6\u786e\u7387\u3002", "conclusion": "RLSC\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u3001\u53ef\u6269\u5c55\u4e14\u65e0\u9700\u5927\u91cf\u76d1\u7763\u7684\u540e\u8bad\u7ec3\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u63a8\u7406\u6a21\u578b\u3002"}}
{"id": "2506.06401", "pdf": "https://arxiv.org/pdf/2506.06401", "abs": "https://arxiv.org/abs/2506.06401", "authors": ["Hongming Yang", "Shi Lin", "Jun Shao", "Changting Lin", "Donghai Zhu", "Meng Han", "Qinglei Kong"], "title": "Direct Behavior Optimization: Unlocking the Potential of Lightweight LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "This work is accepted at ACL 2025", "summary": "Lightweight Large Language Models (LwLLMs) are reduced-parameter, optimized\nmodels designed to run efficiently on consumer-grade hardware, offering\nsignificant advantages in resource efficiency, cost-effectiveness, and data\nprivacy. However, these models often struggle with limited inference and\nreasoning capabilities, which restrict their performance on complex tasks and\nlimit their practical applicability. Moreover, existing prompt optimization\nmethods typically rely on extensive manual effort or the meta-cognitive\nabilities of state-of-the-art LLMs, making them less effective for LwLLMs. To\naddress these challenges, we introduce DeBoP, a new Direct Behavior\nOptimization Paradigm, original from the Chain-of-Thought (CoT) prompting\ntechnique. Unlike CoT Prompting, DeBoP is an automatic optimization method,\nwhich focuses on the optimization directly on the behavior of LwLLMs. In\nparticular, DeBoP transforms the optimization of complex prompts into the\noptimization of discrete, quantifiable execution sequences using a\ngradient-free Monte Carlo Tree Search. We evaluate DeBoP on seven challenging\ntasks where state-of-the-art LLMs excel but LwLLMs generally underperform.\nExperimental results demonstrate that DeBoP significantly outperforms recent\nprompt optimization methods on most tasks. In particular, DeBoP-optimized\nLwLLMs surpass GPT-3.5 on most tasks while reducing computational time by\napproximately 60% compared to other automatic prompt optimization methods.", "AI": {"tldr": "DeBoP\u662f\u4e00\u79cd\u65b0\u7684\u76f4\u63a5\u884c\u4e3a\u4f18\u5316\u8303\u5f0f\uff0c\u4e13\u4e3a\u8f7b\u91cf\u7ea7\u5927\u8bed\u8a00\u6a21\u578b\uff08LwLLMs\uff09\u8bbe\u8ba1\uff0c\u901a\u8fc7\u68af\u5ea6\u81ea\u7531\u7684\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u4f18\u5316\u6267\u884c\u5e8f\u5217\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "LwLLMs\u5728\u63a8\u7406\u548c\u590d\u6742\u4efb\u52a1\u4e0a\u8868\u73b0\u53d7\u9650\uff0c\u73b0\u6709\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u6216\u9ad8\u6027\u80fdLLMs\uff0c\u4e0d\u9002\u7528\u4e8eLwLLMs\u3002", "method": "DeBoP\u5c06\u590d\u6742\u63d0\u793a\u4f18\u5316\u8f6c\u5316\u4e3a\u79bb\u6563\u3001\u53ef\u91cf\u5316\u7684\u6267\u884c\u5e8f\u5217\u4f18\u5316\uff0c\u91c7\u7528\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u3002", "result": "DeBoP\u5728\u4e03\u9879\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4f18\u5316\u540e\u7684LwLLMs\u6027\u80fd\u8d85\u8d8aGPT-3.5\uff0c\u8ba1\u7b97\u65f6\u95f4\u51cf\u5c1160%\u3002", "conclusion": "DeBoP\u4e3aLwLLMs\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u81ea\u52a8\u5316\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u5176\u5b9e\u9645\u5e94\u7528\u80fd\u529b\u3002"}}
{"id": "2506.06404", "pdf": "https://arxiv.org/pdf/2506.06404", "abs": "https://arxiv.org/abs/2506.06404", "authors": ["Sooyung Choi", "Jaehyeok Lee", "Xiaoyuan Yi", "Jing Yao", "Xing Xie", "JinYeong Bak"], "title": "Unintended Harms of Value-Aligned LLMs: Psychological and Empirical Insights", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "comment": "Accepted to ACL 2025", "summary": "The application scope of Large Language Models (LLMs) continues to expand,\nleading to increasing interest in personalized LLMs that align with human\nvalues. However, aligning these models with individual values raises\nsignificant safety concerns, as certain values may correlate with harmful\ninformation. In this paper, we identify specific safety risks associated with\nvalue-aligned LLMs and investigate the psychological principles behind these\nchallenges. Our findings reveal two key insights. (1) Value-aligned LLMs are\nmore prone to harmful behavior compared to non-fine-tuned models and exhibit\nslightly higher risks in traditional safety evaluations than other fine-tuned\nmodels. (2) These safety issues arise because value-aligned LLMs genuinely\ngenerate text according to the aligned values, which can amplify harmful\noutcomes. Using a dataset with detailed safety categories, we find significant\ncorrelations between value alignment and safety risks, supported by\npsychological hypotheses. This study offers insights into the \"black box\" of\nvalue alignment and proposes in-context alignment methods to enhance the safety\nof value-aligned LLMs.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u5bf9\u9f50\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u66f4\u5bb9\u6613\u4ea7\u751f\u6709\u5bb3\u884c\u4e3a\uff0c\u4e14\u5b89\u5168\u98ce\u9669\u9ad8\u4e8e\u672a\u5fae\u8c03\u6216\u5176\u4ed6\u5fae\u8c03\u6a21\u578b\u3002", "motivation": "\u968f\u7740LLMs\u5e94\u7528\u8303\u56f4\u6269\u5927\uff0c\u4e2a\u6027\u5316\u5bf9\u9f50\u4eba\u7c7b\u4ef7\u503c\u89c2\u7684\u9700\u6c42\u589e\u52a0\uff0c\u4f46\u540c\u65f6\u4e5f\u5e26\u6765\u4e86\u6f5c\u5728\u7684\u5b89\u5168\u98ce\u9669\u3002", "method": "\u901a\u8fc7\u6570\u636e\u96c6\u5206\u6790\uff0c\u7ed3\u5408\u5fc3\u7406\u5b66\u5047\u8bbe\uff0c\u7814\u7a76\u4ef7\u503c\u89c2\u5bf9\u9f50\u4e0e\u5b89\u5168\u98ce\u9669\u7684\u5173\u7cfb\u3002", "result": "\u4ef7\u503c\u89c2\u5bf9\u9f50\u7684LLMs\u66f4\u5bb9\u6613\u751f\u6210\u6709\u5bb3\u5185\u5bb9\uff0c\u4e14\u5b89\u5168\u98ce\u9669\u66f4\u9ad8\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u4ef7\u503c\u89c2\u5bf9\u9f50\u7684\u201c\u9ed1\u7bb1\u201d\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e0a\u4e0b\u6587\u5bf9\u9f50\u65b9\u6cd5\u4ee5\u63d0\u5347\u5b89\u5168\u6027\u3002"}}
{"id": "2506.06407", "pdf": "https://arxiv.org/pdf/2506.06407", "abs": "https://arxiv.org/abs/2506.06407", "authors": ["Zhi Wen Soi", "Chaoyi Zhu", "Fouad Abiad", "Aditya Shankar", "Jeroen M. Galjaard", "Huijuan Wang", "Lydia Y. Chen"], "title": "TimeWak: Temporal Chained-Hashing Watermark for Time Series Data", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.MM"], "comment": null, "summary": "Synthetic time series generated by diffusion models enable sharing\nprivacy-sensitive datasets, such as patients' functional MRI records. Key\ncriteria for synthetic data include high data utility and traceability to\nverify the data source. Recent watermarking methods embed in homogeneous latent\nspaces, but state-of-the-art time series generators operate in real space,\nmaking latent-based watermarking incompatible. This creates the challenge of\nwatermarking directly in real space while handling feature heterogeneity and\ntemporal dependencies. We propose TimeWak, the first watermarking algorithm for\nmultivariate time series diffusion models. To handle temporal dependence and\nspatial heterogeneity, TimeWak embeds a temporal chained-hashing watermark\ndirectly within the real temporal-feature space. The other unique feature is\nthe $\\epsilon$-exact inversion, which addresses the non-uniform reconstruction\nerror distribution across features from inverting the diffusion process to\ndetect watermarks. We derive the error bound of inverting multivariate time\nseries and further maintain high watermark detectability. We extensively\nevaluate TimeWak on its impact on synthetic data quality, watermark\ndetectability, and robustness under various post-editing attacks, against 5\ndatasets and baselines of different temporal lengths. Our results show that\nTimeWak achieves improvements of 61.96% in context-FID score, and 8.44% in\ncorrelational scores against the state-of-the-art baseline, while remaining\nconsistently detectable.", "AI": {"tldr": "TimeWak\u662f\u4e00\u79cd\u7528\u4e8e\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u6269\u6563\u6a21\u578b\u7684\u6c34\u5370\u7b97\u6cd5\uff0c\u76f4\u63a5\u5728\u771f\u5b9e\u65f6\u95f4-\u7279\u5f81\u7a7a\u95f4\u4e2d\u5d4c\u5165\u6c34\u5370\uff0c\u89e3\u51b3\u4e86\u7279\u5f81\u5f02\u8d28\u6027\u548c\u65f6\u95f4\u4f9d\u8d56\u6027\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u6c34\u5370\u65b9\u6cd5\u5728\u771f\u5b9e\u7a7a\u95f4\u751f\u6210\u7684\u65f6\u95f4\u5e8f\u5217\u4e2d\u4e0d\u517c\u5bb9\u7684\u95ee\u9898\uff0c\u540c\u65f6\u786e\u4fdd\u6570\u636e\u7684\u9ad8\u6548\u7528\u6027\u548c\u53ef\u8ffd\u6eaf\u6027\u3002", "method": "\u63d0\u51faTimeWak\u7b97\u6cd5\uff0c\u5d4c\u5165\u65f6\u95f4\u94fe\u5f0f\u54c8\u5e0c\u6c34\u5370\uff0c\u5e76\u91c7\u7528\u03b5-\u7cbe\u786e\u53cd\u8f6c\u6280\u672f\u5904\u7406\u6269\u6563\u8fc7\u7a0b\u7684\u53cd\u8f6c\u8bef\u5dee\u3002", "result": "\u57285\u4e2a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0cTimeWak\u5728\u5408\u6210\u6570\u636e\u8d28\u91cf\u548c\u6c34\u5370\u53ef\u68c0\u6d4b\u6027\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u63d0\u5347\u4e8661.96%\u7684context-FID\u5206\u6570\u548c8.44%\u7684\u76f8\u5173\u6027\u5206\u6570\u3002", "conclusion": "TimeWak\u6709\u6548\u89e3\u51b3\u4e86\u65f6\u95f4\u5e8f\u5217\u6c34\u5370\u7684\u6311\u6218\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u6570\u636e\u8d28\u91cf\u548c\u53ef\u68c0\u6d4b\u6027\u3002"}}
{"id": "2506.06409", "pdf": "https://arxiv.org/pdf/2506.06409", "abs": "https://arxiv.org/abs/2506.06409", "authors": ["Dor Tsur", "Carol Xuan Long", "Claudio Mayrink Verdun", "Hsiang Hsu", "Chen-Fu Chen", "Haim Permuter", "Sajani Vithana", "Flavio P. Calmon"], "title": "HeavyWater and SimplexWater: Watermarking Low-Entropy Text Distributions", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.CY", "cs.IT", "cs.LG", "math.IT"], "comment": null, "summary": "Large language model (LLM) watermarks enable authentication of text\nprovenance, curb misuse of machine-generated text, and promote trust in AI\nsystems. Current watermarks operate by changing the next-token predictions\noutput by an LLM. The updated (i.e., watermarked) predictions depend on random\nside information produced, for example, by hashing previously generated tokens.\nLLM watermarking is particularly challenging in low-entropy generation tasks -\nsuch as coding - where next-token predictions are near-deterministic. In this\npaper, we propose an optimization framework for watermark design. Our goal is\nto understand how to most effectively use random side information in order to\nmaximize the likelihood of watermark detection and minimize the distortion of\ngenerated text. Our analysis informs the design of two new watermarks:\nHeavyWater and SimplexWater. Both watermarks are tunable, gracefully\ntrading-off between detection accuracy and text distortion. They can also be\napplied to any LLM and are agnostic to side information generation. We examine\nthe performance of HeavyWater and SimplexWater through several benchmarks,\ndemonstrating that they can achieve high watermark detection accuracy with\nminimal compromise of text generation quality, particularly in the low-entropy\nregime. Our theoretical analysis also reveals surprising new connections\nbetween LLM watermarking and coding theory. The code implementation can be\nfound in https://github.com/DorTsur/HeavyWater_SimplexWater", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f18\u5316\u6846\u67b6\uff0c\u8bbe\u8ba1\u4e86\u4e24\u79cd\u65b0\u578b\u6c34\u5370\uff08HeavyWater\u548cSimplexWater\uff09\uff0c\u5728\u4f4e\u71b5\u4efb\u52a1\u4e2d\u5b9e\u73b0\u9ad8\u68c0\u6d4b\u7cbe\u5ea6\u548c\u4f4e\u6587\u672c\u5931\u771f\u3002", "motivation": "\u89e3\u51b3LLM\u6c34\u5370\u5728\u4f4e\u71b5\u4efb\u52a1\uff08\u5982\u7f16\u7801\uff09\u4e2d\u7684\u6311\u6218\uff0c\u4f18\u5316\u968f\u673a\u4fa7\u4fe1\u606f\u7684\u4f7f\u7528\u4ee5\u63d0\u9ad8\u68c0\u6d4b\u6982\u7387\u5e76\u51cf\u5c11\u6587\u672c\u5931\u771f\u3002", "method": "\u63d0\u51fa\u4f18\u5316\u6846\u67b6\uff0c\u8bbe\u8ba1\u4e24\u79cd\u53ef\u8c03\u6c34\u5370\uff08HeavyWater\u548cSimplexWater\uff09\uff0c\u9002\u7528\u4e8e\u4efb\u4f55LLM\u4e14\u4e0d\u4f9d\u8d56\u4fa7\u4fe1\u606f\u751f\u6210\u65b9\u5f0f\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4e24\u79cd\u6c34\u5370\u5728\u4f4e\u71b5\u4efb\u52a1\u4e2d\u80fd\u5b9e\u73b0\u9ad8\u68c0\u6d4b\u7cbe\u5ea6\u4e14\u5bf9\u6587\u672c\u8d28\u91cf\u5f71\u54cd\u5c0f\u3002", "conclusion": "\u65b0\u6c34\u5370\u65b9\u6cd5\u6709\u6548\u5e73\u8861\u68c0\u6d4b\u7cbe\u5ea6\u4e0e\u6587\u672c\u8d28\u91cf\uff0c\u63ed\u793a\u4e86\u6c34\u5370\u4e0e\u7f16\u7801\u7406\u8bba\u7684\u65b0\u8054\u7cfb\u3002"}}
{"id": "2506.06410", "pdf": "https://arxiv.org/pdf/2506.06410", "abs": "https://arxiv.org/abs/2506.06410", "authors": ["Gabriel Nova", "Sander van Cranenburgh", "Stephane Hess"], "title": "Improving choice model specification using reinforcement learning", "categories": ["econ.GN", "cs.LG", "q-fin.EC"], "comment": "13 pages, 7 figures", "summary": "Discrete choice modelling is a theory-driven modelling framework for\nunderstanding and forecasting choice behaviour. To obtain behavioural insights,\nmodellers test several competing model specifications in their attempts to\ndiscover the 'true' data generation process. This trial-and-error process\nrequires expertise, is time-consuming, and relies on subjective theoretical\nassumptions. Although metaheuristics have been proposed to assist choice\nmodellers, they treat model specification as a classic optimisation problem,\nrelying on static strategies, applying predefined rules, and neglecting\noutcomes from previous estimated models. As a result, current metaheuristics\nstruggle to prioritise promising search regions, adapt exploration dynamically,\nand transfer knowledge to other modelling tasks. To address these limitations,\nwe introduce a deep reinforcement learning-based framework where an 'agent'\nspecifies models by estimating them and receiving rewards based on\ngoodness-of-fit and parsimony. Results demonstrate the agent dynamically adapts\nits strategies to identify promising specifications across data generation\nprocesses, showing robustness and potential transferability, without prior\ndomain knowledge.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u52a8\u6001\u4f18\u5316\u79bb\u6563\u9009\u62e9\u6a21\u578b\u7684\u89c4\u683c\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u9759\u6001\u6027\u548c\u4e3b\u89c2\u6027\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u79bb\u6563\u9009\u62e9\u6a21\u578b\u89c4\u683c\u7684\u8bd5\u9519\u8fc7\u7a0b\u4f9d\u8d56\u4e13\u5bb6\u7ecf\u9a8c\u3001\u8017\u65f6\u4e14\u4e3b\u89c2\uff0c\u73b0\u6709\u5143\u542f\u53d1\u5f0f\u65b9\u6cd5\u65e0\u6cd5\u52a8\u6001\u8c03\u6574\u641c\u7d22\u7b56\u7565\u6216\u8f6c\u79fb\u77e5\u8bc6\u3002", "method": "\u91c7\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u4ee3\u7406\u6a21\u578b\u4f30\u8ba1\u548c\u57fa\u4e8e\u62df\u5408\u4f18\u5ea6\u4e0e\u7b80\u7ea6\u6027\u7684\u5956\u52b1\u673a\u5236\uff0c\u52a8\u6001\u8c03\u6574\u6a21\u578b\u89c4\u683c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u80fd\u52a8\u6001\u9002\u5e94\u4e0d\u540c\u6570\u636e\u751f\u6210\u8fc7\u7a0b\uff0c\u5177\u6709\u9c81\u68d2\u6027\u548c\u6f5c\u5728\u7684\u53ef\u8f6c\u79fb\u6027\uff0c\u65e0\u9700\u5148\u9a8c\u9886\u57df\u77e5\u8bc6\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u79bb\u6563\u9009\u62e9\u6a21\u578b\u89c4\u683c\u63d0\u4f9b\u4e86\u4e00\u79cd\u81ea\u52a8\u5316\u3001\u52a8\u6001\u5316\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6548\u7387\u548c\u9002\u5e94\u6027\u3002"}}
{"id": "2506.06446", "pdf": "https://arxiv.org/pdf/2506.06446", "abs": "https://arxiv.org/abs/2506.06446", "authors": ["Ivi Chatzi", "Nina Corvelo Benz", "Stratis Tsirtsis", "Manuel Gomez-Rodriguez"], "title": "Canonical Autoregressive Generation", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "comment": null, "summary": "State of the art large language models are trained using large amounts of\ntokens derived from raw text using what is called a tokenizer. Crucially, the\ntokenizer determines the (token) vocabulary a model will use during inference\nas well as, in principle, the (token) language. This is because, while the\ntoken vocabulary may allow for different tokenizations of a string, the\ntokenizer always maps the string to only one of these tokenizations--the\ncanonical tokenization. However, multiple lines of empirical evidence suggest\nthat large language models do not always generate canonical token sequences,\nand this comes with several negative consequences. In this work, we first show\nthat, to generate a canonical token sequence, a model needs to generate\n(partial) canonical token sequences at each step of the autoregressive\ngeneration process underpinning its functioning. Building upon this theoretical\nresult, we introduce canonical sampling, a simple and efficient sampling method\nthat precludes a given model from generating non-canonical token sequences.\nFurther, we also show that, in comparison with standard sampling, the\ndistribution of token sequences generated using canonical sampling is provably\ncloser to the true distribution of token sequences used during training.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3a\u201c\u89c4\u8303\u91c7\u6837\u201d\u7684\u65b9\u6cd5\uff0c\u65e8\u5728\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u975e\u89c4\u8303\u6807\u8bb0\u5e8f\u5217\u7684\u95ee\u9898\uff0c\u5e76\u8bc1\u660e\u5176\u751f\u6210\u7684\u5e8f\u5217\u66f4\u63a5\u8fd1\u8bad\u7ec3\u6570\u636e\u7684\u771f\u5b9e\u5206\u5e03\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u6587\u672c\u65f6\u53ef\u80fd\u4ea7\u751f\u975e\u89c4\u8303\u7684\u6807\u8bb0\u5e8f\u5217\uff0c\u8fd9\u5bf9\u6a21\u578b\u6027\u80fd\u6709\u8d1f\u9762\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\uff0c\u63d0\u51fa\u201c\u89c4\u8303\u91c7\u6837\u201d\u65b9\u6cd5\uff0c\u786e\u4fdd\u6a21\u578b\u5728\u81ea\u56de\u5f52\u751f\u6210\u8fc7\u7a0b\u4e2d\u6bcf\u4e00\u6b65\u90fd\u751f\u6210\u89c4\u8303\u7684\u6807\u8bb0\u5e8f\u5217\u3002", "result": "\u89c4\u8303\u91c7\u6837\u65b9\u6cd5\u6709\u6548\u907f\u514d\u4e86\u975e\u89c4\u8303\u5e8f\u5217\u7684\u751f\u6210\uff0c\u4e14\u5176\u751f\u6210\u7684\u5e8f\u5217\u5206\u5e03\u66f4\u63a5\u8fd1\u8bad\u7ec3\u6570\u636e\u7684\u771f\u5b9e\u5206\u5e03\u3002", "conclusion": "\u89c4\u8303\u91c7\u6837\u662f\u4e00\u79cd\u7b80\u5355\u9ad8\u6548\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u6587\u672c\u7684\u89c4\u8303\u6027\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2506.06470", "pdf": "https://arxiv.org/pdf/2506.06470", "abs": "https://arxiv.org/abs/2506.06470", "authors": ["Yanwei Ren", "Haotian Zhang", "Fuxiang Wu", "Jiayan Qiu", "Jiaxing Huang", "Baosheng Yu", "Liu Liu"], "title": "SIGMA: Refining Large Language Model Reasoning via Sibling-Guided Monte Carlo Augmentation", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Enhancing large language models by simply scaling up datasets has begun to\nyield diminishing returns, shifting the spotlight to data quality. Monte Carlo\nTree Search (MCTS) has emerged as a powerful technique for generating\nhigh-quality chain-of-thought data, yet conventional approaches typically\nretain only the top-scoring trajectory from the search tree, discarding sibling\nnodes that often contain valuable partial insights, recurrent error patterns,\nand alternative reasoning strategies. This unconditional rejection of\nnon-optimal reasoning branches may waste vast amounts of informative data in\nthe whole search tree. We propose SIGMA (Sibling Guided Monte Carlo\nAugmentation), a novel framework that reintegrates these discarded sibling\nnodes to refine LLM reasoning. SIGMA forges semantic links among sibling nodes\nalong each search path and applies a two-stage refinement: a critique model\nidentifies overlooked strengths and weaknesses across the sibling set, and a\nrevision model conducts text-based backpropagation to refine the top-scoring\ntrajectory in light of this comparative feedback. By recovering and amplifying\nthe underutilized but valuable signals from non-optimal reasoning branches,\nSIGMA substantially improves reasoning trajectories. On the challenging MATH\nbenchmark, our SIGMA-tuned 7B model achieves 54.92% accuracy using only 30K\nsamples, outperforming state-of-the-art models trained on 590K samples. This\nresult highlights that our sibling-guided optimization not only significantly\nreduces data usage but also significantly boosts LLM reasoning.", "AI": {"tldr": "SIGMA\u6846\u67b6\u901a\u8fc7\u91cd\u65b0\u5229\u7528\u641c\u7d22\u6811\u4e2d\u88ab\u4e22\u5f03\u7684\u975e\u6700\u4f18\u5206\u652f\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4ec5\u4fdd\u7559\u641c\u7d22\u6811\u4e2d\u7684\u6700\u4f18\u8def\u5f84\uff0c\u5ffd\u89c6\u4e86\u975e\u6700\u4f18\u5206\u652f\u4e2d\u7684\u6709\u4ef7\u503c\u4fe1\u606f\uff0c\u5bfc\u81f4\u6570\u636e\u6d6a\u8d39\u3002", "method": "SIGMA\u901a\u8fc7\u8bed\u4e49\u94fe\u63a5\u548c\u4e24\u9636\u6bb5\u4f18\u5316\uff08\u6279\u8bc4\u6a21\u578b\u548c\u4fee\u8ba2\u6a21\u578b\uff09\u91cd\u65b0\u6574\u5408\u975e\u6700\u4f18\u5206\u652f\u6570\u636e\u3002", "result": "\u5728MATH\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSIGMA\u8c03\u6574\u76847B\u6a21\u578b\u4ec5\u752830K\u6837\u672c\u8fbe\u523054.92%\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u4f7f\u7528590K\u6837\u672c\u7684\u73b0\u6709\u6a21\u578b\u3002", "conclusion": "SIGMA\u4e0d\u4ec5\u51cf\u5c11\u6570\u636e\u9700\u6c42\uff0c\u8fd8\u663e\u8457\u63d0\u5347\u6a21\u578b\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2506.06472", "pdf": "https://arxiv.org/pdf/2506.06472", "abs": "https://arxiv.org/abs/2506.06472", "authors": ["Ziqi Yuan", "Haoyang Zhang", "Yirui Eric Zhou", "Apoorve Mohan", "I-Hsin Chung", "Seetharami Seelam", "Jian Huang"], "title": "Cost-Efficient LLM Training with Lifetime-Aware Tensor Offloading via GPUDirect Storage", "categories": ["cs.DC", "cs.AI", "cs.LG", "cs.PF"], "comment": null, "summary": "We present the design and implementation of a new lifetime-aware tensor\noffloading framework for GPU memory expansion using low-cost PCIe-based\nsolid-state drives (SSDs). Our framework, TERAIO, is developed explicitly for\nlarge language model (LLM) training with multiple GPUs and multiple SSDs. Its\ndesign is driven by our observation that the active tensors take only a small\nfraction (1.7% on average) of allocated GPU memory in each LLM training\niteration, the inactive tensors are usually large and will not be used for a\nlong period of time, creating ample opportunities for offloading/prefetching\ntensors to/from slow SSDs without stalling the GPU training process. TERAIO\naccurately estimates the lifetime (active period of time in GPU memory) of each\ntensor with the profiling of the first few iterations in the training process.\nWith the tensor lifetime analysis, TERAIO will generate an optimized tensor\noffloading/prefetching plan and integrate it into the compiled LLM program via\nPyTorch. TERAIO has a runtime tensor migration engine to execute the\noffloading/prefetching plan via GPUDirect storage, which allows direct tensor\nmigration between GPUs and SSDs for alleviating the CPU bottleneck and\nmaximizing the SSD bandwidth utilization. In comparison with state-of-the-art\nstudies such as ZeRO-Offload and ZeRO-Infinity, we show that TERAIO improves\nthe training performance of various LLMs by 1.47x on average, and achieves\n80.7% of the ideal performance assuming unlimited GPU memory.", "AI": {"tldr": "TERAIO\u662f\u4e00\u4e2a\u57fa\u4e8eSSD\u7684GPU\u5185\u5b58\u6269\u5c55\u6846\u67b6\uff0c\u901a\u8fc7\u667a\u80fd\u5f20\u91cf\u5378\u8f7d/\u9884\u53d6\u4f18\u5316LLM\u8bad\u7ec3\u6027\u80fd\u3002", "motivation": "\u89c2\u5bdf\u5230LLM\u8bad\u7ec3\u4e2d\u6d3b\u8dc3\u5f20\u91cf\u4ec5\u5360GPU\u5185\u5b58\u76841.7%\uff0c\u975e\u6d3b\u8dc3\u5f20\u91cf\u5360\u7528\u5927\u91cf\u5185\u5b58\u4e14\u957f\u65f6\u95f4\u672a\u4f7f\u7528\uff0c\u4e3aSSD\u5378\u8f7d/\u9884\u53d6\u63d0\u4f9b\u4e86\u673a\u4f1a\u3002", "method": "\u901a\u8fc7\u524d\u51e0\u6b21\u8fed\u4ee3\u5206\u6790\u5f20\u91cf\u751f\u547d\u5468\u671f\uff0c\u751f\u6210\u4f18\u5316\u5378\u8f7d/\u9884\u53d6\u8ba1\u5212\uff0c\u5e76\u96c6\u6210\u5230PyTorch\u4e2d\uff0c\u5229\u7528GPUDirect\u5b58\u50a8\u76f4\u63a5\u8fc1\u79fb\u5f20\u91cf\u3002", "result": "\u76f8\u6bd4\u73b0\u6709\u6280\u672f\uff08\u5982ZeRO-Offload\u548cZeRO-Infinity\uff09\uff0cTERAIO\u5e73\u5747\u63d0\u5347LLM\u8bad\u7ec3\u6027\u80fd1.47\u500d\uff0c\u8fbe\u5230\u7406\u60f3\u6027\u80fd\u768480.7%\u3002", "conclusion": "TERAIO\u901a\u8fc7\u9ad8\u6548\u5229\u7528SSD\u6269\u5c55GPU\u5185\u5b58\uff0c\u663e\u8457\u63d0\u5347LLM\u8bad\u7ec3\u6548\u7387\u3002"}}
{"id": "2506.06483", "pdf": "https://arxiv.org/pdf/2506.06483", "abs": "https://arxiv.org/abs/2506.06483", "authors": ["Yao Ni", "Song Wen", "Piotr Koniusz", "Anoop Cherian"], "title": "Noise Consistency Regularization for Improved Subject-Driven Image Synthesis", "categories": ["cs.GR", "cs.AI", "cs.CV", "cs.LG", "eess.IV"], "comment": null, "summary": "Fine-tuning Stable Diffusion enables subject-driven image synthesis by\nadapting the model to generate images containing specific subjects. However,\nexisting fine-tuning methods suffer from two key issues: underfitting, where\nthe model fails to reliably capture subject identity, and overfitting, where it\nmemorizes the subject image and reduces background diversity. To address these\nchallenges, we propose two auxiliary consistency losses for diffusion\nfine-tuning. First, a prior consistency regularization loss ensures that the\npredicted diffusion noise for prior (non-subject) images remains consistent\nwith that of the pretrained model, improving fidelity. Second, a subject\nconsistency regularization loss enhances the fine-tuned model's robustness to\nmultiplicative noise modulated latent code, helping to preserve subject\nidentity while improving diversity. Our experimental results demonstrate that\nincorporating these losses into fine-tuning not only preserves subject identity\nbut also enhances image diversity, outperforming DreamBooth in terms of CLIP\nscores, background variation, and overall visual quality.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e24\u79cd\u4e00\u81f4\u6027\u635f\u5931\u51fd\u6570\uff0c\u7528\u4e8e\u89e3\u51b3Stable Diffusion\u5fae\u8c03\u4e2d\u7684\u6b20\u62df\u5408\u548c\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u63d0\u5347\u751f\u6210\u56fe\u50cf\u7684\u591a\u6837\u6027\u548c\u4fdd\u771f\u5ea6\u3002", "motivation": "\u73b0\u6709\u5fae\u8c03\u65b9\u6cd5\u5728\u751f\u6210\u7279\u5b9a\u4e3b\u9898\u56fe\u50cf\u65f6\u5b58\u5728\u6b20\u62df\u5408\uff08\u65e0\u6cd5\u53ef\u9760\u6355\u6349\u4e3b\u9898\u8eab\u4efd\uff09\u548c\u8fc7\u62df\u5408\uff08\u8bb0\u5fc6\u4e3b\u9898\u56fe\u50cf\u5e76\u51cf\u5c11\u80cc\u666f\u591a\u6837\u6027\uff09\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u8f85\u52a9\u4e00\u81f4\u6027\u635f\u5931\uff1a\u5148\u9a8c\u4e00\u81f4\u6027\u6b63\u5219\u5316\u635f\u5931\uff08\u786e\u4fdd\u975e\u4e3b\u9898\u56fe\u50cf\u7684\u6269\u6563\u566a\u58f0\u4e0e\u9884\u8bad\u7ec3\u6a21\u578b\u4e00\u81f4\uff09\u548c\u4e3b\u9898\u4e00\u81f4\u6027\u6b63\u5219\u5316\u635f\u5931\uff08\u589e\u5f3a\u6a21\u578b\u5bf9\u566a\u58f0\u8c03\u5236\u6f5c\u5728\u4ee3\u7801\u7684\u9c81\u68d2\u6027\uff09\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u52a0\u5165\u8fd9\u4e9b\u635f\u5931\u540e\uff0c\u5fae\u8c03\u6a21\u578b\u5728CLIP\u5206\u6570\u3001\u80cc\u666f\u591a\u6837\u6027\u548c\u89c6\u89c9\u8d28\u91cf\u4e0a\u4f18\u4e8eDreamBooth\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u5fae\u8c03\u4e2d\u7684\u6b20\u62df\u5408\u548c\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u540c\u65f6\u63d0\u5347\u4e86\u751f\u6210\u56fe\u50cf\u7684\u591a\u6837\u6027\u548c\u4fdd\u771f\u5ea6\u3002"}}
{"id": "2506.06484", "pdf": "https://arxiv.org/pdf/2506.06484", "abs": "https://arxiv.org/abs/2506.06484", "authors": ["Manuel Sage", "Khalil Al Handawi", "Yaoyao Fiona Zhao"], "title": "The Economic Dispatch of Power-to-Gas Systems with Deep Reinforcement Learning:Tackling the Challenge of Delayed Rewards with Long-Term Energy Storage", "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.SY"], "comment": "Accepted for publication at the 19th ASME International Conference on\n  Energy Sustainability", "summary": "Power-to-Gas (P2G) technologies gain recognition for enabling the integration\nof intermittent renewables, such as wind and solar, into electricity grids.\nHowever, determining the most cost-effective operation of these systems is\ncomplex due to the volatile nature of renewable energy, electricity prices, and\nloads. Additionally, P2G systems are less efficient in converting and storing\nenergy compared to battery energy storage systems (BESs), and the benefits of\nconverting electricity into gas are not immediately apparent. Deep\nReinforcement Learning (DRL) has shown promise in managing the operation of\nenergy systems amidst these uncertainties. Yet, DRL techniques face\ndifficulties with the delayed reward characteristic of P2G system operation.\nPrevious research has mostly focused on short-term studies that look at the\nenergy conversion process, neglecting the long-term storage capabilities of\nP2G.\n  This study presents a new method by thoroughly examining how DRL can be\napplied to the economic operation of P2G systems, in combination with BESs and\ngas turbines, over extended periods. Through three progressively more complex\ncase studies, we assess the performance of DRL algorithms, specifically Deep\nQ-Networks and Proximal Policy Optimization, and introduce modifications to\nenhance their effectiveness. These modifications include integrating forecasts,\nimplementing penalties on the reward function, and applying strategic cost\ncalculations, all aimed at addressing the issue of delayed rewards. Our\nfindings indicate that while DRL initially struggles with the complex\ndecision-making required for P2G system operation, the adjustments we propose\nsignificantly improve its capability to devise cost-effective operation\nstrategies, thereby unlocking the potential for long-term energy storage in P2G\ntechnologies.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u4f18\u5316Power-to-Gas\uff08P2G\uff09\u7cfb\u7edf\u7684\u957f\u671f\u7ecf\u6d4e\u8fd0\u8425\uff0c\u7ed3\u5408\u7535\u6c60\u50a8\u80fd\u7cfb\u7edf\u548c\u71c3\u6c14\u8f6e\u673a\uff0c\u89e3\u51b3\u4e86\u5ef6\u8fdf\u5956\u52b1\u95ee\u9898\u3002", "motivation": "P2G\u6280\u672f\u5728\u6574\u5408\u53ef\u518d\u751f\u80fd\u6e90\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u5176\u7ecf\u6d4e\u8fd0\u8425\u56e0\u80fd\u6e90\u6ce2\u52a8\u6027\u548c\u4f4e\u6548\u7387\u800c\u590d\u6742\u5316\u3002\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u77ed\u671f\u80fd\u6e90\u8f6c\u6362\uff0c\u5ffd\u89c6\u4e86P2G\u7684\u957f\u671f\u50a8\u80fd\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u4e09\u4e2a\u9010\u6b65\u590d\u6742\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u8bc4\u4f30\u4e86\u6df1\u5ea6Q\u7f51\u7edc\u548c\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\uff0c\u5e76\u5f15\u5165\u9884\u6d4b\u6574\u5408\u3001\u5956\u52b1\u51fd\u6570\u60e9\u7f5a\u548c\u6218\u7565\u6210\u672c\u8ba1\u7b97\u7b49\u6539\u8fdb\u63aa\u65bd\u3002", "result": "\u6539\u8fdb\u540e\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86P2G\u7cfb\u7edf\u957f\u671f\u8fd0\u8425\u7684\u6210\u672c\u6548\u76ca\u51b3\u7b56\u80fd\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3aP2G\u6280\u672f\u7684\u957f\u671f\u50a8\u80fd\u6f5c\u529b\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.06518", "pdf": "https://arxiv.org/pdf/2506.06518", "abs": "https://arxiv.org/abs/2506.06518", "authors": ["Neil Fendley", "Edward W. Staley", "Joshua Carney", "William Redman", "Marie Chau", "Nathan Drenkow"], "title": "A Systematic Review of Poisoning Attacks Against Large Language Models", "categories": ["cs.CR", "cs.LG"], "comment": "28 Pages including number", "summary": "With the widespread availability of pretrained Large Language Models (LLMs)\nand their training datasets, concerns about the security risks associated with\ntheir usage has increased significantly. One of these security risks is the\nthreat of LLM poisoning attacks where an attacker modifies some part of the LLM\ntraining process to cause the LLM to behave in a malicious way. As an emerging\narea of research, the current frameworks and terminology for LLM poisoning\nattacks are derived from earlier classification poisoning literature and are\nnot fully equipped for generative LLM settings. We conduct a systematic review\nof published LLM poisoning attacks to clarify the security implications and\naddress inconsistencies in terminology across the literature. We propose a\ncomprehensive poisoning threat model applicable to categorize a wide range of\nLLM poisoning attacks. The poisoning threat model includes four poisoning\nattack specifications that define the logistics and manipulation strategies of\nan attack as well as six poisoning metrics used to measure key characteristics\nof an attack. Under our proposed framework, we organize our discussion of\npublished LLM poisoning literature along four critical dimensions of LLM\npoisoning attacks: concept poisons, stealthy poisons, persistent poisons, and\npoisons for unique tasks, to better understand the current landscape of\nsecurity risks.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7efc\u8ff0\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u4e2d\u6bd2\u653b\u51fb\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u5a01\u80c1\u6a21\u578b\u548c\u5206\u7c7b\u6846\u67b6\uff0c\u4ee5\u6f84\u6e05\u5b89\u5168\u5f71\u54cd\u548c\u672f\u8bed\u4e0d\u4e00\u81f4\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u9884\u8bad\u7ec3LLM\u53ca\u5176\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u5e7f\u6cdb\u4f7f\u7528\uff0c\u5176\u5b89\u5168\u98ce\u9669\uff08\u5982\u4e2d\u6bd2\u653b\u51fb\uff09\u5f15\u8d77\u4e86\u663e\u8457\u5173\u6ce8\u3002\u73b0\u6709\u6846\u67b6\u548c\u672f\u8bed\u6e90\u81ea\u5206\u7c7b\u4e2d\u6bd2\u6587\u732e\uff0c\u4e0d\u5b8c\u5168\u9002\u7528\u4e8e\u751f\u6210\u5f0fLLM\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u7efc\u8ff0\u5df2\u53d1\u8868\u7684LLM\u4e2d\u6bd2\u653b\u51fb\uff0c\u63d0\u51fa\u4e00\u4e2a\u5305\u542b\u56db\u79cd\u653b\u51fb\u89c4\u8303\u548c\u516d\u79cd\u5ea6\u91cf\u6307\u6807\u7684\u5a01\u80c1\u6a21\u578b\uff0c\u7528\u4e8e\u5206\u7c7b\u548c\u8bc4\u4f30\u653b\u51fb\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u9002\u7528\u4e8e\u5e7f\u6cdbLLM\u4e2d\u6bd2\u653b\u51fb\u7684\u5206\u7c7b\u6846\u67b6\uff0c\u5e76\u56f4\u7ed5\u56db\u4e2a\u5173\u952e\u7ef4\u5ea6\uff08\u6982\u5ff5\u6bd2\u836f\u3001\u9690\u853d\u6bd2\u836f\u3001\u6301\u4e45\u6bd2\u836f\u548c\u4efb\u52a1\u7279\u5b9a\u6bd2\u836f\uff09\u7ec4\u7ec7\u8ba8\u8bba\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u52a9\u4e8e\u66f4\u597d\u5730\u7406\u89e3LLM\u4e2d\u6bd2\u653b\u51fb\u7684\u5b89\u5168\u98ce\u9669\u73b0\u72b6\uff0c\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u7edf\u4e00\u672f\u8bed\u548c\u5206\u7c7b\u6807\u51c6\u3002"}}
{"id": "2506.06542", "pdf": "https://arxiv.org/pdf/2506.06542", "abs": "https://arxiv.org/abs/2506.06542", "authors": ["Sherman Khoo", "Yakun Wang", "Song Liu", "Mark Beaumont"], "title": "Direct Fisher Score Estimation for Likelihood Maximization", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We study the problem of likelihood maximization when the likelihood function\nis intractable but model simulations are readily available. We propose a\nsequential, gradient-based optimization method that directly models the Fisher\nscore based on a local score matching technique which uses simulations from a\nlocalized region around each parameter iterate. By employing a linear\nparameterization to the surrogate score model, our technique admits a\nclosed-form, least-squares solution. This approach yields a fast, flexible, and\nefficient approximation to the Fisher score, effectively smoothing the\nlikelihood objective and mitigating the challenges posed by complex likelihood\nlandscapes. We provide theoretical guarantees for our score estimator,\nincluding bounds on the bias introduced by the smoothing. Empirical results on\na range of synthetic and real-world problems demonstrate the superior\nperformance of our method compared to existing benchmarks.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5c40\u90e8\u5f97\u5206\u5339\u914d\u6280\u672f\u7684\u68af\u5ea6\u4f18\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u4f3c\u7136\u51fd\u6570\u96be\u4ee5\u5904\u7406\u4f46\u6a21\u578b\u6a21\u62df\u53ef\u7528\u7684\u95ee\u9898\u3002", "motivation": "\u7814\u7a76\u5728\u4f3c\u7136\u51fd\u6570\u96be\u4ee5\u5904\u7406\u4f46\u6a21\u578b\u6a21\u62df\u53ef\u7528\u7684\u60c5\u51b5\u4e0b\uff0c\u5982\u4f55\u9ad8\u6548\u6700\u5927\u5316\u4f3c\u7136\u51fd\u6570\u3002", "method": "\u91c7\u7528\u5c40\u90e8\u5f97\u5206\u5339\u914d\u6280\u672f\uff0c\u901a\u8fc7\u7ebf\u6027\u53c2\u6570\u5316\u6784\u5efa\u4ee3\u7406\u5f97\u5206\u6a21\u578b\uff0c\u83b7\u5f97\u95ed\u5f0f\u6700\u5c0f\u4e8c\u4e58\u89e3\u3002", "result": "\u7406\u8bba\u4fdd\u8bc1\u5f97\u5206\u4f30\u8ba1\u7684\u504f\u5dee\u754c\u9650\uff0c\u5b9e\u8bc1\u7ed3\u679c\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5feb\u901f\u3001\u7075\u6d3b\u4e14\u9ad8\u6548\uff0c\u80fd\u6709\u6548\u5e73\u6ed1\u4f3c\u7136\u76ee\u6807\u5e76\u5e94\u5bf9\u590d\u6742\u4f3c\u7136\u666f\u89c2\u7684\u6311\u6218\u3002"}}
{"id": "2506.06557", "pdf": "https://arxiv.org/pdf/2506.06557", "abs": "https://arxiv.org/abs/2506.06557", "authors": ["Antonio Pariente", "Ignacio Hounie", "Santiago Segarra", "Alejandro Ribeiro"], "title": "Infinity Search: Approximate Vector Search with Projections on q-Metric Spaces", "categories": ["cs.IR", "cs.LG", "eess.SP", "math.MG"], "comment": null, "summary": "Despite the ubiquity of vector search applications, prevailing search\nalgorithms overlook the metric structure of vector embeddings, treating it as a\nconstraint rather than exploiting its underlying properties. In this paper, we\ndemonstrate that in $q$-metric spaces, metric trees can leverage a stronger\nversion of the triangle inequality to reduce comparisons for exact search.\nNotably, as $q$ approaches infinity, the search complexity becomes logarithmic.\nTherefore, we propose a novel projection method that embeds vector datasets\nwith arbitrary dissimilarity measures into $q$-metric spaces while preserving\nthe nearest neighbor. We propose to learn an approximation of this projection\nto efficiently transform query points to a space where euclidean distances\nsatisfy the desired properties. Our experimental results with text and image\nvector embeddings show that learning $q$-metric approximations enables classic\nmetric tree algorithms -- which typically underperform with high-dimensional\ndata -- to achieve competitive performance against state-of-the-art search\nmethods.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528q-\u5ea6\u91cf\u7a7a\u95f4\u7684\u6295\u5f71\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f3a\u5316\u4e09\u89d2\u4e0d\u7b49\u5f0f\u51cf\u5c11\u7cbe\u786e\u641c\u7d22\u7684\u6bd4\u8f83\u6b21\u6570\uff0c\u4f7f\u7ecf\u5178\u5ea6\u91cf\u6811\u7b97\u6cd5\u5728\u9ad8\u7ef4\u6570\u636e\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u5411\u91cf\u641c\u7d22\u7b97\u6cd5\u5ffd\u7565\u4e86\u5411\u91cf\u5d4c\u5165\u7684\u5ea6\u91cf\u7ed3\u6784\uff0c\u672a\u5145\u5206\u5229\u7528\u5176\u6f5c\u5728\u7279\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u6295\u5f71\u65b9\u6cd5\uff0c\u5c06\u4efb\u610f\u76f8\u4f3c\u6027\u5ea6\u91cf\u7684\u5411\u91cf\u6570\u636e\u96c6\u5d4c\u5165q-\u5ea6\u91cf\u7a7a\u95f4\uff0c\u5e76\u5b66\u4e60\u8fd1\u4f3c\u6295\u5f71\u4ee5\u9ad8\u6548\u8f6c\u6362\u67e5\u8be2\u70b9\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f7f\u7ecf\u5178\u5ea6\u91cf\u6811\u7b97\u6cd5\u5728\u9ad8\u7ef4\u6587\u672c\u548c\u56fe\u50cf\u5411\u91cf\u5d4c\u5165\u4e2d\u8fbe\u5230\u4e0e\u5148\u8fdb\u641c\u7d22\u65b9\u6cd5\u7ade\u4e89\u7684\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u5229\u7528q-\u5ea6\u91cf\u7a7a\u95f4\u7684\u7279\u6027\uff0c\u7ecf\u5178\u7b97\u6cd5\u5728\u9ad8\u7ef4\u6570\u636e\u4e2d\u4e5f\u80fd\u5b9e\u73b0\u9ad8\u6548\u641c\u7d22\u3002"}}
{"id": "2506.06563", "pdf": "https://arxiv.org/pdf/2506.06563", "abs": "https://arxiv.org/abs/2506.06563", "authors": ["Thushari Hapuarachchi", "Long Dang", "Kaiqi Xiong"], "title": "Securing Traffic Sign Recognition Systems in Autonomous Vehicles", "categories": ["cs.CV", "cs.CR", "cs.LG"], "comment": null, "summary": "Deep Neural Networks (DNNs) are widely used for traffic sign recognition\nbecause they can automatically extract high-level features from images. These\nDNNs are trained on large-scale datasets obtained from unknown sources.\nTherefore, it is important to ensure that the models remain secure and are not\ncompromised or poisoned during training. In this paper, we investigate the\nrobustness of DNNs trained for traffic sign recognition. First, we perform the\nerror-minimizing attacks on DNNs used for traffic sign recognition by adding\nimperceptible perturbations on training data. Then, we propose a data\naugmentation-based training method to mitigate the error-minimizing attacks.\nThe proposed training method utilizes nonlinear transformations to disrupt the\nperturbations and improve the model robustness. We experiment with two\nwell-known traffic sign datasets to demonstrate the severity of the attack and\nthe effectiveness of our mitigation scheme. The error-minimizing attacks reduce\nthe prediction accuracy of the DNNs from 99.90% to 10.6%. However, our\nmitigation scheme successfully restores the prediction accuracy to 96.05%.\nMoreover, our approach outperforms adversarial training in mitigating the\nerror-minimizing attacks. Furthermore, we propose a detection model capable of\nidentifying poisoned data even when the perturbations are imperceptible to\nhuman inspection. Our detection model achieves a success rate of over 99% in\nidentifying the attack. This research highlights the need to employ advanced\ntraining methods for DNNs in traffic sign recognition systems to mitigate the\neffects of data poisoning attacks.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff08DNN\uff09\u5728\u4ea4\u901a\u6807\u5fd7\u8bc6\u522b\u4e2d\u7684\u5b89\u5168\u6027\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6570\u636e\u589e\u5f3a\u8bad\u7ec3\u65b9\u6cd5\u4ee5\u62b5\u5fa1\u8bef\u5dee\u6700\u5c0f\u5316\u653b\u51fb\uff0c\u5e76\u5f00\u53d1\u4e86\u68c0\u6d4b\u6a21\u578b\u8bc6\u522b\u4e2d\u6bd2\u6570\u636e\u3002", "motivation": "DNN\u5728\u4ea4\u901a\u6807\u5fd7\u8bc6\u522b\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5176\u8bad\u7ec3\u6570\u636e\u53ef\u80fd\u88ab\u6c61\u67d3\uff0c\u5bfc\u81f4\u6a21\u578b\u5b89\u5168\u6027\u95ee\u9898\u3002\u7814\u7a76\u65e8\u5728\u63d0\u5347DNN\u5bf9\u6297\u653b\u51fb\u7684\u9c81\u68d2\u6027\u3002", "method": "\u901a\u8fc7\u8bef\u5dee\u6700\u5c0f\u5316\u653b\u51fb\u6d4b\u8bd5DNN\u7684\u8106\u5f31\u6027\uff0c\u63d0\u51fa\u57fa\u4e8e\u6570\u636e\u589e\u5f3a\u7684\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5229\u7528\u975e\u7ebf\u6027\u53d8\u6362\u7834\u574f\u6270\u52a8\uff0c\u5e76\u5f00\u53d1\u68c0\u6d4b\u6a21\u578b\u8bc6\u522b\u4e2d\u6bd2\u6570\u636e\u3002", "result": "\u653b\u51fb\u4f7fDNN\u9884\u6d4b\u51c6\u786e\u7387\u4ece99.90%\u964d\u81f310.6%\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u6062\u590d\u81f396.05%\uff0c\u68c0\u6d4b\u6a21\u578b\u8bc6\u522b\u653b\u51fb\u6210\u529f\u7387\u8d8599%\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u5728\u4ea4\u901a\u6807\u5fd7\u8bc6\u522b\u7cfb\u7edf\u4e2d\u91c7\u7528\u5148\u8fdb\u8bad\u7ec3\u65b9\u6cd5\u7684\u5fc5\u8981\u6027\uff0c\u4ee5\u62b5\u5fa1\u6570\u636e\u4e2d\u6bd2\u653b\u51fb\u3002"}}
{"id": "2506.06576", "pdf": "https://arxiv.org/pdf/2506.06576", "abs": "https://arxiv.org/abs/2506.06576", "authors": ["Yijia Shao", "Humishka Zope", "Yucheng Jiang", "Jiaxin Pei", "David Nguyen", "Erik Brynjolfsson", "Diyi Yang"], "title": "Future of Work with AI Agents: Auditing Automation and Augmentation Potential across the U.S. Workforce", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC", "cs.LG"], "comment": "Preprint", "summary": "The rapid rise of compound AI systems (a.k.a., AI agents) is reshaping the\nlabor market, raising concerns about job displacement, diminished human agency,\nand overreliance on automation. Yet, we lack a systematic understanding of the\nevolving landscape. In this paper, we address this gap by introducing a novel\nauditing framework to assess which occupational tasks workers want AI agents to\nautomate or augment, and how those desires align with the current technological\ncapabilities. Our framework features an audio-enhanced mini-interview to\ncapture nuanced worker desires and introduces the Human Agency Scale (HAS) as a\nshared language to quantify the preferred level of human involvement. Using\nthis framework, we construct the WORKBank database, building on the U.S.\nDepartment of Labor's O*NET database, to capture preferences from 1,500 domain\nworkers and capability assessments from AI experts across over 844 tasks\nspanning 104 occupations. Jointly considering the desire and technological\ncapability divides tasks in WORKBank into four zones: Automation \"Green Light\"\nZone, Automation \"Red Light\" Zone, R&D Opportunity Zone, Low Priority Zone.\nThis highlights critical mismatches and opportunities for AI agent development.\nMoving beyond a simple automate-or-not dichotomy, our results reveal diverse\nHAS profiles across occupations, reflecting heterogeneous expectations for\nhuman involvement. Moreover, our study offers early signals of how AI agent\nintegration may reshape the core human competencies, shifting from\ninformation-focused skills to interpersonal ones. These findings underscore the\nimportance of aligning AI agent development with human desires and preparing\nworkers for evolving workplace dynamics.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5ba1\u8ba1\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5de5\u4eba\u5e0c\u671bAI\u4ee3\u7406\u81ea\u52a8\u5316\u6216\u589e\u5f3a\u7684\u4efb\u52a1\uff0c\u5e76\u5206\u6790\u8fd9\u4e9b\u613f\u671b\u4e0e\u5f53\u524d\u6280\u672f\u80fd\u529b\u7684\u5339\u914d\u60c5\u51b5\u3002", "motivation": "\u968f\u7740\u590d\u5408AI\u7cfb\u7edf\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u52b3\u52a8\u529b\u5e02\u573a\u9762\u4e34\u5c31\u4e1a\u66ff\u4ee3\u3001\u4eba\u7c7b\u80fd\u52a8\u6027\u51cf\u5f31\u548c\u5bf9\u81ea\u52a8\u5316\u8fc7\u5ea6\u4f9d\u8d56\u7684\u62c5\u5fe7\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u5bf9\u8fd9\u4e00\u6f14\u53d8\u666f\u89c2\u7684\u7cfb\u7edf\u6027\u7406\u89e3\u3002", "method": "\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u4e2a\u97f3\u9891\u589e\u5f3a\u7684\u8ff7\u4f60\u8bbf\u8c08\u6846\u67b6\u548c\u4eba\u7c7b\u80fd\u52a8\u6027\u91cf\u8868\uff08HAS\uff09\uff0c\u6784\u5efa\u4e86WORKBank\u6570\u636e\u5e93\uff0c\u7ed3\u5408\u5de5\u4eba\u504f\u597d\u548cAI\u4e13\u5bb6\u8bc4\u4f30\uff0c\u5c06\u4efb\u52a1\u5206\u4e3a\u56db\u4e2a\u533a\u57df\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4e0d\u540c\u804c\u4e1a\u5bf9\u4eba\u7c7b\u53c2\u4e0e\u7684\u671f\u671b\u5b58\u5728\u591a\u6837\u6027\uff0c\u5e76\u63ed\u793a\u4e86AI\u4ee3\u7406\u6574\u5408\u53ef\u80fd\u5982\u4f55\u6539\u53d8\u6838\u5fc3\u4eba\u7c7b\u80fd\u529b\uff0c\u4ece\u4fe1\u606f\u6280\u80fd\u8f6c\u5411\u4eba\u9645\u6280\u80fd\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u5c06AI\u4ee3\u7406\u5f00\u53d1\u4e0e\u4eba\u7c7b\u613f\u671b\u5bf9\u9f50\u7684\u91cd\u8981\u6027\uff0c\u5e76\u4e3a\u5de5\u4eba\u9002\u5e94\u52a8\u6001\u5de5\u4f5c\u73af\u5883\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2506.06594", "pdf": "https://arxiv.org/pdf/2506.06594", "abs": "https://arxiv.org/abs/2506.06594", "authors": ["Daniel Leite", "Igor \u0160krjanc", "Fernando Gomide"], "title": "From Model-Based and Adaptive Control to Evolving Fuzzy Control", "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.SY"], "comment": "4 pages, 2 figures. Fuzz-IEEE 2025 Booklet: 60 Years of Fuzzy Set\n  Theory", "summary": "Evolving fuzzy systems build and adapt fuzzy models - such as predictors and\ncontrollers - by incrementally updating their rule-base structure from data\nstreams. On the occasion of the 60-year anniversary of fuzzy set theory,\ncommemorated during the Fuzz-IEEE 2025 event, this brief paper revisits the\nhistorical development and core contributions of classical fuzzy and adaptive\nmodeling and control frameworks. It then highlights the emergence and\nsignificance of evolving intelligent systems in fuzzy modeling and control,\nemphasizing their advantages in handling nonstationary environments. Key\nchallenges and future directions are discussed, including safety,\ninterpretability, and principled structural evolution.", "AI": {"tldr": "\u672c\u6587\u56de\u987e\u4e86\u6a21\u7cca\u96c6\u7406\u8bba60\u5e74\u6765\u7684\u53d1\u5c55\uff0c\u91cd\u70b9\u4ecb\u7ecd\u4e86\u7ecf\u5178\u6a21\u7cca\u4e0e\u81ea\u9002\u5e94\u5efa\u6a21\u63a7\u5236\u6846\u67b6\u7684\u6838\u5fc3\u8d21\u732e\uff0c\u5e76\u63a2\u8ba8\u4e86\u6f14\u5316\u667a\u80fd\u7cfb\u7edf\u5728\u6a21\u7cca\u5efa\u6a21\u4e0e\u63a7\u5236\u4e2d\u7684\u4f18\u52bf\u4e0e\u6311\u6218\u3002", "motivation": "\u7eaa\u5ff5\u6a21\u7cca\u96c6\u7406\u8bba60\u5468\u5e74\uff0c\u603b\u7ed3\u5176\u5386\u53f2\u53d1\u5c55\u4e0e\u6838\u5fc3\u8d21\u732e\uff0c\u5e76\u63a2\u8ba8\u6f14\u5316\u667a\u80fd\u7cfb\u7edf\u5728\u975e\u5e73\u7a33\u73af\u5883\u4e2d\u7684\u91cd\u8981\u6027\u3002", "method": "\u56de\u987e\u7ecf\u5178\u6a21\u7cca\u4e0e\u81ea\u9002\u5e94\u5efa\u6a21\u63a7\u5236\u6846\u67b6\uff0c\u5206\u6790\u6f14\u5316\u667a\u80fd\u7cfb\u7edf\u7684\u4f18\u52bf\u3002", "result": "\u6f14\u5316\u6a21\u7cca\u7cfb\u7edf\u5728\u975e\u5e73\u7a33\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u4ecd\u9762\u4e34\u5b89\u5168\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u7ed3\u6784\u6f14\u5316\u7b49\u6311\u6218\u3002", "conclusion": "\u672a\u6765\u9700\u5173\u6ce8\u5b89\u5168\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u7ed3\u6784\u6f14\u5316\u7b49\u65b9\u5411\uff0c\u4ee5\u63a8\u52a8\u6a21\u7cca\u7cfb\u7edf\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.06604", "pdf": "https://arxiv.org/pdf/2506.06604", "abs": "https://arxiv.org/abs/2506.06604", "authors": ["Armin Sarabi", "Manish Karir", "Mingyan Liu"], "title": "Scoring the Unscorables: Cyber Risk Assessment Beyond Internet Scans", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "In this paper we present a study on using novel data types to perform cyber\nrisk quantification by estimating the likelihood of a data breach. We\ndemonstrate that it is feasible to build a highly accurate cyber risk\nassessment model using public and readily available technology signatures\nobtained from crawling an organization's website. This approach overcomes the\nlimitations of previous similar approaches that relied on large-scale IP\naddress based scanning data, which suffers from incomplete/missing IP address\nmappings as well as the lack of such data for large numbers of small and\nmedium-sized organizations (SMEs). In comparison to scan data, technology\ndigital signature data is more readily available for millions of SMEs. Our\nstudy shows that there is a strong relationship between these technology\nsignatures and an organization's cybersecurity posture. In cross-validating our\nmodel using different cyber incident datasets, we also highlight the key\ndifferences between ransomware attack victims and the larger population of\ncyber incident and data breach victims.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u65b0\u578b\u6570\u636e\u7c7b\u578b\uff08\u6280\u672f\u6570\u5b57\u7b7e\u540d\uff09\u8fdb\u884c\u7f51\u7edc\u98ce\u9669\u91cf\u5316\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u722c\u53d6\u7ec4\u7ec7\u7f51\u7ad9\u6570\u636e\u6784\u5efa\u9ad8\u7cbe\u5ea6\u98ce\u9669\u8bc4\u4f30\u6a21\u578b\uff0c\u514b\u670d\u4e86\u4f20\u7edfIP\u626b\u63cf\u6570\u636e\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8eIP\u626b\u63cf\u7684\u6570\u636e\u5b58\u5728\u4e0d\u5b8c\u6574\u6027\u548c\u5bf9\u4e2d\u5c0f\u578b\u4f01\u4e1a\uff08SMEs\uff09\u8986\u76d6\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u800c\u6280\u672f\u6570\u5b57\u7b7e\u540d\u6570\u636e\u66f4\u6613\u83b7\u53d6\u4e14\u9002\u7528\u4e8e\u5927\u91cfSMEs\u3002", "method": "\u901a\u8fc7\u722c\u53d6\u7ec4\u7ec7\u7f51\u7ad9\u83b7\u53d6\u6280\u672f\u6570\u5b57\u7b7e\u540d\u6570\u636e\uff0c\u6784\u5efa\u7f51\u7edc\u98ce\u9669\u8bc4\u4f30\u6a21\u578b\uff0c\u5e76\u4e0e\u4e0d\u540c\u7f51\u7edc\u4e8b\u4ef6\u6570\u636e\u96c6\u8fdb\u884c\u4ea4\u53c9\u9a8c\u8bc1\u3002", "result": "\u7814\u7a76\u8868\u660e\u6280\u672f\u6570\u5b57\u7b7e\u540d\u4e0e\u7ec4\u7ec7\u7684\u7f51\u7edc\u5b89\u5168\u6001\u52bf\u5bc6\u5207\u76f8\u5173\uff0c\u6a21\u578b\u5728\u4ea4\u53c9\u9a8c\u8bc1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u5e76\u63ed\u793a\u4e86\u52d2\u7d22\u8f6f\u4ef6\u653b\u51fb\u53d7\u5bb3\u8005\u4e0e\u5176\u4ed6\u7f51\u7edc\u4e8b\u4ef6\u53d7\u5bb3\u8005\u7684\u5173\u952e\u5dee\u5f02\u3002", "conclusion": "\u6280\u672f\u6570\u5b57\u7b7e\u540d\u662f\u4e00\u79cd\u53ef\u884c\u4e14\u9ad8\u6548\u7684\u7f51\u7edc\u98ce\u9669\u91cf\u5316\u65b9\u6cd5\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u4e2d\u5c0f\u578b\u4f01\u4e1a\u3002"}}
{"id": "2506.06607", "pdf": "https://arxiv.org/pdf/2506.06607", "abs": "https://arxiv.org/abs/2506.06607", "authors": ["Charles Goddard", "Fernando Fernandes Neto"], "title": "Training-Free Tokenizer Transplantation via Orthogonal Matching Pursuit", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "We present a training-free method to transplant tokenizers in pretrained\nlarge language models (LLMs) by reconstructing unseen token embeddings via\nOrthogonal Matching Pursuit (OMP). Specifically, we approximate each\nout-of-vocabulary token as a sparse linear combination of shared tokens, in two\nphases: first, compute each new token's representation in the donor embedding\nspace with a small dictionary of shared anchor tokens, then transfer these same\nsparse coefficients back into the base model's embedding space.\n  On two challenging cross-tokenizer tasks--Llama$\\to$Mistral NeMo (12B) and\nQwen$\\to$Llama (1B)--we show that OMP achieves best zero-shot preservation of\nthe base model's performance across multiple benchmarks, while other zero-shot\napproaches degrade significantly. Compared to baselines (zero-init, mean-init,\nand existing approaches like WECHSEL, FOCUS, ZETT), OMP consistently achieves\nthe best overall performance, effectively bridging large tokenizer\ndiscrepancies without gradient updates. Our analysis further identifies\nmismatched numerical tokenization schemes as a critical challenge for\npreserving mathematical reasoning capabilities. This technique enables direct\nreuse of pretrained model weights with new tokenizers, facilitating\ncross-tokenizer knowledge distillation, speculative decoding, ensembling,\nmerging, and domain-specific vocabulary adaptations. We integrate our method\ninto the open-source mergekit-tokensurgeon tool for post hoc vocabulary\nrealignment.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684Tokenizer\u79fb\u690d\u65b9\u6cd5\uff0c\u901a\u8fc7\u6b63\u4ea4\u5339\u914d\u8ffd\u8e2a\uff08OMP\uff09\u91cd\u5efa\u672a\u89c1\u8fc7\u7684\u8bcd\u5d4c\u5165\uff0c\u5b9e\u73b0\u9884\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684Tokenizer\u79fb\u690d\u3002", "motivation": "\u89e3\u51b3\u4e0d\u540cTokenizer\u4e4b\u95f4\u7684\u5dee\u5f02\u95ee\u9898\uff0c\u907f\u514d\u68af\u5ea6\u66f4\u65b0\uff0c\u76f4\u63a5\u590d\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u6743\u91cd\u3002", "method": "\u4f7f\u7528OMP\u65b9\u6cd5\uff0c\u5c06\u65b0\u8bcd\u6c47\u8868\u793a\u4e3a\u5171\u4eab\u8bcd\u6c47\u7684\u7a00\u758f\u7ebf\u6027\u7ec4\u5408\uff0c\u5206\u4e24\u9636\u6bb5\u5b9e\u73b0\u8bcd\u5d4c\u5165\u7684\u79fb\u690d\u3002", "result": "\u5728\u591a\u4e2a\u8de8Tokenizer\u4efb\u52a1\u4e2d\uff0cOMP\u65b9\u6cd5\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u8868\u73b0\u6700\u4f73\uff0c\u4f18\u4e8e\u5176\u4ed6\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "OMP\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3Tokenizer\u5dee\u5f02\u95ee\u9898\uff0c\u652f\u6301\u8de8Tokenizer\u7684\u77e5\u8bc6\u84b8\u998f\u3001\u89e3\u7801\u7b49\u5e94\u7528\u3002"}}
{"id": "2506.06609", "pdf": "https://arxiv.org/pdf/2506.06609", "abs": "https://arxiv.org/abs/2506.06609", "authors": ["Alan Chen", "Jack Merullo", "Alessandro Stolfo", "Ellie Pavlick"], "title": "Transferring Features Across Language Models With Model Stitching", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "In this work, we demonstrate that affine mappings between residual streams of\nlanguage models is a cheap way to effectively transfer represented features\nbetween models. We apply this technique to transfer the weights of Sparse\nAutoencoders (SAEs) between models of different sizes to compare their\nrepresentations. We find that small and large models learn highly similar\nrepresentation spaces, which motivates training expensive components like SAEs\non a smaller model and transferring to a larger model at a FLOPs savings. For\nexample, using a small-to-large transferred SAE as initialization can lead to\n50% cheaper training runs when training SAEs on larger models. Next, we show\nthat transferred probes and steering vectors can effectively recover ground\ntruth performance. Finally, we dive deeper into feature-level transferability,\nfinding that semantic and structural features transfer noticeably differently\nwhile specific classes of functional features have their roles faithfully\nmapped. Overall, our findings illustrate similarities and differences in the\nlinear representation spaces of small and large models and demonstrate a method\nfor improving the training efficiency of SAEs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u4eff\u5c04\u6620\u5c04\u5728\u8bed\u8a00\u6a21\u578b\u6b8b\u5dee\u6d41\u4e4b\u95f4\u9ad8\u6548\u4f20\u9012\u7279\u5f81\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u6bd4\u8f83\u4e0d\u540c\u5927\u5c0f\u6a21\u578b\u7684\u8868\u793a\u7a7a\u95f4\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5927\u5c0f\u6a21\u578b\u7684\u8868\u793a\u7a7a\u95f4\u9ad8\u5ea6\u76f8\u4f3c\uff0c\u4ece\u800c\u53ef\u4ee5\u901a\u8fc7\u5728\u5c0f\u6a21\u578b\u4e0a\u8bad\u7ec3\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff08SAE\uff09\u5e76\u8fc1\u79fb\u5230\u5927\u6a21\u578b\u6765\u8282\u7701\u8ba1\u7b97\u6210\u672c\u3002\u6b64\u5916\uff0c\u8fc1\u79fb\u7684\u63a2\u6d4b\u5668\u548c\u5bfc\u5411\u5411\u91cf\u80fd\u6709\u6548\u6062\u590d\u771f\u5b9e\u6027\u80fd\uff0c\u4e14\u8bed\u4e49\u548c\u7ed3\u6784\u7279\u5f81\u7684\u8fc1\u79fb\u6548\u679c\u5b58\u5728\u5dee\u5f02\u3002", "motivation": "\u63a2\u7d22\u8bed\u8a00\u6a21\u578b\u4e2d\u4e0d\u540c\u5927\u5c0f\u6a21\u578b\u4e4b\u95f4\u8868\u793a\u7a7a\u95f4\u7684\u76f8\u4f3c\u6027\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u9ad8\u6548\u8fc1\u79fb\u7279\u5f81\u7684\u65b9\u6cd5\u4ee5\u8282\u7701\u8ba1\u7b97\u8d44\u6e90\u3002", "method": "\u4f7f\u7528\u4eff\u5c04\u6620\u5c04\u5728\u6a21\u578b\u6b8b\u5dee\u6d41\u4e4b\u95f4\u4f20\u9012\u7279\u5f81\uff0c\u5e76\u6bd4\u8f83\u4e0d\u540c\u5927\u5c0f\u6a21\u578b\u7684\u8868\u793a\u7a7a\u95f4\u3002\u901a\u8fc7\u5728\u5c0f\u6a21\u578b\u4e0a\u8bad\u7ec3SAE\u5e76\u8fc1\u79fb\u5230\u5927\u6a21\u578b\uff0c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "result": "\u5927\u5c0f\u6a21\u578b\u7684\u8868\u793a\u7a7a\u95f4\u9ad8\u5ea6\u76f8\u4f3c\uff0c\u8fc1\u79fbSAE\u53ef\u8282\u770150%\u7684\u8bad\u7ec3\u6210\u672c\u3002\u8bed\u4e49\u548c\u7ed3\u6784\u7279\u5f81\u7684\u8fc1\u79fb\u6548\u679c\u4e0d\u540c\uff0c\u4f46\u529f\u80fd\u7279\u5f81\u7684\u89d2\u8272\u80fd\u5fe0\u5b9e\u6620\u5c04\u3002", "conclusion": "\u4eff\u5c04\u6620\u5c04\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u7279\u5f81\u8fc1\u79fb\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86\u5927\u5c0f\u6a21\u578b\u8868\u793a\u7a7a\u95f4\u7684\u76f8\u4f3c\u6027\u548c\u5dee\u5f02\uff0c\u4e3aSAE\u7684\u8bad\u7ec3\u6548\u7387\u63d0\u4f9b\u4e86\u6539\u8fdb\u65b9\u6848\u3002"}}
{"id": "2506.06613", "pdf": "https://arxiv.org/pdf/2506.06613", "abs": "https://arxiv.org/abs/2506.06613", "authors": ["Arefe Boushehrian", "Amir Najafi"], "title": "Robust Learnability of Sample-Compressible Distributions under Noisy or Adversarial Perturbations", "categories": ["stat.ML", "cs.LG"], "comment": "50 pages, 1 figure", "summary": "Learning distribution families over $\\mathbb{R}^d$ is a fundamental problem\nin unsupervised learning and statistics. A central question in this setting is\nwhether a given family of distributions possesses sufficient structure to be\n(at least) information-theoretically learnable and, if so, to characterize its\nsample complexity. In 2018, Ashtiani et al. reframed \\emph{sample\ncompressibility}, originally due to Littlestone and Warmuth (1986), as a\nstructural property of distribution classes, proving that it guarantees\nPAC-learnability. This discovery subsequently enabled a series of recent\nadvancements in deriving nearly tight sample complexity bounds for various\nhigh-dimensional open problems. It has been further conjectured that the\nconverse also holds: every learnable class admits a tight sample compression\nscheme.\n  In this work, we establish that sample compressible families remain learnable\neven from perturbed samples, subject to a set of necessary and sufficient\nconditions. We analyze two models of data perturbation: (i) an additive\nindependent noise model, and (ii) an adversarial corruption model, where an\nadversary manipulates a limited subset of the samples unknown to the learner.\nOur results are general and rely on as minimal assumptions as possible. We\ndevelop a perturbation-quantization framework that interfaces naturally with\nthe compression scheme and leads to sample complexity bounds that scale\ngracefully with the noise level and corruption budget. As concrete\napplications, we establish new sample complexity bounds for learning finite\nmixtures of high-dimensional uniform distributions under both noise and\nadversarial perturbations, as well as for learning Gaussian mixture models from\nadversarially corrupted samples, resolving two open problems in the literature.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5728\u6570\u636e\u6270\u52a8\u4e0b\u6837\u672c\u53ef\u538b\u7f29\u5206\u5e03\u65cf\u7684\u5b66\u4e60\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u6270\u52a8\u6a21\u578b\uff08\u52a0\u6027\u72ec\u7acb\u566a\u58f0\u548c\u5bf9\u6297\u6027\u7834\u574f\uff09\uff0c\u5e76\u5efa\u7acb\u4e86\u6837\u672c\u590d\u6742\u5ea6\u7684\u754c\u9650\u3002", "motivation": "\u63a2\u8ba8\u5206\u5e03\u65cf\u5728\u6570\u636e\u6270\u52a8\u4e0b\u662f\u5426\u4ecd\u80fd\u4fdd\u6301\u53ef\u5b66\u4e60\u6027\uff0c\u5e76\u89e3\u51b3\u9ad8\u7ef4\u5206\u5e03\u5b66\u4e60\u4e2d\u7684\u5f00\u653e\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u6270\u52a8-\u91cf\u5316\u6846\u67b6\uff0c\u5206\u6790\u52a0\u6027\u72ec\u7acb\u566a\u58f0\u548c\u5bf9\u6297\u6027\u7834\u574f\u4e24\u79cd\u6270\u52a8\u6a21\u578b\uff0c\u7ed3\u5408\u538b\u7f29\u65b9\u6848\u63a8\u5bfc\u6837\u672c\u590d\u6742\u5ea6\u3002", "result": "\u8bc1\u660e\u4e86\u6837\u672c\u53ef\u538b\u7f29\u65cf\u5728\u6270\u52a8\u4e0b\u4ecd\u53ef\u5b66\u4e60\uff0c\u5e76\u7ed9\u51fa\u4e86\u5177\u4f53\u5e94\u7528\uff08\u5982\u9ad8\u7ef4\u5747\u5300\u5206\u5e03\u6df7\u5408\u548c\u9ad8\u65af\u6df7\u5408\u6a21\u578b\uff09\u7684\u6837\u672c\u590d\u6742\u5ea6\u754c\u9650\u3002", "conclusion": "\u6837\u672c\u53ef\u538b\u7f29\u6027\u5728\u6570\u636e\u6270\u52a8\u4e0b\u4ecd\u80fd\u4fdd\u8bc1\u5b66\u4e60\u6027\uff0c\u89e3\u51b3\u4e86\u6587\u732e\u4e2d\u7684\u4e24\u4e2a\u5f00\u653e\u6027\u95ee\u9898\u3002"}}
{"id": "2506.06653", "pdf": "https://arxiv.org/pdf/2506.06653", "abs": "https://arxiv.org/abs/2506.06653", "authors": ["Dangxing Chen"], "title": "Explaining Risks: Axiomatic Risk Attributions for Financial Models", "categories": ["q-fin.CP", "cs.LG", "stat.ML"], "comment": "This article has been accepted for publication in Quantitative\n  Finance, published by Taylor & Francis", "summary": "In recent years, machine learning models have achieved great success at the\nexpense of highly complex black-box structures. By using axiomatic attribution\nmethods, we can fairly allocate the contributions of each feature, thus\nallowing us to interpret the model predictions. In high-risk sectors such as\nfinance, risk is just as important as mean predictions. Throughout this work,\nwe address the following risk attribution problem: how to fairly allocate the\nrisk given a model with data? We demonstrate with analysis and empirical\nexamples that risk can be well allocated by extending the Shapley value\nframework.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eShapley\u503c\u6846\u67b6\u7684\u98ce\u9669\u5206\u914d\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u91ca\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u9ad8\u98ce\u9669\u9886\u57df\uff08\u5982\u91d1\u878d\uff09\u4e2d\u7684\u9884\u6d4b\u98ce\u9669\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u6a21\u578b\u867d\u7136\u6210\u529f\uff0c\u4f46\u5176\u9ed1\u7bb1\u7ed3\u6784\u96be\u4ee5\u89e3\u91ca\uff0c\u5c24\u5176\u662f\u5728\u9ad8\u98ce\u9669\u9886\u57df\uff0c\u98ce\u9669\u5206\u914d\u4e0e\u9884\u6d4b\u5747\u503c\u540c\u6837\u91cd\u8981\u3002", "method": "\u901a\u8fc7\u6269\u5c55Shapley\u503c\u6846\u67b6\uff0c\u516c\u5e73\u5206\u914d\u6a21\u578b\u9884\u6d4b\u4e2d\u7684\u98ce\u9669\u3002", "result": "\u5206\u6790\u4e0e\u5b9e\u8bc1\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u5206\u914d\u98ce\u9669\u3002", "conclusion": "\u6269\u5c55\u7684Shapley\u503c\u6846\u67b6\u4e3a\u9ad8\u98ce\u9669\u9886\u57df\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u98ce\u9669\u5206\u914d\u65b9\u6848\u3002"}}
{"id": "2506.06667", "pdf": "https://arxiv.org/pdf/2506.06667", "abs": "https://arxiv.org/abs/2506.06667", "authors": ["Yu-Hsuan Ho", "Ali Mostafavi"], "title": "Flood-DamageSense: Multimodal Mamba with Multitask Learning for Building Flood Damage Assessment using SAR Remote Sensing Imagery", "categories": ["cs.CV", "cs.LG", "eess.IV"], "comment": null, "summary": "Most post-disaster damage classifiers succeed only when destructive forces\nleave clear spectral or structural signatures -- conditions rarely present\nafter inundation. Consequently, existing models perform poorly at identifying\nflood-related building damages. The model presented in this study,\nFlood-DamageSense, addresses this gap as the first deep-learning framework\npurpose-built for building-level flood-damage assessment. The architecture\nfuses pre- and post-event SAR/InSAR scenes with very-high-resolution optical\nbasemaps and an inherent flood-risk layer that encodes long-term exposure\nprobabilities, guiding the network toward plausibly affected structures even\nwhen compositional change is minimal. A multimodal Mamba backbone with a\nsemi-Siamese encoder and task-specific decoders jointly predicts (1) graded\nbuilding-damage states, (2) floodwater extent, and (3) building footprints.\nTraining and evaluation on Hurricane Harvey (2017) imagery from Harris County,\nTexas -- supported by insurance-derived property-damage extents -- show a mean\nF1 improvement of up to 19 percentage points over state-of-the-art baselines,\nwith the largest gains in the frequently misclassified \"minor\" and \"moderate\"\ndamage categories. Ablation studies identify the inherent-risk feature as the\nsingle most significant contributor to this performance boost. An end-to-end\npost-processing pipeline converts pixel-level outputs to actionable,\nbuilding-scale damage maps within minutes of image acquisition. By combining\nrisk-aware modeling with SAR's all-weather capability, Flood-DamageSense\ndelivers faster, finer-grained, and more reliable flood-damage intelligence to\nsupport post-disaster decision-making and resource allocation.", "AI": {"tldr": "Flood-DamageSense\u662f\u4e00\u79cd\u4e13\u4e3a\u6d2a\u6c34\u707e\u5bb3\u540e\u5efa\u7b51\u7269\u635f\u574f\u8bc4\u4f30\u8bbe\u8ba1\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u878d\u5408\u591a\u6e90\u6570\u636e\u663e\u8457\u63d0\u5347\u5206\u7c7b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u5728\u6d2a\u6c34\u707e\u5bb3\u540e\u5efa\u7b51\u7269\u635f\u574f\u5206\u7c7b\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u56e0\u6d2a\u6c34\u7834\u574f\u7684\u75d5\u8ff9\u4e0d\u660e\u663e\u3002", "method": "\u7ed3\u5408SAR/InSAR\u3001\u9ad8\u5206\u8fa8\u7387\u5149\u5b66\u56fe\u50cf\u548c\u6d2a\u6c34\u98ce\u9669\u5c42\uff0c\u91c7\u7528\u591a\u6a21\u6001Mamba\u67b6\u6784\u548c\u534aSiamese\u7f16\u7801\u5668\uff0c\u9884\u6d4b\u635f\u574f\u7b49\u7ea7\u3001\u6d2a\u6c34\u8303\u56f4\u548c\u5efa\u7b51\u7269\u8f6e\u5ed3\u3002", "result": "\u5728Hurricane Harvey\u6570\u636e\u4e0a\uff0c\u5e73\u5747F1\u5206\u6570\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u534719\u4e2a\u767e\u5206\u70b9\uff0c\u5c24\u5176\u5728\u201c\u8f7b\u5fae\u201d\u548c\u201c\u4e2d\u7b49\u201d\u635f\u574f\u7c7b\u522b\u4e2d\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "Flood-DamageSense\u901a\u8fc7\u98ce\u9669\u611f\u77e5\u6a21\u578b\u548cSAR\u7684\u5168\u5929\u5019\u80fd\u529b\uff0c\u4e3a\u707e\u540e\u51b3\u7b56\u63d0\u4f9b\u66f4\u5feb\u3001\u66f4\u7cbe\u7ec6\u7684\u635f\u574f\u8bc4\u4f30\u3002"}}
{"id": "2506.06680", "pdf": "https://arxiv.org/pdf/2506.06680", "abs": "https://arxiv.org/abs/2506.06680", "authors": ["Radha Kodali", "Venkata Rao Dhulipalla", "Venkata Siva Kishor Tatavarty", "Madhavi Nadakuditi", "Bharadwaj Thiruveedhula", "Suryanarayana Gunnam", "Durga Prasad Bavirisetti"], "title": "Interpretation of Deep Learning Model in Embryo Selection for In Vitro Fertilization (IVF) Treatment", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Infertility has a considerable impact on individuals' quality of life,\naffecting them socially and psychologically, with projections indicating a rise\nin the upcoming years. In vitro fertilization (IVF) emerges as one of the\nprimary techniques within economically developed nations, employed to address\nthe rising problem of low fertility. Expert embryologists conventionally grade\nembryos by reviewing blastocyst images to select the most optimal for transfer,\nyet this process is time-consuming and lacks efficiency. Blastocyst images\nprovide a valuable resource for assessing embryo viability. In this study, we\nintroduce an explainable artificial intelligence (XAI) framework for\nclassifying embryos, employing a fusion of convolutional neural network (CNN)\nand long short-term memory (LSTM) architecture, referred to as CNN-LSTM.\nUtilizing deep learning, our model achieves high accuracy in embryo\nclassification while maintaining interpretability through XAI.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408CNN\u548cLSTM\u7684XAI\u6846\u67b6\uff0c\u7528\u4e8e\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u80da\u80ce\u5206\u7c7b\uff0c\u4ee5\u89e3\u51b3\u4f20\u7edf\u80da\u80ce\u8bc4\u7ea7\u6548\u7387\u4f4e\u7684\u95ee\u9898\u3002", "motivation": "\u4e0d\u5b55\u75c7\u5bf9\u751f\u6d3b\u8d28\u91cf\u6709\u663e\u8457\u5f71\u54cd\uff0cIVF\u662f\u4e3b\u8981\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u4f20\u7edf\u80da\u80ce\u8bc4\u7ea7\u65b9\u6cd5\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u91c7\u7528CNN-LSTM\u67b6\u6784\u7684XAI\u6846\u67b6\uff0c\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u8fdb\u884c\u80da\u80ce\u5206\u7c7b\u3002", "result": "\u6a21\u578b\u5b9e\u73b0\u4e86\u9ad8\u51c6\u786e\u7387\u7684\u80da\u80ce\u5206\u7c7b\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "XAI\u6846\u67b6\u4e3a\u80da\u80ce\u5206\u7c7b\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u671b\u63d0\u5347IVF\u6548\u7387\u3002"}}
{"id": "2506.06698", "pdf": "https://arxiv.org/pdf/2506.06698", "abs": "https://arxiv.org/abs/2506.06698", "authors": ["Yitao Liu", "Chenglei Si", "Karthik Narasimhan", "Shunyu Yao"], "title": "Contextual Experience Replay for Self-Improvement of Language Agents", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "comment": "Accepted to ACL 2025. 20 pages", "summary": "Large language model (LLM) agents have been applied to sequential\ndecision-making tasks such as web navigation, but without any\nenvironment-specific experiences, they often fail in these complex tasks.\nMoreover, current LLM agents are not designed to continually learn from past\nexperiences during inference time, which could be crucial for them to gain\nthese environment-specific experiences. To address this, we propose Contextual\nExperience Replay (CER), a training-free framework to enable efficient\nself-improvement for language agents in their context window. Specifically, CER\naccumulates and synthesizes past experiences into a dynamic memory buffer.\nThese experiences encompass environment dynamics and common decision-making\npatterns, allowing the agents to retrieve and augment themselves with relevant\nknowledge in new tasks, enhancing their adaptability in complex environments.\nWe evaluate CER on the challenging WebArena and VisualWebArena benchmarks. On\nVisualWebArena, CER achieves a competitive performance of 31.9%. On WebArena,\nCER also gets a competitive average success rate of 36.7%, relatively improving\nthe success rate of the GPT-4o agent baseline by 51.0%. We also conduct a\ncomprehensive analysis on it to prove its efficiency, validity and understand\nit better.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aContextual Experience Replay (CER)\u7684\u65e0\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8bb0\u5fc6\u7f13\u51b2\u533a\u79ef\u7d2f\u548c\u5408\u6210\u8fc7\u53bb\u7684\u7ecf\u9a8c\uff0c\u5e2e\u52a9\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u81ea\u6211\u6539\u8fdb\u3002", "motivation": "\u5f53\u524d\u7684\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5728\u590d\u6742\u4efb\u52a1\uff08\u5982\u7f51\u9875\u5bfc\u822a\uff09\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u4e14\u65e0\u6cd5\u5728\u63a8\u7406\u65f6\u6301\u7eed\u5b66\u4e60\u8fc7\u53bb\u7684\u7ecf\u9a8c\u3002", "method": "CER\u901a\u8fc7\u52a8\u6001\u8bb0\u5fc6\u7f13\u51b2\u533a\u79ef\u7d2f\u73af\u5883\u52a8\u6001\u548c\u51b3\u7b56\u6a21\u5f0f\u7684\u7ecf\u9a8c\uff0c\u4f7f\u4ee3\u7406\u80fd\u5728\u65b0\u4efb\u52a1\u4e2d\u68c0\u7d22\u5e76\u589e\u5f3a\u76f8\u5173\u77e5\u8bc6\u3002", "result": "\u5728VisualWebArena\u548cWebArena\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCER\u5206\u522b\u8fbe\u523031.9%\u548c36.7%\u7684\u6210\u529f\u7387\uff0c\u76f8\u5bf9\u57fa\u7ebfGPT-4o\u4ee3\u7406\u63d0\u5347\u4e8651.0%\u3002", "conclusion": "CER\u663e\u8457\u63d0\u5347\u4e86\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u9002\u5e94\u80fd\u529b\uff0c\u8bc1\u660e\u4e86\u5176\u9ad8\u6548\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2506.06718", "pdf": "https://arxiv.org/pdf/2506.06718", "abs": "https://arxiv.org/abs/2506.06718", "authors": ["Omar Mashaal", "Hatem Abou-Zeid"], "title": "IQFM A Wireless Foundational Model for I/Q Streams in AI-Native 6G", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "Foundational models have shown remarkable potential in natural language\nprocessing and computer vision, yet remain in their infancy in wireless\ncommunications. While a few efforts have explored image-based modalities such\nas channel state information (CSI) and frequency spectrograms, foundational\nmodels that operate directly on raw IQ data remain largely unexplored. This\npaper presents, IQFM, the first I/Q signal foundational model for wireless\ncommunications. IQFM supporting diverse tasks: modulation classification,\nangle-of-arrival (AoA), beam prediction, and RF fingerprinting, without heavy\npreprocessing or handcrafted features. We also introduce a task-aware\naugmentation strategy that categorizes transformations into core augmentations,\nsuch as cyclic time shifting, and task-specific augmentations. This strategy\nforms the basis for structured, task-dependent representation learning within a\ncontrastive self-supervised learning (SSL) framework. Using this strategy, the\nlightweight encoder, pre-trained via SSL on over-the-air multi-antenna IQ data,\nachieves up to 99.67% and 65.45% accuracy on modulation and AoA classification,\nrespectively, using only one labeled sample per class, outperforming supervised\nbaselines by up to 7x and 145x. The model also generalizes to\nout-of-distribution tasks; when adapted to new tasks using only 500 samples per\nclass and minimal parameter updates via LoRA, the same frozen encoder achieves\n94.15% on beam prediction (vs. 89.53% supervised), 50.00% on RML2016a\nmodulation classification (vs. 49.30%), and 96.05% on RF fingerprinting (vs.\n96.64%). These results demonstrate the potential of raw IQ-based foundational\nmodels as efficient, reusable encoders for multi-task learning in AI-native 6G\nsystems.", "AI": {"tldr": "IQFM\u662f\u9996\u4e2a\u57fa\u4e8e\u539f\u59cbI/Q\u4fe1\u53f7\u7684\u65e0\u7ebf\u901a\u4fe1\u57fa\u7840\u6a21\u578b\uff0c\u652f\u6301\u591a\u79cd\u4efb\u52a1\uff0c\u65e0\u9700\u590d\u6742\u9884\u5904\u7406\u6216\u624b\u5de5\u7279\u5f81\u3002\u901a\u8fc7\u5bf9\u6bd4\u81ea\u76d1\u7763\u5b66\u4e60\u6846\u67b6\uff0c\u5176\u8f7b\u91cf\u7ea7\u7f16\u7801\u5668\u5728\u5c11\u91cf\u6807\u8bb0\u6837\u672c\u4e0b\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u5c55\u793a\u4e86\u5728\u591a\u4efb\u52a1\u5b66\u4e60\u4e2d\u7684\u6f5c\u529b\u3002", "motivation": "\u63a2\u7d22\u57fa\u4e8e\u539f\u59cbI/Q\u4fe1\u53f7\u7684\u65e0\u7ebf\u901a\u4fe1\u57fa\u7840\u6a21\u578b\uff0c\u586b\u8865\u73b0\u6709\u7814\u7a76\u7a7a\u767d\uff0c\u5e76\u652f\u6301\u591a\u6837\u5316\u4efb\u52a1\u3002", "method": "\u63d0\u51faIQFM\u6a21\u578b\uff0c\u91c7\u7528\u4efb\u52a1\u611f\u77e5\u589e\u5f3a\u7b56\u7565\u548c\u5bf9\u6bd4\u81ea\u76d1\u7763\u5b66\u4e60\u6846\u67b6\uff0c\u9884\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u7f16\u7801\u5668\u3002", "result": "\u5728\u8c03\u5236\u5206\u7c7b\u548cAoA\u5206\u7c7b\u4e2d\u5206\u522b\u8fbe\u523099.67%\u548c65.45%\u7684\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u76d1\u7763\u57fa\u7ebf\uff0c\u5e76\u5728\u65b0\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\u3002", "conclusion": "IQFM\u5c55\u793a\u4e86\u539f\u59cbI/Q\u4fe1\u53f7\u57fa\u7840\u6a21\u578b\u57286G\u7cfb\u7edf\u4e2d\u9ad8\u6548\u3001\u53ef\u91cd\u7528\u7f16\u7801\u5668\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.06725", "pdf": "https://arxiv.org/pdf/2506.06725", "abs": "https://arxiv.org/abs/2506.06725", "authors": ["Guillaume Levy", "Cedric Colas", "Pierre-Yves Oudeyer", "Thomas Carta", "Clement Romac"], "title": "WorldLLM: Improving LLMs' world modeling using curiosity-driven theory-making", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) possess general world knowledge but often\nstruggle to generate precise predictions in structured, domain-specific\ncontexts such as simulations. These limitations arise from their inability to\nground their broad, unstructured understanding in specific environments. To\naddress this, we present WorldLLM, a framework that enhances LLM-based world\nmodeling by combining Bayesian inference and autonomous active exploration with\nreinforcement learning. WorldLLM leverages the in-context learning abilities of\nLLMs to guide an LLM-based world model's predictions using natural language\nhypotheses given in its prompt. These hypotheses are iteratively refined\nthrough a Bayesian inference framework that leverages a second LLM as the\nproposal distribution given collected evidence. This evidence is collected\nusing a curiosity-driven reinforcement learning policy that explores the\nenvironment to find transitions with a low log-likelihood under our LLM-based\npredictive model using the current hypotheses. By alternating between refining\nhypotheses and collecting new evidence, our framework autonomously drives\ncontinual improvement of the predictions. Our experiments demonstrate the\neffectiveness of WorldLLM in a textual game environment that requires agents to\nmanipulate and combine objects. The framework not only enhances predictive\naccuracy, but also generates human-interpretable theories of environment\ndynamics.", "AI": {"tldr": "WorldLLM\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u8d1d\u53f6\u65af\u63a8\u65ad\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u63d0\u5347LLM\u5728\u7ed3\u6784\u5316\u9886\u57df\u4e2d\u7684\u9884\u6d4b\u80fd\u529b\u3002", "motivation": "LLMs\u5728\u7ed3\u6784\u5316\u9886\u57df\uff08\u5982\u6a21\u62df\u73af\u5883\uff09\u4e2d\u96be\u4ee5\u751f\u6210\u7cbe\u786e\u9884\u6d4b\uff0c\u56e0\u5176\u65e0\u6cd5\u5c06\u5e7f\u6cdb\u77e5\u8bc6\u843d\u5730\u5230\u5177\u4f53\u73af\u5883\u3002", "method": "\u7ed3\u5408\u8d1d\u53f6\u65af\u63a8\u65ad\u548c\u81ea\u4e3b\u63a2\u7d22\u7684\u5f3a\u5316\u5b66\u4e60\uff0c\u5229\u7528LLM\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\u8fed\u4ee3\u4f18\u5316\u5047\u8bbe\u3002", "result": "\u5728\u6587\u672c\u6e38\u620f\u73af\u5883\u4e2d\uff0cWorldLLM\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u5e76\u751f\u6210\u4e86\u53ef\u89e3\u91ca\u7684\u73af\u5883\u52a8\u6001\u7406\u8bba\u3002", "conclusion": "WorldLLM\u901a\u8fc7\u8fed\u4ee3\u4f18\u5316\u548c\u63a2\u7d22\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u5728\u7ed3\u6784\u5316\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2506.06739", "pdf": "https://arxiv.org/pdf/2506.06739", "abs": "https://arxiv.org/abs/2506.06739", "authors": ["Andrew Cropper", "Filipe Gouveia", "David M. Cerna"], "title": "Honey, I shrunk the hypothesis space (through logical preprocessing)", "categories": ["cs.AI", "cs.LG"], "comment": "Submitted to JAIR", "summary": "Inductive logic programming (ILP) is a form of logical machine learning. The\ngoal is to search a hypothesis space for a hypothesis that generalises training\nexamples and background knowledge. We introduce an approach that 'shrinks' the\nhypothesis space before an ILP system searches it. Our approach uses background\nknowledge to find rules that cannot be in an optimal hypothesis regardless of\nthe training examples. For instance, our approach discovers relationships such\nas \"even numbers cannot be odd\" and \"prime numbers greater than 2 are odd\". It\nthen removes violating rules from the hypothesis space. We implement our\napproach using answer set programming and use it to shrink the hypothesis space\nof a constraint-based ILP system. Our experiments on multiple domains,\nincluding visual reasoning and game playing, show that our approach can\nsubstantially reduce learning times whilst maintaining predictive accuracies.\nFor instance, given just 10 seconds of preprocessing time, our approach can\nreduce learning times from over 10 hours to only 2 seconds.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u901a\u8fc7\u80cc\u666f\u77e5\u8bc6\u7f29\u5c0f\u5f52\u7eb3\u903b\u8f91\u7f16\u7a0b\uff08ILP\uff09\u5047\u8bbe\u7a7a\u95f4\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u51cf\u5c11\u5b66\u4e60\u65f6\u95f4\u3002", "motivation": "\u5728ILP\u4e2d\uff0c\u5047\u8bbe\u7a7a\u95f4\u53ef\u80fd\u5305\u542b\u65e0\u6548\u89c4\u5219\uff0c\u5bfc\u81f4\u641c\u7d22\u6548\u7387\u4f4e\u4e0b\u3002\u901a\u8fc7\u9884\u7b5b\u9009\u5047\u8bbe\u7a7a\u95f4\uff0c\u53ef\u4ee5\u63d0\u5347\u5b66\u4e60\u6548\u7387\u3002", "method": "\u5229\u7528\u80cc\u666f\u77e5\u8bc6\u8bc6\u522b\u5e76\u79fb\u9664\u65e0\u6548\u89c4\u5219\uff08\u5982\u201c\u5076\u6570\u4e0d\u53ef\u80fd\u662f\u5947\u6570\u201d\uff09\uff0c\u4f7f\u7528\u7b54\u6848\u96c6\u7f16\u7a0b\u5b9e\u73b0\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u9884\u5904\u7406\u65f6\u95f4\u4ec5\u970010\u79d2\uff0c\u5b66\u4e60\u65f6\u95f4\u53ef\u4ece10\u5c0f\u65f6\u7f29\u77ed\u81f32\u79d2\uff0c\u4e14\u9884\u6d4b\u7cbe\u5ea6\u4e0d\u53d8\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347ILP\u7cfb\u7edf\u7684\u6548\u7387\uff0c\u9002\u7528\u4e8e\u89c6\u89c9\u63a8\u7406\u548c\u6e38\u620f\u7b49\u9886\u57df\u3002"}}
{"id": "2506.06750", "pdf": "https://arxiv.org/pdf/2506.06750", "abs": "https://arxiv.org/abs/2506.06750", "authors": ["Zofia Rudnicka", "Janusz Szczepanski", "Agnieszka Pregowska"], "title": "Bio-Inspired Classification: Combining Information Theory and Spiking Neural Networks -- Influence of the Learning Rules", "categories": ["cs.AI", "cs.LG", "q-bio.NC"], "comment": null, "summary": "Training of Spiking Neural Networks (SNN) is challenging due to their unique\nproperties, including temporal dynamics, non-differentiability of spike events,\nand sparse event-driven activations. In this paper, we widely consider the\ninfluence of the type of chosen learning algorithm, including bioinspired\nlearning rules on the accuracy of classification. We proposed a bioinspired\nclassifier based on the combination of SNN and Lempel-Ziv complexity (LZC).\nThis approach synergizes the strengths of SNNs in temporal precision and\nbiological realism with LZC's structural complexity analysis, facilitating\nefficient and interpretable classification of spatiotemporal neural data. It\nturned out that the classic backpropagation algorithm achieves excellent\nclassification accuracy, but at extremely high computational cost, which makes\nit impractical for real-time applications. Biologically inspired learning\nalgorithms such as tempotron and Spikprop provide increased computational\nefficiency while maintaining competitive classification performance, making\nthem suitable for time-sensitive tasks. The results obtained indicate that the\nselection of the most appropriate learning algorithm depends on the trade-off\nbetween classification accuracy and computational cost as well as application\nconstraints.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\uff08SNN\uff09\u8bad\u7ec3\u4e2d\u7684\u6311\u6218\uff0c\u6bd4\u8f83\u4e86\u4e0d\u540c\u5b66\u4e60\u7b97\u6cd5\u5bf9\u5206\u7c7b\u51c6\u786e\u6027\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408SNN\u548cLempel-Ziv\u590d\u6742\u5ea6\uff08LZC\uff09\u7684\u751f\u7269\u542f\u53d1\u5206\u7c7b\u5668\u3002", "motivation": "\u89e3\u51b3SNN\u8bad\u7ec3\u4e2d\u7684\u6311\u6218\uff0c\u5982\u65f6\u95f4\u52a8\u6001\u6027\u3001\u8109\u51b2\u4e8b\u4ef6\u7684\u4e0d\u53ef\u5fae\u6027\u548c\u7a00\u758f\u4e8b\u4ef6\u9a71\u52a8\u6fc0\u6d3b\uff0c\u540c\u65f6\u63a2\u7d22\u4e0d\u540c\u5b66\u4e60\u7b97\u6cd5\u5bf9\u5206\u7c7b\u51c6\u786e\u6027\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408SNN\u548cLZC\u7684\u751f\u7269\u542f\u53d1\u5206\u7c7b\u5668\uff0c\u6bd4\u8f83\u4e86\u7ecf\u5178\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u4e0e\u751f\u7269\u542f\u53d1\u5b66\u4e60\u7b97\u6cd5\uff08\u5982tempotron\u548cSpikprop\uff09\u7684\u6027\u80fd\u3002", "result": "\u7ecf\u5178\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u5206\u7c7b\u51c6\u786e\u7387\u9ad8\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u800c\u751f\u7269\u542f\u53d1\u7b97\u6cd5\u5728\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\uff0c\u9002\u5408\u5b9e\u65f6\u5e94\u7528\u3002", "conclusion": "\u9009\u62e9\u6700\u9002\u5408\u7684\u5b66\u4e60\u7b97\u6cd5\u9700\u6743\u8861\u5206\u7c7b\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6210\u672c\uff0c\u5e76\u8003\u8651\u5e94\u7528\u573a\u666f\u7684\u7ea6\u675f\u3002"}}
{"id": "2506.06773", "pdf": "https://arxiv.org/pdf/2506.06773", "abs": "https://arxiv.org/abs/2506.06773", "authors": ["Emet Behrendt", "Shing Wai Pun", "Prashant J. Nair"], "title": "Taming Wild Branches: Overcoming Hard-to-Predict Branches using the Bullseye Predictor", "categories": ["cs.AR", "cs.LG", "cs.PF", "C.1.2; B.2.1; C.4; C.0"], "comment": "Paper accepted and presented at the 6th Championship Branch\n  Prediction (CBP) workshop, co-held with ISCA 2025, on June 21, 2025, Tokyo,\n  Japan", "summary": "Branch prediction is key to the performance of out-of-order processors. While\nthe CBP-2016 winner TAGE-SC-L combines geometric-history tables, a statistical\ncorrector, and a loop predictor, over half of its remaining mispredictions stem\nfrom a small set of hard-to-predict (H2P) branches. These branches occur under\ndiverse global histories, causing repeated thrashing in TAGE and eviction\nbefore usefulness counters can mature. Prior work shows that simply enlarging\nthe tables offers only marginal improvement.\n  We augment a 159 KB TAGE-SC-L predictor with a 28 KB H2P-targeted subsystem\ncalled the Bullseye predictor. It identifies problematic PCs using a\nset-associative H2P Identification Table (HIT) and steers them to one of two\nbranch-specific perceptrons, one indexed by hashed local history and the other\nby folded global history. A short trial phase tracks head-to-head accuracy in\nan H2P cache. A branch becomes perceptron-resident only if the perceptron's\nsustained accuracy and output magnitude exceed dynamic thresholds, after which\nTAGE updates for that PC are suppressed to reduce pollution. The HIT, cache,\nand perceptron operate fully in parallel with TAGE-SC-L, providing higher\nfidelity on the H2P tail. This achieves an average MPKI of 3.4045 and CycWpPKI\nof 145.09.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aBullseye\u7684\u9884\u6d4b\u5668\uff0c\u7528\u4e8e\u89e3\u51b3TAGE-SC-L\u9884\u6d4b\u5668\u4e2d\u96be\u4ee5\u9884\u6d4b\u7684\u5206\u652f\u95ee\u9898\uff0c\u901a\u8fc7\u5c40\u90e8\u548c\u5168\u5c40\u5386\u53f2\u611f\u77e5\u5668\u63d0\u5347\u9884\u6d4b\u7cbe\u5ea6\u3002", "motivation": "TAGE-SC-L\u9884\u6d4b\u5668\u4e2d\u96be\u4ee5\u9884\u6d4b\u7684\u5206\u652f\uff08H2P\uff09\u5bfc\u81f4\u5927\u91cf\u8bef\u9884\u6d4b\uff0c\u4f20\u7edf\u65b9\u6cd5\u5982\u6269\u5927\u8868\u683c\u6548\u679c\u6709\u9650\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a28 KB\u7684Bullseye\u5b50\u7cfb\u7edf\uff0c\u5305\u542bH2P\u8bc6\u522b\u8868\u3001\u5c40\u90e8\u548c\u5168\u5c40\u5386\u53f2\u611f\u77e5\u5668\uff0c\u5e76\u901a\u8fc7\u52a8\u6001\u9608\u503c\u7b5b\u9009\u6709\u6548\u5206\u652f\u3002", "result": "Bullseye\u5c06\u5e73\u5747MPKI\u964d\u81f33.4045\uff0cCycWpPKI\u964d\u81f3145.09\u3002", "conclusion": "Bullseye\u6709\u6548\u63d0\u5347\u4e86TAGE-SC-L\u5bf9H2P\u5206\u652f\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u51cf\u5c11\u4e86\u8bef\u9884\u6d4b\u3002"}}
{"id": "2506.06778", "pdf": "https://arxiv.org/pdf/2506.06778", "abs": "https://arxiv.org/abs/2506.06778", "authors": ["Longlin Yu", "Jiajun Zha", "Tong Yang", "Tianyu Xie", "Xiangyu Zhang", "S. -H. Gary Chan", "Cheng Zhang"], "title": "Continuous Semi-Implicit Models", "categories": ["stat.ML", "cs.LG"], "comment": "26 pages, 8 figures, ICML 2025", "summary": "Semi-implicit distributions have shown great promise in variational inference\nand generative modeling. Hierarchical semi-implicit models, which stack\nmultiple semi-implicit layers, enhance the expressiveness of semi-implicit\ndistributions and can be used to accelerate diffusion models given pretrained\nscore networks. However, their sequential training often suffers from slow\nconvergence. In this paper, we introduce CoSIM, a continuous semi-implicit\nmodel that extends hierarchical semi-implicit models into a continuous\nframework. By incorporating a continuous transition kernel, CoSIM enables\nefficient, simulation-free training. Furthermore, we show that CoSIM achieves\nconsistency with a carefully designed transition kernel, offering a novel\napproach for multistep distillation of generative models at the distributional\nlevel. Extensive experiments on image generation demonstrate that CoSIM\nperforms on par or better than existing diffusion model acceleration methods,\nachieving superior performance on FD-DINOv2.", "AI": {"tldr": "CoSIM\u662f\u4e00\u79cd\u8fde\u7eed\u534a\u9690\u5f0f\u6a21\u578b\uff0c\u901a\u8fc7\u8fde\u7eed\u8fc7\u6e21\u6838\u63d0\u5347\u8bad\u7ec3\u6548\u7387\uff0c\u5e76\u5728\u56fe\u50cf\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u89e3\u51b3\u5c42\u6b21\u534a\u9690\u5f0f\u6a21\u578b\u5728\u8bad\u7ec3\u4e2d\u6536\u655b\u6162\u7684\u95ee\u9898\uff0c\u5e76\u63d0\u5347\u751f\u6210\u6a21\u578b\u7684\u8868\u8fbe\u80fd\u529b\u3002", "method": "\u5f15\u5165\u8fde\u7eed\u8fc7\u6e21\u6838\uff0c\u5b9e\u73b0\u65e0\u6a21\u62df\u7684\u9ad8\u6548\u8bad\u7ec3\uff0c\u5e76\u901a\u8fc7\u8bbe\u8ba1\u7684\u4e00\u81f4\u6027\u8fc7\u6e21\u6838\u5b9e\u73b0\u591a\u6b65\u84b8\u998f\u3002", "result": "\u5728\u56fe\u50cf\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6269\u6563\u6a21\u578b\u52a0\u901f\u65b9\u6cd5\uff0c\u5c24\u5176\u5728FD-DINOv2\u4e0a\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "CoSIM\u4e3a\u751f\u6210\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u6027\u80fd\u4f18\u8d8a\u7684\u8fde\u7eed\u6846\u67b6\u3002"}}
{"id": "2506.06780", "pdf": "https://arxiv.org/pdf/2506.06780", "abs": "https://arxiv.org/abs/2506.06780", "authors": ["Lennart Bastian", "Mohammad Rashed", "Nassir Navab", "Tolga Birdal"], "title": "Continuous-Time SO(3) Forecasting with Savitzky--Golay Neural Controlled Differential Equations", "categories": ["cs.CV", "cs.LG"], "comment": "Extended abstract, presented at the CVPR Workshop on 4D Vision", "summary": "Tracking and forecasting the rotation of objects is fundamental in computer\nvision and robotics, yet SO(3) extrapolation remains challenging as (1) sensor\nobservations can be noisy and sparse, (2) motion patterns can be governed by\ncomplex dynamics, and (3) application settings can demand long-term\nforecasting. This work proposes modeling continuous-time rotational object\ndynamics on $SO(3)$ using Neural Controlled Differential Equations guided by\nSavitzky-Golay paths. Unlike existing methods that rely on simplified motion\nassumptions, our method learns a general latent dynamical system of the\nunderlying object trajectory while respecting the geometric structure of\nrotations. Experimental results on real-world data demonstrate compelling\nforecasting capabilities compared to existing approaches.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u795e\u7ecf\u63a7\u5236\u5fae\u5206\u65b9\u7a0b\u548cSavitzky-Golay\u8def\u5f84\u7684\u8fde\u7eed\u65f6\u95f4\u65cb\u8f6c\u7269\u4f53\u52a8\u529b\u5b66\u5efa\u6a21\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86SO(3)\u5916\u63a8\u4e2d\u7684\u566a\u58f0\u3001\u7a00\u758f\u6027\u548c\u590d\u6742\u52a8\u6001\u95ee\u9898\u3002", "motivation": "\u65cb\u8f6c\u7269\u4f53\u7684\u8ddf\u8e2a\u548c\u9884\u6d4b\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u548c\u673a\u5668\u4eba\u5b66\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46SO(3)\u5916\u63a8\u9762\u4e34\u566a\u58f0\u3001\u7a00\u758f\u89c2\u6d4b\u3001\u590d\u6742\u52a8\u6001\u548c\u957f\u671f\u9884\u6d4b\u9700\u6c42\u7b49\u6311\u6218\u3002", "method": "\u4f7f\u7528\u795e\u7ecf\u63a7\u5236\u5fae\u5206\u65b9\u7a0b\uff08Neural Controlled Differential Equations\uff09\u7ed3\u5408Savitzky-Golay\u8def\u5f84\uff0c\u5efa\u6a21\u8fde\u7eed\u65f6\u95f4\u65cb\u8f6c\u7269\u4f53\u52a8\u529b\u5b66\uff0c\u4fdd\u7559\u65cb\u8f6c\u7684\u51e0\u4f55\u7ed3\u6784\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u771f\u5b9e\u6570\u636e\u4e0a\u5177\u6709\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u9884\u6d4b\u80fd\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u51e0\u4f55\u7ed3\u6784\u4fdd\u7559\u548c\u590d\u6742\u52a8\u6001\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u5347\u4e86\u65cb\u8f6c\u7269\u4f53\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2506.06806", "pdf": "https://arxiv.org/pdf/2506.06806", "abs": "https://arxiv.org/abs/2506.06806", "authors": ["Subhendu Khatuya", "Shashwat Naidu", "Saptarshi Ghosh", "Pawan Goyal", "Niloy Ganguly"], "title": "Label-semantics Aware Generative Approach for Domain-Agnostic Multilabel Classification", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "This work has been accepted to appear at the Association for\n  Computational Linguistics (ACL), 2025", "summary": "The explosion of textual data has made manual document classification\nincreasingly challenging. To address this, we introduce a robust, efficient\ndomain-agnostic generative model framework for multi-label text classification.\nInstead of treating labels as mere atomic symbols, our approach utilizes\npredefined label descriptions and is trained to generate these descriptions\nbased on the input text. During inference, the generated descriptions are\nmatched to the pre-defined labels using a finetuned sentence transformer. We\nintegrate this with a dual-objective loss function, combining cross-entropy\nloss and cosine similarity of the generated sentences with the predefined\ntarget descriptions, ensuring both semantic alignment and accuracy. Our\nproposed model LAGAMC stands out for its parameter efficiency and versatility\nacross diverse datasets, making it well-suited for practical applications. We\ndemonstrate the effectiveness of our proposed model by achieving new\nstate-of-the-art performances across all evaluated datasets, surpassing several\nstrong baselines. We achieve improvements of 13.94% in Micro-F1 and 24.85% in\nMacro-F1 compared to the closest baseline across all datasets.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u751f\u6210\u6a21\u578b\u7684\u591a\u6807\u7b7e\u6587\u672c\u5206\u7c7b\u6846\u67b6LAGAMC\uff0c\u901a\u8fc7\u751f\u6210\u6807\u7b7e\u63cf\u8ff0\u5e76\u5339\u914d\u9884\u5b9a\u4e49\u6807\u7b7e\uff0c\u7ed3\u5408\u53cc\u91cd\u76ee\u6807\u635f\u5931\u51fd\u6570\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u901a\u7528\u7684\u5206\u7c7b\u6027\u80fd\u3002", "motivation": "\u6587\u672c\u6570\u636e\u7206\u70b8\u5bfc\u81f4\u624b\u52a8\u5206\u7c7b\u56f0\u96be\uff0c\u9700\u8981\u4e00\u79cd\u9ad8\u6548\u4e14\u901a\u7528\u7684\u81ea\u52a8\u5206\u7c7b\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u9884\u5b9a\u4e49\u6807\u7b7e\u63cf\u8ff0\u751f\u6210\u6a21\u578b\uff0c\u7ed3\u5408\u53cc\u91cd\u76ee\u6807\u635f\u5931\u51fd\u6570\uff08\u4ea4\u53c9\u71b5\u635f\u5931\u548c\u4f59\u5f26\u76f8\u4f3c\u5ea6\uff09\uff0c\u901a\u8fc7\u5fae\u8c03\u7684\u53e5\u5b50\u8f6c\u6362\u5668\u5339\u914d\u751f\u6210\u63cf\u8ff0\u4e0e\u9884\u5b9a\u4e49\u6807\u7b7e\u3002", "result": "\u5728\u6240\u6709\u8bc4\u4f30\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u65b0\u7684\u6700\u5148\u8fdb\u6027\u80fd\uff0cMicro-F1\u63d0\u534713.94%\uff0cMacro-F1\u63d0\u534724.85%\u3002", "conclusion": "LAGAMC\u6a21\u578b\u5728\u53c2\u6570\u6548\u7387\u548c\u901a\u7528\u6027\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2506.06817", "pdf": "https://arxiv.org/pdf/2506.06817", "abs": "https://arxiv.org/abs/2506.06817", "authors": ["Haoran Wu", "Ce Guo", "Wayne Luk", "Robert Mullins"], "title": "ASPO: Constraint-Aware Bayesian Optimization for FPGA-based Soft Processors", "categories": ["cs.AR", "cs.LG", "cs.NE", "cs.PF"], "comment": "Accepted to International Conference on Field-Programmable Logic and\n  Applications (FPL) 2025", "summary": "Bayesian Optimization (BO) has shown promise in tuning processor design\nparameters. However, standard BO does not support constraints involving\ncategorical parameters such as types of branch predictors and division\ncircuits. In addition, optimization time of BO grows with processor complexity,\nwhich becomes increasingly significant especially for FPGA-based soft\nprocessors. This paper introduces ASPO, an approach that leverages disjunctive\nform to enable BO to handle constraints involving categorical parameters.\nUnlike existing methods that directly apply standard BO, the proposed ASPO\nmethod, for the first time, customizes the mathematical mechanism of BO to\naddress challenges faced by soft-processor designs on FPGAs. Specifically, ASPO\nsupports categorical parameters using a novel customized BO covariance kernel.\nIt also accelerates the design evaluation procedure by penalizing the BO\nacquisition function with potential evaluation time and by reusing FPGA\nsynthesis checkpoints from previously evaluated configurations. ASPO targets\nthree soft processors: RocketChip, BOOM, and EL2 VeeR. The approach is\nevaluated based on seven RISC-V benchmarks. Results show that ASPO can reduce\nexecution time for the ``multiply'' benchmark on the BOOM processor by up to\n35\\% compared to the default configuration. Furthermore, it reduces design time\nfor the BOOM processor by up to 74\\% compared to Boomerang, a state-of-the-art\nhardware-oriented BO approach.", "AI": {"tldr": "ASPO\u662f\u4e00\u79cd\u6539\u8fdb\u7684\u8d1d\u53f6\u65af\u4f18\u5316\u65b9\u6cd5\uff0c\u652f\u6301\u5904\u7406\u5305\u542b\u5206\u7c7b\u53c2\u6570\u7684\u7ea6\u675f\uff0c\u5e76\u52a0\u901fFPGA\u8f6f\u5904\u7406\u5668\u7684\u8bbe\u8ba1\u4f18\u5316\u3002", "motivation": "\u6807\u51c6\u8d1d\u53f6\u65af\u4f18\u5316\uff08BO\uff09\u65e0\u6cd5\u5904\u7406\u6d89\u53ca\u5206\u7c7b\u53c2\u6570\u7684\u7ea6\u675f\uff0c\u4e14\u4f18\u5316\u65f6\u95f4\u968f\u5904\u7406\u5668\u590d\u6742\u5ea6\u589e\u52a0\u800c\u663e\u8457\u589e\u957f\uff0c\u7279\u522b\u662f\u5728FPGA\u8f6f\u5904\u7406\u5668\u8bbe\u8ba1\u4e2d\u3002", "method": "ASPO\u901a\u8fc7\u5b9a\u5236BO\u7684\u6570\u5b66\u673a\u5236\uff0c\u5f15\u5165\u65b0\u7684\u534f\u65b9\u5dee\u6838\u652f\u6301\u5206\u7c7b\u53c2\u6570\uff0c\u5e76\u901a\u8fc7\u60e9\u7f5a\u83b7\u53d6\u51fd\u6570\u548c\u91cd\u7528FPGA\u5408\u6210\u68c0\u67e5\u70b9\u6765\u52a0\u901f\u8bbe\u8ba1\u8bc4\u4f30\u3002", "result": "ASPO\u5728BOOM\u5904\u7406\u5668\u4e0a\u4e3a\u201cmultiply\u201d\u57fa\u51c6\u6d4b\u8bd5\u51cf\u5c11\u4e8635%\u7684\u6267\u884c\u65f6\u95f4\uff0c\u5e76\u5c06\u8bbe\u8ba1\u65f6\u95f4\u6bd4\u73b0\u6709\u65b9\u6cd5Boomerang\u51cf\u5c11\u4e8674%\u3002", "conclusion": "ASPO\u6210\u529f\u89e3\u51b3\u4e86\u6807\u51c6BO\u5728\u8f6f\u5904\u7406\u5668\u8bbe\u8ba1\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4f18\u5316\u6548\u7387\u548c\u6027\u80fd\u3002"}}
{"id": "2506.06828", "pdf": "https://arxiv.org/pdf/2506.06828", "abs": "https://arxiv.org/abs/2506.06828", "authors": ["Simon P. von der Maase"], "title": "The Currents of Conflict: Decomposing Conflict Trends with Gaussian Processes", "categories": ["stat.ML", "cs.LG", "stat.AP"], "comment": "Total Words: 8122, Total pages: 28, Total figures: 6, Total Tables: 5", "summary": "I present a novel approach to estimating the temporal and spatial patterns of\nviolent conflict. I show how we can use highly temporally and spatially\ndisaggregated data on conflict events in tandem with Gaussian processes to\nestimate temporospatial conflict trends. These trends can be studied to gain\ninsight into conflict traps, diffusion and tempo-spatial conflict exposure in\ngeneral; they can also be used to control for such phenomenons given other\nestimation tasks; lastly, the approach allow us to extrapolate the estimated\ntempo-spatial conflict patterns into future temporal units, thus facilitating\npowerful, stat-of-the-art, conflict forecasts. Importantly, these results are\nachieved via a relatively parsimonious framework using only one data source:\npast conflict patterns.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u9ad8\u65af\u8fc7\u7a0b\u548c\u65f6\u95f4\u7a7a\u95f4\u5206\u89e3\u6570\u636e\u4f30\u8ba1\u51b2\u7a81\u8d8b\u52bf\u7684\u65b0\u65b9\u6cd5\uff0c\u53ef\u7528\u4e8e\u7814\u7a76\u51b2\u7a81\u9677\u9631\u3001\u6269\u6563\u548c\u9884\u6d4b\u672a\u6765\u51b2\u7a81\u3002", "motivation": "\u7814\u7a76\u51b2\u7a81\u7684\u65f6\u95f4\u7a7a\u95f4\u6a21\u5f0f\uff0c\u4ee5\u63ed\u793a\u51b2\u7a81\u9677\u9631\u3001\u6269\u6563\u7b49\u73b0\u8c61\uff0c\u5e76\u4e3a\u5176\u4ed6\u4f30\u8ba1\u4efb\u52a1\u63d0\u4f9b\u63a7\u5236\u53d8\u91cf\u3002", "method": "\u4f7f\u7528\u9ad8\u65af\u8fc7\u7a0b\u548c\u65f6\u95f4\u7a7a\u95f4\u5206\u89e3\u7684\u51b2\u7a81\u4e8b\u4ef6\u6570\u636e\uff0c\u4f30\u8ba1\u51b2\u7a81\u8d8b\u52bf\u3002", "result": "\u80fd\u591f\u7814\u7a76\u51b2\u7a81\u8d8b\u52bf\u3001\u63a7\u5236\u51b2\u7a81\u73b0\u8c61\uff0c\u5e76\u9884\u6d4b\u672a\u6765\u51b2\u7a81\u6a21\u5f0f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4ec5\u9700\u5386\u53f2\u51b2\u7a81\u6570\u636e\uff0c\u5373\u53ef\u5b9e\u73b0\u9ad8\u6548\u7684\u51b2\u7a81\u8d8b\u52bf\u4f30\u8ba1\u548c\u9884\u6d4b\u3002"}}
{"id": "2506.06836", "pdf": "https://arxiv.org/pdf/2506.06836", "abs": "https://arxiv.org/abs/2506.06836", "authors": ["Zelin He", "Sarah Alnegheimish", "Matthew Reimherr"], "title": "Harnessing Vision-Language Models for Time Series Anomaly Detection", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Time-series anomaly detection (TSAD) has played a vital role in a variety of\nfields, including healthcare, finance, and industrial monitoring. Prior\nmethods, which mainly focus on training domain-specific models on numerical\ndata, lack the visual-temporal reasoning capacity that human experts have to\nidentify contextual anomalies. To fill this gap, we explore a solution based on\nvision language models (VLMs). Recent studies have shown the ability of VLMs\nfor visual reasoning tasks, yet their direct application to time series has\nfallen short on both accuracy and efficiency. To harness the power of VLMs for\nTSAD, we propose a two-stage solution, with (1) ViT4TS, a vision-screening\nstage built on a relatively lightweight pretrained vision encoder, which\nleverages 2-D time-series representations to accurately localize candidate\nanomalies; (2) VLM4TS, a VLM-based stage that integrates global temporal\ncontext and VLM reasoning capacity to refine the detection upon the candidates\nprovided by ViT4TS. We show that without any time-series training, VLM4TS\noutperforms time-series pretrained and from-scratch baselines in most cases,\nyielding a 24.6 percent improvement in F1-max score over the best baseline.\nMoreover, VLM4TS also consistently outperforms existing language-model-based\nTSAD methods and is on average 36 times more efficient in token usage.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u7684\u4e24\u9636\u6bb5\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\uff0c\u7ed3\u5408\u8f7b\u91cf\u7ea7\u89c6\u89c9\u7f16\u7801\u5668\u548cVLM\u63a8\u7406\u80fd\u529b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u89c6\u89c9-\u65f6\u95f4\u63a8\u7406\u80fd\u529b\uff0c\u65e0\u6cd5\u50cf\u4eba\u7c7b\u4e13\u5bb6\u90a3\u6837\u8bc6\u522b\u4e0a\u4e0b\u6587\u5f02\u5e38\uff0c\u56e0\u6b64\u63a2\u7d22\u57fa\u4e8eVLM\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a1) ViT4TS\uff08\u8f7b\u91cf\u7ea7\u89c6\u89c9\u7f16\u7801\u5668\uff09\u5b9a\u4f4d\u5019\u9009\u5f02\u5e38\uff1b2) VLM4TS\uff08VLM\u9636\u6bb5\uff09\u7ed3\u5408\u5168\u5c40\u65f6\u95f4\u4e0a\u4e0b\u6587\u548cVLM\u63a8\u7406\u80fd\u529b\u4f18\u5316\u68c0\u6d4b\u3002", "result": "VLM4TS\u5728\u672a\u8bad\u7ec3\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0cF1-max\u5206\u6570\u6bd4\u6700\u4f73\u57fa\u7ebf\u63d0\u534724.6%\uff0c\u4e14\u6548\u7387\u66f4\u9ad8\uff08\u4ee4\u724c\u4f7f\u7528\u91cf\u5e73\u5747\u51cf\u5c1136\u500d\uff09\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u7ed3\u5408\u89c6\u89c9\u548c\u65f6\u95f4\u63a8\u7406\u80fd\u529b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2506.06840", "pdf": "https://arxiv.org/pdf/2506.06840", "abs": "https://arxiv.org/abs/2506.06840", "authors": ["Fahad Mostafa"], "title": "A Statistical Framework for Model Selection in LSTM Networks", "categories": ["stat.ML", "cs.AI", "cs.LG", "stat.AP", "62M10, 92B20, 62P10, 62P99"], "comment": null, "summary": "Long Short-Term Memory (LSTM) neural network models have become the\ncornerstone for sequential data modeling in numerous applications, ranging from\nnatural language processing to time series forecasting. Despite their success,\nthe problem of model selection, including hyperparameter tuning, architecture\nspecification, and regularization choice remains largely heuristic and\ncomputationally expensive. In this paper, we propose a unified statistical\nframework for systematic model selection in LSTM networks. Our framework\nextends classical model selection ideas, such as information criteria and\nshrinkage estimation, to sequential neural networks. We define penalized\nlikelihoods adapted to temporal structures, propose a generalized threshold\napproach for hidden state dynamics, and provide efficient estimation strategies\nusing variational Bayes and approximate marginal likelihood methods. Several\nbiomedical data centric examples demonstrate the flexibility and improved\nperformance of the proposed framework.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u7edf\u8ba1\u6846\u67b6\uff0c\u7528\u4e8eLSTM\u7f51\u7edc\u7684\u7cfb\u7edf\u6a21\u578b\u9009\u62e9\uff0c\u89e3\u51b3\u4e86\u8d85\u53c2\u6570\u8c03\u4f18\u3001\u67b6\u6784\u9009\u62e9\u548c\u6b63\u5219\u5316\u7b49\u95ee\u9898\u3002", "motivation": "\u5c3d\u7ba1LSTM\u5728\u5e8f\u5217\u6570\u636e\u5efa\u6a21\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u6a21\u578b\u9009\u62e9\u95ee\u9898\u4ecd\u4f9d\u8d56\u542f\u53d1\u5f0f\u65b9\u6cd5\u4e14\u8ba1\u7b97\u6210\u672c\u9ad8\u3002", "method": "\u6269\u5c55\u7ecf\u5178\u6a21\u578b\u9009\u62e9\u601d\u60f3\uff08\u5982\u4fe1\u606f\u51c6\u5219\u548c\u6536\u7f29\u4f30\u8ba1\uff09\u5230\u5e8f\u5217\u795e\u7ecf\u7f51\u7edc\uff0c\u63d0\u51fa\u60e9\u7f5a\u4f3c\u7136\u548c\u5e7f\u4e49\u9608\u503c\u65b9\u6cd5\uff0c\u5e76\u4f7f\u7528\u53d8\u5206\u8d1d\u53f6\u65af\u548c\u8fd1\u4f3c\u8fb9\u9645\u4f3c\u7136\u8fdb\u884c\u9ad8\u6548\u4f30\u8ba1\u3002", "result": "\u5728\u591a\u4e2a\u751f\u7269\u533b\u5b66\u6570\u636e\u793a\u4f8b\u4e2d\u5c55\u793a\u4e86\u6846\u67b6\u7684\u7075\u6d3b\u6027\u548c\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aLSTM\u6a21\u578b\u9009\u62e9\u63d0\u4f9b\u4e86\u7cfb\u7edf\u4e14\u9ad8\u6548\u7684\u65b9\u6cd5\u3002"}}
{"id": "2506.06862", "pdf": "https://arxiv.org/pdf/2506.06862", "abs": "https://arxiv.org/abs/2506.06862", "authors": ["Chenguang Huang", "Oier Mees", "Andy Zeng", "Wolfram Burgard"], "title": "Multimodal Spatial Language Maps for Robot Navigation and Manipulation", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG", "cs.SD", "eess.AS"], "comment": "accepted to International Journal of Robotics Research (IJRR). 24\n  pages, 18 figures. The paper contains texts from VLMaps(arXiv:2210.05714) and\n  AVLMaps(arXiv:2303.07522). The project page is https://mslmaps.github.io/", "summary": "Grounding language to a navigating agent's observations can leverage\npretrained multimodal foundation models to match perceptions to object or event\ndescriptions. However, previous approaches remain disconnected from environment\nmapping, lack the spatial precision of geometric maps, or neglect additional\nmodality information beyond vision. To address this, we propose multimodal\nspatial language maps as a spatial map representation that fuses pretrained\nmultimodal features with a 3D reconstruction of the environment. We build these\nmaps autonomously using standard exploration. We present two instances of our\nmaps, which are visual-language maps (VLMaps) and their extension to\naudio-visual-language maps (AVLMaps) obtained by adding audio information. When\ncombined with large language models (LLMs), VLMaps can (i) translate natural\nlanguage commands into open-vocabulary spatial goals (e.g., \"in between the\nsofa and TV\") directly localized in the map, and (ii) be shared across\ndifferent robot embodiments to generate tailored obstacle maps on demand.\nBuilding upon the capabilities above, AVLMaps extend VLMaps by introducing a\nunified 3D spatial representation integrating audio, visual, and language cues\nthrough the fusion of features from pretrained multimodal foundation models.\nThis enables robots to ground multimodal goal queries (e.g., text, images, or\naudio snippets) to spatial locations for navigation. Additionally, the\nincorporation of diverse sensory inputs significantly enhances goal\ndisambiguation in ambiguous environments. Experiments in simulation and\nreal-world settings demonstrate that our multimodal spatial language maps\nenable zero-shot spatial and multimodal goal navigation and improve recall by\n50% in ambiguous scenarios. These capabilities extend to mobile robots and\ntabletop manipulators, supporting navigation and interaction guided by visual,\naudio, and spatial cues.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6a21\u6001\u7a7a\u95f4\u8bed\u8a00\u5730\u56fe\uff08VLMaps\u548cAVLMaps\uff09\uff0c\u901a\u8fc7\u878d\u5408\u9884\u8bad\u7ec3\u591a\u6a21\u6001\u7279\u5f81\u4e0e3D\u73af\u5883\u91cd\u5efa\uff0c\u5b9e\u73b0\u81ea\u7136\u8bed\u8a00\u547d\u4ee4\u5230\u7a7a\u95f4\u76ee\u6807\u7684\u7ffb\u8bd1\uff0c\u5e76\u652f\u6301\u591a\u6a21\u6001\u76ee\u6807\u5bfc\u822a\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u73af\u5883\u6620\u5c04\u3001\u7a7a\u95f4\u7cbe\u5ea6\u548c\u591a\u6a21\u6001\u4fe1\u606f\u5229\u7528\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u5168\u9762\u7684\u7a7a\u95f4\u5730\u56fe\u8868\u793a\u65b9\u6cd5\u3002", "method": "\u63d0\u51faVLMaps\u548cAVLMaps\uff0c\u7ed3\u5408\u9884\u8bad\u7ec3\u591a\u6a21\u6001\u7279\u5f81\u4e0e3D\u91cd\u5efa\uff0c\u652f\u6301\u81ea\u7136\u8bed\u8a00\u547d\u4ee4\u7ffb\u8bd1\u548c\u591a\u6a21\u6001\u76ee\u6807\u5bfc\u822a\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4eff\u771f\u548c\u771f\u5b9e\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u96f6\u6837\u672c\u7a7a\u95f4\u548c\u591a\u6a21\u6001\u76ee\u6807\u5bfc\u822a\uff0c\u5e76\u5728\u6a21\u7cca\u573a\u666f\u4e2d\u53ec\u56de\u7387\u63d0\u534750%\u3002", "conclusion": "\u591a\u6a21\u6001\u7a7a\u95f4\u8bed\u8a00\u5730\u56fe\u4e3a\u673a\u5668\u4eba\u5bfc\u822a\u548c\u4ea4\u4e92\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u548c\u7cbe\u786e\u7684\u652f\u6301\u3002"}}
{"id": "2506.06898", "pdf": "https://arxiv.org/pdf/2506.06898", "abs": "https://arxiv.org/abs/2506.06898", "authors": ["Reese Kneeland", "Paul S. Scotti", "Ghislain St-Yves", "Jesse Breedlove", "Kendrick Kay", "Thomas Naselaris"], "title": "NSD-Imagery: A benchmark dataset for extending fMRI vision decoding methods to mental imagery", "categories": ["cs.CV", "cs.LG", "eess.IV", "q-bio.NC"], "comment": "Published at CVPR 2025", "summary": "We release NSD-Imagery, a benchmark dataset of human fMRI activity paired\nwith mental images, to complement the existing Natural Scenes Dataset (NSD), a\nlarge-scale dataset of fMRI activity paired with seen images that enabled\nunprecedented improvements in fMRI-to-image reconstruction efforts. Recent\nmodels trained on NSD have been evaluated only on seen image reconstruction.\nUsing NSD-Imagery, it is possible to assess how well these models perform on\nmental image reconstruction. This is a challenging generalization requirement\nbecause mental images are encoded in human brain activity with relatively lower\nsignal-to-noise and spatial resolution; however, generalization from seen to\nmental imagery is critical for real-world applications in medical domains and\nbrain-computer interfaces, where the desired information is always internally\ngenerated. We provide benchmarks for a suite of recent NSD-trained open-source\nvisual decoding models (MindEye1, MindEye2, Brain Diffuser, iCNN, Takagi et\nal.) on NSD-Imagery, and show that the performance of decoding methods on\nmental images is largely decoupled from performance on vision reconstruction.\nWe further demonstrate that architectural choices significantly impact\ncross-decoding performance: models employing simple linear decoding\narchitectures and multimodal feature decoding generalize better to mental\nimagery, while complex architectures tend to overfit visual training data. Our\nfindings indicate that mental imagery datasets are critical for the development\nof practical applications, and establish NSD-Imagery as a useful resource for\nbetter aligning visual decoding methods with this goal.", "AI": {"tldr": "NSD-Imagery\u662f\u4e00\u4e2a\u65b0\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30fMRI\u5230\u56fe\u50cf\u91cd\u5efa\u6a21\u578b\u5728\u5fc3\u7406\u56fe\u50cf\u4e0a\u7684\u8868\u73b0\uff0c\u586b\u8865\u4e86\u73b0\u6709NSD\u6570\u636e\u96c6\u7684\u7a7a\u767d\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u4ec5\u5728\u5df2\u89c1\u56fe\u50cf\u91cd\u5efa\u4e0a\u8bc4\u4f30\uff0c\u800c\u5fc3\u7406\u56fe\u50cf\u91cd\u5efa\u5bf9\u533b\u5b66\u548c\u8111\u673a\u63a5\u53e3\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u4f9bNSD-Imagery\u6570\u636e\u96c6\uff0c\u5e76\u8bc4\u4f30\u591a\u79cdNSD\u8bad\u7ec3\u7684\u5f00\u6e90\u89c6\u89c9\u89e3\u7801\u6a21\u578b\uff08\u5982MindEye1\u3001Brain Diffuser\u7b49\uff09\u5728\u5fc3\u7406\u56fe\u50cf\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u5fc3\u7406\u56fe\u50cf\u89e3\u7801\u6027\u80fd\u4e0e\u89c6\u89c9\u91cd\u5efa\u6027\u80fd\u8131\u94a9\uff0c\u7b80\u5355\u7ebf\u6027\u67b6\u6784\u548c\u591a\u6a21\u6001\u7279\u5f81\u89e3\u7801\u6a21\u578b\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "\u5fc3\u7406\u56fe\u50cf\u6570\u636e\u96c6\u5bf9\u5b9e\u9645\u5e94\u7528\u81f3\u5173\u91cd\u8981\uff0cNSD-Imagery\u4e3a\u89c6\u89c9\u89e3\u7801\u65b9\u6cd5\u7684\u4f18\u5316\u63d0\u4f9b\u4e86\u8d44\u6e90\u3002"}}
{"id": "2506.06915", "pdf": "https://arxiv.org/pdf/2506.06915", "abs": "https://arxiv.org/abs/2506.06915", "authors": ["Odin Zhang", "Haitao Lin", "Xujun Zhang", "Xiaorui Wang", "Zhenxing Wu", "Qing Ye", "Weibo Zhao", "Jike Wang", "Kejun Ying", "Yu Kang", "Chang-yu Hsieh", "Tingjun Hou"], "title": "Graph Neural Networks in Modern AI-aided Drug Discovery", "categories": ["q-bio.BM", "cs.LG"], "comment": null, "summary": "Graph neural networks (GNNs), as topology/structure-aware models within deep\nlearning, have emerged as powerful tools for AI-aided drug discovery (AIDD). By\ndirectly operating on molecular graphs, GNNs offer an intuitive and expressive\nframework for learning the complex topological and geometric features of\ndrug-like molecules, cementing their role in modern molecular modeling. This\nreview provides a comprehensive overview of the methodological foundations and\nrepresentative applications of GNNs in drug discovery, spanning tasks such as\nmolecular property prediction, virtual screening, molecular generation,\nbiomedical knowledge graph construction, and synthesis planning. Particular\nattention is given to recent methodological advances, including geometric GNNs,\ninterpretable models, uncertainty quantification, scalable graph architectures,\nand graph generative frameworks. We also discuss how these models integrate\nwith modern deep learning approaches, such as self-supervised learning,\nmulti-task learning, meta-learning and pre-training. Throughout this review, we\nhighlight the practical challenges and methodological bottlenecks encountered\nwhen applying GNNs to real-world drug discovery pipelines, and conclude with a\ndiscussion on future directions.", "AI": {"tldr": "\u8be5\u7efc\u8ff0\u5168\u9762\u4ecb\u7ecd\u4e86\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNNs\uff09\u5728\u836f\u7269\u53d1\u73b0\u4e2d\u7684\u65b9\u6cd5\u57fa\u7840\u548c\u5e94\u7528\uff0c\u5305\u62ec\u5206\u5b50\u6027\u8d28\u9884\u6d4b\u3001\u865a\u62df\u7b5b\u9009\u7b49\u4efb\u52a1\uff0c\u5e76\u63a2\u8ba8\u4e86\u6700\u65b0\u65b9\u6cd5\u8fdb\u5c55\u4e0e\u5b9e\u9645\u6311\u6218\u3002", "motivation": "GNNs\u56e0\u5176\u5bf9\u5206\u5b50\u56fe\u7ed3\u6784\u7684\u76f4\u63a5\u64cd\u4f5c\u80fd\u529b\uff0c\u6210\u4e3a\u836f\u7269\u53d1\u73b0\u4e2d\u5f3a\u5927\u7684\u5de5\u5177\uff0c\u672c\u6587\u65e8\u5728\u603b\u7ed3\u5176\u65b9\u6cd5\u4e0e\u5e94\u7528\u3002", "method": "\u7efc\u8ff0\u4e86GNNs\u7684\u65b9\u6cd5\u8bba\u57fa\u7840\uff0c\u5305\u62ec\u51e0\u4f55GNNs\u3001\u53ef\u89e3\u91ca\u6a21\u578b\u7b49\uff0c\u5e76\u63a2\u8ba8\u5176\u4e0e\u5176\u4ed6\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u7684\u7ed3\u5408\u3002", "result": "GNNs\u5728\u836f\u7269\u53d1\u73b0\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u4e2d\u4ecd\u9762\u4e34\u6311\u6218\u548c\u65b9\u6cd5\u74f6\u9888\u3002", "conclusion": "\u672a\u6765\u9700\u8fdb\u4e00\u6b65\u4f18\u5316GNNs\u5728\u836f\u7269\u53d1\u73b0\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\uff0c\u89e3\u51b3\u73b0\u6709\u6311\u6218\u3002"}}
{"id": "2506.06941", "pdf": "https://arxiv.org/pdf/2506.06941", "abs": "https://arxiv.org/abs/2506.06941", "authors": ["Parshin Shojaee", "Iman Mirzadeh", "Keivan Alizadeh", "Maxwell Horton", "Samy Bengio", "Mehrdad Farajtabar"], "title": "The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "preprint", "summary": "Recent generations of language models have introduced Large Reasoning Models\n(LRMs) that generate detailed thinking processes before providing answers.\nWhile these models demonstrate improved performance on reasoning benchmarks,\ntheir fundamental capabilities, scaling properties, and limitations remain\ninsufficiently understood. Current evaluations primarily focus on established\nmath and coding benchmarks, emphasizing final answer accuracy. However, this\nevaluation paradigm often suffers from contamination and does not provide\ninsights into the reasoning traces. In this work, we systematically investigate\nthese gaps with the help of controllable puzzle environments that allow precise\nmanipulation of complexity while maintaining consistent logical structures.\nThis setup enables the analysis of not only final answers but also the internal\nreasoning traces, offering insights into how LRMs think. Through extensive\nexperiments, we show that LRMs face a complete accuracy collapse beyond certain\ncomplexities. Moreover, they exhibit a counterintuitive scaling limit: their\nreasoning effort increases with problem complexity up to a point, then declines\ndespite having remaining token budget. By comparing LRMs with their standard\nLLM counterparts under same inference compute, we identify three performance\nregimes: (1) low-complexity tasks where standard models outperform LRMs, (2)\nmedium-complexity tasks where LRMs demonstrates advantage, and (3)\nhigh-complexity tasks where both models face complete collapse. We found that\nLRMs have limitations in exact computation: they fail to use explicit\nalgorithms and reason inconsistently across scales. We also investigate the\nreasoning traces in more depth, studying the patterns of explored solutions and\nanalyzing the models' computational behavior, shedding light on their\nstrengths, limitations, and raising questions about their reasoning\ncapabilities.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u7684\u80fd\u529b\u3001\u6269\u5c55\u6027\u548c\u5c40\u9650\u6027\uff0c\u53d1\u73b0\u5176\u5728\u590d\u6742\u5ea6\u8d85\u8fc7\u4e00\u5b9a\u9608\u503c\u65f6\u51c6\u786e\u6027\u5d29\u6e83\uff0c\u5e76\u63ed\u793a\u4e86\u5176\u63a8\u7406\u884c\u4e3a\u7684\u53cd\u76f4\u89c9\u7279\u6027\u3002", "motivation": "\u5f53\u524d\u5bf9LRMs\u7684\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u6570\u5b66\u548c\u7f16\u7a0b\u57fa\u51c6\u7684\u6700\u7ec8\u7b54\u6848\u51c6\u786e\u6027\uff0c\u7f3a\u4e4f\u5bf9\u5176\u63a8\u7406\u8fc7\u7a0b\u7684\u6df1\u5165\u7406\u89e3\uff0c\u4e14\u5b58\u5728\u6570\u636e\u6c61\u67d3\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u53ef\u63a7\u7684\u62fc\u56fe\u73af\u5883\u7cfb\u7edf\u7814\u7a76LRMs\uff0c\u7cbe\u786e\u64cd\u7eb5\u590d\u6742\u5ea6\u5e76\u5206\u6790\u63a8\u7406\u75d5\u8ff9\u3002", "result": "\u53d1\u73b0LRMs\u5728\u590d\u6742\u5ea6\u8d85\u8fc7\u9608\u503c\u65f6\u51c6\u786e\u6027\u5d29\u6e83\uff0c\u63a8\u7406\u52aa\u529b\u968f\u590d\u6742\u5ea6\u589e\u52a0\u81f3\u67d0\u70b9\u540e\u4e0b\u964d\uff0c\u4e14\u5728\u4e0d\u540c\u590d\u6742\u5ea6\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u540c\u3002", "conclusion": "LRMs\u5728\u7cbe\u786e\u8ba1\u7b97\u548c\u4e00\u81f4\u6027\u63a8\u7406\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u5176\u63a8\u7406\u80fd\u529b\u4ecd\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2506.06942", "pdf": "https://arxiv.org/pdf/2506.06942", "abs": "https://arxiv.org/abs/2506.06942", "authors": ["Mohammad Farzanullah", "Han Zhang", "Akram Bin Sediq", "Ali Afana", "Melike Erol-Kantarci"], "title": "Conditional Denoising Diffusion for ISAC Enhanced Channel Estimation in Cell-Free 6G", "categories": ["eess.SP", "cs.LG"], "comment": "IEEE PIMRC conference, 6 pages, 6 figures", "summary": "Cell-free Integrated Sensing and Communication (ISAC) aims to revolutionize\n6th Generation (6G) networks. By combining distributed access points with ISAC\ncapabilities, it boosts spectral efficiency, situational awareness, and\ncommunication reliability. Channel estimation is a critical step in cell-free\nISAC systems to ensure reliable communication, but its performance is usually\nlimited by challenges such as pilot contamination and noisy channel estimates.\nThis paper presents a novel framework leveraging sensing information as a key\ninput within a Conditional Denoising Diffusion Model (CDDM). In this framework,\nwe integrate CDDM with a Multimodal Transformer (MMT) to enhance channel\nestimation in ISAC-enabled cell-free systems. The MMT encoder effectively\ncaptures inter-modal relationships between sensing and location data, enabling\nthe CDDM to iteratively denoise and refine channel estimates. Simulation\nresults demonstrate that the proposed approach achieves significant performance\ngains. As compared with Least Squares (LS) and Minimum Mean Squared Error\n(MMSE) estimators, the proposed model achieves normalized mean squared error\n(NMSE) improvements of 8 dB and 9 dB, respectively. Moreover, we achieve a\n27.8% NMSE improvement compared to the traditional denoising diffusion model\n(TDDM), which does not incorporate sensing channel information. Additionally,\nthe model exhibits higher robustness against pilot contamination and maintains\nhigh accuracy under challenging conditions, such as low signal-to-noise ratios\n(SNRs). According to the simulation results, the model performs well for users\nnear sensing targets by leveraging the correlation between sensing and\ncommunication channels.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6761\u4ef6\u53bb\u566a\u6269\u6563\u6a21\u578b\uff08CDDM\uff09\u548c\u591a\u6a21\u6001\u53d8\u6362\u5668\uff08MMT\uff09\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u5347\u65e0\u8702\u7a9d\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\uff08ISAC\uff09\u7cfb\u7edf\u4e2d\u7684\u4fe1\u9053\u4f30\u8ba1\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u65e0\u8702\u7a9dISAC\u7cfb\u7edf\u4e2d\u4fe1\u9053\u4f30\u8ba1\u9762\u4e34\u7684\u5bfc\u9891\u6c61\u67d3\u548c\u566a\u58f0\u4fe1\u9053\u4f30\u8ba1\u7b49\u6311\u6218\uff0c\u63d0\u5347\u901a\u4fe1\u53ef\u9760\u6027\u3002", "method": "\u7ed3\u5408CDDM\u548cMMT\uff0c\u5229\u7528\u611f\u77e5\u4fe1\u606f\u4f5c\u4e3a\u8f93\u5165\uff0c\u901a\u8fc7MMT\u6355\u6349\u611f\u77e5\u4e0e\u4f4d\u7f6e\u6570\u636e\u7684\u6a21\u6001\u95f4\u5173\u7cfb\uff0cCDDM\u8fed\u4ee3\u53bb\u566a\u548c\u4f18\u5316\u4fe1\u9053\u4f30\u8ba1\u3002", "result": "\u76f8\u6bd4LS\u548cMMSE\u4f30\u8ba1\u5668\uff0cNMSE\u5206\u522b\u63d0\u53478 dB\u548c9 dB\uff1b\u76f8\u6bd4\u4f20\u7edf\u53bb\u566a\u6269\u6563\u6a21\u578b\uff08TDDM\uff09\uff0cNMSE\u63d0\u534727.8%\uff0c\u4e14\u5728\u4f4e\u4fe1\u566a\u6bd4\u548c\u5bfc\u9891\u6c61\u67d3\u4e0b\u8868\u73b0\u7a33\u5065\u3002", "conclusion": "\u8be5\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u4fe1\u9053\u4f30\u8ba1\u6027\u80fd\uff0c\u5c24\u5176\u5728\u611f\u77e5\u76ee\u6807\u9644\u8fd1\u7528\u6237\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u9a8c\u8bc1\u4e86\u611f\u77e5\u4e0e\u901a\u4fe1\u4fe1\u9053\u76f8\u5173\u6027\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2506.06944", "pdf": "https://arxiv.org/pdf/2506.06944", "abs": "https://arxiv.org/abs/2506.06944", "authors": ["Mellon M. Zhang", "Glen Chou", "Saibal Mukhopadhyay"], "title": "Polar Hierarchical Mamba: Towards Streaming LiDAR Object Detection with Point Clouds as Egocentric Sequences", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Accurate and efficient object detection is essential for autonomous vehicles,\nwhere real-time perception requires low latency and high throughput. LiDAR\nsensors provide robust depth information, but conventional methods process full\n360{\\deg} scans in a single pass, introducing significant delay. Streaming\napproaches address this by sequentially processing partial scans in the native\npolar coordinate system, yet they rely on translation-invariant convolutions\nthat are misaligned with polar geometry -- resulting in degraded performance or\nrequiring complex distortion mitigation. Recent Mamba-based state space models\n(SSMs) have shown promise for LiDAR perception, but only in the full-scan\nsetting, relying on geometric serialization and positional embeddings that are\nmemory-intensive and ill-suited to streaming. We propose Polar Hierarchical\nMamba (PHiM), a novel SSM architecture designed for polar-coordinate streaming\nLiDAR. PHiM uses local bidirectional Mamba blocks for intra-sector spatial\nencoding and a global forward Mamba for inter-sector temporal modeling,\nreplacing convolutions and positional encodings with distortion-aware,\ndimensionally-decomposed operations. PHiM sets a new state-of-the-art among\nstreaming detectors on the Waymo Open Dataset, outperforming the previous best\nby 10\\% and matching full-scan baselines at twice the throughput. Code will be\navailable at https://github.com/meilongzhang/Polar-Hierarchical-Mamba .", "AI": {"tldr": "PHiM\u662f\u4e00\u79cd\u65b0\u578b\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u67b6\u6784\uff0c\u4e13\u4e3a\u6781\u5750\u6807\u6d41\u5f0fLiDAR\u8bbe\u8ba1\uff0c\u901a\u8fc7\u5c40\u90e8\u53cc\u5411Mamba\u5757\u548c\u5168\u5c40\u524d\u5411Mamba\u5757\u5b9e\u73b0\u9ad8\u6548\u68c0\u6d4b\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u6d41\u5f0f\u68c0\u6d4b\u5668\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u9700\u8981\u4f4e\u5ef6\u8fdf\u3001\u9ad8\u541e\u5410\u91cf\u7684\u5b9e\u65f6\u611f\u77e5\uff0c\u4f20\u7edf\u65b9\u6cd5\u5904\u7406\u5168\u626b\u63cfLiDAR\u6570\u636e\u65f6\u5ef6\u8fdf\u9ad8\uff0c\u6d41\u5f0f\u65b9\u6cd5\u867d\u80fd\u7f13\u89e3\u4f46\u53d7\u9650\u4e8e\u6781\u5750\u6807\u51e0\u4f55\u4e0d\u5339\u914d\u95ee\u9898\u3002", "method": "PHiM\u91c7\u7528\u5c40\u90e8\u53cc\u5411Mamba\u5757\u8fdb\u884c\u6247\u533a\u5185\u7a7a\u95f4\u7f16\u7801\uff0c\u5168\u5c40\u524d\u5411Mamba\u5757\u8fdb\u884c\u6247\u533a\u95f4\u65f6\u5e8f\u5efa\u6a21\uff0c\u907f\u514d\u5377\u79ef\u548c\u4f4d\u7f6e\u7f16\u7801\uff0c\u5b9e\u73b0\u9ad8\u6548\u6781\u5750\u6807\u6d41\u5f0f\u5904\u7406\u3002", "result": "PHiM\u5728Waymo Open Dataset\u4e0a\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u6d41\u5f0f\u68c0\u6d4b\u566810%\uff0c\u4e14\u541e\u5410\u91cf\u7ffb\u500d\uff0c\u8fbe\u5230\u5168\u626b\u63cf\u57fa\u7ebf\u6c34\u5e73\u3002", "conclusion": "PHiM\u4e3a\u6781\u5750\u6807\u6d41\u5f0fLiDAR\u68c0\u6d4b\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u6027\u80fd\u663e\u8457\u63d0\u5347\uff0c\u9002\u7528\u4e8e\u81ea\u52a8\u9a7e\u9a76\u5b9e\u65f6\u611f\u77e5\u3002"}}
{"id": "2506.06946", "pdf": "https://arxiv.org/pdf/2506.06946", "abs": "https://arxiv.org/abs/2506.06946", "authors": ["Daniel Lawand", "Lucas Quaresma", "Roberto Bolgheroni", "Alfredo Goldman", "Renato Cordeiro Ferreira"], "title": "Is Your Training Pipeline Production-Ready? A Case Study in the Healthcare Domain", "categories": ["cs.SE", "cs.AI", "cs.LG", "D.2.11; D.2.7; I.2.7; I.5.4"], "comment": "9 pages, 3 figures (2 diagrams, 1 code listing), submitted to the\n  workshop SADIS 2025", "summary": "Deploying a Machine Learning (ML) training pipeline into production requires\nrobust software engineering practices. This differs significantly from\nexperimental workflows. This experience report investigates this challenge in\nSPIRA, a project whose goal is to create an ML-Enabled System (MLES) to\npre-diagnose insufficiency respiratory via speech analysis. The first version\nof SPIRA's training pipeline lacked critical software quality attributes. This\npaper presents an overview of the MLES, then compares three versions of the\narchitecture of the Continuous Training subsystem, which evolved from a Big\nBall of Mud, to a Modular Monolith, towards Microservices. By adopting\ndifferent design principles and patterns to enhance its maintainability,\nrobustness, and extensibility. In this way, the paper seeks to offer insights\nfor both ML Engineers tasked to productionize ML training pipelines and Data\nScientists seeking to adopt MLOps practices.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5c06\u673a\u5668\u5b66\u4e60\u8bad\u7ec3\u7ba1\u9053\u90e8\u7f72\u5230\u751f\u4ea7\u73af\u5883\u4e2d\u7684\u6311\u6218\uff0c\u4ee5SPIRA\u9879\u76ee\u4e3a\u4f8b\uff0c\u6bd4\u8f83\u4e86\u4e09\u79cd\u67b6\u6784\u7248\u672c\uff0c\u4ece\u6df7\u4e71\u5230\u6a21\u5757\u5316\u518d\u5230\u5fae\u670d\u52a1\uff0c\u4ee5\u63d0\u9ad8\u53ef\u7ef4\u62a4\u6027\u548c\u6269\u5c55\u6027\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u6539\u8fdb\u67b6\u6784\u8bbe\u8ba1\u539f\u5219\u548c\u6a21\u5f0f\uff0c\u63d0\u5347\u673a\u5668\u5b66\u4e60\u8bad\u7ec3\u7ba1\u9053\u7684\u8f6f\u4ef6\u8d28\u91cf\u5c5e\u6027\uff08\u5982\u53ef\u7ef4\u62a4\u6027\u3001\u5065\u58ee\u6027\u548c\u6269\u5c55\u6027\uff09\u3002", "method": "\u901a\u8fc7SPIRA\u9879\u76ee\uff0c\u6bd4\u8f83\u4e86\u4e09\u79cd\u67b6\u6784\u7248\u672c\uff08Big Ball of Mud\u3001Modular Monolith\u3001Microservices\uff09\uff0c\u5206\u6790\u5176\u8bbe\u8ba1\u539f\u5219\u548c\u6a21\u5f0f\u7684\u5e94\u7528\u3002", "result": "\u5c55\u793a\u4e86\u67b6\u6784\u6f14\u5316\u7684\u8fc7\u7a0b\uff0c\u8bc1\u660e\u4e86\u91c7\u7528\u6a21\u5757\u5316\u548c\u5fae\u670d\u52a1\u67b6\u6784\u80fd\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u7684\u53ef\u7ef4\u62a4\u6027\u548c\u6269\u5c55\u6027\u3002", "conclusion": "\u4e3aML\u5de5\u7a0b\u5e08\u548c\u6570\u636e\u79d1\u5b66\u5bb6\u63d0\u4f9b\u4e86\u5c06ML\u8bad\u7ec3\u7ba1\u9053\u751f\u4ea7\u5316\u548c\u91c7\u7528MLOps\u5b9e\u8df5\u7684\u5b9e\u7528\u89c1\u89e3\u3002"}}
{"id": "2506.06964", "pdf": "https://arxiv.org/pdf/2506.06964", "abs": "https://arxiv.org/abs/2506.06964", "authors": ["Subhojyoti Mukherjee", "Viet Dac Lai", "Raghavendra Addanki", "Ryan Rossi", "Seunghyun Yoon", "Trung Bui", "Anup Rao", "Jayakumar Subramanian", "Branislav Kveton"], "title": "Learning to Clarify by Reinforcement Learning Through Reward-Weighted Fine-Tuning", "categories": ["cs.CL", "cs.LG"], "comment": "39 pages", "summary": "Question answering (QA) agents automatically answer questions posed in\nnatural language. In this work, we learn to ask clarifying questions in QA\nagents. The key idea in our method is to simulate conversations that contain\nclarifying questions and learn from them using reinforcement learning (RL). To\nmake RL practical, we propose and analyze offline RL objectives that can be\nviewed as reward-weighted supervised fine-tuning (SFT) and easily optimized in\nlarge language models. Our work stands in a stark contrast to recently proposed\nmethods, based on SFT and direct preference optimization, which have additional\nhyper-parameters and do not directly optimize rewards. We compare to these\nmethods empirically and report gains in both optimized rewards and language\nquality.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u8bad\u7ec3\u95ee\u7b54\uff08QA\uff09\u4ee3\u7406\u4ee5\u63d0\u51fa\u6f84\u6e05\u95ee\u9898\u7684\u65b9\u6cd5\uff0c\u5e76\u5206\u6790\u4e86\u79bb\u7ebfRL\u76ee\u6807\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\u5728\u5956\u52b1\u548c\u8bed\u8a00\u8d28\u91cf\u4e0a\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u73b0\u6709\u7684\u95ee\u7b54\u4ee3\u7406\u901a\u5e38\u76f4\u63a5\u56de\u7b54\u95ee\u9898\uff0c\u800c\u7f3a\u4e4f\u63d0\u51fa\u6f84\u6e05\u95ee\u9898\u7684\u80fd\u529b\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u6a21\u62df\u5bf9\u8bdd\u5e76\u4f18\u5316\u4ee3\u7406\u7684\u8868\u73b0\u3002", "method": "\u91c7\u7528\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u6a21\u62df\u5305\u542b\u6f84\u6e05\u95ee\u9898\u7684\u5bf9\u8bdd\uff0c\u5e76\u63d0\u51fa\u79bb\u7ebfRL\u76ee\u6807\uff08\u5956\u52b1\u52a0\u6743\u7684\u76d1\u7763\u5fae\u8c03\uff09\uff0c\u4ee5\u4f18\u5316\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u4e0e\u57fa\u4e8e\u76d1\u7763\u5fae\u8c03\u548c\u76f4\u63a5\u504f\u597d\u4f18\u5316\u7684\u65b9\u6cd5\u76f8\u6bd4\uff0c\u672c\u6587\u65b9\u6cd5\u5728\u5956\u52b1\u548c\u8bed\u8a00\u8d28\u91cf\u4e0a\u5747\u53d6\u5f97\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u901a\u8fc7\u79bb\u7ebfRL\u76ee\u6807\u4f18\u5316\u95ee\u7b54\u4ee3\u7406\uff0c\u80fd\u591f\u6709\u6548\u63d0\u5347\u5176\u63d0\u51fa\u6f84\u6e05\u95ee\u9898\u7684\u80fd\u529b\uff0c\u5e76\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u66f4\u4f18\u3002"}}
{"id": "2506.06981", "pdf": "https://arxiv.org/pdf/2506.06981", "abs": "https://arxiv.org/abs/2506.06981", "authors": ["Riley Simmons-Edler", "Ryan P. Badman", "Felix Baastad Berg", "Raymond Chua", "John J. Vastola", "Joshua Lunger", "William Qian", "Kanaka Rajan"], "title": "Deep RL Needs Deep Behavior Analysis: Exploring Implicit Planning by Model-Free Agents in Open-Ended Environments", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Understanding the behavior of deep reinforcement learning (DRL) agents --\nparticularly as task and agent sophistication increase -- requires more than\nsimple comparison of reward curves, yet standard methods for behavioral\nanalysis remain underdeveloped in DRL. We apply tools from neuroscience and\nethology to study DRL agents in a novel, complex, partially observable\nenvironment, ForageWorld, designed to capture key aspects of real-world animal\nforaging -- including sparse, depleting resource patches, predator threats, and\nspatially extended arenas. We use this environment as a platform for applying\njoint behavioral and neural analysis to agents, revealing detailed,\nquantitatively grounded insights into agent strategies, memory, and planning.\nContrary to common assumptions, we find that model-free RNN-based DRL agents\ncan exhibit structured, planning-like behavior purely through emergent dynamics\n-- without requiring explicit memory modules or world models. Our results show\nthat studying DRL agents like animals -- analyzing them with\nneuroethology-inspired tools that reveal structure in both behavior and neural\ndynamics -- uncovers rich structure in their learning dynamics that would\notherwise remain invisible. We distill these tools into a general analysis\nframework linking core behavioral and representational features to diagnostic\nmethods, which can be reused for a wide range of tasks and agents. As agents\ngrow more complex and autonomous, bridging neuroscience, cognitive science, and\nAI will be essential -- not just for understanding their behavior, but for\nensuring safe alignment and maximizing desirable behaviors that are hard to\nmeasure via reward. We show how this can be done by drawing on lessons from how\nbiological intelligence is studied.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u795e\u7ecf\u79d1\u5b66\u548c\u52a8\u7269\u884c\u4e3a\u5b66\u5de5\u5177\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5206\u6790\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u4ee3\u7406\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u884c\u4e3a\uff0c\u63ed\u793a\u4e86\u5176\u7b56\u7565\u548c\u8bb0\u5fc6\u7684\u4e30\u5bcc\u7ed3\u6784\u3002", "motivation": "\u5f53\u524dDRL\u4ee3\u7406\u7684\u884c\u4e3a\u5206\u6790\u65b9\u6cd5\u4e0d\u8db3\uff0c\u5c24\u5176\u662f\u5728\u4efb\u52a1\u548c\u4ee3\u7406\u590d\u6742\u6027\u589e\u52a0\u65f6\uff0c\u9700\u8981\u66f4\u6df1\u5165\u7684\u5de5\u5177\u6765\u7406\u89e3\u5176\u884c\u4e3a\u3002", "method": "\u5728ForageWorld\u73af\u5883\u4e2d\uff0c\u7ed3\u5408\u795e\u7ecf\u79d1\u5b66\u548c\u52a8\u7269\u884c\u4e3a\u5b66\u7684\u5de5\u5177\uff0c\u5bf9DRL\u4ee3\u7406\u8fdb\u884c\u884c\u4e3a\u548c\u795e\u7ecf\u52a8\u6001\u5206\u6790\u3002", "result": "\u53d1\u73b0\u57fa\u4e8eRNN\u7684\u6a21\u578b\u65e0\u5173DRL\u4ee3\u7406\u53ef\u4ee5\u8868\u73b0\u51fa\u7c7b\u4f3c\u89c4\u5212\u7684\u884c\u4e3a\uff0c\u65e0\u9700\u663e\u5f0f\u8bb0\u5fc6\u6a21\u5757\u6216\u4e16\u754c\u6a21\u578b\u3002", "conclusion": "\u901a\u8fc7\u501f\u9274\u751f\u7269\u667a\u80fd\u7814\u7a76\u65b9\u6cd5\uff0c\u53ef\u4ee5\u63ed\u793aDRL\u4ee3\u7406\u7684\u590d\u6742\u5b66\u4e60\u52a8\u6001\uff0c\u5e76\u4e3a\u672a\u6765\u590d\u6742\u4ee3\u7406\u7684\u884c\u4e3a\u5206\u6790\u548c\u5b89\u5168\u5bf9\u9f50\u63d0\u4f9b\u6846\u67b6\u3002"}}
{"id": "2506.06989", "pdf": "https://arxiv.org/pdf/2506.06989", "abs": "https://arxiv.org/abs/2506.06989", "authors": ["Md Aminul Islam", "Kathryn Vasilaky", "Elena Zheleva"], "title": "Correcting for Position Bias in Learning to Rank: A Control Function Approach", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "Implicit feedback data, such as user clicks, is commonly used in\nlearning-to-rank (LTR) systems because it is easy to collect and it often\nreflects user preferences. However, this data is prone to various biases, and\ntraining an LTR system directly on biased data can result in suboptimal ranking\nperformance. One of the most prominent and well-studied biases in implicit\nfeedback data is position bias, which occurs because users are more likely to\ninteract with higher-ranked documents regardless of their true relevance. In\nthis paper, we propose a novel control function-based method that accounts for\nposition bias in a two-stage process. The first stage uses exogenous variation\nfrom the residuals of the ranking process to correct for position bias in the\nsecond stage click equation. Unlike previous position bias correction methods,\nour method does not require knowledge of the click or propensity model and\nallows for nonlinearity in the underlying ranking model. Moreover, our method\nis general and allows for debiasing any state-of-the-art ranking algorithm by\nplugging it into the second stage. We also introduce a technique to debias\nvalidation clicks for hyperparameter tuning to select the optimal model in the\nabsence of unbiased validation data. Experimental results demonstrate that our\nmethod outperforms state-of-the-art approaches in correcting for position bias.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u63a7\u5236\u51fd\u6570\u7684\u4e24\u9636\u6bb5\u65b9\u6cd5\uff0c\u7528\u4e8e\u7ea0\u6b63\u9690\u5f0f\u53cd\u9988\u6570\u636e\u4e2d\u7684\u4f4d\u7f6e\u504f\u5dee\uff0c\u65e0\u9700\u70b9\u51fb\u6216\u503e\u5411\u6a21\u578b\u77e5\u8bc6\uff0c\u4e14\u9002\u7528\u4e8e\u975e\u7ebf\u6027\u6392\u540d\u6a21\u578b\u3002", "motivation": "\u9690\u5f0f\u53cd\u9988\u6570\u636e\uff08\u5982\u7528\u6237\u70b9\u51fb\uff09\u5b58\u5728\u4f4d\u7f6e\u504f\u5dee\uff0c\u76f4\u63a5\u7528\u4e8e\u5b66\u4e60\u6392\u540d\u7cfb\u7edf\u4f1a\u5bfc\u81f4\u6027\u80fd\u4e0d\u4f73\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u8fc7\u7a0b\uff0c\u7b2c\u4e00\u9636\u6bb5\u5229\u7528\u6392\u540d\u8fc7\u7a0b\u7684\u6b8b\u5dee\u5916\u751f\u53d8\u91cf\u7ea0\u6b63\u7b2c\u4e8c\u9636\u6bb5\u70b9\u51fb\u65b9\u7a0b\u4e2d\u7684\u4f4d\u7f6e\u504f\u5dee\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u7ea0\u6b63\u4f4d\u7f6e\u504f\u5dee\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u7528\u6027\u5f3a\uff0c\u53ef\u5e94\u7528\u4e8e\u4efb\u4f55\u5148\u8fdb\u6392\u540d\u7b97\u6cd5\uff0c\u4e14\u65e0\u9700\u65e0\u504f\u9a8c\u8bc1\u6570\u636e\u5373\u53ef\u4f18\u5316\u6a21\u578b\u3002"}}
{"id": "2506.06998", "pdf": "https://arxiv.org/pdf/2506.06998", "abs": "https://arxiv.org/abs/2506.06998", "authors": ["Ming Li", "Zhengyuan Yang", "Xiyao Wang", "Dianqi Li", "Kevin Lin", "Tianyi Zhou", "Lijuan Wang"], "title": "What makes Reasoning Models Different? Follow the Reasoning Leader for Efficient Decoding", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large reasoning models (LRMs) achieve strong reasoning performance by\nemitting long chains of thought. Yet, these verbose traces slow down inference\nand often drift into unnecessary detail, known as the overthinking phenomenon.\nTo better understand LRMs' behavior, we systematically analyze the token-level\nmisalignment between reasoning and non-reasoning models. While it is expected\nthat their primary difference lies in the stylistic \"thinking cues\", LRMs\nuniquely exhibit two pivotal, previously under-explored phenomena: a Global\nMisalignment Rebound, where their divergence from non-reasoning models persists\nor even grows as response length increases, and more critically, a Local\nMisalignment Diminish, where the misalignment concentrates at the \"thinking\ncues\" each sentence starts with but rapidly declines in the remaining of the\nsentence. Motivated by the Local Misalignment Diminish, we propose\nFoReaL-Decoding, a collaborative fast-slow thinking decoding method for\ncost-quality trade-off. In FoReaL-Decoding, a Leading model leads the first few\ntokens for each sentence, and then a weaker draft model completes the following\ntokens to the end of each sentence. FoReaL-Decoding adopts a stochastic gate to\nsmoothly interpolate between the small and the large model. On four popular\nmath-reasoning benchmarks (AIME24, GPQA-Diamond, MATH500, AMC23),\nFoReaL-Decoding reduces theoretical FLOPs by 30 to 50% and trims CoT length by\nup to 40%, while preserving 86 to 100% of model performance. These results\nestablish FoReaL-Decoding as a simple, plug-and-play route to controllable\ncost-quality trade-offs in reasoning-centric tasks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faFoReaL-Decoding\u65b9\u6cd5\uff0c\u901a\u8fc7\u5feb\u901f-\u6162\u901f\u534f\u4f5c\u89e3\u7801\u4f18\u5316\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u6548\u7387\uff0c\u51cf\u5c11\u8ba1\u7b97\u6210\u672c\u5e76\u4fdd\u6301\u6027\u80fd\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u5b58\u5728\u8fc7\u5ea6\u601d\u8003\u73b0\u8c61\uff0c\u5bfc\u81f4\u63a8\u7406\u901f\u5ea6\u6162\u4e14\u5197\u4f59\u3002\u7814\u7a76\u65e8\u5728\u5206\u6790\u5176\u4e0e\u975e\u63a8\u7406\u6a21\u578b\u7684\u5dee\u5f02\uff0c\u5e76\u63d0\u51fa\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faFoReaL-Decoding\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e3b\u5bfc\u6a21\u578b\u548c\u8349\u7a3f\u6a21\u578b\u534f\u4f5c\u89e3\u7801\uff0c\u901a\u8fc7\u968f\u673a\u95e8\u5e73\u6ed1\u5207\u6362\u6a21\u578b\uff0c\u51cf\u5c11\u8ba1\u7b97\u91cf\u3002", "result": "\u5728\u56db\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cFoReaL-Decoding\u51cf\u5c1130-50%\u8ba1\u7b97\u91cf\uff0c\u7f29\u77ed\u63a8\u7406\u94fe40%\uff0c\u540c\u65f6\u4fdd\u630186-100%\u6027\u80fd\u3002", "conclusion": "FoReaL-Decoding\u662f\u4e00\u79cd\u7b80\u5355\u3001\u5373\u63d2\u5373\u7528\u7684\u65b9\u6cd5\uff0c\u53ef\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u5b9e\u73b0\u6210\u672c\u4e0e\u6027\u80fd\u7684\u53ef\u63a7\u6743\u8861\u3002"}}
{"id": "2506.07011", "pdf": "https://arxiv.org/pdf/2506.07011", "abs": "https://arxiv.org/abs/2506.07011", "authors": ["Yuan-Hao Wei", "Yan-Jie Sun"], "title": "Half-AVAE: Adversarial-Enhanced Factorized and Structured Encoder-Free VAE for Underdetermined Independent Component Analysis", "categories": ["stat.ML", "cs.LG", "eess.SP"], "comment": null, "summary": "This study advances the Variational Autoencoder (VAE) framework by addressing\nchallenges in Independent Component Analysis (ICA) under both determined and\nunderdetermined conditions, focusing on enhancing the independence and\ninterpretability of latent variables. Traditional VAEs map observed data to\nlatent variables and back via an encoder-decoder architecture, but struggle\nwith underdetermined ICA where the number of latent variables exceeds observed\nsignals. The proposed Half Adversarial VAE (Half-AVAE) builds on the\nencoder-free Half-VAE framework, eliminating explicit inverse mapping to tackle\nunderdetermined scenarios. By integrating adversarial networks and External\nEnhancement (EE) terms, Half-AVAE promotes mutual independence among latent\ndimensions, achieving factorized and interpretable representations. Experiments\nwith synthetic signals demonstrate that Half-AVAE outperforms baseline models,\nincluding GP-AVAE and Half-VAE, in recovering independent components under\nunderdetermined conditions, as evidenced by lower root mean square errors. The\nstudy highlights the flexibility of VAEs in variational inference, showing that\nencoder omission, combined with adversarial training and structured priors,\nenables effective solutions for complex ICA tasks, advancing applications in\ndisentanglement, causal inference, and generative modeling.", "AI": {"tldr": "Half-AVAE\u6539\u8fdbVAE\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6297\u7f51\u7edc\u548c\u5916\u90e8\u589e\u5f3a\u9879\u89e3\u51b3\u6b20\u5b9aICA\u95ee\u9898\uff0c\u63d0\u5347\u6f5c\u5728\u53d8\u91cf\u7684\u72ec\u7acb\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u4f20\u7edfVAE\u5728\u6b20\u5b9aICA\uff08\u6f5c\u5728\u53d8\u91cf\u591a\u4e8e\u89c2\u6d4b\u4fe1\u53f7\uff09\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u6539\u8fdb\u4ee5\u589e\u5f3a\u6f5c\u5728\u53d8\u91cf\u7684\u72ec\u7acb\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u63d0\u51faHalf-AVAE\uff0c\u57fa\u4e8e\u65e0\u7f16\u7801\u5668\u7684Half-VAE\u6846\u67b6\uff0c\u7ed3\u5408\u5bf9\u6297\u7f51\u7edc\u548c\u5916\u90e8\u589e\u5f3a\u9879\uff0c\u6d88\u9664\u663e\u5f0f\u9006\u6620\u5c04\u3002", "result": "\u5b9e\u9a8c\u663e\u793aHalf-AVAE\u5728\u6b20\u5b9a\u6761\u4ef6\u4e0b\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff08\u5982GP-AVAE\u548cHalf-VAE\uff09\uff0c\u5747\u65b9\u6839\u8bef\u5dee\u66f4\u4f4e\u3002", "conclusion": "Half-AVAE\u5c55\u793a\u4e86VAE\u5728\u53d8\u5206\u63a8\u65ad\u4e2d\u7684\u7075\u6d3b\u6027\uff0c\u4e3a\u590d\u6742ICA\u4efb\u52a1\u63d0\u4f9b\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u63a8\u52a8\u89e3\u8026\u3001\u56e0\u679c\u63a8\u65ad\u548c\u751f\u6210\u5efa\u6a21\u7684\u5e94\u7528\u3002"}}
{"id": "2506.07015", "pdf": "https://arxiv.org/pdf/2506.07015", "abs": "https://arxiv.org/abs/2506.07015", "authors": ["Qiyu Hou", "Jun Wang"], "title": "TABLET: Table Structure Recognition using Encoder-only Transformers", "categories": ["cs.CV", "cs.LG"], "comment": "ICDAR 2025", "summary": "To address the challenges of table structure recognition, we propose a novel\nSplit-Merge-based top-down model optimized for large, densely populated tables.\nOur approach formulates row and column splitting as sequence labeling tasks,\nutilizing dual Transformer encoders to capture feature interactions. The\nmerging process is framed as a grid cell classification task, leveraging an\nadditional Transformer encoder to ensure accurate and coherent merging. By\neliminating unstable bounding box predictions, our method reduces resolution\nloss and computational complexity, achieving high accuracy while maintaining\nfast processing speed. Extensive experiments on FinTabNet and PubTabNet\ndemonstrate the superiority of our model over existing approaches, particularly\nin real-world applications. Our method offers a robust, scalable, and efficient\nsolution for large-scale table recognition, making it well-suited for\nindustrial deployment.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eSplit-Merge\u7684\u8868\u683c\u7ed3\u6784\u8bc6\u522b\u65b9\u6cd5\uff0c\u901a\u8fc7\u53ccTransformer\u7f16\u7801\u5668\u4f18\u5316\u884c\u548c\u5217\u7684\u5206\u5272\uff0c\u5e76\u5229\u7528\u989d\u5916\u7f16\u7801\u5668\u786e\u4fdd\u5408\u5e76\u51c6\u786e\u6027\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u9ad8\u7cbe\u5ea6\u7684\u8868\u683c\u8bc6\u522b\u3002", "motivation": "\u89e3\u51b3\u5927\u578b\u5bc6\u96c6\u8868\u683c\u7ed3\u6784\u8bc6\u522b\u7684\u6311\u6218\uff0c\u63d0\u4f9b\u4e00\u79cd\u7a33\u5b9a\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5c06\u884c\u548c\u5217\u5206\u5272\u4efb\u52a1\u5efa\u6a21\u4e3a\u5e8f\u5217\u6807\u6ce8\u95ee\u9898\uff0c\u4f7f\u7528\u53ccTransformer\u7f16\u7801\u5668\uff1b\u5408\u5e76\u4efb\u52a1\u5efa\u6a21\u4e3a\u7f51\u683c\u5206\u7c7b\u95ee\u9898\uff0c\u4f7f\u7528\u989d\u5916Transformer\u7f16\u7801\u5668\u3002", "result": "\u5728FinTabNet\u548cPubTabNet\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u51cf\u5c11\u4e86\u5206\u8fa8\u7387\u635f\u5931\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u4fdd\u6301\u4e86\u9ad8\u7cbe\u5ea6\u548c\u5feb\u901f\u5904\u7406\u901f\u5ea6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5927\u89c4\u6a21\u8868\u683c\u8bc6\u522b\u63d0\u4f9b\u4e86\u9c81\u68d2\u3001\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u5408\u5de5\u4e1a\u90e8\u7f72\u3002"}}
{"id": "2506.07056", "pdf": "https://arxiv.org/pdf/2506.07056", "abs": "https://arxiv.org/abs/2506.07056", "authors": ["Zhenyu Liu", "Huizhi Liang", "Rajiv Ranjan", "Zhanxing Zhu", "Vaclav Snasel", "Varun Ojha"], "title": "D2R: dual regularization loss with collaborative adversarial generation for model robustness", "categories": ["cs.CV", "cs.CR", "cs.LG"], "comment": null, "summary": "The robustness of Deep Neural Network models is crucial for defending models\nagainst adversarial attacks. Recent defense methods have employed collaborative\nlearning frameworks to enhance model robustness. Two key limitations of\nexisting methods are (i) insufficient guidance of the target model via loss\nfunctions and (ii) non-collaborative adversarial generation. We, therefore,\npropose a dual regularization loss (D2R Loss) method and a collaborative\nadversarial generation (CAG) strategy for adversarial training. D2R loss\nincludes two optimization steps. The adversarial distribution and clean\ndistribution optimizations enhance the target model's robustness by leveraging\nthe strengths of different loss functions obtained via a suitable function\nspace exploration to focus more precisely on the target model's distribution.\nCAG generates adversarial samples using a gradient-based collaboration between\nguidance and target models. We conducted extensive experiments on three\nbenchmark databases, including CIFAR-10, CIFAR-100, Tiny ImageNet, and two\npopular target models, WideResNet34-10 and PreActResNet18. Our results show\nthat D2R loss with CAG produces highly robust models.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u6b63\u5219\u5316\u635f\u5931\uff08D2R Loss\uff09\u548c\u534f\u4f5c\u5bf9\u6297\u751f\u6210\uff08CAG\uff09\u7b56\u7565\uff0c\u901a\u8fc7\u4f18\u5316\u5bf9\u6297\u5206\u5e03\u548c\u5e72\u51c0\u5206\u5e03\uff0c\u63d0\u5347\u76ee\u6807\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u76ee\u6807\u6a21\u578b\u635f\u5931\u51fd\u6570\u5f15\u5bfc\u4e0d\u8db3\u548c\u975e\u534f\u4f5c\u5bf9\u6297\u751f\u6210\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u6539\u8fdb\u4ee5\u589e\u5f3a\u6a21\u578b\u5bf9\u6297\u653b\u51fb\u7684\u9632\u5fa1\u80fd\u529b\u3002", "method": "\u91c7\u7528D2R Loss\uff08\u53cc\u4f18\u5316\u6b65\u9aa4\uff09\u548cCAG\uff08\u68af\u5ea6\u534f\u4f5c\u751f\u6210\u5bf9\u6297\u6837\u672c\uff09\uff0c\u7ed3\u5408\u4e0d\u540c\u635f\u5931\u51fd\u6570\u4f18\u5316\u76ee\u6807\u6a21\u578b\u5206\u5e03\u3002", "result": "\u5728CIFAR-10\u3001CIFAR-100\u3001Tiny ImageNet\u7b49\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0cD2R Loss\u4e0eCAG\u80fd\u663e\u8457\u63d0\u5347\u6a21\u578b\u9c81\u68d2\u6027\u3002", "conclusion": "D2R Loss\u548cCAG\u7b56\u7565\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u4e0d\u8db3\uff0c\u663e\u8457\u589e\u5f3a\u4e86\u6a21\u578b\u5bf9\u6297\u653b\u51fb\u7684\u9632\u5fa1\u80fd\u529b\u3002"}}
{"id": "2506.07069", "pdf": "https://arxiv.org/pdf/2506.07069", "abs": "https://arxiv.org/abs/2506.07069", "authors": ["Zhican Wang", "Guanghui He", "Dantong Liu", "Lingjun Gao", "Shell Xu Hu", "Chen Zhang", "Zhuoran Song", "Nicholas Lane", "Wayne Luk", "Hongxiang Fan"], "title": "Accelerating 3D Gaussian Splatting with Neural Sorting and Axis-Oriented Rasterization", "categories": ["cs.GR", "cs.AR", "cs.CV", "cs.LG"], "comment": "Preprint. Under review", "summary": "3D Gaussian Splatting (3DGS) has recently gained significant attention for\nhigh-quality and efficient view synthesis, making it widely adopted in fields\nsuch as AR/VR, robotics, and autonomous driving. Despite its impressive\nalgorithmic performance, real-time rendering on resource-constrained devices\nremains a major challenge due to tight power and area budgets. This paper\npresents an architecture-algorithm co-design to address these inefficiencies.\nFirst, we reveal substantial redundancy caused by repeated computation of\ncommon terms/expressions during the conventional rasterization. To resolve\nthis, we propose axis-oriented rasterization, which pre-computes and reuses\nshared terms along both the X and Y axes through a dedicated hardware design,\neffectively reducing multiply-and-add (MAC) operations by up to 63%. Second, by\nidentifying the resource and performance inefficiency of the sorting process,\nwe introduce a novel neural sorting approach that predicts order-independent\nblending weights using an efficient neural network, eliminating the need for\ncostly hardware sorters. A dedicated training framework is also proposed to\nimprove its algorithmic stability. Third, to uniformly support rasterization\nand neural network inference, we design an efficient reconfigurable processing\narray that maximizes hardware utilization and throughput. Furthermore, we\nintroduce a $\\pi$-trajectory tile schedule, inspired by Morton encoding and\nHilbert curve, to optimize Gaussian reuse and reduce memory access overhead.\nComprehensive experiments demonstrate that the proposed design preserves\nrendering quality while achieving a speedup of $23.4\\sim27.8\\times$ and energy\nsavings of $28.8\\sim51.4\\times$ compared to edge GPUs for real-world scenes. We\nplan to open-source our design to foster further development in this field.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u67b6\u6784\u4e0e\u7b97\u6cd5\u534f\u540c\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u8f74\u5b9a\u5411\u5149\u6805\u5316\u3001\u795e\u7ecf\u6392\u5e8f\u548c\u53ef\u91cd\u6784\u5904\u7406\u9635\u5217\uff0c\u663e\u8457\u63d0\u5347\u4e863D\u9ad8\u65af\u6e85\u5c04\uff083DGS\uff09\u5728\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u7684\u5b9e\u65f6\u6e32\u67d3\u6548\u7387\u3002", "motivation": "\u5c3d\u7ba13DGS\u5728\u9ad8\u8d28\u91cf\u89c6\u56fe\u5408\u6210\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u7684\u5b9e\u65f6\u6e32\u67d3\u4ecd\u9762\u4e34\u529f\u8017\u548c\u9762\u79ef\u9650\u5236\u7684\u6311\u6218\u3002", "method": "1. \u8f74\u5b9a\u5411\u5149\u6805\u5316\u51cf\u5c11\u5197\u4f59\u8ba1\u7b97\uff1b2. \u795e\u7ecf\u6392\u5e8f\u66ff\u4ee3\u786c\u4ef6\u6392\u5e8f\u5668\uff1b3. \u53ef\u91cd\u6784\u5904\u7406\u9635\u5217\u652f\u6301\u5149\u6805\u5316\u548c\u795e\u7ecf\u7f51\u7edc\u63a8\u7406\uff1b4. \u03c0\u8f68\u8ff9\u74e6\u7247\u8c03\u5ea6\u4f18\u5316\u5185\u5b58\u8bbf\u95ee\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u76f8\u6bd4\u8fb9\u7f18GPU\uff0c\u8bbe\u8ba1\u5b9e\u73b0\u4e8623.4~27.8\u500d\u7684\u901f\u5ea6\u63d0\u5347\u548c28.8~51.4\u500d\u7684\u80fd\u8017\u8282\u7701\u3002", "conclusion": "\u8be5\u8bbe\u8ba1\u5728\u4fdd\u6301\u6e32\u67d3\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u6548\u7387\u548c\u80fd\u8017\u8868\u73b0\uff0c\u8ba1\u5212\u5f00\u6e90\u4ee5\u63a8\u52a8\u9886\u57df\u53d1\u5c55\u3002"}}
{"id": "2506.07079", "pdf": "https://arxiv.org/pdf/2506.07079", "abs": "https://arxiv.org/abs/2506.07079", "authors": ["Mostafa Eslami", "Maryam Babazadeh"], "title": "On the Generalization of Data-Assisted Control in port-Hamiltonian Systems (DAC-pH)", "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.SY"], "comment": "This paper presents an early investigation of Data-Assisted Control\n  (DAC) with reinforcement learning, showcasing its potential through a simple\n  example. Theoretical analysis is ongoing to establish formal support and\n  guarantees for the proposed approach", "summary": "This paper introduces a hypothetical hybrid control framework for\nport-Hamiltonian (p$\\mathcal{H}$) systems, employing a dynamic decomposition\nbased on Data-Assisted Control (DAC). The system's evolution is split into two\nparts with fixed topology: Right-Hand Side (RHS)- an intrinsic Hamiltonian flow\nhandling worst-case parametric uncertainties, and Left-Hand Side (LHS)- a\ndissipative/input flow addressing both structural and parametric uncertainties.\nA virtual port variable $\\Pi$ serves as the interface between these two\ncomponents. A nonlinear controller manages the intrinsic Hamiltonian flow,\ndetermining a desired port control value $\\Pi_c$. Concurrently, Reinforcement\nLearning (RL) is applied to the dissipative/input flow to learn an agent for\nproviding optimal policy in mapping $\\Pi_c$ to the actual system input. This\nhybrid approach effectively manages RHS uncertainties while preserving the\nsystem's inherent structure. Key advantages include adjustable performance via\nLHS controller parameters, enhanced AI explainability and interpretability\nthrough the port variable $\\Pi$, the ability to guarantee safety and state\nattainability with hard/soft constraints, reduced complexity in learning\nhypothesis classes compared to end-to-end solutions, and improved\nstate/parameter estimation using LHS prior knowledge and system Hamiltonian to\naddress partial observability. The paper details the p$\\mathcal{H}$\nformulation, derives the decomposition, and presents the modular controller\narchitecture. Beyond design, crucial aspects of stability and robustness\nanalysis and synthesis are investigated, paving the way for deeper theoretical\ninvestigations. An application example, a pendulum with nonlinear dynamics, is\nsimulated to demonstrate the approach's empirical and phenomenological benefits\nfor future research.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6570\u636e\u8f85\u52a9\u63a7\u5236\uff08DAC\uff09\u7684\u6df7\u5408\u63a7\u5236\u6846\u67b6\uff0c\u7528\u4e8e\u7aef\u53e3\u54c8\u5bc6\u987f\u7cfb\u7edf\uff0c\u901a\u8fc7\u52a8\u6001\u5206\u89e3\u5c06\u7cfb\u7edf\u5206\u4e3a\u4e24\u90e8\u5206\u5904\u7406\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u7ed3\u5408\u975e\u7ebf\u6027\u63a7\u5236\u5668\u548c\u5f3a\u5316\u5b66\u4e60\u5b9e\u73b0\u4f18\u5316\u63a7\u5236\u3002", "motivation": "\u89e3\u51b3\u7aef\u53e3\u54c8\u5bc6\u987f\u7cfb\u7edf\u4e2d\u7ed3\u6784\u548c\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\u7684\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u7cfb\u7edf\u56fa\u6709\u7ed3\u6784\uff0c\u5e76\u63d0\u5347\u63a7\u5236\u6027\u80fd\u3001\u5b89\u5168\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u5c06\u7cfb\u7edf\u52a8\u6001\u5206\u89e3\u4e3a\u53f3\u7aef\uff08RHS\uff09\u548c\u5de6\u7aef\uff08LHS\uff09\uff0c\u5206\u522b\u5904\u7406\u54c8\u5bc6\u987f\u6d41\u548c\u8017\u6563/\u8f93\u5165\u6d41\uff1b\u4f7f\u7528\u975e\u7ebf\u6027\u63a7\u5236\u5668\u548c\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u63a7\u5236\u7b56\u7565\u3002", "result": "\u6846\u67b6\u6709\u6548\u7ba1\u7406\u4e86\u4e0d\u786e\u5b9a\u6027\uff0c\u63d0\u5347\u4e86\u6027\u80fd\u3001\u5b89\u5168\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u6548\u679c\u3002", "conclusion": "\u8be5\u6df7\u5408\u63a7\u5236\u6846\u67b6\u4e3a\u7aef\u53e3\u54c8\u5bc6\u987f\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u672a\u6765\u7406\u8bba\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.07083", "pdf": "https://arxiv.org/pdf/2506.07083", "abs": "https://arxiv.org/abs/2506.07083", "authors": ["Jiawen Li", "Jiang Guo", "Yuanzhe Li", "Zetian Mao", "Jiaxing Shen", "Tashi Xu", "Diptesh Das", "Jinming He", "Run Hu", "Yaerim Lee", "Koji Tsuda", "Junichiro Shiomi"], "title": "Inverse Design of Metamaterials with Manufacturing-Guiding Spectrum-to-Structure Conditional Diffusion Model", "categories": ["physics.optics", "cs.LG"], "comment": "20 pages, 7 figures", "summary": "Metamaterials are artificially engineered structures that manipulate\nelectromagnetic waves, having optical properties absent in natural materials.\nRecently, machine learning for the inverse design of metamaterials has drawn\nattention. However, the highly nonlinear relationship between the metamaterial\nstructures and optical behaviour, coupled with fabrication difficulties, poses\nchallenges for using machine learning to design and manufacture complex\nmetamaterials. Herein, we propose a general framework that implements\ncustomised spectrum-to-shape and size parameters to address one-to-many\nmetamaterial inverse design problems using conditional diffusion models. Our\nmethod exhibits superior spectral prediction accuracy, generates a diverse\nrange of patterns compared to other typical generative models, and offers\nvaluable prior knowledge for manufacturing through the subsequent analysis of\nthe diverse generated results, thereby facilitating the experimental\nfabrication of metamaterial designs. We demonstrate the efficacy of the\nproposed method by successfully designing and fabricating a free-form\nmetamaterial with a tailored selective emission spectrum for thermal camouflage\napplications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6761\u4ef6\u6269\u6563\u6a21\u578b\u7684\u901a\u7528\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u8d85\u6750\u6599\u9006\u5411\u8bbe\u8ba1\u4e2d\u7684\u4e00\u5bf9\u591a\u95ee\u9898\uff0c\u5177\u6709\u9ad8\u5149\u8c31\u9884\u6d4b\u7cbe\u5ea6\u548c\u591a\u6837\u6027\u751f\u6210\u80fd\u529b\u3002", "motivation": "\u8d85\u6750\u6599\u7684\u5149\u5b66\u884c\u4e3a\u4e0e\u7ed3\u6784\u95f4\u5b58\u5728\u9ad8\u5ea6\u975e\u7ebf\u6027\u5173\u7cfb\uff0c\u4e14\u5236\u9020\u590d\u6742\uff0c\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u3002", "method": "\u91c7\u7528\u6761\u4ef6\u6269\u6563\u6a21\u578b\uff0c\u5b9a\u5236\u5149\u8c31\u5230\u5f62\u72b6\u548c\u5c3a\u5bf8\u53c2\u6570\u7684\u6620\u5c04\uff0c\u751f\u6210\u591a\u6837\u5316\u8bbe\u8ba1\u3002", "result": "\u65b9\u6cd5\u5728\u5149\u8c31\u9884\u6d4b\u7cbe\u5ea6\u548c\u751f\u6210\u591a\u6837\u6027\u4e0a\u4f18\u4e8e\u5176\u4ed6\u751f\u6210\u6a21\u578b\uff0c\u5e76\u4e3a\u5236\u9020\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u5148\u9a8c\u77e5\u8bc6\u3002", "conclusion": "\u6210\u529f\u8bbe\u8ba1\u5e76\u5236\u9020\u4e86\u4e00\u79cd\u5177\u6709\u5b9a\u5236\u9009\u62e9\u6027\u53d1\u5c04\u5149\u8c31\u7684\u81ea\u7531\u5f62\u5f0f\u8d85\u6750\u6599\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2506.07140", "pdf": "https://arxiv.org/pdf/2506.07140", "abs": "https://arxiv.org/abs/2506.07140", "authors": ["Zhongren Chen", "Siyu Chen", "Zhengling Qi", "Xiaohong Chen", "Zhuoran Yang"], "title": "Quantile-Optimal Policy Learning under Unmeasured Confounding", "categories": ["stat.ML", "cs.LG", "econ.EM"], "comment": null, "summary": "We study quantile-optimal policy learning where the goal is to find a policy\nwhose reward distribution has the largest $\\alpha$-quantile for some $\\alpha\n\\in (0, 1)$. We focus on the offline setting whose generating process involves\nunobserved confounders. Such a problem suffers from three main challenges: (i)\nnonlinearity of the quantile objective as a functional of the reward\ndistribution, (ii) unobserved confounding issue, and (iii) insufficient\ncoverage of the offline dataset. To address these challenges, we propose a\nsuite of causal-assisted policy learning methods that provably enjoy strong\ntheoretical guarantees under mild conditions. In particular, to address (i) and\n(ii), using causal inference tools such as instrumental variables and negative\ncontrols, we propose to estimate the quantile objectives by solving nonlinear\nfunctional integral equations. Then we adopt a minimax estimation approach with\nnonparametric models to solve these integral equations, and propose to\nconstruct conservative policy estimates that address (iii). The final policy is\nthe one that maximizes these pessimistic estimates. In addition, we propose a\nnovel regularized policy learning method that is more amenable to computation.\nFinally, we prove that the policies learned by these methods are\n$\\tilde{\\mathscr{O}}(n^{-1/2})$ quantile-optimal under a mild coverage\nassumption on the offline dataset. Here, $\\tilde{\\mathscr{O}}(\\cdot)$ omits\npoly-logarithmic factors. To the best of our knowledge, we propose the first\nsample-efficient policy learning algorithms for estimating the quantile-optimal\npolicy when there exist unmeasured confounding.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5728\u5b58\u5728\u672a\u89c2\u6d4b\u6df7\u6742\u53d8\u91cf\u7684\u79bb\u7ebf\u8bbe\u7f6e\u4e0b\uff0c\u5b66\u4e60\u5177\u6709\u6700\u5927\u03b1-\u5206\u4f4d\u6570\u5956\u52b1\u5206\u5e03\u7684\u7b56\u7565\u3002\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u56e0\u679c\u63a8\u65ad\u5de5\u5177\u548c\u60b2\u89c2\u4f30\u8ba1\u7684\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u975e\u7ebf\u6027\u76ee\u6807\u3001\u672a\u89c2\u6d4b\u6df7\u6742\u548c\u6570\u636e\u8986\u76d6\u4e0d\u8db3\u7684\u6311\u6218\u3002", "motivation": "\u5728\u79bb\u7ebf\u7b56\u7565\u5b66\u4e60\u4e2d\uff0c\u672a\u89c2\u6d4b\u6df7\u6742\u53d8\u91cf\u548c\u975e\u7ebf\u6027\u5206\u4f4d\u6570\u76ee\u6807\u5bfc\u81f4\u4f20\u7edf\u65b9\u6cd5\u5931\u6548\uff0c\u9700\u8981\u65b0\u7684\u7406\u8bba\u548c\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u5de5\u5177\u53d8\u91cf\u548c\u8d1f\u63a7\u5236\u7b49\u56e0\u679c\u63a8\u65ad\u5de5\u5177\uff0c\u901a\u8fc7\u89e3\u975e\u7ebf\u6027\u51fd\u6570\u79ef\u5206\u65b9\u7a0b\u4f30\u8ba1\u5206\u4f4d\u6570\u76ee\u6807\uff0c\u5e76\u91c7\u7528\u6781\u5c0f\u6781\u5927\u4f30\u8ba1\u548c\u975e\u53c2\u6570\u6a21\u578b\u6784\u5efa\u4fdd\u5b88\u7b56\u7565\u4f30\u8ba1\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u6e29\u548c\u6761\u4ef6\u4e0b\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\uff0c\u5b66\u4e60\u5230\u7684\u7b56\u7565\u5728\u79bb\u7ebf\u6570\u636e\u96c6\u4e2d\u5177\u6709\u6837\u672c\u6548\u7387\uff0c\u4e14\u5206\u4f4d\u6570\u6700\u4f18\u3002", "conclusion": "\u8bba\u6587\u9996\u6b21\u63d0\u51fa\u4e86\u5728\u5b58\u5728\u672a\u89c2\u6d4b\u6df7\u6742\u53d8\u91cf\u65f6\uff0c\u4f30\u8ba1\u5206\u4f4d\u6570\u6700\u4f18\u7b56\u7565\u7684\u6837\u672c\u9ad8\u6548\u7b97\u6cd5\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u7684\u7a7a\u767d\u3002"}}
{"id": "2506.07154", "pdf": "https://arxiv.org/pdf/2506.07154", "abs": "https://arxiv.org/abs/2506.07154", "authors": ["Vicky Xefteri", "Tim Vieira", "Ryan Cotterell", "Afra Amini"], "title": "Syntactic Control of Language Models by Posterior Inference", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Controlling the syntactic structure of text generated by language models is\nvaluable for applications requiring clarity, stylistic consistency, or\ninterpretability, yet it remains a challenging task. In this paper, we argue\nthat sampling algorithms based on the posterior inference can effectively\nenforce a target constituency structure during generation. Our approach\ncombines sequential Monte Carlo, which estimates the posterior distribution by\nsampling from a proposal distribution, with a syntactic tagger that ensures\nthat each generated token aligns with the desired syntactic structure. Our\nexperiments with GPT2 and Llama3-8B models show that with an appropriate\nproposal distribution, we can improve syntactic accuracy, increasing the F1\nscore from $12.31$ (GPT2-large) and $35.33$ (Llama3-8B) to about $93$ in both\ncases without compromising the language model's fluency. These results\nunderscore both the complexity of syntactic control and the effectiveness of\nsampling algorithms, offering a promising approach for applications where\nprecise control over syntax is essential.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u540e\u9a8c\u63a8\u65ad\u7684\u91c7\u6837\u7b97\u6cd5\uff0c\u7528\u4e8e\u5728\u751f\u6210\u6587\u672c\u65f6\u6709\u6548\u63a7\u5236\u76ee\u6807\u53e5\u6cd5\u7ed3\u6784\uff0c\u7ed3\u5408\u4e86\u5e8f\u8d2f\u8499\u7279\u5361\u6d1b\u548c\u53e5\u6cd5\u6807\u6ce8\u5668\uff0c\u663e\u8457\u63d0\u5347\u4e86\u53e5\u6cd5\u51c6\u786e\u6027\u3002", "motivation": "\u63a7\u5236\u8bed\u8a00\u6a21\u578b\u751f\u6210\u6587\u672c\u7684\u53e5\u6cd5\u7ed3\u6784\u5bf9\u4e8e\u9700\u8981\u6e05\u6670\u6027\u3001\u98ce\u683c\u4e00\u81f4\u6027\u6216\u53ef\u89e3\u91ca\u6027\u7684\u5e94\u7528\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u76ee\u524d\u4ecd\u5177\u6311\u6218\u6027\u3002", "method": "\u7ed3\u5408\u5e8f\u8d2f\u8499\u7279\u5361\u6d1b\uff08\u4f30\u8ba1\u540e\u9a8c\u5206\u5e03\uff09\u548c\u53e5\u6cd5\u6807\u6ce8\u5668\uff0c\u786e\u4fdd\u751f\u6210\u7684\u6bcf\u4e2a\u8bcd\u7b26\u7b26\u5408\u76ee\u6807\u53e5\u6cd5\u7ed3\u6784\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728GPT2\u548cLlama3-8B\u6a21\u578b\u4e0a\u5c06\u53e5\u6cd5\u51c6\u786e\u6027F1\u5206\u6570\u4ece12.31\u548c35.33\u63d0\u5347\u81f3\u7ea693\uff0c\u4e14\u4e0d\u5f71\u54cd\u6d41\u7545\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u9700\u8981\u7cbe\u786e\u63a7\u5236\u53e5\u6cd5\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u7a81\u663e\u4e86\u91c7\u6837\u7b97\u6cd5\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.07159", "pdf": "https://arxiv.org/pdf/2506.07159", "abs": "https://arxiv.org/abs/2506.07159", "authors": ["Mrinmay Sen", "Chalavadi Krishna Mohan"], "title": "pFedSOP : Accelerating Training Of Personalized Federated Learning Using Second-Order Optimization", "categories": ["cs.DC", "cs.LG", "68Q25, 68T05, 90C06, 90C25, 90C30", "I.2.6; G.1.6; C.2.4"], "comment": null, "summary": "Personalized Federated Learning (PFL) enables clients to collaboratively\ntrain personalized models tailored to their individual objectives, addressing\nthe challenge of model generalization in traditional Federated Learning (FL)\ndue to high data heterogeneity. However, existing PFL methods often require\nincreased communication rounds to achieve the desired performance, primarily\ndue to slow training caused by the use of first-order optimization, which has\nlinear convergence. Additionally, many of these methods increase local\ncomputation because of the additional data fed into the model during the search\nfor personalized local models. One promising solution to this slow training is\nsecond-order optimization, known for its quadratic convergence. However,\nemploying it in PFL is challenging due to the Hessian matrix and its inverse.\nIn this paper, we propose pFedSOP, which efficiently utilizes second-order\noptimization in PFL to accelerate the training of personalized models and\nenhance performance with fewer communication rounds. Our approach first\ncomputes a personalized local gradient update using the Gompertz function-based\nnormalized angle between local and global gradient updates, incorporating\nclient-specific global information. We then use a regularized Fisher\nInformation Matrix (FIM), computed from this personalized gradient update, as\nan approximation of the Hessian to update the personalized models. This\nFIM-based second-order optimization speeds up training with fewer communication\nrounds by tackling the challenges with exact Hessian and avoids additional data\nbeing fed into the model during the search for personalized local models.\nExtensive experiments on heterogeneously partitioned image classification\ndatasets with partial client participation demonstrate that pFedSOP outperforms\nstate-of-the-art FL and PFL algorithms.", "AI": {"tldr": "pFedSOP\u5229\u7528\u4e8c\u9636\u4f18\u5316\u52a0\u901f\u4e2a\u6027\u5316\u8054\u90a6\u5b66\u4e60\uff0c\u51cf\u5c11\u901a\u4fe1\u8f6e\u6b21\u5e76\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u5728\u6570\u636e\u5f02\u6784\u6027\u4e0b\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u540c\u65f6\u907f\u514d\u73b0\u6709PFL\u65b9\u6cd5\u56e0\u4e00\u9636\u4f18\u5316\u5bfc\u81f4\u7684\u8bad\u7ec3\u7f13\u6162\u548c\u989d\u5916\u8ba1\u7b97\u8d1f\u62c5\u3002", "method": "\u901a\u8fc7Gompertz\u51fd\u6570\u8ba1\u7b97\u4e2a\u6027\u5316\u68af\u5ea6\u66f4\u65b0\uff0c\u5229\u7528\u6b63\u5219\u5316Fisher\u4fe1\u606f\u77e9\u9635\u8fd1\u4f3cHessian\u77e9\u9635\uff0c\u5b9e\u73b0\u4e8c\u9636\u4f18\u5316\u3002", "result": "\u5728\u5f02\u6784\u56fe\u50cf\u5206\u7c7b\u6570\u636e\u96c6\u4e0a\uff0cpFedSOP\u4f18\u4e8e\u73b0\u6709FL\u548cPFL\u7b97\u6cd5\u3002", "conclusion": "pFedSOP\u901a\u8fc7\u4e8c\u9636\u4f18\u5316\u6709\u6548\u52a0\u901f\u8bad\u7ec3\u5e76\u51cf\u5c11\u901a\u4fe1\u8f6e\u6b21\uff0c\u63d0\u5347\u4e86PFL\u7684\u6027\u80fd\u3002"}}
{"id": "2506.07171", "pdf": "https://arxiv.org/pdf/2506.07171", "abs": "https://arxiv.org/abs/2506.07171", "authors": ["Chenlong Zhang", "Zhuoran Jin", "Hongbang Yuan", "Jiaheng Wei", "Tong Zhou", "Kang Liu", "Jun Zhao", "Yubo Chen"], "title": "RULE: Reinforcement UnLEarning Achieves Forget-Retain Pareto Optimality", "categories": ["cs.CL", "cs.LG"], "comment": "Paper under review", "summary": "The widespread deployment of Large Language Models (LLMs) trained on massive,\nuncurated corpora has raised growing concerns about the inclusion of sensitive,\ncopyrighted, or illegal content. This has led to increasing interest in LLM\nunlearning: the task of selectively removing specific information from a model\nwithout retraining from scratch or degrading overall utility. However, existing\nmethods often rely on large-scale forget and retain datasets, and suffer from\nunnatural responses, poor generalization, or catastrophic utility loss. In this\nwork, we propose Reinforcement UnLearning (RULE), an efficient framework that\nformulates unlearning as a refusal boundary optimization problem. RULE is\ntrained with a small portion of the forget set and synthesized boundary\nqueries, using a verifiable reward function that encourages safe refusal on\nforget--related queries while preserving helpful responses on permissible\ninputs. We provide both theoretical and empirical evidence demonstrating the\neffectiveness of RULE in achieving targeted unlearning without compromising\nmodel utility. Experimental results show that, with only $12%$ forget set and\n$8%$ synthesized boundary data, RULE outperforms existing baselines by up to\n$17.5%$ forget quality and $16.3%$ naturalness response while maintaining\ngeneral utility, achieving forget--retain Pareto optimality. Remarkably, we\nfurther observe that RULE improves the naturalness of model outputs, enhances\ntraining efficiency, and exhibits strong generalization ability, generalizing\nrefusal behavior to semantically related but unseen queries.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRULE\u7684\u9ad8\u6548\u6846\u67b6\uff0c\u7528\u4e8e\u9009\u62e9\u6027\u79fb\u9664\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u7279\u5b9a\u4fe1\u606f\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6574\u4f53\u6027\u80fd\u3002", "motivation": "\u7531\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u80fd\u5305\u542b\u654f\u611f\u3001\u53d7\u7248\u6743\u4fdd\u62a4\u6216\u975e\u6cd5\u5185\u5bb9\uff0c\u9700\u8981\u4e00\u79cd\u65e0\u9700\u4ece\u5934\u8bad\u7ec3\u5373\u53ef\u9009\u62e9\u6027\u79fb\u9664\u4fe1\u606f\u7684\u65b9\u6cd5\u3002", "method": "RULE\u6846\u67b6\u5c06\u9057\u5fd8\u4efb\u52a1\u89c6\u4e3a\u62d2\u7edd\u8fb9\u754c\u4f18\u5316\u95ee\u9898\uff0c\u4f7f\u7528\u5c11\u91cf\u9057\u5fd8\u6570\u636e\u548c\u5408\u6210\u8fb9\u754c\u67e5\u8be2\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u901a\u8fc7\u53ef\u9a8c\u8bc1\u7684\u5956\u52b1\u51fd\u6570\u5b9e\u73b0\u5b89\u5168\u62d2\u7edd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cRULE\u4ec5\u970012%\u7684\u9057\u5fd8\u6570\u636e\u548c8%\u7684\u5408\u6210\u6570\u636e\uff0c\u5728\u9057\u5fd8\u8d28\u91cf\u548c\u54cd\u5e94\u81ea\u7136\u5ea6\u4e0a\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u4e14\u4fdd\u6301\u6a21\u578b\u5b9e\u7528\u6027\u3002", "conclusion": "RULE\u4e0d\u4ec5\u5b9e\u73b0\u4e86\u76ee\u6807\u9057\u5fd8\uff0c\u8fd8\u63d0\u5347\u4e86\u6a21\u578b\u8f93\u51fa\u7684\u81ea\u7136\u6027\u548c\u8bad\u7ec3\u6548\u7387\uff0c\u5e76\u5c55\u73b0\u51fa\u5f3a\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2506.07199", "pdf": "https://arxiv.org/pdf/2506.07199", "abs": "https://arxiv.org/abs/2506.07199", "authors": ["Ben Hayes", "Charalampos Saitis", "Gy\u00f6rgy Fazekas"], "title": "Audio synthesizer inversion in symmetric parameter spaces with approximately equivariant flow matching", "categories": ["cs.SD", "cs.LG", "eess.AS", "eess.SP"], "comment": "Accepted at ISMIR 2025", "summary": "Many audio synthesizers can produce the same signal given different parameter\nconfigurations, meaning the inversion from sound to parameters is an inherently\nill-posed problem. We show that this is largely due to intrinsic symmetries of\nthe synthesizer, and focus in particular on permutation invariance. First, we\ndemonstrate on a synthetic task that regressing point estimates under\npermutation symmetry degrades performance, even when using a\npermutation-invariant loss function or symmetry-breaking heuristics. Then,\nviewing equivalent solutions as modes of a probability distribution, we show\nthat a conditional generative model substantially improves performance.\nFurther, acknowledging the invariance of the implicit parameter distribution,\nwe find that performance is further improved by using a permutation equivariant\ncontinuous normalizing flow. To accommodate intricate symmetries in real\nsynthesizers, we also propose a relaxed equivariance strategy that adaptively\ndiscovers relevant symmetries from data. Applying our method to Surge XT, a\nfull-featured open source synthesizer used in real world audio production, we\nfind our method outperforms regression and generative baselines across audio\nreconstruction metrics.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u97f3\u9891\u5408\u6210\u5668\u53c2\u6570\u53cd\u6f14\u7684\u56fa\u6709\u5bf9\u79f0\u6027\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6761\u4ef6\u751f\u6210\u6a21\u578b\u548c\u7f6e\u6362\u7b49\u53d8\u8fde\u7eed\u5f52\u4e00\u5316\u6d41\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u97f3\u9891\u5408\u6210\u5668\u53c2\u6570\u53cd\u6f14\u662f\u4e00\u4e2a\u75c5\u6001\u95ee\u9898\uff0c\u4e3b\u8981\u7531\u4e8e\u5408\u6210\u5668\u7684\u5185\u5728\u5bf9\u79f0\u6027\uff08\u5982\u7f6e\u6362\u4e0d\u53d8\u6027\uff09\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u6761\u4ef6\u751f\u6210\u6a21\u578b\u548c\u7f6e\u6362\u7b49\u53d8\u8fde\u7eed\u5f52\u4e00\u5316\u6d41\u5904\u7406\u5bf9\u79f0\u6027\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u81ea\u9002\u5e94\u53d1\u73b0\u5bf9\u79f0\u6027\u7684\u7b56\u7565\u3002", "result": "\u5728Surge XT\u5408\u6210\u5668\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u97f3\u9891\u91cd\u5efa\u6307\u6807\u4e0a\u4f18\u4e8e\u56de\u5f52\u548c\u751f\u6210\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u5efa\u6a21\u53c2\u6570\u5206\u5e03\u548c\u81ea\u9002\u5e94\u5bf9\u79f0\u6027\u53d1\u73b0\uff0c\u663e\u8457\u63d0\u5347\u4e86\u97f3\u9891\u5408\u6210\u5668\u53c2\u6570\u53cd\u6f14\u7684\u6027\u80fd\u3002"}}
{"id": "2506.07232", "pdf": "https://arxiv.org/pdf/2506.07232", "abs": "https://arxiv.org/abs/2506.07232", "authors": ["Xinran Li", "Chenjia Bai", "Zijian Li", "Jiakun Zheng", "Ting Xiao", "Jun Zhang"], "title": "Learn as Individuals, Evolve as a Team: Multi-agent LLMs Adaptation in Embodied Environments", "categories": ["cs.MA", "cs.AI", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) possess extensive knowledge bases and strong\nreasoning capabilities, making them promising tools for complex, multi-agent\nplanning in embodied environments. However, despite LLMs' advanced abilities\nand the sophisticated modular design of agentic methods, existing LLM-based\nplanning algorithms remain limited by weak adaptation capabilities to\nmulti-agent embodied scenarios. We address this limitation by introducing a\nframework that enables LLM agents to learn and evolve both before and during\ntest time, equipping them with environment-relevant knowledge for better\nplanning and enhanced communication for improved cooperation. Inspired by\ncentralized training with decentralized execution in multi-agent reinforcement\nlearning, we propose a \\textit{Learn as Individuals, Evolve as a Team (LIET)}\nparadigm for multi-agent LLMs adaptation. At the individual level, LLM agents\nlearn a local utility function from exploratory datasets to better comprehend\nthe embodied environment, which is then queried during test time to support\ninformed decision-making. At the team level, LLM agents collaboratively and\niteratively maintain and update a shared cooperation knowledge list based on\nnew experiences, using it to guide more effective communication. By combining\nindividual learning with team evolution, LIET enables comprehensive and\nflexible adaptation for LLM agents. Our experiments on Communicative\nWatch-And-Help and ThreeD-World Multi-Agent Transport benchmarks demonstrate\nthat LIET, instantiated with both LLaMA and GPT-4o, outperforms existing\nbaselines and exhibits strong cooperative planning abilities.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLIET\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u4e2a\u4f53\u5b66\u4e60\u548c\u56e2\u961f\u6f14\u5316\u63d0\u5347LLM\u5728\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u7684\u9002\u5e94\u80fd\u529b\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709LLM\u5728\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u7684\u9002\u5e94\u80fd\u529b\u4e0d\u8db3\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u63d0\u5347\u5176\u89c4\u5212\u548c\u534f\u4f5c\u80fd\u529b\u3002", "method": "\u63d0\u51faLIET\u6846\u67b6\uff0c\u7ed3\u5408\u4e2a\u4f53\u5b66\u4e60\uff08\u672c\u5730\u6548\u7528\u51fd\u6570\uff09\u548c\u56e2\u961f\u6f14\u5316\uff08\u5171\u4eab\u5408\u4f5c\u77e5\u8bc6\u5217\u8868\uff09\uff0c\u5b9e\u73b0\u7075\u6d3b\u9002\u5e94\u3002", "result": "\u5728Communicative Watch-And-Help\u548cThreeD-World Multi-Agent Transport\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLIET\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "LIET\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86LLM\u5728\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u7684\u9002\u5e94\u6027\u548c\u534f\u4f5c\u80fd\u529b\u3002"}}
{"id": "2506.07248", "pdf": "https://arxiv.org/pdf/2506.07248", "abs": "https://arxiv.org/abs/2506.07248", "authors": ["Prathamesh Kokate", "Mitali Sarnaik", "Manavi Khopade", "Raviraj Joshi"], "title": "Improving the Efficiency of Long Document Classification using Sentence Ranking Approach", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Long document classification poses challenges due to the computational\nlimitations of transformer-based models, particularly BERT, which are\nconstrained by fixed input lengths and quadratic attention complexity.\nMoreover, using the full document for classification is often redundant, as\nonly a subset of sentences typically carries the necessary information. To\naddress this, we propose a TF-IDF-based sentence ranking method that improves\nefficiency by selecting the most informative content. Our approach explores\nfixed-count and percentage-based sentence selection, along with an enhanced\nscoring strategy combining normalized TF-IDF scores and sentence length.\nEvaluated on the MahaNews LDC dataset of long Marathi news articles, the method\nconsistently outperforms baselines such as first, last, and random sentence\nselection. With MahaBERT-v2, we achieve near-identical classification accuracy\nwith just a 0.33 percent drop compared to the full-context baseline, while\nreducing input size by over 50 percent and inference latency by 43 percent.\nThis demonstrates that significant context reduction is possible without\nsacrificing performance, making the method practical for real-world long\ndocument classification tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eTF-IDF\u7684\u53e5\u5b50\u6392\u540d\u65b9\u6cd5\uff0c\u7528\u4e8e\u957f\u6587\u6863\u5206\u7c7b\uff0c\u663e\u8457\u51cf\u5c11\u8f93\u5165\u5927\u5c0f\u548c\u63a8\u7406\u5ef6\u8fdf\uff0c\u540c\u65f6\u4fdd\u6301\u5206\u7c7b\u51c6\u786e\u6027\u3002", "motivation": "\u957f\u6587\u6863\u5206\u7c7b\u4e2d\uff0cBERT\u7b49\u6a21\u578b\u56e0\u56fa\u5b9a\u8f93\u5165\u957f\u5ea6\u548c\u4e8c\u6b21\u6ce8\u610f\u529b\u590d\u6742\u5ea6\u53d7\u9650\uff0c\u4e14\u5168\u6587\u6863\u5206\u7c7b\u901a\u5e38\u5197\u4f59\u3002", "method": "\u91c7\u7528TF-IDF\u53e5\u5b50\u6392\u540d\u65b9\u6cd5\uff0c\u7ed3\u5408\u56fa\u5b9a\u6570\u91cf\u6216\u767e\u5206\u6bd4\u9009\u62e9\u53e5\u5b50\uff0c\u5e76\u4f18\u5316\u8bc4\u5206\u7b56\u7565\uff08\u5f52\u4e00\u5316TF-IDF\u5206\u6570\u548c\u53e5\u5b50\u957f\u5ea6\uff09\u3002", "result": "\u5728MahaNews LDC\u6570\u636e\u96c6\u4e0a\uff0c\u65b9\u6cd5\u4f18\u4e8e\u57fa\u7ebf\uff08\u9996\u5c3e\u53e5\u6216\u968f\u673a\u9009\u62e9\uff09\uff0c\u8f93\u5165\u51cf\u5c1150%\u4ee5\u4e0a\uff0c\u63a8\u7406\u5ef6\u8fdf\u964d\u4f4e43%\uff0c\u5206\u7c7b\u51c6\u786e\u7387\u4ec5\u4e0b\u964d0.33%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u8bc1\u660e\u5728\u4e0d\u727a\u7272\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u51cf\u5c11\u4e0a\u4e0b\u6587\u662f\u53ef\u884c\u7684\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u957f\u6587\u6863\u5206\u7c7b\u4efb\u52a1\u3002"}}
{"id": "2506.07259", "pdf": "https://arxiv.org/pdf/2506.07259", "abs": "https://arxiv.org/abs/2506.07259", "authors": ["Daolang Huang", "Xinyi Wen", "Ayush Bharti", "Samuel Kaski", "Luigi Acerbi"], "title": "ALINE: Joint Amortization for Bayesian Inference and Active Data Acquisition", "categories": ["stat.ML", "cs.LG"], "comment": "27 pages, 13 figures", "summary": "Many critical applications, from autonomous scientific discovery to\npersonalized medicine, demand systems that can both strategically acquire the\nmost informative data and instantaneously perform inference based upon it.\nWhile amortized methods for Bayesian inference and experimental design offer\npart of the solution, neither approach is optimal in the most general and\nchallenging task, where new data needs to be collected for instant inference.\nTo tackle this issue, we introduce the Amortized Active Learning and Inference\nEngine (ALINE), a unified framework for amortized Bayesian inference and active\ndata acquisition. ALINE leverages a transformer architecture trained via\nreinforcement learning with a reward based on self-estimated information gain\nprovided by its own integrated inference component. This allows it to\nstrategically query informative data points while simultaneously refining its\npredictions. Moreover, ALINE can selectively direct its querying strategy\ntowards specific subsets of model parameters or designated predictive tasks,\noptimizing for posterior estimation, data prediction, or a mixture thereof.\nEmpirical results on regression-based active learning, classical Bayesian\nexperimental design benchmarks, and a psychometric model with selectively\ntargeted parameters demonstrate that ALINE delivers both instant and accurate\ninference along with efficient selection of informative points.", "AI": {"tldr": "ALINE\u662f\u4e00\u4e2a\u7ed3\u5408\u8d1d\u53f6\u65af\u63a8\u7406\u548c\u4e3b\u52a8\u6570\u636e\u91c7\u96c6\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3Transformer\u67b6\u6784\uff0c\u5b9e\u73b0\u9ad8\u6548\u6570\u636e\u67e5\u8be2\u548c\u5373\u65f6\u63a8\u7406\u3002", "motivation": "\u89e3\u51b3\u5728\u9700\u8981\u5373\u65f6\u63a8\u7406\u7684\u65b0\u6570\u636e\u91c7\u96c6\u4efb\u52a1\u4e2d\uff0c\u73b0\u6709\u65b9\u6cd5\uff08\u5982\u644a\u9500\u8d1d\u53f6\u65af\u63a8\u7406\u548c\u5b9e\u9a8c\u8bbe\u8ba1\uff09\u7684\u4e0d\u8db3\u3002", "method": "ALINE\u91c7\u7528Transformer\u67b6\u6784\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u4fe1\u606f\u589e\u76ca\u5956\u52b1\uff0c\u540c\u65f6\u652f\u6301\u9488\u5bf9\u7279\u5b9a\u53c2\u6570\u6216\u4efb\u52a1\u7684\u67e5\u8be2\u7b56\u7565\u3002", "result": "\u5728\u56de\u5f52\u4efb\u52a1\u3001\u8d1d\u53f6\u65af\u5b9e\u9a8c\u8bbe\u8ba1\u57fa\u51c6\u548c\u5fc3\u7406\u6d4b\u91cf\u6a21\u578b\u4e2d\uff0cALINE\u8868\u73b0\u51fa\u9ad8\u6548\u7684\u63a8\u7406\u548c\u6570\u636e\u9009\u62e9\u80fd\u529b\u3002", "conclusion": "ALINE\u4e3a\u5373\u65f6\u63a8\u7406\u548c\u9ad8\u6548\u6570\u636e\u91c7\u96c6\u63d0\u4f9b\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.07261", "pdf": "https://arxiv.org/pdf/2506.07261", "abs": "https://arxiv.org/abs/2506.07261", "authors": ["Amit Jaspal", "Qian Dang", "Ajantha Ramineni"], "title": "RADAR: Recall Augmentation through Deferred Asynchronous Retrieval", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "Modern large-scale recommender systems employ multi-stage ranking funnel\n(Retrieval, Pre-ranking, Ranking) to balance engagement and computational\nconstraints (latency, CPU). However, the initial retrieval stage, often relying\non efficient but less precise methods like K-Nearest Neighbors (KNN), struggles\nto effectively surface the most engaging items from billion-scale catalogs,\nparticularly distinguishing highly relevant and engaging candidates from merely\nrelevant ones. We introduce Recall Augmentation through Deferred Asynchronous\nRetrieval (RADAR), a novel framework that leverages asynchronous, offline\ncomputation to pre-rank a significantly larger candidate set for users using\nthe full complexity ranking model. These top-ranked items are stored and\nutilized as a high-quality retrieval source during online inference, bypassing\nonline retrieval and pre-ranking stages for these candidates. We demonstrate\nthrough offline experiments that RADAR significantly boosts recall (2X\nRecall@200 vs DNN retrieval baseline) by effectively combining a larger\nretrieved candidate set with a more powerful ranking model. Online A/B tests\nconfirm a +0.8% lift in topline engagement metrics, validating RADAR as a\npractical and effective method to improve recommendation quality under strict\nonline serving constraints.", "AI": {"tldr": "RADAR\u6846\u67b6\u901a\u8fc7\u5f02\u6b65\u79bb\u7ebf\u8ba1\u7b97\u9884\u6392\u540d\u66f4\u5927\u5019\u9009\u96c6\uff0c\u663e\u8457\u63d0\u5347\u53ec\u56de\u7387\uff0c\u5e76\u5728\u5728\u7ebf\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u89e3\u51b3\u5927\u89c4\u6a21\u63a8\u8350\u7cfb\u7edf\u4e2d\u521d\u59cb\u68c0\u7d22\u9636\u6bb5\u96be\u4ee5\u4ece\u6d77\u91cf\u5185\u5bb9\u4e2d\u7cbe\u51c6\u7b5b\u9009\u9ad8\u5438\u5f15\u529b\u5019\u9009\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165RADAR\u6846\u67b6\uff0c\u5229\u7528\u79bb\u7ebf\u8ba1\u7b97\u9884\u6392\u540d\u66f4\u5927\u5019\u9009\u96c6\uff0c\u5e76\u5728\u5728\u7ebf\u63a8\u7406\u4e2d\u76f4\u63a5\u4f7f\u7528\u8fd9\u4e9b\u9ad8\u8d28\u91cf\u5019\u9009\u3002", "result": "\u79bb\u7ebf\u5b9e\u9a8c\u663e\u793a\u53ec\u56de\u7387\u63d0\u53472\u500d\uff0c\u5728\u7ebfA/B\u6d4b\u8bd5\u9a8c\u8bc1\u4e860.8%\u7684\u53c2\u4e0e\u5ea6\u63d0\u5347\u3002", "conclusion": "RADAR\u662f\u4e00\u79cd\u5728\u4e25\u683c\u5728\u7ebf\u670d\u52a1\u7ea6\u675f\u4e0b\u63d0\u5347\u63a8\u8350\u8d28\u91cf\u7684\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2506.07271", "pdf": "https://arxiv.org/pdf/2506.07271", "abs": "https://arxiv.org/abs/2506.07271", "authors": ["Hikaru Sawafuji", "Ryota Ozaki", "Takuto Motomura", "Toyohisa Matsuda", "Masanori Tojima", "Kento Uchida", "Shinichi Shirakawa"], "title": "Machine Learning-Based Self-Localization Using Internal Sensors for Automating Bulldozers", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Self-localization is an important technology for automating bulldozers.\nConventional bulldozer self-localization systems rely on RTK-GNSS (Real Time\nKinematic-Global Navigation Satellite Systems). However, RTK-GNSS signals are\nsometimes lost in certain mining conditions. Therefore, self-localization\nmethods that do not depend on RTK-GNSS are required. In this paper, we propose\na machine learning-based self-localization method for bulldozers. The proposed\nmethod consists of two steps: estimating local velocities using a machine\nlearning model from internal sensors, and incorporating these estimates into an\nExtended Kalman Filter (EKF) for global localization. We also created a novel\ndataset for bulldozer odometry and conducted experiments across various driving\nscenarios, including slalom, excavation, and driving on slopes. The result\ndemonstrated that the proposed self-localization method suppressed the\naccumulation of position errors compared to kinematics-based methods,\nespecially when slip occurred. Furthermore, this study showed that\nbulldozer-specific sensors, such as blade position sensors and hydraulic\npressure sensors, contributed to improving self-localization accuracy.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u63a8\u571f\u673a\u81ea\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3RTK-GNSS\u4fe1\u53f7\u4e22\u5931\u7684\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u7ed3\u5408\u5c40\u90e8\u901f\u5ea6\u4f30\u8ba1\u548c\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u80fd\u6709\u6548\u51cf\u5c11\u4f4d\u7f6e\u8bef\u5dee\u3002", "motivation": "RTK-GNSS\u4fe1\u53f7\u5728\u67d0\u4e9b\u91c7\u77ff\u6761\u4ef6\u4e0b\u4f1a\u4e22\u5931\uff0c\u56e0\u6b64\u9700\u8981\u4e0d\u4f9d\u8d56RTK-GNSS\u7684\u81ea\u5b9a\u4f4d\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4ece\u5185\u90e8\u4f20\u611f\u5668\u4f30\u8ba1\u5c40\u90e8\u901f\u5ea6\uff0c\u5e76\u5c06\u5176\u8f93\u5165\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u8fdb\u884c\u5168\u5c40\u5b9a\u4f4d\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6ed1\u52a8\u7b49\u60c5\u51b5\u4e0b\u6bd4\u57fa\u4e8e\u8fd0\u52a8\u5b66\u7684\u65b9\u6cd5\u66f4\u80fd\u6291\u5236\u4f4d\u7f6e\u8bef\u5dee\u7d2f\u79ef\uff0c\u4e14\u63a8\u571f\u673a\u4e13\u7528\u4f20\u611f\u5668\u6709\u52a9\u4e8e\u63d0\u9ad8\u5b9a\u4f4d\u7cbe\u5ea6\u3002", "conclusion": "\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u81ea\u5b9a\u4f4d\u65b9\u6cd5\u5728\u63a8\u571f\u673a\u5e94\u7528\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u5c24\u5176\u5728RTK-GNSS\u4fe1\u53f7\u4e0d\u53ef\u9760\u65f6\u3002"}}
{"id": "2506.07286", "pdf": "https://arxiv.org/pdf/2506.07286", "abs": "https://arxiv.org/abs/2506.07286", "authors": ["Aditya Chakravarty"], "title": "Multi-Step Guided Diffusion for Image Restoration on Edge Devices: Toward Lightweight Perception in Embodied AI", "categories": ["cs.CV", "cs.LG", "cs.RO"], "comment": "Accepted in CVPR 2025 Embodied AI Workshop", "summary": "Diffusion models have shown remarkable flexibility for solving inverse\nproblems without task-specific retraining. However, existing approaches such as\nManifold Preserving Guided Diffusion (MPGD) apply only a single gradient update\nper denoising step, limiting restoration fidelity and robustness, especially in\nembedded or out-of-distribution settings. In this work, we introduce a\nmultistep optimization strategy within each denoising timestep, significantly\nenhancing image quality, perceptual accuracy, and generalization. Our\nexperiments on super-resolution and Gaussian deblurring demonstrate that\nincreasing the number of gradient updates per step improves LPIPS and PSNR with\nminimal latency overhead. Notably, we validate this approach on a Jetson Orin\nNano using degraded ImageNet and a UAV dataset, showing that MPGD, originally\ntrained on face datasets, generalizes effectively to natural and aerial scenes.\nOur findings highlight MPGD's potential as a lightweight, plug-and-play\nrestoration module for real-time visual perception in embodied AI agents such\nas drones and mobile robots.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6b65\u4f18\u5316\u7b56\u7565\uff0c\u7528\u4e8e\u63d0\u5347\u6269\u6563\u6a21\u578b\u5728\u9006\u95ee\u9898\u4e2d\u7684\u6062\u590d\u8d28\u91cf\u548c\u9c81\u68d2\u6027\uff0c\u5c24\u5176\u5728\u5d4c\u5165\u5f0f\u6216\u5206\u5e03\u5916\u573a\u666f\u4e2d\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\uff08\u5982MPGD\uff09\u5728\u6bcf\u4e00\u6b65\u53bb\u566a\u4e2d\u4ec5\u5e94\u7528\u5355\u6b21\u68af\u5ea6\u66f4\u65b0\uff0c\u9650\u5236\u4e86\u6062\u590d\u7684\u4fdd\u771f\u5ea6\u548c\u9c81\u68d2\u6027\u3002", "method": "\u5728\u6bcf\u4e00\u6b65\u53bb\u566a\u65f6\u95f4\u6b65\u4e2d\u5f15\u5165\u591a\u6b65\u4f18\u5316\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u56fe\u50cf\u8d28\u91cf\u3001\u611f\u77e5\u51c6\u786e\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u589e\u52a0\u6bcf\u6b65\u68af\u5ea6\u66f4\u65b0\u6b21\u6570\u53ef\u6539\u5584LPIPS\u548cPSNR\uff0c\u4e14\u5728Jetson Orin Nano\u4e0a\u9a8c\u8bc1\u4e86MPGD\u5728\u81ea\u7136\u548c\u822a\u62cd\u573a\u666f\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "MPGD\u5177\u6709\u4f5c\u4e3a\u8f7b\u91cf\u7ea7\u3001\u5373\u63d2\u5373\u7528\u6062\u590d\u6a21\u5757\u7684\u6f5c\u529b\uff0c\u9002\u7528\u4e8e\u65e0\u4eba\u673a\u548c\u79fb\u52a8\u673a\u5668\u4eba\u7b49\u5b9e\u65f6\u89c6\u89c9\u611f\u77e5\u4efb\u52a1\u3002"}}
{"id": "2506.07294", "pdf": "https://arxiv.org/pdf/2506.07294", "abs": "https://arxiv.org/abs/2506.07294", "authors": ["Xuanjun Chen", "I-Ming Lin", "Lin Zhang", "Haibin Wu", "Hung-yi Lee", "Jyh-Shing Roger Jang"], "title": "Towards Generalized Source Tracing for Codec-Based Deepfake Speech", "categories": ["cs.SD", "cs.CR", "cs.LG", "eess.AS"], "comment": "Submitted to IEEE ASRU 2025", "summary": "Recent attempts at source tracing for codec-based deepfake speech\n(CodecFake), generated by neural audio codec-based speech generation (CoSG)\nmodels, have exhibited suboptimal performance. However, how to train source\ntracing models using simulated CoSG data while maintaining strong performance\non real CoSG-generated audio remains an open challenge. In this paper, we show\nthat models trained solely on codec-resynthesized data tend to overfit to\nnon-speech regions and struggle to generalize to unseen content. To mitigate\nthese challenges, we introduce the Semantic-Acoustic Source Tracing Network\n(SASTNet), which jointly leverages Whisper for semantic feature encoding and\nWav2vec2 with AudioMAE for acoustic feature encoding. Our proposed SASTNet\nachieves state-of-the-art performance on the CoSG test set of the CodecFake+\ndataset, demonstrating its effectiveness for reliable source tracing.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faSASTNet\u6a21\u578b\uff0c\u7ed3\u5408\u8bed\u4e49\u548c\u58f0\u5b66\u7279\u5f81\u7f16\u7801\uff0c\u663e\u8457\u63d0\u5347CodecFake\u8bed\u97f3\u7684\u6e90\u8ffd\u8e2a\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u795e\u7ecf\u97f3\u9891\u7f16\u89e3\u7801\u7684\u8bed\u97f3\u751f\u6210\u6a21\u578b\uff08CoSG\uff09\u7684\u6e90\u8ffd\u8e2a\u65b9\u6cd5\u6027\u80fd\u4e0d\u4f73\uff0c\u4e14\u5982\u4f55\u5728\u6a21\u62df\u6570\u636e\u4e0a\u8bad\u7ec3\u6a21\u578b\u5e76\u4fdd\u6301\u5bf9\u771f\u5b9e\u6570\u636e\u7684\u6cdb\u5316\u80fd\u529b\u5c1a\u5f85\u89e3\u51b3\u3002", "method": "\u63d0\u51faSASTNet\u6a21\u578b\uff0c\u8054\u5408\u4f7f\u7528Whisper\u8fdb\u884c\u8bed\u4e49\u7279\u5f81\u7f16\u7801\u548cWav2vec2\u4e0eAudioMAE\u8fdb\u884c\u58f0\u5b66\u7279\u5f81\u7f16\u7801\u3002", "result": "SASTNet\u5728CodecFake+\u6570\u636e\u96c6\u7684CoSG\u6d4b\u8bd5\u96c6\u4e0a\u8fbe\u5230\u6700\u4f18\u6027\u80fd\u3002", "conclusion": "SASTNet\u901a\u8fc7\u7ed3\u5408\u8bed\u4e49\u548c\u58f0\u5b66\u7279\u5f81\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6e90\u8ffd\u8e2a\u7684\u6cdb\u5316\u95ee\u9898\u3002"}}
{"id": "2506.07299", "pdf": "https://arxiv.org/pdf/2506.07299", "abs": "https://arxiv.org/abs/2506.07299", "authors": ["Hans Buehler", "Blanka Horvath", "Yannick Limmer", "Thorsten Schmidt"], "title": "Uncertainty-Aware Strategies: A Model-Agnostic Framework for Robust Financial Optimization through Subsampling", "categories": ["q-fin.CP", "cs.LG", "q-fin.MF", "q-fin.RM"], "comment": "18 pages, 12 figures", "summary": "This paper addresses the challenge of model uncertainty in quantitative\nfinance, where decisions in portfolio allocation, derivative pricing, and risk\nmanagement rely on estimating stochastic models from limited data. In practice,\nthe unavailability of the true probability measure forces reliance on an\nempirical approximation, and even small misestimations can lead to significant\ndeviations in decision quality. Building on the framework of Klibanoff et al.\n(2005), we enhance the conventional objective - whether this is expected\nutility in an investing context or a hedging metric - by superimposing an outer\n\"uncertainty measure\", motivated by traditional monetary risk measures, on the\nspace of models. In scenarios where a natural model distribution is lacking or\nBayesian methods are impractical, we propose an ad hoc subsampling strategy,\nanalogous to bootstrapping in statistical finance and related to mini-batch\nsampling in deep learning, to approximate model uncertainty. To address the\nquadratic memory demands of naive implementations, we also present an adapted\nstochastic gradient descent algorithm that enables efficient parallelization.\nThrough analytical, simulated, and empirical studies - including multi-period,\nreal data and high-dimensional examples - we demonstrate that uncertainty\nmeasures outperform traditional mixture of measures strategies and our\nmodel-agnostic subsampling-based approach not only enhances robustness against\nmodel risk but also achieves performance comparable to more elaborate Bayesian\nmethods.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u5b9a\u91cf\u91d1\u878d\u4e2d\u5904\u7406\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u53e0\u52a0\u5916\u90e8\u4e0d\u786e\u5b9a\u6027\u5ea6\u91cf\u589e\u5f3a\u4f20\u7edf\u76ee\u6807\uff0c\u5e76\u63d0\u51fa\u4e86\u5b50\u91c7\u6837\u7b56\u7565\u548c\u9ad8\u6548\u5e76\u884c\u5316\u7b97\u6cd5\u3002", "motivation": "\u89e3\u51b3\u5b9a\u91cf\u91d1\u878d\u4e2d\u56e0\u6570\u636e\u6709\u9650\u5bfc\u81f4\u7684\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u5bf9\u51b3\u7b56\u8d28\u91cf\u7684\u5f71\u54cd\u3002", "method": "\u57fa\u4e8eKlibanoff\u6846\u67b6\uff0c\u53e0\u52a0\u4e0d\u786e\u5b9a\u6027\u5ea6\u91cf\uff0c\u63d0\u51fa\u5b50\u91c7\u6837\u7b56\u7565\u548c\u4f18\u5316\u7b97\u6cd5\u3002", "result": "\u4e0d\u786e\u5b9a\u6027\u5ea6\u91cf\u4f18\u4e8e\u4f20\u7edf\u6df7\u5408\u5ea6\u91cf\u7b56\u7565\uff0c\u5b50\u91c7\u6837\u65b9\u6cd5\u5728\u6a21\u578b\u98ce\u9669\u4e0b\u8868\u73b0\u7a33\u5065\u4e14\u6027\u80fd\u63a5\u8fd1\u8d1d\u53f6\u65af\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u517c\u5177\u9ad8\u6548\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2506.07326", "pdf": "https://arxiv.org/pdf/2506.07326", "abs": "https://arxiv.org/abs/2506.07326", "authors": ["Brian Christian", "Hannah Rose Kirk", "Jessica A. F. Thompson", "Christopher Summerfield", "Tsvetomira Dumbalska"], "title": "Reward Model Interpretability via Optimal and Pessimal Tokens", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG", "I.2.6; I.2.7; H.5.2; J.4; K.4.2"], "comment": "Accepted for publication in Proceedings of the 2025 ACM Conference on\n  Fairness, Accountability, and Transparency (FAccT '25), to appear June 2025", "summary": "Reward modeling has emerged as a crucial component in aligning large language\nmodels with human values. Significant attention has focused on using reward\nmodels as a means for fine-tuning generative models. However, the reward models\nthemselves -- which directly encode human value judgments by turning\nprompt-response pairs into scalar rewards -- remain relatively understudied. We\npresent a novel approach to reward model interpretability through exhaustive\nanalysis of their responses across their entire vocabulary space. By examining\nhow different reward models score every possible single-token response to\nvalue-laden prompts, we uncover several striking findings: (i) substantial\nheterogeneity between models trained on similar objectives, (ii) systematic\nasymmetries in how models encode high- vs low-scoring tokens, (iii) significant\nsensitivity to prompt framing that mirrors human cognitive biases, and (iv)\novervaluation of more frequent tokens. We demonstrate these effects across ten\nrecent open-source reward models of varying parameter counts and architectures.\nOur results challenge assumptions about the interchangeability of reward\nmodels, as well as their suitability as proxies of complex and\ncontext-dependent human values. We find that these models can encode concerning\nbiases toward certain identity groups, which may emerge as unintended\nconsequences of harmlessness training -- distortions that risk propagating\nthrough the downstream large language models now deployed to millions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5956\u52b1\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u5176\u5728\u6574\u4e2a\u8bcd\u6c47\u7a7a\u95f4\u4e2d\u7684\u54cd\u5e94\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u95f4\u7684\u5f02\u8d28\u6027\u3001\u8bc4\u5206\u4e0d\u5bf9\u79f0\u6027\u3001\u5bf9\u63d0\u793a\u6846\u67b6\u7684\u654f\u611f\u6027\u4ee5\u53ca\u5bf9\u9ad8\u9891\u8bcd\u7684\u8fc7\u5ea6\u91cd\u89c6\u3002", "motivation": "\u5956\u52b1\u6a21\u578b\u5728\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u5bf9\u9f50\u4e2d\u8d77\u5173\u952e\u4f5c\u7528\uff0c\u4f46\u5176\u672c\u8eab\u7684\u7814\u7a76\u8f83\u5c11\uff0c\u5c24\u5176\u662f\u5176\u5982\u4f55\u7f16\u7801\u4eba\u7c7b\u4ef7\u503c\u5224\u65ad\u3002", "method": "\u901a\u8fc7\u5206\u6790\u5956\u52b1\u6a21\u578b\u5bf9\u6240\u6709\u53ef\u80fd\u7684\u5355\u4ee4\u724c\u54cd\u5e94\u5728\u4ef7\u503c\u76f8\u5173\u63d0\u793a\u4e0b\u7684\u8bc4\u5206\uff0c\u63ed\u793a\u5176\u884c\u4e3a\u7279\u5f81\u3002", "result": "\u53d1\u73b0\u6a21\u578b\u95f4\u5b58\u5728\u663e\u8457\u5f02\u8d28\u6027\u3001\u8bc4\u5206\u4e0d\u5bf9\u79f0\u6027\u3001\u5bf9\u63d0\u793a\u6846\u67b6\u7684\u654f\u611f\u6027\u4ee5\u53ca\u5bf9\u9ad8\u9891\u8bcd\u7684\u8fc7\u5ea6\u91cd\u89c6\uff0c\u5e76\u63ed\u793a\u4e86\u6f5c\u5728\u7684\u504f\u89c1\u95ee\u9898\u3002", "conclusion": "\u5956\u52b1\u6a21\u578b\u5e76\u975e\u53ef\u4e92\u6362\uff0c\u4e14\u53ef\u80fd\u7f16\u7801\u6709\u5bb3\u504f\u89c1\uff0c\u8fd9\u5bf9\u5176\u4f5c\u4e3a\u4eba\u7c7b\u4ef7\u503c\u89c2\u4ee3\u7406\u7684\u9002\u7528\u6027\u63d0\u51fa\u4e86\u6311\u6218\u3002"}}
{"id": "2506.07327", "pdf": "https://arxiv.org/pdf/2506.07327", "abs": "https://arxiv.org/abs/2506.07327", "authors": ["Dane Williamson", "Yangfeng Ji", "Matthew Dwyer"], "title": "\"CASE: Contrastive Activation for Saliency Estimation", "categories": ["cs.CV", "cs.LG", "I.2.6; I.5.1; I.5.5; I.2.10"], "comment": "9 pages, 5 figures. Submitted to IEEE Transactions on Neural Networks\n  and Learning Systems (TNNLS)", "summary": "Saliency methods are widely used to visualize which input features are deemed\nrelevant to a model's prediction. However, their visual plausibility can\nobscure critical limitations. In this work, we propose a diagnostic test for\nclass sensitivity: a method's ability to distinguish between competing class\nlabels on the same input. Through extensive experiments, we show that many\nwidely used saliency methods produce nearly identical explanations regardless\nof the class label, calling into question their reliability. We find that\nclass-insensitive behavior persists across architectures and datasets,\nsuggesting the failure mode is structural rather than model-specific. Motivated\nby these findings, we introduce CASE, a contrastive explanation method that\nisolates features uniquely discriminative for the predicted class. We evaluate\nCASE using the proposed diagnostic and a perturbation-based fidelity test, and\nshow that it produces faithful and more class-specific explanations than\nexisting methods.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bca\u65ad\u6d4b\u8bd5\uff08class sensitivity\uff09\u6765\u8bc4\u4f30\u663e\u8457\u6027\u65b9\u6cd5\u7684\u53ef\u9760\u6027\uff0c\u53d1\u73b0\u8bb8\u591a\u65b9\u6cd5\u5bf9\u7c7b\u522b\u6807\u7b7e\u4e0d\u654f\u611f\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u5bf9\u6bd4\u89e3\u91ca\u65b9\u6cd5CASE\uff0c\u5176\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u663e\u8457\u6027\u65b9\u6cd5\u5728\u53ef\u89c6\u5316\u6a21\u578b\u9884\u6d4b\u65f6\u88ab\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u5176\u89c6\u89c9\u5408\u7406\u6027\u53ef\u80fd\u63a9\u76d6\u4e86\u5173\u952e\u5c40\u9650\u6027\u3002\u672c\u6587\u65e8\u5728\u63ed\u793a\u8fd9\u4e9b\u65b9\u6cd5\u7684\u53ef\u9760\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8bca\u65ad\u6d4b\u8bd5\uff08class sensitivity\uff09\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8bb8\u591a\u663e\u8457\u6027\u65b9\u6cd5\u5bf9\u7c7b\u522b\u6807\u7b7e\u4e0d\u654f\u611f\u3002\u968f\u540e\u63d0\u51fa\u4e86\u5bf9\u6bd4\u89e3\u91ca\u65b9\u6cd5CASE\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8bb8\u591a\u663e\u8457\u6027\u65b9\u6cd5\u5bf9\u7c7b\u522b\u6807\u7b7e\u4e0d\u654f\u611f\uff0c\u800cCASE\u65b9\u6cd5\u80fd\u751f\u6210\u66f4\u5fe0\u5b9e\u4e14\u7c7b\u522b\u7279\u5b9a\u7684\u89e3\u91ca\u3002", "conclusion": "CASE\u65b9\u6cd5\u5728\u8bca\u65ad\u6d4b\u8bd5\u548c\u4fdd\u771f\u5ea6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u663e\u8457\u6027\u65b9\u6cd5\u7684\u7c7b\u522b\u4e0d\u654f\u611f\u95ee\u9898\u3002"}}
{"id": "2506.07339", "pdf": "https://arxiv.org/pdf/2506.07339", "abs": "https://arxiv.org/abs/2506.07339", "authors": ["Kevin Black", "Manuel Y. Galliker", "Sergey Levine"], "title": "Real-Time Execution of Action Chunking Flow Policies", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "Modern AI systems, especially those interacting with the physical world,\nincreasingly require real-time performance. However, the high latency of\nstate-of-the-art generalist models, including recent vision-language action\nmodels (VLAs), poses a significant challenge. While action chunking has enabled\ntemporal consistency in high-frequency control tasks, it does not fully address\nthe latency problem, leading to pauses or out-of-distribution jerky movements\nat chunk boundaries. This paper presents a novel inference-time algorithm that\nenables smooth asynchronous execution of action chunking policies. Our method,\nreal-time chunking (RTC), is applicable to any diffusion- or flow-based VLA out\nof the box with no re-training. It generates the next action chunk while\nexecuting the current one, \"freezing\" actions guaranteed to execute and\n\"inpainting\" the rest. To test RTC, we introduce a new benchmark of 12 highly\ndynamic tasks in the Kinetix simulator, as well as evaluate 6 challenging\nreal-world bimanual manipulation tasks. Results demonstrate that RTC is fast,\nperformant, and uniquely robust to inference delay, significantly improving\ntask throughput and enabling high success rates in precise tasks\n$\\unicode{x2013}$ such as lighting a match $\\unicode{x2013}$ even in the\npresence of significant latency. See\nhttps://pi.website/research/real_time_chunking for videos.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5b9e\u65f6\u5206\u5757\uff08RTC\uff09\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3AI\u7cfb\u7edf\u5728\u9ad8\u9891\u63a7\u5236\u4efb\u52a1\u4e2d\u7684\u5ef6\u8fdf\u95ee\u9898\uff0c\u5b9e\u73b0\u5e73\u6ed1\u5f02\u6b65\u6267\u884c\u52a8\u4f5c\u5206\u5757\u7b56\u7565\u3002", "motivation": "\u73b0\u4ee3AI\u7cfb\u7edf\u5728\u5b9e\u65f6\u6027\u80fd\u4e0a\u7684\u9700\u6c42\u65e5\u76ca\u589e\u957f\uff0c\u4f46\u73b0\u6709\u901a\u7528\u6a21\u578b\u7684\u5ef6\u8fdf\u95ee\u9898\u9650\u5236\u4e86\u5176\u5728\u9ad8\u9891\u63a7\u5236\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002", "method": "RTC\u7b97\u6cd5\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\uff0c\u9002\u7528\u4e8e\u4efb\u4f55\u57fa\u4e8e\u6269\u6563\u6216\u6d41\u7684\u89c6\u89c9\u8bed\u8a00\u52a8\u4f5c\u6a21\u578b\uff0c\u901a\u8fc7\u5728\u6267\u884c\u5f53\u524d\u52a8\u4f5c\u5206\u5757\u65f6\u751f\u6210\u4e0b\u4e00\u4e2a\u5206\u5757\uff0c\u786e\u4fdd\u52a8\u4f5c\u5e73\u6ed1\u8fc7\u6e21\u3002", "result": "\u5728Kinetix\u6a21\u62df\u5668\u548c\u771f\u5b9e\u4e16\u754c\u53cc\u624b\u673a\u5668\u4eba\u4efb\u52a1\u4e2d\uff0cRTC\u663e\u8457\u63d0\u9ad8\u4e86\u4efb\u52a1\u541e\u5410\u91cf\u548c\u6210\u529f\u7387\uff0c\u5c24\u5176\u5728\u5b58\u5728\u5ef6\u8fdf\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "RTC\u662f\u4e00\u79cd\u9ad8\u6548\u3001\u9c81\u68d2\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347AI\u7cfb\u7edf\u5728\u5b9e\u65f6\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002"}}
{"id": "2506.07347", "pdf": "https://arxiv.org/pdf/2506.07347", "abs": "https://arxiv.org/abs/2506.07347", "authors": ["Armin Lederer", "Erfaun Noorani", "Andreas Krause"], "title": "Distributed Risk-Sensitive Safety Filters for Uncertain Discrete-Time Systems", "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.SY"], "comment": null, "summary": "Ensuring safety in multi-agent systems is a significant challenge,\nparticularly in settings where centralized coordination is impractical. In this\nwork, we propose a novel risk-sensitive safety filter for discrete-time\nmulti-agent systems with uncertain dynamics that leverages control barrier\nfunctions (CBFs) defined through value functions. Our approach relies on\ncentralized risk-sensitive safety conditions based on exponential risk\noperators to ensure robustness against model uncertainties. We introduce a\ndistributed formulation of the safety filter by deriving two alternative\nstrategies: one based on worst-case anticipation and another on proximity to a\nknown safe policy. By allowing agents to switch between strategies, feasibility\ncan be ensured. Through detailed numerical evaluations, we demonstrate the\nefficacy of our approach in maintaining safety without being overly\nconservative.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u63a7\u5236\u5c4f\u969c\u51fd\u6570\uff08CBFs\uff09\u7684\u98ce\u9669\u654f\u611f\u5b89\u5168\u8fc7\u6ee4\u5668\uff0c\u7528\u4e8e\u79bb\u6563\u65f6\u95f4\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u901a\u8fc7\u96c6\u4e2d\u5f0f\u98ce\u9669\u654f\u611f\u6761\u4ef6\u548c\u5206\u5e03\u5f0f\u7b56\u7565\u5207\u6362\u786e\u4fdd\u5b89\u5168\u6027\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u7f3a\u4e4f\u96c6\u4e2d\u534f\u8c03\u65f6\u7684\u5b89\u5168\u6027\u95ee\u9898\uff0c\u5c24\u5176\u662f\u9762\u5bf9\u52a8\u6001\u4e0d\u786e\u5b9a\u6027\u65f6\u7684\u6311\u6218\u3002", "method": "\u5229\u7528\u57fa\u4e8e\u503c\u51fd\u6570\u7684CBFs\uff0c\u63d0\u51fa\u96c6\u4e2d\u5f0f\u98ce\u9669\u654f\u611f\u6761\u4ef6\uff0c\u5e76\u5f15\u5165\u4e24\u79cd\u5206\u5e03\u5f0f\u7b56\u7565\uff08\u6700\u574f\u60c5\u51b5\u9884\u6d4b\u548c\u63a5\u8fd1\u5df2\u77e5\u5b89\u5168\u7b56\u7565\uff09\u4ee5\u786e\u4fdd\u53ef\u884c\u6027\u3002", "result": "\u6570\u503c\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u5728\u4e0d\u4fdd\u5b88\u7684\u60c5\u51b5\u4e0b\u6709\u6548\u7ef4\u6301\u5b89\u5168\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u4e00\u79cd\u7075\u6d3b\u4e14\u7a33\u5065\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.07351", "pdf": "https://arxiv.org/pdf/2506.07351", "abs": "https://arxiv.org/abs/2506.07351", "authors": ["Jun Chen", "Lina Liu", "Tianyi Zhu", "Yong Liu", "Guang Dai", "Yunliang Jiang", "Ivor W. Tsang"], "title": "Decentralized Optimization on Compact Submanifolds by Quantized Riemannian Gradient Tracking", "categories": ["math.OC", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "This paper considers the problem of decentralized optimization on compact\nsubmanifolds, where a finite sum of smooth (possibly non-convex) local\nfunctions is minimized by $n$ agents forming an undirected and connected graph.\nHowever, the efficiency of distributed optimization is often hindered by\ncommunication bottlenecks. To mitigate this, we propose the Quantized\nRiemannian Gradient Tracking (Q-RGT) algorithm, where agents update their local\nvariables using quantized gradients. The introduction of quantization noise\nallows our algorithm to bypass the constraints of the accurate Riemannian\nprojection operator (such as retraction), further improving iterative\nefficiency. To the best of our knowledge, this is the first algorithm to\nachieve an $\\mathcal{O}(1/K)$ convergence rate in the presence of quantization,\nmatching the convergence rate of methods without quantization. Additionally, we\nexplicitly derive lower bounds on decentralized consensus associated with a\nfunction of quantization levels. Numerical experiments demonstrate that Q-RGT\nperforms comparably to non-quantized methods while reducing communication\nbottlenecks and computational overhead.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u91cf\u5316\u9ece\u66fc\u68af\u5ea6\u8ddf\u8e2a\u7b97\u6cd5\uff08Q-RGT\uff09\uff0c\u7528\u4e8e\u89e3\u51b3\u7d27\u81f4\u5b50\u6d41\u5f62\u4e0a\u7684\u53bb\u4e2d\u5fc3\u5316\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u91cf\u5316\u68af\u5ea6\u51cf\u5c11\u901a\u4fe1\u74f6\u9888\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u975e\u91cf\u5316\u65b9\u6cd5\u76f8\u5f53\u7684\u6536\u655b\u901f\u5ea6\u3002", "motivation": "\u53bb\u4e2d\u5fc3\u5316\u4f18\u5316\u5728\u7d27\u81f4\u5b50\u6d41\u5f62\u4e0a\u7684\u6548\u7387\u5e38\u53d7\u901a\u4fe1\u74f6\u9888\u9650\u5236\uff0c\u91cf\u5316\u68af\u5ea6\u53ef\u7f13\u89e3\u6b64\u95ee\u9898\u3002", "method": "\u63d0\u51faQ-RGT\u7b97\u6cd5\uff0c\u5229\u7528\u91cf\u5316\u68af\u5ea6\u66f4\u65b0\u5c40\u90e8\u53d8\u91cf\uff0c\u907f\u514d\u7cbe\u786e\u9ece\u66fc\u6295\u5f71\u7b97\u5b50\u7684\u7ea6\u675f\u3002", "result": "Q-RGT\u5728\u91cf\u5316\u60c5\u51b5\u4e0b\u8fbe\u5230\u4e0e\u975e\u91cf\u5316\u65b9\u6cd5\u76f8\u540c\u7684\u6536\u655b\u901f\u5ea6\uff08O(1/K)\uff09\uff0c\u5e76\u660e\u786e\u91cf\u5316\u6c34\u5e73\u4e0e\u53bb\u4e2d\u5fc3\u5316\u5171\u8bc6\u7684\u4e0b\u754c\u5173\u7cfb\u3002", "conclusion": "Q-RGT\u5728\u51cf\u5c11\u901a\u4fe1\u548c\u8ba1\u7b97\u5f00\u9500\u7684\u540c\u65f6\uff0c\u6027\u80fd\u4e0e\u975e\u91cf\u5316\u65b9\u6cd5\u76f8\u5f53\uff0c\u662f\u9996\u4e2a\u5728\u91cf\u5316\u60c5\u51b5\u4e0b\u5b9e\u73b0\u9ad8\u6548\u6536\u655b\u7684\u7b97\u6cd5\u3002"}}
{"id": "2506.07357", "pdf": "https://arxiv.org/pdf/2506.07357", "abs": "https://arxiv.org/abs/2506.07357", "authors": ["Satvik Praveen", "Yoonsung Jung"], "title": "CBAM-STN-TPS-YOLO: Enhancing Agricultural Object Detection through Spatially Adaptive Attention Mechanisms", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Object detection is vital in precision agriculture for plant monitoring,\ndisease detection, and yield estimation. However, models like YOLO struggle\nwith occlusions, irregular structures, and background noise, reducing detection\naccuracy. While Spatial Transformer Networks (STNs) improve spatial invariance\nthrough learned transformations, affine mappings are insufficient for non-rigid\ndeformations such as bent leaves and overlaps.\n  We propose CBAM-STN-TPS-YOLO, a model integrating Thin-Plate Splines (TPS)\ninto STNs for flexible, non-rigid spatial transformations that better align\nfeatures. Performance is further enhanced by the Convolutional Block Attention\nModule (CBAM), which suppresses background noise and emphasizes relevant\nspatial and channel-wise features.\n  On the occlusion-heavy Plant Growth and Phenotyping (PGP) dataset, our model\noutperforms STN-YOLO in precision, recall, and mAP. It achieves a 12% reduction\nin false positives, highlighting the benefits of improved spatial flexibility\nand attention-guided refinement. We also examine the impact of the TPS\nregularization parameter in balancing transformation smoothness and detection\nperformance.\n  This lightweight model improves spatial awareness and supports real-time edge\ndeployment, making it ideal for smart farming applications requiring accurate\nand efficient monitoring.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408TPS\u7684STN-YOLO\u6a21\u578b\uff08CBAM-STN-TPS-YOLO\uff09\uff0c\u7528\u4e8e\u89e3\u51b3\u519c\u4e1a\u76ee\u6807\u68c0\u6d4b\u4e2d\u7684\u906e\u6321\u548c\u975e\u521a\u6027\u53d8\u5f62\u95ee\u9898\uff0c\u6027\u80fd\u4f18\u4e8eSTN-YOLO\u3002", "motivation": "\u519c\u4e1a\u76ee\u6807\u68c0\u6d4b\u4e2d\uff0c\u73b0\u6709\u6a21\u578b\uff08\u5982YOLO\uff09\u5bf9\u906e\u6321\u3001\u4e0d\u89c4\u5219\u7ed3\u6784\u548c\u80cc\u666f\u566a\u58f0\u5904\u7406\u4e0d\u4f73\uff0cSTN\u7684\u4eff\u5c04\u53d8\u6362\u65e0\u6cd5\u6ee1\u8db3\u975e\u521a\u6027\u53d8\u5f62\u9700\u6c42\u3002", "method": "\u96c6\u6210TPS\u5230STN\u4e2d\u5b9e\u73b0\u975e\u521a\u6027\u7a7a\u95f4\u53d8\u6362\uff0c\u7ed3\u5408CBAM\u6a21\u5757\u6291\u5236\u80cc\u666f\u566a\u58f0\u5e76\u589e\u5f3a\u5173\u952e\u7279\u5f81\u3002", "result": "\u5728PGP\u6570\u636e\u96c6\u4e0a\uff0c\u6a21\u578b\u5728\u7cbe\u5ea6\u3001\u53ec\u56de\u7387\u548cmAP\u4e0a\u4f18\u4e8eSTN-YOLO\uff0c\u5047\u9633\u6027\u51cf\u5c1112%\u3002", "conclusion": "\u8be5\u8f7b\u91cf\u7ea7\u6a21\u578b\u63d0\u5347\u4e86\u7a7a\u95f4\u611f\u77e5\u80fd\u529b\uff0c\u9002\u5408\u5b9e\u65f6\u8fb9\u7f18\u90e8\u7f72\uff0c\u9002\u7528\u4e8e\u7cbe\u51c6\u519c\u4e1a\u76d1\u6d4b\u3002"}}
{"id": "2506.07358", "pdf": "https://arxiv.org/pdf/2506.07358", "abs": "https://arxiv.org/abs/2506.07358", "authors": ["Kuiyuan Zhang", "Wenjie Pei", "Rushi Lan", "Yifang Guo", "Zhongyun Hua"], "title": "Lightweight Joint Audio-Visual Deepfake Detection via Single-Stream Multi-Modal Learning Framework", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "comment": null, "summary": "Deepfakes are AI-synthesized multimedia data that may be abused for spreading\nmisinformation. Deepfake generation involves both visual and audio\nmanipulation. To detect audio-visual deepfakes, previous studies commonly\nemploy two relatively independent sub-models to learn audio and visual\nfeatures, respectively, and fuse them subsequently for deepfake detection.\nHowever, this may underutilize the inherent correlations between audio and\nvisual features. Moreover, utilizing two isolated feature learning sub-models\ncan result in redundant neural layers, making the overall model inefficient and\nimpractical for resource-constrained environments.\n  In this work, we design a lightweight network for audio-visual deepfake\ndetection via a single-stream multi-modal learning framework. Specifically, we\nintroduce a collaborative audio-visual learning block to efficiently integrate\nmulti-modal information while learning the visual and audio features. By\niteratively employing this block, our single-stream network achieves a\ncontinuous fusion of multi-modal features across its layers. Thus, our network\nefficiently captures visual and audio features without the need for excessive\nblock stacking, resulting in a lightweight network design. Furthermore, we\npropose a multi-modal classification module that can boost the dependence of\nthe visual and audio classifiers on modality content. It also enhances the\nwhole resistance of the video classifier against the mismatches between audio\nand visual modalities. We conduct experiments on the DF-TIMIT, FakeAVCeleb, and\nDFDC benchmark datasets. Compared to state-of-the-art audio-visual joint\ndetection methods, our method is significantly lightweight with only 0.48M\nparameters, yet it achieves superiority in both uni-modal and multi-modal\ndeepfakes, as well as in unseen types of deepfakes.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u5355\u6d41\u591a\u6a21\u6001\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u97f3\u89c6\u9891\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\uff0c\u901a\u8fc7\u534f\u4f5c\u5b66\u4e60\u5757\u548c\u591a\u6a21\u6001\u5206\u7c7b\u6a21\u5757\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u53c2\u6570\u6570\u91cf\u5e76\u63d0\u5347\u4e86\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u4f7f\u7528\u4e24\u4e2a\u72ec\u7acb\u7684\u5b50\u6a21\u578b\u5206\u522b\u5b66\u4e60\u97f3\u89c6\u9891\u7279\u5f81\uff0c\u672a\u80fd\u5145\u5206\u5229\u7528\u4e24\u8005\u95f4\u7684\u76f8\u5173\u6027\uff0c\u4e14\u6a21\u578b\u5197\u4f59\uff0c\u4e0d\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u73af\u5883\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5355\u6d41\u591a\u6a21\u6001\u5b66\u4e60\u6846\u67b6\uff0c\u5f15\u5165\u534f\u4f5c\u97f3\u89c6\u9891\u5b66\u4e60\u5757\u5b9e\u73b0\u591a\u6a21\u6001\u7279\u5f81\u7684\u8fde\u7eed\u878d\u5408\uff0c\u5e76\u63d0\u51fa\u591a\u6a21\u6001\u5206\u7c7b\u6a21\u5757\u589e\u5f3a\u5206\u7c7b\u5668\u5bf9\u6a21\u6001\u5185\u5bb9\u7684\u4f9d\u8d56\u6027\u3002", "result": "\u5728DF-TIMIT\u3001FakeAVCeleb\u548cDFDC\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u4ec5\u97000.48M\u53c2\u6570\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u97f3\u89c6\u9891\u8054\u5408\u68c0\u6d4b\u65b9\u6cd5\uff0c\u4e14\u5bf9\u672a\u89c1\u8fc7\u7684\u6df1\u5ea6\u4f2a\u9020\u7c7b\u578b\u4e5f\u6709\u6548\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u8f7b\u91cf\u7ea7\u8bbe\u8ba1\u548c\u9ad8\u6548\u7684\u591a\u6a21\u6001\u7279\u5f81\u878d\u5408\uff0c\u663e\u8457\u63d0\u5347\u4e86\u97f3\u89c6\u9891\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u7684\u6548\u7387\u548c\u6027\u80fd\u3002"}}
{"id": "2506.07364", "pdf": "https://arxiv.org/pdf/2506.07364", "abs": "https://arxiv.org/abs/2506.07364", "authors": ["Chengchao Shen", "Dawei Liu", "Jianxin Wang"], "title": "Multiple Object Stitching for Unsupervised Representation Learning", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Contrastive learning for single object centric images has achieved remarkable\nprogress on unsupervised representation, but suffering inferior performance on\nthe widespread images with multiple objects. In this paper, we propose a simple\nbut effective method, Multiple Object Stitching (MOS), to refine the\nunsupervised representation for multi-object images. Specifically, we construct\nthe multi-object images by stitching the single object centric ones, where the\nobjects in the synthesized multi-object images are predetermined. Hence,\ncompared to the existing contrastive methods, our method provides additional\nobject correspondences between multi-object images without human annotations.\nIn this manner, our method pays more attention to the representations of each\nobject in multi-object image, thus providing more detailed representations for\ncomplicated downstream tasks, such as object detection and semantic\nsegmentation. Experimental results on ImageNet, CIFAR and COCO datasets\ndemonstrate that our proposed method achieves the leading unsupervised\nrepresentation performance on both single object centric images and\nmulti-object ones. The source code is available at\nhttps://github.com/visresearch/MultipleObjectStitching.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMOS\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u62fc\u63a5\u5355\u76ee\u6807\u56fe\u50cf\u751f\u6210\u591a\u76ee\u6807\u56fe\u50cf\uff0c\u4ee5\u6539\u8fdb\u65e0\u76d1\u7763\u8868\u793a\u5b66\u4e60\uff0c\u5728\u591a\u76ee\u6807\u56fe\u50cf\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\u5728\u591a\u76ee\u6807\u56fe\u50cf\u4e0a\u8868\u73b0\u4e0d\u4f73\u7684\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u62fc\u63a5\u5355\u76ee\u6807\u56fe\u50cf\u751f\u6210\u591a\u76ee\u6807\u56fe\u50cf\uff0c\u5229\u7528\u9884\u5b9a\u7684\u5bf9\u8c61\u5bf9\u5e94\u5173\u7cfb\u6539\u8fdb\u65e0\u76d1\u7763\u8868\u793a\u3002", "result": "\u5728ImageNet\u3001CIFAR\u548cCOCO\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u9886\u5148\u7684\u65e0\u76d1\u7763\u8868\u793a\u6027\u80fd\u3002", "conclusion": "MOS\u65b9\u6cd5\u5728\u591a\u76ee\u6807\u56fe\u50cf\u4e0a\u63d0\u4f9b\u4e86\u66f4\u8be6\u7ec6\u7684\u8868\u793a\uff0c\u9002\u7528\u4e8e\u590d\u6742\u4e0b\u6e38\u4efb\u52a1\u3002"}}
{"id": "2506.07376", "pdf": "https://arxiv.org/pdf/2506.07376", "abs": "https://arxiv.org/abs/2506.07376", "authors": ["Jintao Tong", "Ran Ma", "Yixiong Zou", "Guangyao Chen", "Yuhua Li", "Ruixuan Li"], "title": "Adapter Naturally Serves as Decoupler for Cross-Domain Few-Shot Semantic Segmentation", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "ICML 2025 Spotlight", "summary": "Cross-domain few-shot segmentation (CD-FSS) is proposed to pre-train the\nmodel on a source-domain dataset with sufficient samples, and then transfer the\nmodel to target-domain datasets where only a few samples are available for\nefficient fine-tuning. There are majorly two challenges in this task: (1) the\ndomain gap and (2) fine-tuning with scarce data. To solve these challenges, we\nrevisit the adapter-based methods, and discover an intriguing insight not\nexplored in previous works: the adapter not only helps the fine-tuning of\ndownstream tasks but also naturally serves as a domain information decoupler.\nThen, we delve into this finding for an interpretation, and find the model's\ninherent structure could lead to a natural decoupling of domain information.\nBuilding upon this insight, we propose the Domain Feature Navigator (DFN),\nwhich is a structure-based decoupler instead of loss-based ones like current\nworks, to capture domain-specific information, thereby directing the model's\nattention towards domain-agnostic knowledge. Moreover, to prevent the potential\nexcessive overfitting of DFN during the source-domain training, we further\ndesign the SAM-SVN method to constrain DFN from learning sample-specific\nknowledge. On target domains, we freeze the model and fine-tune the DFN to\nlearn target-specific knowledge specific. Extensive experiments demonstrate\nthat our method surpasses the state-of-the-art method in CD-FSS significantly\nby 2.69% and 4.68% MIoU in 1-shot and 5-shot scenarios, respectively.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8de8\u57df\u5c11\u6837\u672c\u5206\u5272\u65b9\u6cd5\uff08CD-FSS\uff09\uff0c\u901a\u8fc7\u9002\u914d\u5668\u81ea\u7136\u89e3\u8026\u57df\u4fe1\u606f\uff0c\u5e76\u8bbe\u8ba1\u4e86\u57df\u7279\u5f81\u5bfc\u822a\u5668\uff08DFN\uff09\u548cSAM-SVN\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u8de8\u57df\u5c11\u6837\u672c\u5206\u5272\u4e2d\u7684\u57df\u5dee\u8ddd\u548c\u5c11\u6837\u672c\u5fae\u8c03\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u57df\u7279\u5f81\u5bfc\u822a\u5668\uff08DFN\uff09\u89e3\u8026\u57df\u4fe1\u606f\uff0c\u7ed3\u5408SAM-SVN\u9632\u6b62\u8fc7\u62df\u5408\uff0c\u51bb\u7ed3\u6a21\u578b\u5e76\u5fae\u8c03DFN\u3002", "result": "\u57281-shot\u548c5-shot\u573a\u666f\u4e0b\u5206\u522b\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd52.69%\u548c4.68% MIoU\u3002", "conclusion": "DFN\u548cSAM-SVN\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u8de8\u57df\u5c11\u6837\u672c\u5206\u5272\u7684\u6311\u6218\uff0c\u6027\u80fd\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2506.07392", "pdf": "https://arxiv.org/pdf/2506.07392", "abs": "https://arxiv.org/abs/2506.07392", "authors": ["Yuyang Zhou", "Guang Cheng", "Kang Du", "Zihan Chen", "Tian Qin", "Yuyu Zhao"], "title": "From Static to Adaptive Defense: Federated Multi-Agent Deep Reinforcement Learning-Driven Moving Target Defense Against DoS Attacks in UAV Swarm Networks", "categories": ["cs.CR", "cs.AI", "cs.LG", "68", "F.2.2"], "comment": "13pages; In submission", "summary": "The proliferation of unmanned aerial vehicle (UAV) swarms has enabled a wide\nrange of mission-critical applications, but also exposes UAV networks to severe\nDenial-of-Service (DoS) threats due to their open wireless environment, dynamic\ntopology, and resource constraints. Traditional static or centralized defense\nmechanisms are often inadequate for such dynamic and distributed scenarios. To\naddress these challenges, we propose a novel federated multi-agent deep\nreinforcement learning (FMADRL)-driven moving target defense (MTD) framework\nfor proactive and adaptive DoS mitigation in UAV swarm networks. Specifically,\nwe design three lightweight and coordinated MTD mechanisms, including leader\nswitching, route mutation, and frequency hopping, that leverage the inherent\nflexibility of UAV swarms to disrupt attacker efforts and enhance network\nresilience. The defense problem is formulated as a multi-agent partially\nobservable Markov decision process (POMDP), capturing the distributed,\nresource-constrained, and uncertain nature of UAV swarms under attack. Each UAV\nis equipped with a local policy agent that autonomously selects MTD actions\nbased on partial observations and local experiences. By employing a policy\ngradient-based FMADRL algorithm, UAVs collaboratively optimize their defense\npolicies via reward-weighted aggregation, enabling distributed learning without\nsharing raw data and thus reducing communication overhead. Extensive\nsimulations demonstrate that our approach significantly outperforms\nstate-of-the-art baselines, achieving up to a 34.6% improvement in attack\nmitigation rate, a reduction in average recovery time of up to 94.6%, and\ndecreases in energy consumption and defense cost by as much as 29.3% and 98.3%,\nrespectively, while maintaining robust mission continuity under various DoS\nattack strategies.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8054\u90a6\u591a\u667a\u80fd\u4f53\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u79fb\u52a8\u76ee\u6807\u9632\u5fa1\u6846\u67b6\uff0c\u7528\u4e8e\u65e0\u4eba\u673a\u7fa4\u7f51\u7edc\u7684\u4e3b\u52a8\u548c\u81ea\u9002\u5e94DoS\u7f13\u89e3\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u65e0\u4eba\u673a\u7fa4\u7f51\u7edc\u7684\u5f00\u653e\u65e0\u7ebf\u73af\u5883\u3001\u52a8\u6001\u62d3\u6251\u548c\u8d44\u6e90\u9650\u5236\u4f7f\u5176\u9762\u4e34\u4e25\u91cd\u7684DoS\u5a01\u80c1\uff0c\u4f20\u7edf\u9759\u6001\u6216\u96c6\u4e2d\u5f0f\u9632\u5fa1\u673a\u5236\u96be\u4ee5\u5e94\u5bf9\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e09\u79cd\u8f7b\u91cf\u7ea7\u534f\u8c03\u7684MTD\u673a\u5236\uff08\u9886\u5bfc\u8005\u5207\u6362\u3001\u8def\u7531\u53d8\u5f02\u548c\u9891\u7387\u8df3\u53d8\uff09\uff0c\u5e76\u901a\u8fc7\u8054\u90a6\u591a\u667a\u80fd\u4f53\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u4f18\u5316\u9632\u5fa1\u7b56\u7565\u3002", "result": "\u5728\u653b\u51fb\u7f13\u89e3\u7387\u3001\u5e73\u5747\u6062\u590d\u65f6\u95f4\u3001\u80fd\u8017\u548c\u9632\u5fa1\u6210\u672c\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5206\u522b\u63d0\u534734.6%\u3001\u51cf\u5c1194.6%\u3001\u964d\u4f4e29.3%\u548c98.3%\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u52a8\u6001\u548c\u5206\u5e03\u5f0f\u573a\u666f\u4e0b\u6709\u6548\u63d0\u5347\u4e86\u65e0\u4eba\u673a\u7fa4\u7f51\u7edc\u7684\u6297DoS\u80fd\u529b\u548c\u4efb\u52a1\u8fde\u7eed\u6027\u3002"}}
{"id": "2506.07398", "pdf": "https://arxiv.org/pdf/2506.07398", "abs": "https://arxiv.org/abs/2506.07398", "authors": ["Guibin Zhang", "Muxin Fu", "Guancheng Wan", "Miao Yu", "Kun Wang", "Shuicheng Yan"], "title": "G-Memory: Tracing Hierarchical Memory for Multi-Agent Systems", "categories": ["cs.MA", "cs.CL", "cs.LG"], "comment": null, "summary": "Large language model (LLM)-powered multi-agent systems (MAS) have\ndemonstrated cognitive and execution capabilities that far exceed those of\nsingle LLM agents, yet their capacity for self-evolution remains hampered by\nunderdeveloped memory architectures. Upon close inspection, we are alarmed to\ndiscover that prevailing MAS memory mechanisms (1) are overly simplistic,\ncompletely disregarding the nuanced inter-agent collaboration trajectories, and\n(2) lack cross-trial and agent-specific customization, in stark contrast to the\nexpressive memory developed for single agents. To bridge this gap, we introduce\nG-Memory, a hierarchical, agentic memory system for MAS inspired by\norganizational memory theory, which manages the lengthy MAS interaction via a\nthree-tier graph hierarchy: insight, query, and interaction graphs. Upon\nreceiving a new user query, G-Memory performs bi-directional memory traversal\nto retrieve both $\\textit{high-level, generalizable insights}$ that enable the\nsystem to leverage cross-trial knowledge, and $\\textit{fine-grained, condensed\ninteraction trajectories}$ that compactly encode prior collaboration\nexperiences. Upon task execution, the entire hierarchy evolves by assimilating\nnew collaborative trajectories, nurturing the progressive evolution of agent\nteams. Extensive experiments across five benchmarks, three LLM backbones, and\nthree popular MAS frameworks demonstrate that G-Memory improves success rates\nin embodied action and accuracy in knowledge QA by up to $20.89\\%$ and\n$10.12\\%$, respectively, without any modifications to the original frameworks.\nOur codes are available at https://github.com/bingreeky/GMemory.", "AI": {"tldr": "G-Memory\u662f\u4e00\u79cd\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8bbe\u8ba1\u7684\u5206\u5c42\u8bb0\u5fc6\u67b6\u6784\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u8bb0\u5fc6\u673a\u5236\u8fc7\u4e8e\u7b80\u5355\u548c\u7f3a\u4e4f\u5b9a\u5236\u5316\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4efb\u52a1\u6210\u529f\u7387\u3002", "motivation": "\u73b0\u6709\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u8bb0\u5fc6\u673a\u5236\u8fc7\u4e8e\u7b80\u5355\uff0c\u5ffd\u89c6\u4e86\u667a\u80fd\u4f53\u95f4\u7684\u534f\u4f5c\u8f68\u8ff9\uff0c\u4e14\u7f3a\u4e4f\u8de8\u4efb\u52a1\u548c\u667a\u80fd\u4f53\u7279\u5b9a\u7684\u5b9a\u5236\u5316\u8bb0\u5fc6\uff0c\u9650\u5236\u4e86\u7cfb\u7edf\u7684\u81ea\u6211\u8fdb\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51faG-Memory\uff0c\u4e00\u79cd\u53d7\u7ec4\u7ec7\u8bb0\u5fc6\u7406\u8bba\u542f\u53d1\u7684\u5206\u5c42\u8bb0\u5fc6\u7cfb\u7edf\uff0c\u901a\u8fc7\u4e09\u5c42\u56fe\u7ed3\u6784\uff08\u6d1e\u5bdf\u56fe\u3001\u67e5\u8be2\u56fe\u548c\u4ea4\u4e92\u56fe\uff09\u7ba1\u7406\u667a\u80fd\u4f53\u95f4\u7684\u4ea4\u4e92\uff0c\u5e76\u652f\u6301\u53cc\u5411\u8bb0\u5fc6\u68c0\u7d22\u3002", "result": "\u5728\u4e94\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u3001\u4e09\u79cdLLM\u9aa8\u5e72\u548c\u4e09\u79cd\u6d41\u884cMAS\u6846\u67b6\u4e2d\uff0cG-Memory\u663e\u8457\u63d0\u5347\u4e86\u4efb\u52a1\u6210\u529f\u7387\uff08\u6700\u9ad820.89%\uff09\u548c\u77e5\u8bc6\u95ee\u7b54\u51c6\u786e\u7387\uff08\u6700\u9ad810.12%\uff09\u3002", "conclusion": "G-Memory\u901a\u8fc7\u5206\u5c42\u8bb0\u5fc6\u67b6\u6784\u6709\u6548\u89e3\u51b3\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u8bb0\u5fc6\u9650\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u6027\u80fd\uff0c\u4e14\u65e0\u9700\u4fee\u6539\u539f\u6709\u6846\u67b6\u3002"}}
{"id": "2506.07400", "pdf": "https://arxiv.org/pdf/2506.07400", "abs": "https://arxiv.org/abs/2506.07400", "authors": ["Philip Liu", "Sparsh Bansal", "Jimmy Dinh", "Aditya Pawar", "Ramani Satishkumar", "Shail Desai", "Neeraj Gupta", "Xin Wang", "Shu Hu"], "title": "MedChat: A Multi-Agent Framework for Multimodal Diagnosis with Large Language Models", "categories": ["cs.MA", "cs.AI", "cs.CV", "cs.LG"], "comment": "7 pages, 6 figures. Accepted to the 2025 IEEE 8th International\n  Conference on Multimedia Information Processing and Retrieval (MIPR). Code\n  and platform available at https://github.com/Purdue-M2/MedChat", "summary": "The integration of deep learning-based glaucoma detection with large language\nmodels (LLMs) presents an automated strategy to mitigate ophthalmologist\nshortages and improve clinical reporting efficiency. However, applying general\nLLMs to medical imaging remains challenging due to hallucinations, limited\ninterpretability, and insufficient domain-specific medical knowledge, which can\npotentially reduce clinical accuracy. Although recent approaches combining\nimaging models with LLM reasoning have improved reporting, they typically rely\non a single generalist agent, restricting their capacity to emulate the diverse\nand complex reasoning found in multidisciplinary medical teams. To address\nthese limitations, we propose MedChat, a multi-agent diagnostic framework and\nplatform that combines specialized vision models with multiple role-specific\nLLM agents, all coordinated by a director agent. This design enhances\nreliability, reduces hallucination risk, and enables interactive diagnostic\nreporting through an interface tailored for clinical review and educational\nuse. Code available at https://github.com/Purdue-M2/MedChat.", "AI": {"tldr": "MedChat\u662f\u4e00\u4e2a\u591a\u4ee3\u7406\u8bca\u65ad\u6846\u67b6\uff0c\u7ed3\u5408\u4e13\u4e1a\u89c6\u89c9\u6a21\u578b\u548c\u89d2\u8272\u7279\u5b9a\u7684LLM\u4ee3\u7406\uff0c\u901a\u8fc7\u534f\u8c03\u4ee3\u7406\u63d0\u5347\u9752\u5149\u773c\u68c0\u6d4b\u7684\u53ef\u9760\u6027\u548c\u62a5\u544a\u6548\u7387\u3002", "motivation": "\u89e3\u51b3\u901a\u7528LLM\u5728\u533b\u5b66\u5f71\u50cf\u4e2d\u5b58\u5728\u7684\u5e7b\u89c9\u3001\u89e3\u91ca\u6027\u4e0d\u8db3\u548c\u9886\u57df\u77e5\u8bc6\u7f3a\u4e4f\u95ee\u9898\uff0c\u540c\u65f6\u6a21\u62df\u591a\u5b66\u79d1\u533b\u7597\u56e2\u961f\u7684\u590d\u6742\u63a8\u7406\u3002", "method": "\u63d0\u51faMedChat\u6846\u67b6\uff0c\u7ed3\u5408\u4e13\u4e1a\u89c6\u89c9\u6a21\u578b\u548c\u591a\u4e2a\u89d2\u8272\u7279\u5b9a\u7684LLM\u4ee3\u7406\uff0c\u7531\u534f\u8c03\u4ee3\u7406\u7edf\u4e00\u7ba1\u7406\u3002", "result": "\u63d0\u9ad8\u4e86\u8bca\u65ad\u53ef\u9760\u6027\uff0c\u51cf\u5c11\u5e7b\u89c9\u98ce\u9669\uff0c\u652f\u6301\u4ea4\u4e92\u5f0f\u8bca\u65ad\u62a5\u544a\u751f\u6210\u3002", "conclusion": "MedChat\u4e3a\u533b\u5b66\u5f71\u50cf\u8bca\u65ad\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u53ef\u9760\u3001\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u4e34\u5e8a\u548c\u6559\u80b2\u573a\u666f\u3002"}}
{"id": "2506.07428", "pdf": "https://arxiv.org/pdf/2506.07428", "abs": "https://arxiv.org/abs/2506.07428", "authors": ["Yuling Wang", "Zihui Chen", "Pengfei Jiao", "Xiao Wang"], "title": "HeTa: Relation-wise Heterogeneous Graph Foundation Attack Model", "categories": ["cs.AI", "cs.LG"], "comment": "Accepted by IJCAI 2025", "summary": "Heterogeneous Graph Neural Networks (HGNNs) are vulnerable, highlighting the\nneed for tailored attacks to assess their robustness and ensure security.\nHowever, existing HGNN attacks often require complex retraining of parameters\nto generate specific perturbations for new scenarios. Recently, foundation\nmodels have opened new horizons for the generalization of graph neural networks\nby capturing shared semantics across various graph distributions. This leads us\nto ask:Can we design a foundation attack model for HGNNs that enables\ngeneralizable perturbations across different HGNNs, and quickly adapts to new\nheterogeneous graphs (HGs)? Empirical findings reveal that, despite significant\ndifferences in model design and parameter space, different HGNNs surprisingly\nshare common vulnerability patterns from a relation-aware perspective.\nTherefore, we explore how to design foundation HGNN attack criteria by mining\nshared attack units. In this paper, we propose a novel relation-wise\nheterogeneous graph foundation attack model, HeTa. We introduce a foundation\nsurrogate model to align heterogeneity and identify the importance of shared\nrelation-aware attack units. Building on this, we implement a serialized\nrelation-by-relation attack based on the identified relational weights. In this\nway, the perturbation can be transferred to various target HGNNs and easily\nfine-tuned for new HGs. Extensive experiments exhibit powerful attack\nperformances and generalizability of our method.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aHeTa\u7684\u5173\u7cfb\u611f\u77e5\u5f02\u6784\u56fe\u57fa\u7840\u653b\u51fb\u6a21\u578b\uff0c\u901a\u8fc7\u6316\u6398\u5171\u4eab\u653b\u51fb\u5355\u5143\u5b9e\u73b0\u901a\u7528\u6270\u52a8\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u5f3a\u5927\u7684\u653b\u51fb\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5f02\u6784\u56fe\u795e\u7ecf\u7f51\u7edc\uff08HGNNs\uff09\u6613\u53d7\u653b\u51fb\uff0c\u73b0\u6709\u653b\u51fb\u65b9\u6cd5\u9700\u590d\u6742\u53c2\u6570\u91cd\u8bad\u7ec3\uff0c\u65e0\u6cd5\u5feb\u901f\u9002\u5e94\u65b0\u573a\u666f\u3002\u57fa\u7840\u6a21\u578b\u7684\u51fa\u73b0\u4e3a\u6cdb\u5316\u653b\u51fb\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "method": "\u63d0\u51faHeTa\u6a21\u578b\uff0c\u5229\u7528\u57fa\u7840\u4ee3\u7406\u6a21\u578b\u5bf9\u9f50\u5f02\u8d28\u6027\u5e76\u8bc6\u522b\u5171\u4eab\u5173\u7cfb\u611f\u77e5\u653b\u51fb\u5355\u5143\uff0c\u5b9e\u73b0\u57fa\u4e8e\u5173\u7cfb\u6743\u91cd\u7684\u5e8f\u5217\u5316\u653b\u51fb\u3002", "result": "\u5b9e\u9a8c\u8868\u660eHeTa\u5728\u653b\u51fb\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u80fd\u5feb\u901f\u9002\u5e94\u65b0\u5f02\u6784\u56fe\u3002", "conclusion": "HeTa\u4e3aHGNNs\u63d0\u4f9b\u4e86\u4e00\u79cd\u901a\u7528\u4e14\u9ad8\u6548\u7684\u57fa\u7840\u653b\u51fb\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86\u5171\u4eab\u6f0f\u6d1e\u6a21\u5f0f\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2506.07435", "pdf": "https://arxiv.org/pdf/2506.07435", "abs": "https://arxiv.org/abs/2506.07435", "authors": ["Alexander Kolpakov", "Igor Rivin"], "title": "Fast Geometric Embedding for Node Influence Maximization", "categories": ["cs.SI", "cs.AI", "cs.LG", "E.1; G.2.2; G.4"], "comment": "8 pages, 4 figures, 18 tables; Github repository available\n  (https://github.com/sashakolpakov/graphem/); Package available on PyPi\n  (https://pypi.org/project/graphem-jax/)", "summary": "Computing classical centrality measures such as betweenness and closeness is\ncomputationally expensive on large-scale graphs. In this work, we introduce an\nefficient force layout algorithm that embeds a graph into a low-dimensional\nspace, where the radial distance from the origin serves as a proxy for various\ncentrality measures. We evaluate our method on multiple graph families and\ndemonstrate strong correlations with degree, PageRank, and paths-based\ncentralities. As an application, it turns out that the proposed embedding\nallows to find high-influence nodes in a network, and provides a fast and\nscalable alternative to the standard greedy algorithm.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u529b\u5bfc\u5411\u5e03\u5c40\u7b97\u6cd5\uff0c\u5c06\u56fe\u5d4c\u5165\u4f4e\u7ef4\u7a7a\u95f4\uff0c\u7528\u5f84\u5411\u8ddd\u79bb\u4f5c\u4e3a\u4e2d\u5fc3\u6027\u5ea6\u91cf\u7684\u4ee3\u7406\u3002", "motivation": "\u5927\u89c4\u6a21\u56fe\u4e0a\u8ba1\u7b97\u4f20\u7edf\u4e2d\u5fc3\u6027\u5ea6\u91cf\uff08\u5982\u4ecb\u6570\u548c\u63a5\u8fd1\u5ea6\uff09\u8ba1\u7b97\u6210\u672c\u9ad8\u3002", "method": "\u4f7f\u7528\u529b\u5bfc\u5411\u5e03\u5c40\u7b97\u6cd5\u5c06\u56fe\u5d4c\u5165\u4f4e\u7ef4\u7a7a\u95f4\uff0c\u5f84\u5411\u8ddd\u79bb\u4f5c\u4e3a\u4e2d\u5fc3\u6027\u5ea6\u91cf\u7684\u66ff\u4ee3\u3002", "result": "\u5728\u591a\u79cd\u56fe\u5bb6\u65cf\u4e0a\u9a8c\u8bc1\uff0c\u4e0e\u5ea6\u3001PageRank\u548c\u8def\u5f84\u4e2d\u5fc3\u6027\u6709\u5f3a\u76f8\u5173\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u5feb\u901f\u627e\u5230\u7f51\u7edc\u4e2d\u7684\u9ad8\u5f71\u54cd\u529b\u8282\u70b9\uff0c\u662f\u6807\u51c6\u8d2a\u5a6a\u7b97\u6cd5\u7684\u5feb\u901f\u53ef\u6269\u5c55\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2506.07458", "pdf": "https://arxiv.org/pdf/2506.07458", "abs": "https://arxiv.org/abs/2506.07458", "authors": ["Yuxin Xiao", "Shan Chen", "Jack Gallifant", "Danielle Bitterman", "Thomas Hartvigsen", "Marzyeh Ghassemi"], "title": "KScope: A Framework for Characterizing the Knowledge Status of Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Characterizing a large language model's (LLM's) knowledge of a given question\nis challenging. As a result, prior work has primarily examined LLM behavior\nunder knowledge conflicts, where the model's internal parametric memory\ncontradicts information in the external context. However, this does not fully\nreflect how well the model knows the answer to the question. In this paper, we\nfirst introduce a taxonomy of five knowledge statuses based on the consistency\nand correctness of LLM knowledge modes. We then propose KScope, a hierarchical\nframework of statistical tests that progressively refines hypotheses about\nknowledge modes and characterizes LLM knowledge into one of these five\nstatuses. We apply KScope to nine LLMs across four datasets and systematically\nestablish: (1) Supporting context narrows knowledge gaps across models. (2)\nContext features related to difficulty, relevance, and familiarity drive\nsuccessful knowledge updates. (3) LLMs exhibit similar feature preferences when\npartially correct or conflicted, but diverge sharply when consistently wrong.\n(4) Context summarization constrained by our feature analysis, together with\nenhanced credibility, further improves update effectiveness and generalizes\nacross LLMs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aKScope\u7684\u5206\u5c42\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u77e5\u8bc6\u72b6\u6001\uff0c\u5e76\u5c06\u5176\u5206\u4e3a\u4e94\u79cd\u7c7b\u578b\u3002\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u4e0a\u4e0b\u6587\u652f\u6301\u3001\u7279\u5f81\u5206\u6790\u548c\u603b\u7ed3\u5bf9\u77e5\u8bc6\u66f4\u65b0\u7684\u5f71\u54cd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8LLM\u5728\u77e5\u8bc6\u51b2\u7a81\u4e0b\u7684\u884c\u4e3a\uff0c\u4f46\u672a\u80fd\u5168\u9762\u8bc4\u4f30\u6a21\u578b\u5bf9\u95ee\u9898\u7684\u77e5\u8bc6\u638c\u63e1\u7a0b\u5ea6\u3002", "method": "\u63d0\u51fa\u4e86KScope\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5c42\u7edf\u8ba1\u6d4b\u8bd5\u5c06LLM\u7684\u77e5\u8bc6\u72b6\u6001\u5206\u4e3a\u4e94\u79cd\u7c7b\u578b\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u6a21\u578b\u4e0a\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0a\u4e0b\u6587\u652f\u6301\u7f29\u5c0f\u4e86\u77e5\u8bc6\u5dee\u8ddd\uff0c\u7279\u5b9a\u7279\u5f81\uff08\u5982\u96be\u5ea6\u3001\u76f8\u5173\u6027\u548c\u719f\u6089\u5ea6\uff09\u9a71\u52a8\u4e86\u77e5\u8bc6\u66f4\u65b0\uff0c\u4e0d\u540cLLM\u5728\u77e5\u8bc6\u72b6\u6001\u4e0b\u7684\u884c\u4e3a\u5b58\u5728\u5dee\u5f02\u3002", "conclusion": "KScope\u6846\u67b6\u80fd\u591f\u7cfb\u7edf\u8bc4\u4f30LLM\u7684\u77e5\u8bc6\u72b6\u6001\uff0c\u4e0a\u4e0b\u6587\u603b\u7ed3\u548c\u7279\u5f81\u5206\u6790\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u77e5\u8bc6\u66f4\u65b0\u7684\u6548\u679c\u3002"}}
{"id": "2506.07484", "pdf": "https://arxiv.org/pdf/2506.07484", "abs": "https://arxiv.org/abs/2506.07484", "authors": ["Dasol Hong", "Wooju Lee", "Hyun Myung"], "title": "CoCoA-Mix: Confusion-and-Confidence-Aware Mixture Model for Context Optimization", "categories": ["cs.CV", "cs.AI", "cs.LG", "I.2.6; I.5.2"], "comment": "8 pages, 5 figures; accepted at ICML 2025", "summary": "Prompt tuning, which adapts vision-language models by freezing model\nparameters and optimizing only the prompt, has proven effective for\ntask-specific adaptations. The core challenge in prompt tuning is improving\nspecialization for a specific task and generalization for unseen domains.\nHowever, frozen encoders often produce misaligned features, leading to\nconfusion between classes and limiting specialization. To overcome this issue,\nwe propose a confusion-aware loss (CoA-loss) that improves specialization by\nrefining the decision boundaries between confusing classes. Additionally, we\nmathematically demonstrate that a mixture model can enhance generalization\nwithout compromising specialization. This is achieved using confidence-aware\nweights (CoA-weights), which adjust the weights of each prediction in the\nmixture model based on its confidence within the class domains. Extensive\nexperiments show that CoCoA-Mix, a mixture model with CoA-loss and CoA-weights,\noutperforms state-of-the-art methods by enhancing specialization and\ngeneralization. Our code is publicly available at\nhttps://github.com/url-kaist/CoCoA-Mix.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6df7\u6dc6\u611f\u77e5\u635f\u5931\uff08CoA-loss\uff09\u548c\u7f6e\u4fe1\u611f\u77e5\u6743\u91cd\uff08CoA-weights\uff09\u7684\u6df7\u5408\u6a21\u578b\uff08CoCoA-Mix\uff09\uff0c\u4ee5\u63d0\u5347\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u4efb\u52a1\u7279\u5b9a\u9002\u5e94\u4e2d\u7684\u4e13\u4e1a\u5316\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u51bb\u7ed3\u7f16\u7801\u5668\u5e38\u5bfc\u81f4\u7279\u5f81\u4e0d\u5bf9\u9f50\uff0c\u5f15\u53d1\u7c7b\u522b\u6df7\u6dc6\uff0c\u9650\u5236\u4e86\u6a21\u578b\u7684\u4e13\u4e1a\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51faCoA-loss\u4f18\u5316\u51b3\u7b56\u8fb9\u754c\u4ee5\u51cf\u5c11\u6df7\u6dc6\uff0c\u5e76\u5229\u7528CoA-weights\u5728\u6df7\u5408\u6a21\u578b\u4e2d\u8c03\u6574\u9884\u6d4b\u6743\u91cd\u4ee5\u589e\u5f3a\u6cdb\u5316\u3002", "result": "CoCoA-Mix\u5728\u4e13\u4e1a\u5316\u548c\u6cdb\u5316\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "CoCoA-Mix\u901a\u8fc7\u6539\u8fdb\u51b3\u7b56\u8fb9\u754c\u548c\u9884\u6d4b\u6743\u91cd\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2506.07527", "pdf": "https://arxiv.org/pdf/2506.07527", "abs": "https://arxiv.org/abs/2506.07527", "authors": ["Lu Ma", "Hao Liang", "Meiyi Qiang", "Lexiang Tang", "Xiaochen Ma", "Zhen Hao Wong", "Junbo Niu", "Chengyu Shen", "Runming He", "Bin Cui", "Wentao Zhang"], "title": "Learning What Reinforcement Learning Can't: Interleaved Online Fine-Tuning for Hardest Questions", "categories": ["cs.AI", "cs.LG"], "comment": "12 pages, 5 figures", "summary": "Recent advances in large language model (LLM) reasoning have shown that\nsophisticated behaviors such as planning and self-reflection can emerge through\nreinforcement learning (RL). However, despite these successes, RL in its\ncurrent form remains insufficient to induce capabilities that exceed the\nlimitations of the base model, as it is primarily optimized based on existing\nknowledge of the model rather than facilitating the acquisition of new\ninformation. To address this limitation, we employ supervised fine-tuning (SFT)\nto learn what RL cannot, which enables the incorporation of new knowledge and\nreasoning patterns by leveraging high-quality demonstration data. We analyze\nthe training dynamics of RL and SFT for LLM reasoning and find that RL excels\nat maintaining and improving performance on questions within the model's\noriginal capabilities, while SFT is more effective at enabling progress on\nquestions beyond the current scope of the model. Motivated by the complementary\nstrengths of RL and SFT, we introduce a novel training approach,\n\\textbf{ReLIFT} (\\textbf{Re}inforcement \\textbf{L}earning \\textbf{I}nterleaved\nwith Online \\textbf{F}ine-\\textbf{T}uning). In ReLIFT, the model is primarily\ntrained using RL, but when it encounters challenging questions, high-quality\nsolutions are collected for fine-tuning, and the training process alternates\nbetween RL and fine-tuning to enhance the model's reasoning abilities. ReLIFT\nachieves an average improvement of over +5.2 points across five\ncompetition-level benchmarks and one out-of-distribution benchmark compared to\nother zero-RL models. Furthermore, we demonstrate that ReLIFT outperforms both\nRL and SFT while using only 13\\% of the detailed demonstration data,\nhighlighting its scalability. These results provide compelling evidence that\nReLIFT overcomes the fundamental limitations of RL and underscores the\nsignificant potential.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aReLIFT\u7684\u65b0\u8bad\u7ec3\u65b9\u6cd5\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u548c\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\uff0c\u4ee5\u514b\u670dRL\u5728\u6269\u5c55\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u63a8\u7406\u80fd\u529b\u4e0a\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u5c3d\u7ba1RL\u5728LLM\u63a8\u7406\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u65e0\u6cd5\u8d85\u8d8a\u6a21\u578b\u7684\u57fa\u7840\u80fd\u529b\uff0c\u800cSFT\u53ef\u4ee5\u5f15\u5165\u65b0\u77e5\u8bc6\u548c\u63a8\u7406\u6a21\u5f0f\u3002\u56e0\u6b64\uff0c\u7ed3\u5408\u4e24\u8005\u7684\u4f18\u52bf\u6210\u4e3a\u7814\u7a76\u52a8\u673a\u3002", "method": "\u63d0\u51faReLIFT\u65b9\u6cd5\uff0c\u4ea4\u66ff\u4f7f\u7528RL\u548c\u5728\u7ebf\u5fae\u8c03\uff08SFT\uff09\uff0c\u5728\u9047\u5230\u96be\u9898\u65f6\u6536\u96c6\u9ad8\u8d28\u91cf\u89e3\u51b3\u65b9\u6848\u8fdb\u884c\u5fae\u8c03\u3002", "result": "ReLIFT\u5728\u4e94\u4e2a\u7ade\u8d5b\u7ea7\u57fa\u51c6\u548c\u4e00\u4e2a\u5206\u5e03\u5916\u57fa\u51c6\u4e0a\u5e73\u5747\u63d0\u53475.2\u5206\uff0c\u4e14\u4ec5\u970013%\u7684\u8be6\u7ec6\u6f14\u793a\u6570\u636e\u3002", "conclusion": "ReLIFT\u6709\u6548\u514b\u670d\u4e86RL\u7684\u5c40\u9650\u6027\uff0c\u5c55\u793a\u4e86\u7ed3\u5408RL\u548cSFT\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.07575", "pdf": "https://arxiv.org/pdf/2506.07575", "abs": "https://arxiv.org/abs/2506.07575", "authors": ["Ruiyang Zhang", "Hu Zhang", "Hao Fei", "Zhedong Zheng"], "title": "Uncertainty-o: One Model-agnostic Framework for Unveiling Uncertainty in Large Multimodal Models", "categories": ["cs.CV", "cs.LG"], "comment": "Project page: https://uncertainty-o.github.io/", "summary": "Large Multimodal Models (LMMs), harnessing the complementarity among diverse\nmodalities, are often considered more robust than pure Language Large Models\n(LLMs); yet do LMMs know what they do not know? There are three key open\nquestions remaining: (1) how to evaluate the uncertainty of diverse LMMs in a\nunified manner, (2) how to prompt LMMs to show its uncertainty, and (3) how to\nquantify uncertainty for downstream tasks. In an attempt to address these\nchallenges, we introduce Uncertainty-o: (1) a model-agnostic framework designed\nto reveal uncertainty in LMMs regardless of their modalities, architectures, or\ncapabilities, (2) an empirical exploration of multimodal prompt perturbations\nto uncover LMM uncertainty, offering insights and findings, and (3) derive the\nformulation of multimodal semantic uncertainty, which enables quantifying\nuncertainty from multimodal responses. Experiments across 18 benchmarks\nspanning various modalities and 10 LMMs (both open- and closed-source)\ndemonstrate the effectiveness of Uncertainty-o in reliably estimating LMM\nuncertainty, thereby enhancing downstream tasks such as hallucination\ndetection, hallucination mitigation, and uncertainty-aware Chain-of-Thought\nreasoning.", "AI": {"tldr": "Uncertainty-o\u662f\u4e00\u4e2a\u6a21\u578b\u65e0\u5173\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u548c\u63ed\u793a\u591a\u6a21\u6001\u6a21\u578b\uff08LMMs\uff09\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u5728\u591a\u79cd\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5c3d\u7ba1\u591a\u6a21\u6001\u6a21\u578b\uff08LMMs\uff09\u88ab\u8ba4\u4e3a\u6bd4\u7eaf\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u66f4\u9c81\u68d2\uff0c\u4f46\u5176\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u4ecd\u5b58\u5728\u4e09\u4e2a\u5173\u952e\u95ee\u9898\uff1a\u7edf\u4e00\u8bc4\u4f30\u65b9\u6cd5\u3001\u5982\u4f55\u63d0\u793aLMMs\u5c55\u793a\u4e0d\u786e\u5b9a\u6027\uff0c\u4ee5\u53ca\u5982\u4f55\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\u4ee5\u652f\u6301\u4e0b\u6e38\u4efb\u52a1\u3002", "method": "\u63d0\u51fa\u4e86Uncertainty-o\u6846\u67b6\uff0c\u5305\u62ec\u6a21\u578b\u65e0\u5173\u7684\u4e0d\u786e\u5b9a\u6027\u63ed\u793a\u65b9\u6cd5\u3001\u591a\u6a21\u6001\u63d0\u793a\u6270\u52a8\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u4ee5\u53ca\u591a\u6a21\u6001\u8bed\u4e49\u4e0d\u786e\u5b9a\u6027\u7684\u91cf\u5316\u516c\u5f0f\u3002", "result": "\u572818\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u548c10\u79cdLMMs\uff08\u5f00\u6e90\u548c\u95ed\u6e90\uff09\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cUncertainty-o\u80fd\u53ef\u9760\u5730\u4f30\u8ba1LMMs\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u63d0\u5347\u4e0b\u6e38\u4efb\u52a1\uff08\u5982\u5e7b\u89c9\u68c0\u6d4b\u548c\u7f13\u89e3\uff09\u7684\u6027\u80fd\u3002", "conclusion": "Uncertainty-o\u4e3a\u591a\u6a21\u6001\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u7edf\u4e00\u4e14\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u652f\u6301\u5176\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2506.07590", "pdf": "https://arxiv.org/pdf/2506.07590", "abs": "https://arxiv.org/abs/2506.07590", "authors": ["Jiacheng Shi", "Yanfu Zhang", "Huajie Shao", "Ashley Gao"], "title": "Explore the vulnerability of black-box models via diffusion models", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Recent advancements in diffusion models have enabled high-fidelity and\nphotorealistic image generation across diverse applications. However, these\nmodels also present security and privacy risks, including copyright violations,\nsensitive information leakage, and the creation of harmful or offensive content\nthat could be exploited maliciously. In this study, we uncover a novel security\nthreat where an attacker leverages diffusion model APIs to generate synthetic\nimages, which are then used to train a high-performing substitute model. This\nenables the attacker to execute model extraction and transfer-based adversarial\nattacks on black-box classification models with minimal queries, without\nneeding access to the original training data. The generated images are\nsufficiently high-resolution and diverse to train a substitute model whose\noutputs closely match those of the target model. Across the seven benchmarks,\nincluding CIFAR and ImageNet subsets, our method shows an average improvement\nof 27.37% over state-of-the-art methods while using just 0.01 times of the\nquery budget, achieving a 98.68% success rate in adversarial attacks on the\ntarget model.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u6269\u6563\u6a21\u578bAPI\u53ef\u80fd\u88ab\u7528\u4e8e\u751f\u6210\u5408\u6210\u56fe\u50cf\u4ee5\u8bad\u7ec3\u66ff\u4ee3\u6a21\u578b\uff0c\u4ece\u800c\u5bf9\u9ed1\u76d2\u5206\u7c7b\u6a21\u578b\u53d1\u8d77\u9ad8\u6548\u653b\u51fb\uff0c\u6210\u529f\u7387\u8fbe98.68%\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u7684\u9ad8\u4fdd\u771f\u56fe\u50cf\u751f\u6210\u80fd\u529b\u53ef\u80fd\u88ab\u6076\u610f\u5229\u7528\uff0c\u5e26\u6765\u5b89\u5168\u548c\u9690\u79c1\u98ce\u9669\uff0c\u5982\u7248\u6743\u4fb5\u72af\u548c\u654f\u611f\u4fe1\u606f\u6cc4\u9732\u3002", "method": "\u653b\u51fb\u8005\u5229\u7528\u6269\u6563\u6a21\u578bAPI\u751f\u6210\u5408\u6210\u56fe\u50cf\uff0c\u8bad\u7ec3\u66ff\u4ee3\u6a21\u578b\uff0c\u4ee5\u6700\u5c0f\u67e5\u8be2\u91cf\u5b9e\u73b0\u5bf9\u9ed1\u76d2\u6a21\u578b\u7684\u63d0\u53d6\u548c\u5bf9\u6297\u653b\u51fb\u3002", "result": "\u57287\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u65b9\u6cd5\u6bd4\u73b0\u6709\u6280\u672f\u5e73\u5747\u63d0\u534727.37%\uff0c\u4ec5\u75280.01\u500d\u67e5\u8be2\u91cf\uff0c\u5bf9\u6297\u653b\u51fb\u6210\u529f\u7387\u8fbe98.68%\u3002", "conclusion": "\u6269\u6563\u6a21\u578bAPI\u7684\u5b89\u5168\u98ce\u9669\u9700\u5f15\u8d77\u91cd\u89c6\uff0c\u672a\u6765\u9700\u5f00\u53d1\u9632\u5fa1\u673a\u5236\u4ee5\u5e94\u5bf9\u6b64\u7c7b\u653b\u51fb\u3002"}}
{"id": "2506.07605", "pdf": "https://arxiv.org/pdf/2506.07605", "abs": "https://arxiv.org/abs/2506.07605", "authors": ["Marco Di Gennaro", "Giovanni De Lucia", "Stefano Longari", "Stefano Zanero", "Michele Carminati"], "title": "TimberStrike: Dataset Reconstruction Attack Revealing Privacy Leakage in Federated Tree-Based Systems", "categories": ["cs.CR", "cs.DC", "cs.LG"], "comment": "Proceedings on Privacy Enhancing Technologies (To appear) 2025(4)", "summary": "Federated Learning has emerged as a privacy-oriented alternative to\ncentralized Machine Learning, enabling collaborative model training without\ndirect data sharing. While extensively studied for neural networks, the\nsecurity and privacy implications of tree-based models remain underexplored.\nThis work introduces TimberStrike, an optimization-based dataset reconstruction\nattack targeting horizontally federated tree-based models. Our attack, carried\nout by a single client, exploits the discrete nature of decision trees by using\nsplit values and decision paths to infer sensitive training data from other\nclients. We evaluate TimberStrike on State-of-the-Art federated gradient\nboosting implementations across multiple frameworks, including Flower, NVFlare,\nand FedTree, demonstrating their vulnerability to privacy breaches. On a\npublicly available stroke prediction dataset, TimberStrike consistently\nreconstructs between 73.05% and 95.63% of the target dataset across all\nimplementations. We further analyze Differential Privacy, showing that while it\npartially mitigates the attack, it also significantly degrades model\nperformance. Our findings highlight the need for privacy-preserving mechanisms\nspecifically designed for tree-based Federated Learning systems, and we provide\npreliminary insights into their design.", "AI": {"tldr": "TimberStrike\u662f\u4e00\u79cd\u9488\u5bf9\u6c34\u5e73\u8054\u90a6\u6811\u6a21\u578b\u7684\u4f18\u5316\u6570\u636e\u96c6\u91cd\u5efa\u653b\u51fb\uff0c\u901a\u8fc7\u51b3\u7b56\u6811\u7684\u5206\u88c2\u503c\u548c\u8def\u5f84\u63a8\u65ad\u654f\u611f\u6570\u636e\uff0c\u63ed\u793a\u4e86\u73b0\u6709\u8054\u90a6\u68af\u5ea6\u63d0\u5347\u5b9e\u73b0\u7684\u9690\u79c1\u6f0f\u6d1e\u3002", "motivation": "\u7814\u7a76\u6811\u6a21\u578b\u5728\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u5b89\u5168\u6027\u548c\u9690\u79c1\u95ee\u9898\uff0c\u586b\u8865\u73b0\u6709\u7814\u7a76\u7684\u7a7a\u767d\u3002", "method": "\u63d0\u51faTimberStrike\u653b\u51fb\uff0c\u5229\u7528\u51b3\u7b56\u6811\u7684\u79bb\u6563\u7279\u6027\uff0c\u901a\u8fc7\u5206\u88c2\u503c\u548c\u51b3\u7b56\u8def\u5f84\u91cd\u5efa\u6570\u636e\u96c6\u3002", "result": "\u5728\u591a\u4e2a\u6846\u67b6\u4e2d\uff0c\u653b\u51fb\u6210\u529f\u91cd\u5efa\u4e8673.05%\u81f395.63%\u7684\u76ee\u6807\u6570\u636e\u96c6\uff0c\u5dee\u5206\u9690\u79c1\u90e8\u5206\u7f13\u89e3\u653b\u51fb\u4f46\u635f\u5bb3\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "\u9700\u8bbe\u8ba1\u4e13\u95e8\u9488\u5bf9\u6811\u6a21\u578b\u7684\u9690\u79c1\u4fdd\u62a4\u673a\u5236\uff0c\u4ee5\u5e73\u8861\u9690\u79c1\u548c\u6027\u80fd\u3002"}}
{"id": "2506.07614", "pdf": "https://arxiv.org/pdf/2506.07614", "abs": "https://arxiv.org/abs/2506.07614", "authors": ["Rishikesh Srinivasan", "Dheeraj Nagaraj"], "title": "Poisson Midpoint Method for Log Concave Sampling: Beyond the Strong Error Lower Bounds", "categories": ["math.PR", "cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "We study the problem of sampling from strongly log-concave distributions over\n$\\mathbb{R}^d$ using the Poisson midpoint discretization (a variant of the\nrandomized midpoint method) for overdamped/underdamped Langevin dynamics. We\nprove its convergence in the 2-Wasserstein distance ($W_2$), achieving a cubic\nspeedup in dependence on the target accuracy ($\\epsilon$) over the\nEuler-Maruyama discretization, surpassing existing bounds for randomized\nmidpoint methods. Notably, in the case of underdamped Langevin dynamics, we\ndemonstrate the complexity of $W_2$ convergence is much smaller than the\ncomplexity lower bounds for convergence in $L^2$ strong error established in\nthe literature.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u4f7f\u7528\u6cca\u677e\u4e2d\u70b9\u79bb\u6563\u5316\u65b9\u6cd5\u4ece\u5f3a\u5bf9\u6570\u51f9\u5206\u5e03\u4e2d\u91c7\u6837\u7684\u6536\u655b\u6027\uff0c\u76f8\u6bd4\u6b27\u62c9-\u9a6c\u9c81\u4e9a\u9a6c\u79bb\u6563\u5316\uff0c\u5728\u76ee\u6807\u7cbe\u5ea6\u4e0a\u5b9e\u73b0\u4e86\u4e09\u6b21\u52a0\u901f\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u9ad8\u6548\u5730\u4ece\u5f3a\u5bf9\u6570\u51f9\u5206\u5e03\u4e2d\u91c7\u6837\uff0c\u7279\u522b\u662f\u5728\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\uff0c\u4ee5\u63d0\u5347\u91c7\u6837\u6548\u7387\u548c\u7cbe\u5ea6\u3002", "method": "\u91c7\u7528\u6cca\u677e\u4e2d\u70b9\u79bb\u6563\u5316\u65b9\u6cd5\uff08\u968f\u673a\u4e2d\u70b9\u65b9\u6cd5\u7684\u53d8\u4f53\uff09\u5e94\u7528\u4e8e\u8fc7\u963b\u5c3c/\u6b20\u963b\u5c3c\u6717\u4e4b\u4e07\u52a8\u529b\u5b66\uff0c\u5e76\u5206\u6790\u5176\u57282-Wasserstein\u8ddd\u79bb\u4e0b\u7684\u6536\u655b\u6027\u3002", "result": "\u5728\u76ee\u6807\u7cbe\u5ea6\u4e0a\u5b9e\u73b0\u4e86\u4e09\u6b21\u52a0\u901f\uff0c\u4e14\u5728\u6b20\u963b\u5c3c\u6717\u4e4b\u4e07\u52a8\u529b\u5b66\u4e2d\uff0c\u590d\u6742\u5ea6\u8fdc\u4f4e\u4e8e\u6587\u732e\u4e2d\u5efa\u7acb\u7684L2\u5f3a\u8bef\u5dee\u6536\u655b\u7684\u4e0b\u754c\u3002", "conclusion": "\u6cca\u677e\u4e2d\u70b9\u79bb\u6563\u5316\u65b9\u6cd5\u5728\u91c7\u6837\u6548\u7387\u548c\u7cbe\u5ea6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u6b20\u963b\u5c3c\u6717\u4e4b\u4e07\u52a8\u529b\u5b66\u4e2d\u8868\u73b0\u7a81\u51fa\u3002"}}
{"id": "2506.07621", "pdf": "https://arxiv.org/pdf/2506.07621", "abs": "https://arxiv.org/abs/2506.07621", "authors": ["Harsh Bihany", "Shubham Patel", "Ashutosh Modi"], "title": "LoRMA: Low-Rank Multiplicative Adaptation for LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted at ACL Findings 2025; 21 pages (9 main paper + 5 pages\n  references + 7 pages appendix)", "summary": "Large Language Models have shown remarkable capabilities in the NLP domain.\nTheir effectiveness can mainly be attributed to their ability to adapt to an\narray of downstream tasks. However, generally, full fine-tuning is a\ncomputationally expensive job. To mitigate this, many techniques have been\ndeveloped that prime efficiency, a prominent one being Low-Rank Adaptation\n(LoRA). However, LoRA and its variants employ re-parametrized additive updates.\nIn this paper, we propose Low-Rank Multiplicative Adaptation (LoRMA), which\nshifts the paradigm of additive updates to a richer space of matrix\nmultiplicative transformations. We tackle challenges such as computational\ncomplexity and rank bottleneck of matrix multiplication by effectively\nre-ordering operations and introducing rank inflation strategies. We conduct\nextensive experiments to demonstrate the effectiveness of our approach in terms\nof various evaluation metrics.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLoRMA\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u77e9\u9635\u4e58\u6cd5\u53d8\u6362\u66ff\u4ee3\u4f20\u7edf\u7684\u52a0\u6cd5\u66f4\u65b0\uff0c\u89e3\u51b3\u4e86\u8ba1\u7b97\u590d\u6742\u6027\u548c\u79e9\u74f6\u9888\u95ee\u9898\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728NLP\u9886\u57df\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b8c\u5168\u5fae\u8c03\u8ba1\u7b97\u6210\u672c\u9ad8\u3002\u73b0\u6709\u65b9\u6cd5\u5982LoRA\u91c7\u7528\u52a0\u6cd5\u66f4\u65b0\uff0c\u9650\u5236\u4e86\u6027\u80fd\u3002", "method": "\u63d0\u51faLoRMA\uff0c\u5c06\u52a0\u6cd5\u66f4\u65b0\u8f6c\u6362\u4e3a\u77e9\u9635\u4e58\u6cd5\u53d8\u6362\uff0c\u901a\u8fc7\u64cd\u4f5c\u91cd\u6392\u5e8f\u548c\u79e9\u81a8\u80c0\u7b56\u7565\u4f18\u5316\u8ba1\u7b97\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cLoRMA\u5728\u591a\u79cd\u8bc4\u4f30\u6307\u6807\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "LoRMA\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6548\u5fae\u8c03\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u5177\u6709\u663e\u8457\u6f5c\u529b\u3002"}}
{"id": "2506.07637", "pdf": "https://arxiv.org/pdf/2506.07637", "abs": "https://arxiv.org/abs/2506.07637", "authors": ["Yuchong Long", "Wen Sun", "Ningxiao Sun", "Wenxiao Wang", "Chao Li", "Shan Yin"], "title": "HieraEdgeNet: A Multi-Scale Edge-Enhanced Framework for Automated Pollen Recognition", "categories": ["cs.CV", "cs.LG", "68T07, 68T45", "I.2.10; I.4.9; I.5.4"], "comment": "16 pages, 5 figures, 2 tables. The dataset at\n  https://www.kaggle.com/datasets/ayinven/hieraedgenetintegratesdatasets. The\n  models at\n  https://huggingface.co/datasets/AyinMostima/HieraEdgeNetintegratesdatasets.\n  The source code in at https://github.com/AyinMostima/PalynoKit", "summary": "Automated pollen recognition is vital to paleoclimatology, biodiversity\nmonitoring, and public health, yet conventional methods are hampered by\ninefficiency and subjectivity. Existing deep learning models often struggle to\nachieve the requisite localization accuracy for microscopic targets like\npollen, which are characterized by their minute size, indistinct edges, and\ncomplex backgrounds. To overcome this limitation, we introduce HieraEdgeNet, a\nmulti-scale edge-enhancement framework. The framework's core innovation is the\nintroduction of three synergistic modules: the Hierarchical Edge Module (HEM),\nwhich explicitly extracts a multi-scale pyramid of edge features that\ncorresponds to the semantic hierarchy at early network stages; the Synergistic\nEdge Fusion (SEF) module, for deeply fusing these edge priors with semantic\ninformation at each respective scale; and the Cross Stage Partial Omni-Kernel\nModule (CSPOKM), which maximally refines the most detail-rich feature layers\nusing an Omni-Kernel operator - comprising anisotropic large-kernel\nconvolutions and mixed-domain attention - all within a computationally\nefficient Cross-Stage Partial (CSP) framework. On a large-scale dataset\ncomprising 120 pollen classes, HieraEdgeNet achieves a mean Average Precision\n(mAP@.5) of 0.9501, significantly outperforming state-of-the-art baseline\nmodels such as YOLOv12n and RT-DETR. Furthermore, qualitative analysis confirms\nthat our approach generates feature representations that are more precisely\nfocused on object boundaries. By systematically integrating edge information,\nHieraEdgeNet provides a robust and powerful solution for high-precision,\nhigh-efficiency automated detection of microscopic objects.", "AI": {"tldr": "HieraEdgeNet\u662f\u4e00\u79cd\u591a\u5c3a\u5ea6\u8fb9\u7f18\u589e\u5f3a\u6846\u67b6\uff0c\u7528\u4e8e\u9ad8\u6548\u3001\u9ad8\u7cbe\u5ea6\u7684\u81ea\u52a8\u5316\u82b1\u7c89\u8bc6\u522b\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u82b1\u7c89\u8bc6\u522b\u65b9\u6cd5\u6548\u7387\u4f4e\u4e14\u4e3b\u89c2\u6027\u5f3a\uff0c\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u5fae\u89c2\u76ee\u6807\uff08\u5982\u82b1\u7c89\uff09\u7684\u5b9a\u4f4d\u7cbe\u5ea6\u4e0a\u8868\u73b0\u4e0d\u8db3\u3002", "method": "\u63d0\u51faHieraEdgeNet\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u6a21\u5757\uff1aHEM\uff08\u591a\u5c3a\u5ea6\u8fb9\u7f18\u7279\u5f81\u63d0\u53d6\uff09\u3001SEF\uff08\u8fb9\u7f18\u4e0e\u8bed\u4e49\u4fe1\u606f\u878d\u5408\uff09\u548cCSPOKM\uff08\u7ec6\u8282\u7279\u5f81\u4f18\u5316\uff09\u3002", "result": "\u5728120\u7c7b\u82b1\u7c89\u6570\u636e\u96c6\u4e0a\uff0cmAP@.5\u8fbe\u52300.9501\uff0c\u4f18\u4e8eYOLOv12n\u548cRT-DETR\u7b49\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "HieraEdgeNet\u901a\u8fc7\u7cfb\u7edf\u6574\u5408\u8fb9\u7f18\u4fe1\u606f\uff0c\u4e3a\u5fae\u89c2\u7269\u4f53\u68c0\u6d4b\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u9ad8\u7cbe\u5ea6\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.07667", "pdf": "https://arxiv.org/pdf/2506.07667", "abs": "https://arxiv.org/abs/2506.07667", "authors": ["Prarabdh Shukla", "Wei Yin Chong", "Yash Patel", "Brennan Schaffner", "Danish Pruthi", "Arjun Bhagoji"], "title": "Silencing Empowerment, Allowing Bigotry: Auditing the Moderation of Hate Speech on Twitch", "categories": ["cs.CL", "cs.HC", "cs.LG"], "comment": null, "summary": "To meet the demands of content moderation, online platforms have resorted to\nautomated systems. Newer forms of real-time engagement($\\textit{e.g.}$, users\ncommenting on live streams) on platforms like Twitch exert additional pressures\non the latency expected of such moderation systems. Despite their prevalence,\nrelatively little is known about the effectiveness of these systems. In this\npaper, we conduct an audit of Twitch's automated moderation tool\n($\\texttt{AutoMod}$) to investigate its effectiveness in flagging hateful\ncontent. For our audit, we create streaming accounts to act as siloed test\nbeds, and interface with the live chat using Twitch's APIs to send over\n$107,000$ comments collated from $4$ datasets. We measure $\\texttt{AutoMod}$'s\naccuracy in flagging blatantly hateful content containing misogyny, racism,\nableism and homophobia. Our experiments reveal that a large fraction of hateful\nmessages, up to $94\\%$ on some datasets, $\\textit{bypass moderation}$.\nContextual addition of slurs to these messages results in $100\\%$ removal,\nrevealing $\\texttt{AutoMod}$'s reliance on slurs as a moderation signal. We\nalso find that contrary to Twitch's community guidelines, $\\texttt{AutoMod}$\nblocks up to $89.5\\%$ of benign examples that use sensitive words in\npedagogical or empowering contexts. Overall, our audit points to large gaps in\n$\\texttt{AutoMod}$'s capabilities and underscores the importance for such\nsystems to understand context effectively.", "AI": {"tldr": "\u8bba\u6587\u5ba1\u8ba1\u4e86Twitch\u7684\u81ea\u52a8\u5ba1\u6838\u5de5\u5177AutoMod\uff0c\u53d1\u73b0\u5176\u5728\u8bc6\u522b\u4ec7\u6068\u5185\u5bb9\u65f6\u5b58\u5728\u663e\u8457\u6f0f\u6d1e\uff0c94%\u7684\u4ec7\u6068\u5185\u5bb9\u672a\u88ab\u6807\u8bb0\uff0c\u540c\u65f6\u8bef\u5220\u4e8689.5%\u7684\u826f\u6027\u5185\u5bb9\u3002", "motivation": "\u5728\u7ebf\u5e73\u53f0\u4f9d\u8d56\u81ea\u52a8\u5316\u7cfb\u7edf\u8fdb\u884c\u5185\u5bb9\u5ba1\u6838\uff0c\u4f46\u5b9e\u65f6\u4e92\u52a8\uff08\u5982\u76f4\u64ad\u8bc4\u8bba\uff09\u5bf9\u5ba1\u6838\u7cfb\u7edf\u7684\u5ef6\u8fdf\u548c\u6709\u6548\u6027\u63d0\u51fa\u4e86\u66f4\u9ad8\u8981\u6c42\u3002\u76ee\u524d\u5bf9\u8fd9\u7c7b\u7cfb\u7edf\u7684\u6709\u6548\u6027\u4e86\u89e3\u6709\u9650\u3002", "method": "\u901a\u8fc7\u521b\u5efa\u6d4b\u8bd5\u8d26\u6237\uff0c\u4f7f\u7528Twitch API\u53d1\u900110.7\u4e07\u6761\u8bc4\u8bba\uff08\u6765\u81ea4\u4e2a\u6570\u636e\u96c6\uff09\uff0c\u8bc4\u4f30AutoMod\u5bf9\u4ec7\u6068\u5185\u5bb9\uff08\u5982\u6027\u522b\u6b67\u89c6\u3001\u79cd\u65cf\u6b67\u89c6\u7b49\uff09\u7684\u6807\u8bb0\u51c6\u786e\u6027\u3002", "result": "AutoMod\u6f0f\u6807\u4e86\u9ad8\u8fbe94%\u7684\u4ec7\u6068\u5185\u5bb9\uff0c\u4f46\u5bf9\u5305\u542b\u654f\u611f\u8bcd\u7684\u826f\u6027\u5185\u5bb9\u8bef\u5220\u7387\u8fbe89.5%\u3002\u5176\u4f9d\u8d56\u654f\u611f\u8bcd\u4f5c\u4e3a\u5ba1\u6838\u4fe1\u53f7\uff0c\u7f3a\u4e4f\u4e0a\u4e0b\u6587\u7406\u89e3\u80fd\u529b\u3002", "conclusion": "AutoMod\u5728\u5ba1\u6838\u80fd\u529b\u4e0a\u5b58\u5728\u91cd\u5927\u7f3a\u9677\uff0c\u9700\u6539\u8fdb\u4e0a\u4e0b\u6587\u7406\u89e3\u80fd\u529b\u4ee5\u66f4\u6709\u6548\u5730\u533a\u5206\u4ec7\u6068\u5185\u5bb9\u4e0e\u826f\u6027\u5185\u5bb9\u3002"}}
{"id": "2506.07687", "pdf": "https://arxiv.org/pdf/2506.07687", "abs": "https://arxiv.org/abs/2506.07687", "authors": ["Kevin Lam", "Thang Bui", "George Deligiannidis", "Yee Whye Teh"], "title": "Rao-Blackwellised Reparameterisation Gradients", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Latent Gaussian variables have been popularised in probabilistic machine\nlearning. In turn, gradient estimators are the machinery that facilitates\ngradient-based optimisation for models with latent Gaussian variables. The\nreparameterisation trick is often used as the default estimator as it is simple\nto implement and yields low-variance gradients for variational inference. In\nthis work, we propose the R2-G2 estimator as the Rao-Blackwellisation of the\nreparameterisation gradient estimator. Interestingly, we show that the local\nreparameterisation gradient estimator for Bayesian MLPs is an instance of the\nR2-G2 estimator and Rao-Blackwellisation. This lets us extend benefits of\nRao-Blackwellised gradients to a suite of probabilistic models. We show that\ninitial training with R2-G2 consistently yields better performance in models\nwith multiple applications of the reparameterisation trick.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faR2-G2\u4f30\u8ba1\u5668\uff0c\u4f5c\u4e3a\u91cd\u53c2\u6570\u5316\u68af\u5ea6\u4f30\u8ba1\u5668\u7684Rao-Blackwell\u5316\u7248\u672c\uff0c\u5e76\u8bc1\u660e\u5176\u5728\u8d1d\u53f6\u65af\u591a\u5c42\u611f\u77e5\u673a\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u7814\u7a76\u68af\u5ea6\u4f30\u8ba1\u5668\u5728\u6f5c\u5728\u9ad8\u65af\u53d8\u91cf\u6a21\u578b\u4e2d\u7684\u4f18\u5316\u6548\u679c\uff0c\u7279\u522b\u662f\u91cd\u53c2\u6570\u5316\u68af\u5ea6\u4f30\u8ba1\u5668\u7684\u6539\u8fdb\u3002", "method": "\u63d0\u51faR2-G2\u4f30\u8ba1\u5668\uff0c\u4f5c\u4e3a\u91cd\u53c2\u6570\u5316\u68af\u5ea6\u4f30\u8ba1\u5668\u7684Rao-Blackwell\u5316\u7248\u672c\uff0c\u5e76\u5206\u6790\u5176\u5728\u8d1d\u53f6\u65af\u591a\u5c42\u611f\u77e5\u673a\u4e2d\u7684\u5b9e\u4f8b\u3002", "result": "R2-G2\u5728\u521d\u59cb\u8bad\u7ec3\u4e2d\u8868\u73b0\u66f4\u4f18\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u591a\u6b21\u5e94\u7528\u91cd\u53c2\u6570\u5316\u6280\u5de7\u7684\u6a21\u578b\u3002", "conclusion": "R2-G2\u6269\u5c55\u4e86Rao-Blackwell\u5316\u68af\u5ea6\u7684\u4f18\u52bf\uff0c\u63d0\u5347\u4e86\u591a\u7c7b\u6982\u7387\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2506.07691", "pdf": "https://arxiv.org/pdf/2506.07691", "abs": "https://arxiv.org/abs/2506.07691", "authors": ["Jiaming Li", "Haoran Ye", "Yukun Chen", "Xinyue Li", "Lei Zhang", "Hamid Alinejad-Rokny", "Jimmy Chih-Hsien Peng", "Min Yang"], "title": "Training Superior Sparse Autoencoders for Instruct Models", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "As large language models (LLMs) grow in scale and capability, understanding\ntheir internal mechanisms becomes increasingly critical. Sparse autoencoders\n(SAEs) have emerged as a key tool in mechanistic interpretability, enabling the\nextraction of human-interpretable features from LLMs. However, existing SAE\ntraining methods are primarily designed for base models, resulting in reduced\nreconstruction quality and interpretability when applied to instruct models. To\nbridge this gap, we propose\n$\\underline{\\textbf{F}}$inetuning-$\\underline{\\textbf{a}}$ligned\n$\\underline{\\textbf{S}}$equential $\\underline{\\textbf{T}}$raining\n($\\textit{FAST}$), a novel training method specifically tailored for instruct\nmodels. $\\textit{FAST}$ aligns the training process with the data distribution\nand activation patterns characteristic of instruct models, resulting in\nsubstantial improvements in both reconstruction and feature interpretability.\nOn Qwen2.5-7B-Instruct, $\\textit{FAST}$ achieves a mean squared error of 0.6468\nin token reconstruction, significantly outperforming baseline methods with\nerrors of 5.1985 and 1.5096. In feature interpretability, $\\textit{FAST}$\nyields a higher proportion of high-quality features, for Llama3.2-3B-Instruct,\n$21.1\\%$ scored in the top range, compared to $7.0\\%$ and $10.2\\%$ for\n$\\textit{BT(P)}$ and $\\textit{BT(F)}$. Surprisingly, we discover that\nintervening on the activations of special tokens via the SAEs leads to\nimprovements in output quality, suggesting new opportunities for fine-grained\ncontrol of model behavior. Code, data, and 240 trained SAEs are available at\nhttps://github.com/Geaming2002/FAST.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFAST\u7684\u65b0\u8bad\u7ec3\u65b9\u6cd5\uff0c\u4e13\u95e8\u9488\u5bf9\u6307\u4ee4\u6a21\u578b\u4f18\u5316\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff08SAEs\uff09\uff0c\u663e\u8457\u63d0\u5347\u4e86\u91cd\u6784\u8d28\u91cf\u548c\u7279\u5f81\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u6709\u7a00\u758f\u81ea\u7f16\u7801\u5668\u8bad\u7ec3\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u57fa\u7840\u6a21\u578b\uff0c\u5e94\u7528\u4e8e\u6307\u4ee4\u6a21\u578b\u65f6\u91cd\u6784\u8d28\u91cf\u548c\u53ef\u89e3\u91ca\u6027\u4e0b\u964d\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u4e13\u95e8\u9488\u5bf9\u6307\u4ee4\u6a21\u578b\u7684\u4f18\u5316\u65b9\u6cd5\u3002", "method": "\u63d0\u51faFAST\u65b9\u6cd5\uff0c\u901a\u8fc7\u8c03\u6574\u8bad\u7ec3\u8fc7\u7a0b\u4ee5\u5339\u914d\u6307\u4ee4\u6a21\u578b\u7684\u6570\u636e\u5206\u5e03\u548c\u6fc0\u6d3b\u6a21\u5f0f\uff0c\u4ece\u800c\u4f18\u5316\u7a00\u758f\u81ea\u7f16\u7801\u5668\u7684\u6027\u80fd\u3002", "result": "\u5728Qwen2.5-7B-Instruct\u4e0a\uff0cFAST\u7684\u5747\u65b9\u8bef\u5dee\u4e3a0.6468\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff085.1985\u548c1.5096\uff09\uff1b\u5728Llama3.2-3B-Instruct\u4e0a\uff0c\u9ad8\u8d28\u91cf\u7279\u5f81\u5360\u6bd4\u8fbe21.1%\uff0c\u4f18\u4e8e\u57fa\u7ebf\uff087.0%\u548c10.2%\uff09\u3002", "conclusion": "FAST\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u7a00\u758f\u81ea\u7f16\u7801\u5668\u5728\u6307\u4ee4\u6a21\u578b\u4e0a\u7684\u6027\u80fd\uff0c\u540c\u65f6\u53d1\u73b0\u5bf9\u7279\u6b8a\u4ee4\u724c\u6fc0\u6d3b\u7684\u5e72\u9884\u53ef\u4ee5\u6539\u5584\u8f93\u51fa\u8d28\u91cf\uff0c\u4e3a\u6a21\u578b\u884c\u4e3a\u7cbe\u7ec6\u63a7\u5236\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.07695", "pdf": "https://arxiv.org/pdf/2506.07695", "abs": "https://arxiv.org/abs/2506.07695", "authors": ["Parsa Miraghaei", "Sergio Moreschini", "Antti Kolehmainen", "David H\u00e4stbacka"], "title": "Towards a Small Language Model Lifecycle Framework", "categories": ["cs.SE", "cs.LG"], "comment": null, "summary": "Background: The growing demand for efficient and deployable language models\nhas led to increased interest in Small Language Models (SLMs). However,\nexisting research remains fragmented, lacking a unified lifecycle perspective.\n  Objective: This study aims to define a comprehensive lifecycle framework for\nSLMs by synthesizing insights from academic literature and practitioner\nsources.\n  Method: We conducted a comprehensive survey of 36 works, analyzing and\ncategorizing lifecycle-relevant techniques.\n  Results: We propose a modular lifecycle model structured into main, optional,\nand cross-cutting components. The model captures key interconnections across\nstages, supporting method reuse, co-adaptation, and lifecycle-awareness.\n  Conclusion: Our framework provides a coherent foundation for developing and\nmaintaining SLMs, bridging theory and practice, and guiding future research and\ntool development.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08SLM\uff09\u751f\u547d\u5468\u671f\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u5b66\u672f\u548c\u5b9e\u8df5\u8d44\u6e90\uff0c\u586b\u8865\u4e86\u73b0\u6709\u7814\u7a76\u7684\u788e\u7247\u5316\u95ee\u9898\u3002", "motivation": "\u7531\u4e8e\u5bf9\u9ad8\u6548\u4e14\u53ef\u90e8\u7f72\u8bed\u8a00\u6a21\u578b\u7684\u9700\u6c42\u589e\u957f\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u7edf\u4e00\u7684\u751f\u547d\u5468\u671f\u89c6\u89d2\uff0c\u56e0\u6b64\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u7efc\u5408\u6846\u67b6\u3002", "method": "\u901a\u8fc7\u5bf936\u9879\u5de5\u4f5c\u7684\u5168\u9762\u8c03\u67e5\uff0c\u5206\u6790\u5e76\u5206\u7c7b\u4e86\u4e0e\u751f\u547d\u5468\u671f\u76f8\u5173\u7684\u6280\u672f\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6a21\u5757\u5316\u7684\u751f\u547d\u5468\u671f\u6a21\u578b\uff0c\u5305\u62ec\u4e3b\u8981\u3001\u53ef\u9009\u548c\u8de8\u9886\u57df\u7ec4\u4ef6\uff0c\u652f\u6301\u65b9\u6cd5\u91cd\u7528\u3001\u534f\u540c\u9002\u5e94\u548c\u751f\u547d\u5468\u671f\u610f\u8bc6\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aSLM\u7684\u5f00\u53d1\u548c\u7ef4\u62a4\u63d0\u4f9b\u4e86\u8fde\u8d2f\u7684\u57fa\u7840\uff0c\u8fde\u63a5\u7406\u8bba\u4e0e\u5b9e\u8df5\uff0c\u5e76\u6307\u5bfc\u672a\u6765\u7814\u7a76\u548c\u5de5\u5177\u5f00\u53d1\u3002"}}
{"id": "2506.07714", "pdf": "https://arxiv.org/pdf/2506.07714", "abs": "https://arxiv.org/abs/2506.07714", "authors": ["Francesco Marchiori", "Denis Donadel", "Alessandro Brighente", "Mauro Conti"], "title": "Profiling Electric Vehicles via Early Charging Voltage Patterns", "categories": ["cs.CR", "cs.ET", "cs.LG"], "comment": "Accepted to be presented at the AI&CPSS Workshop in conjunction with\n  ARES 2025", "summary": "Electric Vehicles (EVs) are rapidly gaining adoption as a sustainable\nalternative to fuel-powered vehicles, making secure charging infrastructure\nessential. Despite traditional authentication protocols, recent results showed\nthat attackers may steal energy through tailored relay attacks. One\ncountermeasure is leveraging the EV's fingerprint on the current exchanged\nduring charging. However, existing methods focus on the final charging stage,\nallowing malicious actors to consume substantial energy before being detected\nand repudiated. This underscores the need for earlier and more effective\nauthentication methods to prevent unauthorized charging. Meanwhile, profiling\nraises privacy concerns, as uniquely identifying EVs through charging patterns\ncould enable user tracking.\n  In this paper, we propose a framework for uniquely identifying EVs using\nphysical measurements from the early charging stages. We hypothesize that\nvoltage behavior early in the process exhibits similar characteristics to\ncurrent behavior in later stages. By extracting features from early voltage\nmeasurements, we demonstrate the feasibility of EV profiling. Our approach\nimproves existing methods by enabling faster and more reliable vehicle\nidentification. We test our solution on a dataset of 7408 usable charges from\n49 EVs, achieving up to 0.86 accuracy. Feature importance analysis shows that\nnear-optimal performance is possible with just 10 key features, improving\nefficiency alongside our lightweight models. This research lays the foundation\nfor a novel authentication factor while exposing potential privacy risks from\nunauthorized access to charging data.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u65e9\u671f\u5145\u7535\u9636\u6bb5\u7535\u538b\u884c\u4e3a\u7684\u7535\u52a8\u6c7d\u8f66\uff08EV\uff09\u8bc6\u522b\u6846\u67b6\uff0c\u65e8\u5728\u63d0\u9ad8\u5145\u7535\u5b89\u5168\u6027\u548c\u6548\u7387\uff0c\u540c\u65f6\u63ed\u793a\u9690\u79c1\u98ce\u9669\u3002", "motivation": "\u968f\u7740\u7535\u52a8\u6c7d\u8f66\u7684\u666e\u53ca\uff0c\u5145\u7535\u57fa\u7840\u8bbe\u65bd\u7684\u5b89\u5168\u6027\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u5145\u7535\u540e\u671f\u624d\u80fd\u68c0\u6d4b\u653b\u51fb\uff0c\u5bfc\u81f4\u80fd\u6e90\u6d6a\u8d39\uff0c\u4e14\u7528\u6237\u9690\u79c1\u53ef\u80fd\u56e0\u5145\u7535\u6a21\u5f0f\u8bc6\u522b\u800c\u6cc4\u9732\u3002", "method": "\u901a\u8fc7\u63d0\u53d6\u65e9\u671f\u5145\u7535\u9636\u6bb5\u7684\u7535\u538b\u7279\u5f81\uff0c\u6784\u5efa\u8f7b\u91cf\u7ea7\u6a21\u578b\uff0c\u5b9e\u73b0\u5feb\u901f\u53ef\u9760\u7684\u7535\u52a8\u6c7d\u8f66\u8bc6\u522b\u3002", "result": "\u572849\u8f86EV\u76847408\u6b21\u5145\u7535\u6570\u636e\u4e0a\u6d4b\u8bd5\uff0c\u51c6\u786e\u7387\u8fbe0.86\uff0c\u4ec5\u970010\u4e2a\u5173\u952e\u7279\u5f81\u5373\u53ef\u63a5\u8fd1\u6700\u4f18\u6027\u80fd\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5145\u7535\u8ba4\u8bc1\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\uff0c\u4f46\u4e5f\u8b66\u793a\u4e86\u5145\u7535\u6570\u636e\u6cc4\u9732\u53ef\u80fd\u5e26\u6765\u7684\u9690\u79c1\u98ce\u9669\u3002"}}
{"id": "2506.07756", "pdf": "https://arxiv.org/pdf/2506.07756", "abs": "https://arxiv.org/abs/2506.07756", "authors": ["Mark Burgess"], "title": "Agent Semantics, Semantic Spacetime, and Graphical Reasoning", "categories": ["cs.AI", "cs.LG", "cs.MA", "I.2.11; F.4.1; I.2.4; G.2.2"], "comment": null, "summary": "Some formal aspects of the Semantic Spacetime graph model are presented, with\nreference to its use for directed knowledge representations and process\nmodelling. A finite $\\gamma(3,4)$ representation is defined to form a closed\nset of operations that can scale to any degree of semantic complexity. The\nSemantic Spacetime postulates bring predictability with minimal constraints to\npathways in graphs. The ubiquitous appearance of absorbing states in any\npartial graph means that a graph process leaks information. The issue is\nclosely associated with the issue of division by zero, which signals a loss of\nclosure and the need for manual injection of remedial information. The Semantic\nSpacetime model (and its Promise Theory) origins help to clarify how such\nabsorbing states are associated with boundary information where intentionality\ncan enter.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u8bed\u4e49\u65f6\u7a7a\u56fe\u6a21\u578b\u7684\u5f62\u5f0f\u5316\u7279\u6027\uff0c\u7528\u4e8e\u5b9a\u5411\u77e5\u8bc6\u8868\u793a\u548c\u8fc7\u7a0b\u5efa\u6a21\uff0c\u5b9a\u4e49\u4e86\u4e00\u4e2a\u6709\u9650\u03b3(3,4)\u8868\u793a\u4ee5\u5f62\u6210\u53ef\u6269\u5c55\u7684\u5c01\u95ed\u64cd\u4f5c\u96c6\u3002", "motivation": "\u7814\u7a76\u8bed\u4e49\u65f6\u7a7a\u56fe\u6a21\u578b\u7684\u5f62\u5f0f\u5316\u7279\u6027\uff0c\u4ee5\u652f\u6301\u53ef\u9884\u6d4b\u7684\u77e5\u8bc6\u8868\u793a\u548c\u8fc7\u7a0b\u5efa\u6a21\u3002", "method": "\u5b9a\u4e49\u4e86\u4e00\u4e2a\u6709\u9650\u03b3(3,4)\u8868\u793a\uff0c\u5f62\u6210\u5c01\u95ed\u64cd\u4f5c\u96c6\uff0c\u5e76\u5229\u7528\u8bed\u4e49\u65f6\u7a7a\u5047\u8bbe\u4e3a\u56fe\u8def\u5f84\u63d0\u4f9b\u6700\u5c0f\u7ea6\u675f\u7684\u9884\u6d4b\u6027\u3002", "result": "\u53d1\u73b0\u90e8\u5206\u56fe\u4e2d\u666e\u904d\u5b58\u5728\u7684\u5438\u6536\u72b6\u6001\u4f1a\u5bfc\u81f4\u4fe1\u606f\u6cc4\u6f0f\uff0c\u8fd9\u4e0e\u9664\u4ee5\u96f6\u95ee\u9898\u76f8\u5173\uff0c\u8868\u660e\u5c01\u95ed\u6027\u4e27\u5931\u3002", "conclusion": "\u8bed\u4e49\u65f6\u7a7a\u6a21\u578b\u53ca\u5176\u627f\u8bfa\u7406\u8bba\u6709\u52a9\u4e8e\u9610\u660e\u5438\u6536\u72b6\u6001\u4e0e\u8fb9\u754c\u4fe1\u606f\u7684\u5173\u8054\uff0c\u4e3a\u610f\u56fe\u6027\u5f15\u5165\u63d0\u4f9b\u9014\u5f84\u3002"}}
{"id": "2506.07760", "pdf": "https://arxiv.org/pdf/2506.07760", "abs": "https://arxiv.org/abs/2506.07760", "authors": ["Haijie Xu", "Chen Zhang"], "title": "Quickest Causal Change Point Detection by Adaptive Intervention", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We propose an algorithm for change point monitoring in linear causal models\nthat accounts for interventions. Through a special centralization technique, we\ncan concentrate the changes arising from causal propagation across nodes into a\nsingle dimension. Additionally, by selecting appropriate intervention nodes\nbased on Kullback-Leibler divergence, we can amplify the change magnitude. We\nalso present an algorithm for selecting the intervention values, which aids in\nthe identification of the most effective intervention nodes. Two monitoring\nmethods are proposed, each with an adaptive intervention policy to make a\nbalance between exploration and exploitation. We theoretically demonstrate the\nfirst-order optimality of the proposed methods and validate their properties\nusing simulation datasets and two real-world case studies.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7528\u4e8e\u7ebf\u6027\u56e0\u679c\u6a21\u578b\u4e2d\u53d8\u5316\u70b9\u76d1\u6d4b\u7684\u7b97\u6cd5\uff0c\u901a\u8fc7\u96c6\u4e2d\u5316\u6280\u672f\u548c\u5e72\u9884\u8282\u70b9\u9009\u62e9\u653e\u5927\u53d8\u5316\u4fe1\u53f7\uff0c\u5e76\u9a8c\u8bc1\u5176\u6700\u4f18\u6027\u3002", "motivation": "\u89e3\u51b3\u56e0\u679c\u6a21\u578b\u4e2d\u53d8\u5316\u70b9\u76d1\u6d4b\u7684\u6311\u6218\uff0c\u5c24\u5176\u662f\u5e72\u9884\u5bf9\u53d8\u5316\u4f20\u64ad\u7684\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u96c6\u4e2d\u5316\u6280\u672f\u5c06\u53d8\u5316\u96c6\u4e2d\u5230\u5355\u4e00\u7ef4\u5ea6\uff0c\u57fa\u4e8eKullback-Leibler\u6563\u5ea6\u9009\u62e9\u5e72\u9884\u8282\u70b9\uff0c\u5e76\u63d0\u51fa\u4e24\u79cd\u76d1\u6d4b\u65b9\u6cd5\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u65b9\u6cd5\u7684\u4e00\u9636\u6700\u4f18\u6027\uff0c\u5e76\u901a\u8fc7\u6a21\u62df\u548c\u5b9e\u9645\u6848\u4f8b\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u7b97\u6cd5\u5728\u53d8\u5316\u70b9\u76d1\u6d4b\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5e73\u8861\u4e86\u63a2\u7d22\u4e0e\u5229\u7528\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2506.07770", "pdf": "https://arxiv.org/pdf/2506.07770", "abs": "https://arxiv.org/abs/2506.07770", "authors": ["Yang Wang", "Yin Xu", "Cixiao Zhang", "Zhiyong Chen", "Xiaowu Ou", "Mingzeng Dai", "Meixia Tao", "Wenjun Zhang"], "title": "Diffusion Models-Aided Uplink Channel Estimation for RIS-Assisted Systems", "categories": ["eess.SP", "cs.LG"], "comment": "5 pages", "summary": "This letter proposes a channel estimation method for reconfigurable\nintelligent surface (RIS)-assisted systems through a novel diffusion model (DM)\nframework. We reformulate the channel estimation problem as a denoising\nprocess, which aligns with the reverse process of the DM. To overcome the\ninherent randomness in the reverse process of conventional DM approaches, we\nadopt a deterministic sampling strategy with a step alignment mechanism that\nensures the accuracy of channel estimation while adapting to different\nsignal-to-noise ratio (SNR). Furthermore, to reduce the number of parameters of\nthe U-Net, we meticulously design a lightweight network that achieves\ncomparable performance, thereby enhancing the practicality of our proposed\nmethod. Extensive simulations demonstrate superior performance over a wide\nrange of SNRs compared to baselines. For instance, the proposed method achieves\nperformance improvements of up to 13.5 dB in normalized mean square error\n(NMSE) at SNR = 0 dB. Notably, the proposed lightweight network exhibits almost\nno performance loss compared to the original U-Net, while requiring only 6.59\\%\nof its parameters.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u6a21\u578b\uff08DM\uff09\u7684\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\uff08RIS\uff09\u8f85\u52a9\u7cfb\u7edf\u4fe1\u9053\u4f30\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u786e\u5b9a\u6027\u91c7\u6837\u7b56\u7565\u548c\u8f7b\u91cf\u7ea7\u7f51\u7edc\u8bbe\u8ba1\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u6269\u6563\u6a21\u578b\u5728\u4fe1\u9053\u4f30\u8ba1\u4e2d\u5b58\u5728\u968f\u673a\u6027\u95ee\u9898\uff0c\u4e14\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u65b9\u6cd5\u3002", "method": "\u5c06\u4fe1\u9053\u4f30\u8ba1\u95ee\u9898\u8f6c\u5316\u4e3a\u53bb\u566a\u8fc7\u7a0b\uff0c\u91c7\u7528\u786e\u5b9a\u6027\u91c7\u6837\u7b56\u7565\u548c\u6b65\u957f\u5bf9\u9f50\u673a\u5236\uff0c\u5e76\u8bbe\u8ba1\u8f7b\u91cf\u7ea7\u7f51\u7edc\u4ee5\u51cf\u5c11\u53c2\u6570\u3002", "result": "\u5728\u591a\u79cd\u4fe1\u566a\u6bd4\uff08SNR\uff09\u4e0b\u6027\u80fd\u4f18\u4e8e\u57fa\u7ebf\uff0cNMSE\u63d0\u5347\u8fbe13.5 dB\uff08SNR=0 dB\uff09\uff0c\u8f7b\u91cf\u7ea7\u7f51\u7edc\u53c2\u6570\u4ec5\u4e3a\u539fU-Net\u76846.59%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u6027\u80fd\u548c\u5b9e\u7528\u6027\u4e0a\u5747\u6709\u663e\u8457\u63d0\u5347\uff0c\u9002\u7528\u4e8eRIS\u8f85\u52a9\u7cfb\u7edf\u7684\u4fe1\u9053\u4f30\u8ba1\u3002"}}
{"id": "2506.07773", "pdf": "https://arxiv.org/pdf/2506.07773", "abs": "https://arxiv.org/abs/2506.07773", "authors": ["Mohamed Djilani", "Nassim Ali Ousalah", "Nidhal Eddine Chenni"], "title": "Trend-Aware Fashion Recommendation with Visual Segmentation and Semantic Similarity", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "We introduce a trend-aware and visually-grounded fashion recommendation\nsystem that integrates deep visual representations, garment-aware segmentation,\nsemantic category similarity and user behavior simulation. Our pipeline\nextracts focused visual embeddings by masking non-garment regions via semantic\nsegmentation followed by feature extraction using pretrained CNN backbones\n(ResNet-50, DenseNet-121, VGG16). To simulate realistic shopping behavior, we\ngenerate synthetic purchase histories influenced by user-specific trendiness\nand item popularity. Recommendations are computed using a weighted scoring\nfunction that fuses visual similarity, semantic coherence and popularity\nalignment. Experiments on the DeepFashion dataset demonstrate consistent gender\nalignment and improved category relevance, with ResNet-50 achieving 64.95%\ncategory similarity and lowest popularity MAE. An ablation study confirms the\ncomplementary roles of visual and popularity cues. Our method provides a\nscalable framework for personalized fashion recommendations that balances\nindividual style with emerging trends. Our implementation is available at\nhttps://github.com/meddjilani/FashionRecommender", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u89c6\u89c9\u7279\u5f81\u3001\u8bed\u4e49\u5206\u5272\u548c\u7528\u6237\u884c\u4e3a\u6a21\u62df\u7684\u65f6\u5c1a\u63a8\u8350\u7cfb\u7edf\uff0c\u901a\u8fc7\u52a0\u6743\u8bc4\u5206\u51fd\u6570\u5b9e\u73b0\u4e2a\u6027\u5316\u63a8\u8350\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4f18\u8d8a\u3002", "motivation": "\u89e3\u51b3\u65f6\u5c1a\u63a8\u8350\u4e2d\u5982\u4f55\u5e73\u8861\u4e2a\u4eba\u98ce\u683c\u4e0e\u6d41\u884c\u8d8b\u52bf\u7684\u95ee\u9898\uff0c\u540c\u65f6\u63d0\u5347\u63a8\u8350\u7684\u89c6\u89c9\u548c\u8bed\u4e49\u76f8\u5173\u6027\u3002", "method": "\u4f7f\u7528\u8bed\u4e49\u5206\u5272\u63d0\u53d6\u670d\u88c5\u533a\u57df\u7279\u5f81\uff0c\u7ed3\u5408\u9884\u8bad\u7ec3CNN\u6a21\u578b\u751f\u6210\u89c6\u89c9\u5d4c\u5165\uff0c\u6a21\u62df\u7528\u6237\u8d2d\u7269\u884c\u4e3a\uff0c\u5e76\u901a\u8fc7\u52a0\u6743\u8bc4\u5206\u51fd\u6570\u878d\u5408\u89c6\u89c9\u76f8\u4f3c\u6027\u3001\u8bed\u4e49\u4e00\u81f4\u6027\u548c\u6d41\u884c\u5ea6\u3002", "result": "\u5728DeepFashion\u6570\u636e\u96c6\u4e0a\uff0cResNet-50\u8868\u73b0\u6700\u4f73\uff0c\u7c7b\u522b\u76f8\u4f3c\u6027\u8fbe64.95%\uff0c\u6d41\u884c\u5ea6MAE\u6700\u4f4e\u3002\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u89c6\u89c9\u548c\u6d41\u884c\u5ea6\u7ebf\u7d22\u7684\u4e92\u8865\u4f5c\u7528\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u6846\u67b6\uff0c\u80fd\u591f\u5e73\u8861\u4e2a\u4eba\u98ce\u683c\u4e0e\u6d41\u884c\u8d8b\u52bf\uff0c\u5b9e\u73b0\u4e2a\u6027\u5316\u65f6\u5c1a\u63a8\u8350\u3002"}}
{"id": "2506.07785", "pdf": "https://arxiv.org/pdf/2506.07785", "abs": "https://arxiv.org/abs/2506.07785", "authors": ["Qi Yang", "Chenghao Zhang", "Lubin Fan", "Kun Ding", "Jieping Ye", "Shiming Xiang"], "title": "Re-ranking Reasoning Context with Tree Search Makes Large Vision-Language Models Stronger", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "ICML 2025 Spotlight. 22 pages, 16 figures", "summary": "Recent advancements in Large Vision Language Models (LVLMs) have\nsignificantly improved performance in Visual Question Answering (VQA) tasks\nthrough multimodal Retrieval-Augmented Generation (RAG). However, existing\nmethods still face challenges, such as the scarcity of knowledge with reasoning\nexamples and erratic responses from retrieved knowledge. To address these\nissues, in this study, we propose a multimodal RAG framework, termed RCTS,\nwhich enhances LVLMs by constructing a Reasoning Context-enriched knowledge\nbase and a Tree Search re-ranking method. Specifically, we introduce a\nself-consistent evaluation mechanism to enrich the knowledge base with\nintrinsic reasoning patterns. We further propose a Monte Carlo Tree Search with\nHeuristic Rewards (MCTS-HR) to prioritize the most relevant examples. This\nensures that LVLMs can leverage high-quality contextual reasoning for better\nand more consistent responses. Extensive experiments demonstrate that our\nframework achieves state-of-the-art performance on multiple VQA datasets,\nsignificantly outperforming In-Context Learning (ICL) and Vanilla-RAG methods.\nIt highlights the effectiveness of our knowledge base and re-ranking method in\nimproving LVLMs. Our code is available at https://github.com/yannqi/RCTS-RAG.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRCTS\u7684\u591a\u6a21\u6001RAG\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u63a8\u7406\u4e0a\u4e0b\u6587\u4e30\u5bcc\u7684\u77e5\u8bc6\u5e93\u548c\u6811\u641c\u7d22\u91cd\u6392\u5e8f\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709LVLMs\u5728VQA\u4efb\u52a1\u4e2d\u77e5\u8bc6\u7a00\u7f3a\u548c\u54cd\u5e94\u4e0d\u7a33\u5b9a\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08LVLMs\uff09\u5728\u89c6\u89c9\u95ee\u7b54\uff08VQA\uff09\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u4ecd\u9762\u4e34\u77e5\u8bc6\u5e93\u4e2d\u63a8\u7406\u793a\u4f8b\u7a00\u7f3a\u548c\u68c0\u7d22\u77e5\u8bc6\u54cd\u5e94\u4e0d\u7a33\u5b9a\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faRCTS\u6846\u67b6\uff0c\u5305\u62ec\u6784\u5efa\u63a8\u7406\u4e0a\u4e0b\u6587\u4e30\u5bcc\u7684\u77e5\u8bc6\u5e93\u548c\u57fa\u4e8e\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u4e0e\u542f\u53d1\u5f0f\u5956\u52b1\uff08MCTS-HR\uff09\u7684\u91cd\u6392\u5e8f\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cRCTS\u5728\u591a\u4e2aVQA\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u663e\u8457\u4f18\u4e8e\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\u548c\u4f20\u7edfRAG\u65b9\u6cd5\u3002", "conclusion": "RCTS\u6846\u67b6\u901a\u8fc7\u9ad8\u8d28\u91cf\u7684\u77e5\u8bc6\u5e93\u548c\u91cd\u6392\u5e8f\u65b9\u6cd5\uff0c\u6709\u6548\u63d0\u5347\u4e86LVLMs\u7684\u6027\u80fd\u548c\u54cd\u5e94\u4e00\u81f4\u6027\u3002"}}
{"id": "2506.07795", "pdf": "https://arxiv.org/pdf/2506.07795", "abs": "https://arxiv.org/abs/2506.07795", "authors": ["Xiaotian Ye", "Mengqi Zhang", "Shu Wu"], "title": "LLM Unlearning Should Be Form-Independent", "categories": ["cs.CL", "cs.CR", "cs.LG"], "comment": null, "summary": "Large Language Model (LLM) unlearning aims to erase or suppress undesirable\nknowledge within the model, offering promise for controlling harmful or private\ninformation to prevent misuse. However, recent studies highlight its limited\nefficacy in real-world scenarios, hindering practical adoption. In this study,\nwe identify a pervasive issue underlying many downstream failures: the\neffectiveness of existing unlearning methods heavily depends on the form of\ntraining samples and frequently fails to generalize to alternate expressions of\nthe same knowledge. We formally characterize this problem as Form-Dependent\nBias and systematically investigate its specific manifestation patterns across\nvarious downstream tasks. To quantify its prevalence and support future\nresearch, we introduce ORT, a novel benchmark designed to evaluate the\nrobustness of unlearning methods against variations in knowledge expression.\nResults reveal that Form-Dependent Bias is both widespread and severe among\ncurrent techniques.\n  We argue that LLM unlearning should be form-independent to address the\nendless forms of downstream tasks encountered in real-world security-critical\nscenarios. Towards this goal, we introduce Rank-one Concept Redirection (ROCR),\na novel training-free method, as a promising solution path. ROCR performs\nunlearning by targeting the invariants in downstream tasks, specifically the\nactivated dangerous concepts. It is capable of modifying model parameters\nwithin seconds to redirect the model's perception of a specific unlearning\ntarget concept to another harmless concept. Extensive experiments demonstrate\nthat ROCR significantly improves unlearning effectiveness compared to\ntraditional methods while generating highly natural outputs.", "AI": {"tldr": "LLM \u9057\u5fd8\u6280\u672f\u65e8\u5728\u6d88\u9664\u6a21\u578b\u4e2d\u7684\u4e0d\u826f\u77e5\u8bc6\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u56e0\u5f62\u5f0f\u4f9d\u8d56\u504f\u5dee\uff08Form-Dependent Bias\uff09\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u6548\u679c\u6709\u9650\u3002\u7814\u7a76\u63d0\u51fa\u65b0\u57fa\u51c6 ORT \u8bc4\u4f30\u65b9\u6cd5\u9c81\u68d2\u6027\uff0c\u5e76\u5f15\u5165 ROCR \u65b9\u6cd5\u4ee5\u63d0\u5347\u9057\u5fd8\u6548\u679c\u3002", "motivation": "\u89e3\u51b3 LLM \u9057\u5fd8\u6280\u672f\u56e0\u5f62\u5f0f\u4f9d\u8d56\u504f\u5dee\u5bfc\u81f4\u7684\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u95ee\u9898\uff0c\u4ee5\u5e94\u5bf9\u73b0\u5b9e\u5b89\u5168\u5173\u952e\u573a\u666f\u4e2d\u7684\u591a\u6837\u5316\u9700\u6c42\u3002", "method": "\u63d0\u51fa ORT \u57fa\u51c6\u91cf\u5316\u5f62\u5f0f\u4f9d\u8d56\u504f\u5dee\uff0c\u5e76\u5f00\u53d1 ROCR \u65b9\u6cd5\uff0c\u901a\u8fc7\u91cd\u5b9a\u5411\u6fc0\u6d3b\u7684\u5371\u9669\u6982\u5ff5\u5b9e\u73b0\u65e0\u9700\u8bad\u7ec3\u7684\u5feb\u901f\u9057\u5fd8\u3002", "result": "\u5b9e\u9a8c\u8868\u660e ROCR \u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u80fd\u9ad8\u6548\u4e14\u81ea\u7136\u5730\u5b8c\u6210\u9057\u5fd8\u4efb\u52a1\u3002", "conclusion": "LLM \u9057\u5fd8\u9700\u5f62\u5f0f\u65e0\u5173\uff0cROCR \u4e3a\u89e3\u51b3\u5f62\u5f0f\u4f9d\u8d56\u504f\u5dee\u63d0\u4f9b\u4e86\u6709\u6548\u8def\u5f84\u3002"}}
{"id": "2506.07801", "pdf": "https://arxiv.org/pdf/2506.07801", "abs": "https://arxiv.org/abs/2506.07801", "authors": ["Iustin Sirbu", "Robert-Adrian Popovici", "Cornelia Caragea", "Stefan Trausan-Matu", "Traian Rebedea"], "title": "MultiMatch: Multihead Consistency Regularization Matching for Semi-Supervised Text Classification", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7"], "comment": null, "summary": "We introduce MultiMatch, a novel semi-supervised learning (SSL) algorithm\ncombining the paradigms of co-training and consistency regularization with\npseudo-labeling. At its core, MultiMatch features a three-fold pseudo-label\nweighting module designed for three key purposes: selecting and filtering\npseudo-labels based on head agreement and model confidence, and weighting them\naccording to the perceived classification difficulty. This novel module\nenhances and unifies three existing techniques -- heads agreement from\nMultihead Co-training, self-adaptive thresholds from FreeMatch, and Average\nPseudo-Margins from MarginMatch -- resulting in a holistic approach that\nimproves robustness and performance in SSL settings. Experimental results on\nbenchmark datasets highlight the superior performance of MultiMatch, achieving\nstate-of-the-art results on 9 out of 10 setups from 5 natural language\nprocessing datasets and ranking first according to the Friedman test among 19\nmethods. Furthermore, MultiMatch demonstrates exceptional robustness in highly\nimbalanced settings, outperforming the second-best approach by 3.26% -- and\ndata imbalance is a key factor for many text classification tasks.", "AI": {"tldr": "MultiMatch\u662f\u4e00\u79cd\u7ed3\u5408\u534f\u540c\u8bad\u7ec3\u548c\u4e00\u81f4\u6027\u6b63\u5219\u5316\u7684\u534a\u76d1\u7763\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u4e09\u91cd\u91cd\u4f2a\u6807\u7b7e\u52a0\u6743\u6a21\u5757\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u534a\u76d1\u7763\u5b66\u4e60\u4e2d\u4f2a\u6807\u7b7e\u9009\u62e9\u548c\u52a0\u6743\u7684\u95ee\u9898\uff0c\u63d0\u5347\u6a21\u578b\u5728\u6570\u636e\u4e0d\u5e73\u8861\u60c5\u51b5\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "method": "\u7ed3\u5408\u534f\u540c\u8bad\u7ec3\u548c\u4e00\u81f4\u6027\u6b63\u5219\u5316\uff0c\u8bbe\u8ba1\u4e09\u91cd\u91cd\u4f2a\u6807\u7b7e\u52a0\u6743\u6a21\u5757\uff0c\u7edf\u4e00\u4e86\u591a\u79cd\u73b0\u6709\u6280\u672f\u3002", "result": "\u57285\u4e2aNLP\u6570\u636e\u96c6\u768410\u4e2a\u8bbe\u7f6e\u4e2d\uff0c9\u4e2a\u8fbe\u5230SOTA\uff0c\u4e14\u5728\u6570\u636e\u4e0d\u5e73\u8861\u60c5\u51b5\u4e0b\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "MultiMatch\u5728\u6027\u80fd\u548c\u9c81\u68d2\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u7279\u522b\u9002\u7528\u4e8e\u6570\u636e\u4e0d\u5e73\u8861\u7684\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u3002"}}
{"id": "2506.07810", "pdf": "https://arxiv.org/pdf/2506.07810", "abs": "https://arxiv.org/abs/2506.07810", "authors": ["Emiliano Tolotti", "Enrico Blanzieri", "Davide Pastorello"], "title": "A weighted quantum ensemble of homogeneous quantum classifiers", "categories": ["quant-ph", "cs.ET", "cs.LG"], "comment": "21 pages, 4 figures", "summary": "Ensemble methods in machine learning aim to improve prediction accuracy by\ncombining multiple models. This is achieved by ensuring diversity among\npredictors to capture different data aspects. Homogeneous ensembles use\nidentical models, achieving diversity through different data subsets, and\nweighted-average ensembles assign higher influence to more accurate models\nthrough a weight learning procedure. We propose a method to achieve a weighted\nhomogeneous quantum ensemble using quantum classifiers with indexing registers\nfor data encoding. This approach leverages instance-based quantum classifiers,\nenabling feature and training point subsampling through superposition and\ncontrolled unitaries, and allowing for a quantum-parallel execution of diverse\ninternal classifiers with different data compositions in superposition. The\nmethod integrates a learning process involving circuit execution and classical\nweight optimization, for a trained ensemble execution with weights encoded in\nthe circuit at test-time. Empirical evaluation demonstrate the effectiveness of\nthe proposed method, offering insights into its performance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u91cf\u5b50\u5206\u7c7b\u5668\u7684\u52a0\u6743\u540c\u8d28\u96c6\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cf\u5b50\u5e76\u884c\u6267\u884c\u591a\u6837\u5316\u7684\u5185\u90e8\u5206\u7c7b\u5668\uff0c\u5e76\u7ed3\u5408\u7ecf\u5178\u6743\u91cd\u4f18\u5316\uff0c\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u901a\u8fc7\u7ed3\u5408\u91cf\u5b50\u8ba1\u7b97\u7684\u5e76\u884c\u6027\u548c\u96c6\u6210\u5b66\u4e60\u7684\u591a\u6837\u6027\uff0c\u63d0\u5347\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u9884\u6d4b\u6027\u80fd\u3002", "method": "\u4f7f\u7528\u91cf\u5b50\u5206\u7c7b\u5668\u548c\u7d22\u5f15\u5bc4\u5b58\u5668\u8fdb\u884c\u6570\u636e\u7f16\u7801\uff0c\u901a\u8fc7\u53e0\u52a0\u548c\u63a7\u5236\u95e8\u5b9e\u73b0\u7279\u5f81\u548c\u8bad\u7ec3\u70b9\u5b50\u91c7\u6837\uff0c\u91cf\u5b50\u5e76\u884c\u6267\u884c\u591a\u6837\u5316\u5185\u90e8\u5206\u7c7b\u5668\uff0c\u5e76\u7ed3\u5408\u7ecf\u5178\u6743\u91cd\u4f18\u5316\u3002", "result": "\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\u8be5\u65b9\u6cd5\u6709\u6548\uff0c\u63d0\u4f9b\u4e86\u6027\u80fd\u63d0\u5347\u7684\u89c1\u89e3\u3002", "conclusion": "\u63d0\u51fa\u7684\u91cf\u5b50\u52a0\u6743\u540c\u8d28\u96c6\u6210\u65b9\u6cd5\u5728\u9884\u6d4b\u51c6\u786e\u6027\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5c55\u793a\u4e86\u91cf\u5b50\u8ba1\u7b97\u5728\u96c6\u6210\u5b66\u4e60\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.07816", "pdf": "https://arxiv.org/pdf/2506.07816", "abs": "https://arxiv.org/abs/2506.07816", "authors": ["Yingli Wang", "Changwei Tu", "Xiaoyu Wang", "Lingjiong Zhu"], "title": "Accelerating Constrained Sampling: A Large Deviations Approach", "categories": ["stat.ML", "cs.LG", "math.PR"], "comment": "40 pages, 7 figures", "summary": "The problem of sampling a target probability distribution on a constrained\ndomain arises in many applications including machine learning. For constrained\nsampling, various Langevin algorithms such as projected Langevin Monte Carlo\n(PLMC) based on the discretization of reflected Langevin dynamics (RLD) and\nmore generally skew-reflected non-reversible Langevin Monte Carlo (SRNLMC)\nbased on the discretization of skew-reflected non-reversible Langevin dynamics\n(SRNLD) have been proposed and studied in the literature. This work focuses on\nthe long-time behavior of SRNLD, where a skew-symmetric matrix is added to RLD.\nAlthough the non-asymptotic convergence analysis for SRNLD (and SRNLMC) and the\nacceleration compared to RLD (and PMLC) have been studied in the literature, it\nis not clear how one should design the skew-symmetric matrix in the dynamics to\nachieve good performance in practice. We establish a large deviation principle\n(LDP) for the empirical measure of SRNLD when the skew-symmetric matrix is\nchosen such that its product with the inward unit normal vector field on the\nboundary is zero. By explicitly characterizing the rate functions, we show that\nSRNLD can accelerate the convergence to the target distribution compared to RLD\nwith this choice of the skew-symmetric matrix. Numerical experiments for SRNLMC\nbased on the proposed skew-symmetric matrix show superior performance which\nvalidate the theoretical findings from the large deviations theory.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u504f\u659c\u53cd\u5c04\u975e\u53ef\u9006\u6717\u4e4b\u4e07\u52a8\u529b\u5b66\uff08SRNLD\uff09\u7684\u957f\u671f\u884c\u4e3a\uff0c\u901a\u8fc7\u8bbe\u8ba1\u5408\u9002\u7684\u504f\u659c\u5bf9\u79f0\u77e9\u9635\uff0c\u8bc1\u660e\u4e86\u5176\u6bd4\u53cd\u5c04\u6717\u4e4b\u4e07\u52a8\u529b\u5b66\uff08RLD\uff09\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u679c\u3002", "motivation": "\u5728\u7ea6\u675f\u57df\u4e0a\u91c7\u6837\u76ee\u6807\u6982\u7387\u5206\u5e03\u662f\u673a\u5668\u5b66\u4e60\u7b49\u5e94\u7528\u4e2d\u7684\u91cd\u8981\u95ee\u9898\u3002\u867d\u7136\u5df2\u6709\u7814\u7a76\u63a2\u8ba8\u4e86SRNLD\u7684\u975e\u6e10\u8fd1\u6536\u655b\u6027\u548c\u52a0\u901f\u6548\u679c\uff0c\u4f46\u5982\u4f55\u8bbe\u8ba1\u504f\u659c\u5bf9\u79f0\u77e9\u9635\u4ee5\u4f18\u5316\u6027\u80fd\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u901a\u8fc7\u5efa\u7acbSRNLD\u7ecf\u9a8c\u6d4b\u5ea6\u7684\u5927\u504f\u5dee\u539f\u7406\uff08LDP\uff09\uff0c\u5e76\u660e\u786e\u8868\u5f81\u901f\u7387\u51fd\u6570\uff0c\u7814\u7a76\u504f\u659c\u5bf9\u79f0\u77e9\u9635\u7684\u8bbe\u8ba1\u53ca\u5176\u5bf9\u6536\u655b\u901f\u5ea6\u7684\u5f71\u54cd\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u5f53\u504f\u659c\u5bf9\u79f0\u77e9\u9635\u6ee1\u8db3\u7279\u5b9a\u6761\u4ef6\u65f6\uff0cSRNLD\u6bd4RLD\u66f4\u5feb\u6536\u655b\u5230\u76ee\u6807\u5206\u5e03\u3002\u6570\u503c\u5b9e\u9a8c\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u8fd9\u4e00\u7406\u8bba\u53d1\u73b0\u3002", "conclusion": "\u901a\u8fc7\u5408\u7406\u8bbe\u8ba1\u504f\u659c\u5bf9\u79f0\u77e9\u9635\uff0cSRNLD\u5728\u7ea6\u675f\u91c7\u6837\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2506.07826", "pdf": "https://arxiv.org/pdf/2506.07826", "abs": "https://arxiv.org/abs/2506.07826", "authors": ["William Ljungbergh", "Bernardo Taveira", "Wenzhao Zheng", "Adam Tonderski", "Chensheng Peng", "Fredrik Kahl", "Christoffer Petersson", "Michael Felsberg", "Kurt Keutzer", "Masayoshi Tomizuka", "Wei Zhan"], "title": "R3D2: Realistic 3D Asset Insertion via Diffusion for Autonomous Driving Simulation", "categories": ["cs.CV", "cs.LG", "cs.RO"], "comment": null, "summary": "Validating autonomous driving (AD) systems requires diverse and\nsafety-critical testing, making photorealistic virtual environments essential.\nTraditional simulation platforms, while controllable, are resource-intensive to\nscale and often suffer from a domain gap with real-world data. In contrast,\nneural reconstruction methods like 3D Gaussian Splatting (3DGS) offer a\nscalable solution for creating photorealistic digital twins of real-world\ndriving scenes. However, they struggle with dynamic object manipulation and\nreusability as their per-scene optimization-based methodology tends to result\nin incomplete object models with integrated illumination effects. This paper\nintroduces R3D2, a lightweight, one-step diffusion model designed to overcome\nthese limitations and enable realistic insertion of complete 3D assets into\nexisting scenes by generating plausible rendering effects-such as shadows and\nconsistent lighting-in real time. This is achieved by training R3D2 on a novel\ndataset: 3DGS object assets are generated from in-the-wild AD data using an\nimage-conditioned 3D generative model, and then synthetically placed into\nneural rendering-based virtual environments, allowing R3D2 to learn realistic\nintegration. Quantitative and qualitative evaluations demonstrate that R3D2\nsignificantly enhances the realism of inserted assets, enabling use-cases like\ntext-to-3D asset insertion and cross-scene/dataset object transfer, allowing\nfor true scalability in AD validation. To promote further research in scalable\nand realistic AD simulation, we will release our dataset and code, see\nhttps://research.zenseact.com/publications/R3D2/.", "AI": {"tldr": "R3D2\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u6269\u6563\u6a21\u578b\uff0c\u7528\u4e8e\u5728\u81ea\u52a8\u9a7e\u9a76\u9a8c\u8bc1\u4e2d\u5b9e\u73b0\u771f\u5b9e3D\u8d44\u4ea7\u63d2\u5165\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u52a8\u6001\u5bf9\u8c61\u64cd\u4f5c\u548c\u53ef\u91cd\u7528\u6027\u95ee\u9898\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u9a8c\u8bc1\u9700\u8981\u591a\u6837\u5316\u548c\u5b89\u5168\u5173\u952e\u7684\u6d4b\u8bd5\uff0c\u4f20\u7edf\u4eff\u771f\u5e73\u53f0\u8d44\u6e90\u5bc6\u96c6\u4e14\u5b58\u5728\u9886\u57df\u5dee\u8ddd\uff0c\u800c\u795e\u7ecf\u91cd\u5efa\u65b9\u6cd5\u59823DGS\u5728\u52a8\u6001\u5bf9\u8c61\u64cd\u4f5c\u548c\u53ef\u91cd\u7528\u6027\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002", "method": "R3D2\u901a\u8fc7\u4e00\u6b65\u6269\u6563\u6a21\u578b\u751f\u6210\u903c\u771f\u7684\u6e32\u67d3\u6548\u679c\uff08\u5982\u9634\u5f71\u548c\u4e00\u81f4\u5149\u7167\uff09\uff0c\u8bad\u7ec3\u6570\u636e\u6765\u81ea3DGS\u5bf9\u8c61\u8d44\u4ea7\uff0c\u8fd9\u4e9b\u8d44\u4ea7\u7531\u56fe\u50cf\u6761\u4ef63D\u751f\u6210\u6a21\u578b\u4ece\u771f\u5b9e\u9a7e\u9a76\u6570\u636e\u4e2d\u751f\u6210\u3002", "result": "R3D2\u663e\u8457\u63d0\u5347\u4e86\u63d2\u5165\u8d44\u4ea7\u7684\u771f\u5b9e\u611f\uff0c\u652f\u6301\u6587\u672c\u52303D\u8d44\u4ea7\u63d2\u5165\u548c\u8de8\u573a\u666f/\u6570\u636e\u96c6\u5bf9\u8c61\u8f6c\u79fb\uff0c\u5b9e\u73b0\u4e86\u81ea\u52a8\u9a7e\u9a76\u9a8c\u8bc1\u7684\u771f\u6b63\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "R3D2\u4e3a\u81ea\u52a8\u9a7e\u9a76\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u903c\u771f\u7684\u4eff\u771f\u89e3\u51b3\u65b9\u6848\uff0c\u672a\u6765\u5c06\u516c\u5f00\u6570\u636e\u96c6\u548c\u4ee3\u7801\u4ee5\u4fc3\u8fdb\u7814\u7a76\u3002"}}
{"id": "2506.07844", "pdf": "https://arxiv.org/pdf/2506.07844", "abs": "https://arxiv.org/abs/2506.07844", "authors": ["Mingzhou Liu", "Xinwei Sun", "Yizhou Wang"], "title": "Conditional Local Independence Testing with Application to Dynamic Causal Discovery", "categories": ["stat.ME", "cs.LG"], "comment": "Working paper", "summary": "In this note, we extend the conditional local independence testing theory\ndeveloped in Christgau et al. (2024) to Ito processes. The result can be\napplied to causal discovery in dynamic systems.", "AI": {"tldr": "\u5c06\u6761\u4ef6\u5c40\u90e8\u72ec\u7acb\u6027\u68c0\u9a8c\u7406\u8bba\u6269\u5c55\u5230Ito\u8fc7\u7a0b\uff0c\u9002\u7528\u4e8e\u52a8\u6001\u7cfb\u7edf\u4e2d\u7684\u56e0\u679c\u53d1\u73b0\u3002", "motivation": "\u6269\u5c55\u73b0\u6709\u7406\u8bba\u4ee5\u9002\u7528\u4e8e\u66f4\u5e7f\u6cdb\u7684\u52a8\u6001\u7cfb\u7edf\uff0c\u63d0\u5347\u56e0\u679c\u53d1\u73b0\u7684\u9002\u7528\u6027\u3002", "method": "\u57fa\u4e8eChristgau\u7b49\u4eba\u7684\u7406\u8bba\uff0c\u5c06\u5176\u6269\u5c55\u5230Ito\u8fc7\u7a0b\u3002", "result": "\u7406\u8bba\u6269\u5c55\u6210\u529f\uff0c\u9002\u7528\u4e8e\u52a8\u6001\u7cfb\u7edf\u7684\u56e0\u679c\u53d1\u73b0\u3002", "conclusion": "\u6269\u5c55\u540e\u7684\u7406\u8bba\u4e3a\u52a8\u6001\u7cfb\u7edf\u4e2d\u7684\u56e0\u679c\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2506.07857", "pdf": "https://arxiv.org/pdf/2506.07857", "abs": "https://arxiv.org/abs/2506.07857", "authors": ["Zihui Zhang", "Weisheng Dai", "Hongtao Wen", "Bo Yang"], "title": "LogoSP: Local-global Grouping of Superpoints for Unsupervised Semantic Segmentation of 3D Point Clouds", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "comment": "CVPR 2025. Code and data are available at:\n  https://github.com/vLAR-group/LogoSP", "summary": "We study the problem of unsupervised 3D semantic segmentation on raw point\nclouds without needing human labels in training. Existing methods usually\nformulate this problem into learning per-point local features followed by a\nsimple grouping strategy, lacking the ability to discover additional and\npossibly richer semantic priors beyond local features. In this paper, we\nintroduce LogoSP to learn 3D semantics from both local and global point\nfeatures. The key to our approach is to discover 3D semantic information by\ngrouping superpoints according to their global patterns in the frequency\ndomain, thus generating highly accurate semantic pseudo-labels for training a\nsegmentation network. Extensive experiments on two indoor and an outdoor\ndatasets show that our LogoSP surpasses all existing unsupervised methods by\nlarge margins, achieving the state-of-the-art performance for unsupervised 3D\nsemantic segmentation. Notably, our investigation into the learned global\npatterns reveals that they truly represent meaningful 3D semantics in the\nabsence of human labels during training.", "AI": {"tldr": "LogoSP\u662f\u4e00\u79cd\u65e0\u76d1\u77633D\u8bed\u4e49\u5206\u5272\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u5c40\u90e8\u548c\u5168\u5c40\u70b9\u7279\u5f81\u5b66\u4e603D\u8bed\u4e49\uff0c\u5229\u7528\u9891\u57df\u4e2d\u7684\u5168\u5c40\u6a21\u5f0f\u751f\u6210\u9ad8\u7cbe\u5ea6\u4f2a\u6807\u7b7e\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4ec5\u4f9d\u8d56\u5c40\u90e8\u7279\u5f81\uff0c\u7f3a\u4e4f\u53d1\u73b0\u66f4\u4e30\u5bcc\u8bed\u4e49\u5148\u9a8c\u7684\u80fd\u529b\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u7ed3\u5408\u5168\u5c40\u7279\u5f81\u7684\u65b9\u6cd5\u3002", "method": "LogoSP\u901a\u8fc7\u9891\u57df\u4e2d\u7684\u5168\u5c40\u6a21\u5f0f\u5bf9\u8d85\u70b9\u8fdb\u884c\u5206\u7ec4\uff0c\u751f\u6210\u8bed\u4e49\u4f2a\u6807\u7b7e\uff0c\u7528\u4e8e\u8bad\u7ec3\u5206\u5272\u7f51\u7edc\u3002", "result": "\u5728\u4e24\u4e2a\u5ba4\u5185\u548c\u4e00\u4e2a\u5ba4\u5916\u6570\u636e\u96c6\u4e0a\uff0cLogoSP\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65e0\u76d1\u7763\u65b9\u6cd5\uff0c\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "LogoSP\u8bc1\u660e\u4e86\u5728\u65e0\u4eba\u7c7b\u6807\u7b7e\u7684\u60c5\u51b5\u4e0b\uff0c\u5168\u5c40\u6a21\u5f0f\u80fd\u591f\u6709\u6548\u8868\u793a\u6709\u610f\u4e49\u76843D\u8bed\u4e49\u3002"}}
{"id": "2506.07859", "pdf": "https://arxiv.org/pdf/2506.07859", "abs": "https://arxiv.org/abs/2506.07859", "authors": ["Amanuel Anteneh L\u00e9andre Brunel", "Carlos Gonz\u00e1lez-Arciniegas", "Olivier Pfister"], "title": "Deep reinforcement learning for near-deterministic preparation of cubic- and quartic-phase gates in photonic quantum computing", "categories": ["quant-ph", "cs.LG"], "comment": null, "summary": "Cubic-phase states are a sufficient resource for universal quantum computing\nover continuous variables. We present results from numerical experiments in\nwhich deep neural networks are trained via reinforcement learning to control a\nquantum optical circuit for generating cubic-phase states, with an average\nsuccess rate of 96%. The only non-Gaussian resource required is\nphoton-number-resolving measurements. We also show that the exact same\nresources enable the direct generation of a quartic-phase gate, with no need\nfor a cubic gate decomposition.", "AI": {"tldr": "\u5229\u7528\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u63a7\u5236\u91cf\u5b50\u5149\u5b66\u7535\u8def\u751f\u6210\u7acb\u65b9\u76f8\u4f4d\u6001\uff0c\u5e73\u5747\u6210\u529f\u738796%\uff0c\u4ec5\u9700\u5149\u5b50\u6570\u5206\u8fa8\u6d4b\u91cf\u4f5c\u4e3a\u975e\u9ad8\u65af\u8d44\u6e90\u3002", "motivation": "\u7acb\u65b9\u76f8\u4f4d\u6001\u662f\u5b9e\u73b0\u8fde\u7eed\u53d8\u91cf\u901a\u7528\u91cf\u5b50\u8ba1\u7b97\u7684\u5145\u5206\u8d44\u6e90\uff0c\u7814\u7a76\u5982\u4f55\u9ad8\u6548\u751f\u6210\u6b64\u7c7b\u6001\u3002", "method": "\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff0c\u63a7\u5236\u91cf\u5b50\u5149\u5b66\u7535\u8def\u751f\u6210\u7acb\u65b9\u76f8\u4f4d\u6001\u3002", "result": "\u5e73\u5747\u6210\u529f\u7387\u8fbe96%\uff0c\u4e14\u65e0\u9700\u9ad8\u65af\u8d44\u6e90\uff0c\u4ec5\u9700\u5149\u5b50\u6570\u5206\u8fa8\u6d4b\u91cf\u3002\u540c\u65f6\u53ef\u76f4\u63a5\u751f\u6210\u56db\u6b21\u76f8\u4f4d\u95e8\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u9ad8\u6548\u751f\u6210\u7acb\u65b9\u76f8\u4f4d\u6001\uff0c\u5e76\u6269\u5c55\u81f3\u56db\u6b21\u76f8\u4f4d\u95e8\uff0c\u4e3a\u91cf\u5b50\u8ba1\u7b97\u63d0\u4f9b\u65b0\u9014\u5f84\u3002"}}
{"id": "2506.07863", "pdf": "https://arxiv.org/pdf/2506.07863", "abs": "https://arxiv.org/abs/2506.07863", "authors": ["Lev Novitskiy", "Viacheslav Vasilev", "Maria Kovaleva", "Vladimir Arkhipkin", "Denis Dimitrov"], "title": "VIVAT: Virtuous Improving VAE Training through Artifact Mitigation", "categories": ["cs.CV", "cs.LG", "cs.MM"], "comment": null, "summary": "Variational Autoencoders (VAEs) remain a cornerstone of generative computer\nvision, yet their training is often plagued by artifacts that degrade\nreconstruction and generation quality. This paper introduces VIVAT, a\nsystematic approach to mitigating common artifacts in KL-VAE training without\nrequiring radical architectural changes. We present a detailed taxonomy of five\nprevalent artifacts - color shift, grid patterns, blur, corner and droplet\nartifacts - and analyze their root causes. Through straightforward\nmodifications, including adjustments to loss weights, padding strategies, and\nthe integration of Spatially Conditional Normalization, we demonstrate\nsignificant improvements in VAE performance. Our method achieves\nstate-of-the-art results in image reconstruction metrics (PSNR and SSIM) across\nmultiple benchmarks and enhances text-to-image generation quality, as evidenced\nby superior CLIP scores. By preserving the simplicity of the KL-VAE framework\nwhile addressing its practical challenges, VIVAT offers actionable insights for\nresearchers and practitioners aiming to optimize VAE training.", "AI": {"tldr": "VIVAT\u901a\u8fc7\u7b80\u5355\u8c03\u6574\u635f\u5931\u6743\u91cd\u3001\u586b\u5145\u7b56\u7565\u548c\u5f15\u5165\u7a7a\u95f4\u6761\u4ef6\u5f52\u4e00\u5316\uff0c\u6709\u6548\u51cf\u5c11KL-VAE\u8bad\u7ec3\u4e2d\u7684\u5e38\u89c1\u4f2a\u5f71\uff0c\u63d0\u5347\u91cd\u5efa\u548c\u751f\u6210\u8d28\u91cf\u3002", "motivation": "KL-VAE\u8bad\u7ec3\u4e2d\u5e38\u89c1\u7684\u4f2a\u5f71\uff08\u5982\u989c\u8272\u504f\u79fb\u3001\u7f51\u683c\u6a21\u5f0f\u7b49\uff09\u5f71\u54cd\u91cd\u5efa\u548c\u751f\u6210\u8d28\u91cf\uff0c\u4e9f\u9700\u89e3\u51b3\u3002", "method": "\u63d0\u51faVIVAT\u65b9\u6cd5\uff0c\u5305\u62ec\u635f\u5931\u6743\u91cd\u8c03\u6574\u3001\u586b\u5145\u7b56\u7565\u6539\u8fdb\u548c\u7a7a\u95f4\u6761\u4ef6\u5f52\u4e00\u5316\uff0c\u65e0\u9700\u5927\u5e45\u6539\u52a8\u67b6\u6784\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u6700\u4f73\u56fe\u50cf\u91cd\u5efa\u6307\u6807\uff08PSNR\u548cSSIM\uff09\uff0c\u5e76\u63d0\u5347\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u7684CLIP\u5206\u6570\u3002", "conclusion": "VIVAT\u5728\u4fdd\u6301KL-VAE\u6846\u67b6\u7b80\u5355\u6027\u7684\u540c\u65f6\uff0c\u89e3\u51b3\u4e86\u5b9e\u9645\u8bad\u7ec3\u4e2d\u7684\u95ee\u9898\uff0c\u4e3a\u4f18\u5316VAE\u8bad\u7ec3\u63d0\u4f9b\u4e86\u5b9e\u7528\u65b9\u6848\u3002"}}
{"id": "2506.07865", "pdf": "https://arxiv.org/pdf/2506.07865", "abs": "https://arxiv.org/abs/2506.07865", "authors": ["Jinxi Li", "Ziyang Song", "Siyuan Zhou", "Bo Yang"], "title": "FreeGave: 3D Physics Learning from Dynamic Videos by Gaussian Velocity", "categories": ["cs.CV", "cs.AI", "cs.CE", "cs.LG", "cs.RO"], "comment": "CVPR 2025. Code and data are available at:\n  https://github.com/vLAR-group/FreeGave", "summary": "In this paper, we aim to model 3D scene geometry, appearance, and the\nunderlying physics purely from multi-view videos. By applying various governing\nPDEs as PINN losses or incorporating physics simulation into neural networks,\nexisting works often fail to learn complex physical motions at boundaries or\nrequire object priors such as masks or types. In this paper, we propose\nFreeGave to learn the physics of complex dynamic 3D scenes without needing any\nobject priors. The key to our approach is to introduce a physics code followed\nby a carefully designed divergence-free module for estimating a per-Gaussian\nvelocity field, without relying on the inefficient PINN losses. Extensive\nexperiments on three public datasets and a newly collected challenging\nreal-world dataset demonstrate the superior performance of our method for\nfuture frame extrapolation and motion segmentation. Most notably, our\ninvestigation into the learned physics codes reveals that they truly learn\nmeaningful 3D physical motion patterns in the absence of any human labels in\ntraining.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faFreeGave\u65b9\u6cd5\uff0c\u65e0\u9700\u7269\u4f53\u5148\u9a8c\u5373\u53ef\u5b66\u4e60\u590d\u6742\u52a8\u60013D\u573a\u666f\u7684\u7269\u7406\u7279\u6027\uff0c\u901a\u8fc7\u5f15\u5165\u7269\u7406\u7f16\u7801\u548c\u6563\u5ea6\u81ea\u7531\u6a21\u5757\uff0c\u663e\u8457\u63d0\u5347\u4e86\u672a\u6765\u5e27\u9884\u6d4b\u548c\u8fd0\u52a8\u5206\u5272\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742\u7269\u7406\u8fd0\u52a8\u65f6\u4f9d\u8d56\u7269\u4f53\u5148\u9a8c\u6216\u4f4e\u6548\u7684PINN\u635f\u5931\uff0c\u65e0\u6cd5\u6709\u6548\u5b66\u4e60\u8fb9\u754c\u52a8\u6001\u3002", "method": "\u63d0\u51faFreeGave\u65b9\u6cd5\uff0c\u5f15\u5165\u7269\u7406\u7f16\u7801\u548c\u6563\u5ea6\u81ea\u7531\u6a21\u5757\uff0c\u4f30\u8ba1\u6bcf\u9ad8\u65af\u901f\u5ea6\u573a\uff0c\u907f\u514d\u4f7f\u7528PINN\u635f\u5931\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5171\u6570\u636e\u96c6\u548c\u65b0\u6536\u96c6\u7684\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u7269\u7406\u7f16\u7801\u6210\u529f\u5b66\u4e60\u65e0\u6807\u7b7e\u76843D\u7269\u7406\u8fd0\u52a8\u6a21\u5f0f\u3002", "conclusion": "FreeGave\u65b9\u6cd5\u65e0\u9700\u5148\u9a8c\u5373\u53ef\u5b66\u4e60\u590d\u6742\u7269\u7406\u52a8\u6001\uff0c\u4e3a3D\u573a\u666f\u5efa\u6a21\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.07888", "pdf": "https://arxiv.org/pdf/2506.07888", "abs": "https://arxiv.org/abs/2506.07888", "authors": ["Rui Wen", "Yiyong Liu", "Michael Backes", "Yang Zhang"], "title": "SoK: Data Reconstruction Attacks Against Machine Learning Models: Definition, Metrics, and Benchmark", "categories": ["cs.CR", "cs.LG"], "comment": "To Appear in the 34th USENIX Security Symposium, August 13-15, 2025", "summary": "Data reconstruction attacks, which aim to recover the training dataset of a\ntarget model with limited access, have gained increasing attention in recent\nyears. However, there is currently no consensus on a formal definition of data\nreconstruction attacks or appropriate evaluation metrics for measuring their\nquality. This lack of rigorous definitions and universal metrics has hindered\nfurther advancement in this field. In this paper, we address this issue in the\nvision domain by proposing a unified attack taxonomy and formal definitions of\ndata reconstruction attacks. We first propose a set of quantitative evaluation\nmetrics that consider important criteria such as quantifiability, consistency,\nprecision, and diversity. Additionally, we leverage large language models\n(LLMs) as a substitute for human judgment, enabling visual evaluation with an\nemphasis on high-quality reconstructions. Using our proposed taxonomy and\nmetrics, we present a unified framework for systematically evaluating the\nstrengths and limitations of existing attacks and establishing a benchmark for\nfuture research. Empirical results, primarily from a memorization perspective,\nnot only validate the effectiveness of our metrics but also offer valuable\ninsights for designing new attacks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u6570\u636e\u91cd\u5efa\u653b\u51fb\u5206\u7c7b\u548c\u6b63\u5f0f\u5b9a\u4e49\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u5957\u91cf\u5316\u8bc4\u4f30\u6307\u6807\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u66ff\u4ee3\u4eba\u5de5\u8bc4\u4f30\uff0c\u5efa\u7acb\u4e86\u4e00\u4e2a\u7cfb\u7edf\u8bc4\u4f30\u6846\u67b6\u3002", "motivation": "\u6570\u636e\u91cd\u5efa\u653b\u51fb\u9886\u57df\u7f3a\u4e4f\u7edf\u4e00\u7684\u5b9a\u4e49\u548c\u8bc4\u4f30\u6807\u51c6\uff0c\u963b\u788d\u4e86\u8fdb\u4e00\u6b65\u7814\u7a76\u3002", "method": "\u63d0\u51fa\u653b\u51fb\u5206\u7c7b\u548c\u5b9a\u4e49\uff0c\u8bbe\u8ba1\u91cf\u5316\u6307\u6807\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u89c6\u89c9\u8bc4\u4f30\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u9a8c\u8bc1\u4e86\u6307\u6807\u7684\u6709\u6548\u6027\uff0c\u5e76\u4e3a\u65b0\u653b\u51fb\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002", "conclusion": "\u672c\u6587\u4e3a\u6570\u636e\u91cd\u5efa\u653b\u51fb\u7814\u7a76\u63d0\u4f9b\u4e86\u7edf\u4e00\u6846\u67b6\u548c\u8bc4\u4f30\u57fa\u51c6\u3002"}}
{"id": "2506.07897", "pdf": "https://arxiv.org/pdf/2506.07897", "abs": "https://arxiv.org/abs/2506.07897", "authors": ["Shuja Khalid", "Mohamed Ibrahim", "Yang Liu"], "title": "GaussianVAE: Adaptive Learning Dynamics of 3D Gaussians for High-Fidelity Super-Resolution", "categories": ["cs.GR", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "We present a novel approach for enhancing the resolution and geometric\nfidelity of 3D Gaussian Splatting (3DGS) beyond native training resolution.\nCurrent 3DGS methods are fundamentally limited by their input resolution,\nproducing reconstructions that cannot extrapolate finer details than are\npresent in the training views. Our work breaks this limitation through a\nlightweight generative model that predicts and refines additional 3D Gaussians\nwhere needed most. The key innovation is our Hessian-assisted sampling\nstrategy, which intelligently identifies regions that are likely to benefit\nfrom densification, ensuring computational efficiency. Unlike computationally\nintensive GANs or diffusion approaches, our method operates in real-time\n(0.015s per inference on a single consumer-grade GPU), making it practical for\ninteractive applications. Comprehensive experiments demonstrate significant\nimprovements in both geometric accuracy and rendering quality compared to\nstate-of-the-art methods, establishing a new paradigm for resolution-free 3D\nscene enhancement.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u751f\u6210\u6a21\u578b\uff0c\u901a\u8fc7Hessian\u8f85\u52a9\u91c7\u6837\u7b56\u7565\u63d0\u53473D\u9ad8\u65af\u6cfc\u6e85\u7684\u5206\u8fa8\u7387\u548c\u51e0\u4f55\u4fdd\u771f\u5ea6\uff0c\u7a81\u7834\u8f93\u5165\u5206\u8fa8\u7387\u7684\u9650\u5236\u3002", "motivation": "\u5f53\u524d3DGS\u65b9\u6cd5\u53d7\u9650\u4e8e\u8f93\u5165\u5206\u8fa8\u7387\uff0c\u65e0\u6cd5\u91cd\u5efa\u6bd4\u8bad\u7ec3\u89c6\u56fe\u66f4\u7cbe\u7ec6\u7684\u7ec6\u8282\u3002", "method": "\u91c7\u7528\u8f7b\u91cf\u7ea7\u751f\u6210\u6a21\u578b\u9884\u6d4b\u548c\u7ec6\u5316\u989d\u5916\u76843D\u9ad8\u65af\u5206\u5e03\uff0c\u7ed3\u5408Hessian\u8f85\u52a9\u91c7\u6837\u7b56\u7565\u667a\u80fd\u8bc6\u522b\u9700\u8981\u5bc6\u96c6\u5316\u7684\u533a\u57df\u3002", "result": "\u5728\u5355\u6d88\u8d39\u7ea7GPU\u4e0a\u5b9e\u73b0\u5b9e\u65f6\u63a8\u7406\uff080.015s/\u6b21\uff09\uff0c\u51e0\u4f55\u7cbe\u5ea6\u548c\u6e32\u67d3\u8d28\u91cf\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u4e3a\u5206\u8fa8\u7387\u65e0\u5173\u76843D\u573a\u666f\u589e\u5f3a\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\u3002"}}
{"id": "2506.07899", "pdf": "https://arxiv.org/pdf/2506.07899", "abs": "https://arxiv.org/abs/2506.07899", "authors": ["Ke Wang", "Yiming Qin", "Nikolaos Dimitriadis", "Alessandro Favero", "Pascal Frossard"], "title": "MEMOIR: Lifelong Model Editing with Minimal Overwrite and Informed Retention for LLMs", "categories": ["cs.CL", "cs.LG"], "comment": "The first two authors contributed equally to this work", "summary": "Language models deployed in real-world systems often require post-hoc updates\nto incorporate new or corrected knowledge. However, editing such models\nefficiently and reliably - without retraining or forgetting previous\ninformation - remains a major challenge. Existing methods for lifelong model\nediting either compromise generalization, interfere with past edits, or fail to\nscale to long editing sequences. We propose MEMOIR, a novel scalable framework\nthat injects knowledge through a residual memory, i.e., a dedicated parameter\nmodule, while preserving the core capabilities of the pre-trained model. By\nsparsifying input activations through sample-dependent masks, MEMOIR confines\neach edit to a distinct subset of the memory parameters, minimizing\ninterference among edits. At inference, it identifies relevant edits by\ncomparing the sparse activation patterns of new queries to those stored during\nediting. This enables generalization to rephrased queries by activating only\nthe relevant knowledge while suppressing unnecessary memory activation for\nunrelated prompts. Experiments on question answering, hallucination correction,\nand out-of-distribution generalization benchmarks across LLaMA-3 and Mistral\ndemonstrate that MEMOIR achieves state-of-the-art performance across\nreliability, generalization, and locality metrics, scaling to thousands of\nsequential edits with minimal forgetting.", "AI": {"tldr": "MEMOIR\u662f\u4e00\u79cd\u65b0\u578b\u7684\u53ef\u6269\u5c55\u6846\u67b6\uff0c\u901a\u8fc7\u6b8b\u5dee\u8bb0\u5fc6\u6a21\u5757\u6ce8\u5165\u77e5\u8bc6\uff0c\u907f\u514d\u5e72\u6270\u548c\u9057\u5fd8\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u6301\u7eed\u7f16\u8f91\u3002", "motivation": "\u89e3\u51b3\u8bed\u8a00\u6a21\u578b\u5728\u5b9e\u65f6\u66f4\u65b0\u77e5\u8bc6\u65f6\u9762\u4e34\u7684\u6548\u7387\u3001\u53ef\u9760\u6027\u548c\u6269\u5c55\u6027\u95ee\u9898\uff0c\u907f\u514d\u91cd\u8bad\u7ec3\u6216\u9057\u5fd8\u5df2\u6709\u4fe1\u606f\u3002", "method": "\u901a\u8fc7\u6837\u672c\u4f9d\u8d56\u7684\u63a9\u7801\u7a00\u758f\u5316\u8f93\u5165\u6fc0\u6d3b\uff0c\u5c06\u6bcf\u4e2a\u7f16\u8f91\u9650\u5236\u5728\u8bb0\u5fc6\u53c2\u6570\u7684\u7279\u5b9a\u5b50\u96c6\uff0c\u51cf\u5c11\u7f16\u8f91\u95f4\u7684\u5e72\u6270\u3002\u63a8\u7406\u65f6\u901a\u8fc7\u7a00\u758f\u6fc0\u6d3b\u6a21\u5f0f\u5339\u914d\u76f8\u5173\u7f16\u8f91\u3002", "result": "\u5728\u95ee\u7b54\u3001\u5e7b\u89c9\u4fee\u6b63\u548c\u5206\u5e03\u5916\u6cdb\u5316\u4efb\u52a1\u4e2d\uff0cMEMOIR\u5728\u53ef\u9760\u6027\u3001\u6cdb\u5316\u6027\u548c\u5c40\u90e8\u6027\u6307\u6807\u4e0a\u8868\u73b0\u6700\u4f18\uff0c\u652f\u6301\u6570\u5343\u6b21\u8fde\u7eed\u7f16\u8f91\u4e14\u9057\u5fd8\u6700\u5c0f\u3002", "conclusion": "MEMOIR\u4e3a\u8bed\u8a00\u6a21\u578b\u7684\u6301\u7eed\u77e5\u8bc6\u66f4\u65b0\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u9760\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.07925", "pdf": "https://arxiv.org/pdf/2506.07925", "abs": "https://arxiv.org/abs/2506.07925", "authors": ["Yaxita Amin", "Naimisha S Trivedi", "Rashmi Bhattad"], "title": "A Comparative Study of U-Net Architectures for Change Detection in Satellite Images", "categories": ["cs.CV", "cs.LG", "eess.IV"], "comment": null, "summary": "Remote sensing change detection is essential for monitoring the everchanging\nlandscapes of the Earth. The U-Net architecture has gained popularity for its\ncapability to capture spatial information and perform pixel-wise\nclassification. However, their application in the Remote sensing field remains\nlargely unexplored. Therefore, this paper fill the gap by conducting a\ncomprehensive analysis of 34 papers. This study conducts a comparison and\nanalysis of 18 different U-Net variations, assessing their potential for\ndetecting changes in remote sensing. We evaluate both benefits along with\ndrawbacks of each variation within the framework of this particular\napplication. We emphasize variations that are explicitly built for change\ndetection, such as Siamese Swin-U-Net, which utilizes a Siamese architecture.\nThe analysis highlights the significance of aspects such as managing data from\ndifferent time periods and collecting relationships over a long distance to\nenhance the precision of change detection. This study provides valuable\ninsights for researchers and practitioners that choose U-Net versions for\nremote sensing change detection tasks.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e8634\u7bc7\u6587\u732e\uff0c\u6bd4\u8f83\u4e8618\u79cdU-Net\u53d8\u4f53\u5728\u9065\u611f\u53d8\u5316\u68c0\u6d4b\u4e2d\u7684\u5e94\u7528\uff0c\u91cd\u70b9\u8bc4\u4f30\u4e86\u5176\u4f18\u7f3a\u70b9\uff0c\u5e76\u63a8\u8350\u4e86\u9002\u5408\u7684\u53d8\u4f53\u3002", "motivation": "\u586b\u8865U-Net\u5728\u9065\u611f\u53d8\u5316\u68c0\u6d4b\u9886\u57df\u5e94\u7528\u7684\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u5bf934\u7bc7\u6587\u732e\u8fdb\u884c\u7efc\u5408\u5206\u6790\uff0c\u6bd4\u8f8318\u79cdU-Net\u53d8\u4f53\u7684\u6027\u80fd\u3002", "result": "\u53d1\u73b0Siamese Swin-U-Net\u7b49\u53d8\u4f53\u5728\u53d8\u5316\u68c0\u6d4b\u4e2d\u8868\u73b0\u7a81\u51fa\uff0c\u5f3a\u8c03\u4e86\u591a\u65f6\u76f8\u6570\u636e\u7ba1\u7406\u548c\u957f\u8ddd\u79bb\u5173\u7cfb\u6355\u6349\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u4e3a\u7814\u7a76\u8005\u548c\u5b9e\u8df5\u8005\u9009\u62e9U-Net\u53d8\u4f53\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u53c2\u8003\u3002"}}
{"id": "2506.07927", "pdf": "https://arxiv.org/pdf/2506.07927", "abs": "https://arxiv.org/abs/2506.07927", "authors": ["Jiayi Sheng", "Luna Lyu", "Jikai Jin", "Tony Xia", "Alex Gu", "James Zou", "Pan Lu"], "title": "Solving Inequality Proofs with Large Language Models", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "52 pages, 16 figures", "summary": "Inequality proving, crucial across diverse scientific and mathematical\nfields, tests advanced reasoning skills such as discovering tight bounds and\nstrategic theorem application. This makes it a distinct, demanding frontier for\nlarge language models (LLMs), offering insights beyond general mathematical\nproblem-solving. Progress in this area is hampered by existing datasets that\nare often scarce, synthetic, or rigidly formal. We address this by proposing an\ninformal yet verifiable task formulation, recasting inequality proving into two\nautomatically checkable subtasks: bound estimation and relation prediction.\nBuilding on this, we release IneqMath, an expert-curated dataset of\nOlympiad-level inequalities, including a test set and training corpus enriched\nwith step-wise solutions and theorem annotations. We also develop a novel\nLLM-as-judge evaluation framework, combining a final-answer judge with four\nstep-wise judges designed to detect common reasoning flaws. A systematic\nevaluation of 29 leading LLMs on IneqMath reveals a surprising reality: even\ntop models like o1 achieve less than 10% overall accuracy under step-wise\nscrutiny; this is a drop of up to 65.5% from their accuracy considering only\nfinal answer equivalence. This discrepancy exposes fragile deductive chains and\na critical gap for current LLMs between merely finding an answer and\nconstructing a rigorous proof. Scaling model size and increasing test-time\ncomputation yield limited gains in overall proof correctness. Instead, our\nfindings highlight promising research directions such as theorem-guided\nreasoning and self-refinement. Code and data are available at\nhttps://ineqmath.github.io/.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u975e\u6b63\u5f0f\u4f46\u53ef\u9a8c\u8bc1\u7684\u4e0d\u7b49\u5f0f\u8bc1\u660e\u4efb\u52a1\uff0c\u5e76\u53d1\u5e03\u4e86IneqMath\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u4e8629\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u53d1\u73b0\u5176\u5728\u9010\u6b65\u63a8\u7406\u4e2d\u5b58\u5728\u663e\u8457\u7f3a\u9677\u3002", "motivation": "\u4e0d\u7b49\u5f0f\u8bc1\u660e\u662f\u6570\u5b66\u548c\u79d1\u5b66\u9886\u57df\u7684\u91cd\u8981\u6280\u80fd\uff0c\u4f46\u73b0\u6709\u6570\u636e\u96c6\u7a00\u7f3a\u6216\u5f62\u5f0f\u5316\uff0c\u9650\u5236\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6b64\u9886\u57df\u7684\u53d1\u5c55\u3002", "method": "\u5c06\u4e0d\u7b49\u5f0f\u8bc1\u660e\u5206\u4e3a\u4e24\u4e2a\u53ef\u81ea\u52a8\u68c0\u67e5\u7684\u5b50\u4efb\u52a1\uff1a\u8fb9\u754c\u4f30\u8ba1\u548c\u5173\u7cfb\u9884\u6d4b\uff0c\u5e76\u5f00\u53d1\u4e86IneqMath\u6570\u636e\u96c6\u53ca\u57fa\u4e8eLLM\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "result": "\u8bc4\u4f30\u663e\u793a\uff0c\u5373\u4f7f\u662f\u9876\u7ea7\u6a21\u578b\u5728\u9010\u6b65\u63a8\u7406\u4e2d\u7684\u51c6\u786e\u7387\u4f4e\u4e8e10%\uff0c\u8fdc\u4f4e\u4e8e\u4ec5\u8003\u8651\u6700\u7ec8\u7b54\u6848\u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u5f53\u524dLLM\u5728\u4e25\u8c28\u8bc1\u660e\u4e2d\u7684\u4e0d\u8db3\uff0c\u5e76\u63d0\u51fa\u4e86\u5b9a\u7406\u5f15\u5bfc\u63a8\u7406\u548c\u81ea\u6211\u4f18\u5316\u7b49\u672a\u6765\u65b9\u5411\u3002"}}
{"id": "2506.07932", "pdf": "https://arxiv.org/pdf/2506.07932", "abs": "https://arxiv.org/abs/2506.07932", "authors": ["Rishit Dagli", "Yushi Guan", "Sankeerth Durvasula", "Mohammadreza Mofayezi", "Nandita Vijaykumar"], "title": "Squeeze3D: Your 3D Generation Model is Secretly an Extreme Neural Compressor", "categories": ["cs.GR", "cs.CV", "cs.LG"], "comment": null, "summary": "We propose Squeeze3D, a novel framework that leverages implicit prior\nknowledge learnt by existing pre-trained 3D generative models to compress 3D\ndata at extremely high compression ratios. Our approach bridges the latent\nspaces between a pre-trained encoder and a pre-trained generation model through\ntrainable mapping networks. Any 3D model represented as a mesh, point cloud, or\na radiance field is first encoded by the pre-trained encoder and then\ntransformed (i.e. compressed) into a highly compact latent code. This latent\ncode can effectively be used as an extremely compressed representation of the\nmesh or point cloud. A mapping network transforms the compressed latent code\ninto the latent space of a powerful generative model, which is then conditioned\nto recreate the original 3D model (i.e. decompression). Squeeze3D is trained\nentirely on generated synthetic data and does not require any 3D datasets. The\nSqueeze3D architecture can be flexibly used with existing pre-trained 3D\nencoders and existing generative models. It can flexibly support different\nformats, including meshes, point clouds, and radiance fields. Our experiments\ndemonstrate that Squeeze3D achieves compression ratios of up to 2187x for\ntextured meshes, 55x for point clouds, and 619x for radiance fields while\nmaintaining visual quality comparable to many existing methods. Squeeze3D only\nincurs a small compression and decompression latency since it does not involve\ntraining object-specific networks to compress an object.", "AI": {"tldr": "Squeeze3D\u662f\u4e00\u79cd\u65b0\u578b\u6846\u67b6\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u76843D\u751f\u6210\u6a21\u578b\u7684\u9690\u5f0f\u5148\u9a8c\u77e5\u8bc6\uff0c\u5b9e\u73b0\u6781\u9ad8\u538b\u7f29\u6bd4\u76843D\u6570\u636e\u538b\u7f29\u3002", "motivation": "\u73b0\u67093D\u6570\u636e\u538b\u7f29\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u5b9e\u73b0\u9ad8\u538b\u7f29\u6bd4\u548c\u9ad8\u8d28\u91cf\u8fd8\u539f\uff0cSqueeze3D\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u53ef\u8bad\u7ec3\u7684\u6620\u5c04\u7f51\u7edc\u8fde\u63a5\u9884\u8bad\u7ec3\u7f16\u7801\u5668\u548c\u751f\u6210\u6a21\u578b\u7684\u6f5c\u5728\u7a7a\u95f4\uff0c\u5c063D\u6570\u636e\u538b\u7f29\u4e3a\u7d27\u51d1\u7684\u6f5c\u5728\u4ee3\u7801\uff0c\u518d\u901a\u8fc7\u751f\u6210\u6a21\u578b\u8fd8\u539f\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0cSqueeze3D\u5bf9\u7eb9\u7406\u7f51\u683c\u3001\u70b9\u4e91\u548c\u8f90\u5c04\u573a\u7684\u538b\u7f29\u6bd4\u5206\u522b\u9ad8\u8fbe2187x\u300155x\u548c619x\uff0c\u4e14\u89c6\u89c9\u8d28\u91cf\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u5f53\u3002", "conclusion": "Squeeze3D\u65e0\u9700\u8bad\u7ec3\u5bf9\u8c61\u7279\u5b9a\u7f51\u7edc\uff0c\u652f\u6301\u591a\u79cd3D\u683c\u5f0f\uff0c\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u7075\u6d3b\u7684\u538b\u7f29\u6846\u67b6\u3002"}}
{"id": "2506.07936", "pdf": "https://arxiv.org/pdf/2506.07936", "abs": "https://arxiv.org/abs/2506.07936", "authors": ["Chengyue Huang", "Yuchen Zhu", "Sichen Zhu", "Jingyun Xiao", "Moises Andrade", "Shivang Chopra", "Zsolt Kira"], "title": "Mimicking or Reasoning: Rethinking Multi-Modal In-Context Learning in Vision-Language Models", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Vision-language models (VLMs) are widely assumed to exhibit in-context\nlearning (ICL), a property similar to that of their language-only counterparts.\nWhile recent work suggests VLMs can perform multimodal ICL (MM-ICL), studies\nshow they often rely on shallow heuristics -- such as copying or majority\nvoting -- rather than true task understanding. We revisit this assumption by\nevaluating VLMs under distribution shifts, where support examples come from a\ndataset different from the query. Surprisingly, performance often degrades with\nmore demonstrations, and models tend to copy answers rather than learn from\nthem. To investigate further, we propose a new MM-ICL with Reasoning pipeline\nthat augments each demonstration with a generated rationale alongside the\nanswer. We conduct extensive and comprehensive experiments on both perception-\nand reasoning-required datasets with open-source VLMs ranging from 3B to 72B\nand proprietary models such as Gemini 2.0. We conduct controlled studies\nvarying shot count, retrieval method, rationale quality, and distribution. Our\nresults show limited performance sensitivity across these factors, suggesting\nthat current VLMs do not effectively utilize demonstration-level information as\nintended in MM-ICL.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u5f53\u524d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u5728\u591a\u6a21\u6001\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08MM-ICL\uff09\u4e2d\u4f9d\u8d56\u6d45\u5c42\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u800c\u975e\u771f\u6b63\u7406\u89e3\u4efb\u52a1\u3002\u901a\u8fc7\u5206\u5e03\u504f\u79fb\u5b9e\u9a8c\u548c\u63d0\u51fa\u7684\u65b0\u65b9\u6cd5\uff0c\u53d1\u73b0\u6a21\u578b\u6027\u80fd\u5e76\u672a\u6709\u6548\u5229\u7528\u6f14\u793a\u4fe1\u606f\u3002", "motivation": "\u9a8c\u8bc1\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u662f\u5426\u771f\u6b63\u5177\u5907\u591a\u6a21\u6001\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\uff0c\u800c\u975e\u4f9d\u8d56\u6d45\u5c42\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "method": "\u63d0\u51faMM-ICL with Reasoning\u7ba1\u9053\uff0c\u4e3a\u6bcf\u4e2a\u6f14\u793a\u751f\u6210\u7b54\u6848\u548c\u63a8\u7406\u8fc7\u7a0b\uff0c\u5e76\u5728\u4e0d\u540c\u6570\u636e\u96c6\u548c\u6a21\u578b\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6a21\u578b\u6027\u80fd\u5bf9\u6f14\u793a\u6570\u91cf\u3001\u68c0\u7d22\u65b9\u6cd5\u7b49\u4e0d\u654f\u611f\uff0c\u672a\u80fd\u6709\u6548\u5229\u7528\u6f14\u793a\u4fe1\u606f\u3002", "conclusion": "\u5f53\u524d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6a21\u6001\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e2d\u8868\u73b0\u6709\u9650\uff0c\u9700\u8fdb\u4e00\u6b65\u6539\u8fdb\u4ee5\u63d0\u5347\u4efb\u52a1\u7406\u89e3\u80fd\u529b\u3002"}}
{"id": "2506.07940", "pdf": "https://arxiv.org/pdf/2506.07940", "abs": "https://arxiv.org/abs/2506.07940", "authors": ["Christopher Subia-Waud"], "title": "Gradients: When Markets Meet Fine-tuning -- A Distributed Approach to Model Optimisation", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Foundation model fine-tuning faces a fundamental challenge: existing AutoML\nplatforms rely on single optimisation strategies that explore only a fraction\nof viable hyperparameter configurations. In this white paper, We introduce\nGradients, a decentralised AutoML platform that transforms hyperparameter\noptimisation into a competitive marketplace where independent miners compete to\ndiscover optimal configurations. Economic incentives align individual\nexploration with collective optimisation goals, driving systematic\ninvestigation of hyperparameter regions that centralised methods miss. We\nevaluate our approach across 180 controlled experiments spanning diverse model\narchitectures (70M to 70B parameters) and task types. Gradients achieves an\n82.8\\% win rate against HuggingFace AutoTrain and 100\\% against TogetherAI,\nDatabricks, and Google Cloud, with mean improvements of 11.8\\% and 42.1\\%\nrespectively. Complex reasoning and retrieval tasks show particularly strong\ngains of 30-40\\%, whilst diffusion models achieve 23.4\\% improvements for\nperson-specific generation. These results demonstrate that competitive,\neconomically-driven approaches can systematically discover superior\nconfigurations that centralised AutoML consistently miss.", "AI": {"tldr": "Gradients\u662f\u4e00\u4e2a\u53bb\u4e2d\u5fc3\u5316\u7684AutoML\u5e73\u53f0\uff0c\u901a\u8fc7\u7ade\u4e89\u6027\u5e02\u573a\u673a\u5236\u4f18\u5316\u8d85\u53c2\u6570\u914d\u7f6e\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u96c6\u4e2d\u5f0f\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709AutoML\u5e73\u53f0\u4f9d\u8d56\u5355\u4e00\u4f18\u5316\u7b56\u7565\uff0c\u4ec5\u63a2\u7d22\u90e8\u5206\u53ef\u884c\u8d85\u53c2\u6570\u914d\u7f6e\uff0c\u9650\u5236\u4e86\u6027\u80fd\u63d0\u5347\u3002", "method": "\u5c06\u8d85\u53c2\u6570\u4f18\u5316\u8f6c\u5316\u4e3a\u7ade\u4e89\u6027\u5e02\u573a\uff0c\u72ec\u7acb\u77ff\u5de5\u901a\u8fc7\u7ecf\u6d4e\u6fc0\u52b1\u7ade\u4e89\u53d1\u73b0\u6700\u4f18\u914d\u7f6e\u3002", "result": "\u5728180\u4e2a\u5b9e\u9a8c\u4e2d\uff0cGradients\u4ee582.8%\u80dc\u7387\u4f18\u4e8eHuggingFace AutoTrain\uff0c100%\u4f18\u4e8e\u5176\u4ed6\u5e73\u53f0\uff0c\u5e73\u5747\u63d0\u534711.8%-42.1%\u3002", "conclusion": "\u7ecf\u6d4e\u9a71\u52a8\u7684\u7ade\u4e89\u6027\u65b9\u6cd5\u80fd\u7cfb\u7edf\u6027\u53d1\u73b0\u96c6\u4e2d\u5f0fAutoML\u9057\u6f0f\u7684\u4f18\u8d8a\u914d\u7f6e\u3002"}}
{"id": "2506.07952", "pdf": "https://arxiv.org/pdf/2506.07952", "abs": "https://arxiv.org/abs/2506.07952", "authors": ["George Orfanides", "Tim Hoheisel", "Marwa El Halabi"], "title": "Discrete and Continuous Difference of Submodular Minimization", "categories": ["math.OC", "cs.DS", "cs.LG"], "comment": null, "summary": "Submodular functions, defined on continuous or discrete domains, arise in\nnumerous applications. We study the minimization of the difference of two\nsubmodular (DS) functions, over both domains, extending prior work restricted\nto set functions. We show that all functions on discrete domains and all smooth\nfunctions on continuous domains are DS. For discrete domains, we observe that\nDS minimization is equivalent to minimizing the difference of two convex (DC)\nfunctions, as in the set function case. We propose a novel variant of the DC\nAlgorithm (DCA) and apply it to the resulting DC Program, obtaining comparable\ntheoretical guarantees as in the set function case. The algorithm can be\napplied to continuous domains via discretization. Experiments demonstrate that\nour method outperforms baselines in integer compressive sensing and integer\nleast squares.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u8fde\u7eed\u548c\u79bb\u6563\u57df\u4e0a\u4e24\u4e2a\u5b50\u6a21\u51fd\u6570\u5dee\uff08DS\uff09\u7684\u6700\u5c0f\u5316\u95ee\u9898\uff0c\u6269\u5c55\u4e86\u4e4b\u524d\u4ec5\u9488\u5bf9\u96c6\u5408\u51fd\u6570\u7684\u7814\u7a76\u3002\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684DC\u7b97\u6cd5\u53d8\u4f53\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u5b50\u6a21\u51fd\u6570\u5728\u4f17\u591a\u5e94\u7528\u4e2d\u5e7f\u6cdb\u5b58\u5728\uff0c\u4f46\u4e4b\u524d\u7684\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u96c6\u5408\u51fd\u6570\u4e0a\uff0c\u7f3a\u4e4f\u5bf9\u8fde\u7eed\u548c\u79bb\u6563\u57df\u7684\u7cfb\u7edf\u7814\u7a76\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684DC\u7b97\u6cd5\u53d8\u4f53\uff08DCA\uff09\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u79bb\u6563\u57df\u548c\u8fde\u7eed\u57df\uff08\u901a\u8fc7\u79bb\u6563\u5316\uff09\u7684DS\u6700\u5c0f\u5316\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6574\u6570\u538b\u7f29\u611f\u77e5\u548c\u6574\u6570\u6700\u5c0f\u4e8c\u4e58\u95ee\u9898\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u6269\u5c55\u4e86DS\u6700\u5c0f\u5316\u7684\u9002\u7528\u8303\u56f4\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u6709\u6548\u7684\u7b97\u6cd5\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2506.07956", "pdf": "https://arxiv.org/pdf/2506.07956", "abs": "https://arxiv.org/abs/2506.07956", "authors": ["Tim Vieira", "Tianyu Liu", "Clemente Pasti", "Yahya Emara", "Brian DuSell", "Benjamin LeBrun", "Mario Giulianelli", "Juan Luis Gastaldi", "Timothy J. O'Donnell", "Ryan Cotterell"], "title": "Language Models over Canonical Byte-Pair Encodings", "categories": ["cs.CL", "cs.FL", "cs.LG"], "comment": "ICML 2025", "summary": "Modern language models represent probability distributions over character\nstrings as distributions over (shorter) token strings derived via a\ndeterministic tokenizer, such as byte-pair encoding. While this approach is\nhighly effective at scaling up language models to large corpora, its current\nincarnations have a concerning property: the model assigns nonzero probability\nmass to an exponential number of $\\it{noncanonical}$ token encodings of each\ncharacter string -- these are token strings that decode to valid character\nstrings but are impossible under the deterministic tokenizer (i.e., they will\nnever be seen in any training corpus, no matter how large). This misallocation\nis both erroneous, as noncanonical strings never appear in training data, and\nwasteful, diverting probability mass away from plausible outputs. These are\navoidable mistakes! In this work, we propose methods to enforce canonicality in\ntoken-level language models, ensuring that only canonical token strings are\nassigned positive probability. We present two approaches: (1) canonicality by\nconditioning, leveraging test-time inference strategies without additional\ntraining, and (2) canonicality by construction, a model parameterization that\nguarantees canonical outputs but requires training. We demonstrate that fixing\ncanonicality mistakes improves the likelihood of held-out data for several\nmodels and corpora.", "AI": {"tldr": "\u73b0\u4ee3\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u786e\u5b9a\u6027\u5206\u8bcd\u5668\uff08\u5982\u5b57\u8282\u5bf9\u7f16\u7801\uff09\u5c06\u5b57\u7b26\u5b57\u7b26\u4e32\u7684\u6982\u7387\u5206\u5e03\u8868\u793a\u4e3a\u66f4\u77ed\u7684\u6807\u8bb0\u5b57\u7b26\u4e32\u5206\u5e03\uff0c\u4f46\u5b58\u5728\u975e\u89c4\u8303\u6807\u8bb0\u7f16\u7801\u7684\u95ee\u9898\u3002\u672c\u6587\u63d0\u51fa\u4e24\u79cd\u65b9\u6cd5\u786e\u4fdd\u4ec5\u89c4\u8303\u6807\u8bb0\u5b57\u7b26\u4e32\u83b7\u5f97\u6b63\u6982\u7387\uff0c\u5e76\u8bc1\u660e\u4fee\u6b63\u6b64\u95ee\u9898\u80fd\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u8bed\u8a00\u6a21\u578b\u5bf9\u5b57\u7b26\u5b57\u7b26\u4e32\u7684\u975e\u89c4\u8303\u6807\u8bb0\u7f16\u7801\u5206\u914d\u4e86\u975e\u96f6\u6982\u7387\uff0c\u8fd9\u4e9b\u7f16\u7801\u867d\u80fd\u89e3\u7801\u4e3a\u6709\u6548\u5b57\u7b26\u4e32\u4f46\u5b9e\u9645\u4e0d\u4f1a\u51fa\u73b0\u5728\u8bad\u7ec3\u6570\u636e\u4e2d\uff0c\u5bfc\u81f4\u6982\u7387\u5206\u914d\u9519\u8bef\u4e14\u6d6a\u8d39\u8d44\u6e90\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u65b9\u6cd5\uff1a(1) \u901a\u8fc7\u6761\u4ef6\u63a8\u65ad\u5728\u6d4b\u8bd5\u65f6\u786e\u4fdd\u89c4\u8303\u6807\u8bb0\uff1b(2) \u901a\u8fc7\u6a21\u578b\u53c2\u6570\u5316\u5728\u8bad\u7ec3\u65f6\u4fdd\u8bc1\u89c4\u8303\u8f93\u51fa\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4fee\u6b63\u975e\u89c4\u8303\u6807\u8bb0\u95ee\u9898\u80fd\u63d0\u5347\u591a\u4e2a\u6a21\u578b\u548c\u8bed\u6599\u5e93\u7684\u4f3c\u7136\u6027\u80fd\u3002", "conclusion": "\u786e\u4fdd\u6807\u8bb0\u5b57\u7b26\u4e32\u7684\u89c4\u8303\u6027\u53ef\u907f\u514d\u6982\u7387\u5206\u914d\u9519\u8bef\uff0c\u63d0\u5347\u6a21\u578b\u6548\u7387\u3002"}}
{"id": "2506.07981", "pdf": "https://arxiv.org/pdf/2506.07981", "abs": "https://arxiv.org/abs/2506.07981", "authors": ["Dmitrii Vorobev", "Artem Prosvetov", "Karim Elhadji Daou"], "title": "Real-time Localization of a Soccer Ball from a Single Camera", "categories": ["cs.CV", "cs.LG"], "comment": "13 pages, 4 figures", "summary": "We propose a computationally efficient method for real-time three-dimensional\nfootball trajectory reconstruction from a single broadcast camera. In contrast\nto previous work, our approach introduces a multi-mode state model with $W$\ndiscrete modes to significantly accelerate optimization while preserving\ncentimeter-level accuracy -- even in cases of severe occlusion, motion blur,\nand complex backgrounds. The system operates on standard CPUs and achieves low\nlatency suitable for live broadcast settings. Extensive evaluation on a\nproprietary dataset of 6K-resolution Russian Premier League matches\ndemonstrates performance comparable to multi-camera systems, without the need\nfor specialized or costly infrastructure. This work provides a practical method\nfor accessible and accurate 3D ball tracking in professional football\nenvironments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u5355\u6444\u50cf\u5934\u5b9e\u65f63D\u8db3\u7403\u8f68\u8ff9\u91cd\u5efa\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u6a21\u5f0f\u72b6\u6001\u6a21\u578b\u663e\u8457\u63d0\u5347\u4f18\u5316\u901f\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u5398\u7c73\u7ea7\u7cbe\u5ea6\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u906e\u6321\u3001\u8fd0\u52a8\u6a21\u7cca\u548c\u590d\u6742\u80cc\u666f\u4e0b\u7684\u6027\u80fd\u95ee\u9898\uff0c\u540c\u65f6\u964d\u4f4e\u5bf9\u591a\u6444\u50cf\u5934\u548c\u6602\u8d35\u8bbe\u5907\u7684\u4f9d\u8d56\u3002", "method": "\u91c7\u7528\u591a\u6a21\u5f0f\u72b6\u6001\u6a21\u578b\uff08$W$\u79bb\u6563\u6a21\u5f0f\uff09\u52a0\u901f\u4f18\u5316\uff0c\u9002\u7528\u4e8e\u6807\u51c6CPU\uff0c\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u3002", "result": "\u57286K\u5206\u8fa8\u7387\u4fc4\u7f57\u65af\u8d85\u7ea7\u8054\u8d5b\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u6027\u80fd\u63a5\u8fd1\u591a\u6444\u50cf\u5934\u7cfb\u7edf\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u9ad8\u7cbe\u5ea6\u76843D\u8db3\u7403\u8f68\u8ff9\u8ddf\u8e2a\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u4e13\u4e1a\u8db3\u7403\u73af\u5883\u3002"}}
{"id": "2506.07984", "pdf": "https://arxiv.org/pdf/2506.07984", "abs": "https://arxiv.org/abs/2506.07984", "authors": ["Mingquan Lin", "Gregory Holste", "Song Wang", "Yiliang Zhou", "Yishu Wei", "Imon Banerjee", "Pengyi Chen", "Tianjie Dai", "Yuexi Du", "Nicha C. Dvornek", "Yuyan Ge", "Zuowei Guo", "Shouhei Hanaoka", "Dongkyun Kim", "Pablo Messina", "Yang Lu", "Denis Parra", "Donghyun Son", "\u00c1lvaro Soto", "Aisha Urooj", "Ren\u00e9 Vidal", "Yosuke Yamagishi", "Zefan Yang", "Ruichi Zhang", "Yang Zhou", "Leo Anthony Celi", "Ronald M. Summers", "Zhiyong Lu", "Hao Chen", "Adam Flanders", "George Shih", "Zhangyang Wang", "Yifan Peng"], "title": "CXR-LT 2024: A MICCAI challenge on long-tailed, multi-label, and zero-shot disease classification from chest X-ray", "categories": ["cs.CV", "cs.LG"], "comment": "17 pages, 3 figures", "summary": "The CXR-LT series is a community-driven initiative designed to enhance lung\ndisease classification using chest X-rays (CXR). It tackles challenges in open\nlong-tailed lung disease classification and enhances the measurability of\nstate-of-the-art techniques. The first event, CXR-LT 2023, aimed to achieve\nthese goals by providing high-quality benchmark CXR data for model development\nand conducting comprehensive evaluations to identify ongoing issues impacting\nlung disease classification performance. Building on the success of CXR-LT\n2023, the CXR-LT 2024 expands the dataset to 377,110 chest X-rays (CXRs) and 45\ndisease labels, including 19 new rare disease findings. It also introduces a\nnew focus on zero-shot learning to address limitations identified in the\nprevious event. Specifically, CXR-LT 2024 features three tasks: (i) long-tailed\nclassification on a large, noisy test set, (ii) long-tailed classification on a\nmanually annotated \"gold standard\" subset, and (iii) zero-shot generalization\nto five previously unseen disease findings. This paper provides an overview of\nCXR-LT 2024, detailing the data curation process and consolidating\nstate-of-the-art solutions, including the use of multimodal models for rare\ndisease detection, advanced generative approaches to handle noisy labels, and\nzero-shot learning strategies for unseen diseases. Additionally, the expanded\ndataset enhances disease coverage to better represent real-world clinical\nsettings, offering a valuable resource for future research. By synthesizing the\ninsights and innovations of participating teams, we aim to advance the\ndevelopment of clinically realistic and generalizable diagnostic models for\nchest radiography.", "AI": {"tldr": "CXR-LT 2024\u662f\u4e00\u4e2a\u793e\u533a\u9a71\u52a8\u7684\u9879\u76ee\uff0c\u65e8\u5728\u901a\u8fc7\u6269\u5c55\u6570\u636e\u96c6\u548c\u5f15\u5165\u96f6\u6837\u672c\u5b66\u4e60\u6765\u6539\u8fdb\u80ba\u90e8\u75be\u75c5\u5206\u7c7b\u3002", "motivation": "\u89e3\u51b3\u5f00\u653e\u957f\u5c3e\u80ba\u90e8\u75be\u75c5\u5206\u7c7b\u7684\u6311\u6218\uff0c\u5e76\u63d0\u5347\u73b0\u6709\u6280\u672f\u7684\u53ef\u6d4b\u91cf\u6027\u3002", "method": "\u6269\u5c55\u6570\u636e\u96c6\u81f3377,110\u5f20\u80f8\u90e8X\u5149\u7247\u548c45\u79cd\u75be\u75c5\u6807\u7b7e\uff0c\u5f15\u5165\u96f6\u6837\u672c\u5b66\u4e60\uff0c\u5e76\u8bbe\u8ba1\u4e09\u9879\u4efb\u52a1\uff1a\u957f\u5c3e\u5206\u7c7b\u3001\u9ec4\u91d1\u6807\u51c6\u5b50\u96c6\u5206\u7c7b\u548c\u96f6\u6837\u672c\u6cdb\u5316\u3002", "result": "\u63d0\u4f9b\u4e86\u9ad8\u8d28\u91cf\u7684\u6570\u636e\u96c6\u548c\u5148\u8fdb\u89e3\u51b3\u65b9\u6848\uff0c\u5305\u62ec\u591a\u6a21\u6001\u6a21\u578b\u3001\u751f\u6210\u65b9\u6cd5\u548c\u96f6\u6837\u672c\u5b66\u4e60\u7b56\u7565\u3002", "conclusion": "CXR-LT 2024\u4e3a\u4e34\u5e8a\u73b0\u5b9e\u548c\u6cdb\u5316\u8bca\u65ad\u6a21\u578b\u7684\u5f00\u53d1\u63d0\u4f9b\u4e86\u5b9d\u8d35\u8d44\u6e90\u3002"}}
{"id": "2506.07985", "pdf": "https://arxiv.org/pdf/2506.07985", "abs": "https://arxiv.org/abs/2506.07985", "authors": ["Tuomas Oikarinen", "Ge Yan", "Akshay Kulkarni", "Tsui-Wei Weng"], "title": "Rethinking Crowd-Sourced Evaluation of Neuron Explanations", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Interpreting individual neurons or directions in activations space is an\nimportant component of mechanistic interpretability. As such, many algorithms\nhave been proposed to automatically produce neuron explanations, but it is\noften not clear how reliable these explanations are, or which methods produce\nthe best explanations. This can be measured via crowd-sourced evaluations, but\nthey can often be noisy and expensive, leading to unreliable results. In this\npaper, we carefully analyze the evaluation pipeline and develop a\ncost-effective and highly accurate crowdsourced evaluation strategy. In\ncontrast to previous human studies that only rate whether the explanation\nmatches the most highly activating inputs, we estimate whether the explanation\ndescribes neuron activations across all inputs. To estimate this effectively,\nwe introduce a novel application of importance sampling to determine which\ninputs are the most valuable to show to raters, leading to around 30x cost\nreduction compared to uniform sampling. We also analyze the label noise present\nin crowd-sourced evaluations and propose a Bayesian method to aggregate\nmultiple ratings leading to a further ~5x reduction in number of ratings\nrequired for the same accuracy. Finally, we use these methods to conduct a\nlarge-scale study comparing the quality of neuron explanations produced by the\nmost popular methods for two different vision models.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u4eba\u7fa4\u8bc4\u4f30\u7b56\u7565\uff0c\u7528\u4e8e\u8bc4\u4f30\u795e\u7ecf\u5143\u89e3\u91ca\u7684\u53ef\u9760\u6027\uff0c\u5e76\u901a\u8fc7\u91cd\u8981\u6027\u91c7\u6837\u548c\u8d1d\u53f6\u65af\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u795e\u7ecf\u5143\u89e3\u91ca\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u566a\u97f3\u5927\u3001\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u53ef\u9760\u4e14\u7ecf\u6d4e\u7684\u8bc4\u4f30\u7b56\u7565\u3002", "method": "\u5f15\u5165\u91cd\u8981\u6027\u91c7\u6837\u9009\u62e9\u6700\u6709\u4ef7\u503c\u7684\u8f93\u5165\u6837\u672c\uff0c\u5e76\u63d0\u51fa\u8d1d\u53f6\u65af\u65b9\u6cd5\u805a\u5408\u591a\u4e2a\u8bc4\u5206\uff0c\u663e\u8457\u51cf\u5c11\u6240\u9700\u8bc4\u5206\u6570\u91cf\u3002", "result": "\u5b9e\u73b0\u4e86\u7ea630\u500d\u7684\u6210\u672c\u964d\u4f4e\u548c\u989d\u59165\u500d\u7684\u8bc4\u5206\u6548\u7387\u63d0\u5347\uff0c\u6210\u529f\u6bd4\u8f83\u4e86\u4e24\u79cd\u89c6\u89c9\u6a21\u578b\u7684\u795e\u7ecf\u5143\u89e3\u91ca\u8d28\u91cf\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u4e3a\u795e\u7ecf\u5143\u89e3\u91ca\u7684\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.07999", "pdf": "https://arxiv.org/pdf/2506.07999", "abs": "https://arxiv.org/abs/2506.07999", "authors": ["Junhao Chen", "Yulia Tsvetkov", "Xiaochuang Han"], "title": "MADFormer: Mixed Autoregressive and Diffusion Transformers for Continuous Image Generation", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Recent progress in multimodal generation has increasingly combined\nautoregressive (AR) and diffusion-based approaches, leveraging their\ncomplementary strengths: AR models capture long-range dependencies and produce\nfluent, context-aware outputs, while diffusion models operate in continuous\nlatent spaces to refine high-fidelity visual details. However, existing hybrids\noften lack systematic guidance on how and why to allocate model capacity\nbetween these paradigms. In this work, we introduce MADFormer, a Mixed\nAutoregressive and Diffusion Transformer that serves as a testbed for analyzing\nAR-diffusion trade-offs. MADFormer partitions image generation into spatial\nblocks, using AR layers for one-pass global conditioning across blocks and\ndiffusion layers for iterative local refinement within each block. Through\ncontrolled experiments on FFHQ-1024 and ImageNet, we identify two key insights:\n(1) block-wise partitioning significantly improves performance on\nhigh-resolution images, and (2) vertically mixing AR and diffusion layers\nyields better quality-efficiency balances--improving FID by up to 75% under\nconstrained inference compute. Our findings offer practical design principles\nfor future hybrid generative models.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faMADFormer\uff0c\u7ed3\u5408\u81ea\u56de\u5f52\uff08AR\uff09\u548c\u6269\u6563\u6a21\u578b\uff0c\u901a\u8fc7\u7a7a\u95f4\u5206\u5757\u548c\u6df7\u5408\u5c42\u8bbe\u8ba1\u4f18\u5316\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u751f\u6210\u3002", "motivation": "\u73b0\u6709\u6df7\u5408\u6a21\u578b\u7f3a\u4e4f\u7cfb\u7edf\u6307\u5bfc\uff0c\u65e0\u6cd5\u5408\u7406\u5206\u914dAR\u548c\u6269\u6563\u6a21\u578b\u7684\u80fd\u529b\u3002", "method": "MADFormer\u5c06\u56fe\u50cf\u751f\u6210\u5206\u4e3a\u7a7a\u95f4\u5757\uff0cAR\u5c42\u7528\u4e8e\u5168\u5c40\u6761\u4ef6\uff0c\u6269\u6563\u5c42\u7528\u4e8e\u5c40\u90e8\u7ec6\u5316\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u5206\u5757\u7b56\u7565\u63d0\u5347\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u6027\u80fd\uff0c\u6df7\u5408\u5c42\u8bbe\u8ba1\u5728\u8ba1\u7b97\u53d7\u9650\u4e0bFID\u63d0\u534775%\u3002", "conclusion": "\u7814\u7a76\u4e3a\u672a\u6765\u6df7\u5408\u751f\u6210\u6a21\u578b\u63d0\u4f9b\u4e86\u5b9e\u7528\u8bbe\u8ba1\u539f\u5219\u3002"}}
{"id": "2506.08008", "pdf": "https://arxiv.org/pdf/2506.08008", "abs": "https://arxiv.org/abs/2506.08008", "authors": ["Stephanie Fu", "Tyler Bonnen", "Devin Guillory", "Trevor Darrell"], "title": "Hidden in plain sight: VLMs overlook their visual representations", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Project page: https://hidden-plain-sight.github.io/", "summary": "Language provides a natural interface to specify and evaluate performance on\nvisual tasks. To realize this possibility, vision language models (VLMs) must\nsuccessfully integrate visual and linguistic information. Our work compares\nVLMs to a direct readout of their visual encoders to understand their ability\nto integrate across these modalities. Across a series of vision-centric\nbenchmarks (e.g., depth estimation, correspondence), we find that VLMs perform\nsubstantially worse than their visual encoders, dropping to near-chance\nperformance. We investigate these results through a series of analyses across\nthe entire VLM: namely 1) the degradation of vision representations, 2)\nbrittleness to task prompt, and 3) the language model's role in solving the\ntask. We find that the bottleneck in performing these vision-centric tasks lies\nin this third category; VLMs are not effectively using visual information\neasily accessible throughout the entire model, and they inherit the language\npriors present in the LLM. Our work helps diagnose the failure modes of\nopen-source VLMs, and presents a series of evaluations useful for future\ninvestigations into visual understanding within VLMs.", "AI": {"tldr": "\u8bba\u6587\u6bd4\u8f83\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u4e0e\u5176\u89c6\u89c9\u7f16\u7801\u5668\u7684\u76f4\u63a5\u8f93\u51fa\uff0c\u53d1\u73b0VLMs\u5728\u89c6\u89c9\u4efb\u52a1\u4e2d\u8868\u73b0\u663e\u8457\u8f83\u5dee\uff0c\u63a5\u8fd1\u968f\u673a\u6c34\u5e73\u3002\u74f6\u9888\u5728\u4e8eVLMs\u672a\u80fd\u6709\u6548\u5229\u7528\u89c6\u89c9\u4fe1\u606f\uff0c\u4e14\u7ee7\u627f\u4e86\u8bed\u8a00\u6a21\u578b\u7684\u5148\u9a8c\u3002", "motivation": "\u63a2\u7d22VLMs\u5982\u4f55\u6574\u5408\u89c6\u89c9\u4e0e\u8bed\u8a00\u4fe1\u606f\uff0c\u4ee5\u7406\u89e3\u5176\u5728\u89c6\u89c9\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u901a\u8fc7\u4e00\u7cfb\u5217\u89c6\u89c9\u4e2d\u5fc3\u57fa\u51c6\u6d4b\u8bd5\uff08\u5982\u6df1\u5ea6\u4f30\u8ba1\u3001\u5bf9\u5e94\u5173\u7cfb\uff09\u6bd4\u8f83VLMs\u4e0e\u89c6\u89c9\u7f16\u7801\u5668\u7684\u8868\u73b0\uff0c\u5e76\u5206\u6790VLMs\u7684\u5931\u8d25\u6a21\u5f0f\u3002", "result": "VLMs\u8868\u73b0\u663e\u8457\u4f4e\u4e8e\u89c6\u89c9\u7f16\u7801\u5668\uff0c\u4e3b\u8981\u74f6\u9888\u5728\u4e8e\u672a\u80fd\u6709\u6548\u5229\u7528\u89c6\u89c9\u4fe1\u606f\uff0c\u4e14\u53d7\u8bed\u8a00\u6a21\u578b\u5148\u9a8c\u5f71\u54cd\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u5f00\u6e90VLMs\u7684\u5931\u8d25\u6a21\u5f0f\uff0c\u4e3a\u672a\u6765VLMs\u89c6\u89c9\u7406\u89e3\u7814\u7a76\u63d0\u4f9b\u4e86\u8bc4\u4f30\u65b9\u6cd5\u3002"}}
{"id": "2506.08009", "pdf": "https://arxiv.org/pdf/2506.08009", "abs": "https://arxiv.org/abs/2506.08009", "authors": ["Xun Huang", "Zhengqi Li", "Guande He", "Mingyuan Zhou", "Eli Shechtman"], "title": "Self Forcing: Bridging the Train-Test Gap in Autoregressive Video Diffusion", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Project website: http://self-forcing.github.io/", "summary": "We introduce Self Forcing, a novel training paradigm for autoregressive video\ndiffusion models. It addresses the longstanding issue of exposure bias, where\nmodels trained on ground-truth context must generate sequences conditioned on\ntheir own imperfect outputs during inference. Unlike prior methods that denoise\nfuture frames based on ground-truth context frames, Self Forcing conditions\neach frame's generation on previously self-generated outputs by performing\nautoregressive rollout with key-value (KV) caching during training. This\nstrategy enables supervision through a holistic loss at the video level that\ndirectly evaluates the quality of the entire generated sequence, rather than\nrelying solely on traditional frame-wise objectives. To ensure training\nefficiency, we employ a few-step diffusion model along with a stochastic\ngradient truncation strategy, effectively balancing computational cost and\nperformance. We further introduce a rolling KV cache mechanism that enables\nefficient autoregressive video extrapolation. Extensive experiments demonstrate\nthat our approach achieves real-time streaming video generation with sub-second\nlatency on a single GPU, while matching or even surpassing the generation\nquality of significantly slower and non-causal diffusion models. Project\nwebsite: http://self-forcing.github.io/", "AI": {"tldr": "Self Forcing\u662f\u4e00\u79cd\u65b0\u7684\u81ea\u56de\u5f52\u89c6\u9891\u6269\u6563\u6a21\u578b\u8bad\u7ec3\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u66dd\u5149\u504f\u5dee\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u751f\u6210\u8f93\u51fa\u8fdb\u884c\u8bad\u7ec3\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u9ad8\u8d28\u91cf\u7684\u89c6\u9891\u751f\u6210\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u81ea\u56de\u5f52\u89c6\u9891\u6269\u6563\u6a21\u578b\u5728\u63a8\u7406\u65f6\u56e0\u4f9d\u8d56\u81ea\u8eab\u4e0d\u5b8c\u7f8e\u8f93\u51fa\u800c\u4ea7\u751f\u7684\u66dd\u5149\u504f\u5dee\u95ee\u9898\u3002", "method": "\u91c7\u7528\u81ea\u56de\u5f52\u5c55\u5f00\u548cKV\u7f13\u5b58\u7b56\u7565\uff0c\u7ed3\u5408\u591a\u6b65\u6269\u6563\u6a21\u578b\u548c\u968f\u673a\u68af\u5ea6\u622a\u65ad\uff0c\u5b9e\u73b0\u9ad8\u6548\u8bad\u7ec3\u3002", "result": "\u5728\u5355GPU\u4e0a\u5b9e\u73b0\u4e86\u4e9a\u79d2\u7ea7\u5ef6\u8fdf\u7684\u5b9e\u65f6\u89c6\u9891\u751f\u6210\uff0c\u4e14\u751f\u6210\u8d28\u91cf\u4f18\u4e8e\u6216\u5339\u914d\u975e\u56e0\u679c\u6269\u6563\u6a21\u578b\u3002", "conclusion": "Self Forcing\u901a\u8fc7\u81ea\u751f\u6210\u8f93\u51fa\u548c\u9ad8\u6548\u8bad\u7ec3\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u89c6\u9891\u751f\u6210\u7684\u5b9e\u65f6\u6027\u548c\u8d28\u91cf\u3002"}}
{"id": "2506.08013", "pdf": "https://arxiv.org/pdf/2506.08013", "abs": "https://arxiv.org/abs/2506.08013", "authors": ["Anh-Quan Cao", "Ivan Lopes", "Raoul de Charette"], "title": "StableMTL: Repurposing Latent Diffusion Models for Multi-Task Learning from Partially Annotated Synthetic Datasets", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Code is available at https://github.com/astra-vision/StableMTL", "summary": "Multi-task learning for dense prediction is limited by the need for extensive\nannotation for every task, though recent works have explored training with\npartial task labels. Leveraging the generalization power of diffusion models,\nwe extend the partial learning setup to a zero-shot setting, training a\nmulti-task model on multiple synthetic datasets, each labeled for only a subset\nof tasks. Our method, StableMTL, repurposes image generators for latent\nregression. Adapting a denoising framework with task encoding, per-task\nconditioning and a tailored training scheme. Instead of per-task losses\nrequiring careful balancing, a unified latent loss is adopted, enabling\nseamless scaling to more tasks. To encourage inter-task synergy, we introduce a\nmulti-stream model with a task-attention mechanism that converts N-to-N task\ninteractions into efficient 1-to-N attention, promoting effective cross-task\nsharing. StableMTL outperforms baselines on 7 tasks across 8 benchmarks.", "AI": {"tldr": "StableMTL\u5229\u7528\u6269\u6563\u6a21\u578b\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u8fdb\u884c\u591a\u4efb\u52a1\u5b66\u4e60\uff0c\u901a\u8fc7\u5408\u6210\u6570\u636e\u548c\u4efb\u52a1\u6ce8\u610f\u529b\u673a\u5236\u5b9e\u73b0\u9ad8\u6548\u8de8\u4efb\u52a1\u5171\u4eab\u3002", "motivation": "\u591a\u4efb\u52a1\u5bc6\u96c6\u9884\u6d4b\u9700\u8981\u5927\u91cf\u6807\u6ce8\uff0c\u800c\u90e8\u5206\u6807\u6ce8\u5b66\u4e60\u9650\u5236\u4e86\u6027\u80fd\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u6269\u6563\u6a21\u578b\u548c\u5408\u6210\u6570\u636e\u6269\u5c55\u81f3\u96f6\u6837\u672c\u5b66\u4e60\u3002", "method": "\u91c7\u7528\u6269\u6563\u6a21\u578b\u8fdb\u884c\u6f5c\u5728\u56de\u5f52\uff0c\u7ed3\u5408\u4efb\u52a1\u7f16\u7801\u3001\u4efb\u52a1\u6761\u4ef6\u5316\u548c\u7edf\u4e00\u6f5c\u5728\u635f\u5931\uff0c\u8bbe\u8ba1\u591a\u6d41\u6a21\u578b\u548c\u4efb\u52a1\u6ce8\u610f\u529b\u673a\u5236\u3002", "result": "\u57288\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u76847\u4e2a\u4efb\u52a1\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "StableMTL\u901a\u8fc7\u7edf\u4e00\u635f\u5931\u548c\u4efb\u52a1\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u591a\u4efb\u52a1\u5b66\u4e60\uff0c\u65e0\u9700\u5927\u91cf\u6807\u6ce8\u3002"}}
