{"id": "2509.22710", "pdf": "https://arxiv.org/pdf/2509.22710", "abs": "https://arxiv.org/abs/2509.22710", "authors": ["Pavan Reddy", "Aditya Sanjay Gujral"], "title": "Localizing Adversarial Attacks To Produces More Imperceptible Noise", "categories": ["cs.LG", "cs.AI", "cs.CV", "I.2.6; I.2.10; I.5.1"], "comment": "Published, CC BY-NC 4.0; includes 2 figures and 1 table;\n  InceptionV3/ImageNet evaluation", "summary": "Adversarial attacks in machine learning traditionally focus on global\nperturbations to input data, yet the potential of localized adversarial noise\nremains underexplored. This study systematically evaluates localized\nadversarial attacks across widely-used methods, including FGSM, PGD, and C&W,\nto quantify their effectiveness, imperceptibility, and computational\nefficiency. By introducing a binary mask to constrain noise to specific\nregions, localized attacks achieve significantly lower mean pixel\nperturbations, higher Peak Signal-to-Noise Ratios (PSNR), and improved\nStructural Similarity Index (SSIM) compared to global attacks. However, these\nbenefits come at the cost of increased computational effort and a modest\nreduction in Attack Success Rate (ASR). Our results highlight that iterative\nmethods, such as PGD and C&W, are more robust to localization constraints than\nsingle-step methods like FGSM, maintaining higher ASR and imperceptibility\nmetrics. This work provides a comprehensive analysis of localized adversarial\nattacks, offering practical insights for advancing attack strategies and\ndesigning robust defensive systems."}
{"id": "2509.22764", "pdf": "https://arxiv.org/pdf/2509.22764", "abs": "https://arxiv.org/abs/2509.22764", "authors": ["Liuwang Kang", "Fan Wang", "Shaoshan Liu", "Hung-Chyun Chou", "Chuan Lin", "Ning Ding"], "title": "In-Context Learning can Perform Continual Learning Like Humans", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) can adapt to new tasks via in-context learning\n(ICL) without parameter updates, making them powerful learning engines for fast\nadaptation. While extensive research has examined ICL as a few-shot learner,\nwhether it can achieve long-term retention and cross-task knowledge\naccumulation when multitasks arrive sequentially remains underexplored.\nMotivated by human memory studies, we investigate the retention characteristics\nof ICL in multitask settings and extend it to in-context continual learning\n(ICCL), where continual learning ability emerges through task scheduling and\nprompt rearrangement. Experiments on Markov-Chain benchmarks demonstrate that,\nfor specific large-language models, ICCL benefits from distributed practice\n(DP) in a manner analogous to humans, consistently revealing a spacing \"sweet\nspot\" for retention. Beyond retention performance, we propose a human-retention\nsimilarity metric to quantify how closely a continual-learning (CL) method\naligns with human retention dynamics. Using this metric, we show that\nlinear-attention models such as MAMBA and RWKV exhibit particularly human-like\nretention patterns, despite their retention performance lagging behind that of\nTransformer-based LLMs. Overall, our results establish ICCL as both cognitively\nplausible and practically effective, providing an inference-only CL paradigm\nthat mitigates catastrophic forgetting and addresses the stability-plasticity\ndilemma in conventional CL methods."}
{"id": "2509.22823", "pdf": "https://arxiv.org/pdf/2509.22823", "abs": "https://arxiv.org/abs/2509.22823", "authors": ["Mounssif Krouka", "Mehdi Bennis"], "title": "Communication-Efficient and Interoperable Distributed Learning", "categories": ["cs.LG"], "comment": "Preprint version. Submitted for peer review", "summary": "Collaborative learning across heterogeneous model architectures presents\nsignificant challenges in ensuring interoperability and preserving privacy. We\npropose a communication-efficient distributed learning framework that supports\nmodel heterogeneity and enables modular composition during inference. To\nfacilitate interoperability, all clients adopt a common fusion-layer output\ndimension, which permits each model to be partitioned into a personalized base\nblock and a generalized modular block. Clients share their fusion-layer\noutputs, keeping model parameters and architectures private. Experimental\nresults demonstrate that the framework achieves superior communication\nefficiency compared to federated learning (FL) and federated split learning\n(FSL) baselines, while ensuring stable training performance across\nheterogeneous architectures."}
{"id": "2509.22840", "pdf": "https://arxiv.org/pdf/2509.22840", "abs": "https://arxiv.org/abs/2509.22840", "authors": ["Micah Adler"], "title": "On the Capacity of Self-Attention", "categories": ["cs.LG", "I.2.0"], "comment": null, "summary": "While self-attention is known to learn relations among tokens, we lack a\nformal understanding of its capacity: how many distinct relations can a single\nlayer reliably recover for a given budget?\n  To formalize this, we introduce Relational Graph Recognition (RGR), where the\nkey-query channel represents a graph on $m$ items with $m'$ directed edges,\nand, given a context of items, must recover the neighbors of each item. We\nmeasure resources by the total key dimension $D_K = h\\,d_k$. Within this\nframework, we analytically derive a capacity scaling law and validate it\nempirically. We show that $D_K = \\Theta(m' \\log m' / d_{\\text{model}})$ is both\nnecessary (information-theoretic lower bound) and sufficient (explicit\nconstruction) in a broad class of graphs to recover $m'$ relations. This\nscaling law directly leads to a new, capacity-based rationale for multi-head\nattention that applies even when each item only attends to a single target.\nWhen embeddings are uncompressed ($m = d_{\\text{model}}$) and the graph is a\npermutation, a single head suffices. However, compression ($m >\nd_{\\text{model}}$) forces relations into overlapping subspaces, creating\ninterference that a single large head cannot disentangle. Our analysis shows\nthat allocating a fixed $D_K$ across many small heads mitigates this\ninterference, increasing the number of recoverable relations. Controlled\nsingle-layer experiments mirror the theory, revealing a sharp performance\nthreshold that matches the predicted capacity scaling and confirms the benefit\nof distributing $D_K$ across multiple heads.\n  Altogether, these results provide a concrete scaling law for self-attention\ncapacity and a principled design rule for allocating key-query budget across\nheads."}
{"id": "2509.22850", "pdf": "https://arxiv.org/pdf/2509.22850", "abs": "https://arxiv.org/abs/2509.22850", "authors": ["Roie Kazoom", "Yuval Ratzabi", "Etamar Rothstein", "Ofer Hadar"], "title": "Boundary on the Table: Efficient Black-Box Decision-Based Attacks for Structured Data", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Adversarial robustness in structured data remains an underexplored frontier\ncompared to vision and language domains. In this work, we introduce a novel\nblack-box, decision-based adversarial attack tailored for tabular data. Our\napproach combines gradient-free direction estimation with an iterative boundary\nsearch, enabling efficient navigation of discrete and continuous feature spaces\nunder minimal oracle access. Extensive experiments demonstrate that our method\nsuccessfully compromises nearly the entire test set across diverse models,\nranging from classical machine learning classifiers to large language model\n(LLM)-based pipelines. Remarkably, the attack achieves success rates\nconsistently above 90%, while requiring only a small number of queries per\ninstance. These results highlight the critical vulnerability of tabular models\nto adversarial perturbations, underscoring the urgent need for stronger\ndefenses in real-world decision-making systems."}
{"id": "2509.22851", "pdf": "https://arxiv.org/pdf/2509.22851", "abs": "https://arxiv.org/abs/2509.22851", "authors": ["Yaswanth Chittepu", "Prasann Singhal", "Greg Durrett", "Scott Niekum"], "title": "Adaptive Margin RLHF via Preference over Preferences", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Margin-based optimization is fundamental to improving generalization and\nrobustness in classification tasks. In the context of reward model learning\nfrom preferences within Reinforcement Learning from Human Feedback (RLHF),\nexisting methods typically rely on no margins, fixed margins, or margins that\nare simplistic functions of preference ratings. However, such formulations\noften fail to account for the varying strengths of different preferences, for\nexample some preferences are associated with larger margins between responses,\nor they rely on noisy margin information derived from ratings. We argue that\nmodeling the strength of preferences can lead to better generalization and more\nfaithful alignment. Furthermore, many existing methods that use adaptive\nmargins assume access to accurate preference scores, which can be difficult for\nhumans to provide reliably. We propose an approach that leverages preferences\nover preferences, that is annotations indicating which of two preferences\nreflects a stronger distinction. We use this ordinal signal to infer adaptive\nmargins on a per-datapoint basis. We introduce an extension to Direct\nPreference Optimization (DPO), DPO-PoP, that incorporates adaptive margins from\npreference-over-preference supervision, enabling improved discriminative and\ngenerative performance. Empirically, our method outperforms vanilla DPO, DPO\nwith fixed margins, and DPO with ground-truth margins on the UltraFeedback\ndataset. Additionally, we show that there is a tradeoff between discriminative\nand generative performance: improving test classification accuracy,\nparticularly by correctly labeling weaker preferences at the expense of\nstronger ones, can lead to a decline in generative quality. To navigate this\ntradeoff, we propose two sampling strategies to gather\npreference-over-preference labels: one favoring discriminative performance and\none favoring generative performance."}
{"id": "2509.22855", "pdf": "https://arxiv.org/pdf/2509.22855", "abs": "https://arxiv.org/abs/2509.22855", "authors": ["Sameep Chattopadhyay", "Nikhil Karamchandani", "Sharayu Mohair"], "title": "Observation-Free Attacks on Online Learning to Rank", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Online learning to rank (OLTR) plays a critical role in information retrieval\nand machine learning systems, with a wide range of applications in search\nengines and content recommenders. However, despite their extensive adoption,\nthe susceptibility of OLTR algorithms to coordinated adversarial attacks\nremains poorly understood. In this work, we present a novel framework for\nattacking some of the widely used OLTR algorithms. Our framework is designed to\npromote a set of target items so that they appear in the list of top-K\nrecommendations for T - o(T) rounds, while simultaneously inducing linear\nregret in the learning algorithm. We propose two novel attack strategies:\nCascadeOFA for CascadeUCB1 and PBMOFA for PBM-UCB . We provide theoretical\nguarantees showing that both strategies require only O(log T) manipulations to\nsucceed. Additionally, we supplement our theoretical analysis with empirical\nresults on real-world data."}
{"id": "2509.22868", "pdf": "https://arxiv.org/pdf/2509.22868", "abs": "https://arxiv.org/abs/2509.22868", "authors": ["Zehao Niu", "Mihai Anitescu", "Jie Chen"], "title": "Neighborhood Sampling Does Not Learn the Same Graph Neural Network", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Neighborhood sampling is an important ingredient in the training of\nlarge-scale graph neural networks. It suppresses the exponential growth of the\nneighborhood size across network layers and maintains feasible memory\nconsumption and time costs. While it becomes a standard implementation in\npractice, its systemic behaviors are less understood. We conduct a theoretical\nanalysis by using the tool of neural tangent kernels, which characterize the\n(analogous) training dynamics of neural networks based on their infinitely wide\ncounterparts -- Gaussian processes (GPs). We study several established\nneighborhood sampling approaches and the corresponding posterior GP. With\nlimited samples, the posteriors are all different, although they converge to\nthe same one as the sample size increases. Moreover, the posterior covariance,\nwhich lower-bounds the mean squared prediction error, is uncomparable, aligning\nwith observations that no sampling approach dominates."}
{"id": "2509.22881", "pdf": "https://arxiv.org/pdf/2509.22881", "abs": "https://arxiv.org/abs/2509.22881", "authors": ["Karim Khamaisi", "Nicolas Keller", "Stefan Krummenacher", "Valentin Huber", "Bernhard Fässler", "Bruno Rodrigues"], "title": "From Noise to Knowledge: A Comparative Study of Acoustic Anomaly Detection Models in Pumped-storage Hydropower Plants", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In the context of industrial factories and energy producers, unplanned\noutages are highly costly and difficult to service. However, existing\nacoustic-anomaly detection studies largely rely on generic industrial or\nsynthetic datasets, with few focused on hydropower plants due to limited\naccess. This paper presents a comparative analysis of acoustic-based anomaly\ndetection methods, as a way to improve predictive maintenance in hydropower\nplants. We address key challenges in the acoustic preprocessing under highly\nnoisy conditions before extracting time- and frequency-domain features. Then,\nwe benchmark three machine learning models: LSTM AE, K-Means, and OC-SVM, which\nare tested on two real-world datasets from the Rodundwerk II pumped-storage\nplant in Austria, one with induced anomalies and one with real-world\nconditions. The One-Class SVM achieved the best trade-off of accuracy (ROC AUC\n0.966-0.998) and minimal training time, while the LSTM autoencoder delivered\nstrong detection (ROC AUC 0.889-0.997) at the expense of higher computational\ncost."}
{"id": "2509.22907", "pdf": "https://arxiv.org/pdf/2509.22907", "abs": "https://arxiv.org/abs/2509.22907", "authors": ["Anutam Srinivasan", "Aditya T. Vadlamani", "Amin Meghrazi", "Srinivasan Parthasarathy"], "title": "FedCF: Fair Federated Conformal Prediction", "categories": ["cs.LG"], "comment": "Preprint", "summary": "Conformal Prediction (CP) is a widely used technique for quantifying\nuncertainty in machine learning models. In its standard form, CP offers\nprobabilistic guarantees on the coverage of the true label, but it is agnostic\nto sensitive attributes in the dataset. Several recent works have sought to\nincorporate fairness into CP by ensuring conditional coverage guarantees across\ndifferent subgroups. One such method is Conformal Fairness (CF). In this work,\nwe extend the CF framework to the Federated Learning setting and discuss how we\ncan audit a federated model for fairness by analyzing the fairness-related gaps\nfor different demographic groups. We empirically validate our framework by\nconducting experiments on several datasets spanning multiple domains, fully\nleveraging the exchangeability assumption."}
{"id": "2509.22913", "pdf": "https://arxiv.org/pdf/2509.22913", "abs": "https://arxiv.org/abs/2509.22913", "authors": ["Jake S. Rhodes", "Adam G. Rustad", "Marshall S. Nielsen", "Morgan Chase McClellan", "Dallan Gardner", "Dawson Hedges"], "title": "Guided Manifold Alignment with Geometry-Regularized Twin Autoencoders", "categories": ["cs.LG", "stat.ML"], "comment": "10 pages, 4 figures, 7 tables. Accepted at the MMAI workshop at ICDM,\n  2025", "summary": "Manifold alignment (MA) involves a set of techniques for learning shared\nrepresentations across domains, yet many traditional MA methods are incapable\nof performing out-of-sample extension, limiting their real-world applicability.\nWe propose a guided representation learning framework leveraging a\ngeometry-regularized twin autoencoder (AE) architecture to enhance MA while\nenabling generalization to unseen data. Our method enforces structured\ncross-modal mappings to maintain geometric fidelity in learned embeddings. By\nincorporating a pre-trained alignment model and a multitask learning\nformulation, we improve cross-domain generalization and representation\nrobustness while maintaining alignment fidelity. We evaluate our approach using\nseveral MA methods, showing improvements in embedding consistency, information\npreservation, and cross-domain transfer. Additionally, we apply our framework\nto Alzheimer's disease diagnosis, demonstrating its ability to integrate\nmulti-modal patient data and enhance predictive accuracy in cases limited to a\nsingle domain by leveraging insights from the multi-modal problem."}
{"id": "2509.22921", "pdf": "https://arxiv.org/pdf/2509.22921", "abs": "https://arxiv.org/abs/2509.22921", "authors": ["Matthieu Zimmer", "Xiaotong Ji", "Tu Nguyen", "Haitham Bou Ammar"], "title": "Rethinking Large Language Model Distillation: A Constrained Markov Decision Process Perspective", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We introduce a novel approach to large language model (LLM) distillation by\nformulating it as a constrained reinforcement learning problem. While recent\nwork has begun exploring the integration of task-specific rewards into\ndistillation processes, existing methods typically rely on ad-hoc reward\nweighting. We propose a principled optimization framework that maximizes\ntask-specific rewards while constraining the divergence from the teacher model\nto remain below a specified threshold. Our approach adapts constrained state\naugmented reinforcement learning to the distillation setting, introducing a\nmodified reward function that maintains theoretical guarantees of constraint\nsatisfaction without requiring state augmentation or teacher model access\nduring deployment and without the computational overhead of the dual Lagrangian\nmethods. Through extensive experiments on mathematical reasoning tasks, we\ndemonstrate that our method achieves better constraint satisfaction rates and\nbetter reasoning compared to the soft Lagrangian relaxation baselines while\nmaintaining competitive task performance. Our framework provides a\ntheoretically grounded and practically efficient solution for reward-aware\ndistillation in resource-constrained settings."}
{"id": "2509.22931", "pdf": "https://arxiv.org/pdf/2509.22931", "abs": "https://arxiv.org/abs/2509.22931", "authors": ["Shreyas Gokhale"], "title": "MonoCon: A general framework for learning ultra-compact high-fidelity representations using monotonicity constraints", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "16 pages, 7 figures", "summary": "Learning high-quality, robust, efficient, and disentangled representations is\na central challenge in artificial intelligence (AI). Deep metric learning\nframeworks tackle this challenge primarily using architectural and optimization\nconstraints. Here, we introduce a third approach that instead relies on\n$\\textit{functional}$ constraints. Specifically, we present MonoCon, a simple\nframework that uses a small monotonic multi-layer perceptron (MLP) head\nattached to any pre-trained encoder. Due to co-adaptation between encoder and\nhead guided by contrastive loss and monotonicity constraints, MonoCon learns\nrobust, disentangled, and highly compact embeddings at a practically negligible\nperformance cost. On the CIFAR-100 image classification task, MonoCon yields\nrepresentations that are nearly 9x more compact and 1.5x more robust than the\nfine-tuned encoder baseline, while retaining 99\\% of the baseline's 5-NN\nclassification accuracy. We also report a 3.4x more compact and 1.4x more\nrobust representation on an SNLI sentence similarity task for a marginal\nreduction in the STSb score, establishing MonoCon as a general domain-agnostic\nframework. Crucially, these robust, ultra-compact representations learned via\nfunctional constraints offer a unified solution to critical challenges in\ndisparate contexts ranging from edge computing to cloud-scale retrieval."}
{"id": "2509.22935", "pdf": "https://arxiv.org/pdf/2509.22935", "abs": "https://arxiv.org/abs/2509.22935", "authors": ["Aleksandr Dremov", "David Grangier", "Angelos Katharopoulos", "Awni Hannun"], "title": "Compute-Optimal Quantization-Aware Training", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Quantization-aware training (QAT) is a leading technique for improving the\naccuracy of quantized neural networks. Previous work has shown that decomposing\ntraining into a full-precision (FP) phase followed by a QAT phase yields\nsuperior accuracy compared to QAT alone. However, the optimal allocation of\ncompute between the FP and QAT phases remains unclear. We conduct extensive\nexperiments with various compute budgets, QAT bit widths, and model sizes from\n86.0M to 2.2B to investigate how different QAT durations impact final\nperformance. We demonstrate that, contrary to previous findings, the\nloss-optimal ratio of QAT to FP training increases with the total amount of\ncompute. Moreover, the optimal fraction can be accurately predicted for a wide\nrange of model sizes and quantization widths using the\ntokens-per-parameter-byte statistic. From experimental data, we derive a loss\nscaling law that predicts both optimal QAT ratios and final model performance\nacross different QAT/FP compute allocation strategies and QAT bit widths. We\nuse the scaling law to make further predictions, which we verify\nexperimentally, including which QAT bit width is optimal under a given memory\nconstraint and how QAT accuracy with different bit widths compares to\nfull-precision model accuracy. Additionally, we propose a novel cooldown and\nQAT fusion approach that performs learning rate decay jointly with\nquantization-aware training, eliminating redundant full-precision model updates\nand achieving significant compute savings. These findings provide practical\ninsights into efficient QAT planning and enable the training of higher-quality\nquantized models with the same compute budget."}
{"id": "2509.22938", "pdf": "https://arxiv.org/pdf/2509.22938", "abs": "https://arxiv.org/abs/2509.22938", "authors": ["Yanqing Lu", "Letao Wang", "Jinbo Liu"], "title": "Understanding SOAP from the Perspective of Gradient Whitening", "categories": ["cs.LG"], "comment": null, "summary": "Shampoo with Adam in the Preconditioner's eigenbasis (SOAP) has recently\nemerged as a promising optimization algorithm for neural network training,\nachieving superior training efficiency over both Adam and Shampoo in language\nmodeling tasks. In this work, we analyze Adam, Shampoo, and SOAP from the\nperspective of gradient whitening, interpreting their preconditioners as\napproximations to the whitening matrix, which captures second-order curvature\ninformation. We further establish a theoretical equivalence between idealized\nversions of SOAP and Shampoo under the Kronecker product assumption. To\nempirically evaluate these insights, we reproduce the language modeling\nexperiments using nanoGPT and grayscale image colorization. Our results show\nthat SOAP exhibits similar convergence rate as Shampoo, and no significant\nadvantage over both Adam and Shampoo in the final loss achieved, which aligns\nwith their equivalence in theory."}
{"id": "2509.22944", "pdf": "https://arxiv.org/pdf/2509.22944", "abs": "https://arxiv.org/abs/2509.22944", "authors": ["Lorenz K. Müller", "Philippe Bich", "Jiawei Zhuang", "Ahmet Çelik", "Luca Benfenati", "Lukas Cavigelli"], "title": "SINQ: Sinkhorn-Normalized Quantization for Calibration-Free Low-Precision LLM Weights", "categories": ["cs.LG"], "comment": null, "summary": "Post-training quantization has emerged as the most widely used strategy for\ndeploying large language models at low precision. Still, current methods show\nperplexity degradation at bit-widths less than or equal to 4, partly because\nrepresenting outliers causes precision issues in parameters that share the same\nscales as these outliers. This problem is especially pronounced for\ncalibration-free, uniform quantization methods. We introduce SINQ to augment\nexisting post-training quantizers with an additional second-axis scale factor\nand a fast Sinkhorn-Knopp-style algorithm that finds scales to normalize\nper-row and per-column variances, thereby minimizing a novel per-matrix proxy\ntarget for quantization: the matrix imbalance. Our method has no interactions\nbetween layers and can be trivially applied to new architectures to quantize\nany linear layers. We evaluate our method on the Qwen3 model family and\nDeepSeek-V2.5. SINQ improves WikiText2 and C4 perplexity significantly against\nuncalibrated uniform quantization baselines and can be further enhanced by\ncombining it with calibration and non-uniform quantization levels. Code to\nreproduce the results of this work and to easily quantize models using SINQ is\navailable at https://github.com/huawei-csl/SINQ."}
{"id": "2509.22949", "pdf": "https://arxiv.org/pdf/2509.22949", "abs": "https://arxiv.org/abs/2509.22949", "authors": ["Hamidreza Moazzami", "Asma Jamali", "Nicholas Kevlahan", "Rodrigo A. Vargas-Hernández"], "title": "Meta-Learning Fourier Neural Operators for Hessian Inversion and Enhanced Variational Data Assimilation", "categories": ["cs.LG"], "comment": "6 pages, 2 figures, Machine Learning and the Physical Sciences\n  Workshop, (NeurIPS 2025)", "summary": "Data assimilation (DA) is crucial for enhancing solutions to partial\ndifferential equations (PDEs), such as those in numerical weather prediction,\nby optimizing initial conditions using observational data. Variational DA\nmethods are widely used in oceanic and atmospheric forecasting, but become\ncomputationally expensive, especially when Hessian information is involved. To\naddress this challenge, we propose a meta-learning framework that employs the\nFourier Neural Operator (FNO) to approximate the inverse Hessian operator\nacross a family of DA problems, thereby providing an effective initialization\nfor the conjugate gradient (CG) method. Numerical experiments on a linear\nadvection equation demonstrate that the resulting FNO-CG approach reduces the\naverage relative error by $62\\%$ and the number of iterations by $17\\%$\ncompared to the standard CG. These improvements are most pronounced in\nill-conditioned scenarios, highlighting the robustness and efficiency of FNO-CG\nfor challenging DA problems."}
{"id": "2509.22953", "pdf": "https://arxiv.org/pdf/2509.22953", "abs": "https://arxiv.org/abs/2509.22953", "authors": ["Valentyn Melnychuk", "Stefan Feuerriegel"], "title": "GDR-learners: Orthogonal Learning of Generative Models for Potential Outcomes", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Various deep generative models have been proposed to estimate potential\noutcomes distributions from observational data. However, none of them have the\nfavorable theoretical property of general Neyman-orthogonality and, associated\nwith it, quasi-oracle efficiency and double robustness. In this paper, we\nintroduce a general suite of generative Neyman-orthogonal (doubly-robust)\nlearners that estimate the conditional distributions of potential outcomes. Our\nproposed GDR-learners are flexible and can be instantiated with many\nstate-of-the-art deep generative models. In particular, we develop GDR-learners\nbased on (a) conditional normalizing flows (which we call GDR-CNFs), (b)\nconditional generative adversarial networks (GDR-CGANs), (c) conditional\nvariational autoencoders (GDR-CVAEs), and (d) conditional diffusion models\n(GDR-CDMs). Unlike the existing methods, our GDR-learners possess the\nproperties of quasi-oracle efficiency and rate double robustness, and are thus\nasymptotically optimal. In a series of (semi-)synthetic experiments, we\ndemonstrate that our GDR-learners are very effective and outperform the\nexisting methods in estimating the conditional distributions of potential\noutcomes."}
{"id": "2509.22957", "pdf": "https://arxiv.org/pdf/2509.22957", "abs": "https://arxiv.org/abs/2509.22957", "authors": ["Luke Guerdan", "Justin Whitehouse", "Kimberly Truong", "Kenneth Holstein", "Zhiwei Steven Wu"], "title": "Doubly-Robust LLM-as-a-Judge: Externally Valid Estimation with Imperfect Personas", "categories": ["cs.LG"], "comment": null, "summary": "As Generative AI (GenAI) systems see growing adoption, a key concern involves\nthe external validity of evaluations, or the extent to which they generalize\nfrom lab-based to real-world deployment conditions. Threats to the external\nvalidity of GenAI evaluations arise when the source sample of human raters and\nsystem outputs used to obtain a system quality estimate differs from the target\ndistribution at deployment time. In this work, we propose a doubly-robust\nestimation framework designed to address this evaluation sampling bias. Key to\nour approach is the use of \"persona\" ratings produced by prompting an LLM\nevaluator (i.e., an LLM-as-a-judge) to behave as a human rater with specific\nsociodemographic characteristics. Our doubly-robust framework combines these\ninformative yet imperfect persona ratings with human ratings obtained under\nevaluation sampling bias to produce statistically valid system quality\nestimates. In particular, we show that our approach yields valid system quality\nestimates when either (i) a model trained to predict human ratings using\npersona ratings and source data observed under sampling bias, or (ii) a\nreweighting model that corrects for sampling bias is of sufficient quality. We\nvalidate our framework theoretically and via a novel Persona Simulation\nFramework (PSF) designed to systematically manipulate persona quality and the\ndegree of evaluation sampling bias present in source data. Our work provides a\nprincipled foundation for combining imperfect persona ratings with human\nratings observed under sampling bias to obtain valid system quality estimates."}
{"id": "2509.22963", "pdf": "https://arxiv.org/pdf/2509.22963", "abs": "https://arxiv.org/abs/2509.22963", "authors": ["Haitong Ma", "Ofir Nabati", "Aviv Rosenberg", "Bo Dai", "Oran Lang", "Idan Szpektor", "Craig Boutilier", "Na Li", "Shie Mannor", "Lior Shani", "Guy Tenneholtz"], "title": "Reinforcement Learning with Discrete Diffusion Policies for Combinatorial Action Spaces", "categories": ["cs.LG"], "comment": "22 pages, 10 figures. Haitong Ma and Ofir Nabati contributed equally\n  to this paper", "summary": "Reinforcement learning (RL) struggles to scale to large, combinatorial action\nspaces common in many real-world problems. This paper introduces a novel\nframework for training discrete diffusion models as highly effective policies\nin these complex settings. Our key innovation is an efficient online training\nprocess that ensures stable and effective policy improvement. By leveraging\npolicy mirror descent (PMD) to define an ideal, regularized target policy\ndistribution, we frame the policy update as a distributional matching problem,\ntraining the expressive diffusion model to replicate this stable target. This\ndecoupled approach stabilizes learning and significantly enhances training\nperformance. Our method achieves state-of-the-art results and superior sample\nefficiency across a diverse set of challenging combinatorial benchmarks,\nincluding DNA sequence generation, RL with macro-actions, and multi-agent\nsystems. Experiments demonstrate that our diffusion policies attain superior\nperformance compared to other baselines."}
{"id": "2509.22964", "pdf": "https://arxiv.org/pdf/2509.22964", "abs": "https://arxiv.org/abs/2509.22964", "authors": ["Qinxun Bai", "Yuxuan Han", "Wei Xu", "Zhengyuan Zhou"], "title": "Functional Critic Modeling for Provably Convergent Off-Policy Actor-Critic", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Off-policy reinforcement learning (RL) with function approximation offers an\neffective way to improve sample efficiency by reusing past experience. Within\nthis setting, the actor-critic (AC) framework has achieved strong empirical\nsuccess. However, both the critic and actor learning is challenging for the\noff-policy AC methods: first of all, in addition to the classic \"deadly triad\"\ninstability of off-policy evaluation, it also suffers from a \"moving target\"\nproblem, where the policy being evaluated changes continually; secondly, actor\nlearning becomes less efficient due to the difficulty of estimating the exact\noff-policy policy gradient. The first challenge essentially reduces the problem\nto repeatedly performing off-policy evaluation for changing policies. For the\nsecond challenge, the off-policy policy gradient theorem requires a complex and\noften impractical algorithm to estimate an additional emphasis critic, which is\ntypically neglected in practice, thereby reducing to the on-policy policy\ngradient as an approximation. In this work, we introduce a novel concept of\nfunctional critic modeling, which leads to a new AC framework that addresses\nboth challenges for actor-critic learning under the deadly triad setting. We\nprovide a theoretical analysis in the linear function setting, establishing the\nprovable convergence of our framework, which, to the best of our knowledge, is\nthe first convergent off-policy target-based AC algorithm. From a practical\nperspective, we further propose a carefully designed neural network\narchitecture for the functional critic modeling and demonstrate its\neffectiveness through preliminary experiments on widely used RL tasks from the\nDeepMind Control Benchmark."}
{"id": "2509.22969", "pdf": "https://arxiv.org/pdf/2509.22969", "abs": "https://arxiv.org/abs/2509.22969", "authors": ["Samuel V. Singh", "Shirley Coyle", "Mimi Zhang"], "title": "Shape-Informed Clustering of Multi-Dimensional Functional Data via Deep Functional Autoencoders", "categories": ["cs.LG"], "comment": null, "summary": "We introduce FAEclust, a novel functional autoencoder framework for cluster\nanalysis of multi-dimensional functional data, data that are random\nrealizations of vector-valued random functions. Our framework features a\nuniversal-approximator encoder that captures complex nonlinear\ninterdependencies among component functions, and a universal-approximator\ndecoder capable of accurately reconstructing both Euclidean and manifold-valued\nfunctional data. Stability and robustness are enhanced through innovative\nregularization strategies applied to functional weights and biases.\nAdditionally, we incorporate a clustering loss into the network's training\nobjective, promoting the learning of latent representations that are conducive\nto effective clustering. A key innovation is our shape-informed clustering\nobjective, ensuring that the clustering results are resistant to phase\nvariations in the functions. We establish the universal approximation property\nof our non-linear decoder and validate the effectiveness of our model through\nextensive experiments."}
{"id": "2509.22979", "pdf": "https://arxiv.org/pdf/2509.22979", "abs": "https://arxiv.org/abs/2509.22979", "authors": ["Zeyi Chen", "Xinzhi Zhang", "Humishka Zope", "Hugo Barbalho", "Konstantina Mellou", "Marco Molinaro", "Janardhan Kulkarni", "Ishai Menache", "Sirui Li"], "title": "OptiMind: Teaching LLMs to Think Like Optimization Experts", "categories": ["cs.LG"], "comment": null, "summary": "Mathematical programming -- the task of expressing operations and\ndecision-making problems in precise mathematical language -- is fundamental\nacross domains, yet remains a skill-intensive process requiring operations\nresearch expertise. Recent advances in large language models for complex\nreasoning have spurred interest in automating this task, translating natural\nlanguage into executable optimization models. Current approaches, however,\nachieve limited accuracy, hindered by scarce and noisy training data without\nleveraging domain knowledge. In this work, we systematically integrate\noptimization expertise to improve formulation accuracy for mixed-integer linear\nprogramming, a key family of mathematical programs. Our approach first cleans\ntraining data through class-based error analysis to explicitly prevent common\nmistakes within each optimization class. We then develop multi-turn inference\nstrategies that guide LLMs with class-specific error summaries and solver\nfeedback, enabling iterative refinement. Experiments across multiple base LLMs\ndemonstrate that combining cleaned data with domain-informed prompting and\nfeedback improves formulation accuracy by 14 percentage points on average,\nenabling further progress toward robust LLM-assisted optimization formulation."}
{"id": "2509.22981", "pdf": "https://arxiv.org/pdf/2509.22981", "abs": "https://arxiv.org/abs/2509.22981", "authors": ["David P. Morton", "Oscar Dowson", "Bernardo K. Pagnoncelli"], "title": "MDP modeling for multi-stage stochastic programs", "categories": ["cs.LG", "math.OC", "90C15, 90C40"], "comment": null, "summary": "We study a class of multi-stage stochastic programs, which incorporate\nmodeling features from Markov decision processes (MDPs). This class includes\nstructured MDPs with continuous state and action spaces. We extend policy\ngraphs to include decision-dependent uncertainty for one-step transition\nprobabilities as well as a limited form of statistical learning. We focus on\nthe expressiveness of our modeling approach, illustrating ideas with a series\nof examples of increasing complexity. As a solution method, we develop new\nvariants of stochastic dual dynamic programming, including approximations to\nhandle non-convexities."}
{"id": "2509.22992", "pdf": "https://arxiv.org/pdf/2509.22992", "abs": "https://arxiv.org/abs/2509.22992", "authors": ["Yuanyuan Yang", "Ruimin Zhang", "Jamie Morgenstern", "Haifeng Xu"], "title": "T-TAMER: Provably Taming Trade-offs in ML Serving", "categories": ["cs.LG", "cs.GT"], "comment": "Correspondence should be directed to yyangh@cs.washington.edu or\n  haifengxu@uchicago.edu. This manuscript extends our earlier workshop version\n  accepted at NeurIPS SPIGM 2025", "summary": "As machine learning models continue to grow in size and complexity, efficient\nserving faces increasingly broad trade-offs spanning accuracy, latency,\nresource usage, and other objectives. Multi-model serving further complicates\nthese trade-offs; for example, in cascaded models, each early-exit decision\nbalances latency reduction against potential accuracy loss. Despite the\npervasiveness and importance of such trade-offs, current strategies remain\nlargely heuristic and case-specific, limiting both their theoretical guarantees\nand general applicability.\n  We present a general framework, T-Tamer, which formalizes this setting as a\nmulti-stage decision process, where the objective is to determine both when to\nexit and which model to consult. Our main result shows that recall (i.e., the\nability to revisit earlier models) is both necessary and sufficient for\nachieving provable performance guarantees. In particular, we prove that\nstrategies without recall cannot obtain any constant-factor approximation to\nthe optimal trade-off, whereas recall-based strategies provably attain the\noptimal trade-off in polynomial time.\n  We validate our analysis through experiments on synthetic datasets and\nearly-exit workloads for vision and NLP benchmarks. The results show that\nrecall-based strategies consistently yield efficient accuracy-latency\ntrade-offs. We hope this work provides a principled foundation for bridging\nheuristic practice with theoretical guarantees in the design of early-exit and\ncascaded models."}
{"id": "2509.22994", "pdf": "https://arxiv.org/pdf/2509.22994", "abs": "https://arxiv.org/abs/2509.22994", "authors": ["Zachary Baker", "Yuxiao Li"], "title": "Analysis of Variational Autoencoders", "categories": ["cs.LG"], "comment": "15 pages, 11 figures", "summary": "Sparse Autoencoders (SAEs) have emerged as a promising approach for\ninterpreting neural network representations by learning sparse,\nhuman-interpretable features from dense activations. We investigate whether\nincorporating variational methods into SAE architectures can improve feature\norganization and interpretability. We introduce the variational Sparse\nAutoencoder (vSAE), which replaces deterministic ReLU gating with stochastic\nsampling from learned Gaussian posteriors and incorporates KL divergence\nregularization toward a standard normal prior. Our hypothesis is that this\nprobabilistic sampling creates dispersive pressure, causing features to\norganize more coherently in the latent space while avoiding overlap. We\nevaluate a Topk vSAE against a standard TopK SAE on Pythia-70M transformer\nresidual steam activations using comprehensive benchmarks including SAE Bench,\nindividual feature interpretability analysis, and global latent space\nvisualization through t-SNE. The vSAE underperforms standard SAE across core\nevaluation metrics, though excels at feature independence and ablation metrics.\nThe KL divergence term creates excessive regularization pressure that\nsubstantially reduces the fraction of living features, leading to observed\nperformance degradation. While vSAE features demonstrate improved robustness,\nthey exhibit many more dead features than baseline. Our findings suggest that\nnaive application of variational methods to SAEs does not improve feature\norganization or interpretability."}
{"id": "2509.23000", "pdf": "https://arxiv.org/pdf/2509.23000", "abs": "https://arxiv.org/abs/2509.23000", "authors": ["Konstantina Bairaktari", "Huy L. Nguyen"], "title": "Sample-efficient Multiclass Calibration under $\\ell_{p}$ Error", "categories": ["cs.LG", "cs.DS"], "comment": null, "summary": "Calibrating a multiclass predictor, that outputs a distribution over labels,\nis particularly challenging due to the exponential number of possible\nprediction values. In this work, we propose a new definition of calibration\nerror that interpolates between two established calibration error notions, one\nwith known exponential sample complexity and one with polynomial sample\ncomplexity for calibrating a given predictor. Our algorithm can calibrate any\ngiven predictor for the entire range of interpolation, except for one endpoint,\nusing only a polynomial number of samples. At the other endpoint, we achieve\nnearly optimal dependence on the error parameter, improving upon previous work.\nA key technical contribution is a novel application of adaptive data analysis\nwith high adaptivity but only logarithmic overhead in the sample complexity."}
{"id": "2509.23003", "pdf": "https://arxiv.org/pdf/2509.23003", "abs": "https://arxiv.org/abs/2509.23003", "authors": ["Jiayin Liu", "Yulong Yang", "Vineet Bansal", "Christine Allen-Blanchette"], "title": "Physically Plausible Multi-System Trajectory Generation and Symmetry Discovery", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "comment": null, "summary": "From metronomes to celestial bodies, mechanics underpins how the world\nevolves in time and space. With consideration of this, a number of recent\nneural network models leverage inductive biases from classical mechanics to\nencourage model interpretability and ensure forecasted states are physical.\nHowever, in general, these models are designed to capture the dynamics of a\nsingle system with fixed physical parameters, from state-space measurements of\na known configuration space. In this paper we introduce Symplectic Phase Space\nGAN (SPS-GAN) which can capture the dynamics of multiple systems, and\ngeneralize to unseen physical parameters from. Moreover, SPS-GAN does not\nrequire prior knowledge of the system configuration space. In fact, SPS-GAN can\ndiscover the configuration space structure of the system from arbitrary\nmeasurement types (e.g., state-space measurements, video frames). To achieve\nphysically plausible generation, we introduce a novel architecture which embeds\na Hamiltonian neural network recurrent module in a conditional GAN backbone. To\ndiscover the structure of the configuration space, we optimize the conditional\ntime-series GAN objective with an additional physically motivated term to\nencourages a sparse representation of the configuration space. We demonstrate\nthe utility of SPS-GAN for trajectory prediction, video generation and symmetry\ndiscovery. Our approach captures multiple systems and achieves performance on\npar with supervised models designed for single systems."}
{"id": "2509.23012", "pdf": "https://arxiv.org/pdf/2509.23012", "abs": "https://arxiv.org/abs/2509.23012", "authors": ["Lauren. A Hannah", "Soheil Zibakhsh", "Kumari Nishu", "Arnav Kundu", "Mohammad Samragh Razlighi", "Mehrdad Farajtabar", "Minsik Cho"], "title": "MoE-PHDS: One MoE checkpoint for flexible runtime sparsity", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Sparse Mixtures of Experts (MoEs) are typically trained to operate at a fixed\nsparsity level, e.g. $k$ in a top-$k$ gating function. This global sparsity\nlevel determines an operating point on the accuracy/latency curve; currently,\nmeeting multiple efficiency targets means training and maintaining multiple\nmodels. This practice complicates serving, increases training and maintenance\ncosts, and limits flexibility in meeting diverse latency, efficiency, and\nenergy requirements. We show that pretrained MoEs are more robust to runtime\nsparsity shifts than commonly assumed, and introduce MoE-PHDS ({\\bf P}ost {\\bf\nH}oc {\\bf D}eclared {\\bf S}parsity), a lightweight SFT method that turns a\nsingle checkpoint into a global sparsity control surface. PHDS mixes training\nacross sparsity levels and anchors with a short curriculum at high sparsity,\nrequiring no architectural changes. The result is predictable accuracy/latency\ntradeoffs from one model: practitioners can ``dial $k$'' at inference time\nwithout swapping checkpoints, changing architecture, or relying on token-level\nheuristics. Experiments on OLMoE-1B-7B-0125, Qwen1.5-MoE-A2.7B, and proprietary\nmodels fit on multiple operating points show that PHDS matches or exceeds\nwell-specified oracle models, improves cross-sparsity agreement by up to 22\\%\nvs. well-specified oracle models, and enables simplified, flexible runtime MoE\ndeployment by making global sparsity a first-class serving primitive."}
{"id": "2509.23020", "pdf": "https://arxiv.org/pdf/2509.23020", "abs": "https://arxiv.org/abs/2509.23020", "authors": ["Jacob Hume", "Pietro Liò"], "title": "On the Sheafification of Higher-Order Message Passing", "categories": ["cs.LG", "math.AT"], "comment": "45 pages, 24 figures", "summary": "Recent work in Topological Deep Learning (TDL) seeks to generalize graph\nlearning's preeminent $message \\ passing$ paradigm to more complex relational\nstructures: simplicial complexes, cell complexes, hypergraphs, and combinations\nthereof. Many approaches to such ${higher\\text{-}order \\ message \\ passing}$\n(HOMP) admit formulation in terms of nonlinear diffusion with the Hodge\n(combinatorial) Laplacian, a graded operator which carries an inductive bias\nthat dimension-$k$ data features correlate with dimension-$k$ topological\nfeatures encoded in the (singular) cohomology of the underlying domain. For\n$k=0$ this recovers the graph Laplacian and its well-studied homophily bias. In\nhigher gradings, however, the Hodge Laplacian's bias is more opaque and\npotentially even degenerate. In this essay, we position sheaf theory as a\nnatural and principled formalism for modifying the Hodge Laplacian's\ndiffusion-mediated interface between local and global descriptors toward more\nexpressive message passing. The sheaf Laplacian's inductive bias correlates\ndimension-$k$ data features with dimension-$k$ $sheaf$ cohomology, a data-aware\ngeneralization of singular cohomology. We will contextualize and novelly extend\nprior theory on sheaf diffusion in graph learning ($k=0$) in such a light --\nand explore how it fails to generalize to $k>0$ -- before developing novel\ntheory and practice for the higher-order setting. Our exposition is accompanied\nby a self-contained introduction shepherding sheaves from the abstract to the\napplied."}
{"id": "2509.23024", "pdf": "https://arxiv.org/pdf/2509.23024", "abs": "https://arxiv.org/abs/2509.23024", "authors": ["Melody Zixuan Li", "Kumar Krishna Agrawal", "Arna Ghosh", "Komal Kumar Teru", "Adam Santoro", "Guillaume Lajoie", "Blake A. Richards"], "title": "Tracing the Representation Geometry of Language Models from Pretraining to Post-training", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "33 pages, 14 figures, 9 tables", "summary": "Standard training metrics like loss fail to explain the emergence of complex\ncapabilities in large language models. We take a spectral approach to\ninvestigate the geometry of learned representations across pretraining and\npost-training, measuring effective rank (RankMe) and eigenspectrum decay\n($\\alpha$-ReQ). With OLMo (1B-7B) and Pythia (160M-12B) models, we uncover a\nconsistent non-monotonic sequence of three geometric phases during\nautoregressive pretraining. The initial \"warmup\" phase exhibits rapid\nrepresentational collapse. This is followed by an \"entropy-seeking\" phase,\nwhere the manifold's dimensionality expands substantially, coinciding with peak\nn-gram memorization. Subsequently, a \"compression-seeking\" phase imposes\nanisotropic consolidation, selectively preserving variance along dominant\neigendirections while contracting others, a transition marked with significant\nimprovement in downstream task performance. We show these phases can emerge\nfrom a fundamental interplay of cross-entropy optimization under skewed token\nfrequencies and representational bottlenecks ($d \\ll |V|$). Post-training\nfurther transforms geometry: SFT and DPO drive \"entropy-seeking\" dynamics to\nintegrate specific instructional or preferential data, improving\nin-distribution performance while degrading out-of-distribution robustness.\nConversely, RLVR induces \"compression-seeking\", enhancing reward alignment but\nreducing generation diversity."}
{"id": "2509.23027", "pdf": "https://arxiv.org/pdf/2509.23027", "abs": "https://arxiv.org/abs/2509.23027", "authors": ["Yuke Li", "Yujia Zheng", "Tianyi Xiong", "Zhenyi Wang", "Heng Huang"], "title": "Understanding Catastrophic Interference On the Identifibility of Latent Representations", "categories": ["cs.LG"], "comment": null, "summary": "Catastrophic interference, also known as catastrophic forgetting, is a\nfundamental challenge in machine learning, where a trained learning model\nprogressively loses performance on previously learned tasks when adapting to\nnew ones. In this paper, we aim to better understand and model the catastrophic\ninterference problem from a latent representation learning point of view, and\npropose a novel theoretical framework that formulates catastrophic interference\nas an identification problem. Our analysis demonstrates that the forgetting\nphenomenon can be quantified by the distance between partial-task aware (PTA)\nand all-task aware (ATA) setups. Building upon recent advances in\nidentifiability theory, we prove that this distance can be minimized through\nidentification of shared latent variables between these setups. When learning,\nwe propose our method \\ourmeos with two-stage training strategy: First, we\nemploy maximum likelihood estimation to learn the latent representations from\nboth PTA and ATA configurations. Subsequently, we optimize the KL divergence to\nidentify and learn the shared latent variables. Through theoretical guarantee\nand empirical validations, we establish that identifying and learning these\nshared representations can effectively mitigate catastrophic interference in\nmachine learning systems. Our approach provides both theoretical guarantees and\npractical performance improvements across both synthetic and benchmark\ndatasets."}
{"id": "2509.23030", "pdf": "https://arxiv.org/pdf/2509.23030", "abs": "https://arxiv.org/abs/2509.23030", "authors": ["Yang Lv", "Jin Cao", "Ben Niu", "Zhe Sun", "Fengwei Wang", "Fenghua Li", "Hui Li"], "title": "DPFNAS: Differential Privacy-Enhanced Federated Neural Architecture Search for 6G Edge Intelligence", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The Sixth-Generation (6G) network envisions pervasive artificial intelligence\n(AI) as a core goal, enabled by edge intelligence through on-device data\nutilization. To realize this vision, federated learning (FL) has emerged as a\nkey paradigm for collaborative training across edge devices. However, the\nsensitivity and heterogeneity of edge data pose key challenges to FL: parameter\nsharing risks data reconstruction, and a unified global model struggles to\nadapt to diverse local distributions. In this paper, we propose a novel\nfederated learning framework that integrates personalized differential privacy\n(DP) and adaptive model design. To protect training data, we leverage\nsample-level representations for knowledge sharing and apply a personalized DP\nstrategy to resist reconstruction attacks. To ensure distribution-aware\nadaptation under privacy constraints, we develop a privacy-aware neural\narchitecture search (NAS) algorithm that generates locally customized\narchitectures and hyperparameters. To the best of our knowledge, this is the\nfirst personalized DP solution tailored for representation-based FL with\ntheoretical convergence guarantees. Our scheme achieves strong privacy\nguarantees for training data while significantly outperforming state-of-the-art\nmethods in model performance. Experiments on benchmark datasets such as\nCIFAR-10 and CIFAR-100 demonstrate that our scheme improves accuracy by 6.82\\%\nover the federated NAS method PerFedRLNAS, while reducing model size to 1/10\nand communication cost to 1/20."}
{"id": "2509.23037", "pdf": "https://arxiv.org/pdf/2509.23037", "abs": "https://arxiv.org/abs/2509.23037", "authors": ["Javad Forough", "Mohammad Maheri", "Hamed Haddadi"], "title": "GuardNet: Graph-Attention Filtering for Jailbreak Defense in Large Language Models", "categories": ["cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly susceptible to jailbreak\nattacks, which are adversarial prompts that bypass alignment constraints and\ninduce unauthorized or harmful behaviors. These vulnerabilities undermine the\nsafety, reliability, and trustworthiness of LLM outputs, posing critical risks\nin domains such as healthcare, finance, and legal compliance. In this paper, we\npropose GuardNet, a hierarchical filtering framework that detects and filters\njailbreak prompts prior to inference. GuardNet constructs structured graphs\nthat combine sequential links, syntactic dependencies, and attention-derived\ntoken relations to capture both linguistic structure and contextual patterns\nindicative of jailbreak behavior. It then applies graph neural networks at two\nlevels: (i) a prompt-level filter that detects global adversarial prompts, and\n(ii) a token-level filter that pinpoints fine-grained adversarial spans.\nExtensive experiments across three datasets and multiple attack settings show\nthat GuardNet substantially outperforms prior defenses. It raises prompt-level\nF$_1$ scores from 66.4\\% to 99.8\\% on LLM-Fuzzer, and from 67-79\\% to over 94\\%\non PLeak datasets. At the token level, GuardNet improves F$_1$ from 48-75\\% to\n74-91\\%, with IoU gains up to +28\\%. Despite its structural complexity,\nGuardNet maintains acceptable latency and generalizes well in cross-domain\nevaluations, making it a practical and robust defense against jailbreak threats\nin real-world LLM deployments."}
{"id": "2509.23043", "pdf": "https://arxiv.org/pdf/2509.23043", "abs": "https://arxiv.org/abs/2509.23043", "authors": ["Saleh Bunaiyan", "Corentin Delacour", "Shuvro Chowdhury", "Kyle Lee", "Kerem Y. Camsari"], "title": "IsingFormer: Augmenting Parallel Tempering With Learned Proposals", "categories": ["cs.LG", "cond-mat.stat-mech", "cs.AI", "physics.comp-ph"], "comment": "SB, CD, SC, KL are equally contributing authors", "summary": "Markov Chain Monte Carlo (MCMC) underlies both statistical physics and\ncombinatorial optimization, but mixes slowly near critical points and in rough\nlandscapes. Parallel Tempering (PT) improves mixing by swapping replicas across\ntemperatures, yet each replica still relies on slow local updates to change its\nconfiguration. We introduce IsingFormer, a Transformer trained on equilibrium\nsamples that can generate entire spin configurations resembling those from the\ntarget distribution. These uncorrelated samples are used as proposals for\nglobal moves within a Metropolis step in PT, complementing the usual\nsingle-spin flips. On 2D Ising models (sampling), IsingFormer reproduces\nmagnetization and free-energy curves and generalizes to unseen temperatures,\nincluding the critical region. Injecting even a single proposal sharply reduces\nequilibration time, replacing thousands of local updates. On 3D spin glasses\n(optimization), PT enhanced with IsingFormer finds substantially lower-energy\nstates, demonstrating how global moves accelerate search in rugged landscapes.\nFinally, applied to integer factorization encoded as Ising problems,\nIsingFormer trained on a limited set of semiprimes transfers successfully to\nunseen semiprimes, boosting success rates beyond the training distribution.\nSince factorization is a canonical hard benchmark, this ability to generalize\nacross instances highlights the potential of learning proposals that move\nbeyond single problems to entire families of instances. The IsingFormer\ndemonstrates that Monte Carlo methods can be systematically accelerated by\nneural proposals that capture global structure, yielding faster sampling and\nstronger performance in combinatorial optimization."}
{"id": "2509.23049", "pdf": "https://arxiv.org/pdf/2509.23049", "abs": "https://arxiv.org/abs/2509.23049", "authors": ["Zijian Wang", "Xiaofei Zhang", "Xin Zhang", "Yukun Liu", "Qiong Zhang"], "title": "Beyond Aggregation: Guiding Clients in Heterogeneous Federated Learning", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": null, "summary": "Federated learning (FL) is increasingly adopted in domains like healthcare,\nwhere data privacy is paramount. A fundamental challenge in these systems is\nstatistical heterogeneity-the fact that data distributions vary significantly\nacross clients (e.g., different hospitals may treat distinct patient\ndemographics). While current FL algorithms focus on aggregating model updates\nfrom these heterogeneous clients, the potential of the central server remains\nunder-explored. This paper is motivated by a healthcare scenario: could a\ncentral server not only build a model but also guide a new patient to the\nhospital best equipped for their specific condition? We generalize this idea to\npropose a novel paradigm for FL systems where the server actively guides the\nallocation of new tasks or queries to the most appropriate client in the\nnetwork. To enable this, we introduce an empirical likelihood-based framework\nthat simultaneously addresses two goals: (1) learning effective local models on\neach client, and (2) finding the best matching client for a new query.\nEmpirical results demonstrate the framework's effectiveness on benchmark\ndatasets, showing improvements in both model accuracy and the precision of\nclient guidance compared to standard FL approaches. This work opens a new\ndirection for building more intelligent and resource-efficient federated\nsystems that leverage heterogeneity as a feature, not just a bug. Code is\navailable at https://github.com/zijianwang0510/FedDRM.git."}
{"id": "2509.23050", "pdf": "https://arxiv.org/pdf/2509.23050", "abs": "https://arxiv.org/abs/2509.23050", "authors": ["Lin Long", "Changdae Oh", "Seongheon Park", "Yixuan Li"], "title": "Understanding Language Prior of LVLMs by Contrasting Chain-of-Embedding", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large vision-language models (LVLMs) achieve strong performance on multimodal\ntasks, yet they often default to their language prior (LP) -- memorized textual\npatterns from pre-training while under-utilizing visual evidence. Prior\nanalyses of LP mostly rely on input-output probing, which fails to reveal the\ninternal mechanisms governing when and how vision influences model behavior. To\naddress this gap, we present the first systematic analysis of language prior\nthrough the lens of chain-of-embedding, which examines the layer-wise\nrepresentation dynamics within LVLMs. Our analysis reveals a universal\nphenomenon: each model exhibits a Visual Integration Point (VIP), a critical\nlayer at which visual information begins to meaningfully reshape hidden\nrepresentations and influence decoding. Building on this observation, we\nintroduce the Total Visual Integration (TVI) estimator, which aggregates\nrepresentation distance beyond the VIP to quantify how strongly visual query\ninfluences response generation. Across 54 model-dataset combinations spanning 9\ncontemporary LVLMs and 6 benchmarks, we demonstrate that VIP consistently\nemerges, and that TVI reliably predicts the strength of language prior. This\noffers a principled toolkit for diagnosing and understanding language prior in\nLVLMs."}
{"id": "2509.23052", "pdf": "https://arxiv.org/pdf/2509.23052", "abs": "https://arxiv.org/abs/2509.23052", "authors": ["Matt L. Sampson", "Peter Melchior"], "title": "Dynamics of Learning: Generative Schedules from Latent ODEs", "categories": ["cs.LG"], "comment": "9 pages, 5 figures, comments welcome", "summary": "The learning rate schedule is one of the most impactful aspects of neural\nnetwork optimization, yet most schedules either follow simple parametric\nfunctions or react only to short-term training signals. None of them are\nsupported by a comprehensive temporal view of how well neural networks actually\ntrain. We present a new learning rate scheduler that models the training\nperformance of neural networks as a dynamical system. It leverages training\nruns from a hyperparameter search to learn a latent representation of the\ntraining process. Given current training metrics, it predicts the future\nlearning rate schedule with the best long-term validation performance. Our\nscheduler generalizes beyond previously observed training dynamics and creates\nspecialized schedules that deviate noticeably from common parametric functions.\nIt achieves SOTA results for image classification with CNN and ResNet models as\nwell as for next-token prediction with a transformer model. The trained models\nare located in flatter regions of the loss landscape and thus provide better\ngeneralization than those trained with other schedules. Our method is\ncomputationally efficient, optimizer-agnostic, and can easily be layered on top\nof ML experiment-tracking platforms. An implementation of our scheduler will be\nmade available after acceptance."}
{"id": "2509.23074", "pdf": "https://arxiv.org/pdf/2509.23074", "abs": "https://arxiv.org/abs/2509.23074", "authors": ["Wanjin Feng", "Yuan Yuan", "Jingtao Ding", "Yong Li"], "title": "Beyond Model Ranking: Predictability-Aligned Evaluation for Time Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In the era of increasingly complex AI models for time series forecasting,\nprogress is often measured by marginal improvements on benchmark leaderboards.\nHowever, this approach suffers from a fundamental flaw: standard evaluation\nmetrics conflate a model's performance with the data's intrinsic\nunpredictability. To address this pressing challenge, we introduce a novel,\npredictability-aligned diagnostic framework grounded in spectral coherence. Our\nframework makes two primary contributions: the Spectral Coherence\nPredictability (SCP), a computationally efficient ($O(N\\log N)$) and\ntask-aligned score that quantifies the inherent difficulty of a given\nforecasting instance, and the Linear Utilization Ratio (LUR), a\nfrequency-resolved diagnostic tool that precisely measures how effectively a\nmodel exploits the linearly predictable information within the data. We\nvalidate our framework's effectiveness and leverage it to reveal two core\ninsights. First, we provide the first systematic evidence of \"predictability\ndrift\", demonstrating that a task's forecasting difficulty varies sharply over\ntime. Second, our evaluation reveals a key architectural trade-off: complex\nmodels are superior for low-predictability data, whereas linear models are\nhighly effective on more predictable tasks. We advocate for a paradigm shift,\nmoving beyond simplistic aggregate scores toward a more insightful,\npredictability-aware evaluation that fosters fairer model comparisons and a\ndeeper understanding of model behavior."}
{"id": "2509.23077", "pdf": "https://arxiv.org/pdf/2509.23077", "abs": "https://arxiv.org/abs/2509.23077", "authors": ["Reza Rahimi Azghan", "Gautham Krishna Gudur", "Mohit Malu", "Edison Thomaz", "Giulia Pedrielli", "Pavan Turaga", "Hassan Ghasemzadeh"], "title": "CLAD-Net: Continual Activity Recognition in Multi-Sensor Wearable Systems", "categories": ["cs.LG"], "comment": null, "summary": "The rise of deep learning has greatly advanced human behavior monitoring\nusing wearable sensors, particularly human activity recognition (HAR). While\ndeep models have been widely studied, most assume stationary data distributions\n- an assumption often violated in real-world scenarios. For example, sensor\ndata from one subject may differ significantly from another, leading to\ndistribution shifts. In continual learning, this shift is framed as a sequence\nof tasks, each corresponding to a new subject. Such settings suffer from\ncatastrophic forgetting, where prior knowledge deteriorates as new tasks are\nlearned. This challenge is compounded by the scarcity and inconsistency of\nlabeled data in human studies. To address these issues, we propose CLAD-Net\n(Continual Learning with Attention and Distillation), a framework enabling\nwearable-sensor models to be updated continuously without sacrificing\nperformance on past tasks. CLAD-Net integrates a self-supervised transformer,\nacting as long-term memory, with a supervised Convolutional Neural Network\n(CNN) trained via knowledge distillation for activity classification. The\ntransformer captures global activity patterns through cross-attention across\nbody-mounted sensors, learning generalizable representations without labels.\nMeanwhile, the CNN leverages knowledge distillation to retain prior knowledge\nduring subject-wise fine-tuning. On PAMAP2, CLAD-Net achieves 91.36 percent\nfinal accuracy with only 8.78 percent forgetting, surpassing memory-based and\nregularization-based baselines such as Experience Replay and Elastic Weight\nConsolidation. In semi-supervised settings with only 10-20 percent labeled\ndata, CLAD-Net still delivers strong performance, demonstrating robustness to\nlabel scarcity. Ablation studies further validate each module's contribution."}
{"id": "2509.23085", "pdf": "https://arxiv.org/pdf/2509.23085", "abs": "https://arxiv.org/abs/2509.23085", "authors": ["Hyunwoo Lee", "Hayoung Choi", "Hyunju Kim"], "title": "Signal Preserving Weight Initialization for Odd-Sigmoid Activations", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Activation functions critically influence trainability and expressivity, and\nrecent work has therefore explored a broad range of nonlinearities. However,\nactivations and weight initialization are interdependent: without an\nappropriate initialization method, nonlinearities can cause saturation,\nvariance collapse, and increased learning rate sensitivity. We address this by\ndefining an odd sigmoid function class and, given any activation f in this\nclass, proposing an initialization method tailored to f. The method selects a\nnoise scale in closed form so that forward activations remain well dispersed up\nto a target layer, thereby avoiding collapse to zero or saturation.\nEmpirically, the approach trains reliably without normalization layers,\nexhibits strong data efficiency, and enables learning for activations under\nwhich standard initialization methods (Xavier, He, Orthogonal) often do not\nconverge reliably."}
{"id": "2509.23087", "pdf": "https://arxiv.org/pdf/2509.23087", "abs": "https://arxiv.org/abs/2509.23087", "authors": ["Deshu Chen", "Yuchen Liu", "Zhijian Zhou", "Chao Qu", "Yuan Qi"], "title": "Unleashing Flow Policies with Distributional Critics", "categories": ["cs.LG"], "comment": null, "summary": "Flow-based policies have recently emerged as a powerful tool in offline and\noffline-to-online reinforcement learning, capable of modeling the complex,\nmultimodal behaviors found in pre-collected datasets. However, the full\npotential of these expressive actors is often bottlenecked by their critics,\nwhich typically learn a single, scalar estimate of the expected return. To\naddress this limitation, we introduce the Distributional Flow Critic (DFC), a\nnovel critic architecture that learns the complete state-action return\ndistribution. Instead of regressing to a single value, DFC employs flow\nmatching to model the distribution of return as a continuous, flexible\ntransformation from a simple base distribution to the complex target\ndistribution of returns. By doing so, DFC provides the expressive flow-based\npolicy with a rich, distributional Bellman target, which offers a more stable\nand informative learning signal. Extensive experiments across D4RL and OGBench\nbenchmarks demonstrate that our approach achieves strong performance,\nespecially on tasks requiring multimodal action distributions, and excels in\nboth offline and offline-to-online fine-tuning compared to existing methods."}
{"id": "2509.23089", "pdf": "https://arxiv.org/pdf/2509.23089", "abs": "https://arxiv.org/abs/2509.23089", "authors": ["Sylee", "Beltiukov", "Satyandra Guthula", "Wenbo Guo", "Walter Willinger", "Arpit Gupta"], "title": "Demystifying Network Foundation Models", "categories": ["cs.LG", "cs.NI"], "comment": null, "summary": "This work presents a systematic investigation into the latent knowledge\nencoded within Network Foundation Models (NFMs) that focuses on hidden\nrepresentations analysis rather than pure downstream task performance.\nDifferent from existing efforts, we analyze the models through a three-part\nevaluation: Embedding Geometry Analysis to assess representation space\nutilization, Metric Alignment Assessment to measure correspondence with\ndomain-expert features, and Causal Sensitivity Testing to evaluate robustness\nto protocol perturbations. Using five diverse network datasets spanning\ncontrolled and real-world environments, we evaluate four state-of-the-art NFMs,\nrevealing that they all exhibit significant anisotropy, inconsistent feature\nsensitivity patterns, an inability to separate the high-level context, payload\ndependency, and other properties. Our work identifies numerous limitations\nacross all models and demonstrates that addressing them can significantly\nimprove model performance (by up to +0.35 $F_1$ score without architectural\nchanges)."}
{"id": "2509.23092", "pdf": "https://arxiv.org/pdf/2509.23092", "abs": "https://arxiv.org/abs/2509.23092", "authors": ["Christopher Scarvelis", "Justin Solomon"], "title": "Sensitivity Analysis for Diffusion Models", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Training a diffusion model approximates a map from a data distribution $\\rho$\nto the optimal score function $s_t$ for that distribution. Can we differentiate\nthis map? If we could, then we could predict how the score, and ultimately the\nmodel's samples, would change under small perturbations to the training set\nbefore committing to costly retraining. We give a closed-form procedure for\ncomputing this map's directional derivatives, relying only on black-box access\nto a pre-trained score model and its derivatives with respect to its inputs. We\nextend this result to estimate the sensitivity of a diffusion model's samples\nto additive perturbations of its target measure, with runtime comparable to\nsampling from a diffusion model and computing log-likelihoods along the sample\npath. Our method is robust to numerical and approximation error, and the\nresulting sensitivities correlate with changes in an image diffusion model's\nsamples after retraining and fine-tuning."}
{"id": "2509.23095", "pdf": "https://arxiv.org/pdf/2509.23095", "abs": "https://arxiv.org/abs/2509.23095", "authors": ["Xiangqi Wang", "Yue Huang", "Yujun Zhou", "Xiaonan Luo", "Kehan Guo", "Xiangliang Zhang"], "title": "Causally-Enhanced Reinforcement Policy Optimization", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Reinforcement learning publication of 24 pages", "summary": "Large language models (LLMs) trained with reinforcement objectives often\nachieve superficially correct answers via shortcut strategies, pairing correct\noutputs with spurious or unfaithful reasoning and degrading under small causal\nperturbations. We introduce Causally-Enhanced Policy Optimization (CE-PO), a\ndrop-in reward-shaping framework that augments policy optimization with a\ndifferentiable proxy for causal coherence along the generation pathway from\nprompt (Z) to rationale (X) to answer (Y). CE-PO estimates model-internal\ninfluence with Jacobian-based sensitivities, counterfactually hardens these\nsignals to suppress nuisance cues, and fuses the resulting coherence score with\ntask-accuracy feedback via a Minkowski (power-mean) combiner, exposing a single\ntunable between accuracy and coherence trade-off. The unified reward integrates\nwith PPO/GRPO without architectural changes. Across reasoning benchmarks and\ncausal stress tests, CE-PO reduces reward hacking and unfaithful\nchain-of-thought while improving robustness to correlation-causation flips and\nlight counterfactual edits, all at near-parity accuracy. Experimental results\nacross 4 datasets show that CE-PO improves accuracy over baselines by 5.49% on\naverage (up to 9.58%), while improving robustness to correlation-causation\nflips and light counterfactual edits."}
{"id": "2509.23101", "pdf": "https://arxiv.org/pdf/2509.23101", "abs": "https://arxiv.org/abs/2509.23101", "authors": ["M. Z. Haider", "Tayyaba Noreen", "M. Salman"], "title": "Towards Quantum-Ready Blockchain Fraud Detection via Ensemble Graph Neural Networks", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.DC"], "comment": null, "summary": "Blockchain Business applications and cryptocurrencies such as enable secure,\ndecentralized value transfer, yet their pseudonymous nature creates\nopportunities for illicit activity, challenging regulators and exchanges in\nanti money laundering (AML) enforcement. Detecting fraudulent transactions in\nblockchain networks requires models that can capture both structural and\ntemporal dependencies while remaining resilient to noise, imbalance, and\nadversarial behavior. In this work, we propose an ensemble framework that\nintegrates Graph Convolutional Networks (GCN), Graph Attention Networks (GAT),\nand Graph Isomorphism Networks (GIN) to enhance blockchain fraud detection.\nUsing the real-world Elliptic dataset, our tuned soft voting ensemble achieves\nhigh recall of illicit transactions while maintaining a false positive rate\nbelow 1%, beating individual GNN models and baseline methods. The modular\narchitecture incorporates quantum-ready design hooks, allowing seamless future\nintegration of quantum feature mappings and hybrid quantum classical graph\nneural networks. This ensures scalability, robustness, and long-term\nadaptability as quantum computing technologies mature. Our findings highlight\nensemble GNNs as a practical and forward-looking solution for real-time\ncryptocurrency monitoring, providing both immediate AML utility and a pathway\ntoward quantum-enhanced financial security analytics."}
{"id": "2509.23106", "pdf": "https://arxiv.org/pdf/2509.23106", "abs": "https://arxiv.org/abs/2509.23106", "authors": ["Aman Gupta", "Rafael Celente", "Abhishek Shivanna", "D. T. Braithwaite", "Gregory Dexter", "Shao Tang", "Hiroto Udagawa", "Daniel Silva", "Rohan Ramanath", "S. Sathiya Keerthi"], "title": "Effective Quantization of Muon Optimizer States", "categories": ["cs.LG"], "comment": "17 pages", "summary": "The Muon optimizer, based on matrix orthogonalization, has recently shown\nfaster convergence and up to 2x computational efficiency over AdamW in LLM\npretraining. Like AdamW, Muon is stateful, requiring storage of both model\nweights and accumulated gradients. While 8-bit AdamW variants mitigate this\noverhead using blockwise quantization, they are typically stable only under\ndynamic quantization - which improves stability on linear quantization for\nextreme values. In this paper, we introduce the 8-bit Muon optimizer using\nblockwise quantization, supporting both linear and dynamic schemes. We\ndemonstrate that 8-bit Muon maintains stability under both, while delivering\n$\\sim$74\\% reduction in memory footprint compared to full-precision Muon. In\nextensive experiments, 8-bit Muon closely matches the performance of Muon while\noutperforming AdamW and 8-bit AdamW in pre-training a 1.6B model on 4B FineWeb\ntokens. It also shows competitive results when fine-tuning the Llama 3.2 3B\nmodel on post-training data. We also provide a theoretical perspective to help\nexplain this robustness under quantization."}
{"id": "2509.23115", "pdf": "https://arxiv.org/pdf/2509.23115", "abs": "https://arxiv.org/abs/2509.23115", "authors": ["Haoyu He", "Haozheng Luo", "Yan Chen", "Qi R. Wang"], "title": "RHYTHM: Reasoning with Hierarchical Temporal Tokenization for Human Mobility", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Advances in Neural Information Processing Systems 39 (NeurIPS) 2025", "summary": "Predicting human mobility is inherently challenging due to complex long-range\ndependencies and multi-scale periodic behaviors. To address this, we introduce\nRHYTHM (Reasoning with Hierarchical Temporal Tokenization for Human Mobility),\na unified framework that leverages large language models (LLMs) as\ngeneral-purpose spatio-temporal predictors and trajectory reasoners.\nMethodologically, RHYTHM employs temporal tokenization to partition each\ntrajectory into daily segments and encode them as discrete tokens with\nhierarchical attention that captures both daily and weekly dependencies,\nthereby significantly reducing the sequence length while preserving cyclical\ninformation. Additionally, we enrich token representations by adding\npre-computed prompt embeddings for trajectory segments and prediction targets\nvia a frozen LLM, and feeding these combined embeddings back into the LLM\nbackbone to capture complex interdependencies. Computationally, RHYTHM freezes\nthe pretrained LLM's backbone to reduce attention complexity and memory cost.\nWe evaluate our model against state-of-the-art methods using three real-world\ndatasets. Notably, RHYTHM achieves a 2.4% improvement in overall accuracy, a\n5.0% increase on weekends, and a 24.6% reduction in training time. Code is\npublicly available at https://github.com/he-h/rhythm."}
{"id": "2509.23126", "pdf": "https://arxiv.org/pdf/2509.23126", "abs": "https://arxiv.org/abs/2509.23126", "authors": ["Dengyi Liu", "Honggang Wang", "Hua Fang"], "title": "Impute-MACFM: Imputation based on Mask-Aware Flow Matching", "categories": ["cs.LG"], "comment": "Preprint, 2025. 9 pages (main) + appendix", "summary": "Tabular data are central to many applications, especially longitudinal data\nin healthcare, where missing values are common, undermining model fidelity and\nreliability. Prior imputation methods either impose restrictive assumptions or\nstruggle with complex cross-feature structure, while recent generative\napproaches suffer from instability and costly inference. We propose\nImpute-MACFM, a mask-aware conditional flow matching framework for tabular\nimputation that addresses missingness mechanisms, missing completely at random,\nmissing at random, and missing not at random. Its mask-aware objective builds\ntrajectories only on missing entries while constraining predicted velocity to\nremain near zero on observed entries, using flexible nonlinear schedules.\nImpute-MACFM combines: (i) stability penalties on observed positions, (ii)\nconsistency regularization enforcing local invariance, and (iii) time-decayed\nnoise injection for numeric features. Inference uses constraint-preserving\nordinary differential equation integration with per-step projection to fix\nobserved values, optionally aggregating multiple trajectories for robustness.\nAcross diverse benchmarks, Impute-MACFM achieves state-of-the-art results while\ndelivering more robust, efficient, and higher-quality imputation than competing\napproaches, establishing flow matching as a promising direction for tabular\nmissing-data problems, including longitudinal data."}
{"id": "2509.23129", "pdf": "https://arxiv.org/pdf/2509.23129", "abs": "https://arxiv.org/abs/2509.23129", "authors": ["Haotian Liu", "Shuo Wang", "Hongteng Xu"], "title": "C$^2$GSPG: Confidence-calibrated Group Sequence Policy Gradient towards Self-aware Reasoning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Reinforcement Learning (RL) methods, exemplified by Group Relative Policy\nOptimization (GRPO) and its variants, play a central role in developing\nreasoning models. However, these methods often suffer from a critical\noverconfidence issue, which prevents them from achieving self-aware reasoning\nmodels. In this study, we propose a simple yet effective confidence-calibration\ngroup sequence policy gradient method, called C$^2$GSPG, which simultaneously\nenhances reasoning performance while suppressing overconfidence. In principle,\nwe propose a Group Sequence Policy Gradient (GSPG) framework for learning\nreasoning models, which eliminates the token-level bias commonly appearing in\nGRPO and its variants. In this framework, we define the model confidence for\neach reasoning problem using the normalized sequence-level probability, and\nthen apply a cross-entropy regularizer to calibrate the model confidence to the\nsequence's reward. We demonstrate that the confidence calibration regularizer\nand GSPG are collaborative for binary rewards, as their objectives always share\nthe same gradient direction. For non-binary rewards, we apply nonlinear reward\nnormalization and adaptive regularizer clipping, mitigating the potential\nconflict between the two objectives. Applying C$^2$GSPG to post-train large\nlanguage models in logical and mathematical reasoning tasks, we show its\nsuperiority over state-of-the-art methods in both reasoning accuracy and\nconfidence calibration. The code of C$^2$GSPG is available at\nhttps://github.com/HaotianLiu123/CCGSPG."}
{"id": "2509.23135", "pdf": "https://arxiv.org/pdf/2509.23135", "abs": "https://arxiv.org/abs/2509.23135", "authors": ["Yang Chen", "Menglin Zou", "Jiaqi Zhang", "Yitan Zhang", "Junyi Yang", "Gael Gendron", "Libo Zhang", "Jiamou Liu", "Michael J. Witbrock"], "title": "Trust Region Reward Optimization and Proximal Inverse Reward Optimization Algorithm", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to NeurIPS 2025", "summary": "Inverse Reinforcement Learning (IRL) learns a reward function to explain\nexpert demonstrations. Modern IRL methods often use the adversarial (minimax)\nformulation that alternates between reward and policy optimization, which often\nlead to unstable training. Recent non-adversarial IRL approaches improve\nstability by jointly learning reward and policy via energy-based formulations\nbut lack formal guarantees. This work bridges this gap. We first present a\nunified view showing canonical non-adversarial methods explicitly or implicitly\nmaximize the likelihood of expert behavior, which is equivalent to minimizing\nthe expected return gap. This insight leads to our main contribution: Trust\nRegion Reward Optimization (TRRO), a framework that guarantees monotonic\nimprovement in this likelihood via a Minorization-Maximization process. We\ninstantiate TRRO into Proximal Inverse Reward Optimization (PIRO), a practical\nand stable IRL algorithm. Theoretically, TRRO provides the IRL counterpart to\nthe stability guarantees of Trust Region Policy Optimization (TRPO) in forward\nRL. Empirically, PIRO matches or surpasses state-of-the-art baselines in reward\nrecovery, policy imitation with high sample efficiency on MuJoCo and\nGym-Robotics benchmarks and a real-world animal behavior modeling task."}
{"id": "2509.23139", "pdf": "https://arxiv.org/pdf/2509.23139", "abs": "https://arxiv.org/abs/2509.23139", "authors": ["Sipeng Chen", "Yan Zhang", "Shibo Li"], "title": "Beyond Heuristics: Globally Optimal Configuration of Implicit Neural Representations", "categories": ["cs.LG"], "comment": null, "summary": "Implicit Neural Representations (INRs) have emerged as a transformative\nparadigm in signal processing and computer vision, excelling in tasks from\nimage reconstruction to 3D shape modeling. Yet their effectiveness is\nfundamentally limited by the absence of principled strategies for optimal\nconfiguration - spanning activation selection, initialization scales,\nlayer-wise adaptation, and their intricate interdependencies. These choices\ndictate performance, stability, and generalization, but current practice relies\non ad-hoc heuristics, brute-force grid searches, or task-specific tuning, often\nleading to inconsistent results across modalities. This work introduces\nOptiINR, the first unified framework that formulates INR configuration as a\nrigorous optimization problem. Leveraging Bayesian optimization, OptiINR\nefficiently explores the joint space of discrete activation families - such as\nsinusoidal (SIREN), wavelet-based (WIRE), and variable-periodic (FINER) - and\ntheir associated continuous initialization parameters. This systematic approach\nreplaces fragmented manual tuning with a coherent, data-driven optimization\nprocess. By delivering globally optimal configurations, OptiINR establishes a\nprincipled foundation for INR design, consistently maximizing performance\nacross diverse signal processing applications."}
{"id": "2509.23145", "pdf": "https://arxiv.org/pdf/2509.23145", "abs": "https://arxiv.org/abs/2509.23145", "authors": ["Xiaowen Ma", "Shuning Ge", "Fan Yang", "Xiangyu Li", "Yun Chen", "Mengting Ma", "Wei Zhang", "Zhipeng Liu"], "title": "TimeExpert: Boosting Long Time Series Forecasting with Temporal Mix of Experts", "categories": ["cs.LG"], "comment": "Under Review", "summary": "Transformer-based architectures dominate time series modeling by enabling\nglobal attention over all timestamps, yet their rigid 'one-size-fits-all'\ncontext aggregation fails to address two critical challenges in real-world\ndata: (1) inherent lag effects, where the relevance of historical timestamps to\na query varies dynamically; (2) anomalous segments, which introduce noisy\nsignals that degrade forecasting accuracy. To resolve these problems, we\npropose the Temporal Mix of Experts (TMOE), a novel attention-level mechanism\nthat reimagines key-value (K-V) pairs as local experts (each specialized in a\ndistinct temporal context) and performs adaptive expert selection for each\nquery via localized filtering of irrelevant timestamps. Complementing this\nlocal adaptation, a shared global expert preserves the Transformer's strength\nin capturing long-range dependencies. We then replace the vanilla attention\nmechanism in popular time-series Transformer frameworks (i.e., PatchTST and\nTimer) with TMOE, without extra structural modifications, yielding our specific\nversion TimeExpert and general version TimeExpert-G. Extensive experiments on\nseven real-world long-term forecasting benchmarks demonstrate that TimeExpert\nand TimeExpert-G outperform state-of-the-art methods. Code is available at\nhttps://github.com/xwmaxwma/TimeExpert."}
{"id": "2509.23152", "pdf": "https://arxiv.org/pdf/2509.23152", "abs": "https://arxiv.org/abs/2509.23152", "authors": ["Zhicheng Yang", "Zhijiang Guo", "Yinya Huang", "Yongxin Wang", "Yiwei Wang", "Xiaodan Liang", "Jing Tang"], "title": "Critique to Verify: Accurate and Honest Test-Time Scaling with RL-Trained Verifiers", "categories": ["cs.LG"], "comment": "15 pages, 7 figures", "summary": "Test-time scaling via solution sampling and aggregation has become a key\nparadigm for improving the reasoning performance of Large Language Models\n(LLMs). While reward model selection is commonly employed in this approach, it\noften fails to identify minority-yet-correct answers, which limits its\neffectiveness beyond that of simple majority voting. We argue that this\nlimitation stems from a lack of informative critique signals during verifier\ntraining. To bridge this gap, we introduce Mirror-Critique, a framework that\ntrains a verifier with informative critiques. Our key insight is to leverage\nthe rich critique signal by contrasting model-generated solutions with\nground-truth solutions. We deploy a small instruction-tuned model to synthesize\nhigh-quality critique data with rejection sampling that teaches the verifier\nnot only what is wrong, but also why. The synthetic data is used to cold-start\nthe LLMs in the RLVR process to further improve the verification ability. The\nresulting Mirror-Verifier is deployed to evaluate candidate solutions by\ngenerating multiple critiques per solution, aggregating them into a verify\nscore used for weighted voting or selective abstention. The experimental\nresults show that our Mirror-Verifier significantly outperforms majority voting\nin terms of solution accuracy and also improves the solver's honesty to\nrecognize and abstain from answering beyond its capability boundaries."}
{"id": "2509.23156", "pdf": "https://arxiv.org/pdf/2509.23156", "abs": "https://arxiv.org/abs/2509.23156", "authors": ["Prashant Govindarajan", "Mathieu Reymond", "Antoine Clavaud", "Mariano Phielipp", "Santiago Miret", "Sarath Chandar"], "title": "CrystalGym: A New Benchmark for Materials Discovery Using Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "In silico design and optimization of new materials primarily relies on\nhigh-accuracy atomic simulators that perform density functional theory (DFT)\ncalculations. While recent works showcase the strong potential of machine\nlearning to accelerate the material design process, they mostly consist of\ngenerative approaches that do not use direct DFT signals as feedback to improve\ntraining and generation mainly due to DFT's high computational cost. To aid the\nadoption of direct DFT signals in the materials design loop through online\nreinforcement learning (RL), we propose CrystalGym, an open-source RL\nenvironment for crystalline material discovery. Using CrystalGym, we benchmark\ncommon value- and policy-based reinforcement learning algorithms for designing\nvarious crystals conditioned on target properties. Concretely, we optimize for\nchallenging properties like the band gap, bulk modulus, and density, which are\ndirectly calculated from DFT in the environment. While none of the algorithms\nwe benchmark solve all CrystalGym tasks, our extensive experiments and\nablations show different sample efficiencies and ease of convergence to\noptimality for different algorithms and environment settings. Additionally, we\ninclude a case study on the scope of fine-tuning large language models with\nreinforcement learning for improving DFT-based rewards. Our goal is for\nCrystalGym to serve as a test bed for reinforcement learning researchers and\nmaterial scientists to address these real-world design problems with practical\napplications. We therefore introduce a novel class of challenges for\nreinforcement learning methods dealing with time-consuming reward signals,\npaving the way for future interdisciplinary research for machine learning\nmotivated by real-world applications."}
{"id": "2509.23158", "pdf": "https://arxiv.org/pdf/2509.23158", "abs": "https://arxiv.org/abs/2509.23158", "authors": ["Yufei Shen", "Ji Hwan Park", "Minchao Huang", "Jared F. Benge", "Justin F. Rousseau", "Rosemary A. Lester-Smith", "Edison Thomaz"], "title": "Deep Learning-Based Detection of Cognitive Impairment from Passive Smartphone Sensing with Routine-Aware Augmentation and Demographic Personalization", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at 2025 IEEE EMBS International Conference on Biomedical and\n  Health Informatics (IEEE BHI 2025)", "summary": "Early detection of cognitive impairment is critical for timely diagnosis and\nintervention, yet infrequent clinical assessments often lack the sensitivity\nand temporal resolution to capture subtle cognitive declines in older adults.\nPassive smartphone sensing has emerged as a promising approach for naturalistic\nand continuous cognitive monitoring. Building on this potential, we implemented\na Long Short-Term Memory (LSTM) model to detect cognitive impairment from\nsequences of daily behavioral features, derived from multimodal sensing data\ncollected in an ongoing one-year study of older adults. Our key contributions\nare two techniques to enhance model generalizability across participants: (1)\nroutine-aware augmentation, which generates synthetic sequences by replacing\neach day with behaviorally similar alternatives, and (2) demographic\npersonalization, which reweights training samples to emphasize those from\nindividuals demographically similar to the test participant. Evaluated on\n6-month data from 36 older adults, these techniques jointly improved the Area\nUnder the Precision-Recall Curve (AUPRC) of the model trained on sensing and\ndemographic features from 0.637 to 0.766, highlighting the potential of\nscalable monitoring of cognitive impairment in aging populations with passive\nsensing."}
{"id": "2509.23159", "pdf": "https://arxiv.org/pdf/2509.23159", "abs": "https://arxiv.org/abs/2509.23159", "authors": ["Ziheng Peng", "Shijie Ren", "Xinyue Gu", "Linxiao Yang", "Xiting Wang", "Liang Sun"], "title": "ProtoTS: Learning Hierarchical Prototypes for Explainable Time Series Forecasting", "categories": ["cs.LG"], "comment": "Under submission", "summary": "While deep learning has achieved impressive performance in time series\nforecasting, it becomes increasingly crucial to understand its decision-making\nprocess for building trust in high-stakes scenarios. Existing interpretable\nmodels often provide only local and partial explanations, lacking the\ncapability to reveal how heterogeneous and interacting input variables jointly\nshape the overall temporal patterns in the forecast curve. We propose ProtoTS,\na novel interpretable forecasting framework that achieves both high accuracy\nand transparent decision-making through modeling prototypical temporal\npatterns. ProtoTS computes instance-prototype similarity based on a denoised\nrepresentation that preserves abundant heterogeneous information. The\nprototypes are organized hierarchically to capture global temporal patterns\nwith coarse prototypes while capturing finer-grained local variations with\ndetailed prototypes, enabling expert steering and multi-level interpretability.\nExperiments on multiple realistic benchmarks, including a newly released LOF\ndataset, show that ProtoTS not only exceeds existing methods in forecast\naccuracy but also delivers expert-steerable interpretations for better model\nunderstanding and decision support."}
{"id": "2509.23162", "pdf": "https://arxiv.org/pdf/2509.23162", "abs": "https://arxiv.org/abs/2509.23162", "authors": ["Chandan Tankala", "Krishnakumar Balasubramanian"], "title": "Dense associative memory on the Bures-Wasserstein space", "categories": ["cs.LG", "cs.AI", "math.ST", "stat.ML", "stat.TH"], "comment": null, "summary": "Dense associative memories (DAMs) store and retrieve patterns via\nenergy-functional fixed points, but existing models are limited to vector\nrepresentations. We extend DAMs to probability distributions equipped with the\n2-Wasserstein distance, focusing mainly on the Bures-Wasserstein class of\nGaussian densities. Our framework defines a log-sum-exp energy over stored\ndistributions and a retrieval dynamics aggregating optimal transport maps in a\nGibbs-weighted manner. Stationary points correspond to self-consistent\nWasserstein barycenters, generalizing classical DAM fixed points. We prove\nexponential storage capacity, provide quantitative retrieval guarantees under\nWasserstein perturbations, and validate the model on synthetic and real-world\ndistributional tasks. This work elevates associative memory from vectors to\nfull distributions, bridging classical DAMs with modern generative modeling and\nenabling distributional storage and retrieval in memory-augmented learning."}
{"id": "2509.23173", "pdf": "https://arxiv.org/pdf/2509.23173", "abs": "https://arxiv.org/abs/2509.23173", "authors": ["Hangwei Zhang", "Chun Kang", "Yan Wang", "Difan Zou"], "title": "F-Adapter: Frequency-Adaptive Parameter-Efficient Fine-Tuning in Scientific Machine Learning", "categories": ["cs.LG"], "comment": "NeurIPS 2025 Main Track", "summary": "Parameter-efficient fine-tuning (PEFT) of powerful pre-trained models for\ncomplex downstream tasks has proven effective in vision and language\nprocessing, yet this paradigm remains unexplored in scientific machine\nlearning, where the objective is to model complex physical systems. We conduct\nthe first systematic study of PEFT for pre-trained Large Operator Models (LOMs)\nobtained by scaling variants of Fourier Neural Operator. First, we observe that\nthe widely used Low-Rank Adaptation (LoRA) yields markedly poorer performance\non LOMs than Adapter tuning. Then, we further theoretically establish that\nstacked LoRA incurs a depth-amplified lower bound on approximation error within\nFourier layers, whereas adapters retain universal approximation capacity and,\nby concentrating parameters on energy-dominant low-frequency modes, attain\nexponentially decaying error with bottleneck width in the Fourier domain.\nMotivated by the robust empirical gains of adapters and by our theoretical\ncharacterization of PDE solutions as spectrally sparse, we introduce\nFrequency-Adaptive Adapter (F-Adapter). F-Adapter allocates adapter capacity\nbased on spectral complexity, assigning higher-dimension modules to\nlow-frequency components and lower-dimension modules to high-frequency\ncomponents. Our F-Adapters establish state-of-the-art (SOTA) results on\nmultiple challenging 3D Navier-Stokes benchmarks, markedly enhancing both\ngeneralization and spectral fidelity over LoRA and other PEFT techniques\ncommonly used in LLMs. To the best of our knowledge, this work is the first to\nexplore PEFT for scientific machine-learning and establishes F-Adapter as an\neffective paradigm for this domain."}
{"id": "2509.23183", "pdf": "https://arxiv.org/pdf/2509.23183", "abs": "https://arxiv.org/abs/2509.23183", "authors": ["Guohao Chen", "Shuaicheng Niu", "Deyu Chen", "Jiahao Yang", "Zitian Zhang", "Mingkui Tan", "Pengcheng Wu", "Zhiqi Shen"], "title": "ZeroSiam: An Efficient Siamese for Test-Time Entropy Optimization without Collapse", "categories": ["cs.LG", "cs.NI"], "comment": null, "summary": "Test-time entropy minimization helps adapt a model to novel environments and\nincentivize its reasoning capability, unleashing the model's potential during\ninference by allowing it to evolve and improve in real-time using its own\npredictions, achieving promising performance. However, pure entropy\nminimization can favor non-generalizable shortcuts, such as inflating the logit\nnorm and driving all predictions to a dominant class to reduce entropy, risking\ncollapsed solutions (e.g., constant one-hot outputs) that trivially minimize\nthe objective without meaningful learning. In this paper, we introduce\nZeroSiam, an efficient asymmetric Siamese architecture tailored for test-time\nentropy minimization. ZeroSiam prevents collapse through asymmetric divergence\nalignment, which is efficiently achieved by a learnable predictor and a\nstop-gradient operator before the classifier. We provide empirical and\ntheoretical evidence that ZeroSiam not only prevents collapse solutions, but\nalso absorbs and regularizes biased learning signals, enhancing performance\neven when no collapse occurs. Despite its simplicity, extensive results show\nthat ZeroSiam performs more stably over prior methods using negligible\noverhead, demonstrating efficacy on both vision adaptation and large language\nmodel reasoning tasks across challenging test scenarios and diverse models,\nincluding tiny models that are particularly collapse-prone."}
{"id": "2509.23190", "pdf": "https://arxiv.org/pdf/2509.23190", "abs": "https://arxiv.org/abs/2509.23190", "authors": ["Zhanhong Xie", "Meifan Zhang", "Lihua Yin"], "title": "CoSIFL: Collaborative Secure and Incentivized Federated Learning with Differential Privacy", "categories": ["cs.LG"], "comment": null, "summary": "Federated learning (FL) has emerged as a promising paradigm for collaborative\nmodel training while preserving data locality. However, it still faces\nchallenges from malicious or compromised clients, as well as difficulties in\nincentivizing participants to contribute high-quality data under strict privacy\nrequirements. Motivated by these considerations, we propose CoSIFL, a novel\nframework that integrates proactive alarming for robust security and local\ndifferential privacy (LDP) for inference attacks, together with a\nStackelberg-based incentive scheme to encourage client participation and data\nsharing. Specifically, CoSIFL uses an active alarming mechanism and robust\naggregation to defend against Byzantine and inference attacks, while a Tullock\ncontest-inspired incentive module rewards honest clients for both data\ncontributions and reliable alarm triggers. We formulate the interplay between\nthe server and clients as a two-stage game: in the first stage, the server\ndetermines total rewards, selects participants, and fixes global iteration\nsettings, whereas in the second stage, each client decides its mini-batch size,\nprivacy noise scale, and alerting strategy. We prove that the server-client\ngame admits a unique equilibrium, and analyze how clients' multi-dimensional\nattributes - such as non-IID degrees and privacy budgets - jointly affect\nsystem efficiency. Experimental results on standard benchmarks demonstrate that\nCoSIFL outperforms state-of-the-art solutions in improving model robustness and\nreducing total server costs, highlighting the effectiveness of our integrated\ndesign."}
{"id": "2509.23202", "pdf": "https://arxiv.org/pdf/2509.23202", "abs": "https://arxiv.org/abs/2509.23202", "authors": ["Vage Egiazarian", "Roberto L. Castro", "Denis Kuznedelev", "Andrei Panferov", "Eldar Kurtic", "Shubhra Pandit", "Alexandre Marques", "Mark Kurtz", "Saleh Ashkboos", "Torsten Hoefler", "Dan Alistarh"], "title": "Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantization", "categories": ["cs.LG"], "comment": null, "summary": "The recent hardware-accelerated microscaling 4-bit floating-point formats\nsuch as MXFP4 and NVFP4, supported on NVIDIA and AMD GPUs, promise to\nrevolutionize large language model (LLM) inference. Yet, their practical\nbenefits remain unproven. We present the first comprehensive study of MXFP4 and\nNVFP4 for post-training quantization, revealing gaps between their promise and\nreal-world performance. Our analysis shows that state-of-the-art methods\nstruggle with FP4, due to two key issues: (1) NVFP4's small group size provably\nneutralizes traditional outlier mitigation techniques; (2) MXFP4's power-of-two\nscale quantization severely degrades accuracy due to high induced error. To\nbridge this gap, we introduce Micro-Rotated-GPTQ (MR-GPTQ), a variant of the\nclassic GPTQ quantization algorithm that tailors the quantization process to\nFP4's unique properties, by using block-wise Hadamard transforms and\nformat-specific optimizations. We support our proposal with a set of\nhigh-performance GPU kernels that enable the MR-GPTQ format with negligible\noverhead, by rotation fusion into the weights, and fast online computation of\nthe activations. This leads to speedups vs. FP16 of up to 3.6x layer-wise, and\n2.2x end-to-end on NVIDIA B200, and of 6x layer-wise and 4x end-to-end on\nRTX5090. Our extensive empirical evaluation demonstrates that MR-GPTQ matches\nor outperforms state-of-the-art accuracy, significantly boosting MXFP4, to the\npoint where it nears that of NVFP4. We conclude that, while FP4 is not an\nautomatic upgrade over INT4, format-specialized methods like MR-GPTQ can unlock\na new frontier of accuracy-performance trade-offs."}
{"id": "2509.23209", "pdf": "https://arxiv.org/pdf/2509.23209", "abs": "https://arxiv.org/abs/2509.23209", "authors": ["Wenhao Zhang", "Shao Zhang", "Xihuai Wang", "Yang Li", "Ying Wen"], "title": "Towards Monotonic Improvement in In-Context Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In-Context Reinforcement Learning (ICRL) has emerged as a promising paradigm\nfor developing agents that can rapidly adapt to new tasks by leveraging past\nexperiences as context, without updating their parameters. Recent approaches\ntrain large sequence models on monotonic policy improvement data from online\nRL, aiming to a continue improved testing time performance. However, our\nexperimental analysis reveals a critical flaw: these models cannot show a\ncontinue improvement like the training data during testing time. Theoretically,\nwe identify this phenomenon as Contextual Ambiguity, where the model's own\nstochastic actions can generate an interaction history that misleadingly\nresembles that of a sub-optimal policy from the training data, initiating a\nvicious cycle of poor action selection. To resolve the Contextual Ambiguity, we\nintroduce Context Value into training phase and propose Context Value Informed\nICRL (CV-ICRL). CV-ICRL use Context Value as an explicit signal representing\nthe ideal performance theoretically achievable by a policy given the current\ncontext. As the context expands, Context Value could include more task-relevant\ninformation, and therefore the ideal performance should be non-decreasing. We\nprove that the Context Value tightens the lower bound on the performance gap\nrelative to an ideal, monotonically improving policy. We fruther propose two\nmethods for estimating Context Value at both training and testing time.\nExperiments conducted on the Dark Room and Minigrid testbeds demonstrate that\nCV-ICRL effectively mitigates performance degradation and improves overall ICRL\nabilities across various tasks and environments. The source code and data of\nthis paper are available at\nhttps://github.com/Bluixe/towards_monotonic_improvement ."}
{"id": "2509.23213", "pdf": "https://arxiv.org/pdf/2509.23213", "abs": "https://arxiv.org/abs/2509.23213", "authors": ["Hugo Math", "Robin Schön", "Rainer Lienhart"], "title": "One-Shot Multi-Label Causal Discovery in High-Dimensional Event Sequences", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at NeuRIPS2025 Workshop CauScien: Discovering Causality in\n  Science. arXiv admin note: substantial text overlap with arXiv:2509.19112", "summary": "Understanding causality in event sequences with thousands of sparse event\ntypes is critical in domains such as healthcare, cybersecurity, or vehicle\ndiagnostics, yet current methods fail to scale. We present OSCAR, a one-shot\ncausal autoregressive method that infers per-sequence Markov Boundaries using\ntwo pretrained Transformers as density estimators. This enables efficient,\nparallel causal discovery without costly global CI testing. On a real-world\nautomotive dataset with 29,100 events and 474 labels, OSCAR recovers\ninterpretable causal structures in minutes, while classical methods fail to\nscale, enabling practical scientific diagnostics at production scale."}
{"id": "2509.23219", "pdf": "https://arxiv.org/pdf/2509.23219", "abs": "https://arxiv.org/abs/2509.23219", "authors": ["Xin Li", "Mengbing Liu", "Yiyang Zhu", "Wenhe Zhang", "Li Wei", "Jiancheng An", "Chau Yuen"], "title": "WirelessMathLM: Teaching Mathematical Reasoning for LLMs in Wireless Communications with Reinforcement Learning", "categories": ["cs.LG"], "comment": "Project Homepage: https://lixin.ai/WirelessMathLM", "summary": "Large language models (LLMs) excel at general mathematical reasoning but fail\ncatastrophically on specialized technical mathematics. In wireless\ncommunications, where problems require precise manipulation of\ninformation-theoretic bounds, optimization constraints, and signal processing\nformulations, even state-of-the-art models struggle to achieve competent\nperformance. We present WirelessMathLM, demonstrating that compact models\n(0.5B-7B parameters) can match or exceed much larger models through\ndomain-specific reinforcement learning with verifiable rewards. Our key insight\nis that wireless mathematics problems possess a unique property--verifiable\ncorrectness--that enables effective reinforcement learning without human\nfeedback. We construct WirelessMathBench-XL, a comprehensive benchmark of 4,027\nproblems from 970 papers. Using Group Relative Policy Optimization (GRPO) with\nbinary verification rewards, we train models directly from base checkpoints\nwithout supervised warm-start. Our 7B model achieves 39.5% accuracy on\nWirelessMathBench-XL, approaching GPT-4o (40.4%) while using about 100 times\nfewer parameters than DeepSeek-R1 (671B, 57.4%). Remarkably, GRPO training\nnearly doubles performance across all model scales (0.5B +11%, 3B +103%, 7B\n+81%), with positive transfer to general mathematics benchmarks--our models\ngain +8.4 points on average across MATH, Minerva-Math, OlympiadBench, AMC, and\nAIME without any training on these tasks."}
{"id": "2509.23232", "pdf": "https://arxiv.org/pdf/2509.23232", "abs": "https://arxiv.org/abs/2509.23232", "authors": ["Bingshuai Liu", "Ante Wang", "Zijun Min", "Liang Yao", "Haibo Zhang", "Yang Liu", "Anxiang Zeng", "Jinsong Su"], "title": "SPEC-RL: Accelerating On-Policy Reinforcement Learning via Speculative Rollouts", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) increasingly rely on reinforcement learning with\nverifiable rewards (RLVR) to elicit reliable chain-of-thought reasoning.\nHowever, the training process remains bottlenecked by the computationally\nexpensive rollout stage. Existing acceleration methods-such as parallelization,\nobjective- and data-driven modifications, and replay buffers-either incur\ndiminishing returns, introduce bias, or overlook redundancy across iterations.\nWe identify that rollouts from consecutive training epochs frequently share a\nlarge portion of overlapping segments, wasting computation. To address this, we\npropose SPEC-RL, a novel framework that integrates SPECulative decoding with\nthe RL rollout process. SPEC-RL reuses prior trajectory segments as speculative\nprefixes and extends them via a draft-and-verify mechanism, avoiding redundant\ngeneration while ensuring policy consistency. Experiments on diverse math\nreasoning and generalization benchmarks, including GSM8K, MATH-500,\nOlympiadBench, MMLU-STEM, and others, demonstrate that SPEC-RL reduces rollout\ntime by 2-3x without compromising policy quality. As a purely rollout-stage\nenhancement, SPEC-RL integrates seamlessly with mainstream algorithms (e.g.,\nPPO, GRPO, DAPO), offering a general and practical path to scale RLVR for large\nreasoning models. Our code is available at https://github.com/ShopeeLLM/Spec-RL"}
{"id": "2509.23240", "pdf": "https://arxiv.org/pdf/2509.23240", "abs": "https://arxiv.org/abs/2509.23240", "authors": ["Shayan Alahyari"], "title": "More Data or Better Algorithms: Latent Diffusion Augmentation for Deep Imbalanced Regression", "categories": ["cs.LG"], "comment": null, "summary": "In many real-world regression tasks, the data distribution is heavily skewed,\nand models learn predominantly from abundant majority samples while failing to\npredict minority labels accurately. While imbalanced classification has been\nextensively studied, imbalanced regression remains relatively unexplored. Deep\nimbalanced regression (DIR) represents cases where the input data are\nhigh-dimensional and unstructured. Although several data-level approaches for\ntabular imbalanced regression exist, deep imbalanced regression currently lacks\ndedicated data-level solutions suitable for high-dimensional data and relies\nprimarily on algorithmic modifications. To fill this gap, we propose\nLatentDiff, a novel framework that uses conditional diffusion models with\npriority-based generation to synthesize high-quality features in the latent\nrepresentation space. LatentDiff is computationally efficient and applicable\nacross diverse data modalities, including images, text, and other\nhigh-dimensional inputs. Experiments on three DIR benchmarks demonstrate\nsubstantial improvements in minority regions while maintaining overall\naccuracy."}
{"id": "2509.23246", "pdf": "https://arxiv.org/pdf/2509.23246", "abs": "https://arxiv.org/abs/2509.23246", "authors": ["Manjiang Yu", "Priyanka Singh", "Xue Li", "Yang Cao"], "title": "Adaptive Token-Weighted Differential Privacy for LLMs: Not All Tokens Require Equal Protection", "categories": ["cs.LG", "cs.AI"], "comment": "18 pages", "summary": "Large language models (LLMs) frequently memorize sensitive or personal\ninformation, raising significant privacy concerns. Existing variants of\ndifferential privacy stochastic gradient descent (DPSGD) inject uniform noise\ninto every gradient step, significantly extending training time and reducing\nmodel accuracy. We propose that concentrating noise primarily on gradients\nassociated with sensitive tokens can substantially decrease DP training time,\nstrengthen the protection of sensitive information, and simultaneously preserve\nthe model's performance on non-sensitive data. We operationalize this insight\nthrough Adaptive Token-Weighted Differential Privacy (ATDP), a modification of\nvanilla DP-SGD that adaptively assigns different gradient weights to sensitive\nand non-sensitive tokens. By employing a larger noise scale at the early stage\nof training, ATDP rapidly disrupts memorization of sensitive content. As a\nresult, ATDP only requires a few additional epochs of lightweight\npost-processing following standard fine-tuning, injecting targeted noise\nprimarily on parameters corresponding to sensitive tokens, thus minimally\naffecting the model's general capabilities. ATDP can be seamlessly integrated\ninto any existing DP-based fine-tuning pipeline or directly applied to\nnon-private models as a fast privacy-enhancing measure. Additionally, combined\nwith an initial redacted fine-tuning phase, ATDP forms a streamlined DP\npipeline that achieves comparable canary protection to state-of-the-art DP-SGD\nmethods, significantly reduces the computational overhead of DP fine-tuning,\nshortening training time by approximately 90 percent, while achieving\ncomparable or superior privacy protection and minimal accuracy degradation."}
{"id": "2509.23249", "pdf": "https://arxiv.org/pdf/2509.23249", "abs": "https://arxiv.org/abs/2509.23249", "authors": ["Vladimir Fanaskov", "Vladislav Trifonov", "Alexander Rudikov", "Ekaterina Muravleva", "Ivan Oseledets"], "title": "Deep Learning for Subspace Regression", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "It is often possible to perform reduced order modelling by specifying linear\nsubspace which accurately captures the dynamics of the system. This approach\nbecomes especially appealing when linear subspace explicitly depends on\nparameters of the problem. A practical way to apply such a scheme is to compute\nsubspaces for a selected set of parameters in the computationally demanding\noffline stage and in the online stage approximate subspace for unknown\nparameters by interpolation. For realistic problems the space of parameters is\nhigh dimensional, which renders classical interpolation strategies infeasible\nor unreliable. We propose to relax the interpolation problem to regression,\nintroduce several loss functions suitable for subspace data, and use a neural\nnetwork as an approximation to high-dimensional target function. To further\nsimplify a learning problem we introduce redundancy: in place of predicting\nsubspace of a given dimension we predict larger subspace. We show theoretically\nthat this strategy decreases the complexity of the mapping for elliptic\neigenproblems with constant coefficients and makes the mapping smoother for\ngeneral smooth function on the Grassmann manifold. Empirical results also show\nthat accuracy significantly improves when larger-than-needed subspaces are\npredicted. With the set of numerical illustrations we demonstrate that subspace\nregression can be useful for a range of tasks including parametric\neigenproblems, deflation techniques, relaxation methods, optimal control and\nsolution of parametric partial differential equations."}
{"id": "2509.23252", "pdf": "https://arxiv.org/pdf/2509.23252", "abs": "https://arxiv.org/abs/2509.23252", "authors": ["Raviteja Anantha", "Soheil Hor", "Teodor Nicola Antoniu", "Layne C. Price"], "title": "NanoFlux: Adversarial Dual-LLM Evaluation and Distillation For Multi-Domain Reasoning", "categories": ["cs.LG"], "comment": "preprint version", "summary": "We present NanoFlux, a novel adversarial framework for generating targeted\ntraining data to improve LLM reasoning, where adversarially-generated datasets\ncontaining fewer than 200 examples outperform conventional fine-tuning\napproaches. The framework employs a competitive dynamic between models\nalternating as Attacker and Defender, supervised by a tool-augmented Judge,\nsynthesizing multi-step questions with explanatory annotations that target\nspecific reasoning capabilities. Fine-tuning a 4B-parameter model on\nNanoFlux-generated data yields performance gains across diverse domains\ncompared to full-benchmark fine-tuning: +5.9% on mathematical reasoning\n(GSMHard), +3.6% on scientific reasoning (GenomeBench), and +16.6% on medical\nreasoning (MultiMedQA), while reducing computational requirements by 3-14x.\nAblation studies reveal a non-monotonic relationship between dataset\ncharacteristics and model performance, uncovering domain-specific optimal\npoints for question complexity and reasoning quality. NanoFlux automates\ntraining data generation through embedding-based novelty filtering,\ntool-augmented evaluation, and multi-hop reasoning, suggesting that future\nmodel improvements may lie in the intelligent synthesis of small, precisely\ntargeted training datasets."}
{"id": "2509.23254", "pdf": "https://arxiv.org/pdf/2509.23254", "abs": "https://arxiv.org/abs/2509.23254", "authors": ["Zhang-Yu You", "Jiahao Ma", "Hongzong Li", "Ye-Fan Hu", "Jian-Dong Huang"], "title": "ABConformer: Physics-inspired Sliding Attention for Antibody-Antigen Interface Prediction", "categories": ["cs.LG", "q-bio.BM"], "comment": null, "summary": "Accurate prediction of antibody-antigen (Ab-Ag) interfaces is critical for\nvaccine design, immunodiagnostics, and therapeutic antibody development.\nHowever, achieving reliable predictions from sequences alone remains a\nchallenge. In this paper, we present ABCONFORMER, a model based on the\nConformer backbone that captures both local and global features of a\nbiosequence. To accurately capture Ab-Ag interactions, we introduced the\nphysics-inspired sliding attention, enabling residue-level contact recovery\nwithout relying on three-dimensional structural data. ABConformer can\naccurately predict paratopes and epitopes given the antibody and antigen\nsequence, and predict pan-epitopes on the antigen without antibody information.\nIn comparison experiments, ABCONFORMER achieves state-of-the-art performance on\na recent SARS-CoV-2 Ab-Ag dataset, and surpasses widely used sequence-based\nmethods for antibody-agnostic epitope prediction. Ablation studies further\nquantify the contribution of each component, demonstrating that, compared to\nconventional cross-attention, sliding attention significantly enhances the\nprecision of epitope prediction. To facilitate reproducibility, we will release\nthe code under an open-source license upon acceptance."}
{"id": "2509.23265", "pdf": "https://arxiv.org/pdf/2509.23265", "abs": "https://arxiv.org/abs/2509.23265", "authors": ["Jiajun He", "Paul Jeha", "Peter Potaptchik", "Leo Zhang", "José Miguel Hernández-Lobato", "Yuanqi Du", "Saifuddin Syed", "Francisco Vargas"], "title": "CREPE: Controlling Diffusion with Replica Exchange", "categories": ["cs.LG"], "comment": "29 pages, 14 figures, 3 tables", "summary": "Inference-time control of diffusion models aims to steer model outputs to\nsatisfy new constraints without retraining. Previous approaches have mostly\nrelied on heuristic guidance or have been coupled with Sequential Monte Carlo\n(SMC) for bias correction. In this paper, we propose a flexible alternative\nbased on replica exchange, an algorithm designed initially for sampling\nproblems. We refer to this method as the CREPE (Controlling with REPlica\nExchange). Unlike SMC, CREPE: (1) generates particles sequentially, (2)\nmaintains high diversity in the generated samples after a burn-in period, and\n(3) enables online refinement or early termination. We demonstrate its\nversatility across various tasks, including temperature annealing,\nreward-tilting, model composition and classifier-free guidance debiasing, with\ncompetitive performance compared to prior SMC methods."}
{"id": "2509.23268", "pdf": "https://arxiv.org/pdf/2509.23268", "abs": "https://arxiv.org/abs/2509.23268", "authors": ["Lisa Pilgram", "Kai Yang", "Ana-Alicia Beltran-Bless", "Gregory R. Pond", "Lisa Vandermeer", "John Hilton", "Marie-France Savard", "Andréanne Leblanc", "Lois Sheperd", "Bingshu E. Chen", "John M. S. Bartlett", "Karen J. Taylor", "Jane Bayani", "Sarah L. Barker", "Melanie Spears", "Cornelis J. H. van der Velde", "Elma Meershoek-Klein Kranenbarg", "Luc Dirix", "Elizabeth Mallon", "Annette Hasenburg", "Christos Markopoulos", "Lamin Juwara", "Fida K. Dankar", "Mark Clemons", "Khaled El Emam"], "title": "Transfer Learning and Machine Learning for Training Five Year Survival Prognostic Models in Early Breast Cancer", "categories": ["cs.LG", "cs.CY"], "comment": null, "summary": "Prognostic information is essential for decision-making in breast cancer\nmanagement. Recently trials have predominantly focused on genomic\nprognostication tools, even though clinicopathological prognostication is less\ncostly and more widely accessible. Machine learning (ML), transfer learning and\nensemble integration offer opportunities to build robust prognostication\nframeworks. We evaluate this potential to improve survival prognostication in\nbreast cancer by comparing de-novo ML, transfer learning from a pre-trained\nprognostic tool and ensemble integration. Data from the MA.27 trial was used\nfor model training, with external validation on the TEAM trial and a SEER\ncohort. Transfer learning was applied by fine-tuning the pre-trained prognostic\ntool PREDICT v3, de-novo ML included Random Survival Forests and Extreme\nGradient Boosting, and ensemble integration was realized through a weighted sum\nof model predictions. Transfer learning, de-novo RSF, and ensemble integration\nimproved calibration in MA.27 over the pre-trained model (ICI reduced from\n0.042 in PREDICT v3 to <=0.007) while discrimination remained comparable (AUC\nincreased from 0.738 in PREDICT v3 to 0.744-0.799). Invalid PREDICT v3\npredictions were observed in 23.8-25.8% of MA.27 individuals due to missing\ninformation. In contrast, ML models and ensemble integration could predict\nsurvival regardless of missing information. Across all models, patient age,\nnodal status, pathological grading and tumor size had the highest SHAP values,\nindicating their importance for survival prognostication. External validation\nin SEER, but not in TEAM, confirmed the benefits of transfer learning, RSF and\nensemble integration. This study demonstrates that transfer learning, de-novo\nRSF, and ensemble integration can improve prognostication in situations where\nrelevant information for PREDICT v3 is lacking or where a dataset shift is\nlikely."}
{"id": "2509.23280", "pdf": "https://arxiv.org/pdf/2509.23280", "abs": "https://arxiv.org/abs/2509.23280", "authors": ["Yilie Huang"], "title": "Continuous-Time Reinforcement Learning for Asset-Liability Management", "categories": ["cs.LG", "cs.AI", "math.OC", "q-fin.MF"], "comment": "Accepted at the 6th ACM International Conference on AI in Finance\n  (ICAIF 2025), 8 pages, 2 figures", "summary": "This paper proposes a novel approach for Asset-Liability Management (ALM) by\nemploying continuous-time Reinforcement Learning (RL) with a linear-quadratic\n(LQ) formulation that incorporates both interim and terminal objectives. We\ndevelop a model-free, policy gradient-based soft actor-critic algorithm\ntailored to ALM for dynamically synchronizing assets and liabilities. To ensure\nan effective balance between exploration and exploitation with minimal tuning,\nwe introduce adaptive exploration for the actor and scheduled exploration for\nthe critic. Our empirical study evaluates this approach against two enhanced\ntraditional financial strategies, a model-based continuous-time RL method, and\nthree state-of-the-art RL algorithms. Evaluated across 200 randomized market\nscenarios, our method achieves higher average rewards than all alternative\nstrategies, with rapid initial gains and sustained superior performance. The\noutperformance stems not from complex neural networks or improved parameter\nestimation, but from directly learning the optimal ALM strategy without\nlearning the environment."}
{"id": "2509.23307", "pdf": "https://arxiv.org/pdf/2509.23307", "abs": "https://arxiv.org/abs/2509.23307", "authors": ["Gabriel Jarry", "Ramon Dalmau", "Xavier Olive", "Philippe Very"], "title": "A Neural ODE Approach to Aircraft Flight Dynamics Modelling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Accurate aircraft trajectory prediction is critical for air traffic\nmanagement, airline operations, and environmental assessment. This paper\nintroduces NODE-FDM, a Neural Ordinary Differential Equations-based Flight\nDynamics Model trained on Quick Access Recorder (QAR) data. By combining\nanalytical kinematic relations with data-driven components, NODE-FDM achieves a\nmore accurate reproduction of recorded trajectories than state-of-the-art\nmodels such as a BADA-based trajectory generation methodology (BADA4\nperformance model combined with trajectory control routines), particularly in\nthe descent phase of the flight. The analysis demonstrates marked improvements\nacross altitude, speed, and mass dynamics. Despite current limitations,\nincluding limited physical constraints and the limited availability of QAR\ndata, the results demonstrate the potential of physics-informed neural ordinary\ndifferential equations as a high-fidelity, data-driven approach to aircraft\nperformance modelling. Future work will extend the framework to incorporate a\nfull modelling of the lateral dynamics of the aircraft."}
{"id": "2509.23313", "pdf": "https://arxiv.org/pdf/2509.23313", "abs": "https://arxiv.org/abs/2509.23313", "authors": ["Xvyuan Liu", "Xiangfei Qiu", "Hanyin Cheng", "Xingjian Wu", "Chenjuan Guo", "Bin Yang", "Jilin Hu"], "title": "ASTGI: Adaptive Spatio-Temporal Graph Interactions for Irregular Multivariate Time Series Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "Irregular multivariate time series (IMTS) are prevalent in critical domains\nlike healthcare and finance, where accurate forecasting is vital for proactive\ndecision-making. However, the asynchronous sampling and irregular intervals\ninherent to IMTS pose two core challenges for existing methods: (1) how to\naccurately represent the raw information of irregular time series without\nintroducing data distortion, and (2) how to effectively capture the complex\ndynamic dependencies between observation points. To address these challenges,\nwe propose the Adaptive Spatio-Temporal Graph Interaction (ASTGI) framework.\nSpecifically, the framework first employs a Spatio-Temporal Point\nRepresentation module to encode each discrete observation as a point within a\nlearnable spatio-temporal embedding space. Second, a Neighborhood-Adaptive\nGraph Construction module adaptively builds a causal graph for each point in\nthe embedding space via nearest neighbor search. Subsequently, a\nSpatio-Temporal Dynamic Propagation module iteratively updates information on\nthese adaptive causal graphs by generating messages and computing interaction\nweights based on the relative spatio-temporal positions between points.\nFinally, a Query Point-based Prediction module generates the final forecast by\naggregating neighborhood information for a new query point and performing\nregression. Extensive experiments on multiple benchmark datasets demonstrate\nthat ASTGI outperforms various state-of-the-art methods."}
{"id": "2509.23314", "pdf": "https://arxiv.org/pdf/2509.23314", "abs": "https://arxiv.org/abs/2509.23314", "authors": ["Francesco Pappone", "Donato Crisostomi", "Emanuele Rodolà"], "title": "Two-Scale Latent Dynamics for Recurrent-Depth Transformers", "categories": ["cs.LG"], "comment": null, "summary": "Recurrent-depth transformers scale test-time compute by iterating latent\ncomputations before emitting tokens. We study the geometry of these iterates\nand argue for a simple, \\emph{two-scale} operational picture: (i) within a\nlooped block, updates act as \\emph{small-scale refinements}; (ii) across\nconsecutive blocks, states undergo a \\emph{larger-scale drift}. Across\ncheckpoints, our measurements show that loop steps become \\emph{smaller} and\nincreasingly \\emph{orthogonal} to one another, indicating better local modeling\nof fine structure rather than merely pushing in a single direction. These\ndynamics motivate an early-exit mechanism based on the model's second-order\ndifference in step-size, which we show is superior in terms of performance,\nstability and time-efficiency, when compared to the KL-divergence exit strategy\nof Geiping et al. and its naive first-order counterpart."}
{"id": "2509.23315", "pdf": "https://arxiv.org/pdf/2509.23315", "abs": "https://arxiv.org/abs/2509.23315", "authors": ["Khang Tran", "Hieu Cao", "Thinh Pham", "Nghiem Diep", "Tri Cao", "Binh Nguyen"], "title": "MELCOT: A Hybrid Learning Architecture with Marginal Preservation for Matrix-Valued Regression", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Regression is essential across many domains but remains challenging in\nhigh-dimensional settings, where existing methods often lose spatial structure\nor demand heavy storage. In this work, we address the problem of matrix-valued\nregression, where each sample is naturally represented as a matrix. We propose\nMELCOT, a hybrid model that integrates a classical machine learning-based\nMarginal Estimation (ME) block with a deep learning-based Learnable-Cost\nOptimal Transport (LCOT) block. The ME block estimates data marginals to\npreserve spatial information, while the LCOT block learns complex global\nfeatures. This design enables MELCOT to inherit the strengths of both classical\nand deep learning methods. Extensive experiments across diverse datasets and\ndomains demonstrate that MELCOT consistently outperforms all baselines while\nremaining highly efficient."}
{"id": "2509.23323", "pdf": "https://arxiv.org/pdf/2509.23323", "abs": "https://arxiv.org/abs/2509.23323", "authors": ["Xiangchen Song", "Jiaqi Sun", "Zijian Li", "Yujia Zheng", "Kun Zhang"], "title": "LLM Interpretability with Identifiable Temporal-Instantaneous Representation", "categories": ["cs.LG"], "comment": "NeurIPS 2025", "summary": "Despite Large Language Models' remarkable capabilities, understanding their\ninternal representations remains challenging. Mechanistic interpretability\ntools such as sparse autoencoders (SAEs) were developed to extract\ninterpretable features from LLMs but lack temporal dependency modeling,\ninstantaneous relation representation, and more importantly theoretical\nguarantees, undermining both the theoretical foundations and the practical\nconfidence necessary for subsequent analyses. While causal representation\nlearning (CRL) offers theoretically grounded approaches for uncovering latent\nconcepts, existing methods cannot scale to LLMs' rich conceptual space due to\ninefficient computation. To bridge the gap, we introduce an identifiable\ntemporal causal representation learning framework specifically designed for\nLLMs' high-dimensional concept space, capturing both time-delayed and\ninstantaneous causal relations. Our approach provides theoretical guarantees\nand demonstrates efficacy on synthetic datasets scaled to match real-world\ncomplexity. By extending SAE techniques with our temporal causal framework, we\nsuccessfully discover meaningful concept relationships in LLM activations. Our\nfindings show that modeling both temporal and instantaneous conceptual\nrelationships advances the interpretability of LLMs."}
{"id": "2509.23325", "pdf": "https://arxiv.org/pdf/2509.23325", "abs": "https://arxiv.org/abs/2509.23325", "authors": ["Jonas Ngnawé", "Maxime Heuillet", "Sabyasachi Sahoo", "Yann Pequignot", "Ola Ahmad", "Audrey Durand", "Frédéric Precioso", "Christian Gagné"], "title": "Robust Fine-Tuning from Non-Robust Pretrained Models: Mitigating Suboptimal Transfer With Adversarial Scheduling", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Fine-tuning pretrained models is a standard and effective workflow in modern\nmachine learning. However, robust fine-tuning (RFT), which aims to\nsimultaneously achieve adaptation to a downstream task and robustness to\nadversarial examples, remains challenging. Despite the abundance of non-robust\npretrained models in open-source repositories, their potential for RFT is less\nunderstood. We address this knowledge gap by systematically examining RFT from\nsuch non-robust models. Our experiments reveal that fine-tuning non-robust\nmodels with a robust objective, even under small perturbations, can lead to\npoor performance, a phenomenon that we dub \\emph{suboptimal transfer}. In\nchallenging scenarios (eg, difficult tasks, high perturbation), the resulting\nperformance can be so low that it may be considered a transfer failure. We find\nthat fine-tuning using a robust objective impedes task adaptation at the\nbeginning of training and eventually prevents optimal transfer. However, we\npropose a novel heuristic, \\emph{Epsilon-Scheduling}, a schedule over\nperturbation strength used during training that promotes optimal transfer.\nAdditionally, we introduce \\emph{expected robustness}, a metric that captures\nperformance across a range of perturbations, providing a more comprehensive\nevaluation of the accuracy-robustness trade-off for diverse models at test\ntime. Extensive experiments on a wide range of configurations (six pretrained\nmodels and five datasets) show that \\emph{Epsilon-Scheduling} successfully\nprevents \\emph{suboptimal transfer} and consistently improves expected\nrobustness."}
{"id": "2509.23348", "pdf": "https://arxiv.org/pdf/2509.23348", "abs": "https://arxiv.org/abs/2509.23348", "authors": ["Xavier Aramayo Carrasco", "Grigoriy Ksenofontov", "Aleksei Leonov", "Iaroslav Sergeevich Koshelev", "Alexander Korotin"], "title": "Entering the Era of Discrete Diffusion Models: A Benchmark for Schrödinger Bridges and Entropic Optimal Transport", "categories": ["cs.LG"], "comment": null, "summary": "The Entropic Optimal Transport (EOT) problem and its dynamic counterpart, the\nSchr\\\"odinger bridge (SB) problem, play an important role in modern machine\nlearning, linking generative modeling with optimal transport theory. While\nrecent advances in discrete diffusion and flow models have sparked growing\ninterest in applying SB methods to discrete domains, there is still no reliable\nway to evaluate how well these methods actually solve the underlying problem.\nWe address this challenge by introducing a benchmark for SB on discrete spaces.\nOur construction yields pairs of probability distributions with analytically\nknown SB solutions, enabling rigorous evaluation. As a byproduct of building\nthis benchmark, we obtain two new SB algorithms, DLightSB and DLightSB-M, and\nadditionally extend prior related work to construct the $\\alpha$-CSBM\nalgorithm. We demonstrate the utility of our benchmark by evaluating both\nexisting and new solvers in high-dimensional discrete settings. This work\nprovides the first step toward proper evaluation of SB methods on discrete\nspaces, paving the way for more reproducible future studies."}
{"id": "2509.23357", "pdf": "https://arxiv.org/pdf/2509.23357", "abs": "https://arxiv.org/abs/2509.23357", "authors": ["Andrey Kharitenko", "Zebang Shen", "Riccardo de Santi", "Niao He", "Florian Doerfler"], "title": "Landing with the Score: Riemannian Optimization through Denoising", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": "37 pages, 9 figures", "summary": "Under the data manifold hypothesis, high-dimensional data are concentrated\nnear a low-dimensional manifold. We study the problem of Riemannian\noptimization over such manifolds when they are given only implicitly through\nthe data distribution, and the standard manifold operations required by\nclassical algorithms are unavailable. This formulation captures a broad class\nof data-driven design problems that are central to modern generative AI. Our\nkey idea is to introduce a link function that connects the data distribution to\nthe geometric operations needed for optimization. We show that this function\nenables the recovery of essential manifold operations, such as retraction and\nRiemannian gradient computation. Moreover, we establish a direct connection\nbetween our construction and the score function in diffusion models of the data\ndistribution. This connection allows us to leverage well-studied\nparameterizations, efficient training procedures, and even pretrained score\nnetworks from the diffusion model literature to perform optimization. Building\non this foundation, we propose two efficient inference-time algorithms --\nDenoising Landing Flow (DLF) and Denoising Riemannian Gradient Descent (DRGD)\n-- and provide theoretical guarantees for both feasibility (approximate\nmanifold adherence) and optimality (small Riemannian gradient norm). Finally,\nwe demonstrate the effectiveness of our approach on finite-horizon reference\ntracking tasks in data-driven control, highlighting its potential for practical\ngenerative and design applications."}
{"id": "2509.23365", "pdf": "https://arxiv.org/pdf/2509.23365", "abs": "https://arxiv.org/abs/2509.23365", "authors": ["Hanlin Zhu", "Shibo Hao", "Zhiting Hu", "Jiantao Jiao", "Stuart Russell", "Yuandong Tian"], "title": "Emergence of Superposition: Unveiling the Training Dynamics of Chain of Continuous Thought", "categories": ["cs.LG"], "comment": "29 pages, 5 figures", "summary": "Previous work shows that the chain of continuous thought (continuous CoT)\nimproves the reasoning capability of large language models (LLMs) by enabling\nimplicit parallel thinking, and a subsequent work provided theoretical insight\nby showing that a two-layer transformer equipped with continuous CoT can\nefficiently solve directed graph reachability by maintaining a superposition of\nmultiple reasoning traces in the continuous thought. However, it remains\nunclear how the superposition mechanism is naturally learned from\ngradient-based training methods. To fill this gap, we theoretically analyze the\ntraining dynamics of a simplified two-layer transformer on the directed graph\nreachability problem to unveil how the superposition mechanism emerges during\ntraining in two training stages -- (i) a thought-generation stage that\nautoregressively expands the continuous thought, and (ii) a prediction stage\nthat converts the thought into the final answer. Our analysis reveals that\nduring training using continuous thought, the index-matching logit, an\nimportant quantity which reflects the strength of the model's local search\nability, will first increase and then remain bounded under mild assumptions.\nThe bounded index-matching logit effectively balances exploration and\nexploitation during the reasoning process: the model will exploit local problem\nstructures to identify plausible search traces, and assign comparable weights\nto multiple such traces to explore when it is uncertain about which solution is\ncorrect, which results in superposition. Our experimental results tracking the\ngrowth of logits further validate our theory."}
{"id": "2509.23366", "pdf": "https://arxiv.org/pdf/2509.23366", "abs": "https://arxiv.org/abs/2509.23366", "authors": ["Ange-Clément Akazan", "Verlon Roel Mbingui"], "title": "Splines-Based Feature Importance in Kolmogorov-Arnold Networks: A Framework for Supervised Tabular Data Dimensionality Reduction", "categories": ["cs.LG"], "comment": null, "summary": "High-dimensional datasets require effective feature selection to improve\npredictive performance, interpretability, and robustness. We propose and\nevaluate feature selection methods for tabular datasets based on\nKolmogorov-Arnold networks (KANs), which parameterize feature transformations\nthrough splines, enabling direct access to interpretable importance measures.\nWe introduce four KAN-based selectors ($\\textit{KAN-L1}$, $\\textit{KAN-L2}$,\n$\\textit{KAN-SI}$, $\\textit{KAN-KO}$) and compare them against classical\nbaselines (LASSO, Random Forest, Mutual Information, SVM-RFE) across multiple\nclassification and regression tabular dataset benchmarks. Average (over three\nretention levels: 20\\%, 40\\%, and 60\\%) F1 scores and $R^2$ score results\nreveal that KAN-based selectors, particularly $\\textit{KAN-L2}$,\n$\\textit{KAN-L1}$, $\\textit{KAN-SI}$, and $\\textit{KAN-KO}$, are competitive\nwith and sometimes superior to classical baselines in structured and synthetic\ndatasets. However, $\\textit{KAN-L1}$ is often too aggressive in regression,\nremoving useful features, while $\\textit{KAN-L2}$ underperforms in\nclassification, where simple coefficient shrinkage misses complex feature\ninteractions. $\\textit{KAN-L2}$ and $\\textit{KAN-SI}$ provide robust\nperformance on noisy regression datasets and heterogeneous datasets, aligning\nclosely with ensemble predictors. In classification tasks, KAN selectors such\nas $\\textit{KAN-L1}$, $\\textit{KAN-KO}$, and $\\textit{KAN-SI}$ sometimes\nsurpass the other selectors by eliminating redundancy, particularly in\nhigh-dimensional multi-class data. Overall, our findings demonstrate that\nKAN-based feature selection provides a powerful and interpretable alternative\nto traditional methods, capable of uncovering nonlinear and multivariate\nfeature relevance beyond sparsity or impurity-based measures."}
{"id": "2509.23373", "pdf": "https://arxiv.org/pdf/2509.23373", "abs": "https://arxiv.org/abs/2509.23373", "authors": ["Xi Ding", "Lei Wang", "Piotr Koniusz", "Yongsheng Gao"], "title": "Graph Your Own Prompt", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "Accepted at the 39th Conference on Neural Information Processing\n  Systems (NeurIPS 2025)", "summary": "We propose Graph Consistency Regularization (GCR), a novel framework that\ninjects relational graph structures, derived from model predictions, into the\nlearning process to promote class-aware, semantically meaningful feature\nrepresentations. Functioning as a form of self-prompting, GCR enables the model\nto refine its internal structure using its own outputs. While deep networks\nlearn rich representations, these often capture noisy inter-class similarities\nthat contradict the model's predicted semantics. GCR addresses this issue by\nintroducing parameter-free Graph Consistency Layers (GCLs) at arbitrary depths.\nEach GCL builds a batch-level feature similarity graph and aligns it with a\nglobal, class-aware masked prediction graph, derived by modulating softmax\nprediction similarities with intra-class indicators. This alignment enforces\nthat feature-level relationships reflect class-consistent prediction behavior,\nacting as a semantic regularizer throughout the network. Unlike prior work, GCR\nintroduces a multi-layer, cross-space graph alignment mechanism with adaptive\nweighting, where layer importance is learned from graph discrepancy magnitudes.\nThis allows the model to prioritize semantically reliable layers and suppress\nnoisy ones, enhancing feature quality without modifying the architecture or\ntraining procedure. GCR is model-agnostic, lightweight, and improves semantic\nstructure across various networks and datasets. Experiments show that GCR\npromotes cleaner feature structure, stronger intra-class cohesion, and improved\ngeneralization, offering a new perspective on learning from prediction\nstructure. [Project website](https://darcyddx.github.io/gcr/)\n[Code](https://github.com/Darcyddx/graph-prompt)"}
{"id": "2509.23405", "pdf": "https://arxiv.org/pdf/2509.23405", "abs": "https://arxiv.org/abs/2509.23405", "authors": ["Fred Zhangzhi Peng", "Zachary Bezemek", "Jarrid Rector-Brooks", "Shuibai Zhang", "Anru R. Zhang", "Michael Bronstein", "Avishek Joey Bose", "Alexander Tong"], "title": "Planner Aware Path Learning in Diffusion Language Models Training", "categories": ["cs.LG"], "comment": null, "summary": "Diffusion language models have emerged as a powerful alternative to\nautoregressive models, enabling fast inference through flexible and parallel\ngeneration paths. This flexibility is enabled by new sampling strategies, or\nplanners, that iteratively choose where to denoise along the sequence rather\nthan sampling uniformly at random. However, by modifying reverse paths,\nplanners introduce a mismatch between the uniformly random denoising paths used\nduring training and the planning-based paths used at inference. In this work,\nwe systematically investigate this mismatch and theoretically show that the\nstandard discrete diffusion training evidence lower bound (ELBO) does not\naccurately describe a denoiser under non-uniform planning. To bridge this gap,\nwe derive a new Planned Evidence Lower Bound (P-ELBO) that directly\nincorporates planner-based reverse dynamics into the training objective.\nBuilding on this, we propose Planner Aware Path Learning (PAPL), a simple and\neffective modification of the standard masked discrete diffusion loss that\naligns training and inference under planned denoisers. Empirically, PAPL\ndelivers consistent improvements across domains, including a 40% relative gain\nin protein sequence modeling, up to a 4x improvement in MAUVE for text\ngeneration, and a 23% relative gain in HumanEval pass@10 for code generation."}
{"id": "2509.23409", "pdf": "https://arxiv.org/pdf/2509.23409", "abs": "https://arxiv.org/abs/2509.23409", "authors": ["Devesh Sharma", "Aditya Kishore", "Ayush Garg", "Debajyoti Mazumder", "Debasis Mohapatra", "Jasabanta Patro"], "title": "Mind the Links: Cross-Layer Attention for Link Prediction in Multiplex Networks", "categories": ["cs.LG"], "comment": null, "summary": "Multiplex graphs capture diverse relations among shared nodes. Most\npredictors either collapse layers or treat them independently. This loses\ncrucial inter-layer dependencies and struggles with scalability. To overcome\nthis, we frame multiplex link prediction as multi-view edge classification. For\neach node pair, we construct a sequence of per-layer edge views and apply\ncross-layer self-attention to fuse evidence for the target layer. We present\ntwo models as instances of this framework: Trans-SLE, a lightweight transformer\nover static embeddings, and Trans-GAT, which combines layer-specific GAT\nencoders with transformer fusion. To ensure scalability and fairness, we\nintroduce a Union--Set candidate pool and two leakage-free protocols:\ncross-layer and inductive subgraph generalization. Experiments on six public\nmultiplex datasets show consistent macro-F_1 gains over strong baselines (MELL,\nHOPLP-MUL, RMNE). Our approach is simple, scalable, and compatible with both\nprecomputed embeddings and GNN encoders."}
{"id": "2509.23410", "pdf": "https://arxiv.org/pdf/2509.23410", "abs": "https://arxiv.org/abs/2509.23410", "authors": ["Younes Hourri", "Mohammad Mozaffari", "Maryam Mehri Dehnavi"], "title": "PATCH: Learnable Tile-level Hybrid Sparsity for LLMs", "categories": ["cs.LG", "cs.AI", "cs.PF"], "comment": null, "summary": "Large language models (LLMs) deliver impressive performance but incur\nprohibitive memory and compute costs at deployment. Model pruning is an\neffective way to reduce these overheads, yet existing approaches face\nchallenges: unstructured sparsity, where nonzeros can appear anywhere,\npreserves accuracy but yields irregular access patterns that prevent GPU\nacceleration, while semi-structured 2:4 sparsity is hardware-friendly but\nenforces a rigid 50% pattern that degrades model quality. To bridge this gap,\nwe introduce PATCH, a hybrid sparsity framework that enables a continuous\nsparsity ratio between 0% and 50%. PATCH partitions weight matrices into tiles,\nassigning each tile to be either dense or 2:4 sparse via a learnable mask\nselection mechanism. This design provides fine-grained control over\naccuracy-acceleration tradeoffs and supports non-uniform sparsity across\nlayers, leading to superior overall quality. Across models from 0.5B to 8B\nparameters, PATCH consistently narrows the gap to dense accuracy while\ndelivering practical speedups. For instance, on LLaMA-2 7B with an A6000 GPU,\nPATCH achieves 1.18x-1.38x end-to-end speedup over dense baselines while\nimproving accuracy by 0.37%-2.96% compared to the state-of-the-art 2:4 pruning\nmethod, MaskLLM."}
{"id": "2509.23413", "pdf": "https://arxiv.org/pdf/2509.23413", "abs": "https://arxiv.org/abs/2509.23413", "authors": ["Changliang Zhou", "Canhong Yu", "Shunyu Yao", "Xi Lin", "Zhenkun Wang", "Yu Zhou", "Qingfu Zhang"], "title": "URS: A Unified Neural Routing Solver for Cross-Problem Zero-Shot Generalization", "categories": ["cs.LG"], "comment": "31 pages,3 figures", "summary": "Multi-task neural routing solvers have emerged as a promising paradigm for\ntheir ability to solve multiple vehicle routing problems (VRPs) using a single\nmodel. However, existing neural solvers typically rely on predefined problem\nconstraints or require per-problem fine-tuning, which substantially limits\ntheir zero-shot generalization ability to unseen VRP variants. To address this\ncritical bottleneck, we propose URS, a unified neural routing solver capable of\nzero-shot generalization across a wide range of unseen VRPs using a single\nmodel without any fine-tuning. The key component of URS is the unified data\nrepresentation (UDR), which replaces problem enumeration with data unification,\nthereby broadening the problem coverage and reducing reliance on domain\nexpertise. In addition, we propose a Mixed Bias Module (MBM) to efficiently\nlearn the geometric and relational biases inherent in various problems. On top\nof the proposed UDR, we further develop a parameter generator that adaptively\nadjusts the decoder and bias weights of MBM to enhance zero-shot\ngeneralization. Moreover, we propose an LLM-driven constraint satisfaction\nmechanism, which translates raw problem descriptions into executable stepwise\nmasking functions to ensure solution feasibility. Extensive experiments\ndemonstrate that URS can consistently produce high-quality solutions for more\nthan 100 distinct VRP variants without any fine-tuning, which includes more\nthan 90 unseen variants. To the best of our knowledge, URS is the first neural\nsolver capable of handling over 100 VRP variants with a single model."}
{"id": "2509.23436", "pdf": "https://arxiv.org/pdf/2509.23436", "abs": "https://arxiv.org/abs/2509.23436", "authors": ["Ashkan Shahbazi", "Chayne Thrash", "Yikun Bai", "Keaton Hamm", "Navid NaderiAlizadeh", "Soheil Kolouri"], "title": "LOTFormer: Doubly-Stochastic Linear Attention via Low-Rank Optimal Transport", "categories": ["cs.LG"], "comment": null, "summary": "Transformers have proven highly effective across a wide range of modalities.\nHowever, the quadratic complexity of the standard softmax attention mechanism\nposes a fundamental barrier to scaling them to long context windows. A large\nbody of work addresses this with linear attention, which reformulates attention\nas a kernel function and approximates it with finite feature maps to achieve\nlinear-time computation. Orthogonal to computational scaling, most attention\nmechanisms -- both quadratic and linear -- produce row-normalized maps that can\nover-focus on a few tokens, degrading robustness and information flow.\nEnforcing doubly-stochastic attention alleviates this by balancing token\nparticipation across rows and columns, but existing doubly-stochastic attention\nmechanisms typically introduce substantial overhead, undermining scalability.\nWe propose LOTFormer, a principled attention mechanism that is simultaneously\nlinear-time and doubly-stochastic. Our approach exploits the connection between\nattention maps and transportation plans between query and key measures. The\ncentral idea is to constrain the transport plan to be low-rank by conditioning\nit on a learnable pivot measure with small support. Concretely, we solve two\nentropic optimal transport problems (queries $\\to$ pivot and pivot $\\to$ keys)\nand compose them into a conditional (glued) coupling. This yields an attention\nmatrix that is provably doubly-stochastic, has rank at most $r \\ll n$, and\napplies to values in $O(nr)$ time without forming the full $n \\times n$ map.\nThe pivot locations and masses are learned end-to-end. Empirically, LOTFormer\nachieves state-of-the-art results on the Long Range Arena benchmark, surpassing\nprior linear and transport-based attention methods in both accuracy and\nefficiency."}
{"id": "2509.23437", "pdf": "https://arxiv.org/pdf/2509.23437", "abs": "https://arxiv.org/abs/2509.23437", "authors": ["Steve Hong", "Runa Eschenhagen", "Bruno Mlodozeniec", "Richard Turner"], "title": "Better Hessians Matter: Studying the Impact of Curvature Approximations in Influence Functions", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Influence functions offer a principled way to trace model predictions back to\ntraining data, but their use in deep learning is hampered by the need to invert\na large, ill-conditioned Hessian matrix. Approximations such as Generalised\nGauss-Newton (GGN) and Kronecker-Factored Approximate Curvature (K-FAC) have\nbeen proposed to make influence computation tractable, yet it remains unclear\nhow the departure from exactness impacts data attribution performance.\nCritically, given the restricted regime in which influence functions are\nderived, it is not necessarily clear better Hessian approximations should even\nlead to better data attribution performance. In this paper, we investigate the\neffect of Hessian approximation quality on influence-function attributions in a\ncontrolled classification setting. Our experiments show that better Hessian\napproximations consistently yield better influence score quality, offering\njustification for recent research efforts towards that end. We further\ndecompose the approximation steps for recent Hessian approximation methods and\nevaluate each step's influence on attribution accuracy. Notably, the mismatch\nbetween K-FAC eigenvalues and GGN/EK-FAC eigenvalues accounts for the majority\nof the error and influence loss. These findings highlight which approximations\nare most critical, guiding future efforts to balance computational tractability\nand attribution accuracy."}
{"id": "2509.23443", "pdf": "https://arxiv.org/pdf/2509.23443", "abs": "https://arxiv.org/abs/2509.23443", "authors": ["Wenhao Yang", "Lin Li", "Xiaohui Tao", "Kaize Shi"], "title": "Factor Decorrelation Enhanced Data Removal from Deep Predictive Models", "categories": ["cs.LG", "cs.AI"], "comment": "accepted by NeurIPS 2025", "summary": "The imperative of user privacy protection and regulatory compliance\nnecessitates sensitive data removal in model training, yet this process often\ninduces distributional shifts that undermine model performance-particularly in\nout-of-distribution (OOD) scenarios. We propose a novel data removal approach\nthat enhances deep predictive models through factor decorrelation and loss\nperturbation. Our approach introduces: (1) a discriminative-preserving factor\ndecorrelation module employing dynamic adaptive weight adjustment and iterative\nrepresentation updating to reduce feature redundancy and minimize inter-feature\ncorrelations. (2) a smoothed data removal mechanism with loss perturbation that\ncreates information-theoretic safeguards against data leakage during removal\noperations. Extensive experiments on five benchmark datasets show that our\napproach outperforms other baselines and consistently achieves high predictive\naccuracy and robustness even under significant distribution shifts. The results\nhighlight its superior efficiency and adaptability in both in-distribution and\nout-of-distribution scenarios."}
{"id": "2509.23453", "pdf": "https://arxiv.org/pdf/2509.23453", "abs": "https://arxiv.org/abs/2509.23453", "authors": ["Dawei Gao", "Dali Wang", "Zhuowei Gu", "Qinglei Cao", "Xiao Wang", "Peter Thornton", "Dan Ricciuto", "Yunhe Feng"], "title": "PHASE: Physics-Integrated, Heterogeneity-Aware Surrogates for Scientific Simulations", "categories": ["cs.LG", "physics.comp-ph"], "comment": "19 pages, 13 figures", "summary": "Large-scale numerical simulations underpin modern scientific discovery but\nremain constrained by prohibitive computational costs. AI surrogates offer\nacceleration, yet adoption in mission-critical settings is limited by concerns\nover physical plausibility, trustworthiness, and the fusion of heterogeneous\ndata. We introduce PHASE, a modular deep-learning framework for\nphysics-integrated, heterogeneity-aware surrogates in scientific simulations.\nPHASE combines data-type-aware encoders for heterogeneous inputs with\nmulti-level physics-based constraints that promote consistency from local\ndynamics to global system behavior. We validate PHASE on the biogeochemical\n(BGC) spin-up workflow of the U.S. Department of Energy's Energy Exascale Earth\nSystem Model (E3SM) Land Model (ELM), presenting-to our knowledge-the first\nscientifically validated AI-accelerated solution for this task. Using only the\nfirst 20 simulation years, PHASE infers a near-equilibrium state that otherwise\nrequires more than 1,200 years of integration, yielding an effective reduction\nin required integration length by at least 60x. The framework is enabled by a\npipeline for fusing heterogeneous scientific data and demonstrates strong\ngeneralization to higher spatial resolutions with minimal fine-tuning. These\nresults indicate that PHASE captures governing physical regularities rather\nthan surface correlations, enabling practical, physically consistent\nacceleration of land-surface modeling and other complex scientific workflows."}
{"id": "2509.23461", "pdf": "https://arxiv.org/pdf/2509.23461", "abs": "https://arxiv.org/abs/2509.23461", "authors": ["Ziheng Cheng", "Zhong Li", "Jiang Bian"], "title": "Data-Efficient Training by Evolved Sampling", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Data selection is designed to accelerate learning with preserved performance.\nTo achieve this, a fundamental thought is to identify informative data samples\nwith significant contributions to the training. In this work, we propose\n\\textbf{Evolved Sampling} (\\textbf{ES}), a simple yet effective framework for\n\\emph{dynamic} sampling along the training process. This method conducts \\em\nbatch \\em level data selection based on the dynamics of losses and augmented\n\\emph{loss differences}, which enables flexible \\emph{frequency tuning}, and\nhence significantly reduces the back propagation time with maintained model\nperformance. Due to its conciseness, ES is also readily extensible to\nincorporate \\em set \\em level data selection (to form ES with pruning,\n\\textbf{ESWP}) for further accelerations. As a plug-and-play framework, ES(WP)\nconsistently achieves lossless training accelerations across various\npre-training and post-training tasks, saving up to nearly 45\\% wall-clock time.\nOur results motivate further investigations on the data efficiency aspect of\nmodern large-scale machine learning."}
{"id": "2509.23462", "pdf": "https://arxiv.org/pdf/2509.23462", "abs": "https://arxiv.org/abs/2509.23462", "authors": ["Alakh Sharma", "Gaurish Trivedi", "Kartikey Bhandari", "Yash Sinha", "Dhruv Kumar", "Pratik Narang", "Jagat Sesh Challa"], "title": "Generative Evolutionary Meta-Solver (GEMS): Scalable Surrogate-Free Multi-Agent Learning", "categories": ["cs.LG", "cs.AI"], "comment": "Under review", "summary": "Scalable multi-agent reinforcement learning (MARL) remains a central\nchallenge for AI. Existing population-based methods, like Policy-Space Response\nOracles, PSRO, require storing explicit policy populations and constructing\nfull payoff matrices, incurring quadratic computation and linear memory costs.\nWe present Generative Evolutionary Meta-Solver (GEMS), a surrogate-free\nframework that replaces explicit populations with a compact set of latent\nanchors and a single amortized generator. Instead of exhaustively constructing\nthe payoff matrix, GEMS relies on unbiased Monte Carlo rollouts,\nmultiplicative-weights meta-dynamics, and a model-free empirical-Bernstein UCB\noracle to adaptively expand the policy set. Best responses are trained within\nthe generator using an advantage-based trust-region objective, eliminating the\nneed to store and train separate actors. We evaluated GEMS in a variety of\nTwo-player and Multi-Player games such as the Deceptive Messages Game, Kuhn\nPoker and Multi-Particle environment. We find that GEMS is up to ~6x faster,\nhas 1.3x less memory usage than PSRO, while also reaps higher rewards\nsimultaneously. These results demonstrate that GEMS retains the game theoretic\nguarantees of PSRO, while overcoming its fundamental inefficiencies, hence\nenabling scalable multi-agent learning in multiple domains."}
{"id": "2509.23470", "pdf": "https://arxiv.org/pdf/2509.23470", "abs": "https://arxiv.org/abs/2509.23470", "authors": ["Rui Ai", "Hugo De Oliveira Barbalho", "Sirui Li", "Alexei Robsky", "David Simchi-Levi", "Ishai Menache"], "title": "Solve Smart, Not Often: Policy Learning for Costly MILP Re-solving", "categories": ["cs.LG"], "comment": null, "summary": "A common challenge in real-time operations is deciding whether to re-solve an\noptimization problem or continue using an existing solution. While modern data\nplatforms may collect information at high frequencies, many real-time\noperations require repeatedly solving computationally intensive optimization\nproblems formulated as Mixed-Integer Linear Programs (MILPs). Determining when\nto re-solve is, therefore, an economically important question. This problem\nposes several challenges: 1) How to characterize solution optimality and\nsolving cost; 2) How to detect environmental changes and select beneficial\nsamples for solving the MILP; 3) Given the large time horizon and non-MDP\nstructure, vanilla reinforcement learning (RL) methods are not directly\napplicable and tend to suffer from value function explosion. Existing\nliterature largely focuses on heuristics, low-data settings, and smooth\nobjectives, with little focus on common NP-hard MILPs. We propose a framework\ncalled Proximal Policy Optimization with Change Point Detection (POC), which\nsystematically offers a solution for balancing performance and cost when\ndeciding appropriate re-solving times. Theoretically, we establish the\nrelationship between the number of re-solves and the re-solving cost. To test\nour framework, we assemble eight synthetic and real-world datasets, and show\nthat POC consistently outperforms existing baselines by 2%-17%. As a side\nbenefit, our work fills the gap in the literature by introducing real-time MILP\nbenchmarks and evaluation criteria."}
{"id": "2509.23471", "pdf": "https://arxiv.org/pdf/2509.23471", "abs": "https://arxiv.org/abs/2509.23471", "authors": ["Harshil Vejendla"], "title": "Drift-Adapter: A Practical Approach to Near Zero-Downtime Embedding Model Upgrades in Vector Databases", "categories": ["cs.LG", "cs.IR"], "comment": "EMNLP 2025 Main 12 pages, 6 figures", "summary": "Upgrading embedding models in production vector databases typically requires\nre-encoding the entire corpus and rebuilding the Approximate Nearest Neighbor\n(ANN) index, leading to significant operational disruption and computational\ncost. This paper presents Drift-Adapter, a lightweight, learnable\ntransformation layer designed to bridge embedding spaces between model\nversions. By mapping new queries into the legacy embedding space, Drift-Adapter\nenables the continued use of the existing ANN index, effectively deferring full\nre-computation. We systematically evaluate three adapter parameterizations:\nOrthogonal Procrustes, Low-Rank Affine, and a compact Residual MLP, trained on\na small sample of paired old and new embeddings. Experiments on MTEB text\ncorpora and a CLIP image model upgrade (1M items) show that Drift-Adapter\nrecovers 95-99% of the retrieval recall (Recall@10, MRR) of a full\nre-embedding, adding less than 10 microseconds of query latency. Compared to\noperational strategies like full re-indexing or dual-index serving,\nDrift-Adapter reduces recompute costs by over 100 times and facilitates\nupgrades with near-zero operational interruption. We analyze robustness to\nvaried model drift, training data size, scalability to billion-item systems,\nand the impact of design choices like diagonal scaling, demonstrating\nDrift-Adapter's viability as a pragmatic solution for agile model deployment."}
{"id": "2509.23472", "pdf": "https://arxiv.org/pdf/2509.23472", "abs": "https://arxiv.org/abs/2509.23472", "authors": ["Jiang-Xin Shi", "Wen-Da Wei", "Jin-Fei Qi", "Xuanyu Chen", "Tong Wei", "Yu-Feng Li"], "title": "Memory-Efficient Fine-Tuning via Low-Rank Activation Compression", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The parameter-efficient fine-tuning paradigm has garnered significant\nattention with the advancement of foundation models. Although numerous methods\nhave been proposed to reduce the number of trainable parameters, their\nsubstantial memory overhead remains a critical bottleneck that hinders\npractical deployment. In this paper, we observe that model activations\nconstitute a major source of memory consumption, especially under large batch\nsizes and long context lengths; however, the rank of the activations remains\nconsistently low. Motivated by this insight, we propose a memory-efficient\nfine-tuning approach Low-Rank Activation Compression (LoRAct). Unlike prior\nwork, LoRAct provides a more flexible and versatile compressing strategy that\ncan be applied online during the forward pass without the need for any\ncalibration data. Moreover, LoRAct incorporates a novel sampling-based\northogonal decomposition algorithm specifically designed for low-rank matrices,\noffering improved computational efficiency and a tighter error bound compared\nto the widely used RSVD. Experiments on both vision and language tasks\ndemonstrate the effectiveness of LoRAct. Notably, LoRAct further reduces\nactivation memory by approximately 80% in comparison with the widely adopted\nLoRA method, while maintaining competitive performance. The source code is\navailable at https://github.com/shijxcs/meft."}
{"id": "2509.23474", "pdf": "https://arxiv.org/pdf/2509.23474", "abs": "https://arxiv.org/abs/2509.23474", "authors": ["Yahong Yang", "Wei Zhu"], "title": "Statistical Learning Guarantees for Group-Invariant Barron Functions", "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH"], "comment": null, "summary": "We investigate the generalization error of group-invariant neural networks\nwithin the Barron framework. Our analysis shows that incorporating\ngroup-invariant structures introduces a group-dependent factor\n$\\delta_{G,\\Gamma,\\sigma} \\le 1$ into the approximation rate. When this factor\nis small, group invariance yields substantial improvements in approximation\naccuracy. On the estimation side, we establish that the Rademacher complexity\nof the group-invariant class is no larger than that of the non-invariant\ncounterpart, implying that the estimation error remains unaffected by the\nincorporation of symmetry. Consequently, the generalization error can improve\nsignificantly when learning functions with inherent group symmetries. We\nfurther provide illustrative examples demonstrating both favorable cases, where\n$\\delta_{G,\\Gamma,\\sigma}\\approx |G|^{-1}$, and unfavorable ones, where\n$\\delta_{G,\\Gamma,\\sigma}\\approx 1$. Overall, our results offer a rigorous\ntheoretical foundation showing that encoding group-invariant structures in\nneural networks leads to clear statistical advantages for symmetric target\nfunctions."}
{"id": "2509.23487", "pdf": "https://arxiv.org/pdf/2509.23487", "abs": "https://arxiv.org/abs/2509.23487", "authors": ["Divyam Madaan", "Sumit Chopra", "Kyunghyun Cho"], "title": "Temporal Generalization: A Reality Check", "categories": ["cs.LG", "cs.CL", "cs.CV"], "comment": null, "summary": "Machine learning (ML) models often struggle to maintain performance under\ndistribution shifts, leading to inaccurate predictions on unseen future data.\nIn this work, we investigate whether and under what conditions models can\nachieve such a generalization when relying solely on past data. We explore two\nprimary approaches: convex combinations of past model parameters\n(\\emph{parameter interpolation}) and explicit extrapolation beyond the convex\nhull of past parameters (\\emph{parameter extrapolation}). We benchmark several\nmethods within these categories on a diverse set of temporal tasks, including\nlanguage modeling, news summarization, news tag prediction, academic paper\ncategorization, satellite image-based land use classification over time, and\nhistorical yearbook photo gender prediction. Our empirical findings show that\nnone of the evaluated methods consistently outperforms the simple baseline of\nusing the latest available model parameters in all scenarios. In the absence of\naccess to future data or robust assumptions about the underlying\ndata-generating process, these results underscore the inherent difficulties of\ngeneralizing and extrapolating to future data and warrant caution when\nevaluating claims of such generalization."}
{"id": "2509.23494", "pdf": "https://arxiv.org/pdf/2509.23494", "abs": "https://arxiv.org/abs/2509.23494", "authors": ["Jie Yang", "Yifan Hu", "Kexin Zhang", "Luyang Niu", "Yushun Dong", "Philip S. Yu", "Kaize Ding"], "title": "Revisiting Multivariate Time Series Forecasting with Missing Values", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Missing values are common in real-world time series, and multivariate time\nseries forecasting with missing values (MTSF-M) has become a crucial area of\nresearch for ensuring reliable predictions. To address the challenge of missing\ndata, current approaches have developed an imputation-then-prediction framework\nthat uses imputation modules to fill in missing values, followed by forecasting\non the imputed data. However, this framework overlooks a critical issue: there\nis no ground truth for the missing values, making the imputation process\nsusceptible to errors that can degrade prediction accuracy. In this paper, we\nconduct a systematic empirical study and reveal that imputation without direct\nsupervision can corrupt the underlying data distribution and actively degrade\nprediction accuracy. To address this, we propose a paradigm shift that moves\naway from imputation and directly predicts from the partially observed time\nseries. We introduce Consistency-Regularized Information Bottleneck (CRIB), a\nnovel framework built on the Information Bottleneck principle. CRIB combines a\nunified-variate attention mechanism with a consistency regularization scheme to\nlearn robust representations that filter out noise introduced by missing values\nwhile preserving essential predictive signals. Comprehensive experiments on\nfour real-world datasets demonstrate the effectiveness of CRIB, which predicts\naccurately even under high missing rates. Our code is available in\nhttps://github.com/Muyiiiii/CRIB."}
{"id": "2509.23500", "pdf": "https://arxiv.org/pdf/2509.23500", "abs": "https://arxiv.org/abs/2509.23500", "authors": ["Georgios Vlassis", "Saleh Ashkboos", "Alexandra Volkova", "Torsten Hoefler", "Dan Alistarh"], "title": "Beyond Outliers: A Study of Optimizers Under Quantization", "categories": ["cs.LG"], "comment": "20 pages", "summary": "As new optimizers gain traction and model quantization becomes standard for\nefficient deployment, a key question arises: how does the choice of optimizer\naffect model performance in the presence of quantization? Despite progress in\nboth areas, systematic evidence on optimizer-quantization interactions remains\nlimited. To fill this gap, we study the impact of optimizer choice on model\nrobustness under quantization, considering both post-training quantization\n(PTQ), and quantization-aware training (QAT). We first train full-precision\nmodels, ranging from 50M to 1.5B parameters, with six optimizers, to explore\nthe hyperparameter landscape, and establish well-tuned baselines. We then apply\nPTQ to evaluate how model performance degrades when trained with different\noptimizers. We find that outlier-related metrics, such as the max-to-mean ratio\n(MMR) and Kurtosis, fail to predict the PTQ performance across different\noptimizers. We show analytically that this is due to the MMR capturing only\nisolated layer errors, while ignoring how quantization errors accumulate and\npropagate through the network. To study the QAT degradation, we train quantized\nmodels from scratch and compare them to our original-precision baselines. We\nfind that optimizers performing well in the original pretraining setup may not\nremain optimal under QAT, and that models trained with Shampoo show the lowest\naccuracy degradation. Finally, we derive scaling laws for quantization-aware\ntraining under different optimizers, showing that Shampoo achieves the highest\nparameter efficiency of all tested optimizers."}
{"id": "2509.23548", "pdf": "https://arxiv.org/pdf/2509.23548", "abs": "https://arxiv.org/abs/2509.23548", "authors": ["Yijie Zhang", "Yiyang Shen", "Weiran Wang"], "title": "Disentanglement of Variations with Multimodal Generative Modeling", "categories": ["cs.LG", "cs.AI"], "comment": "22 pages, 14 figures, 7 tables", "summary": "Multimodal data are prevalent across various domains, and learning robust\nrepresentations of such data is paramount to enhancing generation quality and\ndownstream task performance. To handle heterogeneity and interconnections among\ndifferent modalities, recent multimodal generative models extract shared and\nprivate (modality-specific) information with two separate variables. Despite\nattempts to enforce disentanglement between these two variables, these methods\nstruggle with challenging datasets where the likelihood model is insufficient.\nIn this paper, we propose Information-disentangled Multimodal VAE (IDMVAE) to\nexplicitly address this issue, with rigorous mutual information-based\nregularizations, including cross-view mutual information maximization for\nextracting shared variables, and a cycle-consistency style loss for redundancy\nremoval using generative augmentations. We further introduce diffusion models\nto improve the capacity of latent priors. These newly proposed components are\ncomplementary to each other. Compared to existing approaches, IDMVAE shows a\nclean separation between shared and private information, demonstrating superior\ngeneration quality and semantic coherence on challenging datasets."}
{"id": "2509.23552", "pdf": "https://arxiv.org/pdf/2509.23552", "abs": "https://arxiv.org/abs/2509.23552", "authors": ["Md. Saiful Bari Siddiqui", "Nowshin Tarannum"], "title": "Fusing Sequence Motifs and Pan-Genomic Features: Antimicrobial Resistance Prediction using an Explainable Lightweight 1D CNN-XGBoost Ensemble", "categories": ["cs.LG", "cs.AI", "q-bio.GN", "q-bio.QM"], "comment": "Submitted to SCA/HPCAsia 2026. This preprint version has been\n  prepared for open-access distribution and may differ in formatting from the\n  official proceedings. Also available on bioRxiv for visibility to the life\n  sciences community", "summary": "Antimicrobial Resistance (AMR) is a rapidly escalating global health crisis.\nWhile genomic sequencing enables rapid prediction of resistance phenotypes,\ncurrent computational methods have limitations. Standard machine learning\nmodels treat the genome as an unordered collection of features, ignoring the\nsequential context of Single Nucleotide Polymorphisms (SNPs). State-of-the-art\nsequence models like Transformers are often too data-hungry and computationally\nexpensive for the moderately-sized datasets that are typical in this domain. To\naddress these challenges, we propose AMR-EnsembleNet, an ensemble framework\nthat synergistically combines sequence-based and feature-based learning. We\ndeveloped a lightweight, custom 1D Convolutional Neural Network (CNN) to\nefficiently learn predictive sequence motifs from high-dimensional SNP data.\nThis sequence-aware model was ensembled with an XGBoost model, a powerful\ngradient boosting system adept at capturing complex, non-local feature\ninteractions. We trained and evaluated our framework on a benchmark dataset of\n809 E. coli strains, predicting resistance across four antibiotics with varying\nclass imbalance. Our 1D CNN-XGBoost ensemble consistently achieved top-tier\nperformance across all the antibiotics, reaching a Matthews Correlation\nCoefficient (MCC) of 0.926 for Ciprofloxacin (CIP) and the highest Macro\nF1-score of 0.691 for the challenging Gentamicin (GEN) AMR prediction. We also\nshow that our model consistently focuses on SNPs within well-known AMR genes\nlike fusA and parC, confirming it learns the correct genetic signals for\nresistance. Our work demonstrates that fusing a sequence-aware 1D CNN with a\nfeature-based XGBoost model creates a powerful ensemble, overcoming the\nlimitations of using either an order-agnostic or a standalone sequence model."}
{"id": "2509.23570", "pdf": "https://arxiv.org/pdf/2509.23570", "abs": "https://arxiv.org/abs/2509.23570", "authors": ["Ruiqi Lyu", "Alistair Turcan", "Martin Jinye Zhang", "Bryan Wilder"], "title": "Improving constraint-based discovery with robust propagation and reliable LLM priors", "categories": ["cs.LG"], "comment": null, "summary": "Learning causal structure from observational data is central to scientific\nmodeling and decision-making. Constraint-based methods aim to recover\nconditional independence (CI) relations in a causal directed acyclic graph\n(DAG). Classical approaches such as PC and subsequent methods orient\nv-structures first and then propagate edge directions from these seeds,\nassuming perfect CI tests and exhaustive search of separating subsets --\nassumptions often violated in practice, leading to cascading errors in the\nfinal graph. Recent work has explored using large language models (LLMs) as\nexperts, prompting sets of nodes for edge directions, and could augment edge\norientation when assumptions are not met. However, such methods implicitly\nassume perfect experts, which is unrealistic for hallucination-prone LLMs. We\npropose MosaCD, a causal discovery method that propagates edges from a\nhigh-confidence set of seeds derived from both CI tests and LLM annotations. To\nfilter hallucinations, we introduce shuffled queries that exploit LLMs'\npositional bias, retaining only high-confidence seeds. We then apply a novel\nconfidence-down propagation strategy that orients the most reliable edges\nfirst, and can be integrated with any skeleton-based discovery method. Across\nmultiple real-world graphs, MosaCD achieves higher accuracy in final graph\nconstruction than existing constraint-based methods, largely due to the\nimproved reliability of initial seeds and robust propagation strategies."}
{"id": "2509.23585", "pdf": "https://arxiv.org/pdf/2509.23585", "abs": "https://arxiv.org/abs/2509.23585", "authors": ["Emerald Zhang", "Julian Weaver", "Edward Castillo"], "title": "EVO-LRP: Evolutionary Optimization of LRP for Interpretable Model Explanations", "categories": ["cs.LG"], "comment": "15 pages", "summary": "Explainable AI (XAI) methods help identify which image regions influence a\nmodel's prediction, but often face a trade-off between detail and\ninterpretability. Layer-wise Relevance Propagation (LRP) offers a model-aware\nalternative. However, LRP implementations commonly rely on heuristic rule sets\nthat are not optimized for clarity or alignment with model behavior. We\nintroduce EVO-LRP, a method that applies Covariance Matrix Adaptation Evolution\nStrategy (CMA-ES) to tune LRP hyperparameters based on quantitative\ninterpretability metrics, such as faithfulness or sparseness. EVO-LRP\noutperforms traditional XAI approaches in both interpretability metric\nperformance and visual coherence, with strong sensitivity to class-specific\nfeatures. These findings demonstrate that attribution quality can be\nsystematically improved through principled, task-specific optimization."}
{"id": "2509.23587", "pdf": "https://arxiv.org/pdf/2509.23587", "abs": "https://arxiv.org/abs/2509.23587", "authors": ["Andres Fernandez", "Felix Dangel", "Philipp Hennig", "Frank Schneider"], "title": "Sketching Low-Rank Plus Diagonal Matrices", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "Many relevant machine learning and scientific computing tasks involve\nhigh-dimensional linear operators accessible only via costly matrix-vector\nproducts. In this context, recent advances in sketched methods have enabled the\nconstruction of *either* low-rank *or* diagonal approximations from few\nmatrix-vector products. This provides great speedup and scalability, but\napproximation errors arise due to the assumed simpler structure. This work\nintroduces SKETCHLORD, a method that simultaneously estimates both low-rank\n*and* diagonal components, targeting the broader class of Low-Rank *plus*\nDiagonal (LoRD) linear operators. We demonstrate theoretically and empirically\nthat this joint estimation is superior also to any sequential variant\n(diagonal-then-low-rank or low-rank-then-diagonal). Then, we cast SKETCHLORD as\na convex optimization problem, leading to a scalable algorithm. Comprehensive\nexperiments on synthetic (approximate) LoRD matrices confirm SKETCHLORD's\nperformance in accurately recovering these structures. This positions it as a\nvaluable addition to the structured approximation toolkit, particularly when\nhigh-fidelity approximations are desired for large-scale operators, such as the\ndeep learning Hessian."}
{"id": "2509.23592", "pdf": "https://arxiv.org/pdf/2509.23592", "abs": "https://arxiv.org/abs/2509.23592", "authors": ["Hoang Phan", "Sungmin Cha", "Tung Lam Tran", "Qi Lei"], "title": "Toward a Holistic Approach to Continual Model Merging", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to Workshop on Continual Learning in Computer Vision, ICCV\n  2025", "summary": "We present a holistic framework for continual model merging that intervenes\nat three critical stages: pre-merging, during merging, and post-merging-to\naddress two fundamental challenges in continual learning. In particular,\nconventional approaches either maintain a growing list of per-domain task\nvectors, leading to scalability issues or rely solely on weight-space merging\nwhen old data is inaccessible, thereby losing crucial functional information.\nOur method overcomes these limitations by first fine-tuning the main model\nwithin its tangent space on domain-specific data; this linearization amplifies\nper-task weight disentanglement, effectively mitigating across-task\ninterference. During merging, we leverage functional information from available\noptimizer states beyond mere parameter averages to avoid the need to revisit\nold data. Finally, a post-merging correction aligns the representation\ndiscrepancy between pre- and post-merged models, reducing bias and enhancing\noverall performance-all while operating under constant memory constraints\nwithout accessing historical data. Extensive experiments on standard\nclass-incremental and domain-incremental benchmarks demonstrate that our\napproach not only achieves competitive performance but also provides a scalable\nand efficient solution to the catastrophic forgetting problem."}
{"id": "2509.23593", "pdf": "https://arxiv.org/pdf/2509.23593", "abs": "https://arxiv.org/abs/2509.23593", "authors": ["Zekun Wang", "Anant Gupta", "Zihan Dong", "Christopher J. MacLellan"], "title": "Avoid Catastrophic Forgetting with Rank-1 Fisher from Diffusion Models", "categories": ["cs.LG"], "comment": "18 pages, 14 figures", "summary": "Catastrophic forgetting remains a central obstacle for continual learning in\nneural models. Popular approaches -- replay and elastic weight consolidation\n(EWC) -- have limitations: replay requires a strong generator and is prone to\ndistributional drift, while EWC implicitly assumes a shared optimum across\ntasks and typically uses a diagonal Fisher approximation. In this work, we\nstudy the gradient geometry of diffusion models, which can already produce\nhigh-quality replay data. We provide theoretical and empirical evidence that,\nin the low signal-to-noise ratio (SNR) regime, per-sample gradients become\nstrongly collinear, yielding an empirical Fisher that is effectively rank-1 and\naligned with the mean gradient. Leveraging this structure, we propose a rank-1\nvariant of EWC that is as cheap as the diagonal approximation yet captures the\ndominant curvature direction. We pair this penalty with a replay-based approach\nto encourage parameter sharing across tasks while mitigating drift. On\nclass-incremental image generation datasets (MNIST, FashionMNIST, CIFAR-10,\nImageNet-1k), our method consistently improves average FID and reduces\nforgetting relative to replay-only and diagonal-EWC baselines. In particular,\nforgetting is nearly eliminated on MNIST and FashionMNIST and is roughly halved\non ImageNet-1k. These results suggest that diffusion models admit an\napproximately rank-1 Fisher. With a better Fisher estimate, EWC becomes a\nstrong complement to replay: replay encourages parameter sharing across tasks,\nwhile EWC effectively constrains replay-induced drift."}
{"id": "2509.23597", "pdf": "https://arxiv.org/pdf/2509.23597", "abs": "https://arxiv.org/abs/2509.23597", "authors": ["Zheng Wang", "Kaixuan Zhang", "Wanfang Chen", "Xiaonan Lu", "Longyuan Li", "Tobias Schlagenhauf"], "title": "Characteristic Root Analysis and Regularization for Linear Time Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Time series forecasting remains a critical challenge across numerous domains,\nyet the effectiveness of complex models often varies unpredictably across\ndatasets. Recent studies highlight the surprising competitiveness of simple\nlinear models, suggesting that their robustness and interpretability warrant\ndeeper theoretical investigation. This paper presents a systematic study of\nlinear models for time series forecasting, with a focus on the role of\ncharacteristic roots in temporal dynamics. We begin by analyzing the noise-free\nsetting, where we show that characteristic roots govern long-term behavior and\nexplain how design choices such as instance normalization and channel\nindependence affect model capabilities. We then extend our analysis to the\nnoisy regime, revealing that models tend to produce spurious roots. This leads\nto the identification of a key data-scaling property: mitigating the influence\nof noise requires disproportionately large training data, highlighting the need\nfor structural regularization. To address these challenges, we propose two\ncomplementary strategies for robust root restructuring. The first uses rank\nreduction techniques, including Reduced-Rank Regression and Direct Weight Rank\nReduction, to recover the low-dimensional latent dynamics. The second, a novel\nadaptive method called Root Purge, encourages the model to learn a\nnoise-suppressing null space during training. Extensive experiments on standard\nbenchmarks demonstrate the effectiveness of both approaches, validating our\ntheoretical insights and achieving state-of-the-art results in several\nsettings. Our findings underscore the potential of integrating classical\ntheories for linear systems with modern learning techniques to build robust,\ninterpretable, and data-efficient forecasting models."}
{"id": "2509.23616", "pdf": "https://arxiv.org/pdf/2509.23616", "abs": "https://arxiv.org/abs/2509.23616", "authors": ["Fanlong Zeng", "Wensheng Gan", "Philip S. Yu"], "title": "GraphIFE: Rethinking Graph Imbalance Node Classification via Invariant Learning", "categories": ["cs.LG", "cs.AI"], "comment": "PrePrint, 16 pages, 7 tables, 6 figures", "summary": "The class imbalance problem refers to the disproportionate distribution of\nsamples across different classes within a dataset, where the minority classes\nare significantly underrepresented. This issue is also prevalent in\ngraph-structured data. Most graph neural networks (GNNs) implicitly assume a\nbalanced class distribution and therefore often fail to account for the\nchallenges introduced by class imbalance, which can lead to biased learning and\ndegraded performance on minority classes. We identify a quality inconsistency\nproblem in synthesized nodes, which leads to suboptimal performance under graph\nimbalance conditions. To mitigate this issue, we propose GraphIFE (Graph\nInvariant Feature Extraction), a novel framework designed to mitigate quality\ninconsistency in synthesized nodes. Our approach incorporates two key concepts\nfrom graph invariant learning and introduces strategies to strengthen the\nembedding space representation, thereby enhancing the model's ability to\nidentify invariant features. Extensive experiments demonstrate the framework's\nefficiency and robust generalization, as GraphIFE consistently outperforms\nvarious baselines across multiple datasets. The code is publicly available at\nhttps://github.com/flzeng1/GraphIFE."}
{"id": "2509.23631", "pdf": "https://arxiv.org/pdf/2509.23631", "abs": "https://arxiv.org/abs/2509.23631", "authors": ["Chen Yang", "Changhao Zhao", "Chen Wang", "Jiansheng Fan"], "title": "DRIK: Distribution-Robust Inductive Kriging without Information Leakage", "categories": ["cs.LG"], "comment": null, "summary": "Inductive kriging supports high-resolution spatio-temporal estimation with\nsparse sensor networks, but conventional training-evaluation setups often\nsuffer from information leakage and poor out-of-distribution (OOD)\ngeneralization. We find that the common 2x2 spatio-temporal split allows test\ndata to influence model selection through early stopping, obscuring the true\nOOD characteristics of inductive kriging. To address this issue, we propose a\n3x3 partition that cleanly separates training, validation, and test sets,\neliminating leakage and better reflecting real-world applications. Building on\nthis redefined setting, we introduce DRIK, a Distribution-Robust Inductive\nKriging approach designed with the intrinsic properties of inductive kriging in\nmind to explicitly enhance OOD generalization, employing a three-tier strategy\nat the node, edge, and subgraph levels. DRIK perturbs node coordinates to\ncapture continuous spatial relationships, drops edges to reduce ambiguity in\ninformation flow and increase topological diversity, and adds pseudo-labeled\nsubgraphs to strengthen domain generalization. Experiments on six diverse\nspatio-temporal datasets show that DRIK consistently outperforms existing\nmethods, achieving up to 12.48% lower MAE while maintaining strong scalability."}
{"id": "2509.23638", "pdf": "https://arxiv.org/pdf/2509.23638", "abs": "https://arxiv.org/abs/2509.23638", "authors": ["Enda Yu", "Zhaoning Zhang", "Dezun Dong", "Yongwei Wu", "Xiangke Liao"], "title": "PreScope: Unleashing the Power of Prefetching for Resource-Constrained MoE Inference", "categories": ["cs.LG"], "comment": null, "summary": "Mixture-of-Experts (MoE) models face memory and PCIe latency bottlenecks when\ndeployed on commodity hardware. Offloading expert weights to CPU memory results\nin PCIe transfer latency that exceeds GPU computation by several folds. We\npresent PreScope, a prediction-driven expert scheduling system that addresses\nthree key challenges: inaccurate activation prediction, PCIe bandwidth\ncompetition, and cross-device scheduling complexity. Our solution includes: 1)\nLearnable Layer-Aware Predictor (LLaPor) that captures layer-specific expert\nactivation patterns; 2) Prefetch-Aware Cross-Layer Scheduling (PreSched) that\ngenerates globally optimal plans balancing prefetching costs and loading\noverhead; 3) Asynchronous I/O Optimizer (AsyncIO) that decouples I/O from\ncomputation, eliminating waiting bubbles. PreScope achieves 141% higher\nthroughput and 74.6% lower latency than state-of-the-art solutions."}
{"id": "2509.23660", "pdf": "https://arxiv.org/pdf/2509.23660", "abs": "https://arxiv.org/abs/2509.23660", "authors": ["Ranhui Yan", "Jia cai"], "title": "Virtual Nodes based Heterogeneous Graph Convolutional Neural Network for Efficient Long-Range Information Aggregation", "categories": ["cs.LG", "I.2.0"], "comment": null, "summary": "Heterogeneous Graph Neural Networks (HGNNs) have exhibited powerful\nperformance in heterogeneous graph learning by aggregating information from\nvarious types of nodes and edges. However, existing heterogeneous graph models\noften struggle to capture long-range information or necessitate stacking\nnumerous layers to learn such dependencies, resulting in high computational\ncomplexity and encountering over-smoothing issues. In this paper, we propose a\nVirtual Nodes based Heterogeneous Graph Convolutional Network (VN-HGCN), which\nleverages virtual nodes to facilitate enhanced information flow within the\ngraph. Virtual nodes are auxiliary nodes interconnected with all nodes of a\nspecific type in the graph, facilitating efficient aggregation of long-range\ninformation across different types of nodes and edges. By incorporating virtual\nnodes into the graph structure, VN-HGCN achieves effective information\naggregation with only $4$ layers. Additionally, we demonstrate that VN-HGCN can\nserve as a versatile framework that can be seamlessly applied to other HGNN\nmodels, showcasing its generalizability. Empirical evaluations validate the\neffectiveness of VN-HGCN, and extensive experiments conducted on three\nreal-world heterogeneous graph datasets demonstrate the superiority of our\nmodel over several state-of-the-art baselines."}
{"id": "2509.23662", "pdf": "https://arxiv.org/pdf/2509.23662", "abs": "https://arxiv.org/abs/2509.23662", "authors": ["Fanlong Zeng", "Wensheng Gan", "Jiayang Wu", "Philip S. Yu"], "title": "Pure Node Selection for Imbalanced Graph Node Classification", "categories": ["cs.LG", "cs.AI"], "comment": "Preprint, 8 tables, 9 figures", "summary": "The problem of class imbalance refers to an uneven distribution of quantity\namong classes in a dataset, where some classes are significantly\nunderrepresented compared to others. Class imbalance is also prevalent in\ngraph-structured data. Graph neural networks (GNNs) are typically based on the\nassumption of class balance, often overlooking the issue of class imbalance. In\nour investigation, we identified a problem, which we term the Randomness\nAnomalous Connectivity Problem (RACP), where certain off-the-shelf models are\naffected by random seeds, leading to a significant performance degradation. To\neliminate the influence of random factors in algorithms, we proposed PNS (Pure\nNode Sampling) to address the RACP in the node synthesis stage. Unlike existing\napproaches that design specialized algorithms to handle either quantity\nimbalance or topological imbalance, PNS is a novel plug-and-play module that\noperates directly during node synthesis to mitigate RACP. Moreover, PNS also\nalleviates performance degradation caused by abnormal distribution of node\nneighbors. We conduct a series of experiments to identify what factors are\ninfluenced by random seeds. Experimental results demonstrate the effectiveness\nand stability of our method, which not only eliminates the effect of\nunfavorable random seeds but also outperforms the baseline across various\nbenchmark datasets with different GNN backbones. Data and code are available at\nhttps://github.com/flzeng1/PNS."}
{"id": "2509.23665", "pdf": "https://arxiv.org/pdf/2509.23665", "abs": "https://arxiv.org/abs/2509.23665", "authors": ["Kristina P. Sinaga", "Arjun S. Nair"], "title": "Calibration Meets Reality: Making Machine Learning Predictions Trustworthy", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT", "math.PR"], "comment": "30 pages, 7 figures, 5 tables", "summary": "Post-hoc calibration methods are widely used to improve the reliability of\nprobabilistic predictions from machine learning models. Despite their\nprevalence, a comprehensive theoretical understanding of these methods remains\nelusive, particularly regarding their performance across different datasets and\nmodel architectures. Input features play a crucial role in shaping model\npredictions and, consequently, their calibration. However, the interplay\nbetween feature quality and calibration performance has not been thoroughly\ninvestigated. In this work, we present a rigorous theoretical analysis of\npost-hoc calibration methods, focusing on Platt scaling and isotonic\nregression. We derive convergence guarantees, computational complexity bounds,\nand finite-sample performance metrics for these methods. Furthermore, we\nexplore the impact of feature informativeness on calibration performance\nthrough controlled synthetic experiments. Our empirical evaluation spans a\ndiverse set of real-world datasets and model architectures, demonstrating\nconsistent improvements in calibration metrics across various scenarios. By\nexamining calibration performance under varying feature conditions utilizing\nonly informative features versus complete feature spaces including noise\ndimensions, we provide fundamental insights into the robustness and reliability\nof different calibration approaches. Our findings offer practical guidelines\nfor selecting appropriate calibration methods based on dataset characteristics\nand computational constraints, bridging the gap between theoretical\nunderstanding and practical implementation in uncertainty quantification. Code\nand experimental data are available at:\nhttps://github.com/Ajwebdevs/calibration-analysis-experiments."}
{"id": "2509.23666", "pdf": "https://arxiv.org/pdf/2509.23666", "abs": "https://arxiv.org/abs/2509.23666", "authors": ["Divya Jyoti Bajpai", "Manjesh Kumar Hanawal"], "title": "Beyond Greedy Exits: Improved Early Exit Decisions for Risk Control and Reliability", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted as poster in NeurIPS 2025", "summary": "Early-Exit Deep Neural Networks enable adaptive inference by allowing\nprediction at intermediary layers, significantly reducing computational costs\nand latency. Most of the early exit strategies greedily exit a sample at an\nintermediary layer if the confidence in class prediction exceeds a predefined\nthreshold that is set using a static validation set. This is problematic as the\nmodel might be overconfident in a wrong class. Also, they are not robust to\ndistribution shifts encountered in deployment, which can undermine model\ntrustworthiness and accuracy. To address these challenges, we propose UAT that\nadapts the threshold for exit decisions using a Multi-Armed Bandit framework,\nenabling online, unsupervised adjustment of exit decisions. UAT makes decisions\nbased on a new reward function that assesses predictive certainty and its\nreliability to balance computational efficiency and prediction quality while\npenalizing unnecessary late exits. We provide guarantees on risk achieved by\nUAT and validate its performance on diverse tasks spanning vision-language\nunderstanding, text generation, and classification. Our framework demonstrates\nconsistent improvements in speedup (1.70-2.10x) with a minimal performance drop\n(<2%) as compared to full model performance. Our source code is available at\nhttps://github.com/Div290/UAT."}
{"id": "2509.23667", "pdf": "https://arxiv.org/pdf/2509.23667", "abs": "https://arxiv.org/abs/2509.23667", "authors": ["Sungmin Cha", "Kyunghyun Cho"], "title": "Why Alignment Must Precede Distillation: A Minimal Working Explanation", "categories": ["cs.LG"], "comment": "Preprint", "summary": "For efficiency, preference alignment is often performed on compact,\nknowledge-distilled (KD) models. We argue this common practice introduces a\nsignificant limitation by overlooking a key property of the alignment's\nreference model: its distributional recall. We show that the standard KD ->\nAlign workflow diminishes the model's capacity to align rare yet desirable\nbehaviors, even under strong preference signals. We instead demonstrate that\nreversing the pipeline (i.e., Align -> KD) is essential: alignment must first\nbe performed on a high-recall reference before distillation. Our contributions\nare threefold. First, we provide a minimal working explanation of how the\nreference model constrains preference alignment objectives at a fundamental\nlevel. Second, we validate this theory in a controllable Mixture-of-Gaussians\nexperiment, where low-recall anchoring consistently results in suboptimal model\nperformance. Finally, we demonstrate that the same phenomenon holds in LLM\nalignment with the SmolLM2 family: models aligned after KD fail to effectively\nalign target behaviors, resulting in substantially lower reward and target\nprecision. In contrast, our proposed Align -> KD pipeline robustly aligns these\nbehaviors, yielding models with superior target-oriented metrics and lower\nvariance. Together, these results establish reference-model recall as a\nfirst-order design choice in alignment, offering a clear principle: alignment\nmust precede distillation."}
{"id": "2509.23668", "pdf": "https://arxiv.org/pdf/2509.23668", "abs": "https://arxiv.org/abs/2509.23668", "authors": ["Xiangfei Qiu", "Liu Yang", "Hanyin Cheng", "Xingjian Wu", "Rongjia Wu", "Zhigang Zhang", "Ding Tu", "Chenjuan Guo", "Bin Yang", "Christian S. Jensen", "Jilin Hu"], "title": "Multi-Scale Spatial-Temporal Hypergraph Network with Lead-Lag Structures for Stock Time Series Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "Time series forecasting occurs in a range of financial applications providing\nessential decision-making support to investors, regulatory institutions, and\nanalysts. Unlike multivariate time series from other domains, stock time series\nexhibit industry correlation. Exploiting this kind of correlation can improve\nforecasting accuracy. However, existing methods based on hypergraphs can only\ncapture industry correlation relatively superficially. These methods face two\nkey limitations: they do not fully consider inter-industry lead-lag\ninteractions, and they do not model multi-scale information within and among\nindustries. This study proposes the Hermes framework for stock time series\nforecasting that aims to improve the exploitation of industry correlation by\neliminating these limitations. The framework integrates moving aggregation and\nmulti-scale fusion modules in a hypergraph network. Specifically, to more\nflexibly capture the lead-lag relationships among industries, Hermes proposes a\nhyperedge-based moving aggregation module. This module incorporates a sliding\nwindow and utilizes dynamic temporal aggregation operations to consider\nlead-lag dependencies among industries. Additionally, to effectively model\nmulti-scale information, Hermes employs cross-scale, edge-to-edge message\npassing to integrate information from different scales while maintaining the\nconsistency of each scale. Experimental results on multiple real-world stock\ndatasets show that Hermes outperforms existing state-of-the-art methods in both\nefficiency and accuracy."}
{"id": "2509.23671", "pdf": "https://arxiv.org/pdf/2509.23671", "abs": "https://arxiv.org/abs/2509.23671", "authors": ["Jingqi Xu", "Guibin Chen", "Jingxi Lu", "Yuzhang Lin"], "title": "Graph Neural Networks with Diversity-aware Neighbor Selection and Dynamic Multi-scale Fusion for Multivariate Time Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recently, numerous deep models have been proposed to enhance the performance\nof multivariate time series (MTS) forecasting. Among them, Graph Neural\nNetworks (GNNs)-based methods have shown great potential due to their\ncapability to explicitly model inter-variable dependencies. However, these\nmethods often overlook the diversity of information among neighbors, which may\nlead to redundant information aggregation. In addition, their final prediction\ntypically relies solely on the representation from a single temporal scale. To\ntackle these issues, we propose a Graph Neural Networks (GNNs) with\nDiversity-aware Neighbor Selection and Dynamic Multi-scale Fusion (DIMIGNN).\nDIMIGNN introduces a Diversity-aware Neighbor Selection Mechanism (DNSM) to\nensure that each variable shares high informational similarity with its\nneighbors while maintaining diversity among neighbors themselves. Furthermore,\na Dynamic Multi-Scale Fusion Module (DMFM) is introduced to dynamically adjust\nthe contributions of prediction results from different temporal scales to the\nfinal forecasting result. Extensive experiments on real-world datasets\ndemonstrate that DIMIGNN consistently outperforms prior methods."}
{"id": "2509.23678", "pdf": "https://arxiv.org/pdf/2509.23678", "abs": "https://arxiv.org/abs/2509.23678", "authors": ["Guoliang Zhao", "Yuhan Fu", "Shuaipeng Li", "Xingwu Sun", "Ruobing Xie", "An Wang", "Weidong Han", "Zhen Yang", "Weixuan Sun", "Yudong Zhang", "Cheng-zhong Xu", "Di Wang", "Jie Jiang"], "title": "Towards a Comprehensive Scaling Law of Mixture-of-Experts", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Mixture-of-Experts (MoE) models have become the consensus approach for\nenabling parameter-efficient scaling and cost-effective deployment in large\nlanguage models. However, existing scaling laws for dense models are\ninapplicable to MoE models, which stems from three critical challenges: the\nmultiplicity of influencing factors, their intricate coupling relationships and\nthe non-monotonic nature of their performance impacts. They collectively\nnecessitate a fine-grained investigation into MoE-specific scaling laws. In\nthis work, we perform a systematic decomposition of MoE settings, identifying\nfive key factors that influence model performance from both size and structural\nperspectives (data size ($D$), total model size ($N$), activated model size\n($N_a$), number of active experts ($G$) and the ratio of shared experts ($S$)).\nSpecifically, we design $446$ controlled experiments to characterize their\nmarginal effects, ultimately constructing a comprehensive and precise joint MoE\nscaling law that considers all essential factors. Furthermore, we derive the\ntheoretically optimal and practically efficiency-aware optimal configurations\nfor $G$, $S$ and $N_a/N$ with detailed analyses. Our results demonstrate that\nthe optimal settings for $G$ and $S$ are independent of both the model\narchitecture and data size. With the scaling of $N$, the optimal activation\nparameter ratio of $N_a/N$ becomes sparser. Our proposed MoE scaling law could\nfunction as an accurate and insightful guidance to facilitate future MoE model\ndesign and training."}
{"id": "2509.23683", "pdf": "https://arxiv.org/pdf/2509.23683", "abs": "https://arxiv.org/abs/2509.23683", "authors": ["Danni Yang", "Zhikang Chen", "Sen Cui", "Mengyue Yang", "Ding Li", "Abudukelimu Wuerkaixi", "Haoxuan Li", "Jinke Ren", "Mingming Gong"], "title": "Decentralized Dynamic Cooperation of Personalized Models for Federated Continual Learning", "categories": ["cs.LG"], "comment": null, "summary": "Federated continual learning (FCL) has garnered increasing attention for its\nability to support distributed computation in environments with evolving data\ndistributions. However, the emergence of new tasks introduces both temporal and\ncross-client shifts, making catastrophic forgetting a critical challenge. Most\nexisting works aggregate knowledge from clients into a global model, which may\nnot enhance client performance since irrelevant knowledge could introduce\ninterference, especially in heterogeneous scenarios. Additionally, directly\napplying decentralized approaches to FCL suffers from ineffective group\nformation caused by task changes. To address these challenges, we propose a\ndecentralized dynamic cooperation framework for FCL, where clients establish\ndynamic cooperative learning coalitions to balance the acquisition of new\nknowledge and the retention of prior learning, thereby obtaining personalized\nmodels. To maximize model performance, each client engages in selective\ncooperation, dynamically allying with others who offer meaningful performance\ngains. This results in non-overlapping, variable coalitions at each stage of\nthe task. Moreover, we use coalitional affinity game to simulate coalition\nrelationships between clients. By assessing both client gradient coherence and\nmodel similarity, we quantify the client benefits derived from cooperation. We\nalso propose a merge-blocking algorithm and a dynamic cooperative evolution\nalgorithm to achieve cooperative and dynamic equilibrium. Comprehensive\nexperiments demonstrate the superiority of our method compared to various\nbaselines. Code is available at: https://github.com/ydn3229/DCFCL."}
{"id": "2509.23684", "pdf": "https://arxiv.org/pdf/2509.23684", "abs": "https://arxiv.org/abs/2509.23684", "authors": ["Tanya Chowdhury", "Atharva Nijasure", "Yair Zick", "James Allan"], "title": "Hedonic Neurons: A Mechanistic Mapping of Latent Coalitions in Transformer MLPs", "categories": ["cs.LG"], "comment": "Preprint", "summary": "Fine-tuned Large Language Models (LLMs) encode rich task-specific features,\nbut the form of these representations, especially within MLP layers, remains\nunclear. Empirical inspection of LoRA updates shows that new features\nconcentrate in mid-layer MLPs, yet the scale of these layers obscures\nmeaningful structure. Prior probing suggests that statistical priors may\nstrengthen, split, or vanish across depth, motivating the need to study how\nneurons work together rather than in isolation.\n  We introduce a mechanistic interpretability framework based on coalitional\ngame theory, where neurons mimic agents in a hedonic game whose preferences\ncapture their synergistic contributions to layer-local computations. Using\ntop-responsive utilities and the PAC-Top-Cover algorithm, we extract stable\ncoalitions of neurons: groups whose joint ablation has non-additive effects. We\nthen track their transitions across layers as persistence, splitting, merging,\nor disappearance.\n  Applied to LLaMA, Mistral, and Pythia rerankers fine-tuned on scalar IR\ntasks, our method finds coalitions with consistently higher synergy than\nclustering baselines. By revealing how neurons cooperate to encode features,\nhedonic coalitions uncover higher-order structure beyond disentanglement and\nyield computational units that are functionally important, interpretable, and\npredictive across domains."}
{"id": "2509.23688", "pdf": "https://arxiv.org/pdf/2509.23688", "abs": "https://arxiv.org/abs/2509.23688", "authors": ["Soroosh Safari Loaliyan", "Jose-Luis Ambite", "Paul M. Thompson", "Neda Jahanshad", "Greg Ver Steeg"], "title": "FedDAPL: Toward Client-Private Generalization in Federated Learning", "categories": ["cs.LG"], "comment": "4 Pages", "summary": "Federated Learning (FL) trains models locally at each research center or\nclinic and aggregates only model updates, making it a natural fit for medical\nimaging, where strict privacy laws forbid raw data sharing. A major obstacle is\nscanner-induced domain shift: non-biological variations in hardware or\nacquisition protocols can cause models to fail on external sites. Most\nharmonization methods correct this shift by directly comparing data across\nsites, conflicting with FL's privacy constraints. Domain Generalization (DG)\noffers a privacy-friendly alternative - learning site-invariant representations\nwithout sharing raw data - but standard DG pipelines still assume centralized\naccess to multi-site data, again violating FL's guarantees. This paper meets\nthese difficulties with a straightforward integration of a Domain-Adversarial\nNeural Network (DANN) within the FL process. After demonstrating that a naive\nfederated DANN fails to converge, we propose a proximal regularization method\nthat stabilizes adversarial training among clients. Experiments on T1-weighted\n3-D brain MRIs from the OpenBHB dataset, performing brain-age prediction on\nparticipants aged 6-64 y (mean 22+/-6 y; 45 percent male) in training and 6-79\ny (mean 19+/-13 y; 55 percent male) in validation, show that training on 15\nsites and testing on 19 unseen sites yields superior cross-site generalization\nover FedAvg and ERM while preserving data privacy."}
{"id": "2509.23689", "pdf": "https://arxiv.org/pdf/2509.23689", "abs": "https://arxiv.org/abs/2509.23689", "authors": ["Ankit Gangwal", "Aaryan Ajay Sharma"], "title": "Merge Now, Regret Later: The Hidden Cost of Model Merging is Adversarial Transferability", "categories": ["cs.LG"], "comment": null, "summary": "Model Merging (MM) has emerged as a promising alternative to multi-task\nlearning, where multiple fine-tuned models are combined, without access to\ntasks' training data, into a single model that maintains performance across\ntasks. Recent works have explored the impact of MM on adversarial attacks,\nparticularly backdoor attacks. However, none of them have sufficiently explored\nits impact on transfer attacks using adversarial examples, i.e., a black-box\nadversarial attack where examples generated for a surrogate model successfully\nmislead a target model.\n  In this work, we study the effect of MM on the transferability of adversarial\nexamples. We perform comprehensive evaluations and statistical analysis\nconsisting of 8 MM methods, 7 datasets, and 6 attack methods, sweeping over 336\ndistinct attack settings. Through it, we first challenge the prevailing notion\nof MM conferring free adversarial robustness, and show MM cannot reliably\ndefend against transfer attacks, with over 95% relative transfer attack success\nrate. Moreover, we reveal 3 key insights for machine-learning practitioners\nregarding MM and transferability for a robust system design: (1) stronger MM\nmethods increase vulnerability to transfer attacks; (2) mitigating\nrepresentation bias increases vulnerability to transfer attacks; and (3) weight\naveraging, despite being the weakest MM method, is the most vulnerable MM\nmethod to transfer attacks. Finally, we analyze the underlying reasons for this\nincreased vulnerability, and provide potential solutions to the problem. Our\nfindings offer critical insights for designing more secure systems employing\nMM."}
{"id": "2509.23695", "pdf": "https://arxiv.org/pdf/2509.23695", "abs": "https://arxiv.org/abs/2509.23695", "authors": ["Qingren Yao", "Ming Jin", "Chengqi Zhang", "Chao-Han Huck Yang", "Jun Qi", "Shirui Pan"], "title": "Estimating Time Series Foundation Model Transferability via In-Context Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Time series foundation models (TSFMs) offer strong zero-shot forecasting via\nlarge-scale pre-training, yet fine-tuning remains critical for boosting\nperformance in domains with limited public data. With the growing number of\nTSFMs, efficiently identifying the best model for downstream fine-tuning\nbecomes increasingly challenging. In this work, we introduce TimeTic, a\ntransferability estimation framework that recasts model selection as an\nin-context-learning problem: given observations on known (source) datasets, it\npredicts how a TSFM will perform after fine-tuning on a downstream (target)\ndataset. TimeTic flexibly organizes the observed model-data relationships as\ncontextual information, allowing it to adapt seamlessly to various test-time\nscenarios. Leveraging the natural tabular structure formed by dataset\nmeta-features, model characteristics, and fine-tuned performance, we employ\ntabular foundation models to serve as in-context learners. We further introduce\na novel model characterization based on entropy evolution across model layers,\ncapturing embedding-space distinctions and enabling TimeTic to generalize\nacross arbitrary model sets. We establish a comprehensive benchmark for\ntransferability estimation including 10 datasets, 10 foundation models, and 3\nforecasting tasks. On this benchmark, TimeTic's estimation demonstrates strong\nalignment with actual fine-tuned performance for previously unseen datasets,\nachieving a mean rank correlation of approximately 0.6 and a 30% improvement\ncompared to using zero-shot performance as the transferability score."}
{"id": "2509.23711", "pdf": "https://arxiv.org/pdf/2509.23711", "abs": "https://arxiv.org/abs/2509.23711", "authors": ["Ziheng Cheng", "Xin Guo", "Yufei Zhang"], "title": "Bridging Discrete and Continuous RL: Stable Deterministic Policy Gradient with Martingale Characterization", "categories": ["cs.LG", "cs.AI", "math.OC", "stat.ML"], "comment": null, "summary": "The theory of discrete-time reinforcement learning (RL) has advanced rapidly\nover the past decades. Although primarily designed for discrete environments,\nmany real-world RL applications are inherently continuous and complex. A major\nchallenge in extending discrete-time algorithms to continuous-time settings is\ntheir sensitivity to time discretization, often leading to poor stability and\nslow convergence. In this paper, we investigate deterministic policy gradient\nmethods for continuous-time RL. We derive a continuous-time policy gradient\nformula based on an analogue of the advantage function and establish its\nmartingale characterization. This theoretical foundation leads to our proposed\nalgorithm, CT-DDPG, which enables stable learning with deterministic policies\nin continuous-time environments. Numerical experiments show that the proposed\nCT-DDPG algorithm offers improved stability and faster convergence compared to\nexisting discrete-time and continuous-time methods, across a wide range of\ncontrol tasks with varying time discretizations and noise levels."}
{"id": "2509.23712", "pdf": "https://arxiv.org/pdf/2509.23712", "abs": "https://arxiv.org/abs/2509.23712", "authors": ["Gholamali Aminian", "Andrew Elliott", "Tiger Li", "Timothy Cheuk Hin Wong", "Victor Claude Dehon", "Lukasz Szpruch", "Carsten Maple", "Christopher Read", "Martin Brown", "Gesine Reinert", "Mo Mamouei"], "title": "FraudTransformer: Time-Aware GPT for Transaction Fraud Detection", "categories": ["cs.LG", "stat.ML"], "comment": "Pre-print", "summary": "Detecting payment fraud in real-world banking streams requires models that\ncan exploit both the order of events and the irregular time gaps between them.\nWe introduce FraudTransformer, a sequence model that augments a vanilla\nGPT-style architecture with (i) a dedicated time encoder that embeds either\nabsolute timestamps or inter-event values, and (ii) a learned positional\nencoder that preserves relative order. Experiments on a large industrial\ndataset -- tens of millions of transactions and auxiliary events -- show that\nFraudTransformer surpasses four strong classical baselines (Logistic\nRegression, XGBoost and LightGBM) as well as transformer ablations that omit\neither the time or positional component. On the held-out test set it delivers\nthe highest AUROC and PRAUC."}
{"id": "2509.23720", "pdf": "https://arxiv.org/pdf/2509.23720", "abs": "https://arxiv.org/abs/2509.23720", "authors": ["Xian Zeng", "Tianze Xu", "Kai Yang", "Jie Sun", "Youran Wang", "Jun Xu", "Mucheng Ren"], "title": "A Self-Adaptive Frequency Domain Network for Continuous Intraoperative Hypotension Prediction", "categories": ["cs.LG"], "comment": "Accepted at ECAI 2025 main conference", "summary": "Intraoperative hypotension (IOH) is strongly associated with postoperative\ncomplications, including postoperative delirium and increased mortality, making\nits early prediction crucial in perioperative care. While several artificial\nintelligence-based models have been developed to provide IOH warnings, existing\nmethods face limitations in incorporating both time and frequency domain\ninformation, capturing short- and long-term dependencies, and handling noise\nsensitivity in biosignal data. To address these challenges, we propose a novel\nSelf-Adaptive Frequency Domain Network (SAFDNet). Specifically, SAFDNet\nintegrates an adaptive spectral block, which leverages Fourier analysis to\nextract frequency-domain features and employs self-adaptive thresholding to\nmitigate noise. Additionally, an interactive attention block is introduced to\ncapture both long-term and short-term dependencies in the data. Extensive\ninternal and external validations on two large-scale real-world datasets\ndemonstrate that SAFDNet achieves up to 97.3\\% AUROC in IOH early warning,\noutperforming state-of-the-art models. Furthermore, SAFDNet exhibits robust\npredictive performance and low sensitivity to noise, making it well-suited for\npractical clinical applications."}
{"id": "2509.23742", "pdf": "https://arxiv.org/pdf/2509.23742", "abs": "https://arxiv.org/abs/2509.23742", "authors": ["Yewang Chen", "Junfeng Li", "Shuyin Xia", "Qinghong Lai", "Xinbo Gao", "Guoyin Wang", "Dongdong Cheng", "Yi Liu", "Yi Wang"], "title": "GBSK: Skeleton Clustering via Granular-ball Computing and Multi-Sampling for Large-Scale Data", "categories": ["cs.LG", "cs.CV", "cs.IR"], "comment": null, "summary": "To effectively handle clustering task for large-scale datasets, we propose a\nnovel scalable skeleton clustering algorithm, namely GBSK, which leverages the\ngranular-ball technique to capture the underlying structure of data. By\nmulti-sampling the dataset and constructing multi-grained granular-balls, GBSK\nprogressively uncovers a statistical \"skeleton\" -- a spatial abstraction that\napproximates the essential structure and distribution of the original data.\nThis strategy enables GBSK to dramatically reduce computational overhead while\nmaintaining high clustering accuracy. In addition, we introduce an adaptive\nversion, AGBSK, with simplified parameter settings to enhance usability and\nfacilitate deployment in real-world scenarios. Extensive experiments conducted\non standard computing hardware demonstrate that GBSK achieves high efficiency\nand strong clustering performance on large-scale datasets, including one with\nup to 100 million instances across 256 dimensions. Our implementation and\nexperimental results are available at: https://github.com/XFastDataLab/GBSK/."}
{"id": "2509.23749", "pdf": "https://arxiv.org/pdf/2509.23749", "abs": "https://arxiv.org/abs/2509.23749", "authors": ["Ting-Kang Wang", "Chih-Pin Tan", "Yi-Hsuan Yang"], "title": "Time-Shifted Token Scheduling for Symbolic Music Generation", "categories": ["cs.LG"], "comment": null, "summary": "Symbolic music generation faces a fundamental trade-off between efficiency\nand quality. Fine-grained tokenizations achieve strong coherence but incur long\nsequences and high complexity, while compact tokenizations improve efficiency\nat the expense of intra-token dependencies. To address this, we adapt a\ndelay-based scheduling mechanism (DP) that expands compound-like tokens across\ndecoding steps, enabling autoregressive modeling of intra-token dependencies\nwhile preserving efficiency. Notably, DP is a lightweight strategy that\nintroduces no additional parameters and can be seamlessly integrated into\nexisting representations. Experiments on symbolic orchestral MIDI datasets show\nthat our method improves all metrics over standard compound tokenizations and\nnarrows the gap to fine-grained tokenizations."}
{"id": "2509.23750", "pdf": "https://arxiv.org/pdf/2509.23750", "abs": "https://arxiv.org/abs/2509.23750", "authors": ["Li Wang", "Sudun", "Xingjian Zhang", "Wenjun Wu", "Lei Huang"], "title": "An Investigation of Batch Normalization in Off-Policy Actor-Critic Algorithms", "categories": ["cs.LG"], "comment": null, "summary": "Batch Normalization (BN) has played a pivotal role in the success of deep\nlearning by improving training stability, mitigating overfitting, and enabling\nmore effective optimization. However, its adoption in deep reinforcement\nlearning (DRL) has been limited due to the inherent non-i.i.d. nature of data\nand the dynamically shifting distributions induced by the agent's learning\nprocess. In this paper, we argue that, despite these challenges, BN retains\nunique advantages in DRL settings, particularly through its stochasticity and\nits ability to ease training. When applied appropriately, BN can adapt to\nevolving data distributions and enhance both convergence speed and final\nperformance. To this end, we conduct a comprehensive empirical study on the use\nof BN in off-policy actor-critic algorithms, systematically analyzing how\ndifferent training and evaluation modes impact performance. We further identify\nfailure modes that lead to instability or divergence, analyze their underlying\ncauses, and propose the Mode-Aware Batch Normalization (MA-BN) method with\npractical actionable recommendations for robust BN integration in DRL\npipelines. We also empirically validate that, in RL settings, MA-BN accelerates\nand stabilizes training, broadens the effective learning rate range, enhances\nexploration, and reduces overall optimization difficulty. Our code is available\nat: https://github.com/monster476/ma-bn.git."}
{"id": "2509.23753", "pdf": "https://arxiv.org/pdf/2509.23753", "abs": "https://arxiv.org/abs/2509.23753", "authors": ["He Zhu", "Junyou Su", "Peng Lai", "Ren Ma", "Wenjia Zhang", "Linyi Yang", "Guanhua Chen"], "title": "Anchored Supervised Fine-Tuning", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Post-training of large language models involves a fundamental trade-off\nbetween supervised fine-tuning (SFT), which efficiently mimics demonstrations\nbut tends to memorize, and reinforcement learning (RL), which achieves better\ngeneralization at higher computational cost. Dynamic Fine-Tuning (DFT) recently\nemerged as a promising middle ground, reweighting SFT objectives with token\nprobabilities and achieving improvements in certain reasoning domains, though\nit exhibits instability in other tasks. We provide a analysis of DFT through\nthe reward-weighted regression (RWR) framework, revealing that it corresponds\nto a specific auxiliary distribution choice that yields provably tighter RL\nbounds than standard SFT. However, our analysis also uncovers a critical\nlimitation: this construction lacks distributional anchoring, leading to\nprogressive drift that undermines training stability. To address this, we\npropose Anchored Supervised Fine-Tuning (ASFT), which augments DFT's\nreweighting with lightweight KL regularization to preserve tightness while\nensuring stability. Empirically, ASFT consistently outperforms both SFT and DFT\nacross mathematical reasoning, medical knowledge grounding, and code\ngeneration, achieving substantial improvements with minimal computational\noverhead. Our RWR framework provides a systematic lens for understanding\npost-training methods and demonstrates that principled theoretical analysis\nleads to both stronger guarantees and practical gains."}
{"id": "2509.23756", "pdf": "https://arxiv.org/pdf/2509.23756", "abs": "https://arxiv.org/abs/2509.23756", "authors": ["Tomer D. Meirman", "Bracha Shapira", "Noa Dagan", "Lior S. Rokach"], "title": "SHAPoint: Task-Agnostic, Efficient, and Interpretable Point-Based Risk Scoring via Shapley Values", "categories": ["cs.LG", "cs.AI", "I.2.6; J.3; H.4.2"], "comment": "29 pages inc. references for main article. 6 Figures and 7 Tables.\n  Including Data and Code availability statements", "summary": "Interpretable risk scores play a vital role in clinical decision support, yet\ntraditional methods for deriving such scores often rely on manual\npreprocessing, task-specific modeling, and simplified assumptions that limit\ntheir flexibility and predictive power. We present SHAPoint, a novel,\ntask-agnostic framework that integrates the predictive accuracy of gradient\nboosted trees with the interpretability of point-based risk scores. SHAPoint\nsupports classification, regression, and survival tasks, while also inheriting\nvaluable properties from tree-based models, such as native handling of missing\ndata and support for monotonic constraints. Compared to existing frameworks,\nSHAPoint offers superior flexibility, reduced reliance on manual preprocessing,\nand faster runtime performance. Empirical results show that SHAPoint produces\ncompact and interpretable scores with predictive performance comparable to\nstate-of-the-art methods, but at a fraction of the runtime, making it a\npowerful tool for transparent and scalable risk stratification."}
{"id": "2509.23773", "pdf": "https://arxiv.org/pdf/2509.23773", "abs": "https://arxiv.org/abs/2509.23773", "authors": ["Utkarsh Sahu", "Zhisheng Qi", "Mahantesh Halappanavar", "Nedim Lipka", "Ryan A. Rossi", "Franck Dernoncourt", "Yu Zhang", "Yao Ma", "Yu Wang"], "title": "Knowledge Homophily in Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.SI"], "comment": null, "summary": "Large Language Models (LLMs) have been increasingly studied as neural\nknowledge bases for supporting knowledge-intensive applications such as\nquestion answering and fact checking. However, the structural organization of\ntheir knowledge remains unexplored. Inspired by cognitive neuroscience\nfindings, such as semantic clustering and priming, where knowing one fact\nincreases the likelihood of recalling related facts, we investigate an\nanalogous knowledge homophily pattern in LLMs. To this end, we map LLM\nknowledge into a graph representation through knowledge checking at both the\ntriplet and entity levels. After that, we analyze the knowledgeability\nrelationship between an entity and its neighbors, discovering that LLMs tend to\npossess a similar level of knowledge about entities positioned closer in the\ngraph. Motivated by this homophily principle, we propose a Graph Neural Network\n(GNN) regression model to estimate entity-level knowledgeability scores for\ntriplets by leveraging their neighborhood scores. The predicted\nknowledgeability enables us to prioritize checking less well-known triplets,\nthereby maximizing knowledge coverage under the same labeling budget. This not\nonly improves the efficiency of active labeling for fine-tuning to inject\nknowledge into LLMs but also enhances multi-hop path retrieval in\nreasoning-intensive question answering."}
{"id": "2509.23779", "pdf": "https://arxiv.org/pdf/2509.23779", "abs": "https://arxiv.org/abs/2509.23779", "authors": ["Jiarui Jiang", "Wei Huang", "Miao Zhang", "Taiji Suzuki", "Liqiang Nie"], "title": "Trained Mamba Emulates Online Gradient Descent in In-Context Linear Regression", "categories": ["cs.LG"], "comment": null, "summary": "State-space models (SSMs), particularly Mamba, emerge as an efficient\nTransformer alternative with linear complexity for long-sequence modeling.\nRecent empirical works demonstrate Mamba's in-context learning (ICL)\ncapabilities competitive with Transformers, a critical capacity for large\nfoundation models. However, theoretical understanding of Mamba's ICL remains\nlimited, restricting deeper insights into its underlying mechanisms. Even\nfundamental tasks such as linear regression ICL, widely studied as a standard\ntheoretical benchmark for Transformers, have not been thoroughly analyzed in\nthe context of Mamba. To address this gap, we study the training dynamics of\nMamba on the linear regression ICL task. By developing novel techniques\ntackling non-convex optimization with gradient descent related to Mamba's\nstructure, we establish an exponential convergence rate to ICL solution, and\nderive a loss bound that is comparable to Transformer's. Importantly, our\nresults reveal that Mamba can perform a variant of \\textit{online gradient\ndescent} to learn the latent function in context. This mechanism is different\nfrom that of Transformer, which is typically understood to achieve ICL through\ngradient descent emulation. The theoretical results are verified by\nexperimental simulation."}
{"id": "2509.23789", "pdf": "https://arxiv.org/pdf/2509.23789", "abs": "https://arxiv.org/abs/2509.23789", "authors": ["Chunxue Xu", "Yiwei Wang", "Yujun Cai", "Bryan Hooi", "Songze Li"], "title": "Visual CoT Makes VLMs Smarter but More Fragile", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "Chain-of-Thought (CoT) techniques have significantly enhanced reasoning in\nVision-Language Models (VLMs). Extending this paradigm, Visual CoT integrates\nexplicit visual edits, such as cropping or annotating regions of interest, into\nthe reasoning process, achieving superior multimodal performance. However, the\nrobustness of Visual CoT-based VLMs against image-level noise remains\nunexplored. In this paper, we present the first systematic evaluation of Visual\nCoT robustness under visual perturbations. Our benchmark spans 12 image\ncorruption types across 4 Visual Question Answering (VQA) datasets, enabling a\ncomprehensive comparison between VLMs that use Visual CoT, and VLMs that do\nnot. The results reveal that integrating Visual CoT consistently improves\nabsolute accuracy regardless of whether the input images are clean or corrupted\nby noise; however, it also increases sensitivity to input perturbations,\nresulting in sharper performance degradation compared to standard VLMs. Through\nextensive analysis, we identify the intermediate reasoning components of Visual\nCoT, i.e., the edited image patches , as the primary source of fragility.\nBuilding on this analysis, we propose a plug-and-play robustness enhancement\nmethod that integrates Grounding DINO model into the Visual CoT pipeline,\nproviding high-confidence local visual cues to stabilize reasoning. Our work\nreveals clear fragility patterns in Visual CoT and offers an effective,\narchitecture-agnostic solution for enhancing visual robustness."}
{"id": "2509.23799", "pdf": "https://arxiv.org/pdf/2509.23799", "abs": "https://arxiv.org/abs/2509.23799", "authors": ["Anyi Wang", "Xuansheng Wu", "Dong Shu", "Yunpu Ma", "Ninghao Liu"], "title": "Enhancing LLM Steering through Sparse Autoencoder-Based Vector Refinement", "categories": ["cs.LG", "cs.AI"], "comment": "19 pages, 11 figures, 7 tables", "summary": "Steering has emerged as a promising approach in controlling large language\nmodels (LLMs) without modifying model parameters. However, most existing\nsteering methods rely on large-scale datasets to learn clear behavioral\ninformation, which limits their applicability in many real-world scenarios. The\nsteering vectors extracted from small dataset often contain task-irrelevant\nnoising features, which degrades their effectiveness. To refine the steering\nvectors learned from limited data, we introduce Refinement of Steering Vector\nvia Sparse Autoencoder (SAE-RSV) that leverages SAEs to semantically denoise\nand augment the steering vectors. In our framework, we first remove\ntask-irrelevant features according to their semantics provided by SAEs, and\nthen enrich task-relevant features missing from the small dataset through their\nsemantic similarity to the identified relevant features. Extensive experiments\ndemonstrate that the proposed SAE-RSV substantially outperforms all the\nbaseline methods including supervised fine-tuning. Our findings show that\neffective steering vector can be constructed from limited training data by\nrefining the original steering vector through SAEs."}
{"id": "2509.23802", "pdf": "https://arxiv.org/pdf/2509.23802", "abs": "https://arxiv.org/abs/2509.23802", "authors": ["Yao Luan", "Ni Mu", "Yiqin Yang", "Bo Xu", "Qing-Shan Jia"], "title": "STAIR: Addressing Stage Misalignment through Temporal-Aligned Preference Reinforcement Learning", "categories": ["cs.LG"], "comment": "NeurIPS 2025", "summary": "Preference-based reinforcement learning (PbRL) bypasses complex reward\nengineering by learning rewards directly from human preferences, enabling\nbetter alignment with human intentions. However, its effectiveness in\nmulti-stage tasks, where agents sequentially perform sub-tasks (e.g.,\nnavigation, grasping), is limited by stage misalignment: Comparing segments\nfrom mismatched stages, such as movement versus manipulation, results in\nuninformative feedback, thus hindering policy learning. In this paper, we\nvalidate the stage misalignment issue through theoretical analysis and\nempirical experiments. To address this issue, we propose STage-AlIgned Reward\nlearning (STAIR), which first learns a stage approximation based on temporal\ndistance, then prioritizes comparisons within the same stage. Temporal distance\nis learned via contrastive learning, which groups temporally close states into\ncoherent stages, without predefined task knowledge, and adapts dynamically to\npolicy changes. Extensive experiments demonstrate STAIR's superiority in\nmulti-stage tasks and competitive performance in single-stage tasks.\nFurthermore, human studies show that stages approximated by STAIR are\nconsistent with human cognition, confirming its effectiveness in mitigating\nstage misalignment."}
{"id": "2509.23803", "pdf": "https://arxiv.org/pdf/2509.23803", "abs": "https://arxiv.org/abs/2509.23803", "authors": ["Pramit Saha", "Joshua Strong", "Divyanshu Mishra", "Cheng Ouyang", "J. Alison Noble"], "title": "FedAgentBench: Towards Automating Real-world Federated Medical Image Analysis with Server-Client LLM Agents", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.DC", "cs.MA"], "comment": null, "summary": "Federated learning (FL) allows collaborative model training across healthcare\nsites without sharing sensitive patient data. However, real-world FL deployment\nis often hindered by complex operational challenges that demand substantial\nhuman efforts. This includes: (a) selecting appropriate clients (hospitals),\n(b) coordinating between the central server and clients, (c) client-level data\npre-processing, (d) harmonizing non-standardized data and labels across\nclients, and (e) selecting FL algorithms based on user instructions and\ncross-client data characteristics. However, the existing FL works overlook\nthese practical orchestration challenges. These operational bottlenecks\nmotivate the need for autonomous, agent-driven FL systems, where intelligent\nagents at each hospital client and the central server agent collaboratively\nmanage FL setup and model training with minimal human intervention. To this\nend, we first introduce an agent-driven FL framework that captures key phases\nof real-world FL workflows from client selection to training completion and a\nbenchmark dubbed FedAgentBench that evaluates the ability of LLM agents to\nautonomously coordinate healthcare FL. Our framework incorporates 40 FL\nalgorithms, each tailored to address diverse task-specific requirements and\ncross-client characteristics. Furthermore, we introduce a diverse set of\ncomplex tasks across 201 carefully curated datasets, simulating 6\nmodality-specific real-world healthcare environments, viz., Dermatoscopy,\nUltrasound, Fundus, Histopathology, MRI, and X-Ray. We assess the agentic\nperformance of 14 open-source and 10 proprietary LLMs spanning small, medium,\nand large model scales. While some agent cores such as GPT-4.1 and DeepSeek V3\ncan automate various stages of the FL pipeline, our results reveal that more\ncomplex, interdependent tasks based on implicit goals remain challenging for\neven the strongest models."}
{"id": "2509.23808", "pdf": "https://arxiv.org/pdf/2509.23808", "abs": "https://arxiv.org/abs/2509.23808", "authors": ["Fanding Huang", "Guanbo Huang", "Xiao Fan", "Yi He", "Xiao Liang", "Xiao Chen", "Qinting Jiang", "Faisal Nadeem Khan", "Jingyan Jiang", "Zhi Wang"], "title": "Beyond the Exploration-Exploitation Trade-off: A Hidden State Approach for LLM Reasoning in RLVR", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "A prevailing view in Reinforcement Learning for Verifiable Rewards (RLVR)\ninterprets recent progress through the lens of an exploration-exploitation\ntrade-off, a perspective largely shaped by token-level metrics. We re-examine\nthis perspective, proposing that this perceived trade-off may not be a\nfundamental constraint but rather an artifact of the measurement level. To\ninvestigate this, we shift the analysis to the semantically rich hidden-state\nspace, adopting Effective Rank (ER) to quantify exploration and proposing its\nnovel first- and second-order derivatives, named Effective Rank Velocity (ERV)\nand Effective Rank Acceleration (ERA), to capture exploitation dynamics. Our\nanalysis reveals that at the hidden-state level, exploration and exploitation\ncould be decoupled (Sec. 4). This finding reveals an opportunity to enhance\nboth capacities simultaneously. This insight motivates our method,\nVelocity-Exploiting Rank-Learning (VERL), the first to operationalize the\nprinciple of synergistic exploration-exploitation enhancement by directly\nshaping the RL advantage function. The key innovation is leveraging the\ntheoretically stable ERA as a predictive meta-controller to create a\nsynergistic, dual-channel incentive structure. Instead of forcing a trade-off,\nVERL prospectively amplifies rewards for exploration to preempt overconfidence\nand reinforces exploitative gains to consolidate reasoning. Experiments across\ndiverse LLMs and reasoning benchmarks show consistent gains, including up to\n21.4% absolute accuracy improvement on the challenging Gaokao 2024 dataset."}
{"id": "2509.23809", "pdf": "https://arxiv.org/pdf/2509.23809", "abs": "https://arxiv.org/abs/2509.23809", "authors": ["Hong Huang", "Decheng Wu", "Rui Cen", "Guanghua Yu", "Zonghang Li", "Kai Liu", "Jianchen Zhu", "Peng Chen", "Xue Liu", "Dapeng Wu"], "title": "Tequila: Trapping-free Ternary Quantization for Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Quantization techniques are essential for the deployment of Large Language\nModels (LLMs) on edge devices. However, prevailing methods often rely on\nmixed-precision multiplication that lacks efficient hardware support, making it\nnot feasible. Ternary weight quantization addresses this by constraining\nweights to {-1, 0, 1}, replacing expensive multiplications with\nhardware-efficient additions. However, such aggressive compression leads to\nsignificant accuracy degradation, even after costly quantization-aware training\nwith massive data. We identify the core issue as deadzone trapping: a large\nnumber of weights are trapped at the deadzone boundary. This occurs because\nthese weights receive only noisy, uninformative gradients, preventing stable\nescape from the deadzone and severely impeding model capacity and optimization.\nTo address this issue, we propose Tequila, a trapping-free quantization\noptimization method that reactivates deadzone-trapped weights by repurposing\nthem as dynamic biases. This allows the repurposed weights to provide a\ncontinuous signal in the forward pass and, critically, receive direct,\nmeaningful gradient signals during backpropagation, thereby enhancing model\ncapacity and optimization with nearly zero inference overhead. Extensive\nevaluations demonstrate that Tequila outperforms state-of-the-art (SOTA)\nternary quantization methods across five benchmarks. Specifically, on the ARC\nbenchmark, it achieves >4% accuracy gain over the SOTA baseline, nearly\nmatching full-precision performance (within <1% gap) with a 3.0x inference\nspeedup. Consequently, Tequila offers a highly practical and efficient\nimplementation for the deployment of advanced LLMs in resource-constrained\nenvironments. The code is available at https://github.com/Tencent/AngelSlim."}
{"id": "2509.23813", "pdf": "https://arxiv.org/pdf/2509.23813", "abs": "https://arxiv.org/abs/2509.23813", "authors": ["Beiliang Wu", "Peiyuan Liu", "Yifan Hu", "Luyan Zhang", "Ao Hu", "Zenglin Xu"], "title": "IndexNet: Timestamp and Variable-Aware Modeling for Time Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Multivariate time series forecasting (MTSF) plays a vital role in a wide\nrange of real-world applications, such as weather prediction and traffic flow\nforecasting. Although recent advances have significantly improved the modeling\nof temporal dynamics and inter-variable dependencies, most existing methods\noverlook index-related descriptive information, such as timestamps and variable\nindices, which carry rich contextual semantics. To unlock the potential of such\ninformation and take advantage of the lightweight and powerful periodic capture\nability of MLP-based architectures, we propose IndexNet, an MLP-based framework\naugmented with an Index Embedding (IE) module. The IE module consists of two\nkey components: Timestamp Embedding (TE) and Channel Embedding (CE).\nSpecifically, TE transforms timestamps into embedding vectors and injects them\ninto the input sequence, thereby improving the model's ability to capture\nlong-term complex periodic patterns. In parallel, CE assigns each variable a\nunique and trainable identity embedding based on its index, allowing the model\nto explicitly distinguish between heterogeneous variables and avoid homogenized\npredictions when input sequences seem close. Extensive experiments on 12\ndiverse real-world datasets demonstrate that IndexNet achieves comparable\nperformance across mainstream baselines, validating the effectiveness of our\ntemporally and variably aware design. Moreover, plug-and-play experiments and\nvisualization analyses further reveal that IndexNet exhibits strong generality\nand interpretability, two aspects that remain underexplored in current MTSF\nresearch."}
{"id": "2509.23816", "pdf": "https://arxiv.org/pdf/2509.23816", "abs": "https://arxiv.org/abs/2509.23816", "authors": ["Bo Li", "Xin Zheng", "Ming Jin", "Can Wang", "Shirui Pan"], "title": "Test-time GNN Model Evaluation on Dynamic Graphs", "categories": ["cs.LG"], "comment": "Accepted by ICDM 2025", "summary": "Dynamic graph neural networks (DGNNs) have emerged as a leading paradigm for\nlearning from dynamic graphs, which are commonly used to model real-world\nsystems and applications. However, due to the evolving nature of dynamic graph\ndata distributions over time, well-trained DGNNs often face significant\nperformance uncertainty when inferring on unseen and unlabeled test graphs in\npractical deployment. In this case, evaluating the performance of deployed\nDGNNs at test time is crucial to determine whether a well-trained DGNN is\nsuited for inference on an unseen dynamic test graph. In this work, we\nintroduce a new research problem: DGNN model evaluation, which aims to assess\nthe performance of a specific DGNN model trained on observed dynamic graphs by\nestimating its performance on unseen dynamic graphs during test time.\nSpecifically, we propose a Dynamic Graph neural network Evaluator, dubbed\nDyGEval, to address this new problem. The proposed DyGEval involves a two-stage\nframework: (1) test-time dynamic graph simulation, which captures the\ntraining-test distributional differences as supervision signals and trains an\nevaluator; and (2) DyGEval development and training, which accurately estimates\nthe performance of the well-trained DGNN model on the test-time dynamic graphs.\nExtensive experiments demonstrate that the proposed DyGEval serves as an\neffective evaluator for assessing various DGNN backbones across different\ndynamic graphs under distribution shifts."}
{"id": "2509.23822", "pdf": "https://arxiv.org/pdf/2509.23822", "abs": "https://arxiv.org/abs/2509.23822", "authors": ["Omri Puny", "Yaron Lipman", "Benjamin Kurt Miller"], "title": "Space Group Conditional Flow Matching", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Inorganic crystals are periodic, highly-symmetric arrangements of atoms in\nthree-dimensional space. Their structures are constrained by the symmetry\noperations of a crystallographic \\emph{space group} and restricted to lie in\nspecific affine subspaces known as \\emph{Wyckoff positions}. The frequency an\natom appears in the crystal and its rough positioning are determined by its\nWyckoff position. Most generative models that predict atomic coordinates\noverlook these symmetry constraints, leading to unrealistically high\npopulations of proposed crystals exhibiting limited symmetry. We introduce\nSpace Group Conditional Flow Matching, a novel generative framework that\nsamples significantly closer to the target population of highly-symmetric,\nstable crystals. We achieve this by conditioning the entire generation process\non a given space group and set of Wyckoff positions; specifically, we define a\nconditionally symmetric noise base distribution and a group-conditioned,\nequivariant, parametric vector field that restricts the motion of atoms to\ntheir initial Wyckoff position. Our form of group-conditioned equivariance is\nachieved using an efficient reformulation of \\emph{group averaging} tailored\nfor symmetric crystals. Importantly, it reduces the computational overhead of\nsymmetrization to a negligible level. We achieve state of the art results on\ncrystal structure prediction and de novo generation benchmarks. We also perform\nrelevant ablations."}
{"id": "2509.23825", "pdf": "https://arxiv.org/pdf/2509.23825", "abs": "https://arxiv.org/abs/2509.23825", "authors": ["Alexander Kolesov", "Stepan Manukhov", "Vladimir V. Palyulin", "Alexander Korotin"], "title": "Electric Currents for Discrete Data Generation", "categories": ["cs.LG"], "comment": "generative models, electrodynamics", "summary": "We propose $\\textbf{E}$lectric $\\textbf{C}$urrent $\\textbf{D}$iscrete\n$\\textbf{D}$ata $\\textbf{G}$eneration (ECD$^{2}$G), a pioneering method for\ndata generation in discrete settings that is grounded in electrical engineering\ntheory. Our approach draws an analogy between electric current flow in a\ncircuit and the transfer of probability mass between data distributions. We\ninterpret samples from the source distribution as current input nodes of a\ncircuit and samples from the target distribution as current output nodes. A\nneural network is then used to learn the electric currents to represent the\nprobability flow in the circuit. To map the source distribution to the target,\nwe sample from the source and transport these samples along the circuit\npathways according to the learned currents. This process provably guarantees\ntransfer between data distributions. We present proof-of-concept experiments to\nillustrate our ECD$^{2}$G method."}
{"id": "2509.23830", "pdf": "https://arxiv.org/pdf/2509.23830", "abs": "https://arxiv.org/abs/2509.23830", "authors": ["Albus Yizhuo Li"], "title": "Bayesian Mixture-of-Experts: Towards Making LLMs Know What They Don't Know", "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH"], "comment": null, "summary": "The Mixture-of-Experts (MoE) architecture has enabled the creation of massive\nyet efficient Large Language Models (LLMs). However, the standard deterministic\nrouting mechanism presents a significant limitation: its inherent brittleness\nis a key contributor to model miscalibration and overconfidence, resulting in\nsystems that often do not know what they don't know.\n  This thesis confronts this challenge by proposing a structured\n\\textbf{Bayesian MoE routing framework}. Instead of forcing a single,\ndeterministic expert selection, our approach models a probability distribution\nover the routing decision itself. We systematically investigate three families\nof methods that introduce this principled uncertainty at different stages of\nthe routing pipeline: in the \\textbf{weight-space}, the \\textbf{logit-space},\nand the final \\textbf{selection-space}.\n  Through a series of controlled experiments on a 3-billion parameter MoE\nmodel, we demonstrate that this framework significantly improves routing\nstability, in-distribution calibration, and out-of-distribution (OoD)\ndetection. The results show that by targeting this core architectural\ncomponent, we can create a more reliable internal uncertainty signal. This work\nprovides a practical and computationally tractable pathway towards building\nmore robust and self-aware LLMs, taking a crucial step towards making them know\nwhat they don't know."}
{"id": "2509.23846", "pdf": "https://arxiv.org/pdf/2509.23846", "abs": "https://arxiv.org/abs/2509.23846", "authors": ["Daniele Foffano", "Alessio Russo", "Alexandre Proutiere"], "title": "Adversarial Diffusion for Robust Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Robustness to modeling errors and uncertainties remains a central challenge\nin reinforcement learning (RL). In this work, we address this challenge by\nleveraging diffusion models to train robust RL policies. Diffusion models have\nrecently gained popularity in model-based RL due to their ability to generate\nfull trajectories \"all at once\", mitigating the compounding errors typical of\nstep-by-step transition models. Moreover, they can be conditioned to sample\nfrom specific distributions, making them highly flexible. We leverage\nconditional sampling to learn policies that are robust to uncertainty in\nenvironment dynamics. Building on the established connection between\nConditional Value at Risk (CVaR) optimization and robust RL, we introduce\nAdversarial Diffusion for Robust Reinforcement Learning (AD-RRL). AD-RRL guides\nthe diffusion process to generate worst-case trajectories during training,\neffectively optimizing the CVaR of the cumulative return. Empirical results\nacross standard benchmarks show that AD-RRL achieves superior robustness and\nperformance compared to existing robust RL methods."}
{"id": "2509.23866", "pdf": "https://arxiv.org/pdf/2509.23866", "abs": "https://arxiv.org/abs/2509.23866", "authors": ["Pengxiang Li", "Zechen Hu", "Zirui Shang", "Jingrong Wu", "Yang Liu", "Hui Liu", "Zhi Gao", "Chenrui Shi", "Bofei Zhang", "Zihao Zhang", "Xiaochuan Shi", "Zedong YU", "Yuwei Wu", "Xinxiao Wu", "Yunde Jia", "Liuyu Xiang", "Zhaofeng He", "Qing Li"], "title": "Efficient Multi-turn RL for GUI Agents via Decoupled Training and Adaptive Data Curation", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Vision-language model (VLM) based GUI agents show promise for automating\ncomplex desktop and mobile tasks, but face significant challenges in applying\nreinforcement learning (RL): (1) slow multi-turn interactions with GUI\nenvironments for policy rollout, and (2) insufficient high-quality\nagent-environment interactions for policy learning. To address these\nchallenges, we propose DART, a Decoupled Agentic RL Training framework for GUI\nagents, which coordinates heterogeneous modules in a highly decoupled manner.\nDART separates the training system into four asynchronous modules: environment\ncluster, rollout service, data manager, and trainer. This design enables\nnon-blocking communication, asynchronous training, rollout-wise trajectory\nsampling, and per-worker model synchronization, significantly improving the\nsystem efficiency: 1.6*GPU utilization for rollout, 1.9* training throughput,\nand 5.5* environment utilization. To facilitate effective learning from\nabundant samples, we introduce an adaptive data curation scheme: (1)\npre-collecting successful trajectories for challenging tasks to supplement\nsparse success in online sampling; (2) dynamically adjusting rollout numbers\nand trajectory lengths based on task difficulty; (3) training selectively on\nhigh-entropy steps to prioritize critical decisions; (4) stabilizing learning\nvia truncated importance sampling for policy mismatch between policy rollout\nand updating. On the OSWorld benchmark, DART-GUI-7B achieves a 42.13% task\nsuccess rate, a 14.61% absolute gain over the base model, and 7.34% higher than\nopen-source SOTA. We will fully open-source our training framework, data, and\nmodel checkpoints via computer-use-agents.github.io/dart-gui, which we believe\nis a timely contribution to the open-source community of agentic RL training."}
{"id": "2509.23886", "pdf": "https://arxiv.org/pdf/2509.23886", "abs": "https://arxiv.org/abs/2509.23886", "authors": ["Simon Schrodi", "Elias Kempf", "Fazl Barez", "Thomas Brox"], "title": "Towards Understanding Subliminal Learning: When and How Hidden Biases Transfer", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Language models can transfer hidden biases during distillation. For example,\na teacher that \"likes owls\" can make its student \"like owls\" too, even when the\ntraining data consists only of lists of numbers. This surprising phenomenon is\ncalled subliminal learning. Subliminal learning can be expected under soft\ndistillation, where the student is trained on the teacher's full next-token\ndistribution. But the fact that this also occurs under hard distillation-where\nthe student only sees sampled tokens-raises a deeper question: when and how\ndoes subliminal learning actually occur? We answer this question through\ncontrolled experiments and mechanistic analysis. Our results show that\nsubliminal learning does not need (global) token entanglement or logit leakage.\nInstead, it comes down to a small set of divergence tokens-rare cases where\nteachers with different biases would predict different tokens. Masking out\nthese tokens mostly removes the hidden bias transfer. Mechanistically,\ndivergence tokens reveal that early layers are critical. Surprisingly,\nfinetuning even a single such early layer is sufficient for subliminal\nlearning. Finally, we find that subliminal learning is fragile. Even small\nchanges, like paraphrasing prompts, are usually sufficient to suppress it."}
{"id": "2509.23887", "pdf": "https://arxiv.org/pdf/2509.23887", "abs": "https://arxiv.org/abs/2509.23887", "authors": ["Yash Jakhmola"], "title": "Gradient Flow Convergence Guarantee for General Neural Network Architectures", "categories": ["cs.LG", "cs.AI"], "comment": "12 pages, 3 figures, 1 table", "summary": "A key challenge in modern deep learning theory is to explain the remarkable\nsuccess of gradient-based optimization methods when training large-scale,\ncomplex deep neural networks. Though linear convergence of such methods has\nbeen proved for a handful of specific architectures, a united theory still\nevades researchers. This article presents a unified proof for linear\nconvergence of continuous gradient descent, also called gradient flow, while\ntraining any neural network with piecewise non-zero polynomial activations or\nReLU, sigmoid activations. Our primary contribution is a single, general\ntheorem that not only covers architectures for which this result was previously\nunknown but also consolidates existing results under weaker assumptions. While\nour focus is theoretical and our results are only exact in the infinitesimal\nstep size limit, we nevertheless find excellent empirical agreement between the\npredictions of our result and those of the practical step-size gradient descent\nmethod."}
{"id": "2509.23893", "pdf": "https://arxiv.org/pdf/2509.23893", "abs": "https://arxiv.org/abs/2509.23893", "authors": ["Zhixin Zhang", "Zeming Wei", "Meng Sun"], "title": "Dynamic Orthogonal Continual Fine-tuning for Mitigating Catastrophic Forgettings", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CR", "math.OC"], "comment": null, "summary": "Catastrophic forgetting remains a critical challenge in continual learning\nfor large language models (LLMs), where models struggle to retain performance\non historical tasks when fine-tuning on new sequential data without access to\npast datasets. In this paper, we first reveal that the drift of functional\ndirections during the fine-tuning process is a key reason why existing\nregularization-based methods fail in long-term LLM continual learning. To\naddress this, we propose Dynamic Orthogonal Continual (DOC) fine-tuning, a\nnovel approach that tracks the drift of these functional directions and\ndynamically updates them during the fine-tuning process. Furthermore, by\nadjusting the gradients of new task parameters to be orthogonal to the tracked\nhistorical function directions, our method mitigates interference between new\nand old tasks. Extensive experiments on various LLM continual learning\nbenchmarks demonstrate that this approach outperforms prior methods,\neffectively reducing catastrophic forgetting and providing a robust tool for\ncontinuous LLM fine-tuning. Our code is available at\nhttps://github.com/meloxxxxxx/DOC."}
{"id": "2509.23898", "pdf": "https://arxiv.org/pdf/2509.23898", "abs": "https://arxiv.org/abs/2509.23898", "authors": ["Chris Kolb", "Laetitia Frost", "Bernd Bischl", "David Rügamer"], "title": "Differentiable Sparsity via $D$-Gating: Simple and Versatile Structured Penalization", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Structured sparsity regularization offers a principled way to compact neural\nnetworks, but its non-differentiability breaks compatibility with conventional\nstochastic gradient descent and requires either specialized optimizers or\nadditional post-hoc pruning without formal guarantees. In this work, we propose\n$D$-Gating, a fully differentiable structured overparameterization that splits\neach group of weights into a primary weight vector and multiple scalar gating\nfactors. We prove that any local minimum under $D$-Gating is also a local\nminimum using non-smooth structured $L_{2,2/D}$ penalization, and further show\nthat the $D$-Gating objective converges at least exponentially fast to the\n$L_{2,2/D}$-regularized loss in the gradient flow limit. Together, our results\nshow that $D$-Gating is theoretically equivalent to solving the original group\nsparsity problem, yet induces distinct learning dynamics that evolve from a\nnon-sparse regime into sparse optimization. We validate our theory across\nvision, language, and tabular tasks, where $D$-Gating consistently delivers\nstrong performance-sparsity tradeoffs and outperforms both direct optimization\nof structured penalties and conventional pruning baselines."}
{"id": "2509.23905", "pdf": "https://arxiv.org/pdf/2509.23905", "abs": "https://arxiv.org/abs/2509.23905", "authors": ["Tianjiao Sun", "Ningyan Guo", "Haozhe Gu", "Yanyan Peng", "Zhiyong Feng"], "title": "Integrated Communication and Control for Energy-Efficient UAV Swarms: A Multi-Agent Reinforcement Learning Approach", "categories": ["cs.LG", "cs.SY", "eess.SP", "eess.SY"], "comment": null, "summary": "The deployment of unmanned aerial vehicle (UAV) swarm-assisted communication\nnetworks has become an increasingly vital approach for remediating coverage\nlimitations in infrastructure-deficient environments, with especially pressing\napplications in temporary scenarios, such as emergency rescue, military and\nsecurity operations, and remote area coverage. However, complex geographic\nenvironments lead to unpredictable and highly dynamic wireless channel\nconditions, resulting in frequent interruptions of air-to-ground (A2G) links\nthat severely constrain the reliability and quality of service in UAV\nswarm-assisted mobile communications. To improve the quality of UAV\nswarm-assisted communications in complex geographic environments, we propose an\nintegrated communication and control co-design mechanism. Given the stringent\nenergy constraints inherent in UAV swarms, our proposed mechanism is designed\nto optimize energy efficiency while maintaining an equilibrium between\nequitable communication rates for mobile ground users (GUs) and UAV energy\nexpenditure. We formulate the joint resource allocation and 3D trajectory\ncontrol problem as a Markov decision process (MDP), and develop a multi-agent\nreinforcement learning (MARL) framework to enable real-time coordinated actions\nacross the UAV swarm. To optimize the action policy of UAV swarms, we propose a\nnovel multi-agent hybrid proximal policy optimization with action masking\n(MAHPPO-AM) algorithm, specifically designed to handle complex hybrid action\nspaces. The algorithm incorporates action masking to enforce hard constraints\nin high-dimensional action spaces. Experimental results demonstrate that our\napproach achieves a fairness index of 0.99 while reducing energy consumption by\nup to 25% compared to baseline methods."}
{"id": "2509.23923", "pdf": "https://arxiv.org/pdf/2509.23923", "abs": "https://arxiv.org/abs/2509.23923", "authors": ["Maya Bechler-Speicher", "Andrea Zerio", "Maor Huri", "Marie Vibeke Vestergaard", "Ran Gilad-Bachrach", "Tine Jess", "Samir Bhatt", "Aleksejs Sazonovs"], "title": "Graph Mixing Additive Networks", "categories": ["cs.LG", "cs.AI"], "comment": "arXiv admin note: substantial text overlap with arXiv:2505.19193", "summary": "We introduce GMAN, a flexible, interpretable, and expressive framework that\nextends Graph Neural Additive Networks (GNANs) to learn from sets of sparse\ntime-series data. GMAN represents each time-dependent trajectory as a directed\ngraph and applies an enriched, more expressive GNAN to each graph. It allows\nusers to control the interpretability-expressivity trade-off by grouping\nfeatures and graphs to encode priors, and it provides feature, node, and\ngraph-level interpretability. On real-world datasets, including mortality\nprediction from blood tests and fake-news detection, GMAN outperforms strong\nnon-interpretable black-box baselines while delivering actionable,\ndomain-aligned explanations."}
{"id": "2509.23928", "pdf": "https://arxiv.org/pdf/2509.23928", "abs": "https://arxiv.org/abs/2509.23928", "authors": ["Zhinan Xie", "Peisong Wang", "Jian Cheng"], "title": "HiViS: Hiding Visual Tokens from the Drafter for Speculative Decoding in Vision-Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Speculative decoding is an effective approach for accelerating inference in\nLarge Language models (LLMs), but its adaptation to Vision-Language models\n(VLMs) remains challenging for additional visual tokens in multimodal inputs.\nFirst, owing to the fact that the drafter and the target VLM may derived from\ndifferent families, the semantic representations of visual tokens in the target\nVLM are misaligned with those in the drafter, introducing bias into the\nKV-cache during the prefill stage. Second, the large number of visual tokens\nsubstantially slows down the drafter's self-attention during the decoding\nstage. We propose Hiding Visual Tokens from the Drafter for Speculative\nDecoding in Vision-Language Models (HiViS), an explicit-implicit input\ndecomposition framework that alleviates the above inefficiency. All visual\ntokens are removed from the drafter's input, retaining only textual tokens as\nexplicit inputs, while directly reusing the target VLM's corresponding\nlast-layer hidden states as implicit visual information without additional\nprocessing. To train the drafter efficiently, we introduces multi-step\nself-feedback training strategy with dynamic data selection and sequential\nembedding supervision to simulate reasoning during training. Our approach\ncompresses the prefill sequence length of the drafter to only 0.7%-1.3% of the\ntarget VLM's input, while maintaining lossless generation quality. Extensive\nexperiments across diverse models and tasks demonstrate up to 2.65x speedup,\nconfirming the effectiveness of HiViS in accelerating VLM inference."}
{"id": "2509.23933", "pdf": "https://arxiv.org/pdf/2509.23933", "abs": "https://arxiv.org/abs/2509.23933", "authors": ["Jiahao Ying", "Mingbao Lin", "Qianru Sun", "Yixin Cao"], "title": "Beyond Benchmarks: Understanding Mixture-of-Experts Models through Internal Mechanisms", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Mixture-of-Experts (MoE) architectures have emerged as a promising direction,\noffering efficiency and scalability by activating only a subset of parameters\nduring inference. However, current research remains largely\nperformance-centric, with limited understanding of its internal mechanisms,\nthereby constraining broader progress. In this work, we use an internal metric\nto investigate the mechanisms of MoE architecture by explicitly incorporating\nrouting mechanisms and analyzing expert-level behaviors. Through systematic\nanalyses of a wide range of publicly available MoE models, we uncover several\nfindings: (1) neuron utilization decreases as models evolve, reflecting\nstronger generalization; (2) training exhibits a dynamic trajectory, where\nbenchmark performance alone provides limited signal while MUI reveals deeper\ninsights; (3) task completion emerges from collaborative contributions of\nmultiple experts, with shared experts driving concentration; and (4) activation\npatterns at the neuron level provide a fine-grained proxy for data diversity.\nTogether, these results demonstrate the potential of MUI as a complementary\nindicator to benchmark performance, offering new insights into the capacity,\ndynamics, and specialization of MoE models. Our project can be found at\nhttps://yingjiahao14.github.io/MoE-MUI/."}
{"id": "2509.23937", "pdf": "https://arxiv.org/pdf/2509.23937", "abs": "https://arxiv.org/abs/2509.23937", "authors": ["Akhil Premkumar"], "title": "Diffusion Models are Kelly Gamblers", "categories": ["cs.LG", "cond-mat.stat-mech", "cs.AI", "cs.IT", "math.IT"], "comment": "26 pages + references, 13 figures", "summary": "We draw a connection between diffusion models and the Kelly criterion for\nmaximizing returns in betting games. We find that conditional diffusion models\nstore additional information to bind the signal $X$ with the conditioning\ninformation $Y$, equal to the mutual information between them. Classifier-free\nguidance effectively boosts the mutual information between $X$ and $Y$ at\nsampling time. This is especially helpful in image models, since the mutual\ninformation between images and their labels is low, a fact which is intimately\nconnected to the manifold hypothesis. Finally, we point out some nuances in the\npopular perspective that diffusion models are infinitely deep autoencoders. In\ndoing so, we relate the denoising loss to the Fermi Golden Rule from quantum\nmechanics."}
{"id": "2509.23941", "pdf": "https://arxiv.org/pdf/2509.23941", "abs": "https://arxiv.org/abs/2509.23941", "authors": ["Victoria Bosch", "Daniel Anthes", "Adrien Doerig", "Sushrut Thorat", "Peter König", "Tim Christian Kietzmann"], "title": "Brain-language fusion enables interactive neural readout and in-silico experimentation", "categories": ["cs.LG", "q-bio.NC"], "comment": null, "summary": "Large language models (LLMs) have revolutionized human-machine interaction,\nand have been extended by embedding diverse modalities such as images into a\nshared language space. Yet, neural decoding has remained constrained by static,\nnon-interactive methods. We introduce CorText, a framework that integrates\nneural activity directly into the latent space of an LLM, enabling open-ended,\nnatural language interaction with brain data. Trained on fMRI data recorded\nduring viewing of natural scenes, CorText generates accurate image captions and\ncan answer more detailed questions better than controls, while having access to\nneural data only. We showcase that CorText achieves zero-shot generalization\nbeyond semantic categories seen during training. Furthermore, we present a\ncounterfactual analysis that emulates in-silico cortical microstimulation.\nThese advances mark a shift from passive decoding toward generative, flexible\ninterfaces between brain activity and language."}
{"id": "2509.23942", "pdf": "https://arxiv.org/pdf/2509.23942", "abs": "https://arxiv.org/abs/2509.23942", "authors": ["John N. Daras"], "title": "Efficient Identification of High Similarity Clusters in Polygon Datasets", "categories": ["cs.LG", "cs.DB", "q-bio.QM"], "comment": "11 pages, 3 figures", "summary": "Advancements in tools like Shapely 2.0 and Triton can significantly improve\nthe efficiency of spatial similarity computations by enabling faster and more\nscalable geometric operations. However, for extremely large datasets, these\noptimizations may face challenges due to the sheer volume of computations\nrequired. To address this, we propose a framework that reduces the number of\nclusters requiring verification, thereby decreasing the computational load on\nthese systems. The framework integrates dynamic similarity index thresholding,\nsupervised scheduling, and recall-constrained optimization to efficiently\nidentify clusters with the highest spatial similarity while meeting\nuser-defined precision and recall requirements. By leveraging Kernel Density\nEstimation (KDE) to dynamically determine similarity thresholds and machine\nlearning models to prioritize clusters, our approach achieves substantial\nreductions in computational cost without sacrificing accuracy. Experimental\nresults demonstrate the scalability and effectiveness of the method, offering a\npractical solution for large-scale geospatial analysis."}
{"id": "2509.23946", "pdf": "https://arxiv.org/pdf/2509.23946", "abs": "https://arxiv.org/abs/2509.23946", "authors": ["Kaisen Yang", "Lixuan He", "Rushi Shah", "Kaicheng Yang", "Qinwei Ma", "Dianbo Liu", "Alex Lamb"], "title": "Explore-Execute Chain: Towards an Efficient Structured Reasoning Paradigm", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "comment": "Under review ICLR 2026", "summary": "Chain-of-Thought (CoT) and its variants have markedly advanced the reasoning\nabilities of Large Language Models (LLMs), yet their monolithic and\nauto-regressive architecture inherently conflates high-level strategic planning\nwith low-level step-by-step execution, leading to computational inefficiency,\nlimited exploration of reasoning paths, and reduced interpretability. To\novercome these issues, we propose the Explore-Execute Chain ($E^2C$), a\nstructured reasoning framework that decouples reasoning into two distinct\nphases: an exploratory phase that stochastically generates succinct high-level\nplans, followed by an execution phase that deterministically carries out the\nchosen plan. Our approach incorporates a two-stage training methodology, which\ncombines Supervised Fine-Tuning (SFT) - augmented by a novel data generation\nalgorithm enforcing strict plan adherence - with a subsequent Reinforcement\nLearning (RL) stage that capitalizes on the informativeness of exploration and\nreinforces the determinism of execution.This decomposition enables an efficient\ntest-time scaling strategy: on AIME'2024, $E^2C$ Test Time Scaling reaches\n58.1% accuracy using <10% of the decoding tokens required by comparable methods\n(e.g., Forest-of-Thought), sharply cutting self-consistency overhead. For\ncross-domain adaptation, our Exploration-Focused SFT (EF-SFT) fine-tunes with\nonly 3.5% of the tokens used by standard SFT yet yields up to 14.5% higher\naccuracy than standard SFT on medical benchmarks, delivering state-of-the-art\nperformance, strong generalization, and greater interpretability by separating\nplanning from execution. The code and pre-trained models for the project are\navailable at: https://github.com/yks23/Explore-Execute-Chain.git"}
{"id": "2509.23948", "pdf": "https://arxiv.org/pdf/2509.23948", "abs": "https://arxiv.org/abs/2509.23948", "authors": ["Surya Murthy", "Kushagra Gupta", "Mustafa O. Karabag", "David Fridovich-Keil", "Ufuk Topcu"], "title": "DiBS-MTL: Transformation-Invariant Multitask Learning with Direction Oracles", "categories": ["cs.LG"], "comment": null, "summary": "Multitask learning (MTL) algorithms typically rely on schemes that combine\ndifferent task losses or their gradients through weighted averaging. These\nmethods aim to find Pareto stationary points by using heuristics that require\naccess to task loss values, gradients, or both. In doing so, a central\nchallenge arises because task losses can be arbitrarily, nonaffinely scaled\nrelative to one another, causing certain tasks to dominate training and degrade\noverall performance. A recent advance in cooperative bargaining theory, the\nDirection-based Bargaining Solution (DiBS), yields Pareto stationary solutions\nimmune to task domination because of its invariance to monotonic nonaffine task\nloss transformations. However, the convergence behavior of DiBS in nonconvex\nMTL settings is currently not understood. To this end, we prove that under\nstandard assumptions, a subsequence of DiBS iterates converges to a Pareto\nstationary point when task losses are possibly nonconvex, and propose DiBS-MTL,\na computationally efficient adaptation of DiBS to the MTL setting. Finally, we\nvalidate DiBS-MTL empirically on standard MTL benchmarks, showing that it\nachieves competitive performance with state-of-the-art methods while\nmaintaining robustness to nonaffine monotonic transformations that\nsignificantly degrade the performance of existing approaches, including prior\nbargaining-inspired MTL methods. Code available at\nhttps://github.com/suryakmurthy/dibs-mtl."}
{"id": "2509.23963", "pdf": "https://arxiv.org/pdf/2509.23963", "abs": "https://arxiv.org/abs/2509.23963", "authors": ["Rylan Schaeffer", "Noam Levi", "Andreas Kirsch", "Theo Guenais", "Brando Miranda", "Elyas Obbad", "Sanmi Koyejo"], "title": "Evaluating the Robustness of Chinchilla Compute-Optimal Scaling", "categories": ["cs.LG"], "comment": null, "summary": "Hoffman et al (2022)'s Chinchilla paper introduced the principle of\ncompute-optimal scaling, laying a foundation for future scaling of language\nmodels. In the years since, however, valid concerns about Chinchilla have been\nraised: wide confidence intervals, discrepancies between its three approaches,\nand incongruities with other scaling laws. This raises a critical question for\nthe field: Can practitioners still rely on Chinchilla's prescriptions? Our work\ndemonstrates the answer is yes. We begin by uncovering that the model\nparameters central to Chinchilla's analyses were ambiguous: three\ninterpretations are possible, with relative differences between different\ninterpretations of model parameters as high as 15.2%. We find that, perhaps\nsurprisingly, which model parameters are used for the analyses do not\nmeaningfully affect key results: the scaling law estimates and the\ncompute-optimal tokens-to-parameter ratio. Indeed, under one interpretation,\nthe tokens-to-parameter ratio becomes more constant with the target compute\nbudget. We then ask how distorted the Chinchilla model parameters could have\nbeen without meaningfully affecting the key results. By deliberately perturbing\nmodel parameters in four structured ways, we find that key Chinchilla results\nare most sensitive to additive or systematic errors, which can alter the\notherwise flat trend of the optimal tokens-to-parameter ratio, but overall,\nChinchilla's key results withstand sizable perturbations. Altogether, our\nfindings offer the field renewed confidence in Chinchilla as a durable guide\nfor scaling language models."}
{"id": "2509.23964", "pdf": "https://arxiv.org/pdf/2509.23964", "abs": "https://arxiv.org/abs/2509.23964", "authors": ["Dang Huu-Tien", "Naoya Inoue"], "title": "Detecting and Rectifying Noisy Labels: A Similarity-based Approach", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Label noise in datasets could damage the performance of neural net training.\nAs the size of modern deep networks grows, there is a growing demand for\nautomated tools for detecting such errors. In this paper, we propose post-hoc,\nmodel-agnostic error detection and rectification methods utilizing the\npenultimate feature from a neural network. Our idea is based on the observation\nthat the similarity between the penultimate feature of a mislabeled data point\nand its true class data points is higher than that for data points from other\nclasses, making the probability of label occurrence within a tight, similar\ncluster informative for detecting and rectifying errors. Extensive experiments\nshow our method not only demonstrates high performance across various noises\nbut also automatically rectifies these errors to improve the quality of\ndatasets."}
{"id": "2509.23976", "pdf": "https://arxiv.org/pdf/2509.23976", "abs": "https://arxiv.org/abs/2509.23976", "authors": ["Maruf Ahmed Mridul", "Oshani Seneviratne"], "title": "Curriculum-Guided Reinforcement Learning for Synthesizing Gas-Efficient Financial Derivatives Contracts", "categories": ["cs.LG"], "comment": "8 pages, 3 figures, 2 tables", "summary": "Smart contract-based automation of financial derivatives offers substantial\nefficiency gains, but its real-world adoption is constrained by the complexity\nof translating financial specifications into gas-efficient executable code. In\nparticular, generating code that is both functionally correct and economically\nviable from high-level specifications, such as the Common Domain Model (CDM),\nremains a significant challenge. This paper introduces a Reinforcement Learning\n(RL) framework to generate functional and gas-optimized Solidity smart\ncontracts directly from CDM specifications. We employ a Proximal Policy\nOptimization (PPO) agent that learns to select optimal code snippets from a\npre-defined library. To manage the complex search space, a two-phase curriculum\nfirst trains the agent for functional correctness before shifting its focus to\ngas optimization. Our empirical results show the RL agent learns to generate\ncontracts with significant gas savings, achieving cost reductions of up to\n35.59% on unseen test data compared to unoptimized baselines. This work\npresents a viable methodology for the automated synthesis of reliable and\neconomically sustainable smart contracts, bridging the gap between high-level\nfinancial agreements and efficient on-chain execution."}
{"id": "2509.23992", "pdf": "https://arxiv.org/pdf/2509.23992", "abs": "https://arxiv.org/abs/2509.23992", "authors": ["Amartya Roy", "Devharish N", "Shreya Ganguly", "Kripabandhu Ghosh"], "title": "Guide: Generalized-Prior and Data Encoders for DAG Estimation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Modern causal discovery methods face critical limitations in scalability,\ncomputational efficiency, and adaptability to mixed data types, as evidenced by\nbenchmarks on node scalability (30, $\\le 50$, $\\ge 70$ nodes), computational\nenergy demands, and continuous/non-continuous data handling. While traditional\nalgorithms like PC, GES, and ICA-LiNGAM struggle with these challenges,\nexhibiting prohibitive energy costs for higher-order nodes and poor scalability\nbeyond 70 nodes, we propose \\textbf{GUIDE}, a framework that integrates Large\nLanguage Model (LLM)-generated adjacency matrices with observational data\nthrough a dual-encoder architecture. GUIDE uniquely optimizes computational\nefficiency, reducing runtime on average by $\\approx 42%$ compared to RL-BIC and\nKCRL methods, while achieving an average $\\approx 117%$ improvement in accuracy\nover both NOTEARS and GraN-DAG individually. During training, GUIDE's\nreinforcement learning agent dynamically balances reward maximization\n(accuracy) and penalty avoidance (DAG constraints), enabling robust performance\nacross mixed data types and scalability to $\\ge 70$ nodes -- a setting where\nbaseline methods fail."}
{"id": "2509.24005", "pdf": "https://arxiv.org/pdf/2509.24005", "abs": "https://arxiv.org/abs/2509.24005", "authors": ["Chenruo Liu", "Yijun Dong", "Qi Lei"], "title": "Does Weak-to-strong Generalization Happen under Spurious Correlations?", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We initiate a unified theoretical and algorithmic study of a key problem in\nweak-to-strong (W2S) generalization: when fine-tuning a strong pre-trained\nstudent with pseudolabels from a weaker teacher on a downstream task with\nspurious correlations, does W2S happen, and how to improve it upon failures? We\nconsider two sources of spurious correlations caused by group imbalance: (i) a\nweak teacher fine-tuned on group-imbalanced labeled data with a minority group\nof fraction $\\eta_\\ell$, and (ii) a group-imbalanced unlabeled set\npseudolabeled by the teacher with a minority group of fraction $\\eta_u$.\nTheoretically, a precise characterization of W2S gain at the proportional\nasymptotic limit shows that W2S always happens with sufficient pseudolabels\nwhen $\\eta_u = \\eta_\\ell$ but may fail when $\\eta_u \\ne \\eta_\\ell$, where W2S\ngain diminishes as $(\\eta_u - \\eta_\\ell)^2$ increases. Our theory is\ncorroborated by extensive experiments on various spurious correlation\nbenchmarks and teacher-student pairs. To boost W2S performance upon failures,\nwe further propose a simple, effective algorithmic remedy that retrains the\nstrong student on its high-confidence data subset after W2S fine-tuning. Our\nalgorithm is group-label-free and achieves consistent, substantial improvements\nover vanilla W2S fine-tuning."}
{"id": "2509.24006", "pdf": "https://arxiv.org/pdf/2509.24006", "abs": "https://arxiv.org/abs/2509.24006", "authors": ["Jintao Zhang", "Haoxu Wang", "Kai Jiang", "Shuo Yang", "Kaiwen Zheng", "Haocheng Xi", "Ziteng Wang", "Hongzhou Zhu", "Min Zhao", "Ion Stoica", "Joseph E. Gonzalez", "Jun Zhu", "Jianfei Chen"], "title": "SLA: Beyond Sparsity in Diffusion Transformers via Fine-Tunable Sparse-Linear Attention", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "In Diffusion Transformer (DiT) models, particularly for video generation,\nattention latency is a major bottleneck due to the long sequence length and the\nquadratic complexity. We find that attention weights can be separated into two\nparts: a small fraction of large weights with high rank and the remaining\nweights with very low rank. This naturally suggests applying sparse\nacceleration to the first part and low-rank acceleration to the second. Based\non this finding, we propose SLA (Sparse-Linear Attention), a trainable\nattention method that fuses sparse and linear attention to accelerate diffusion\nmodels. SLA classifies attention weights into critical, marginal, and\nnegligible categories, applying O(N^2) attention to critical weights, O(N)\nattention to marginal weights, and skipping negligible ones. SLA combines these\ncomputations into a single GPU kernel and supports both forward and backward\npasses. With only a few fine-tuning steps using SLA, DiT models achieve a 20x\nreduction in attention computation, resulting in significant acceleration\nwithout loss of generation quality. Experiments show that SLA reduces attention\ncomputation by 95% without degrading end-to-end generation quality,\noutperforming baseline methods. In addition, we implement an efficient GPU\nkernel for SLA, which yields a 13.7x speedup in attention computation and a\n2.2x end-to-end speedup in video generation on Wan2.1-1.3B."}
{"id": "2509.24012", "pdf": "https://arxiv.org/pdf/2509.24012", "abs": "https://arxiv.org/abs/2509.24012", "authors": ["Rylan Schaeffer", "Noam Levi", "Brando Miranda", "Sanmi Koyejo"], "title": "Pretraining Scaling Laws for Generative Evaluations of Language Models", "categories": ["cs.LG"], "comment": null, "summary": "Neural scaling laws have played a central role in modern machine learning,\ndriving the field's ever-expanding scaling of parameters, data and compute.\nWhile much research has gone into fitting scaling laws and predicting\nperformance on pretraining losses and on discriminative evaluations such as\nmultiple-choice question-answering, comparatively little research has been done\non fitting scaling laws and predicting performance on generative evaluations\nsuch as mathematical problem-solving or software engineering. We propose and\nevaluate three different pretraining scaling laws for fitting pass-at-$k$ on\ngenerative evaluations and for predicting pass-at-$k$ of the most expensive\nmodel using the performance of cheaper models. Our three scaling laws differ in\nthe covariates used: (1) compute, (2) model parameters and tokens, (3) log\nlikelihoods of gold reference solutions. We make four main contributions: (1)\nWe show how generative evaluations offer new hyperparameters (in our setting,\n$k$) that researchers can use to control the scaling laws parameters and the\npredictability of performance. (2) In terms of scaling law parameters, we find\nthat the compute scaling law and parameters\\,+\\,tokens scaling law stabilize\nfor the last ~$1.5{-}2.5$ orders of magnitude, whereas the gold reference\nlikelihood scaling law stabilizes for the last ~$5$ orders of magnitude. (3) In\nterms of predictive performance, we find all three scaling laws perform\ncomparably, although the compute scaling law predicts slightly worse for small\n$k$ and the log likelihoods of gold reference solutions predicts slightly worse\nfor large $k$. (4) We establish a theoretical connection that the compute\nscaling law emerges as the compute-optimal envelope of the\nparameters-and-tokens scaling law. Our framework provides researchers and\npractitioners with insights and methodologies to forecast generative\nperformance."}
{"id": "2509.24031", "pdf": "https://arxiv.org/pdf/2509.24031", "abs": "https://arxiv.org/abs/2509.24031", "authors": ["Umang Garg", "Bowen Zhang", "Anantanjit Subrahmanya", "Chandrakanth Gudavalli", "BS Manjunath"], "title": "GPS-MTM: Capturing Pattern of Normalcy in GPS-Trajectories with self-supervised learning", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.MA"], "comment": "4 pages, 2 figures", "summary": "Foundation models have driven remarkable progress in text, vision, and video\nunderstanding, and are now poised to unlock similar breakthroughs in trajectory\nmodeling. We introduce the GPSMasked Trajectory Transformer (GPS-MTM), a\nfoundation model for large-scale mobility data that captures patterns of\nnormalcy in human movement. Unlike prior approaches that flatten trajectories\ninto coordinate streams, GPS-MTM decomposes mobility into two complementary\nmodalities: states (point-of-interest categories) and actions (agent\ntransitions). Leveraging a bi-directional Transformer with a self-supervised\nmasked modeling objective, the model reconstructs missing segments across\nmodalities, enabling it to learn rich semantic correlations without manual\nlabels. Across benchmark datasets, including Numosim-LA, Urban Anomalies, and\nGeolife, GPS-MTM consistently outperforms on downstream tasks such as\ntrajectory infilling and next-stop prediction. Its advantages are most\npronounced in dynamic tasks (inverse and forward dynamics), where contextual\nreasoning is critical. These results establish GPS-MTM as a robust foundation\nmodel for trajectory analytics, positioning mobility data as a first-class\nmodality for large-scale representation learning. Code is released for further\nreference."}
{"id": "2509.24047", "pdf": "https://arxiv.org/pdf/2509.24047", "abs": "https://arxiv.org/abs/2509.24047", "authors": ["Runyu Zhang", "Na Li", "Asuman Ozdaglar", "Jeff Shamma", "Gioele Zardini"], "title": "Optimism as Risk-Seeking in Multi-Agent Reinforcement Learning", "categories": ["cs.LG", "cs.SY", "eess.SY", "math.OC"], "comment": null, "summary": "Risk sensitivity has become a central theme in reinforcement learning (RL),\nwhere convex risk measures and robust formulations provide principled ways to\nmodel preferences beyond expected return. Recent extensions to multi-agent RL\n(MARL) have largely emphasized the risk-averse setting, prioritizing robustness\nto uncertainty. In cooperative MARL, however, such conservatism often leads to\nsuboptimal equilibria, and a parallel line of work has shown that optimism can\npromote cooperation. Existing optimistic methods, though effective in practice,\nare typically heuristic and lack theoretical grounding. Building on the dual\nrepresentation for convex risk measures, we propose a principled framework that\ninterprets risk-seeking objectives as optimism. We introduce optimistic value\nfunctions, which formalize optimism as divergence-penalized risk-seeking\nevaluations. Building on this foundation, we derive a policy-gradient theorem\nfor optimistic value functions, including explicit formulas for the entropic\nrisk/KL-penalty setting, and develop decentralized optimistic actor-critic\nalgorithms that implement these updates. Empirical results on cooperative\nbenchmarks demonstrate that risk-seeking optimism consistently improves\ncoordination over both risk-neutral baselines and heuristic optimistic methods.\nOur framework thus unifies risk-sensitive learning and optimism, offering a\ntheoretically grounded and practically effective approach to cooperation in\nMARL."}
{"id": "2509.24050", "pdf": "https://arxiv.org/pdf/2509.24050", "abs": "https://arxiv.org/abs/2509.24050", "authors": ["Wenzhi Fang", "Dong-Jun Han", "Liangqi Yuan", "Christopher Brinton"], "title": "Collaborative Device-Cloud LLM Inference through Reinforcement Learning", "categories": ["cs.LG"], "comment": "We propose a unified post-training framework that integrates routing\n  optimization, enabling the on-device LLM to improve its problem-solving\n  ability while learning routing strategies", "summary": "Device-cloud collaboration has emerged as a promising paradigm for deploying\nlarge language models (LLMs), combining the efficiency of lightweight on-device\ninference with the superior performance of powerful cloud LLMs. An essential\nproblem in this scenario lies in deciding whether a given query is best handled\nlocally or delegated to the cloud. Existing approaches typically rely on\nexternal routers, implemented as binary classifiers, which often struggle to\ndetermine task difficulty from the prompt's surface pattern. To address these\nlimitations, we propose a framework where the on-device LLM makes routing\ndecisions at the end of its solving process, with this capability instilled\nthrough post-training. In particular, we formulate a reward maximization\nproblem with carefully designed rewards that encourage effective problem\nsolving and judicious offloading to the cloud. To solve this problem, we\ndevelop a group-adaptive policy gradient algorithm, featuring a group-level\npolicy gradient, designed to yield an unbiased gradient estimator of the\nreward, and adaptive prompt filtering, developed to enforce the constraint on\ncloud LLM usage. Extensive experiments across models and benchmarks show that\nthe proposed methodology consistently outperforms existing baselines and\nsignificantly narrows the gap to full cloud LLM performance."}
{"id": "2509.24058", "pdf": "https://arxiv.org/pdf/2509.24058", "abs": "https://arxiv.org/abs/2509.24058", "authors": ["Julia Wenkmann", "Damien Garreau"], "title": "On The Variability of Concept Activation Vectors", "categories": ["cs.LG", "stat.ML"], "comment": "26 pages (including appendix), 24 figures (44 panels). Submitted to\n  AAAI-26", "summary": "One of the most pressing challenges in artificial intelligence is to make\nmodels more transparent to their users. Recently, explainable artificial\nintelligence has come up with numerous method to tackle this challenge. A\npromising avenue is to use concept-based explanations, that is, high-level\nconcepts instead of plain feature importance score. Among this class of\nmethods, Concept Activation vectors (CAVs), Kim et al. (2018) stands out as one\nof the main protagonists. One interesting aspect of CAVs is that their\ncomputation requires sampling random examples in the train set. Therefore, the\nactual vectors obtained may vary from user to user depending on the randomness\nof this sampling. In this paper, we propose a fine-grained theoretical analysis\nof CAVs construction in order to quantify their variability. Our results,\nconfirmed by experiments on several real-life datasets, point out towards an\nuniversal result: the variance of CAVs decreases as $1/N$, where $N$ is the\nnumber of random examples. Based on this we give practical recommendations for\na resource-efficient application of the method."}
{"id": "2509.24067", "pdf": "https://arxiv.org/pdf/2509.24067", "abs": "https://arxiv.org/abs/2509.24067", "authors": ["Qiushui Xu", "Yuhao Huang", "Yushu Jiang", "Lei Song", "Jinyu Wang", "Wenliang Zheng", "Jiang Bian"], "title": "In-Context Compositional Q-Learning for Offline Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Accurately estimating the Q-function is a central challenge in offline\nreinforcement learning. However, existing approaches often rely on a single\nglobal Q-function, which struggles to capture the compositional nature of tasks\ninvolving diverse subtasks. We propose In-context Compositional Q-Learning\n(\\texttt{ICQL}), the first offline RL framework that formulates Q-learning as a\ncontextual inference problem, using linear Transformers to adaptively infer\nlocal Q-functions from retrieved transitions without explicit subtask labels.\nTheoretically, we show that under two assumptions--linear approximability of\nthe local Q-function and accurate weight inference from retrieved\ncontext--\\texttt{ICQL} achieves bounded Q-function approximation error, and\nsupports near-optimal policy extraction. Empirically, \\texttt{ICQL}\nsubstantially improves performance in offline settings: improving performance\nin kitchen tasks by up to 16.4\\%, and in Gym and Adroit tasks by up to 8.6\\%\nand 6.3\\%. These results highlight the underexplored potential of in-context\nlearning for robust and compositional value estimation, positioning\n\\texttt{ICQL} as a principled and effective framework for offline RL."}
{"id": "2509.24068", "pdf": "https://arxiv.org/pdf/2509.24068", "abs": "https://arxiv.org/abs/2509.24068", "authors": ["Roussel Rahman", "Jeff Shrager"], "title": "A Small Math Model: Recasting Strategy Choice Theory in an LLM-Inspired Architecture", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Strategy Choice Theory (SCT)\\footnote{``Strategy Choice Theory'',\n``Distributions of Associations'', and ``Overlapping Wave Theory'' have been\nused to refer to this line of work, emphasizing different\naspects.}\\citep[e.g.,][]{siegler1984strategychoices, siegler2000rebirth}\nexplains important aspects of children's arithmetic learning based upon\nprinciples including learning from developmentally naturalistic data,\nprobabilistic representation, confidence-based retrieval, and the phase-like\nimportance of scaffolding strategies, such as finger-counting. Here we recast\nSCT as a ``Small Math Model'' (SMM), employing a neural-network-based\narchitecture analogous to LLMs. The SMM extends SCT to include counting\npractice\\footnote{The original SCT model was pre-biased in accordance with the\nsupposed experience of counting.}, symbol (number) embedding, and gated\nattention. Similar to earlier work, the SMM demonstrates constructive and\ndestructive interference between counting and addition, and the ``wave-like''\nuse of finger-counting as sum recall improves. We plan to extend the SMM to\nlater aspects of the decades-long SCT program, including adaptive strategy\nchoice and eventually strategy discovery, providing a unified platform to\ninvestigate the understanding of numerical characteristics and relationships\nessential for mathematical reasoning -- as it can emerge in LLM-based agents."}
{"id": "2509.24069", "pdf": "https://arxiv.org/pdf/2509.24069", "abs": "https://arxiv.org/abs/2509.24069", "authors": ["Youssef Sabiri", "Walid Houmaidi", "Ouail El Maadi", "Yousra Chtouki"], "title": "AQUAIR: A High-Resolution Indoor Environmental Quality Dataset for Smart Aquaculture Monitoring", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.AP", "62M10, 68T45, 62P35, 92C40, 65C20, 60G35, 92C42, 92C35, 93E10", "I.2.6; C.2.4; H.3.4; I.2.4; H.3.5; C.2.4; C.3; I.4.8; I.5.1; J.3;\n  K.6.1; H.2.8"], "comment": "6 pages, 6 figures, 3 tables. Accepted at the 9th IEEE Global\n  Conference on Artificial Intelligence & Internet of Things (IEEE GCAIoT)\n  2025. Final camera-ready manuscript. Math expressions in this field are\n  rendered via MathJax", "summary": "Smart aquaculture systems depend on rich environmental data streams to\nprotect fish welfare, optimize feeding, and reduce energy use. Yet public\ndatasets that describe the air surrounding indoor tanks remain scarce, limiting\nthe development of forecasting and anomaly-detection tools that couple\nhead-space conditions with water-quality dynamics. We therefore introduce\nAQUAIR, an open-access public dataset that logs six Indoor Environmental\nQuality (IEQ) variables--air temperature, relative humidity, carbon dioxide,\ntotal volatile organic compounds, PM2.5 and PM10--inside a fish aquaculture\nfacility in Amghass, Azrou, Morocco. A single Awair HOME monitor sampled every\nfive minutes from 14 October 2024 to 9 January 2025, producing more than 23,000\ntime-stamped observations that are fully quality-controlled and publicly\narchived on Figshare. We describe the sensor placement, ISO-compliant mounting\nheight, calibration checks against reference instruments, and an open-source\nprocessing pipeline that normalizes timestamps, interpolates short gaps, and\nexports analysis-ready tables. Exploratory statistics show stable conditions\n(median CO2 = 758 ppm; PM2.5 = 12 micrograms/m3) with pronounced feeding-time\npeaks, offering rich structure for short-horizon forecasting, event detection,\nand sensor drift studies. AQUAIR thus fills a critical gap in smart aquaculture\ninformatics and provides a reproducible benchmark for data-centric machine\nlearning curricula and environmental sensing research focused on head-space\ndynamics in recirculating aquaculture systems."}
{"id": "2509.24076", "pdf": "https://arxiv.org/pdf/2509.24076", "abs": "https://arxiv.org/abs/2509.24076", "authors": ["Bo Hu", "José C. Príncipe"], "title": "A Family of Kernelized Matrix Costs for Multiple-Output Mixture Neural Networks", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Pairwise distance-based costs are crucial for self-supervised and contrastive\nfeature learning. Mixture Density Networks (MDNs) are a widely used approach\nfor generative models and density approximation, using neural networks to\nproduce multiple centers that define a Gaussian mixture. By combining MDNs with\ncontrastive costs, this paper proposes data density approximation using four\ntypes of kernelized matrix costs: the scalar cost, the vector-matrix cost, the\nmatrix-matrix cost (the trace of Schur complement), and the SVD cost (the\nnuclear norm), for learning multiple centers required to define a mixture\ndensity."}
{"id": "2509.24077", "pdf": "https://arxiv.org/pdf/2509.24077", "abs": "https://arxiv.org/abs/2509.24077", "authors": ["Zhongteng Cai", "Mohammad Mahdi Khalili", "Xueru Zhang"], "title": "Demographic-Agnostic Fairness without Harm", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "As machine learning (ML) algorithms are increasingly used in social domains\nto make predictions about humans, there is a growing concern that these\nalgorithms may exhibit biases against certain social groups. Numerous notions\nof fairness have been proposed in the literature to measure the unfairness of\nML. Among them, one class that receives the most attention is\n\\textit{parity-based}, i.e., achieving fairness by equalizing treatment or\noutcomes for different social groups. However, achieving parity-based fairness\noften comes at the cost of lowering model accuracy and is undesirable for many\nhigh-stakes domains like healthcare. To avoid inferior accuracy, a line of\nresearch focuses on \\textit{preference-based} fairness, under which any group\nof individuals would experience the highest accuracy and collectively prefer\nthe ML outcomes assigned to them if they were given the choice between various\nsets of outcomes. However, these works assume individual demographic\ninformation is known and fully accessible during training. In this paper, we\nrelax this requirement and propose a novel \\textit{demographic-agnostic\nfairness without harm (DAFH)} optimization algorithm, which jointly learns a\ngroup classifier that partitions the population into multiple groups and a set\nof decoupled classifiers associated with these groups. Theoretically, we\nconduct sample complexity analysis and show that our method can outperform the\nbaselines when demographic information is known and used to train decoupled\nclassifiers. Experiments on both synthetic and real data validate the proposed\nmethod."}
{"id": "2509.24085", "pdf": "https://arxiv.org/pdf/2509.24085", "abs": "https://arxiv.org/abs/2509.24085", "authors": ["Ju-Hyung Lee", "Yanqing Lu", "Klaus Doppler"], "title": "PEARL: Peer-Enhanced Adaptive Radio via On-Device LLM", "categories": ["cs.LG", "cs.AI", "cs.NI", "eess.SP"], "comment": null, "summary": "We present PEARL (Peer-Enhanced Adaptive Radio via On-Device LLM), a\nframework for cooperative cross-layer optimization in device-to-device (D2D)\ncommunication. Building on our previous work on single-device on-device LLMs,\nPEARL extends the paradigm by leveraging both publisher and subscriber states\nto guide Wi-Fi Aware (WA) parameter selection. A context-aware reward, which\nnormalizes latency by application tolerances and modulates energy by device\nbattery states, provides richer supervision for KL-based finetuning. We study\ntwo lightweight variants: PEARL (Head + Low-Rank Adaptation (LoRA)) achieves\nthe best overall performance, while PEARL-Lite (Head-only) delivers sub-20 ms\ninference at near-identical objective scores. Across synthetic scenarios\ngrounded in real measurements, PEARL improves objective scores over heuristic\nand compact model baselines and reduces energy by up to 16% in cooperative\nlow-battery cases. These results demonstrate that peer-aware context,\nreward-aligned training, and head-based efficiency make LLMs practical for\nalways-on, on-device cross-layer control."}
{"id": "2509.24093", "pdf": "https://arxiv.org/pdf/2509.24093", "abs": "https://arxiv.org/abs/2509.24093", "authors": ["Owen Lewis Howell", "Linfeng Zhao", "Xupeng Zhu", "Yaoyao Qian", "Haojie Huang", "Lingfeng Sun", "Wil Thomason", "Robert Platt", "Robin Walters"], "title": "Clebsch-Gordan Transformer: Fast and Global Equivariant Attention", "categories": ["cs.LG", "cs.CV", "cs.RO"], "comment": null, "summary": "The global attention mechanism is one of the keys to the success of\ntransformer architecture, but it incurs quadratic computational costs in\nrelation to the number of tokens. On the other hand, equivariant models, which\nleverage the underlying geometric structures of problem instance, often achieve\nsuperior accuracy in physical, biochemical, computer vision, and robotic tasks,\nat the cost of additional compute requirements. As a result, existing\nequivariant transformers only support low-order equivariant features and local\ncontext windows, limiting their expressiveness and performance. This work\nproposes Clebsch-Gordan Transformer, achieving efficient global attention by a\nnovel Clebsch-Gordon Convolution on $\\SO(3)$ irreducible representations. Our\nmethod enables equivariant modeling of features at all orders while achieving\n${O}(N \\log N)$ input token complexity. Additionally, the proposed method\nscales well with high-order irreducible features, by exploiting the sparsity of\nthe Clebsch-Gordon matrix. Lastly, we also incorporate optional token\npermutation equivariance through either weight sharing or data augmentation. We\nbenchmark our method on a diverse set of benchmarks including n-body\nsimulation, QM9, ModelNet point cloud classification and a robotic grasping\ndataset, showing clear gains over existing equivariant transformers in GPU\nmemory size, speed, and accuracy."}
{"id": "2509.24115", "pdf": "https://arxiv.org/pdf/2509.24115", "abs": "https://arxiv.org/abs/2509.24115", "authors": ["Evan Dramko", "Yihuang Xiong", "Yizhi Zhu", "Geoffroy Hautier", "Thomas Reps", "Christopher Jermaine", "Anastasios Kyrillidis"], "title": "ADAPT: Lightweight, Long-Range Machine Learning Force Fields Without Graphs", "categories": ["cs.LG", "cond-mat.mtrl-sci", "math.OC", "68Q32 (Primary), 68T07 (Secondary)"], "comment": "14 total pages of main content, 4 of references, 3 in Appendix", "summary": "Point defects play a central role in driving the properties of materials.\nFirst-principles methods are widely used to compute defect energetics and\nstructures, including at scale for high-throughput defect databases. However,\nthese methods are computationally expensive, making machine-learning force\nfields (MLFFs) an attractive alternative for accelerating structural\nrelaxations. Most existing MLFFs are based on graph neural networks (GNNs),\nwhich can suffer from oversmoothing and poor representation of long-range\ninteractions. Both of these issues are especially of concern when modeling\npoint defects. To address these challenges, we introduce the Accelerated Deep\nAtomic Potential Transformer (ADAPT), an MLFF that replaces graph\nrepresentations with a direct coordinates-in-space formulation and explicitly\nconsiders all pairwise atomic interactions. Atoms are treated as tokens, with a\nTransformer encoder modeling their interactions. Applied to a dataset of\nsilicon point defects, ADAPT achieves a roughly 33 percent reduction in both\nforce and energy prediction errors relative to a state-of-the-art GNN-based\nmodel, while requiring only a fraction of the computational cost."}
{"id": "2509.24117", "pdf": "https://arxiv.org/pdf/2509.24117", "abs": "https://arxiv.org/abs/2509.24117", "authors": ["Sifan Wang", "Zhikai Wu", "David van Dijk", "Lu Lu"], "title": "GeoFunFlow: Geometric Function Flow Matching for Inverse Operator Learning over Complex Geometries", "categories": ["cs.LG", "physics.comp-ph", "stat.ML"], "comment": "26 pages, 13 figures, 9 tables", "summary": "Inverse problems governed by partial differential equations (PDEs) are\ncrucial in science and engineering. They are particularly challenging due to\nill-posedness, data sparsity, and the added complexity of irregular geometries.\nClassical PDE-constrained optimization methods are computationally expensive,\nespecially when repeated posterior sampling is required. Learning-based\napproaches improve efficiency and scalability, yet most are designed for\nregular domains or focus on forward modeling. Here, we introduce {\\em\nGeoFunFlow}, a geometric diffusion model framework for inverse problems on\ncomplex geometries. GeoFunFlow combines a novel geometric function autoencoder\n(GeoFAE) and a latent diffusion model trained via rectified flow. GeoFAE\nemploys a Perceiver module to process unstructured meshes of varying sizes and\nproduces continuous reconstructions of physical fields, while the diffusion\nmodel enables posterior sampling from sparse and noisy data. Across five\nbenchmarks, GeoFunFlow achieves state-of-the-art reconstruction accuracy over\ncomplex geometries, provides calibrated uncertainty quantification, and\ndelivers efficient inference compared to operator-learning and diffusion model\nbaselines."}
{"id": "2509.24118", "pdf": "https://arxiv.org/pdf/2509.24118", "abs": "https://arxiv.org/abs/2509.24118", "authors": ["Md Mozaharul Mottalib", "Thao-Ly T. Phan", "Rahmatollah Beheshti"], "title": "HyMaTE: A Hybrid Mamba and Transformer Model for EHR Representation Learning", "categories": ["cs.LG"], "comment": null, "summary": "Electronic health Records (EHRs) have become a cornerstone in modern-day\nhealthcare. They are a crucial part for analyzing the progression of patient\nhealth; however, their complexity, characterized by long, multivariate\nsequences, sparsity, and missing values poses significant challenges in\ntraditional deep learning modeling. While Transformer-based models have\ndemonstrated success in modeling EHR data and predicting clinical outcomes,\ntheir quadratic computational complexity and limited context length hinder\ntheir efficiency and practical applications. On the other hand, State Space\nModels (SSMs) like Mamba present a promising alternative offering linear-time\nsequence modeling and improved efficiency for handling long sequences, but\nfocus mostly on mixing sequence-level information rather than channel-level\ndata. To overcome these challenges, we propose HyMaTE (A Hybrid Mamba and\nTransformer Model for EHR Representation Learning), a novel hybrid model\ntailored for representing longitudinal data, combining the strengths of SSMs\nwith advanced attention mechanisms. By testing the model on predictive tasks on\nmultiple clinical datasets, we demonstrate HyMaTE's ability to capture an\neffective, richer, and more nuanced unified representation of EHR data.\nAdditionally, the interpretability of the outcomes achieved by self-attention\nillustrates the effectiveness of our model as a scalable and generalizable\nsolution for real-world healthcare applications. Codes are available at:\nhttps://github.com/healthylaife/HyMaTE."}
{"id": "2509.24122", "pdf": "https://arxiv.org/pdf/2509.24122", "abs": "https://arxiv.org/abs/2509.24122", "authors": ["Hongbo Liu", "Jia Xu"], "title": "Echo Flow Networks", "categories": ["cs.LG"], "comment": "Under Review", "summary": "At the heart of time-series forecasting (TSF) lies a fundamental challenge:\nhow can models efficiently and effectively capture long-range temporal\ndependencies across ever-growing sequences? While deep learning has brought\nnotable progress, conventional architectures often face a trade-off between\ncomputational complexity and their ability to retain accumulative information\nover extended horizons.\n  Echo State Networks (ESNs), a class of reservoir computing models, have\nrecently regained attention for their exceptional efficiency, offering constant\nmemory usage and per-step training complexity regardless of input length. This\nmakes them particularly attractive for modeling extremely long-term event\nhistory in TSF. However, traditional ESNs fall short of state-of-the-art\nperformance due to their limited nonlinear capacity, which constrains both\ntheir expressiveness and stability.\n  We introduce Echo Flow Networks (EFNs), a framework composed of a group of\nextended Echo State Networks (X-ESNs) with MLP readouts, enhanced by our novel\nMatrix-Gated Composite Random Activation (MCRA), which enables complex,\nneuron-specific temporal dynamics, significantly expanding the network's\nrepresentational capacity without compromising computational efficiency. In\naddition, we propose a dual-stream architecture in which recent input history\ndynamically selects signature reservoir features from an infinite-horizon\nmemory, leading to improved prediction accuracy and long-term stability.\n  Extensive evaluations on five benchmarks demonstrate that EFNs achieve up to\n4x faster training and 3x smaller model size compared to leading methods like\nPatchTST, reducing forecasting error from 43% to 35%, a 20% relative\nimprovement. One instantiation of our framework, EchoFormer, consistently\nachieves new state-of-the-art performance across five benchmark datasets: ETTh,\nETTm, DMV, Weather, and Air Quality."}
{"id": "2509.24125", "pdf": "https://arxiv.org/pdf/2509.24125", "abs": "https://arxiv.org/abs/2509.24125", "authors": ["Rohan Alur", "Chris Hays", "Manish Raghavan", "Devavrat Shah"], "title": "The Impossibility of Inverse Permutation Learning in Transformer Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In this technical note, we study the problem of inverse permutation learning\nin decoder-only transformers. Given a permutation and a string to which that\npermutation has been applied, the model is tasked with producing the original\n(``canonical'') string. We argue that this task models a natural robustness\nproperty across a variety of reasoning tasks, including long-context retrieval,\nmultiple choice QA and in-context learning. Our primary contribution is an\nimpossibility result: we show that an arbitrary depth, decoder-only transformer\ncannot learn this task. This result concerns the expressive capacity of\ndecoder-only transformer models and is agnostic to training dynamics or sample\ncomplexity. We give a pair of alternative constructions under which inverse\npermutation learning is feasible. The first of these highlights the fundamental\nrole of the causal attention mask, and reveals a gap between the expressivity\nof encoder-decoder transformers and the more popular decoder-only architecture.\nThe latter result is more surprising: we show that simply padding the input\nwith ``scratch tokens\" yields a construction under which inverse permutation\nlearning is possible. We conjecture that this may suggest an alternative\nmechanism by which chain-of-thought prompting or, more generally, intermediate\n``thinking'' tokens can enable reasoning in large language models, even when\nthese tokens encode no meaningful semantic information (e.g., the results of\nintermediate computations)."}
{"id": "2509.24140", "pdf": "https://arxiv.org/pdf/2509.24140", "abs": "https://arxiv.org/abs/2509.24140", "authors": ["H. N. Mhaskar", "Ryan O'Dowd"], "title": "A signal separation view of classification", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "The problem of classification in machine learning has often been approached\nin terms of function approximation. In this paper, we propose an alternative\napproach for classification in arbitrary compact metric spaces which, in\ntheory, yields both the number of classes, and a perfect classification using a\nminimal number of queried labels. Our approach uses localized trigonometric\npolynomial kernels initially developed for the point source signal separation\nproblem in signal processing. Rather than point sources, we argue that the\nvarious classes come from different probability distributions. The localized\nkernel technique developed for separating point sources is then shown to\nseparate the supports of these distributions. This is done in a hierarchical\nmanner in our MASC algorithm to accommodate touching/overlapping class\nboundaries. We illustrate our theory on several simulated and real life\ndatasets, including the Salinas and Indian Pines hyperspectral datasets and a\ndocument dataset."}
{"id": "2509.24146", "pdf": "https://arxiv.org/pdf/2509.24146", "abs": "https://arxiv.org/abs/2509.24146", "authors": ["Ethan Zachary Lo", "Dan Chie-Tien Lo"], "title": "Evaluation of Machine and Deep Learning Techniques for Cyclone Trajectory Regression and Status Classification by Time Series Data", "categories": ["cs.LG"], "comment": null, "summary": "Accurate cyclone forecasting is essential for minimizing loss of life,\ninfrastructure damage, and economic disruption. Traditional numerical weather\nprediction models, though effective, are computationally intensive and prone to\nerror due to the chaotic nature of atmospheric systems. This study proposes a\nmachine learning (ML) approach to forecasting tropical cyclone trajectory and\nstatus using time series data from the National Hurricane Center, including\nrecently added best track wind radii. A two-stage ML pipeline is developed: a\nregression model first predicts cyclone features maximum wind speed, minimum\npressure, trajectory length, and directional change using a sliding window of\nhistorical data. These outputs are then input into classification models to\npredict the cyclone's categorical status. Gradient boosting regression and\nthree classifiers random forest (RF), support vector machine (SVM), and\nmultilayer perceptron (MLP) are evaluated. After hyperparameter tuning and\nsynthetic minority oversampling (SMOTE), the RF classifier achieves the highest\nperformance with 93% accuracy, outperforming SVM and MLP across precision,\nrecall, and F1 score. The RF model is particularly robust in identifying\nminority cyclone statuses and minimizing false negatives. Regression results\nyield low mean absolute errors, with pressure and wind predictions within about\n2.2 mb and 2.4 kt, respectively. These findings demonstrate that ML models,\nespecially ensemble-based classifiers, offer an effective, scalable alternative\nto traditional forecasting methods, with potential for real-time cyclone\nprediction and integration into decision support systems."}
{"id": "2509.24166", "pdf": "https://arxiv.org/pdf/2509.24166", "abs": "https://arxiv.org/abs/2509.24166", "authors": ["Arpit Garg", "Hemanth Saratchandran", "Ravi Garg", "Simon Lucey"], "title": "Stable Forgetting: Bounded Parameter-Efficient Unlearning in LLMs", "categories": ["cs.LG", "cs.AI"], "comment": "In Submission", "summary": "Machine unlearning in large language models (LLMs) is essential for privacy\nand safety; however, existing approaches remain unstable and unreliable. A\nwidely used strategy, the gradient difference method, applies gradient descent\non retained data while performing gradient ascent on forget data, the data\nwhose influence should be removed. However, when combined with cross-entropy\nloss, this procedure causes unbounded growth of weights and gradients, leading\nto training instability and degrading both forgetting and retention. We provide\na theoretical framework that explains this failure, explicitly showing how\nascent on the forget set destabilizes optimization in the feedforward MLP\nlayers of LLMs. Guided by this insight, we propose Bounded Parameter-Efficient\nUnlearning, a parameter-efficient approach that stabilizes LoRA-based\nfine-tuning by applying bounded functions to MLP adapters. This simple\nmodification controls the weight dynamics during ascent, enabling the gradient\ndifference method to converge reliably. Across the TOFU, TDEC, and MUSE\nbenchmarks, and across architectures and scales from 125M to 8B parameters, our\nmethod achieves substantial improvements in forgetting while preserving\nretention, establishing a novel theoretically grounded and practically scalable\nframework for unlearning in LLMs."}
{"id": "2509.24168", "pdf": "https://arxiv.org/pdf/2509.24168", "abs": "https://arxiv.org/abs/2509.24168", "authors": ["Qipeng Zhan", "Zhuoping Zhou", "Zexuan Wang", "Li Shen"], "title": "Multi-Scale Geometric Autoencoder", "categories": ["cs.LG"], "comment": null, "summary": "Autoencoders have emerged as powerful models for visualization and\ndimensionality reduction based on the fundamental assumption that\nhigh-dimensional data is generated from a low-dimensional manifold. A critical\nchallenge in autoencoder design is to preserve the geometric structure of data\nin the latent space, with existing approaches typically focusing on either\nglobal or local geometric properties separately. Global approaches often\nencounter errors in distance approximation that accumulate, while local methods\nfrequently converge to suboptimal solutions that distort large-scale\nrelationships. We propose Multi-Scale Geometric Autoencoder (MAE), which\nintroduces an asymmetric architecture that simultaneously preserves both scales\nof the geometric structure by applying global distance constraints to the\nencoder and local geometric constraints to the decoder. Through theoretical\nanalysis, we establish that this asymmetric design aligns naturally with the\ndistinct roles of the encoder and decoder components. Our comprehensive\nexperiments on both synthetic manifolds and real-world datasets demonstrate\nthat MAE consistently outperforms existing methods across various evaluation\nmetrics."}
{"id": "2509.24171", "pdf": "https://arxiv.org/pdf/2509.24171", "abs": "https://arxiv.org/abs/2509.24171", "authors": ["Ruibo Chen", "Sheng Zhang", "Yihan Wu", "Tong Zheng", "Peihua Mai", "Heng Huang"], "title": "Model Correlation Detection via Random Selection Probing", "categories": ["cs.LG"], "comment": null, "summary": "The growing prevalence of large language models (LLMs) and vision-language\nmodels (VLMs) has heightened the need for reliable techniques to determine\nwhether a model has been fine-tuned from or is even identical to another.\nExisting similarity-based methods often require access to model parameters or\nproduce heuristic scores without principled thresholds, limiting their\napplicability. We introduce Random Selection Probing (RSP), a\nhypothesis-testing framework that formulates model correlation detection as a\nstatistical test. RSP optimizes textual or visual prefixes on a reference model\nfor a random selection task and evaluates their transferability to a target\nmodel, producing rigorous p-values that quantify evidence of correlation. To\nmitigate false positives, RSP incorporates an unrelated baseline model to\nfilter out generic, transferable features. We evaluate RSP across both LLMs and\nVLMs under diverse access conditions for reference models and test models.\nExperiments on fine-tuned and open-source models show that RSP consistently\nyields small p-values for related models while maintaining high p-values for\nunrelated ones. Extensive ablation studies further demonstrate the robustness\nof RSP. These results establish RSP as the first principled and general\nstatistical framework for model correlation detection, enabling transparent and\ninterpretable decisions in modern machine learning ecosystems."}
{"id": "2509.24176", "pdf": "https://arxiv.org/pdf/2509.24176", "abs": "https://arxiv.org/abs/2509.24176", "authors": ["Chuntian Chi", "John Clapham", "Leslie Cloud", "Ingrid Pretzer-Aboff", "GinaMari Blackwell", "Huajie Shao", "Gang Zhou"], "title": "FM-FoG: A Real-Time Foundation Model-based Wearable System for Freezing-of-Gait Mitigation", "categories": ["cs.LG"], "comment": "This is a preprint version, 12 pages, 7 figures, 8 tables", "summary": "Freezing-of-Gait (FoG) affects over 50% of mid-to-late stage Parkinson's\ndisease (PD) patients, significantly impairing patients' mobility independence\nand reducing quality of life. FoG is characterized by sudden episodes where\nwalking cannot start or is interrupted, occurring exclusively during standing\nor walking, and never while sitting or lying down. Current FoG detection\nsystems require extensive patient-specific training data and lack\ngeneralization, limiting clinical deployment. To address these issues, we\nintroduce FM-FoG, a real-time foundation model-based wearable system achieving\nFoG detection in unseen patients without patient-specific training. Our\napproach combines self-supervised pretraining on diverse Inertial Measurement\nUnit (IMU) datasets with sensor context integration. Since FoG occurs only\nduring ambulatory activities, a lightweight CNN-LSTM activity classifier\nselectively activates the foundation model only during walking or standing,\navoiding unnecessary computation. Evaluated on the VCU FoG-IMU dataset with 23\nPD patients, FM-FoG achieves a 98.5% F1-score when tested on previously unseen\npatients, substantially outperforming competitive baseline methods. Deployed on\na Google Pixel 8a smartphone, the system extends battery life by up to 72%\nwhile maintaining sub-20ms intervention latency. The results indicate that our\nFM-FoG can enable practical, energy-efficient healthcare applications that\ngeneralize across patients without individual training requirements."}
{"id": "2509.24198", "pdf": "https://arxiv.org/pdf/2509.24198", "abs": "https://arxiv.org/abs/2509.24198", "authors": ["Linghao Kong", "Angelina Ning", "Micah Adler", "Nir Shavit"], "title": "Negative Pre-activations Differentiate Syntax", "categories": ["cs.LG"], "comment": "10 pages, 7 figures", "summary": "A recently discovered class of entangled neurons, known as Wasserstein\nneurons, is disproportionately critical in large language models despite\nconstituting only a very small fraction of the network: their targeted removal\ncollapses the model, consistent with their unique role in differentiating\nsimilar inputs. Interestingly, in Wasserstein neurons immediately preceding\nsmooth activation functions, such differentiation manifests in the negative\npre-activation space, especially in early layers. Pairs of similar inputs are\ndriven to highly distinct negative values, and these pairs involve syntactic\ntokens such as determiners and prepositions. We show that this negative region\nis functional rather than simply favorable for optimization. A minimal,\nsign-specific intervention that zeroes only the negative pre-activations of a\nsmall subset of entangled neurons significantly weakens overall model function\nand disrupts grammatical behavior, while both random and perplexity-matched\ncontrols leave grammatical performance largely unchanged. Part of speech\nanalysis localizes the excess surprisal to syntactic scaffolding tokens, and\nlayer-specific interventions reveal that small local degradations accumulate\nacross depth. Over training checkpoints, the same ablation impairs grammatical\nbehavior as Wasserstein neurons emerge and stabilize. Together, these results\nidentify negative differentiation in a sparse subset of entangled neurons as a\ncrucial mechanism that language models rely on for syntax."}
{"id": "2509.24203", "pdf": "https://arxiv.org/pdf/2509.24203", "abs": "https://arxiv.org/abs/2509.24203", "authors": ["Chaorui Yao", "Yanxi Chen", "Yuchang Sun", "Yushuo Chen", "Wenhao Zhang", "Xuchen Pan", "Yaliang Li", "Bolin Ding"], "title": "Group-Relative REINFORCE Is Secretly an Off-Policy Algorithm: Demystifying Some Myths About GRPO and Its Friends", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Off-policy reinforcement learning (RL) for large language models (LLMs) is\nattracting growing interest, driven by practical constraints in real-world\napplications, the complexity of LLM-RL infrastructure, and the need for further\ninnovations of RL methodologies. While classic REINFORCE and its modern\nvariants like Group Relative Policy Optimization (GRPO) are typically regarded\nas on-policy algorithms with limited tolerance of off-policyness, we present in\nthis work a first-principles derivation for group-relative REINFORCE without\nassuming a specific training data distribution, showing that it admits a native\noff-policy interpretation. This perspective yields two general principles for\nadapting REINFORCE to off-policy settings: regularizing policy updates, and\nactively shaping the data distribution. Our analysis demystifies some myths\nabout the roles of importance sampling and clipping in GRPO, unifies and\nreinterprets two recent algorithms -- Online Policy Mirror Descent (OPMD) and\nAsymmetric REINFORCE (AsymRE) -- as regularized forms of the REINFORCE loss,\nand offers theoretical justification for seemingly heuristic data-weighting\nstrategies. Our findings lead to actionable insights that are validated with\nextensive empirical studies, and open up new opportunities for principled\nalgorithm design in off-policy RL for LLMs. Source code for this work is\navailable at\nhttps://github.com/modelscope/Trinity-RFT/tree/main/examples/rec_gsm8k."}
{"id": "2509.24217", "pdf": "https://arxiv.org/pdf/2509.24217", "abs": "https://arxiv.org/abs/2509.24217", "authors": ["Yuyang Sha", "Hongxin Pan", "Gang Luo", "Caijuan Shi", "Jing Wang", "Kefeng Li"], "title": "MDD-Thinker: Towards Large Reasoning Models for Major Depressive Disorder Diagnosis", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "Background Major depressive disorder (MDD) is a leading cause of global\ndisability, yet current diagnostic approaches often rely on subjective\nassessments and lack the ability to integrate multimodal clinical information.\nLarge language models (LLMs) hold promise for enhancing diagnostic accuracy\nthrough advanced reasoning but face challenges in interpretability,\nhallucination, and reliance on synthetic data.\n  Methods We developed MDD-Thinker, an LLM-based diagnostic framework that\nintegrates supervised fine-tuning (SFT) with reinforcement learning (RL) to\nstrengthen reasoning ability and interpretability. Using the UK Biobank\ndataset, we generated 40,000 reasoning samples, supplemented with 10,000\nsamples from publicly available mental health datasets. The model was\nfine-tuned on these reasoning corpora, and its diagnostic and reasoning\nperformance was evaluated against machine learning, deep learning, and\nstate-of-the-art LLM baselines.\n  Findings MDD-Thinker achieved an accuracy of 0.8268 and F1-score of 0.8081,\nsignificantly outperforming traditional baselines such as SVM and MLP, as well\nas general-purpose LLMs. Incorporating both SFT and RL yielded the greatest\nimprovements, with relative gains of 29.0% in accuracy, 38.1% in F1-score, and\n34.8% in AUC. Moreover, the model demonstrated comparable reasoning performance\ncompared to much larger LLMs, while maintaining computational efficiency.\n  Interpretation This study presents the first reasoning-enhanced LLM framework\nfor MDD diagnosis trained on large-scale real-world clinical data. By\nintegrating SFT and RL, MDD-Thinker balances accuracy, interpretability, and\nefficiency, offering a scalable approach for intelligent psychiatric\ndiagnostics. These findings suggest that reasoning-oriented LLMs can provide\nclinically reliable support for MDD detection and may inform broader\napplications in mental health care."}
{"id": "2509.24218", "pdf": "https://arxiv.org/pdf/2509.24218", "abs": "https://arxiv.org/abs/2509.24218", "authors": ["Junjie Wang", "Pan Zhou", "Yiming Dong", "Huan Li", "Jia Li", "Xun Zhou", "Qicheng Lao", "Cong Fang", "Zhouchen Lin"], "title": "Conda: Column-Normalized Adam for Training Large Language Models Faster", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have demonstrated impressive generalization and\nemergent capabilities, yet their pre-training remains computationally expensive\nand sensitive to optimization dynamics. While Adam-based optimizers offer fast\nconvergence by adapting learning rates coordinate-wise, recent studies reveal\nthat their updates often suffer from poor spectral conditioning and low-rank\nstructures, hindering efficiency. Muon addresses this issue via global spectral\nnormalization but lacks the per-coordinate adaptivity of Adam. In this work, we\npropose \\textbf{Column-Normalized Adam (Conda)}, a novel optimizer that bridges\nthe strengths of both approaches. Conda projects updates into an orthogonal\nsubspace and applies column-wise second moment normalization based on the\nprojected gradients, thereby achieving both improved spectral conditioning and\nmaintaining coordinate-wise adaptivity. This design alleviates the spectral\npathologies of Adam while preserving its fast convergence behavior. Extensive\nexperiments on the LLaMA and GPT-2 series show that Conda consistently\noutperforms AdamW, Muon, and other baselines in pre-training. Remarkably, on\nthe LLaMA series, \\textbf{Conda achieves $2{\\sim}2.5\\times$ the convergence\nspeed of AdamW, measured in both training steps and training time.} Further\nablations demonstrate its robustness under diverse training setups. These\nresults collectively highlight Conda as an effective and broadly applicable\noptimizer for large-scale LLM training. The code is released on\nhttps://github.com/jie040109/Conda"}
{"id": "2509.24223", "pdf": "https://arxiv.org/pdf/2509.24223", "abs": "https://arxiv.org/abs/2509.24223", "authors": ["Jianxin Zhang", "Clayton Scott"], "title": "Semantic Editing with Coupled Stochastic Differential Equations", "categories": ["cs.LG", "cs.CV", "stat.ML"], "comment": null, "summary": "Editing the content of an image with a pretrained text-to-image model remains\nchallenging. Existing methods often distort fine details or introduce\nunintended artifacts. We propose using coupled stochastic differential\nequations (coupled SDEs) to guide the sampling process of any pre-trained\ngenerative model that can be sampled by solving an SDE, including diffusion and\nrectified flow models. By driving both the source image and the edited image\nwith the same correlated noise, our approach steers new samples toward the\ndesired semantics while preserving visual similarity to the source. The method\nworks out-of-the-box-without retraining or auxiliary networks-and achieves high\nprompt fidelity along with near-pixel-level consistency. These results position\ncoupled SDEs as a simple yet powerful tool for controlled generative AI."}
{"id": "2509.24224", "pdf": "https://arxiv.org/pdf/2509.24224", "abs": "https://arxiv.org/abs/2509.24224", "authors": ["Ashiqur Rahman", "Hamed Alhoori"], "title": "Proposing a Framework for Machine Learning Adoption on Legacy Systems", "categories": ["cs.LG"], "comment": "Accepted at The First International Workshop on Resilient Artificial\n  Intelligence for Manufacturing (ICDM'25)", "summary": "The integration of machine learning (ML) is critical for industrial\ncompetitiveness, yet its adoption is frequently stalled by the prohibitive\ncosts and operational disruptions of upgrading legacy systems. The financial\nand logistical overhead required to support the full ML lifecycle presents a\nformidable barrier to widespread implementation, particularly for small and\nmedium-sized enterprises. This paper introduces a pragmatic, API-based\nframework designed to overcome these challenges by strategically decoupling the\nML model lifecycle from the production environment. Our solution delivers the\nanalytical power of ML to domain experts through a lightweight, browser-based\ninterface, eliminating the need for local hardware upgrades and ensuring model\nmaintenance can occur with zero production downtime. This human-in-the-loop\napproach empowers experts with interactive control over model parameters,\nfostering trust and facilitating seamless integration into existing workflows.\nBy mitigating the primary financial and operational risks, this framework\noffers a scalable and accessible pathway to enhance production quality and\nsafety, thereby strengthening the competitive advantage of the manufacturing\nsector."}
{"id": "2509.24228", "pdf": "https://arxiv.org/pdf/2509.24228", "abs": "https://arxiv.org/abs/2509.24228", "authors": ["Wei Wang", "Dong-Dong Wu", "Ming Li", "Jingxiong Zhang", "Gang Niu", "Masashi Sugiyama"], "title": "Accessible, Realistic, and Fair Evaluation of Positive-Unlabeled Learning Algorithms", "categories": ["cs.LG"], "comment": null, "summary": "Positive-unlabeled (PU) learning is a weakly supervised binary classification\nproblem, in which the goal is to learn a binary classifier from only positive\nand unlabeled data, without access to negative data. In recent years, many PU\nlearning algorithms have been developed to improve model performance. However,\nexperimental settings are highly inconsistent, making it difficult to identify\nwhich algorithm performs better. In this paper, we propose the first PU\nlearning benchmark to systematically compare PU learning algorithms. During our\nimplementation, we identify subtle yet critical factors that affect the\nrealistic and fair evaluation of PU learning algorithms. On the one hand, many\nPU learning algorithms rely on a validation set that includes negative data for\nmodel selection. This is unrealistic in traditional PU learning settings, where\nno negative data are available. To handle this problem, we systematically\ninvestigate model selection criteria for PU learning. On the other hand, the\nproblem settings and solutions of PU learning have different families, i.e.,\nthe one-sample and two-sample settings. However, existing evaluation protocols\nare heavily biased towards the one-sample setting and neglect the significant\ndifference between them. We identify the internal label shift problem of\nunlabeled training data for the one-sample setting and propose a simple yet\neffective calibration approach to ensure fair comparisons within and across\nfamilies. We hope our framework will provide an accessible, realistic, and fair\nenvironment for evaluating PU learning algorithms in the future."}
{"id": "2509.24239", "pdf": "https://arxiv.org/pdf/2509.24239", "abs": "https://arxiv.org/abs/2509.24239", "authors": ["Jincheng Liu", "Sijun He", "Jingjing Wu", "Xiangsen Wang", "Yang Chen", "Zhaoqi Kuang", "Siqi Bao", "Yuan Yao"], "title": "ChessArena: A Chess Testbed for Evaluating Strategic Reasoning Capabilities of Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent large language models (LLMs) have shown strong reasoning capabilities.\nHowever, a critical question remains: do these models possess genuine reasoning\nskills particularly complex strategic reasoning or are they primarily excelling\nat sophisticated pattern recognition within their training data? To address\nthis question, this paper presents a chess testbed, ChessArena, to evaluate the\nstrategic reasoning capabilities of LLMs. Chess requires complex strategic\nreasoning capabilities including long-term planning, strict rule comprehension,\nand multi-turn conversation memorization. Specifically, ChessArena is a\ncompetitive framework where LLMs play against each other, under four different\nplay modes. The testbed is equipped with a ranking algorithm and a leaderboard.\nThe testbed can also evaluate fine-grained capabilities including basic\nunderstanding, move selection, and puzzle solving. Over 13 LLMs with different\nmodes are evaluated in ChessArena, playing over 800 games. The results reveal\nsignificant shortcomings in current LLMs: no model can beat Maia-1100 (a chess\nengine at human amateur level), while some even failed to defeat a random\nplayer that selects moves arbitrarily. We also present a strong baseline to the\ntestbed: our fine-tuned Qwen3-8B substantially improved performance,\napproaching much larger state-of-the-art reasoning models."}
{"id": "2509.24256", "pdf": "https://arxiv.org/pdf/2509.24256", "abs": "https://arxiv.org/abs/2509.24256", "authors": ["Yunhao Liang", "Pujun Zhang", "Yuan Qu", "Shaochong Lin", "Zuo-jun Max Shen"], "title": "Graph Foundation Models: Bridging Language Model Paradigms and Graph Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The pretrain-transfer paradigm, which underpins the success of large language\nmodels (LLMs), has demonstrated the immense power of creating foundation models\nthat learn generalizable representations from vast datasets. However, extending\nthis paradigm to Operations Research (OR) problems on graph structures remains\nchallenging due to the fundamental conflict between the statistical flexibility\nof language and the strict combinatorial constraints of graphs. To bridge this\ngap, we introduce the Graph Foundation Model (GFM), the first framework capable\nof solving all distance-based optimization problems on graph structures. By\nintroducing the LLM-like self-supervised pre-training paradigm on the paths\ngenerated from random walks in the graph, GFM is compelled to internalize the\ngraph's complex topological and combinatorial rules, where the connectivity of\nthe structure itself can be treated as the supervisory signal. Unlike existing\nneural methods that learn complex and task-specific solving policies, our\napproach leverages the pre-trained GFM as a foundational model of the graph's\nintrinsic structure, which in turn enables a simple generative heuristic to\ntackle a diverse range of optimization challenges effectively. Comprehensive\nexperiments on networks ranging from 20 to 893 nodes demonstrate that GFM\nachieves competitive performance against specialized solvers across a variety\nof distinct optimization task classes, while maintaining significantly faster\ninference times. Our work establishes a new paradigm of adapting the\npretrain-transfer framework to graph optimization, opening the door for\napplying foundation model innovations to OR."}
{"id": "2509.24274", "pdf": "https://arxiv.org/pdf/2509.24274", "abs": "https://arxiv.org/abs/2509.24274", "authors": ["Inkyu Park", "Jeong-Gwan Lee", "Taehwan Kwon", "Juheon Choi", "Seungku Kim", "Junsu Kim", "Kimin Lee"], "title": "Adversarial Reinforcement Learning Framework for ESP Cheater Simulation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Extra-Sensory Perception (ESP) cheats, which reveal hidden in-game\ninformation such as enemy locations, are difficult to detect because their\neffects are not directly observable in player behavior. The lack of observable\nevidence makes it difficult to collect reliably labeled data, which is\nessential for training effective anti-cheat systems. Furthermore, cheaters\noften adapt their behavior by limiting or disguising their cheat usage, which\nfurther complicates detection and detector development. To address these\nchallenges, we propose a simulation framework for controlled modeling of ESP\ncheaters, non-cheaters, and trajectory-based detectors. We model cheaters and\nnon-cheaters as reinforcement learning agents with different levels of\nobservability, while detectors classify their behavioral trajectories. Next, we\nformulate the interaction between the cheater and the detector as an\nadversarial game, allowing both players to co-adapt over time. To reflect\nrealistic cheater strategies, we introduce a structured cheater model that\ndynamically switches between cheating and non-cheating behaviors based on\ndetection risk. Experiments demonstrate that our framework successfully\nsimulates adaptive cheater behaviors that strategically balance reward\noptimization and detection evasion. This work provides a controllable and\nextensible platform for studying adaptive cheating behaviors and developing\neffective cheat detectors."}
{"id": "2509.24302", "pdf": "https://arxiv.org/pdf/2509.24302", "abs": "https://arxiv.org/abs/2509.24302", "authors": ["Muyun Jiang", "Shuailei Zhang", "Zhenjie Yang", "Mengjun Wu", "Weibang Jiang", "Zhiwei Guo", "Wei Zhang", "Rui Liu", "Shangen Zhang", "Yong Li", "Yi Ding", "Cuntai Guan"], "title": "ELASTIQ: EEG-Language Alignment with Semantic Task Instruction and Querying", "categories": ["cs.LG"], "comment": null, "summary": "Recent advances in electroencephalography (EEG) foundation models, which\ncapture transferable EEG representations, have greatly accelerated the\ndevelopment of brain-computer interfaces (BCI). However, existing approaches\nstill struggle to incorporate language instructions as prior constraints for\nEEG representation learning, limiting their ability to leverage the semantic\nknowledge inherent in language to unify different labels and tasks. To address\nthis challenge, we present ELASTIQ, a foundation model for EEG-Language\nAlignment with Semantic Task Instruction and Querying. ELASTIQ integrates\ntask-aware semantic guidance to produce structured and linguistically aligned\nEEG embeddings, thereby enhancing decoding robustness and transferability. In\nthe pretraining stage, we introduce a joint Spectral-Temporal Reconstruction\n(STR) module, which combines frequency masking as a global spectral\nperturbation with two complementary temporal objectives: random masking to\ncapture contextual dependencies and causal masking to model sequential\ndynamics. In the instruction tuning stage, we propose the\nInstruction-conditioned Q-Former (IQF), a query-based cross-attention\ntransformer that injects instruction embeddings into EEG tokens and aligns them\nwith textual label embeddings through learnable queries. We evaluate ELASTIQ on\n20 datasets spanning motor imagery, emotion recognition, steady-state visual\nevoked potentials, covert speech, and healthcare tasks. ELASTIQ achieves\nstate-of-the-art performance on 14 of the 20 datasets and obtains the best\naverage results across all five task categories. Importantly, our analyses\nreveal for the first time that explicit task instructions serve as semantic\npriors guiding EEG embeddings into coherent and linguistically grounded spaces.\nThe code and pre-trained weights will be released."}
{"id": "2509.24305", "pdf": "https://arxiv.org/pdf/2509.24305", "abs": "https://arxiv.org/abs/2509.24305", "authors": ["Alexander Tyurin", "Andrei Spiridonov", "Varvara Rudenko"], "title": "Asynchronous Policy Gradient Aggregation for Efficient Distributed Reinforcement Learning", "categories": ["cs.LG", "cs.DC", "math.OC"], "comment": null, "summary": "We study distributed reinforcement learning (RL) with policy gradient methods\nunder asynchronous and parallel computations and communications. While\nnon-distributed methods are well understood theoretically and have achieved\nremarkable empirical success, their distributed counterparts remain less\nexplored, particularly in the presence of heterogeneous asynchronous\ncomputations and communication bottlenecks. We introduce two new algorithms,\nRennala NIGT and Malenia NIGT, which implement asynchronous policy gradient\naggregation and achieve state-of-the-art efficiency. In the homogeneous\nsetting, Rennala NIGT provably improves the total computational and\ncommunication complexity while supporting the AllReduce operation. In the\nheterogeneous setting, Malenia NIGT simultaneously handles asynchronous\ncomputations and heterogeneous environments with strictly better theoretical\nguarantees. Our results are further corroborated by experiments, showing that\nour methods significantly outperform prior approaches."}
{"id": "2509.24306", "pdf": "https://arxiv.org/pdf/2509.24306", "abs": "https://arxiv.org/abs/2509.24306", "authors": ["Satyanarayana Raju G. V. V", "Prathamesh Dinesh Joshi", "Raj Abhijit Dandekar", "Rajat Dandekar", "Sreedath Panat"], "title": "A study of Universal ODE approaches to predicting soil organic carbon", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Soil Organic Carbon (SOC) is a foundation of soil health and global climate\nresilience, yet its prediction remains difficult because of intricate physical,\nchemical, and biological processes. In this study, we explore a Scientific\nMachine Learning (SciML) framework built on Universal Differential Equations\n(UDEs) to forecast SOC dynamics across soil depth and time. UDEs blend\nmechanistic physics, such as advection diffusion transport, with neural\nnetworks that learn nonlinear microbial production and respiration. Using\nsynthetic datasets, we systematically evaluated six experimental cases,\nprogressing from clean, noise free benchmarks to stress tests with high (35%)\nmultiplicative, spatially correlated noise. Our results highlight both the\npotential and limitations of the approach. In noise free and moderate noise\nsettings, the UDE accurately reconstructed SOC dynamics. In clean terminal\nprofile at 50 years (Case 4) achieved near perfect fidelity, with MSE = 1.6e-5,\nand R2 = 0.9999. Case 5, with 7% noise, remained robust (MSE = 3.4e-6, R2 =\n0.99998), capturing depth wise SOC trends while tolerating realistic\nmeasurement uncertainty. In contrast, Case 3 (35% noise at t = 0) showed clear\nevidence of overfitting: the model reproduced noisy inputs with high accuracy\nbut lost generalization against the clean truth (R2 = 0.94). Case 6 (35% noise\nat t = 50) collapsed toward overly smooth mean profiles, failing to capture\ndepth wise variability and yielding negative R2, underscoring the limits of\nstandard training under severe uncertainty. These findings suggest that UDEs\nare well suited for scalable, noise tolerant SOC forecasting, though advancing\ntoward field deployment will require noise aware loss functions, probabilistic\nmodelling, and tighter integration of microbial dynamics."}
{"id": "2509.24317", "pdf": "https://arxiv.org/pdf/2509.24317", "abs": "https://arxiv.org/abs/2509.24317", "authors": ["Xianhang Li", "Chen Huang", "Chun-Liang Li", "Eran Malach", "Josh Susskind", "Vimal Thilak", "Etai Littwin"], "title": "Rethinking JEPA: Compute-Efficient Video SSL with Frozen Teachers", "categories": ["cs.LG", "cs.CV"], "comment": "Technical Report", "summary": "Video Joint Embedding Predictive Architectures (V-JEPA) learn generalizable\noff-the-shelf video representation by predicting masked regions in latent space\nwith an exponential moving average (EMA)-updated teacher. While EMA prevents\nrepresentation collapse, it complicates scalable model selection and couples\nteacher and student architectures. We revisit masked-latent prediction and show\nthat a frozen teacher suffices. Concretely, we (i) train a target encoder with\na simple pixel-reconstruction objective under V-JEPA masking, then (ii) freeze\nit and train a student to predict the teacher's latents on masked regions. This\nleads to a two-stage, unregularized scheme that we refer to as SALT\n(Static-teacher Asymmetric Latent Training). SALT decouples optimization into\npixel reconstruction (teacher) and masked latent prediction (student),\nincreasing transparency, efficiency, and scalability while preserving the\nability of representation to generalize under frozen evaluation. Empirically,\nour student models outperform recently proposed V-JEPA 2 encoders under frozen\nbackbone evaluation across diverse benchmarks. They are also more\ncompute-optimal: at matched pretraining FLOPs, our method achieves higher\nprobing accuracy, and its scaling curves dominate V-JEPA's accuracy-FLOPs\nPareto frontier. Finally, we find that student quality is remarkably robust to\nteacher quality: high-performing students emerge even with small, sub-optimal\nteachers. This points to a compute budget allocation that should overwhelmingly\nfavor the student. These results position SALT as a simple, scalable, and\ncompute-efficient alternative to EMA-based self-distillation for video\nrepresentation learning."}
{"id": "2509.24320", "pdf": "https://arxiv.org/pdf/2509.24320", "abs": "https://arxiv.org/abs/2509.24320", "authors": ["Dipan Maity"], "title": "AuON: A Linear-time Alternative to Semi-Orthogonal Momentum Updates", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Orthogonal gradient updates have emerged as a promising direction in\noptimization for machine learning. However, traditional approaches such as\nSVD/QR decomposition incur prohibitive computational costs of O(n^3) and\nunderperform compared to well-tuned SGD with momentum, since momentum is\napplied only after strict orthogonalization. Recent advances, such as Muon,\nimprove efficiency by applying momentum before orthogonalization and producing\nsemi-orthogonal matrices via Newton-Schulz iterations, reducing complexity to\nO(n^2). Nevertheless, quadratic costs remain a bottleneck.\n  In this work, we study the semi-orthogonal properties of momentum-based\nupdates and develop a method to bound momentum updates under a spectral-norm\ntrust region, preserving directional information without requiring explicit\nsemi-orthogonalization.\n  We propose AuON (Alternative Unit-norm momentum updates by Normalized\nnonlinear scaling), a linear-time optimizer that achieves strong performance\nwithout constructing semi-orthogonal matrices, while preserving structural\nalignment and reconditioning ill-posed updates. Our approach combines\nhyperbolic-cosine RMS scaling transformations with normalization, demonstrating\nboth effectiveness and computational efficiency compared to Newton-Schulz\nmethods. We further introduce a hybrid variant (Hybrid-AuON) that applies a\nsingle Newton-Schulz iteration. Experiments across vision and language\nbenchmarks show that AuON and its hybrid variant achieve performance comparable\nto strong baselines such as AdamW and Muon.\n  Code is available at: https://github.com/ryyzn9/AuON"}
{"id": "2509.24330", "pdf": "https://arxiv.org/pdf/2509.24330", "abs": "https://arxiv.org/abs/2509.24330", "authors": ["Shiyuan Zuo", "Rongfei Fan", "Cheng Zhan", "Jie Xu", "Puning Zhao", "Han Hu"], "title": "H+: An Efficient Similarity-Aware Aggregation for Byzantine Resilient Federated Learning", "categories": ["cs.LG"], "comment": null, "summary": "Federated Learning (FL) enables decentralized model training without sharing\nraw data. However, it remains vulnerable to Byzantine attacks, which can\ncompromise the aggregation of locally updated parameters at the central server.\nSimilarity-aware aggregation has emerged as an effective strategy to mitigate\nsuch attacks by identifying and filtering out malicious clients based on\nsimilarity between client model parameters and those derived from clean data,\ni.e., data that is uncorrupted and trustworthy. However, existing methods adopt\nthis strategy only in FL systems with clean data, making them inapplicable to\nsettings where such data is unavailable. In this paper, we propose H+, a novel\nsimilarity-aware aggregation approach that not only outperforms existing\nmethods in scenarios with clean data, but also extends applicability to FL\nsystems without any clean data. Specifically, H+ randomly selects\n$r$-dimensional segments from the $p$-dimensional parameter vectors uploaded to\nthe server and applies a similarity check function $H$ to compare each segment\nagainst a reference vector, preserving the most similar client vectors for\naggregation. The reference vector is derived either from existing robust\nalgorithms when clean data is unavailable or directly from clean data.\nRepeating this process $K$ times enables effective identification of honest\nclients. Moreover, H+ maintains low computational complexity, with an\nanalytical time complexity of $\\mathcal{O}(KMr)$, where $M$ is the number of\nclients and $Kr \\ll p$. Comprehensive experiments validate H+ as a\nstate-of-the-art (SOTA) method, demonstrating substantial robustness\nimprovements over existing approaches under varying Byzantine attack ratios and\nmultiple types of traditional Byzantine attacks, across all evaluated scenarios\nand benchmark datasets."}
{"id": "2509.24332", "pdf": "https://arxiv.org/pdf/2509.24332", "abs": "https://arxiv.org/abs/2509.24332", "authors": ["Siyang Li", "Yize Chen", "Yan Guo", "Ming Huang", "Hui Xiong"], "title": "Towards Generalizable PDE Dynamics Forecasting via Physics-Guided Invariant Learning", "categories": ["cs.LG", "cs.AI"], "comment": "27 pages, 13 figues. In Submission", "summary": "Advanced deep learning-based approaches have been actively applied to\nforecast the spatiotemporal physical dynamics governed by partial differential\nequations (PDEs), which acts as a critical procedure in tackling many science\nand engineering problems. As real-world physical environments like PDE system\nparameters are always capricious, how to generalize across unseen\nout-of-distribution (OOD) forecasting scenarios using limited training data is\nof great importance. To bridge this barrier, existing methods focus on\ndiscovering domain-generalizable representations across various PDE dynamics\ntrajectories. However, their zero-shot OOD generalization capability remains\ndeficient, since extra test-time samples for domain-specific adaptation are\nstill required. This is because the fundamental physical invariance in PDE\ndynamical systems are yet to be investigated or integrated. To this end, we\nfirst explicitly define a two-fold PDE invariance principle, which points out\nthat ingredient operators and their composition relationships remain invariant\nacross different domains and PDE system evolution. Next, to capture this\ntwo-fold PDE invariance, we propose a physics-guided invariant learning method\ntermed iMOOE, featuring an Invariance-aligned Mixture Of Operator Expert\narchitecture and a frequency-enriched invariant learning objective. Extensive\nexperiments across simulated benchmarks and real-world applications validate\niMOOE's superior in-distribution performance and zero-shot generalization\ncapabilities on diverse OOD forecasting scenarios."}
{"id": "2509.24341", "pdf": "https://arxiv.org/pdf/2509.24341", "abs": "https://arxiv.org/abs/2509.24341", "authors": ["Qingquan Zhang", "Ziqi Wang", "Yuchen Li", "Keyuan Zhang", "Bo Yuan", "Jialin Liu"], "title": "Expanding Horizons of Level Diversity via Multi-objective Evolutionary Learning", "categories": ["cs.LG"], "comment": "12 pages,6 figures", "summary": "In recent years, the generation of diverse game levels has gained increasing\ninterest, contributing to a richer and more engaging gaming experience. A\nnumber of level diversity metrics have been proposed in literature, which are\nnaturally multi-dimensional, leading to conflicted, complementary, or both\nrelationships among these dimensions. However, existing level generation\napproaches often fail to comprehensively assess diversity across those\ndimensions. This paper aims to expand horizons of level diversity by\nconsidering multi-dimensional diversity when training generative models. We\nformulate the model training as a multi-objective learning problem, where each\ndiversity metric is treated as a distinct objective. Furthermore, a\nmulti-objective evolutionary learning framework that optimises multiple\ndiversity metrics simultaneously throughout the model training process is\nproposed. Our case study on the commonly used benchmark Super Mario Bros.\ndemonstrates that our proposed framework can enhance multi-dimensional\ndiversity and identify a Pareto front of generative models, which provides a\nrange of tradeoffs among playability and two representative diversity metrics,\nincluding a content-based one and a player-centered one. Such capability\nenables decision-makers to make informed choices when selecting generators\naccommodating a variety of scenarios and the diverse needs of players and\ndesigners."}
{"id": "2509.24368", "pdf": "https://arxiv.org/pdf/2509.24368", "abs": "https://arxiv.org/abs/2509.24368", "authors": ["Thibaud Gloaguen", "Robin Staab", "Nikola Jovanović", "Martin Vechev"], "title": "Watermarking Diffusion Language Models", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "We introduce the first watermark tailored for diffusion language models\n(DLMs), an emergent LLM paradigm able to generate tokens in arbitrary order, in\ncontrast to standard autoregressive language models (ARLMs) which generate\ntokens sequentially. While there has been much work in ARLM watermarking, a key\nchallenge when attempting to apply these schemes directly to the DLM setting is\nthat they rely on previously generated tokens, which are not always available\nwith DLM generation. In this work we address this challenge by: (i) applying\nthe watermark in expectation over the context even when some context tokens are\nyet to be determined, and (ii) promoting tokens which increase the watermark\nstrength when used as context for other tokens. This is accomplished while\nkeeping the watermark detector unchanged. Our experimental evaluation\ndemonstrates that the DLM watermark leads to a >99% true positive rate with\nminimal quality impact and achieves similar robustness to existing ARLM\nwatermarks, enabling for the first time reliable DLM watermarking."}
{"id": "2509.24372", "pdf": "https://arxiv.org/pdf/2509.24372", "abs": "https://arxiv.org/abs/2509.24372", "authors": ["Xin Qiu", "Yulu Gan", "Conor F. Hayes", "Qiyao Liang", "Elliot Meyerson", "Babak Hodjat", "Risto Miikkulainen"], "title": "Evolution Strategies at Scale: LLM Fine-Tuning Beyond Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": "24 pages, including the appendix", "summary": "Fine-tuning pre-trained large language models (LLMs) for down-stream tasks is\na critical step in the AI deployment pipeline. Reinforcement learning (RL) is\narguably the most prominent fine-tuning method, contributing to the birth of\nmany state-of-the-art LLMs. In contrast, evolution strategies (ES), which once\nshowed comparable performance to RL on models with a few million parameters,\nwas neglected due to the pessimistic perception of its scalability to larger\nmodels. In this work, we report the first successful attempt to scale up ES for\nfine-tuning the full parameters of LLMs, showing the surprising fact that ES\ncan search efficiently over billions of parameters and outperform existing RL\nfine-tuning methods in multiple respects, including sample efficiency,\ntolerance to long-horizon rewards, robustness to different base LLMs, less\ntendency to reward hacking, and more stable performance across runs. It\ntherefore serves as a basis to unlock a new direction in LLM fine-tuning beyond\nwhat current RL techniques provide. The source codes are provided at:\nhttps://github.com/VsonicV/es-fine-tuning-paper."}
{"id": "2509.24378", "pdf": "https://arxiv.org/pdf/2509.24378", "abs": "https://arxiv.org/abs/2509.24378", "authors": ["Tian Lan", "Hao Duong Le", "Jinbo Li", "Wenjun He", "Meng Wang", "Chenghao Liu", "Chen Zhang"], "title": "AXIS: Explainable Time Series Anomaly Detection with Large Language Models", "categories": ["cs.LG"], "comment": null, "summary": "Time-series anomaly detection (TSAD) increasingly demands explanations that\narticulate not only if an anomaly occurred, but also what pattern it exhibits\nand why it is anomalous. Leveraging the impressive explanatory capabilities of\nLarge Language Models (LLMs), recent works have attempted to treat time series\nas text for explainable TSAD. However, this approach faces a fundamental\nchallenge: LLMs operate on discrete tokens and struggle to directly process\nlong, continuous signals. Consequently, naive time-to-text serialization\nsuffers from a lack of contextual grounding and representation alignment\nbetween the two modalities. To address this gap, we introduce AXIS, a framework\nthat conditions a frozen LLM for nuanced time-series understanding. Instead of\ndirect serialization, AXIS enriches the LLM's input with three complementary\nhints derived from the series: (i) a symbolic numeric hint for numerical\ngrounding, (ii) a context-integrated, step-aligned hint distilled from a\npretrained time-series encoder to capture fine-grained dynamics, and (iii) a\ntask-prior hint that encodes global anomaly characteristics. Furthermore, to\nfacilitate robust evaluation of explainability, we introduce a new benchmark\nfeaturing multi-format questions and rationales that supervise contextual\ngrounding and pattern-level semantics. Extensive experiments, including both\nLLM-based and human evaluations, demonstrate that AXIS yields explanations of\nsignificantly higher quality and achieves competitive detection accuracy\ncompared to general-purpose LLMs, specialized time-series LLMs, and time-series\nVision Language Models."}
{"id": "2509.24406", "pdf": "https://arxiv.org/pdf/2509.24406", "abs": "https://arxiv.org/abs/2509.24406", "authors": ["Sushant Mehta", "Raj Dandekar", "Rajat Dandekar", "Sreedath Panat"], "title": "Muon: Training and Trade-offs with Latent Attention and MoE", "categories": ["cs.LG"], "comment": null, "summary": "We present a comprehensive theoretical and empirical study of the Muon\noptimizer for training transformers only with a small to medium decoder (30M -\n200M parameters), with an emphasis on its mathematical foundations, convergence\nproperties and synergistic interactions with modern architectural\noptimizations. Building on recent work showing Muon's scalability, we provide\nrigorous theoretical analysis including: (i)showing the convergence rate under\nstandard assumptions, (ii) spectral regularization properties that prevent\ngradient explosion, (iii) connection to natural gradient descent on the Stiefel\nmanifold, and (iv) equivalence to steepest gradient descent under the spectral\nnorm. Crucially, we demonstrate that Muon expands the Pareto frontier in the\ncompute-time trade-off by maintaining superior data efficiency at large batch\nsizes, a key finding of~\\cite{essentialai2025muon} that we validate across our\nmodel scales. Empirically, Muon reaches the target loss with 48-52\\% of the\ntraining calculated by AdamW while maintaining or improving the final\nperplexity, consistent with larger-scale results. When combined with Multi-Head\nLatent Attention (MLA) and Mixture-of-Experts (MoE), we observe multiplicative\nefficiency gains: MLA+MoE+Muon achieves 68\\% memory reduction and 3.2$\\times$\ninference speedup, while improving perplexity by 8-12\\%. We provide detailed\nprocedures on 15 architectural and optimizer components, stability analyzes\nacross 100+ training runs, and practical implementation guidelines including\nNewton-Schulz coefficients $(3.4445, -4.7750, 2.0315)$ optimized\nby~\\cite{su2024muonblog}. Our theoretical analysis and comprehensive\nexperiments establish Muon as a principled, robust alternative to AdamW that\nparticularly excels when combined with modern efficiency techniques and\nlarge-batch training regimes."}
{"id": "2509.24414", "pdf": "https://arxiv.org/pdf/2509.24414", "abs": "https://arxiv.org/abs/2509.24414", "authors": ["Tao Yin", "Xiaohong Zhang", "Shaochen Fu", "Zhibin Zhang", "Li Huang", "Yiyuan Yang", "Kaixiang Yang", "Meng Yan"], "title": "ScatterAD: Temporal-Topological Scattering Mechanism for Time Series Anomaly Detection", "categories": ["cs.LG", "cs.AI"], "comment": "39th Conference on Neural Information Processing Systems (NeurIPS\n  2025)", "summary": "One main challenge in time series anomaly detection for industrial IoT lies\nin the complex spatio-temporal couplings within multivariate data. However,\ntraditional anomaly detection methods focus on modeling spatial or temporal\ndependencies independently, resulting in suboptimal representation learning and\nlimited sensitivity to anomalous dispersion in high-dimensional spaces. In this\nwork, we conduct an empirical analysis showing that both normal and anomalous\nsamples tend to scatter in high-dimensional space, especially anomalous samples\nare markedly more dispersed. We formalize this dispersion phenomenon as\nscattering, quantified by the mean pairwise distance among sample\nrepresentations, and leverage it as an inductive signal to enhance\nspatio-temporal anomaly detection. Technically, we propose ScatterAD to model\nrepresentation scattering across temporal and topological dimensions. ScatterAD\nincorporates a topological encoder for capturing graph-structured scattering\nand a temporal encoder for constraining over-scattering through mean squared\nerror minimization between neighboring time steps. We introduce a contrastive\nfusion mechanism to ensure the complementarity of the learned temporal and\ntopological representations. Additionally, we theoretically show that\nmaximizing the conditional mutual information between temporal and topological\nviews improves cross-view consistency and enhances more discriminative\nrepresentations. Extensive experiments on multiple public benchmarks show that\nScatterAD achieves state-of-the-art performance on multivariate time series\nanomaly detection. Code is available at this repository:\nhttps://github.com/jk-sounds/ScatterAD."}
{"id": "2509.24425", "pdf": "https://arxiv.org/pdf/2509.24425", "abs": "https://arxiv.org/abs/2509.24425", "authors": ["Jingtao Zhang", "Yi Liu", "Qi Shen", "Changhong Wang"], "title": "BiHDTrans: binary hyperdimensional transformer for efficient multivariate time series classification", "categories": ["cs.LG", "cs.AR"], "comment": null, "summary": "The proliferation of Internet-of-Things (IoT) devices has led to an\nunprecedented volume of multivariate time series (MTS) data, requiring\nefficient and accurate processing for timely decision-making in\nresource-constrained edge environments. Hyperdimensional (HD) computing, with\nits inherent efficiency and parallelizability, has shown promise in\nclassification tasks but struggles to capture complex temporal patterns, while\nTransformers excel at sequence modeling but incur high computational and memory\noverhead. We introduce BiHDTrans, an efficient neurosymbolic binary\nhyperdimensional Transformer that integrates self-attention into the HD\ncomputing paradigm, unifying the representational efficiency of HD computing\nwith the temporal modeling power of Transformers. Empirically, BiHDTrans\noutperforms state-of-the-art (SOTA) HD computing models by at least 14.47% and\nachieves 6.67% higher accuracy on average than SOTA binary Transformers. With\nhardware acceleration on FPGA, our pipelined implementation leverages the\nindependent and identically distributed properties of high-dimensional\nrepresentations, delivering 39.4 times lower inference latency than SOTA binary\nTransformers. Theoretical analysis shows that binarizing in holographic\nhigh-dimensional space incurs significantly less information distortion than\ndirectly binarizing neural networks, explaining BiHDTrans's superior accuracy.\nFurthermore, dimensionality experiments confirm that BiHDTrans remains\ncompetitive even with a 64% reduction in hyperspace dimensionality, surpassing\nSOTA binary Transformers by 1-2% in accuracy with 4.4 times less model size, as\nwell as further reducing the latency by 49.8% compare to the full-dimensional\nbaseline. Together, these contributions bridge the gap between the\nexpressiveness of Transformers and the efficiency of HD computing, enabling\naccurate, scalable, and low-latency MTS classification."}
{"id": "2509.24431", "pdf": "https://arxiv.org/pdf/2509.24431", "abs": "https://arxiv.org/abs/2509.24431", "authors": ["Eleonora Grassucci", "Giordano Cicchetti", "Aurelio Uncini", "Danilo Comminiello"], "title": "Semantic Compression via Multimodal Representation Learning", "categories": ["cs.LG"], "comment": null, "summary": "Multimodal representation learning produces high-dimensional embeddings that\nalign diverse modalities in a shared latent space. While this enables strong\ngeneralization, it also introduces scalability challenges, both in terms of\nstorage and downstream processing. A key open problem is how to achieve\nsemantic compression, reducing the memory footprint of multimodal embeddings\nwhile preserving their ability to represent shared semantic content across\nmodalities. In this paper, we prove a strong connection between reducing the\nmodality gap, which is the residual separation of embeddings from different\nmodalities, and the feasibility of post-training semantic compression. When the\ngap is sufficiently reduced, embeddings from different modalities but\nexpressing the same semantics share a common portion of the space. Therefore,\ntheir centroid is a faithful representation of such a semantic concept. This\nenables replacing multiple embeddings with a single centroid, yielding\nsignificant memory savings. We propose a novel approach for semantic\ncompression grounded on the latter intuition, operating directly on pretrained\nencoders. We demonstrate its effectiveness across diverse large-scale\nmultimodal downstream tasks. Our results highlight that modality alignment is a\nkey enabler for semantic compression, showing that the proposed approach\nachieves significant compression without sacrificing performance."}
{"id": "2509.24436", "pdf": "https://arxiv.org/pdf/2509.24436", "abs": "https://arxiv.org/abs/2509.24436", "authors": ["Yingshi Chen"], "title": "EOE: Evolutionary Optimization of Experts for Training Language Models", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": "6 pages, 2 figures", "summary": "This paper presents an evolutionary framework for the training of large\nlanguage models(LLM). The models are divided into several\nexperts(sub-networks), which have the same structure but different parameter\nvalues. Only one expert is trained at each step. After the classical AdamW\noptimization, some evolutionary operators(crossover, PSO, and mutation) act on\nthe tensor weights between the current expert and the best expert. So current\nexpert would learn the experience of best expert. The direction of best expert\nwould help current expert's loss decrease faster. Finally, only save the weight\nof the best expert. Experiments show that best expert would achieve nearly the\nsame accuracy as the full model. This would greatly reduce the size of the\nmodel for inference. Since only one expert is trained at each step, the\ntraining needs much less memory and has much higher throughput. Experiments\nshow that the throughput would accelerate more than ten times! Our source code\nis available. It's a pure c++/cu framework, which is suitable for easy\ndeployment on PCs and edge computing devices."}
{"id": "2509.24462", "pdf": "https://arxiv.org/pdf/2509.24462", "abs": "https://arxiv.org/abs/2509.24462", "authors": ["Zifan Wang", "Xinlei Yi", "Xenia Konti", "Michael M. Zavlanos", "Karl H. Johansson"], "title": "Distributionally Robust Federated Learning with Outlier Resilience", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Federated learning (FL) enables collaborative model training without direct\ndata sharing, but its performance can degrade significantly in the presence of\ndata distribution perturbations. Distributionally robust optimization (DRO)\nprovides a principled framework for handling this by optimizing performance\nagainst the worst-case distributions within a prescribed ambiguity set.\nHowever, existing DRO-based FL methods often overlook the detrimental impact of\noutliers in local datasets, which can disproportionately bias the learned\nmodels. In this work, we study distributionally robust federated learning with\nexplicit outlier resilience. We introduce a novel ambiguity set based on the\nunbalanced Wasserstein distance, which jointly captures geometric\ndistributional shifts and incorporates a non-geometric Kullback--Leibler\npenalization to mitigate the influence of outliers. This formulation naturally\nleads to a challenging min--max--max optimization problem. To enable\ndecentralized training, we reformulate the problem as a tractable Lagrangian\npenalty optimization, which admits robustness certificates. Building on this\nreformulation, we propose the distributionally outlier-robust federated\nlearning algorithm and establish its convergence guarantees. Extensive\nexperiments on both synthetic and real-world datasets demonstrate the\neffectiveness of our approach."}
{"id": "2509.24467", "pdf": "https://arxiv.org/pdf/2509.24467", "abs": "https://arxiv.org/abs/2509.24467", "authors": ["Maedeh Zarvandi", "Michael Timothy", "Theresa Wasserer", "Debarghya Ghoshdastidar"], "title": "Interpretable Kernel Representation Learning at Scale: A Unified Framework Utilizing Nyström Approximation", "categories": ["cs.LG", "stat.ML"], "comment": "19 Pages, 3 figures", "summary": "Kernel methods provide a theoretically grounded framework for non-linear and\nnon-parametric learning, with strong analytic foundations and statistical\nguarantees. Yet, their scalability has long been limited by prohibitive time\nand memory costs. While progress has been made in scaling kernel regression, no\nframework exists for scalable kernel-based representation learning, restricting\ntheir use in the era of foundation models where representations are learned\nfrom massive unlabeled data. We introduce KREPES -- a unified, scalable\nframework for kernel-based representation learning via Nystr\\\"om approximation.\nKREPES accommodates a wide range of unsupervised and self-supervised losses,\nand experiments on large image and tabular datasets demonstrate its efficiency.\nCrucially, KREPES enables principled interpretability of the learned\nrepresentations, an immediate benefit over deep models, which we substantiate\nthrough dedicated analysis."}
{"id": "2509.24472", "pdf": "https://arxiv.org/pdf/2509.24472", "abs": "https://arxiv.org/abs/2509.24472", "authors": ["Ran Elbaz", "Guy Bar-Shalom", "Yam Eitan", "Fabrizio Frasca", "Haggai Maron"], "title": "FS-KAN: Permutation Equivariant Kolmogorov-Arnold Networks via Function Sharing", "categories": ["cs.LG"], "comment": null, "summary": "Permutation equivariant neural networks employing parameter-sharing schemes\nhave emerged as powerful models for leveraging a wide range of data symmetries,\nsignificantly enhancing the generalization and computational efficiency of the\nresulting models. Recently, Kolmogorov-Arnold Networks (KANs) have demonstrated\npromise through their improved interpretability and expressivity compared to\ntraditional architectures based on MLPs. While equivariant KANs have been\nexplored in recent literature for a few specific data types, a principled\nframework for applying them to data with permutation symmetries in a general\ncontext remains absent. This paper introduces Function Sharing KAN (FS-KAN), a\nprincipled approach to constructing equivariant and invariant KA layers for\narbitrary permutation symmetry groups, unifying and significantly extending\nprevious work in this domain. We derive the basic construction of these FS-KAN\nlayers by generalizing parameter-sharing schemes to the Kolmogorov-Arnold setup\nand provide a theoretical analysis demonstrating that FS-KANs have the same\nexpressive power as networks that use standard parameter-sharing layers,\nallowing us to transfer well-known and important expressivity results from\nparameter-sharing networks to FS-KANs. Empirical evaluations on multiple data\ntypes and symmetry groups show that FS-KANs exhibit superior data efficiency\ncompared to standard parameter-sharing layers, by a wide margin in certain\ncases, while preserving the interpretability and adaptability of KANs, making\nthem an excellent architecture choice in low-data regimes."}
{"id": "2509.24483", "pdf": "https://arxiv.org/pdf/2509.24483", "abs": "https://arxiv.org/abs/2509.24483", "authors": ["Minh Le", "Bao-Ngoc Dao", "Huy Nguyen", "Quyen Tran", "Anh Nguyen", "Nhat Ho"], "title": "One-Prompt Strikes Back: Sparse Mixture of Experts for Prompt-based Continual Learning", "categories": ["cs.LG"], "comment": "40 pages, 9 figures", "summary": "Prompt-based methods have recently gained prominence in Continual Learning\n(CL) due to their strong performance and memory efficiency. A prevalent\nstrategy in this paradigm assigns a dedicated subset of prompts to each task,\nwhich, while effective, incurs substantial computational overhead and causes\nmemory requirements to scale linearly with the number of tasks. Conversely,\napproaches employing a single shared prompt across tasks offer greater\nefficiency but often suffer from degraded performance due to knowledge\ninterference. To reconcile this trade-off, we propose SMoPE, a novel framework\nthat integrates the benefits of both task-specific and shared prompt\nstrategies. Inspired by recent findings on the relationship between Prefix\nTuning and Mixture of Experts (MoE), SMoPE organizes a shared prompt into\nmultiple \"prompt experts\" within a sparse MoE architecture. For each input,\nonly a select subset of relevant experts is activated, effectively mitigating\ninterference. To facilitate expert selection, we introduce a prompt-attention\nscore aggregation mechanism that computes a unified proxy score for each\nexpert, enabling dynamic and sparse activation. Additionally, we propose an\nadaptive noise mechanism to encourage balanced expert utilization while\npreserving knowledge from prior tasks. To further enhance expert\nspecialization, we design a prototype-based loss function that leverages prefix\nkeys as implicit memory representations. Extensive experiments across multiple\nCL benchmarks demonstrate that SMoPE consistently outperforms task-specific\nprompt methods and achieves performance competitive with state-of-the-art\napproaches, all while significantly reducing parameter counts and computational\ncosts."}
{"id": "2509.24492", "pdf": "https://arxiv.org/pdf/2509.24492", "abs": "https://arxiv.org/abs/2509.24492", "authors": ["Charmaine Barker", "Daniel Bethell", "Simos Gerasimou"], "title": "Guided Uncertainty Learning Using a Post-Hoc Evidential Meta-Model", "categories": ["cs.LG"], "comment": null, "summary": "Reliable uncertainty quantification remains a major obstacle to the\ndeployment of deep learning models under distributional shift. Existing\npost-hoc approaches that retrofit pretrained models either inherit misplaced\nconfidence or merely reshape predictions, without teaching the model when to be\nuncertain. We introduce GUIDE, a lightweight evidential learning meta-model\napproach that attaches to a frozen deep learning model and explicitly learns\nhow and when to be uncertain. GUIDE identifies salient internal features via a\ncalibration stage, and then employs these features to construct a noise-driven\ncurriculum that teaches the model how and when to express uncertainty. GUIDE\nrequires no retraining, no architectural modifications, and no manual\nintermediate-layer selection to the base deep learning model, thus ensuring\nbroad applicability and minimal user intervention. The resulting model avoids\ndistilling overconfidence from the base model, improves out-of-distribution\ndetection by ~77% and adversarial attack detection by ~80%, while preserving\nin-distribution performance. Across diverse benchmarks, GUIDE consistently\noutperforms state-of-the-art approaches, evidencing the need for actively\nguiding uncertainty to close the gap between predictive confidence and\nreliability."}
{"id": "2509.24496", "pdf": "https://arxiv.org/pdf/2509.24496", "abs": "https://arxiv.org/abs/2509.24496", "authors": ["Zhaomin Wu", "Haodong Zhao", "Ziyang Wang", "Jizhou Guo", "Qian Wang", "Bingsheng He"], "title": "LLM DNA: Tracing Model Evolution via Functional Representations", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The explosive growth of large language models (LLMs) has created a vast but\nopaque landscape: millions of models exist, yet their evolutionary\nrelationships through fine-tuning, distillation, or adaptation are often\nundocumented or unclear, complicating LLM management. Existing methods are\nlimited by task specificity, fixed model sets, or strict assumptions about\ntokenizers or architectures. Inspired by biological DNA, we address these\nlimitations by mathematically defining LLM DNA as a low-dimensional,\nbi-Lipschitz representation of functional behavior. We prove that LLM DNA\nsatisfies inheritance and genetic determinism properties and establish the\nexistence of DNA. Building on this theory, we derive a general, scalable,\ntraining-free pipeline for DNA extraction. In experiments across 305 LLMs, DNA\naligns with prior studies on limited subsets and achieves superior or\ncompetitive performance on specific tasks. Beyond these tasks, DNA comparisons\nuncover previously undocumented relationships among LLMs. We further construct\nthe evolutionary tree of LLMs using phylogenetic algorithms, which align with\nshifts from encoder-decoder to decoder-only architectures, reflect temporal\nprogression, and reveal distinct evolutionary speeds across LLM families."}
{"id": "2509.24510", "pdf": "https://arxiv.org/pdf/2509.24510", "abs": "https://arxiv.org/abs/2509.24510", "authors": ["Jonas Hübotter", "Patrik Wolf", "Alexander Shevchenko", "Dennis Jüni", "Andreas Krause", "Gil Kur"], "title": "Specialization after Generalization: Towards Understanding Test-Time Training in Foundation Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent empirical studies have explored the idea of continuing to train a\nmodel at test-time for a given task, known as test-time training (TTT), and\nhave found it to yield significant performance improvements. However, there is\nlimited understanding of why and when TTT is effective. Earlier explanations\nmostly focused on the observation that TTT may help when applied to\nout-of-distribution adaptation or used with privileged data. However, the\ngrowing scale of foundation models with most test data being in-distribution\nquestions these explanations. We instead posit that foundation models remain\nglobally underparameterized, with TTT providing a mechanism for specialization\nafter generalization, focusing capacity on concepts relevant to the test task.\nSpecifically, under the linear representation hypothesis, we propose a model in\nwhich TTT achieves a substantially smaller in-distribution test error than\nglobal training. We empirically validate our model's key assumptions by\ntraining a sparse autoencoder on ImageNet, showing that semantically related\ndata points are explained by only a few shared concepts. Finally, we perform\nscaling studies across image and language tasks that confirm the practical\nimplications of our model, identifying the regimes where specialization is most\neffective."}
{"id": "2509.24517", "pdf": "https://arxiv.org/pdf/2509.24517", "abs": "https://arxiv.org/abs/2509.24517", "authors": ["Sophia N. Wilson", "Jens Hesselbjerg Christensen", "Raghavendra Selvan"], "title": "Trading Carbon for Physics: On the Resource Efficiency of Machine Learning for Spatio-Temporal Forecasting", "categories": ["cs.LG"], "comment": "Source code available at\n  https://github.com/sophiawilson18/FlowMatching", "summary": "Development of modern deep learning methods has been driven primarily by the\npush for improving model efficacy (accuracy metrics). This sole focus on\nefficacy has steered development of large-scale models that require massive\nresources, and results in considerable carbon footprint across the model\nlife-cycle. In this work, we explore how physics inductive biases can offer\nuseful trade-offs between model efficacy and model efficiency (compute, energy,\nand carbon). We study a variety of models for spatio-temporal forecasting, a\ntask governed by physical laws and well-suited for exploring different levels\nof physics inductive bias. We show that embedding physics inductive biases into\nthe model design can yield substantial efficiency gains while retaining or even\nimproving efficacy for the tasks under consideration. In addition to using\nstandard physics-informed spatio-temporal models, we demonstrate the usefulness\nof more recent models like flow matching as a general purpose method for\nspatio-temporal forecasting. Our experiments show that incorporating physics\ninductive biases offer a principled way to improve the efficiency and reduce\nthe carbon footprint of machine learning models. We argue that model\nefficiency, along with model efficacy, should become a core consideration\ndriving machine learning model development and deployment."}
{"id": "2509.24547", "pdf": "https://arxiv.org/pdf/2509.24547", "abs": "https://arxiv.org/abs/2509.24547", "authors": ["Bao-Ngoc Dao", "Quang Nguyen", "Luyen Ngo Dinh", "Minh Le", "Linh Ngo Van"], "title": "LEAF: A Robust Expert-Based Framework for Few-Shot Continual Event Detection", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Few-shot Continual Event Detection (FCED) poses the dual challenges of\nlearning from limited data and mitigating catastrophic forgetting across\nsequential tasks. Existing approaches often suffer from severe forgetting due\nto the full fine-tuning of a shared base model, which leads to knowledge\ninterference between tasks. Moreover, they frequently rely on data augmentation\nstrategies that can introduce unnatural or semantically distorted inputs. To\naddress these limitations, we propose LEAF, a novel and robust expert-based\nframework for FCED. LEAF integrates a specialized mixture of experts\narchitecture into the base model, where each expert is parameterized with\nlow-rank adaptation (LoRA) matrices. A semantic-aware expert selection\nmechanism dynamically routes instances to the most relevant experts, enabling\nexpert specialization and reducing knowledge interference. To improve\ngeneralization in limited-data settings, LEAF incorporates a contrastive\nlearning objective guided by label descriptions, which capture high-level\nsemantic information about event types. Furthermore, to prevent overfitting on\nthe memory buffer, our framework employs a knowledge distillation strategy that\ntransfers knowledge from previous models to the current one. Extensive\nexperiments on multiple FCED benchmarks demonstrate that LEAF consistently\nachieves state-of-the-art performance."}
{"id": "2509.24550", "pdf": "https://arxiv.org/pdf/2509.24550", "abs": "https://arxiv.org/abs/2509.24550", "authors": ["Eleonora Grassucci", "Giuliano Galadini", "Giordano Cicchetti", "Aurelio Uncini", "Fabio Antonacci", "Danilo Comminiello"], "title": "Training-Free Multimodal Guidance for Video to Audio Generation", "categories": ["cs.LG", "cs.SD"], "comment": null, "summary": "Video-to-audio (V2A) generation aims to synthesize realistic and semantically\naligned audio from silent videos, with potential applications in video editing,\nFoley sound design, and assistive multimedia. Although the excellent results,\nexisting approaches either require costly joint training on large-scale paired\ndatasets or rely on pairwise similarities that may fail to capture global\nmultimodal coherence. In this work, we propose a novel training-free multimodal\nguidance mechanism for V2A diffusion that leverages the volume spanned by the\nmodality embeddings to enforce unified alignment across video, audio, and text.\nThe proposed multimodal diffusion guidance (MDG) provides a lightweight,\nplug-and-play control signal that can be applied on top of any pretrained audio\ndiffusion model without retraining. Experiments on VGGSound and AudioCaps\ndemonstrate that our MDG consistently improves perceptual quality and\nmultimodal alignment compared to baselines, proving the effectiveness of a\njoint multimodal guidance for V2A."}
{"id": "2509.24552", "pdf": "https://arxiv.org/pdf/2509.24552", "abs": "https://arxiv.org/abs/2509.24552", "authors": ["Loïc Cabannes", "Maximilian Beck", "Gergely Szilvasy", "Matthijs Douze", "Maria Lomeli", "Jade Copet", "Pierre-Emmanuel Mazaré", "Gabriel Synnaeve", "Hervé Jégou"], "title": "Short window attention enables long-term memorization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent works show that hybrid architectures combining sliding window softmax\nattention layers with linear recurrent neural network (RNN) layers outperform\nboth of these architectures taken separately. However, the impact of the window\nlength and the interplay between softmax attention and linear RNN layers remain\nunder-studied. In this work, we introduce SWAX, a hybrid architecture\nconsisting of sliding-window attention and xLSTM linear RNN layers.\n  A counter-intuitive finding with SWAX is that larger sliding windows do not\nimprove the long-context performance. In fact, short window attention\nencourages the model to better train the long-term memory of the xLSTM, by\nrelying less on the softmax attention mechanism for long context-retrieval.\n  The issue with small sliding windows is that they are detrimental for\nshort-context tasks, which could be solved with information from moderately\nlarger sliding windows otherwise. Therefore, we train SWAX by stochastically\nchanging the sliding window size, forcing the model to leverage both a longer\ncontext window and the xLSTM memory. SWAX trained with stochastic window sizes\nsignificantly outperforms regular window attention both on short and\nlong-context problems."}
{"id": "2509.24556", "pdf": "https://arxiv.org/pdf/2509.24556", "abs": "https://arxiv.org/abs/2509.24556", "authors": ["Hussam Sababha", "Bernat Font", "Mohammed Daqaq"], "title": "Deep Reinforcement Learning in Action: Real-Time Control of Vortex-Induced Vibrations", "categories": ["cs.LG", "cs.AI", "physics.flu-dyn"], "comment": null, "summary": "This study showcases an experimental deployment of deep reinforcement\nlearning (DRL) for active flow control (AFC) of vortex-induced vibrations (VIV)\nin a circular cylinder at a high Reynolds number (Re = 3000) using rotary\nactuation. Departing from prior work that relied on low-Reynolds-number\nnumerical simulations, this research demonstrates real-time control in a\nchallenging experimental setting, successfully addressing practical constraints\nsuch as actuator delay. When the learning algorithm is provided with state\nfeedback alone (displacement and velocity of the oscillating cylinder), the DRL\nagent learns a low-frequency rotary control strategy that achieves up to 80%\nvibration suppression which leverages the traditional lock-on phenomenon. While\nthis level of suppression is significant, it remains below the performance\nachieved using high-frequency rotary actuation. The reduction in performance is\nattributed to actuation delays and can be mitigated by augmenting the learning\nalgorithm with past control actions. This enables the agent to learn a\nhigh-frequency rotary control strategy that effectively modifies vortex\nshedding and achieves over 95% vibration attenuation. These results demonstrate\nthe adaptability of DRL for AFC in real-world experiments and its ability to\novercome instrumental limitations such as actuation lag."}
{"id": "2509.24559", "pdf": "https://arxiv.org/pdf/2509.24559", "abs": "https://arxiv.org/abs/2509.24559", "authors": ["Marco Molinari", "Leonardo Nevali", "Saharsha Navani", "Omar G. Younis"], "title": "Emergent World Representations in OpenVLA", "categories": ["cs.LG"], "comment": null, "summary": "Vision Language Action models (VLAs) trained with policy-based reinforcement\nlearning (RL) encode complex behaviors without explicitly modeling\nenvironmental dynamics. However, it remains unclear whether VLAs implicitly\nlearn world models, a hallmark of model-based RL. We propose an experimental\nmethodology using embedding arithmetic on state representations to probe\nwhether OpenVLA, the current state of the art in VLAs, contains latent\nknowledge of state transitions. Specifically, we measure the difference between\nembeddings of sequential environment states and test whether this transition\nvector is recoverable from intermediate model activations. Using linear and non\nlinear probes trained on activations across layers, we find statistically\nsignificant predictive ability on state transitions exceeding baselines\n(embeddings), indicating that OpenVLA encodes an internal world model (as\nopposed to the probes learning the state transitions). We investigate the\npredictive ability of an earlier checkpoint of OpenVLA, and uncover hints that\nthe world model emerges as training progresses. Finally, we outline a pipeline\nleveraging Sparse Autoencoders (SAEs) to analyze OpenVLA's world model."}
{"id": "2509.24573", "pdf": "https://arxiv.org/pdf/2509.24573", "abs": "https://arxiv.org/abs/2509.24573", "authors": ["Yusuf Guven", "Vincenzo Di Vito", "Ferdinando Fioretto"], "title": "Learning to Solve Optimization Problems Constrained with Partial Differential Equations", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Partial differential equation (PDE)-constrained optimization arises in many\nscientific and engineering domains, such as energy systems, fluid dynamics and\nmaterial design. In these problems, the decision variables (e.g., control\ninputs or design parameters) are tightly coupled with the PDE state variables,\nand the feasible set is implicitly defined by the governing PDE constraints.\nThis coupling makes the problems computationally demanding, as it requires\nhandling high dimensional discretization and dynamic constraints. To address\nthese challenges, this paper introduces a learning-based framework that\nintegrates a dynamic predictor with an optimization surrogate. The dynamic\npredictor, a novel time-discrete Neural Operator (Lu et al.), efficiently\napproximate system trajectories governed by PDE dynamics, while the\noptimization surrogate leverages proxy optimizer techniques (Kotary et al.) to\napproximate the associated optimal decisions. This dual-network design enables\nreal-time approximation of optimal strategies while explicitly capturing the\ncoupling between decisions and PDE dynamics. We validate the proposed approach\non benchmark PDE-constrained optimization tasks inlacing Burgers' equation,\nheat equation and voltage regulation, and demonstrate that it achieves solution\nquality comparable to classical control-based algorithms, such as the Direct\nMethod and Model Predictive Control (MPC), while providing up to four orders of\nmagnitude improvement in computational speed."}
{"id": "2509.24580", "pdf": "https://arxiv.org/pdf/2509.24580", "abs": "https://arxiv.org/abs/2509.24580", "authors": ["Lingyu Wang", "Xiangming Meng"], "title": "SAIP: A Plug-and-Play Scale-adaptive Module in Diffusion-based Inverse Problems", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Solving inverse problems with diffusion models has shown promise in tasks\nsuch as image restoration. A common approach is to formulate the problem in a\nBayesian framework and sample from the posterior by combining the prior score\nwith the likelihood score. Since the likelihood term is often intractable,\nestimators like DPS, DMPS, and $\\pi$GDM are widely adopted. However, these\nmethods rely on a fixed, manually tuned scale to balance prior and likelihood\ncontributions. Such a static design is suboptimal, as the ideal balance varies\nacross timesteps and tasks, limiting performance and generalization. To address\nthis issue, we propose SAIP, a plug-and-play module that adaptively refines the\nscale at each timestep without retraining or altering the diffusion backbone.\nSAIP integrates seamlessly into existing samplers and consistently improves\nreconstruction quality across diverse image restoration tasks, including\nchallenging scenarios."}
{"id": "2509.24601", "pdf": "https://arxiv.org/pdf/2509.24601", "abs": "https://arxiv.org/abs/2509.24601", "authors": ["Jae-Bum Seo", "Muhammad Salman", "Lismer Andres Caceres-Najarro"], "title": "CURA: Size Isnt All You Need -- A Compact Universal Architecture for On-Device Intelligence", "categories": ["cs.LG", "eess.SP"], "comment": "14 pages, 3 figures, 8 tables", "summary": "Existing on-device AI architectures for resource-constrained environments\nface two critical limitations: they lack compactness, with parameter\nrequirements scaling proportionally to task complexity, and they exhibit poor\ngeneralizability, performing effectively only on specific application domains\n(e.g., models designed for regression tasks cannot adapt to natural language\nprocessing (NLP) applications). In this paper, we propose CURA, an architecture\ninspired by analog audio signal processing circuits that provides a compact and\nlightweight solution for diverse machine learning tasks across multiple\ndomains. Our architecture offers three key advantages over existing approaches:\n(1) Compactness: it requires significantly fewer parameters regardless of task\ncomplexity; (2) Generalizability: it adapts seamlessly across regression,\nclassification, complex NLP, and computer vision tasks; and (3) Complex pattern\nrecognition: it can capture intricate data patterns while maintaining extremely\nlow model complexity. We evaluated CURA across diverse datasets and domains.\nFor compactness, it achieved equivalent accuracy using up to 2,500 times fewer\nparameters compared to baseline models. For generalizability, it demonstrated\nconsistent performance across four NLP benchmarks and one computer vision\ndataset, nearly matching specialized existing models (achieving F1-scores up to\n90%). Lastly, it delivers superior forecasting accuracy for complex patterns,\nachieving 1.6 times lower mean absolute error and 2.1 times lower mean squared\nerror than competing models."}
{"id": "2509.24608", "pdf": "https://arxiv.org/pdf/2509.24608", "abs": "https://arxiv.org/abs/2509.24608", "authors": ["Louise AC Millard", "Peter A Flach"], "title": "Evaluating classification performance across operating contexts: A comparison of decision curve analysis and cost curves", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Classification models typically predict a score and use a decision threshold\nto produce a classification. Appropriate model evaluation should carefully\nconsider the context in which a model will be used, including the relative\nvalue of correct classifications of positive versus negative examples, which\naffects the threshold that should be used. Decision curve analysis (DCA) and\ncost curves are model evaluation approaches that assess the expected utility\nand expected loss of prediction models, respectively, across decision\nthresholds. We compared DCA and cost curves to determine how they are related,\nand their strengths and limitations. We demonstrate that decision curves are\nclosely related to a specific type of cost curve called a Brier curve. Both\ncurves are derived assuming model scores are calibrated and setting the\nclassification threshold using the relative value of correct positive and\nnegative classifications, and the x-axis of both curves are equivalent. Net\nbenefit (used for DCA) and Brier loss (used for Brier curves) will always\nchoose the same model as optimal at any given threshold. Across thresholds,\ndifferences in Brier loss are comparable whereas differences in net benefit\ncannot be compared. Brier curves are more generally applicable (when a wider\nrange of thresholds are plausible), and the area under the Brier curve is the\nBrier score. We demonstrate that reference lines common in each space can be\nincluded in either and suggest the upper envelope decision curve as a useful\ncomparison for DCA showing the possible gain in net benefit that could be\nachieved through recalibration alone."}
{"id": "2509.24610", "pdf": "https://arxiv.org/pdf/2509.24610", "abs": "https://arxiv.org/abs/2509.24610", "authors": ["Liang Lin", "Zhihao Xu", "Junhao Dong", "Jian Zhao", "Yuchen Yuan", "Guibin Zhang", "Miao Yu", "Yiming Zhang", "Zhengtao Yao", "Huahui Yi", "Dongrui Liu", "Xinfeng Li", "Kun Wang"], "title": "OrthAlign: Orthogonal Subspace Decomposition for Non-Interfering Multi-Objective Alignment", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Large language model (LLM) alignment faces a critical dilemma when addressing\nmultiple human preferences: improvements in one dimension frequently come at\nthe expense of others, creating unavoidable trade-offs between competing\nobjectives like helpfulness and harmlessness. While prior work mainly focuses\non constraint-based optimization algorithms and data selection strategies to\nmitigate conflicts, these approaches overlook the fundamental issue of\nresolving conflicts directly at the parameter level. In this paper, we present\nOrthAlign, an innovative approach that pioneers a new paradigm by leveraging\northogonal subspace decomposition to fundamentally resolve gradient-level\nconflicts in multi-objective preference alignment. OrthAlign strategically\ndecomposes parameter update spaces into orthogonal subspaces, ensuring that\noptimization toward different preferences occurs in mathematically\nnon-interfering directions. Building upon this, we provide theoretical\nguarantees demonstrating that when parameter increments satisfy both orthogonal\nsubspace constraints and spectral norm bounds, the resulting updates exhibit\nlinear Lipschitz growth rather than exponential instability, ensuring stable\nconvergence across all preference dimensions. Extensive experiments show that:\nI. OrthAlign achieves maximum single-preference improvements ranging from\n34.61% to 50.89% after multiple-objective alignment across helpful, harmless,\nand truthful dimensions. II. With an average overall reward improvement of\n13.96%."}
{"id": "2509.24627", "pdf": "https://arxiv.org/pdf/2509.24627", "abs": "https://arxiv.org/abs/2509.24627", "authors": ["Katharina Friedl", "Noémie Jaquier", "Mika Liao", "Danica Kragic"], "title": "Learning Hamiltonian Dynamics at Scale: A Differential-Geometric Approach", "categories": ["cs.LG"], "comment": "28 pages, 15 figures", "summary": "By embedding physical intuition, network architectures enforce fundamental\nproperties, such as energy conservation laws, leading to plausible predictions.\nYet, scaling these models to intrinsically high-dimensional systems remains a\nsignificant challenge. This paper introduces Geometric Reduced-order\nHamiltonian Neural Network (RO-HNN), a novel physics-inspired neural network\nthat combines the conservation laws of Hamiltonian mechanics with the\nscalability of model order reduction. RO-HNN is built on two core components: a\nnovel geometrically-constrained symplectic autoencoder that learns a\nlow-dimensional, structure-preserving symplectic submanifold, and a geometric\nHamiltonian neural network that models the dynamics on the submanifold. Our\nexperiments demonstrate that RO-HNN provides physically-consistent, stable, and\ngeneralizable predictions of complex high-dimensional dynamics, thereby\neffectively extending the scope of Hamiltonian neural networks to\nhigh-dimensional physical systems."}
{"id": "2509.24653", "pdf": "https://arxiv.org/pdf/2509.24653", "abs": "https://arxiv.org/abs/2509.24653", "authors": ["Pengxiao Lin", "Zheng-An Chen", "Zhi-Qin John Xu"], "title": "Identity Bridge: Enabling Implicit Reasoning via Shared Latent Memory", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Despite remarkable advances, large language models often fail at\ncompositional reasoning tasks, a phenomenon exemplified by the ``curse of\ntwo-hop reasoning''. This paper introduces the Identity Bridge, a simple yet\npowerful mechanism that resolves this compositionality gap by supervising the\nmodel on a zero-hop identity task. We demonstrate empirically that this\naddition enables models to successfully perform out-of-distribution two-hop\nreasoning, a task they otherwise completely fail. To explain this phenomenon,\nwe provide a theoretical analysis using a simplified Emb-MLP model, proving\nthat identity supervision reshapes the model's latent geometry. We show this\nalignment is induced by an implicit nuclear-norm regularization during\noptimization, which favors low-rank solutions that share structure across\ntasks. For complex tasks, we use small initialization or weight decay to\nenhance the regularization effect, which enhances the latent space alignment\neffect and slows down the generalization decay. Finally, we extend our\ninvestigation to large-scale models, observing that they still achieve two-hop\nreasoning through the latent memory, which provides crucial inspiration for\nenhancing their implicit reasoning abilities."}
{"id": "2509.24655", "pdf": "https://arxiv.org/pdf/2509.24655", "abs": "https://arxiv.org/abs/2509.24655", "authors": ["Max van Spengler", "Artem Moskalev", "Tommaso Mansi", "Mangal Prakash", "Rui Liao"], "title": "HyperHELM: Hyperbolic Hierarchy Encoding for mRNA Language Modeling", "categories": ["cs.LG", "q-bio.GN"], "comment": null, "summary": "Language models are increasingly applied to biological sequences like\nproteins and mRNA, yet their default Euclidean geometry may mismatch the\nhierarchical structures inherent to biological data. While hyperbolic geometry\nprovides a better alternative for accommodating hierarchical data, it has yet\nto find a way into language modeling for mRNA sequences. In this work, we\nintroduce HyperHELM, a framework that implements masked language model\npre-training in hyperbolic space for mRNA sequences. Using a hybrid design with\nhyperbolic layers atop Euclidean backbone, HyperHELM aligns learned\nrepresentations with the biological hierarchy defined by the relationship\nbetween mRNA and amino acids. Across multiple multi-species datasets, it\noutperforms Euclidean baselines on 9 out of 10 tasks involving property\nprediction, with 10% improvement on average, and excels in out-of-distribution\ngeneralization to long and low-GC content sequences; for antibody region\nannotation, it surpasses hierarchy-aware Euclidean models by 3% in annotation\naccuracy. Our results highlight hyperbolic geometry as an effective inductive\nbias for hierarchical language modeling of mRNA sequences."}
{"id": "2509.24696", "pdf": "https://arxiv.org/pdf/2509.24696", "abs": "https://arxiv.org/abs/2509.24696", "authors": ["Zikun Qu", "Min Zhang", "Mingze Kong", "Xiang Li", "Zhiwei Shang", "Zhiyong Wang", "Yikun Ban", "Shuang Qiu", "Yao Shu", "Zhongxiang Dai"], "title": "T-POP: Test-Time Personalization with Online Preference Feedback", "categories": ["cs.LG", "cs.AI"], "comment": "Preprint", "summary": "Personalizing large language models (LLMs) to individual user preferences is\na critical step beyond generating generically helpful responses. However,\ncurrent personalization methods are ill-suited for new users, as they typically\nrequire either slow, resource-intensive fine-tuning or a substantial amount of\npre-existing user data, creating a significant cold-start problem. To address\nthis challenge, we introduce a new paradigm for real-time personalization by\nlearning from online pairwise preference feedback collected during text\ngeneration. We propose T-POP (Test-Time Personalization with Online Preference\nFeedback}), a novel algorithm that synergistically combines test-time alignment\nwith dueling bandits. Without updating the LLM parameters, T-POP steers the\ndecoding process of a frozen LLM by learning a reward function online that\ncaptures user preferences. By leveraging dueling bandits, T-POP intelligently\nqueries the user to efficiently balance between exploring their preferences and\nexploiting the learned knowledge to generate personalized text. Extensive\nexperiments demonstrate that T-POP achieves rapid and data-efficient\npersonalization, significantly outperforming existing baselines and showing\nconsistent improvement with more user interactions."}
{"id": "2509.24701", "pdf": "https://arxiv.org/pdf/2509.24701", "abs": "https://arxiv.org/abs/2509.24701", "authors": ["Pingchen Lu", "Zhi Hong", "Zhiwei Shang", "Zhiyong Wang", "Yikun Ban", "Yao Shu", "Min Zhang", "Shuang Qiu", "Zhongxiang Dai"], "title": "FedPOB: Sample-Efficient Federated Prompt Optimization via Bandits", "categories": ["cs.LG", "cs.AI"], "comment": "Preprint", "summary": "The performance of large language models (LLMs) is highly sensitive to the\ninput prompt, making prompt optimization a critical task. However, real-world\napplication is hindered by three major challenges: (1) the black-box nature of\npowerful proprietary LLMs, (2) the need for high sample efficiency due to query\ncosts, and (3) the desire for privacy-preserving collaboration among multiple\nusers. To address these challenges simultaneously, we introduce a novel\nframework for sample-efficient federated prompt optimization based on\nmulti-armed bandits (MABs). The MAB framework is uniquely suited for this\nproblem as it is (1) inherently a black-box optimization method, (2)\npractically sample-efficient, and (3) enables collaborative learning with\ntheoretically guaranteed benefit from more participating agents. We first\npropose the Federated Prompt Optimization via Bandits (FedPOB) algorithm, a\nfederated variant of the Linear UCB algorithm, where agents collaborate by\nsharing model parameters instead of raw data. We then extend our approach to\nthe practical setting of comparative user feedback by introducing FedPOB with\nPreference Feedback (FedPOB-Pref), an efficient algorithm based on federated\ndueling bandits. Extensive experiments demonstrate that both FedPOB and\nFedPOB-Pref significantly outperform existing baselines and that their\nperformance consistently improves as more agents participate in the\ncollaboration, validating the effectiveness of our federated approach."}
{"id": "2509.24713", "pdf": "https://arxiv.org/pdf/2509.24713", "abs": "https://arxiv.org/abs/2509.24713", "authors": ["Jing Liu"], "title": "Circuit-Aware Reward Training: A Mechanistic Framework for Longtail Robustness in RLHF", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement Learning from Human Feedback (RLHF) reward models exhibit\nsystematic failures on longtail distributions, leading to reward hacking and\nmisalignment. We propose a mechanistic interpretability framework that\nidentifies specialized neural circuits responsible for rare-event processing in\nreward models. Drawing from recent advances showing distributed specialization\nfor rare tokens in language models\\citep{liu2025no, liu2025emergent}, we\nhypothesize that reward models also develop functionally distinct circuits for\nlongtail scenarios. Our theoretical framework establishes formal connections\nbetween circuit specialization, reward generalization bounds, and longtail\nperformance. We introduce \\textbf{Circuit-Aware Reward Training (CART)}, which\nuses circuit analysis to guide data augmentation, regularization, and ensemble\nstrategies. This approach provides both theoretical insights into reward model\nfailures and practical interventions for improving longtail robustness."}
{"id": "2509.24716", "pdf": "https://arxiv.org/pdf/2509.24716", "abs": "https://arxiv.org/abs/2509.24716", "authors": ["Michael Drolet", "Firas Al-Hafez", "Aditya Bhatt", "Jan Peters", "Oleg Arenz"], "title": "Discrete Variational Autoencoding via Policy Search", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "Discrete latent bottlenecks in variational autoencoders (VAEs) offer high bit\nefficiency and can be modeled with autoregressive discrete distributions,\nenabling parameter-efficient multimodal search with transformers. However,\ndiscrete random variables do not allow for exact differentiable\nparameterization; therefore, discrete VAEs typically rely on approximations,\nsuch as Gumbel-Softmax reparameterization or straight-through gradient\nestimates, or employ high-variance gradient-free methods such as REINFORCE that\nhave had limited success on high-dimensional tasks such as image\nreconstruction. Inspired by popular techniques in policy search, we propose a\ntraining framework for discrete VAEs that leverages the natural gradient of a\nnon-parametric encoder to update the parametric encoder without requiring\nreparameterization. Our method, combined with automatic step size adaptation\nand a transformer-based encoder, scales to challenging datasets such as\nImageNet and outperforms both approximate reparameterization methods and\nquantization-based discrete autoencoders in reconstructing high-dimensional\ndata from compact latent spaces, achieving a 20% improvement on FID Score for\nImageNet 256."}
{"id": "2509.24725", "pdf": "https://arxiv.org/pdf/2509.24725", "abs": "https://arxiv.org/abs/2509.24725", "authors": ["Ting Gao", "Elvin Isufi", "Winnie Daamen", "Erik-Sander Smits", "Serge Hoogendoorn"], "title": "Q-Net: Transferable Queue Length Estimation via Kalman-based Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Estimating queue lengths at signalized intersections remains a challenge in\ntraffic management, especially under partially observed conditions where\nvehicle flows are not fully captured. This paper introduces Q-Net, a\ndata-efficient and interpretable framework for queue length estimation that\nperforms robustly even when traffic conservation assumptions are violated.\nQ-Net integrates two widely available and privacy-friendly data sources: (i)\nvehicle counts from loop detectors near stop lines, and (ii) aggregated\nfloating car data (aFCD), which divides each road section into segments and\nprovides segment-wise average speed measurements. These data sources often\ndiffer in spatial and temporal resolution, creating fusion challenges. Q-Net\naddresses this by employing a tailored state-space model and an AI-augmented\nKalman filter, KalmanNet, which learns the Kalman gain from data without\nrequiring prior knowledge of noise covariances or full system dynamics. We\nbuild on the vanilla KalmanNet pipeline to decouple measurement dimensionality\nfrom section length, enabling spatial transferability across road segments.\nUnlike black-box models, Q-Net maintains physical interpretability, with\ninternal variables linked to real-world traffic dynamics. Evaluations on main\nroads in Rotterdam, the Netherlands, demonstrate that Q-Net outperforms\nbaseline methods by over 60\\% in Root Mean Square Error (RMSE), accurately\ntracking queue formation and dissipation while correcting aFCD-induced delays.\nQ-Net also demonstrates strong spatial and temporal transferability, enabling\ndeployment without costly sensing infrastructure like cameras or radar.\nAdditionally, we propose a real-time variant of Q-Net, highlighting its\npotential for integration into dynamic, queue-based traffic control systems."}
{"id": "2509.24728", "pdf": "https://arxiv.org/pdf/2509.24728", "abs": "https://arxiv.org/abs/2509.24728", "authors": ["Alessandro Manenti", "Cesare Alippi"], "title": "Beyond Softmax: A Natural Parameterization for Categorical Random Variables", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Latent categorical variables are frequently found in deep learning\narchitectures. They can model actions in discrete reinforcement-learning\nenvironments, represent categories in latent-variable models, or express\nrelations in graph neural networks. Despite their widespread use, their\ndiscrete nature poses significant challenges to gradient-descent learning\nalgorithms. While a substantial body of work has offered improved gradient\nestimation techniques, we take a complementary approach. Specifically, we: 1)\nrevisit the ubiquitous $\\textit{softmax}$ function and demonstrate its\nlimitations from an information-geometric perspective; 2) replace the\n$\\textit{softmax}$ with the $\\textit{catnat}$ function, a function composed of\na sequence of hierarchical binary splits; we prove that this choice offers\nsignificant advantages to gradient descent due to the resulting diagonal Fisher\nInformation Matrix. A rich set of experiments - including graph structure\nlearning, variational autoencoders, and reinforcement learning - empirically\nshow that the proposed function improves the learning efficiency and yields\nmodels characterized by consistently higher test performance. $\\textit{Catnat}$\nis simple to implement and seamlessly integrates into existing codebases.\nMoreover, it remains compatible with standard training stabilization techniques\nand, as such, offers a better alternative to the $\\textit{softmax}$ function."}
{"id": "2509.24732", "pdf": "https://arxiv.org/pdf/2509.24732", "abs": "https://arxiv.org/abs/2509.24732", "authors": ["Juergen Schmidhuber"], "title": "Who invented deep residual learning?", "categories": ["cs.LG", "cs.NE"], "comment": "12 pages, 2 illustrations, circa 100 partially annotated references", "summary": "Modern AI is based on deep artificial neural networks (NNs). As of 2025, the\nmost cited scientific article of the 21st century is an NN paper on deep\nresidual learning with residual connections. Who invented this? We present a\ntimeline of the evolution of deep residual learning."}
{"id": "2509.24734", "pdf": "https://arxiv.org/pdf/2509.24734", "abs": "https://arxiv.org/abs/2509.24734", "authors": ["Giordano Cicchetti", "Eleonora Grassucci", "Danilo Comminiello"], "title": "A TRIANGLE Enables Multimodal Alignment Beyond Cosine Similarity", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "NeurIPS 2025", "summary": "Multimodal learning plays a pivotal role in advancing artificial intelligence\nsystems by incorporating information from multiple modalities to build a more\ncomprehensive representation. Despite its importance, current state-of-the-art\nmodels still suffer from severe limitations that prevent the successful\ndevelopment of a fully multimodal model. Such methods may not provide\nindicators that all the involved modalities are effectively aligned. As a\nresult, some modalities may not be aligned, undermining the effectiveness of\nthe model in downstream tasks where multiple modalities should provide\nadditional information that the model fails to exploit. In this paper, we\npresent TRIANGLE: TRI-modAl Neural Geometric LEarning, the novel proposed\nsimilarity measure that is directly computed in the higher-dimensional space\nspanned by the modality embeddings. TRIANGLE improves the joint alignment of\nthree modalities via a triangle-area similarity, avoiding additional fusion\nlayers or pairwise similarities. When incorporated in contrastive losses\nreplacing cosine similarity, TRIANGLE significantly boosts the performance of\nmultimodal modeling, while yielding interpretable alignment rationales.\nExtensive evaluation in three-modal tasks such as video-text and audio-text\nretrieval or audio-video classification, demonstrates that TRIANGLE achieves\nstate-of-the-art results across different datasets improving the performance of\ncosine-based methods up to 9 points of Recall@1."}
{"id": "2509.24748", "pdf": "https://arxiv.org/pdf/2509.24748", "abs": "https://arxiv.org/abs/2509.24748", "authors": ["Longxiang He", "Deheng Ye", "Junbo Tan", "Xueqian Wang", "Li Shen"], "title": "Robust Policy Expansion for Offline-to-Online RL under Diverse Data Corruption", "categories": ["cs.LG", "cs.AI"], "comment": "39th Conference on Neural Information Processing Systems", "summary": "Pretraining a policy on offline data followed by fine-tuning through online\ninteractions, known as Offline-to-Online Reinforcement Learning (O2O RL), has\nemerged as a promising paradigm for real-world RL deployment. However, both\noffline datasets and online interactions in practical environments are often\nnoisy or even maliciously corrupted, severely degrading the performance of O2O\nRL. Existing works primarily focus on mitigating the conservatism of offline\npolicies via online exploration, while the robustness of O2O RL under data\ncorruption, including states, actions, rewards, and dynamics, is still\nunexplored. In this work, we observe that data corruption induces heavy-tailed\nbehavior in the policy, thereby substantially degrading the efficiency of\nonline exploration. To address this issue, we incorporate Inverse Probability\nWeighted (IPW) into the online exploration policy to alleviate\nheavy-tailedness, and propose a novel, simple yet effective method termed\n$\\textbf{RPEX}$: $\\textbf{R}$obust $\\textbf{P}$olicy $\\textbf{EX}$pansion.\nExtensive experimental results on D4RL datasets demonstrate that RPEX achieves\nSOTA O2O performance across a wide range of data corruption scenarios. Code is\navailable at\n$\\href{https://github.com/felix-thu/RPEX}{https://github.com/felix-thu/RPEX}$."}
{"id": "2509.24762", "pdf": "https://arxiv.org/pdf/2509.24762", "abs": "https://arxiv.org/abs/2509.24762", "authors": ["David Berghaus", "Patrick Seifner", "Kostadin Cvejoski", "César Ojeda", "Ramsés J. Sánchez"], "title": "In-Context Learning of Temporal Point Processes with Foundation Inference Models", "categories": ["cs.LG"], "comment": null, "summary": "Modeling event sequences of multiple event types with marked temporal point\nprocesses (MTPPs) provides a principled way to uncover governing dynamical\nrules and predict future events. Current neural network approaches to MTPP\ninference rely on training separate, specialized models for each target system.\nWe pursue a radically different approach: drawing on amortized inference and\nin-context learning, we pretrain a deep neural network to infer, in-context,\nthe conditional intensity functions of event histories from a context defined\nby sets of event sequences. Pretraining is performed on a large synthetic\ndataset of MTPPs sampled from a broad distribution of Hawkes processes. Once\npretrained, our Foundation Inference Model for Point Processes (FIM-PP) can\nestimate MTPPs from real-world data without any additional training, or be\nrapidly finetuned to target systems. Experiments show that this amortized\napproach matches the performance of specialized models on next-event prediction\nacross common benchmark datasets.\n  Our pretrained model, repository and tutorials will soon be available online"}
{"id": "2509.24770", "pdf": "https://arxiv.org/pdf/2509.24770", "abs": "https://arxiv.org/abs/2509.24770", "authors": ["Fabrizio Frasca", "Guy Bar-Shalom", "Yftah Ziser", "Haggai Maron"], "title": "Neural Message-Passing on Attention Graphs for Hallucination Detection", "categories": ["cs.LG"], "comment": "Preprint. 25 pages, 2 figures", "summary": "Large Language Models (LLMs) often generate incorrect or unsupported content,\nknown as hallucinations. Existing detection methods rely on heuristics or\nsimple models over isolated computational traces such as activations, or\nattention maps. We unify these signals by representing them as attributed\ngraphs, where tokens are nodes, edges follow attentional flows, and both carry\nfeatures from attention scores and activations. Our approach, CHARM, casts\nhallucination detection as a graph learning task and tackles it by applying\nGNNs over the above attributed graphs. We show that CHARM provably subsumes\nprior attention-based heuristics and, experimentally, it consistently\noutperforms other leading approaches across diverse benchmarks. Our results\nshed light on the relevant role played by the graph structure and on the\nbenefits of combining computational traces, whilst showing CHARM exhibits\npromising zero-shot performance on cross-dataset transfer."}
{"id": "2509.24779", "pdf": "https://arxiv.org/pdf/2509.24779", "abs": "https://arxiv.org/abs/2509.24779", "authors": ["Kacper Kapuśniak", "Cristian Gabellini", "Michael Bronstein", "Prudencio Tossou", "Francesco Di Giovanni"], "title": "MarS-FM: Generative Modeling of Molecular Dynamics via Markov State Models", "categories": ["cs.LG", "q-bio.BM"], "comment": null, "summary": "Molecular Dynamics (MD) is a powerful computational microscope for probing\nprotein functions. However, the need for fine-grained integration and the long\ntimescales of biomolecular events make MD computationally expensive. To address\nthis, several generative models have been proposed to generate surrogate\ntrajectories at lower cost. Yet, these models typically learn a fixed-lag\ntransition density, causing the training signal to be dominated by frequent but\nuninformative transitions. We introduce a new class of generative models, MSM\nEmulators, which instead learn to sample transitions across discrete states\ndefined by an underlying Markov State Model (MSM). We instantiate this class\nwith Markov Space Flow Matching (MarS-FM), whose sampling offers more than two\norders of magnitude speedup compared to implicit- or explicit-solvent MD\nsimulations. We benchmark Mars-FM ability to reproduce MD statistics through\nstructural observables such as RMSD, radius of gyration, and secondary\nstructure content. Our evaluation spans protein domains (up to 500 residues)\nwith significant chemical and structural diversity, including unfolding events,\nand enforces strict sequence dissimilarity between training and test sets to\nassess generalization. Across all metrics, MarS-FM outperforms existing\nmethods, often by a substantial margin."}
{"id": "2509.24784", "pdf": "https://arxiv.org/pdf/2509.24784", "abs": "https://arxiv.org/abs/2509.24784", "authors": ["Nathan Gavenski", "Odinaldo Rodrigues"], "title": "Quantifying Generalisation in Imitation Learning", "categories": ["cs.LG", "cs.AI"], "comment": "NeurIPS 2025 Datasets and Benchmarks Track poster", "summary": "Imitation learning benchmarks often lack sufficient variation between\ntraining and evaluation, limiting meaningful generalisation assessment. We\nintroduce Labyrinth, a benchmarking environment designed to test generalisation\nwith precise control over structure, start and goal positions, and task\ncomplexity. It enables verifiably distinct training, evaluation, and test\nsettings. Labyrinth provides a discrete, fully observable state space and known\noptimal actions, supporting interpretability and fine-grained evaluation. Its\nflexible setup allows targeted testing of generalisation factors and includes\nvariants like partial observability, key-and-door tasks, and ice-floor hazards.\nBy enabling controlled, reproducible experiments, Labyrinth advances the\nevaluation of generalisation in imitation learning and provides a valuable tool\nfor developing more robust agents."}
{"id": "2509.24788", "pdf": "https://arxiv.org/pdf/2509.24788", "abs": "https://arxiv.org/abs/2509.24788", "authors": ["Felix Strnad", "Jonathan Schmidt", "Fabian Mockert", "Philipp Hennig", "Nicole Ludwig"], "title": "Assessing the risk of future Dunkelflaute events for Germany using generative deep learning", "categories": ["cs.LG", "physics.geo-ph"], "comment": null, "summary": "The European electricity power grid is transitioning towards renewable energy\nsources, characterized by an increasing share of off- and onshore wind and\nsolar power. However, the weather dependency of these energy sources poses a\nchallenge to grid stability, with so-called Dunkelflaute events -- periods of\nlow wind and solar power generation -- being of particular concern due to their\npotential to cause electricity supply shortages. In this study, we investigate\nthe impact of these events on the German electricity production in the years\nand decades to come. For this purpose, we adapt a recently developed generative\ndeep learning framework to downscale climate simulations from the CMIP6\nensemble. We first compare their statistics to the historical record taken from\nERA5 data. Next, we use these downscaled simulations to assess plausible future\noccurrences of Dunkelflaute events in Germany under the optimistic low\n(SSP2-4.5) and high (SSP5-8.5) emission scenarios. Our analysis indicates that\nboth the frequency and duration of Dunkelflaute events in Germany in the\nensemble mean are projected to remain largely unchanged compared to the\nhistorical period. This suggests that, under the considered climate scenarios,\nthe associated risk is expected to remain stable throughout the century."}
{"id": "2509.24789", "pdf": "https://arxiv.org/pdf/2509.24789", "abs": "https://arxiv.org/abs/2509.24789", "authors": ["Zhijian Xu", "Wanxu Cai", "Xilin Dai", "Zhaorong Deng", "Qiang Xu"], "title": "Fidel-TS: A High-Fidelity Benchmark for Multimodal Time Series Forecasting", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "The evaluation of time series forecasting models is hindered by a critical\nlack of high-quality benchmarks, leading to a potential illusion of progress.\nExisting datasets suffer from issues ranging from pre-training data\ncontamination in the age of LLMs to the causal and description leakage\nprevalent in early multimodal designs. To address this, we formalize the core\nprinciples of high-fidelity benchmarking, focusing on data sourcing integrity,\nstrict causal soundness, and structural clarity. We introduce Fidel-TS, a new\nlarge-scale benchmark built from the ground up on these principles by sourcing\ndata from live APIs. Our extensive experiments validate this approach by\nexposing the critical biases and design limitations of prior benchmarks.\nFurthermore, we conclusively demonstrate that the causal relevance of textual\ninformation is the key factor in unlocking genuine performance gains in\nmultimodal forecasting."}
{"id": "2509.24800", "pdf": "https://arxiv.org/pdf/2509.24800", "abs": "https://arxiv.org/abs/2509.24800", "authors": ["Zixu Wang", "Hongbin Dong", "Xiaoping Zhang"], "title": "DSAT-HD: Dual-Stream Adaptive Transformer with Hybrid Decomposition for Multivariate Time Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": "10 pages, 5 figures", "summary": "Time series forecasting is crucial for various applications, such as weather,\ntraffic, electricity, and energy predictions. Currently, common time series\nforecasting methods are based on Transformers. However, existing approaches\nprimarily model limited time series or fixed scales, making it more challenging\nto capture diverse features cross different ranges. Additionally, traditional\nmethods like STL for complex seasonality-trend decomposition require\npre-specified seasonal periods and typically handle only single, fixed\nseasonality. We propose the Hybrid Decomposition Dual-Stream Adaptive\nTransformer (DSAT-HD), which integrates three key innovations to address the\nlimitations of existing methods: 1) A hybrid decomposition mechanism combining\nEMA and Fourier decomposition with RevIN normalization, dynamically balancing\nseasonal and trend components through noise Top-k gating; 2) A multi-scale\nadaptive pathway leveraging a sparse allocator to route features to four\nparallel Transformer layers, followed by feature merging via a sparse combiner,\nenhanced by hybrid attention combining local CNNs and global interactions; 3) A\ndual-stream residual learning framework where CNN and MLP branches separately\nprocess seasonal and trend components, coordinated by a balanced loss function\nminimizing expert collaboration variance. Extensive experiments on nine\ndatasets demonstrate that DSAT-HD outperforms existing methods overall and\nachieves state-of-the-art performance on some datasets. Notably, it also\nexhibits stronger generalization capabilities across various transfer\nscenarios."}
{"id": "2509.24801", "pdf": "https://arxiv.org/pdf/2509.24801", "abs": "https://arxiv.org/abs/2509.24801", "authors": ["Anna Scampicchio", "Leonardo F. Toso", "Rahel Rickenbach", "James Anderson", "Melanie N. Zeilinger"], "title": "Physics-informed learning under mixing: How physical knowledge speeds up learning", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "A major challenge in physics-informed machine learning is to understand how\nthe incorporation of prior domain knowledge affects learning rates when data\nare dependent. Focusing on empirical risk minimization with physics-informed\nregularization, we derive complexity-dependent bounds on the excess risk in\nprobability and in expectation. We prove that, when the physical prior\ninformation is aligned, the learning rate improves from the (slow) Sobolev\nminimax rate to the (fast) optimal i.i.d. one without any sample-size deflation\ndue to data dependence."}
{"id": "2509.24804", "pdf": "https://arxiv.org/pdf/2509.24804", "abs": "https://arxiv.org/abs/2509.24804", "authors": ["Boxuan Zhang", "Runqing Wang", "Wei Xiao", "Weipu Zhang", "Jian Sun", "Gao Huang", "Jie Chen", "Gang Wang"], "title": "DyMoDreamer: World Modeling with Dynamic Modulation", "categories": ["cs.LG"], "comment": null, "summary": "A critical bottleneck in deep reinforcement learning (DRL) is sample\ninefficiency, as training high-performance agents often demands extensive\nenvironmental interactions. Model-based reinforcement learning (MBRL) mitigates\nthis by building world models that simulate environmental dynamics and generate\nsynthetic experience, improving sample efficiency. However, conventional world\nmodels process observations holistically, failing to decouple dynamic objects\nand temporal features from static backgrounds. This approach is computationally\ninefficient, especially for visual tasks where dynamic objects significantly\ninfluence rewards and decision-making performance. To address this, we\nintroduce DyMoDreamer, a novel MBRL algorithm that incorporates a dynamic\nmodulation mechanism to improve the extraction of dynamic features and enrich\nthe temporal information. DyMoDreamer employs differential observations derived\nfrom a novel inter-frame differencing mask, explicitly encoding object-level\nmotion cues and temporal dynamics. Dynamic modulation is modeled as stochastic\ncategorical distributions and integrated into a recurrent state-space model\n(RSSM), enhancing the model's focus on reward-relevant dynamics. Experiments\ndemonstrate that DyMoDreamer sets a new state-of-the-art on the Atari $100$k\nbenchmark with a $156.6$\\% mean human-normalized score, establishes a new\nrecord of $832$ on the DeepMind Visual Control Suite, and gains a $9.5$\\%\nperformance improvement after $1$M steps on the Crafter benchmark. Our code is\nreleased at https://github.com/Ultraman-Tiga1/DyMoDreamer."}
{"id": "2509.24827", "pdf": "https://arxiv.org/pdf/2509.24827", "abs": "https://arxiv.org/abs/2509.24827", "authors": ["Bartosz Bieganowski", "Daniel Strzelecki", "Robert Skiba", "Mateusz Topolewski"], "title": "Putnam-like dataset summary: LLMs as mathematical competition contestants", "categories": ["cs.LG", "cs.AI"], "comment": "11 pages, 11 figures", "summary": "In this paper we summarize the results of the Putnam-like benchmark published\nby Google DeepMind. This dataset consists of 96 original problems in the spirit\nof the Putnam Competition and 576 solutions of LLMs. We analyse the performance\nof models on this set of problems to verify their ability to solve problems\nfrom mathematical contests."}
{"id": "2509.24840", "pdf": "https://arxiv.org/pdf/2509.24840", "abs": "https://arxiv.org/abs/2509.24840", "authors": ["Oussama Kharouiche", "Aris Markogiannakis", "Xiao Fei", "Michail Chatzianastasis", "Michalis Vazirgiannis"], "title": "Cell2Text: Multimodal LLM for Generating Single-Cell Descriptions from RNA-Seq Data", "categories": ["cs.LG", "cs.CE"], "comment": null, "summary": "Single-cell RNA sequencing has transformed biology by enabling the\nmeasurement of gene expression at cellular resolution, providing information\nfor cell types, states, and disease contexts. Recently, single-cell foundation\nmodels have emerged as powerful tools for learning transferable representations\ndirectly from expression profiles, improving performance on classification and\nclustering tasks. However, these models are limited to discrete prediction\nheads, which collapse cellular complexity into predefined labels that fail to\ncapture the richer, contextual explanations biologists need. We introduce\nCell2Text, a multimodal generative framework that translates scRNA-seq profiles\ninto structured natural language descriptions. By integrating gene-level\nembeddings from single-cell foundation models with pretrained large language\nmodels, Cell2Text generates coherent summaries that capture cellular identity,\ntissue origin, disease associations, and pathway activity, generalizing to\nunseen cells. Empirically, Cell2Text outperforms baselines on classification\naccuracy, demonstrates strong ontological consistency using PageRank-based\nsimilarity metrics, and achieves high semantic fidelity in text generation.\nThese results demonstrate that coupling expression data with natural language\noffers both stronger predictive performance and inherently interpretable\noutputs, pointing to a scalable path for label-efficient characterization of\nunseen cells."}
{"id": "2509.24856", "pdf": "https://arxiv.org/pdf/2509.24856", "abs": "https://arxiv.org/abs/2509.24856", "authors": ["Christos Mountzouris"], "title": "Beyond the Hook: Predicting Billboard Hot 100 Chart Inclusion with Machine Learning from Streaming, Audio Signals, and Perceptual Features", "categories": ["cs.LG"], "comment": "17 pages, 6 figures, 3 tables", "summary": "The advent of digital streaming platforms have recently revolutionized the\nlandscape of music industry, with the ensuing digitalization providing\nstructured data collections that open new research avenues for investigating\npopularity dynamics and mainstream success. The present work explored which\ndeterminants hold the strongest predictive influence for a track's inclusion in\nthe Billboard Hot 100 charts, including streaming popularity, measurable audio\nsignal attributes, and probabilistic indicators of human listening. The\nanalysis revealed that popularity was by far the most decisive predictor of\nBillboard Hot 100 inclusion, with considerable contribution from\ninstrumentalness, valence, duration and speechiness. Logistic Regression\nachieved 90.0% accuracy, with very high recall for charting singles (0.986) but\nlower recall for non-charting ones (0.813), yielding balanced F1-scores around\n0.90. Random Forest slightly improved performance to 90.4% accuracy,\nmaintaining near-perfect precision for non-charting singles (0.990) and high\nrecall for charting ones (0.992), with F1-scores up to 0.91. Gradient Boosting\n(XGBoost) reached 90.3% accuracy, delivering a more balanced trade-off by\nimproving recall for non-charting singles (0.837) while sustaining high recall\nfor charting ones (0.969), resulting in F1-scores comparable to the other\nmodels."}
{"id": "2509.24868", "pdf": "https://arxiv.org/pdf/2509.24868", "abs": "https://arxiv.org/abs/2509.24868", "authors": ["Jiayi Li", "Flora D. Salim"], "title": "DRIFT-Net: A Spectral--Coupled Neural Operator for PDEs Learning", "categories": ["cs.LG", "physics.comp-ph"], "comment": null, "summary": "Learning PDE dynamics with neural solvers can significantly improve\nwall-clock efficiency and accuracy compared with classical numerical solvers.\nIn recent years, foundation models for PDEs have largely adopted multi-scale\nwindowed self-attention, with the scOT backbone in \\textsc{Poseidon} serving as\na representative example.\n  However, because of their locality, truly globally consistent spectral\ncoupling can only be propagated gradually through deep stacking and window\nshifting. This weakens global coupling and leads to error accumulation and\ndrift during closed-loop rollouts. To address this, we propose\n\\textbf{DRIFT-Net}. It employs a dual-branch design comprising a spectral\nbranch and an image branch. The spectral branch is responsible for capturing\nglobal, large-scale low-frequency information, whereas the image branch focuses\non local details and nonstationary structures. Specifically, we first perform\ncontrolled, lightweight mixing within the low-frequency range. Then we fuse the\nspectral and image paths at each layer via bandwise weighting, which avoids the\nwidth inflation and training instability caused by naive concatenation. The\nfused result is transformed back into the spatial domain and added to the image\nbranch, thereby preserving both global structure and high-frequency details\nacross scales. Compared with strong attention-based baselines, DRIFT-Net\nachieves lower error and higher throughput with fewer parameters under\nidentical training settings and budget. On Navier--Stokes benchmarks, the\nrelative $L_{1}$ error is reduced by 7\\%--54\\%, the parameter count decreases\nby about 15\\%, and the throughput remains higher than scOT. Ablation studies\nand theoretical analyses further demonstrate the stability and effectiveness of\nthis design. The code is available at\nhttps://github.com/cruiseresearchgroup/DRIFT-Net."}
{"id": "2509.24873", "pdf": "https://arxiv.org/pdf/2509.24873", "abs": "https://arxiv.org/abs/2509.24873", "authors": ["Teodor Chiaburu", "Vipin Singh", "Frank Haußer", "Felix Bießmann"], "title": "Uncertainty-Guided Expert-AI Collaboration for Efficient Soil Horizon Annotation", "categories": ["cs.LG", "cs.AI"], "comment": "11 pages, 7 figures, presented at ECAI 2025, CLEAR-AI Workshop,\n  Bologna", "summary": "Uncertainty quantification is essential in human-machine collaboration, as\nhuman agents tend to adjust their decisions based on the confidence of the\nmachine counterpart. Reliably calibrated model uncertainties, hence, enable\nmore effective collaboration, targeted expert intervention and more responsible\nusage of Machine Learning (ML) systems. Conformal prediction has become a well\nestablished model-agnostic framework for uncertainty calibration of ML models,\noffering statistically valid confidence estimates for both regression and\nclassification tasks. In this work, we apply conformal prediction to\n$\\textit{SoilNet}$, a multimodal multitask model for describing soil profiles.\nWe design a simulated human-in-the-loop (HIL) annotation pipeline, where a\nlimited budget for obtaining ground truth annotations from domain experts is\navailable when model uncertainty is high. Our experiments show that\nconformalizing SoilNet leads to more efficient annotation in regression tasks\nand comparable performance scores in classification tasks under the same\nannotation budget when tested against its non-conformal counterpart. All code\nand experiments can be found in our repository:\nhttps://github.com/calgo-lab/BGR"}
{"id": "2509.24882", "pdf": "https://arxiv.org/pdf/2509.24882", "abs": "https://arxiv.org/abs/2509.24882", "authors": ["Leonardo Defilippis", "Yizhou Xu", "Julius Girardin", "Emanuele Troiani", "Vittorio Erba", "Lenka Zdeborová", "Bruno Loureiro", "Florent Krzakala"], "title": "Scaling Laws and Spectra of Shallow Neural Networks in the Feature Learning Regime", "categories": ["cs.LG", "cond-mat.dis-nn", "cs.AI", "stat.ML"], "comment": null, "summary": "Neural scaling laws underlie many of the recent advances in deep learning,\nyet their theoretical understanding remains largely confined to linear models.\nIn this work, we present a systematic analysis of scaling laws for quadratic\nand diagonal neural networks in the feature learning regime. Leveraging\nconnections with matrix compressed sensing and LASSO, we derive a detailed\nphase diagram for the scaling exponents of the excess risk as a function of\nsample complexity and weight decay. This analysis uncovers crossovers between\ndistinct scaling regimes and plateau behaviors, mirroring phenomena widely\nreported in the empirical neural scaling literature. Furthermore, we establish\na precise link between these regimes and the spectral properties of the trained\nnetwork weights, which we characterize in detail. As a consequence, we provide\na theoretical validation of recent empirical observations connecting the\nemergence of power-law tails in the weight spectrum with network generalization\nperformance, yielding an interpretation from first principles."}
{"id": "2509.24886", "pdf": "https://arxiv.org/pdf/2509.24886", "abs": "https://arxiv.org/abs/2509.24886", "authors": ["Ya-Wei Eileen Lin", "Ron Levie"], "title": "Adaptive Canonicalization with Application to Invariant Anisotropic Geometric Networks", "categories": ["cs.LG"], "comment": null, "summary": "Canonicalization is a widely used strategy in equivariant machine learning,\nenforcing symmetry in neural networks by mapping each input to a standard form.\nYet, it often introduces discontinuities that can affect stability during\ntraining, limit generalization, and complicate universal approximation\ntheorems. In this paper, we address this by introducing \\emph{adaptive\ncanonicalization}, a general framework in which the canonicalization depends\nboth on the input and the network. Specifically, we present the adaptive\ncanonicalization based on prior maximization, where the standard form of the\ninput is chosen to maximize the predictive confidence of the network. We prove\nthat this construction yields continuous and symmetry-respecting models that\nadmit universal approximation properties.\n  We propose two applications of our setting: (i) resolving eigenbasis\nambiguities in spectral graph neural networks, and (ii) handling rotational\nsymmetries in point clouds. We empirically validate our methods on molecular\nand protein classification, as well as point cloud classification tasks. Our\nadaptive canonicalization outperforms the three other common solutions to\nequivariant machine learning: data augmentation, standard canonicalization, and\nequivariant architectures."}
{"id": "2509.24895", "pdf": "https://arxiv.org/pdf/2509.24895", "abs": "https://arxiv.org/abs/2509.24895", "authors": ["Kosio Beshkov", "Anders Malthe-Sørenssen"], "title": "Towards Understanding the Shape of Representations in Protein Language Models", "categories": ["cs.LG"], "comment": null, "summary": "While protein language models (PLMs) are one of the most promising avenues of\nresearch for future de novo protein design, the way in which they transform\nsequences to hidden representations, as well as the information encoded in such\nrepresentations is yet to be fully understood. Several works have attempted to\npropose interpretability tools for PLMs, but they have focused on understanding\nhow individual sequences are transformed by such models. Therefore, the way in\nwhich PLMs transform the whole space of sequences along with their relations is\nstill unknown. In this work we attempt to understand this transformed space of\nsequences by identifying protein structure and representation with square-root\nvelocity (SRV) representations and graph filtrations. Both approaches naturally\nlead to a metric space in which pairs of proteins or protein representations\ncan be compared with each other.\n  We analyze different types of proteins from the SCOP dataset and show that\nthe Karcher mean and effective dimension of the SRV shape space follow a\nnon-linear pattern as a function of the layers in ESM2 models of different\nsizes. Furthermore, we use graph filtrations as a tool to study the context\nlengths at which models encode the structural features of proteins. We find\nthat PLMs preferentially encode immediate as well as local relations between\nresidues, but start to degrade for larger context lengths. The most\nstructurally faithful encoding tends to occur close to, but before the last\nlayer of the models, indicating that training a folding model ontop of these\nlayers might lead to improved folding performance."}
{"id": "2509.24923", "pdf": "https://arxiv.org/pdf/2509.24923", "abs": "https://arxiv.org/abs/2509.24923", "authors": ["Sanxing Chen", "Xiaoyin Chen", "Yukun Huang", "Roy Xie", "Bhuwan Dhingra"], "title": "When Greedy Wins: Emergent Exploitation Bias in Meta-Bandit LLM Training", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "While Large Language Models (LLMs) hold promise to become autonomous agents,\nthey often explore suboptimally in sequential decision-making. Recent work has\nsought to enhance this capability via supervised fine-tuning (SFT) or\nreinforcement learning (RL), improving regret on the classic multi-armed bandit\ntask. However, it remains unclear how these learning methods shape exploration\nstrategies and how well they generalize. We investigate both paradigms by\ntraining LLMs with SFT on expert trajectories and RL with a range of tailored\nreward signals including a strategic, regret-shaped reward to reduce variance,\nand an algorithmic reward that enables oracle imitation. The resulting agents\noutperform pre-trained models and achieve performance comparable to Upper\nConfidence Bound (UCB) and Thompson Sampling, with robust generalization to 6x\nlonger horizons and across bandit families. Behavioral analysis reveals that\ngains often stem from more sophisticated but greedier exploitation: RL/SFT\nagents are more prone to early catastrophic failure than pre-trained models,\nprematurely abandoning exploration. Furthermore, agents trained to imitate UCB\nlearn to outperform their teacher by adopting more exploitative variants. Our\nfindings clarify when each training paradigm is preferable and advocate\ntailored reward design and evaluation beyond average regret to promote robust\nexploratory behavior."}
{"id": "2509.24933", "pdf": "https://arxiv.org/pdf/2509.24933", "abs": "https://arxiv.org/abs/2509.24933", "authors": ["Sebastian W. Ober", "Calvin McCarter", "Aniruddh Raghu", "Yucen Lily Li", "Alan N. Amin", "Andrew Gordon Wilson", "Hunter Elliott"], "title": "Is Sequence Information All You Need for Bayesian Optimization of Antibodies?", "categories": ["cs.LG", "q-bio.QM"], "comment": "Accepted into the AI for Science Workshop, NeurIPS 2025", "summary": "Bayesian optimization is a natural candidate for the engineering of antibody\ntherapeutic properties, which is often iterative and expensive. However,\nfinding the optimal choice of surrogate model for optimization over the highly\nstructured antibody space is difficult, and may differ depending on the\nproperty being optimized. Moreover, to the best of our knowledge, no prior\nworks have attempted to incorporate structural information into antibody\nBayesian optimization. In this work, we explore different approaches to\nincorporating structural information into Bayesian optimization, and compare\nthem to a variety of sequence-only approaches on two different antibody\nproperties, binding affinity and stability. In addition, we propose the use of\na protein language model-based ``soft constraint,'' which helps guide the\noptimization to promising regions of the space. We find that certain types of\nstructural information improve data efficiency in early optimization rounds for\nstability, but have equivalent peak performance. Moreover, when incorporating\nthe protein language model soft constraint we find that the data efficiency gap\nis diminished for affinity and eliminated for stability, resulting in\nsequence-only methods that match the performance of structure-based methods,\nraising questions about the necessity of structure in Bayesian optimization for\nantibodies."}
{"id": "2509.24936", "pdf": "https://arxiv.org/pdf/2509.24936", "abs": "https://arxiv.org/abs/2509.24936", "authors": ["Angxiao Yue", "Anqi Dong", "Hongteng Xu"], "title": "OAT-FM: Optimal Acceleration Transport for Improved Flow Matching", "categories": ["cs.LG"], "comment": null, "summary": "As a powerful technique in generative modeling, Flow Matching (FM) aims to\nlearn velocity fields from noise to data, which is often explained and\nimplemented as solving Optimal Transport (OT) problems. In this study, we\nbridge FM and the recent theory of Optimal Acceleration Transport (OAT),\ndeveloping an improved FM method called OAT-FM and exploring its benefits in\nboth theory and practice. In particular, we demonstrate that the straightening\nobjective hidden in existing OT-based FM methods is mathematically equivalent\nto minimizing the physical action associated with acceleration defined by OAT.\nAccordingly, instead of enforcing constant velocity, OAT-FM optimizes the\nacceleration transport in the product space of sample and velocity, whose\nobjective corresponds to a necessary and sufficient condition of flow\nstraightness. An efficient algorithm is designed to achieve OAT-FM with low\ncomplexity. OAT-FM motivates a new two-phase FM paradigm: Given a generative\nmodel trained by an arbitrary FM method, whose velocity information has been\nrelatively reliable, we can fine-tune and improve it via OAT-FM. This paradigm\neliminates the risk of data distribution drift and the need to generate a large\nnumber of noise data pairs, which consistently improves model performance in\nvarious generative tasks. Code is available at:\nhttps://github.com/AngxiaoYue/OAT-FM"}
{"id": "2509.24947", "pdf": "https://arxiv.org/pdf/2509.24947", "abs": "https://arxiv.org/abs/2509.24947", "authors": ["Sooraj Sathish", "Keshav Goyal", "Raghuram Bharadwaj Diddigi"], "title": "Learning Distinguishable Representations in Deep Q-Networks for Linear Transfer", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Deep Reinforcement Learning (RL) has demonstrated success in solving complex\nsequential decision-making problems by integrating neural networks with the RL\nframework. However, training deep RL models poses several challenges, such as\nthe need for extensive hyperparameter tuning and high computational costs.\nTransfer learning has emerged as a promising strategy to address these\nchallenges by enabling the reuse of knowledge from previously learned tasks for\nnew, related tasks. This avoids the need for retraining models entirely from\nscratch. A commonly used approach for transfer learning in RL is to leverage\nthe internal representations learned by the neural network during training.\nSpecifically, the activations from the last hidden layer can be viewed as\nrefined state representations that encapsulate the essential features of the\ninput. In this work, we investigate whether these representations can be used\nas input for training simpler models, such as linear function approximators, on\nnew tasks. We observe that the representations learned by standard deep RL\nmodels can be highly correlated, which limits their effectiveness when used\nwith linear function approximation. To mitigate this problem, we propose a\nnovel deep Q-learning approach that introduces a regularization term to reduce\npositive correlations between feature representation of states. By leveraging\nthese reduced correlated features, we enable more effective use of linear\nfunction approximation in transfer learning. Through experiments and ablation\nstudies on standard RL benchmarks and MinAtar games, we demonstrate the\nefficacy of our approach in improving transfer learning performance and thereby\nreducing computational overhead."}
{"id": "2509.24957", "pdf": "https://arxiv.org/pdf/2509.24957", "abs": "https://arxiv.org/abs/2509.24957", "authors": ["Weifan Jiang", "Rana Shahout", "Yilun Du", "Michael Mitzenmacher", "Minlan Yu"], "title": "Intra-request branch orchestration for efficient LLM reasoning", "categories": ["cs.LG"], "comment": "15 pages, 6 figures", "summary": "Large Language Models (LLMs) increasingly rely on inference-time reasoning\nalgorithms such as chain-of-thought and multi-branch reasoning to improve\naccuracy on complex tasks. These methods, however, substantially increase token\nusage and per-request latency. Prior work has largely focused on reducing token\nusage, often at the expense of accuracy, while overlooking other latency\nfactors. We present DUCHESS, an LLM serving system that reduces cost and\nlatency without sacrificing accuracy through intra-request branch orchestration\nguided by predictions. DUCHESS employs a lightweight linear probing model over\nLLM layer activations to estimate branch correctness, and its orchestration\npolicy decides whether to terminate, duplicate, or continue a branch. When\nhandling multiple requests, DUCHESS further reduces latency by prioritizing\neasier reasoning tasks when complexity can be estimated from the prompt.\nExperiments on three reasoning benchmarks show that DUCHESS consistently\nimproves the token-accuracy Pareto frontier, reducing token usage by 42-63% at\nmatched accuracy compared to self-consistency. In serving with vLLM, DUCHESS\nreduces mean, median, and tail latencies by 57-81%, 58-85%, and 52-84% with\nFirst-Come-First-Served scheduling, and achieves additional gains under\ndifficulty-aware scheduling at higher request rates."}
{"id": "2509.24962", "pdf": "https://arxiv.org/pdf/2509.24962", "abs": "https://arxiv.org/abs/2509.24962", "authors": ["Valentyn Melnychuk", "Dennis Frauen", "Jonas Schweisthal", "Stefan Feuerriegel"], "title": "Overlap-Adaptive Regularization for Conditional Average Treatment Effect Estimation", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "The conditional average treatment effect (CATE) is widely used in\npersonalized medicine to inform therapeutic decisions. However,\nstate-of-the-art methods for CATE estimation (so-called meta-learners) often\nperform poorly in the presence of low overlap. In this work, we introduce a new\napproach to tackle this issue and improve the performance of existing\nmeta-learners in the low-overlap regions. Specifically, we introduce\nOverlap-Adaptive Regularization (OAR) that regularizes target models\nproportionally to overlap weights so that, informally, the regularization is\nhigher in regions with low overlap. To the best of our knowledge, our OAR is\nthe first approach to leverage overlap weights in the regularization terms of\nthe meta-learners. Our OAR approach is flexible and works with any existing\nCATE meta-learner: we demonstrate how OAR can be applied to both parametric and\nnon-parametric second-stage models. Furthermore, we propose debiased versions\nof our OAR that preserve the Neyman-orthogonality of existing meta-learners and\nthus ensure more robust inference. Through a series of (semi-)synthetic\nexperiments, we demonstrate that our OAR significantly improves CATE estimation\nin low-overlap settings in comparison to constant regularization."}
{"id": "2509.24974", "pdf": "https://arxiv.org/pdf/2509.24974", "abs": "https://arxiv.org/abs/2509.24974", "authors": ["Ahmad Fraij", "Sam Dauncey"], "title": "Double Descent as a Lens for Sample Efficiency in Autoregressive vs. Discrete Diffusion Models", "categories": ["cs.LG"], "comment": null, "summary": "Data scarcity drives the need for more sample-efficient large language\nmodels. In this work, we use the double descent phenomenon to holistically\ncompare the sample efficiency of discrete diffusion and autoregressive models.\nWe show that discrete diffusion models require larger capacity and more\ntraining epochs to escape their underparameterized regime and reach the\ninterpolation threshold. In the strongly overparameterized regime, both models\nexhibit similar behavior, with neither exhibiting a pronounced second descent\nin test loss across a large range of model sizes. Overall, our results indicate\nthat autoregressive models are more sample-efficient on small-scale datasets,\nwhile discrete diffusion models only become competitive when given sufficient\ncapacity and compute."}
{"id": "2509.24981", "pdf": "https://arxiv.org/pdf/2509.24981", "abs": "https://arxiv.org/abs/2509.24981", "authors": ["Haoran He", "Yuxiao Ye", "Qingpeng Cai", "Chen Hu", "Binxing Jiao", "Daxin Jiang", "Ling Pan"], "title": "Random Policy Valuation is Enough for LLM Reasoning with Verifiable Rewards", "categories": ["cs.LG", "cs.AI"], "comment": "32 pages", "summary": "RL with Verifiable Rewards (RLVR) has emerged as a promising paradigm for\nimproving the reasoning abilities of large language models (LLMs). Current\nmethods rely primarily on policy optimization frameworks like PPO and GRPO,\nwhich follow generalized policy iteration that alternates between evaluating\nthe current policy's value and improving the policy based on evaluation. While\neffective, they often suffer from training instability and diversity collapse,\nrequiring complex heuristic tricks and careful tuning. We observe that standard\nRLVR in math reasoning can be formalized as a specialized finite-horizon Markov\nDecision Process with deterministic state transitions, tree-structured\ndynamics, and binary terminal rewards. Though large in scale, the underlying\nstructure is simpler than general-purpose control settings for which popular RL\nalgorithms (e.g., PPO) were developed, suggesting that several sophisticated\ntechniques in existing methods may be reduced or even omitted. Based on this\ninsight, we prove a surprising result: the optimal action can be recovered from\nthe Q-function of a fixed uniformly random policy, thereby bypassing the\ngeneralized policy iteration loop and its associated heuristics. We introduce\nRandom Policy Valuation for Diverse Reasoning (ROVER) to translate this\nprinciple into a practical and scalable algorithm for LLM math reasoning, a\nminimalist yet highly effective RL method that samples actions from a softmax\nover these uniform-policy Q-values. ROVER preserves diversity throughout\ntraining, allowing sustained exploration of multiple valid pathways. Across\nmultiple base models and standard math reasoning benchmarks, ROVER demonstrates\nsuperior performance in both \\textbf{quality} (\\textbf{+8.2} on pass@1,\n\\textbf{+16.8} on pass@256) and \\textbf{diversity} (\\textbf{+17.6\\%}), despite\nits radical simplification compared to strong, complicated existing methods."}
{"id": "2509.24991", "pdf": "https://arxiv.org/pdf/2509.24991", "abs": "https://arxiv.org/abs/2509.24991", "authors": ["Lu Zou", "Wendi Ren", "Weizhong Zhang", "Liang Ding", "Shuang Li"], "title": "Sampling Complexity of TD and PPO in RKHS", "categories": ["cs.LG"], "comment": null, "summary": "We revisit Proximal Policy Optimization (PPO) from a function-space\nperspective. Our analysis decouples policy evaluation and improvement in a\nreproducing kernel Hilbert space (RKHS): (i) A kernelized temporal-difference\n(TD) critic performs efficient RKHS-gradient updates using only one-step\nstate-action transition samples; (ii) a KL-regularized, natural-gradient policy\nstep exponentiates the evaluated action-value, recovering a PPO/TRPO-style\nproximal update in continuous state-action spaces. We provide non-asymptotic,\ninstance-adaptive guarantees whose rates depend on RKHS entropy, unifying\ntabular, linear, Sobolev, Gaussian, and Neural Tangent Kernel (NTK) regimes,\nand we derive a sampling rule for the proximal update that ensures the optimal\n$k^{-1/2}$ convergence rate for stochastic optimization. Empirically, the\ntheory-aligned schedule improves stability and sample efficiency on common\ncontrol tasks (e.g., CartPole, Acrobot), while our TD-based critic attains\nfavorable throughput versus a GAE baseline. Altogether, our results place PPO\non a firmer theoretical footing beyond finite-dimensional assumptions and\nclarify when RKHS-proximal updates with kernel-TD critics yield global policy\nimprovement with practical efficiency."}
{"id": "2509.25003", "pdf": "https://arxiv.org/pdf/2509.25003", "abs": "https://arxiv.org/abs/2509.25003", "authors": ["Mingxing Rao", "Bowen Qu", "Daniel Moyer"], "title": "Score-based Membership Inference on Diffusion Models", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Membership inference attacks (MIAs) against diffusion models have emerged as\na pressing privacy concern, as these models may inadvertently reveal whether a\ngiven sample was part of their training set. We present a theoretical and\nempirical study of score-based MIAs, focusing on the predicted noise vectors\nthat diffusion models learn to approximate. We show that the expected denoiser\noutput points toward a kernel-weighted local mean of nearby training samples,\nsuch that its norm encodes proximity to the training set and thereby reveals\nmembership. Building on this observation, we propose SimA, a single-query\nattack that provides a principled, efficient alternative to existing\nmulti-query methods. SimA achieves consistently strong performance across\nvariants of DDPM, Latent Diffusion Model (LDM). Notably, we find that Latent\nDiffusion Models are surprisingly less vulnerable than pixel-space models, due\nto the strong information bottleneck imposed by their latent auto-encoder. We\nfurther investigate this by differing the regularization hyperparameters\n($\\beta$ in $\\beta$-VAE) in latent channel and suggest a strategy to make LDM\ntraining more robust to MIA. Our results solidify the theory of score-based\nMIAs, while highlighting that Latent Diffusion class of methods requires better\nunderstanding of inversion for VAE, and not simply inversion of the Diffusion\nprocess"}
{"id": "2509.25017", "pdf": "https://arxiv.org/pdf/2509.25017", "abs": "https://arxiv.org/abs/2509.25017", "authors": ["Spyros Kondylatos", "Gustau Camps-Valls", "Ioannis Papoutsis"], "title": "Uncertainty-Aware Deep Learning for Wildfire Danger Forecasting", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Wildfires are among the most severe natural hazards, posing a significant\nthreat to both humans and natural ecosystems. The growing risk of wildfires\nincreases the demand for forecasting models that are not only accurate but also\nreliable. Deep Learning (DL) has shown promise in predicting wildfire danger;\nhowever, its adoption is hindered by concerns over the reliability of its\npredictions, some of which stem from the lack of uncertainty quantification. To\naddress this challenge, we present an uncertainty-aware DL framework that\njointly captures epistemic (model) and aleatoric (data) uncertainty to enhance\nshort-term wildfire danger forecasting. In the next-day forecasting, our\nbest-performing model improves the F1 Score by 2.3% and reduces the Expected\nCalibration Error by 2.1% compared to a deterministic baseline, enhancing both\npredictive skill and calibration. Our experiments confirm the reliability of\nthe uncertainty estimates and illustrate their practical utility for decision\nsupport, including the identification of uncertainty thresholds for rejecting\nlow-confidence predictions and the generation of well-calibrated wildfire\ndanger maps with accompanying uncertainty layers. Extending the forecast\nhorizon up to ten days, we observe that aleatoric uncertainty increases with\ntime, showing greater variability in environmental conditions, while epistemic\nuncertainty remains stable. Finally, we show that although the two uncertainty\ntypes may be redundant in low-uncertainty cases, they provide complementary\ninsights under more challenging conditions, underscoring the value of their\njoint modeling for robust wildfire danger prediction. In summary, our approach\nsignificantly improves the accuracy and reliability of wildfire danger\nforecasting, advancing the development of trustworthy wildfire DL systems."}
{"id": "2509.25020", "pdf": "https://arxiv.org/pdf/2509.25020", "abs": "https://arxiv.org/abs/2509.25020", "authors": ["Jiayu Liu", "Zhenya Huang", "Anya Sims", "Enhong Chen", "Yee Whye Teh", "Ning Miao"], "title": "MARCOS: Deep Thinking by Markov Chain of Continuous Thoughts", "categories": ["cs.LG"], "comment": null, "summary": "The current paradigm for reasoning in large language models (LLMs) involves\nmodels \"thinking out loud\" via a sequence of tokens, known as chain-of-thought\n(CoT). This approach, while effective, has several significant drawbacks.\nFirstly, inference requires autoregressive generation of often thousands of CoT\ntokens, which is slow and computationally expensive. Secondly, it constrains\nreasoning to the discrete space of tokens, creating an information bottleneck\nacross reasoning steps. Thirdly, it fundamentally entangles reasoning with\ntoken generation, forcing LLMs to \"think while speaking,\" which causes\npotentially short-sighted reasoning. In light of these limitations, we\nre-imagine reasoning in LLMs and present a new paradigm: MARCOS. In our\napproach, rather than autoregressively generating tokens, we model reasoning as\na hidden Markov chain of continuous, high-dimensional \"thoughts\". Each\nreasoning step involves a transition of the internal thoughts, where explicit\nreasoning steps (which may consist of hundreds of tokens) serve as observable\nvariables, which are windows to peek into the implicit thoughts. Since this\nlatent process is incompatible with the standard supervised learning, we\nfurther propose a two-phase variational training scheme. Our experiments on\nthree benchmarks demonstrate that MARCOS outperforms existing continuous\nreasoning methods and, for the first time, achieves performance comparable to\ntoken-based CoT, even surpassing it by 4.7% on GSM8K with up to 15.7x speedup\nin inference. Beyond this, MARCOS offers additional advantages, such as\nstep-level instead of token-level control over randomness, opening significant\nopportunities for reinforcement learning and reasoning in LLMs."}
{"id": "2509.25031", "pdf": "https://arxiv.org/pdf/2509.25031", "abs": "https://arxiv.org/abs/2509.25031", "authors": ["Sophia V. Kuhn", "Rafael Bischof", "Marius Weber", "Antoine Binggeli", "Michael A. Kraus", "Walter Kaufmann", "Fernando Pérez-Cruz"], "title": "Bayesian Surrogates for Risk-Aware Pre-Assessment of Aging Bridge Portfolios", "categories": ["cs.LG"], "comment": "Accepted at the NeurIPS 2025 Workshop on MLxOR: Mathematical\n  Foundations and Operational Integration of Machine Learning for\n  Uncertainty-Aware Decision-Making", "summary": "Aging infrastructure portfolios pose a critical resource allocation\nchallenge: deciding which structures require intervention and which can safely\nremain in service. Structural assessments must balance the trade-off between\ncheaper, conservative analysis methods and accurate but costly simulations that\ndo not scale portfolio-wide. We propose Bayesian neural network (BNN)\nsurrogates for rapid structural pre-assessment of worldwide common bridge\ntypes, such as reinforced concrete frame bridges. Trained on a large-scale\ndatabase of non-linear finite element analyses generated via a parametric\npipeline and developed based on the Swiss Federal Railway's bridge portfolio,\nthe models accurately and efficiently estimate high-fidelity structural\nanalysis results by predicting code compliance factors with calibrated\nepistemic uncertainty. Our BNN surrogate enables fast, uncertainty-aware\ntriage: flagging likely critical structures and providing guidance where\nrefined analysis is pertinent. We demonstrate the framework's effectiveness in\na real-world case study of a railway underpass, showing its potential to\nsignificantly reduce costs and emissions by avoiding unnecessary analyses and\nphysical interventions across entire infrastructure portfolios."}
{"id": "2509.25040", "pdf": "https://arxiv.org/pdf/2509.25040", "abs": "https://arxiv.org/abs/2509.25040", "authors": ["Giuseppe Bruno", "Federico Pasqualotto", "Andrea Agazzi"], "title": "A multiscale analysis of mean-field transformers in the moderate interaction regime", "categories": ["cs.LG", "math.PR", "stat.ML"], "comment": "30 pages, 4 figures", "summary": "In this paper, we study the evolution of tokens through the depth of\nencoder-only transformer models at inference time by modeling them as a system\nof particles interacting in a mean-field way and studying the corresponding\ndynamics. More specifically, we consider this problem in the moderate\ninteraction regime, where the number $N$ of tokens is large and the inverse\ntemperature parameter $\\beta$ of the model scales together with $N$. In this\nregime, the dynamics of the system displays a multiscale behavior: a fast\nphase, where the token empirical measure collapses on a low-dimensional space,\nan intermediate phase, where the measure further collapses into clusters, and a\nslow one, where such clusters sequentially merge into a single one. We provide\na rigorous characterization of the limiting dynamics in each of these phases\nand prove convergence in the above mentioned limit, exemplifying our results\nwith some simulations."}
{"id": "2509.25049", "pdf": "https://arxiv.org/pdf/2509.25049", "abs": "https://arxiv.org/abs/2509.25049", "authors": ["Bingrui Li", "Jiaxin Wen", "Zhanpeng Zhou", "Jun Zhu", "Jianfei Chen"], "title": "Efficient Hyperparameter Tuning via Trajectory Invariance Principle", "categories": ["cs.LG"], "comment": null, "summary": "As hyperparameter tuning becomes increasingly costly at scale, efficient\ntuning methods are essential. Yet principles for guiding hyperparameter tuning\nremain limited. In this work, we seek to establish such principles by\nconsidering a broad range of hyperparameters, including batch size, learning\nrate, and weight decay. We identify a phenomenon we call trajectory invariance,\nwhere pre-training loss curves, gradient noise, and gradient norm exhibit\ninvariance--closely overlapping--with respect to a quantity that combines\nlearning rate and weight decay. This phenomenon effectively reduces the\noriginal two-dimensional hyperparameter space to one dimension, yielding an\nefficient tuning rule: follow the salient direction revealed by trajectory\ninvariance. Furthermore, we refine previous scaling laws and challenge several\nexisting viewpoints. Overall, our work proposes new principles for efficient\ntuning and inspires future research on scaling laws."}
{"id": "2509.25050", "pdf": "https://arxiv.org/pdf/2509.25050", "abs": "https://arxiv.org/abs/2509.25050", "authors": ["Shuchen Xue", "Chongjian Ge", "Shilong Zhang", "Yichen Li", "Zhi-Ming Ma"], "title": "Advantage Weighted Matching: Aligning RL with Pretraining in Diffusion Models", "categories": ["cs.LG"], "comment": null, "summary": "Reinforcement Learning (RL) has emerged as a central paradigm for advancing\nLarge Language Models (LLMs), where pre-training and RL post-training share the\nsame log-likelihood formulation. In contrast, recent RL approaches for\ndiffusion models, most notably Denoising Diffusion Policy Optimization (DDPO),\noptimize an objective different from the pretraining objectives--score/flow\nmatching loss. In this work, we establish a novel theoretical analysis: DDPO is\nan implicit form of score/flow matching with noisy targets, which increases\nvariance and slows convergence. Building on this analysis, we introduce\n\\textbf{Advantage Weighted Matching (AWM)}, a policy-gradient method for\ndiffusion. It uses the same score/flow-matching loss as pretraining to obtain a\nlower-variance objective and reweights each sample by its advantage. In effect,\nAWM raises the influence of high-reward samples and suppresses low-reward ones\nwhile keeping the modeling objective identical to pretraining. This unifies\npretraining and RL conceptually and practically, is consistent with\npolicy-gradient theory, reduces variance, and yields faster convergence. This\nsimple yet effective design yields substantial benefits: on GenEval, OCR, and\nPickScore benchmarks, AWM delivers up to a $24\\times$ speedup over Flow-GRPO\n(which builds on DDPO), when applied to Stable Diffusion 3.5 Medium and FLUX,\nwithout compromising generation quality. Code is available at\nhttps://github.com/scxue/advantage_weighted_matching."}
{"id": "2509.25080", "pdf": "https://arxiv.org/pdf/2509.25080", "abs": "https://arxiv.org/abs/2509.25080", "authors": ["Bogdan Raonić", "Siddhartha Mishra", "Samuel Lanthaler"], "title": "Towards a Certificate of Trust: Task-Aware OOD Detection for Scientific AI", "categories": ["cs.LG"], "comment": null, "summary": "Data-driven models are increasingly adopted in critical scientific fields\nlike weather forecasting and fluid dynamics. These methods can fail on\nout-of-distribution (OOD) data, but detecting such failures in regression tasks\nis an open challenge. We propose a new OOD detection method based on estimating\njoint likelihoods using a score-based diffusion model. This approach considers\nnot just the input but also the regression model's prediction, providing a\ntask-aware reliability score. Across numerous scientific datasets, including\nPDE datasets, satellite imagery and brain tumor segmentation, we show that this\nlikelihood strongly correlates with prediction error. Our work provides a\nfoundational step towards building a verifiable 'certificate of trust', thereby\noffering a practical tool for assessing the trustworthiness of AI-based\nscientific predictions. Our code is publicly available at\nhttps://github.com/bogdanraonic3/OOD_Detection_ScientificML"}
{"id": "2509.25087", "pdf": "https://arxiv.org/pdf/2509.25087", "abs": "https://arxiv.org/abs/2509.25087", "authors": ["Shane Bergsma", "Bin Claire Zhang", "Nolan Dey", "Shaheer Muhammad", "Gurpreet Gosal", "Joel Hestness"], "title": "Scaling with Collapse: Efficient and Predictable Training of LLM Families", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Effective LLM training relies on *consistency*, meaning that key quantities\n-- such as final losses and optimal hyperparameters -- scale predictably across\nmodel sizes. Qiu et al. (2025) recently showed that this consistency extends\nbeyond scalars: whole training loss curves can *collapse* onto a universal\ntrajectory after a simple normalization. What remains unclear is whether this\nphenomenon holds for LLM families trained under *practical scaling recipes*,\nwhere width, depth, learning rate, batch size, and weight decay are scaled\njointly. We show that it does: loss curves collapse across scales precisely\nwhen optimization hyperparameters are set optimally for the given data budget,\nin accordance with recent empirical scaling laws. Collapse thus emerges as a\nsignature of compute-efficient training. We demonstrate two applications at\nscale: (1) deviation-from-collapse provides a sensitive, early diagnostic of\ntraining pathologies, and (2) the predictability of collapsed curves enables\nearly stopping in large-scale hyperparameter tuning. Finally, we train a\ncompetitive LLM family, *Celerity*, using these insights, highlighting collapse\nas an effective tool for developing efficient LLMs."}
{"id": "2509.25100", "pdf": "https://arxiv.org/pdf/2509.25100", "abs": "https://arxiv.org/abs/2509.25100", "authors": ["Aasheesh Singh", "Vishal Vaddina", "Dagnachew Birru"], "title": "ORPO-Distill: Mixed-Policy Preference Optimization for Cross-Architecture LLM Distillation", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Accepted at NeurIPS 2025, Efficient Reasoning Workshop", "summary": "We introduce ORPO-Distill, a general-purpose method for cross-architecture\nLLM distillation that formulates the problem as a preference optimization task.\nUnlike standard CoT distillation, the approach transfers knowledge through\ndiverse reasoning traces. It employs an Odds-Ratio Preference Optimization\nobjective that contrasts teacher and student traces for more effective\nlearning, and adopts a mixed-policy strategy for utilizing student-generated\noutputs, outperforming both off- and on-policy alternatives. Experiments on\nfive datasets and multiple student models show consistent improvements over\nconventional black-box KD baselines."}
{"id": "2509.25104", "pdf": "https://arxiv.org/pdf/2509.25104", "abs": "https://arxiv.org/abs/2509.25104", "authors": ["Albert Vong", "Steven Henke", "Oliver Hoidn", "Hanna Ruth", "Junjing Deng", "Alexander Hexemer", "Apurva Mehta", "Arianna Gleason", "Levi Hancock", "Nicholas Schwarz"], "title": "Towards generalizable deep ptychography neural networks", "categories": ["cs.LG"], "comment": "Submitted to scientific journal for peer review", "summary": "X-ray ptychography is a data-intensive imaging technique expected to become\nubiquitous at next-generation light sources delivering many-fold increases in\ncoherent flux. The need for real-time feedback under accelerated acquisition\nrates motivates surrogate reconstruction models like deep neural networks,\nwhich offer orders-of-magnitude speedup over conventional methods. However,\nexisting deep learning approaches lack robustness across diverse experimental\nconditions. We propose an unsupervised training workflow emphasizing probe\nlearning by combining experimentally-measured probes with synthetic,\nprocedurally generated objects. This probe-centric approach enables a single\nphysics-informed neural network to reconstruct unseen experiments across\nmultiple beamlines; among the first demonstrations of multi-probe\ngeneralization. We find probe learning is equally important as in-distribution\nlearning; models trained using this synthetic workflow achieve reconstruction\nfidelity comparable to those trained exclusively on experimental data, even\nwhen changing the type of synthetic training object. The proposed approach\nenables training of experiment-steering models that provide real-time feedback\nunder dynamic experimental conditions."}
{"id": "2509.25133", "pdf": "https://arxiv.org/pdf/2509.25133", "abs": "https://arxiv.org/abs/2509.25133", "authors": ["Yuxian Jiang", "Yafu Li", "Guanxu Chen", "Dongrui Liu", "Yu Cheng", "Jing Shao"], "title": "Rethinking Entropy Regularization in Large Reasoning Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Reinforcement learning with verifiable rewards (RLVR) has shown great promise\nin enhancing the reasoning abilities of large reasoning models (LRMs). However,\nit suffers from a critical issue: entropy collapse and premature convergence.\nNaive entropy regularization, a common approach for encouraging exploration in\nthe traditional RL literature, fails to address this problem in the context of\nLRM. Our analysis reveals that this failure stems from the vast action space\nand long trajectories in LRMs, which easily trigger a global entropy explosion\nas the model indiscriminately explores all possible actions and states. To\naddress this, we propose SIREN (SelectIve entRopy rEgularizatioN), a method\nthat confines exploration to a meaningful subset of actions and states. SIREN\nachieves this through a two-step entropy masking mechanism, consisting of a\ntop-p mask and a peak-entropy mask. In addition, regularization is transformed\ninto a self-anchored form to stabilize training. Across five mathematical\nbenchmarks, SIREN attains superior average performance over previous\nentropy-related RLVR approaches, exemplified by a +6.6 maj@k improvement on\nAIME24/25 with Qwen2.5-Math-7B. Further analysis confirms that SIREN promotes\ngreater response diversity and maintains entropy at an appropriate level, which\nhelps to preserve the validation pass@k throughout training. This effectively\nmitigates the premature convergence problem common in RLVR for LRM."}
{"id": "2509.25135", "pdf": "https://arxiv.org/pdf/2509.25135", "abs": "https://arxiv.org/abs/2509.25135", "authors": ["Daniil Dmitriev", "Harald Eskelund Franck", "Carolin Heinzler", "Amartya Sanyal"], "title": "Learning in an Echo Chamber: Online Learning with Replay Adversary", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "As machine learning systems increasingly train on self-annotated data, they\nrisk reinforcing errors and becoming echo chambers of their own beliefs. We\nmodel this phenomenon by introducing a learning-theoretic framework: Online\nLearning in the Replay Setting. In round $t$, the learner outputs a hypothesis\n$\\hat{h}_t$; the adversary then reveals either the true label $f^\\ast(x_t)$ or\na replayed label $\\hat{h}_i(x_t)$ from an earlier round $i < t$. A mistake is\ncounted only when the true label is shown, yet classical algorithms such as the\nSOA or the halving algorithm are easily misled by the replayed errors.\n  We introduce the Extended Threshold dimension, $\\mathrm{ExThD}(\\mathcal{H})$,\nand prove matching upper and lower bounds that make\n$\\mathrm{ExThD}(\\mathcal{H})$ the exact measure of learnability in this model.\nA closure-based learner makes at most $\\mathrm{ExThD}(\\mathcal{H})$ mistakes\nagainst any adaptive adversary, and no algorithm can perform better. For\nstochastic adversaries, we prove a similar bound for every intersection-closed\nclass. The replay setting is provably harder than the classical mistake bound\nsetting: some classes have constant Littlestone dimension but arbitrarily large\n$\\mathrm{ExThD}(\\mathcal{H})$. Proper learning exhibits an even sharper\nseparation: a class is properly learnable under replay if and only if it is\n(almost) intersection-closed. Otherwise, every proper learner suffers\n$\\Omega(T)$ errors, whereas our improper algorithm still achieves the\n$\\mathrm{ExThD}(\\mathcal{H})$ bound. These results give the first tight\nanalysis of learning against replay adversaries, based on new results for\nclosure-type algorithms."}
{"id": "2509.25136", "pdf": "https://arxiv.org/pdf/2509.25136", "abs": "https://arxiv.org/abs/2509.25136", "authors": ["David González Martínez"], "title": "BALF: Budgeted Activation-Aware Low-Rank Factorization for Fine-Tuning-Free Model Compression", "categories": ["cs.LG"], "comment": null, "summary": "Neural network compression techniques typically require expensive fine-tuning\nor search procedures, rendering them impractical on commodity hardware.\nInspired by recent LLM compression research, we present a general\nactivation-aware factorization framework that can be applied to a broad range\nof layers. Moreover, we introduce a scalable budgeted rank allocator that\nallows flexible control over compression targets (e.g., retaining 50% of\nparameters) with no overhead. Together, these components form BALF, an\nefficient pipeline for compressing models without fine-tuning. We demonstrate\nits effectiveness across multiple scales and architectures, from ResNet-20 on\nCIFAR-10 to ResNeXt-101 and vision transformers on ImageNet, and show that it\nachieves excellent results in the fine-tuning-free regime. For instance, BALF\nreduces FLOPs on ResNeXt-101 by 45% with only a 1-percentage-point top-1\naccuracy drop."}
{"id": "2509.25153", "pdf": "https://arxiv.org/pdf/2509.25153", "abs": "https://arxiv.org/abs/2509.25153", "authors": ["Nicholas Barnfield", "Hugo Cui", "Yue M. Lu"], "title": "High-Dimensional Analysis of Single-Layer Attention for Sparse-Token Classification", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "When and how can an attention mechanism learn to selectively attend to\ninformative tokens, thereby enabling detection of weak, rare, and sparsely\nlocated features? We address these questions theoretically in a sparse-token\nclassification model in which positive samples embed a weak signal vector in a\nrandomly chosen subset of tokens, whereas negative samples are pure noise. In\nthe long-sequence limit, we show that a simple single-layer attention\nclassifier can in principle achieve vanishing test error when the signal\nstrength grows only logarithmically in the sequence length $L$, whereas linear\nclassifiers require $\\sqrt{L}$ scaling. Moving from representational power to\nlearnability, we study training at finite $L$ in a high-dimensional regime,\nwhere sample size and embedding dimension grow proportionally. We prove that\njust two gradient updates suffice for the query weight vector of the attention\nclassifier to acquire a nontrivial alignment with the hidden signal, inducing\nan attention map that selectively amplifies informative tokens. We further\nderive an exact asymptotic expression for the test error and training loss of\nthe trained attention-based classifier, and quantify its capacity -- the\nlargest dataset size that is typically perfectly separable -- thereby\nexplaining the advantage of adaptive token selection over nonadaptive linear\nbaselines."}
{"id": "2509.25157", "pdf": "https://arxiv.org/pdf/2509.25157", "abs": "https://arxiv.org/abs/2509.25157", "authors": ["Jinhao Liang", "Yixuan Sun", "Anirban Samaddar", "Sandeep Madireddy", "Ferdinando Fioretto"], "title": "Chance-constrained Flow Matching for High-Fidelity Constraint-aware Generation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Generative models excel at synthesizing high-fidelity samples from complex\ndata distributions, but they often violate hard constraints arising from\nphysical laws or task specifications. A common remedy is to project\nintermediate samples onto the feasible set; however, repeated projection can\ndistort the learned distribution and induce a mismatch with the data manifold.\nThus, recent multi-stage procedures attempt to defer projection to clean\nsamples during sampling, but they increase algorithmic complexity and\naccumulate errors across steps. This paper addresses these challenges by\nproposing a novel training-free method, Chance-constrained Flow Matching\n(CCFM), that integrates stochastic optimization into the sampling process,\nenabling effective enforcement of hard constraints while maintaining\nhigh-fidelity sample generation. Importantly, CCFM guarantees feasibility in\nthe same manner as conventional repeated projection, yet, despite operating\ndirectly on noisy intermediate samples, it is theoretically equivalent to\nprojecting onto the feasible set defined by clean samples. This yields a\nsampler that mitigates distributional distortion. Empirical experiments show\nthat CCFM outperforms current state-of-the-art constrained generative models in\nmodeling complex physical systems governed by partial differential equations\nand molecular docking problems, delivering higher feasibility and fidelity."}
{"id": "2509.25158", "pdf": "https://arxiv.org/pdf/2509.25158", "abs": "https://arxiv.org/abs/2509.25158", "authors": ["Ehimare Okoyomon", "Arbel Yaniv", "Christoph Goebel"], "title": "Physics-Informed Inductive Biases for Voltage Prediction in Distribution Grids", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "Voltage prediction in distribution grids is a critical yet difficult task for\nmaintaining power system stability. Machine learning approaches, particularly\nGraph Neural Networks (GNNs), offer significant speedups but suffer from poor\ngeneralization when trained on limited or incomplete data. In this work, we\nsystematically investigate the role of inductive biases in improving a model's\nability to reliably learn power flow. Specifically, we evaluate three\nphysics-informed strategies: (i) power-flow-constrained loss functions, (ii)\ncomplex-valued neural networks, and (iii) residual-based task reformulation.\nUsing the ENGAGE dataset, which spans multiple low- and medium-voltage grid\nconfigurations, we conduct controlled experiments to isolate the effect of each\ninductive bias and assess both standard predictive performance and\nout-of-distribution generalization. Our study provides practical insights into\nwhich model assumptions most effectively guide learning for reliable and\nefficient voltage prediction in modern distribution networks."}
{"id": "2509.25170", "pdf": "https://arxiv.org/pdf/2509.25170", "abs": "https://arxiv.org/abs/2509.25170", "authors": ["Peter Holderrieth", "Uriel Singer", "Tommi Jaakkola", "Ricky T. Q. Chen", "Yaron Lipman", "Brian Karrer"], "title": "GLASS Flows: Transition Sampling for Alignment of Flow and Diffusion Models", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "The performance of flow matching and diffusion models can be greatly improved\nat inference time using reward alignment algorithms, yet efficiency remains a\nmajor limitation. While several algorithms were proposed, we demonstrate that a\ncommon bottleneck is the sampling method these algorithms rely on: many\nalgorithms require to sample Markov transitions via SDE sampling, which is\nsignificantly less efficient and often less performant than ODE sampling. To\nremove this bottleneck, we introduce GLASS Flows, a new sampling paradigm that\nsimulates a \"flow matching model within a flow matching model\" to sample Markov\ntransitions. As we show in this work, this \"inner\" flow matching model can be\nretrieved from a pre-trained model without any re-training, combining the\nefficiency of ODEs with the stochastic evolution of SDEs. On large-scale\ntext-to-image models, we show that GLASS Flows eliminate the trade-off between\nstochastic evolution and efficiency. Combined with Feynman-Kac Steering, GLASS\nFlows improve state-of-the-art performance in text-to-image generation, making\nit a simple, drop-in solution for inference-time scaling of flow and diffusion\nmodels."}
{"id": "2509.25171", "pdf": "https://arxiv.org/pdf/2509.25171", "abs": "https://arxiv.org/abs/2509.25171", "authors": ["Sophia Tang", "Yuchen Zhu", "Molei Tao", "Pranam Chatterjee"], "title": "TR2-D2: Tree Search Guided Trajectory-Aware Fine-Tuning for Discrete Diffusion", "categories": ["cs.LG", "q-bio.BM"], "comment": null, "summary": "Reinforcement learning with stochastic optimal control offers a promising\nframework for diffusion fine-tuning, where a pre-trained diffusion model is\noptimized to generate paths that lead to a reward-tilted distribution. While\nthese approaches enable optimization without access to explicit samples from\nthe optimal distribution, they require training on rollouts under the current\nfine-tuned model, making them susceptible to reinforcing sub-optimal\ntrajectories that yield poor rewards. To overcome this challenge, we introduce\nTRee Search Guided TRajectory-Aware Fine-Tuning for Discrete Diffusion\n(TR2-D2), a novel framework that optimizes reward-guided discrete diffusion\ntrajectories with tree search to construct replay buffers for trajectory-aware\nfine-tuning. These buffers are generated using Monte Carlo Tree Search (MCTS)\nand subsequently used to fine-tune a pre-trained discrete diffusion model under\na stochastic optimal control objective. We validate our framework on single-\nand multi-objective fine-tuning of biological sequence diffusion models,\nhighlighting the overall effectiveness of TR2-D2 for reliable reward-guided\nfine-tuning in discrete sequence generation."}
{"id": "2509.25174", "pdf": "https://arxiv.org/pdf/2509.25174", "abs": "https://arxiv.org/abs/2509.25174", "authors": ["Daniel Palenicek", "Florian Vogt", "Joe Watson", "Ingmar Posner", "Jan Peters"], "title": "XQC: Well-conditioned Optimization Accelerates Deep Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Sample efficiency is a central property of effective deep reinforcement\nlearning algorithms. Recent work has improved this through added complexity,\nsuch as larger models, exotic network architectures, and more complex\nalgorithms, which are typically motivated purely by empirical performance. We\ntake a more principled approach by focusing on the optimization landscape of\nthe critic network. Using the eigenspectrum and condition number of the\ncritic's Hessian, we systematically investigate the impact of common\narchitectural design decisions on training dynamics. Our analysis reveals that\na novel combination of batch normalization (BN), weight normalization (WN), and\na distributional cross-entropy (CE) loss produces condition numbers orders of\nmagnitude smaller than baselines. This combination also naturally bounds\ngradient norms, a property critical for maintaining a stable effective learning\nrate under non-stationary targets and bootstrapping. Based on these insights,\nwe introduce XQC: a well-motivated, sample-efficient deep actor-critic\nalgorithm built upon soft actor-critic that embodies these optimization-aware\nprinciples. We achieve state-of-the-art sample efficiency across 55\nproprioception and 15 vision-based continuous control tasks, all while using\nsignificantly fewer parameters than competing methods."}
{"id": "2509.25176", "pdf": "https://arxiv.org/pdf/2509.25176", "abs": "https://arxiv.org/abs/2509.25176", "authors": ["Haoming Wen", "Yushi Bai", "Juanzi Li", "Jie Tang"], "title": "SIRI: Scaling Iterative Reinforcement Learning with Interleaved Compression", "categories": ["cs.LG", "cs.CL"], "comment": "In submission", "summary": "We introduce SIRI, Scaling Iterative Reinforcement Learning with Interleaved\nCompression, a simple yet effective RL approach for Large Reasoning Models\n(LRMs) that enables more efficient and accurate reasoning. Existing studies\nhave observed repetitive thinking patterns in LRMs, and attempts to reduce them\noften come at the cost of performance. In this paper, we show that this\ntrade-off can be overcome through a training regime that iteratively alternates\nbetween compressing and expanding the reasoning budget, by dynamically\nadjusting the maximum rollout length during training. The compression phase\ncuts the rollout length, forcing the model to make precise and valuable\ndecisions within a limited context, which effectively reduces redundant tokens\nand increases reasoning density. The expansion phase then relaxes the length\nlimit, providing space for the model to explore and plan in long-horizon\nsettings. Remarkably, we find that after each compression-expansion cycle, the\nmodel's performance improves even as its output length decreases, steadily\npushing it closer to the Pareto frontier in the performance-efficiency\ntrade-off. Training on DeepSeek-R1-Distill-Qwen-1.5B, SIRI-low improves\nperformance on AIME24 by 43.2% while reducing token usage by 46.9% after three\niterations, and SIRI-high achieves the highest accuracy compared to all other\nmethods (Figure 1). Our findings shed light on the potential of periodically\noscillating the LRM's output truncation length during training to dynamically\nbalance exploration and efficiency in reasoning, converging towards an optimal\n\"sweet spot\" between the two. Our models are publicly available."}
{"id": "2501.05601", "pdf": "https://arxiv.org/pdf/2501.05601", "abs": "https://arxiv.org/abs/2501.05601", "authors": ["Adrian Marius Dumitran", "Adrian-Catalin Badea", "Stefan-Gabriel Muscalu", "Angela-Liliana Dumitran", "Stefan-Cosmin Dascalescu", "Radu-Sebastian Amarie"], "title": "Exploring Large Language Models for Translating Romanian Computational Problems into English", "categories": ["cs.CL", "cs.LG", "cs.SE"], "comment": "12 pages", "summary": "Recent studies have suggested that large language models (LLMs) underperform\non mathematical and computer science tasks when these problems are translated\nfrom Romanian into English, compared to their original Romanian format.\nAccurate translation is critical for applications ranging from automatic\ntranslations in programming competitions to the creation of high-quality\neducational materials, as well as minimizing errors or fraud in human\ntranslations. This study shows that robust large language models (LLMs) can\nmaintain or even enhance their performance in translating less common languages\nwhen given well-structured prompts. Our findings suggest that LLMs, with\nappropriate supervision, can be reliably used for the automatic translation of\nIOI (International Olympiad in Informatics)-style tasks. We evaluate several\ntranslation methods across multiple LLMs, including OpenRoLLM, Llama 3.1 8B,\nLlama 3.2 3B and GPT-4o, assessing their translation accuracy and performance\nstability through repeated runs. Additionally, we augment the OJI (Romanian\nCounty-Level Informatics Olympiad) Romanian dataset with accurate English\ntranslations, enhancing its utility for future LLM training and evaluation.\nThrough detailed syntactic and semantic analyses, we confirm that with human\noversight, LLMs can serve as a viable solution for multilingual\nproblem-solving. We also compare the translation quality of LLMs against human\ntranslators, as evaluated by a certified expert, underscoring the potential of\nLLMs in realworld scenarios."}
{"id": "2506.04989", "pdf": "https://arxiv.org/pdf/2506.04989", "abs": "https://arxiv.org/abs/2506.04989", "authors": ["Dumitran Adrian Marius", "Dita Radu"], "title": "BacPrep: An Experimental Platform for Evaluating LLM-Based Bacalaureat Assessment", "categories": ["cs.SE", "cs.CY", "cs.LG"], "comment": "9 pages Preprint ACCEPTED at BBGI (ITS Workshop)", "summary": "Accessing quality preparation and feedback for the Romanian Bacalaureat exam\nis challenging, particularly for students in remote or underserved areas. This\npaper introduces BacPrep, an experimental online platform exploring Large\nLanguage Model (LLM) potential for automated assessment, aiming to offer a\nfree, accessible resource. Using official exam questions from the last 5 years,\nBacPrep employs one of Google's newest models, Gemini 2.0 Flash (released Feb\n2025), guided by official grading schemes, to provide experimental feedback.\nCurrently operational, its primary research function is collecting student\nsolutions and LLM outputs. This focused dataset is vital for planned expert\nvalidation to rigorously evaluate the feasibility and accuracy of this\ncutting-edge LLM in the specific Bacalaureat context before reliable\ndeployment. We detail the design, data strategy, status, validation plan, and\nethics."}
{"id": "2506.05990", "pdf": "https://arxiv.org/pdf/2506.05990", "abs": "https://arxiv.org/abs/2506.05990", "authors": ["Stefan Dascalescu", "Adrian Marius Dumitran", "Mihai Alexandru Vasiluta"], "title": "Leveraging Generative AI for Enhancing Automated Assessment in Programming Education Contests", "categories": ["cs.SE", "cs.AI", "cs.CY", "cs.LG"], "comment": "11 pages, 2 chart pies, 1 figure Pre-print version Accepted at BEA\n  2025", "summary": "Competitive programming contests play a crucial role in cultivating\ncomputational thinking and algorithmic skills among learners. However,\ngenerating comprehensive test cases to effectively assess programming solutions\nremains resource-intensive and challenging for educators. This paper introduces\nan innovative NLP-driven method leveraging generative AI (large language\nmodels) to automate the creation of high-quality test cases for competitive\nprogramming assessments. We extensively evaluated our approach on diverse\ndatasets, including 25 years of Romanian Informatics Olympiad (OJI) data for\n5th graders, recent competitions hosted on the Kilonova.ro platform, and the\nInternational Informatics Olympiad in Teams (IIOT). Our results demonstrate\nthat AI-generated test cases substantially enhanced assessments, notably\nidentifying previously undetected errors in 67% of the OJI 5th grade\nprogramming problems. These improvements underscore the complementary\neducational value of our technique in formative assessment contexts. By openly\nsharing our prompts, translated datasets, and methodologies, we offer practical\nNLP-based tools that educators and contest organizers can readily integrate to\nenhance assessment quality, reduce workload, and deepen insights into learner\nperformance."}
{"id": "2506.05991", "pdf": "https://arxiv.org/pdf/2506.05991", "abs": "https://arxiv.org/abs/2506.05991", "authors": ["Alexandru-Gabriel Ganea", "Antonia-Adelina Popovici", "Adrian-Marius Dumitran"], "title": "A Culturally-Rich Romanian NLP Dataset from \"Who Wants to Be a Millionaire?\" Videos", "categories": ["cs.CL", "cs.LG"], "comment": "10 pages", "summary": "Large Language Models (LLMs) demonstrate varying performance across languages\nand cultural contexts. This study introduces a novel, culturally-rich,\nmultilingual dataset derived from video recordings of the Romanian game show\n\"Who Wants to Be a Millionaire?\" (Vrei s\\u{a} fii Milionar?). We employed an\ninnovative process combining optical character recognition (OCR), automated\ntext extraction, and manual verification to collect question-answer pairs,\nenriching them with metadata including question domain (e.g., biology,\nhistory), cultural relevance (Romanian-specific vs. international), and\ndifficulty. Benchmarking state-of-the-art LLMs, including Romanian-adapted\nmodels, on this dataset revealed significant performance disparities: models\nconsistently achieve higher accuracy (80-95%) on international questions\ncompared to Romanian-specific cultural questions (50-75%). We further\ninvestigate these differences through experiments involving machine translation\nof Romanian questions into English and cross-lingual tests using a comparable\ndataset in French. Our findings underscore the impact of cultural context and\ndata source on LLM performance and offer practical insights for building\nrobust, culturally-aware multilingual NLP systems, especially in educational\ndomains. The dataset is publicly available at Hugging Face."}
{"id": "2506.22694", "pdf": "https://arxiv.org/pdf/2506.22694", "abs": "https://arxiv.org/abs/2506.22694", "authors": ["Raghavv Goel", "Sudhanshu Agrawal", "Mukul Gagrani", "Junyoung Park", "Yifan Zao", "He Zhang", "Tian Liu", "Yiping Yang", "Xin Yuan", "Jiuyan Lu", "Chris Lott", "Mingu Lee"], "title": "VOCABTRIM: Vocabulary Pruning for Efficient Speculative Decoding in LLMs", "categories": ["cs.CL", "cs.LG"], "comment": "8 pages, 4 figures, 5 tables, accepted at ICML 2025 workshop on\n  Efficient Systems for Foundational Models", "summary": "In this paper, we introduce a simple training-free technique to improve the\nperformance of drafter-based speculative decoding (SpD) methods that\nincorporates language modeling head (LM head) during drafting process. A\ndrafter-based speculative decoding leverages one or more smaller language\nmodels, a.k.a. drafters or draft models, to sample a draft sequence or tree\nconsisting of multiple tokens, followed by verification by a base LLM, a target\nmodel, accepting a subset as its valid generation. As it is usually considered\nthat the speculative decoding requires one-to-one mapping between vocabularies\nof the target model and the draft model, it has been natural to share the\nvocabulary between them, or even share the LM head as in EAGLE or Medusa. We\nfirst identify that this draft token sampling scheme inherently contains an\nunnecessary inference overhead in drafting, especially for some target LLMs\nwith very large vocabularies. Then, we propose a simple technique, VocabTrim,\nto mitigate the drafting overhead to improve the generation speed in\nmemory-bound environment. VocabTrim reconstructs the drafter LM head to contain\nonly a limited set of tokens, selected by the most frequently sampled from the\nvocabulary of the target model. While limiting the vocabulary in drafting\nslightly degrades the acceptance rate, it significantly reduces the drafting\nlatency in memory-bound process which is often the case on edge devices,\nresulting in higher memory-bound speed up (MBSU). We show that our method can\nboost the memory-bound speed-up for Llama-3 models on Spec-Bench, specifically\nby 16% for Llama-3.2-3B-Instruct."}
{"id": "2507.03162", "pdf": "https://arxiv.org/pdf/2507.03162", "abs": "https://arxiv.org/abs/2507.03162", "authors": ["Dumitran Adrian Marius", "Theodor-Pierre Moroianu", "Buca Mihnea-Vicentiu"], "title": "MateInfoUB: A Real-World Benchmark for Testing LLMs in Competitive, Multilingual, and Multimodal Educational Tasks", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.LG"], "comment": "14 pages (9 paper, 2 references, 3 annexes). Accepted for BEA 2025!", "summary": "The rapid advancement of Large Language Models (LLMs) has transformed various\ndomains, particularly computer science (CS) education. These models exhibit\nremarkable capabilities in code-related tasks and problem-solving, raising\nquestions about their potential and limitations in advanced CS contexts. This\nstudy presents a novel bilingual (English-Romanian) multimodal (text and image)\ndataset of multiple-choice questions derived from a high-level computer science\ncompetition. A particularity of our dataset is that the problems are conceived\nsuch that some of them are easier solved using reasoning on paper, while for\nothers writing code is more efficient. We systematically evaluate State of The\nArt LLMs on this dataset, analyzing their performance on theoretical\nprogramming tasks. Our findings reveal the strengths and limitations of current\nLLMs, including the influence of language choice (English vs. Romanian),\nproviding insights into their applicability in CS education and competition\nsettings. We also address critical ethical considerations surrounding\neducational integrity and the fairness of assessments in the context of LLM\nusage. These discussions aim to inform future educational practices and\npolicies. To support further research, our dataset will be made publicly\navailable in both English and Romanian. Additionally, we release an educational\napplication tailored for Romanian students, enabling them to self-assess using\nthe dataset in an interactive and practice-oriented environment."}
{"id": "2508.14279", "pdf": "https://arxiv.org/pdf/2508.14279", "abs": "https://arxiv.org/abs/2508.14279", "authors": ["Adrian-Marius Dumitran", "Alexandra-Mihaela Danila", "Angela-Liliana Dumitran"], "title": "GRILE: A Benchmark for Grammar Reasoning and Explanation in Romanian LLMs", "categories": ["cs.CL", "cs.CY", "cs.LG"], "comment": "Accepted as long paper @RANLP2025", "summary": "LLMs (Large language models) have revolutionized NLP (Natural Language\nProcessing), yet their pedagogical value for low-resource languages remains\nunclear. We present GRILE (Grammar Romanian Inference and Language\nExplanations) , the first open benchmark of 1,151 multiple-choice questions\nharvested from Romanian high-stakes exams (National Evaluation, Baccalaureate,\nuniversity admissions). GRILE enables us to probe two complementary abilities\nof seven state-of-the-art multilingual and Romanian-specific LLMs: (i)\nselecting the correct answer, and (ii) producing linguistically accurate\nexplanations. While Gemini 2.5 Pro reaches 83% accuracy, most open-weight\nmodels stay below 65%, and 48% of their explanations contain factual or\npedagogical flaws according to expert review. A detailed error analysis\npinpoints systematic weaknesses in morphology and in applying the latest DOOM3\northographic norms. All data, code and a public web demo are released to\ncatalyze future research. Our findings expose open challenges for trustworthy\neducational NLP in low-resource settings and establish GRILE as a new test-bed\nfor controllable explanation generation and evaluation."}
{"id": "2509.22059", "pdf": "https://arxiv.org/pdf/2509.22059", "abs": "https://arxiv.org/abs/2509.22059", "authors": ["Partha Konar", "Vishal S. Ngairangbam", "Michael Spannowsky", "Deepanshu Srivastava"], "title": "Stable and Interpretable Jet Physics with IRC-Safe Equivariant Feature Extraction", "categories": ["hep-ph", "cs.LG", "hep-ex"], "comment": "30 pages, 3 tables, 7 figures", "summary": "Deep learning has achieved remarkable success in jet classification tasks,\nyet a key challenge remains: understanding what these models learn and how\ntheir features relate to known QCD observables. Improving interpretability is\nessential for building robust and trustworthy machine learning tools in\ncollider physics. To address this challenge, we investigate graph neural\nnetworks for quark-gluon discrimination, systematically incorporating\nphysics-motivated inductive biases. In particular, we design message-passing\narchitectures that enforce infrared and collinear (IRC) safety, as well as E(2)\nand O(2) equivariance in the rapidity-azimuth plane. Using simulated jet\ndatasets, we compare these networks against unconstrained baselines in terms of\nclassification performance, robustness to soft emissions, and latent\nrepresentation structures. Our analysis shows that physics-aware networks are\nmore stable across training instances and distribute their latent variance\nacross multiple interpretable directions. By regressing Energy Flow Polynomials\nonto the leading principal components, we establish a direct correspondence\nbetween learned representations and established IRC-safe jet observables. These\nresults demonstrate that embedding symmetry and safety constraints not only\nimproves robustness but also grounds network representations in known QCD\nstructures, providing a principled approach toward interpretable deep learning\nin collider physics."}
{"id": "2509.22654", "pdf": "https://arxiv.org/pdf/2509.22654", "abs": "https://arxiv.org/abs/2509.22654", "authors": ["Xuhang Chen", "Bo Lv", "Mengqian Wang", "Xunwen Xiang", "Shiting Wu", "Shenghong Luo", "Wenjun Zhang"], "title": "A Comprehensive Analysis of Churn Prediction in Telecommunications Using Machine Learning", "categories": ["stat.AP", "cs.LG"], "comment": "Accepted by CAIT 2025", "summary": "Customer churn prediction in the telecommunications sector represents a\ncritical business intelligence task that has evolved from subjective human\nassessment to sophisticated algorithmic approaches. In this work, we present a\ncomprehensive framework for telecommunications churn prediction leveraging deep\nneural networks. Through systematic problem formulation, rigorous dataset\nanalysis, and careful feature engineering, we develop a model that captures\ncomplex patterns in customer behavior indicative of potential churn. We conduct\nextensive empirical evaluations across multiple performance metrics,\ndemonstrating that our proposed neural architecture achieves significant\nimprovements over existing baseline methods. Our approach not only advances the\nstate-of-the-art in churn prediction accuracy but also provides interpretable\ninsights into the key factors driving customer attrition in telecommunications\nservices."}
{"id": "2509.22657", "pdf": "https://arxiv.org/pdf/2509.22657", "abs": "https://arxiv.org/abs/2509.22657", "authors": ["Ethan Greiffenstein", "Trevor Harris", "Rebecca Smith"], "title": "Forecasting West Nile virus with deep graph encoders", "categories": ["stat.AP", "cs.LG"], "comment": "34 pages, 13 tables, and 3 figures", "summary": "West Nile virus is a significant, and growing, public health issue in the\nUnited States. With no human vaccine, mosquito control programs rely on\naccurate forecasting to determine when and where WNV will emerge. Recently,\nspatial Graph neural networks (GNNs) were shown to be a powerful tool for WNV\nforecasting, significantly improving over traditional methods. Building on this\nwork, we introduce a new GNN variant that linearly connects graph attention\nlayers, allowing us to train much larger models than previously used for WNV\nforecasting. This architecture specializes general densely connected GNNs so\nthat the model focuses more heavily on local information to prevent over\nsmoothing. To support training large GNNs we compiled a massive new dataset of\nweather data, land use information, and mosquito trap results across Illinois.\nExperiments show that our approach significantly outperforms both GNN and\nclassical baselines in both out-of-sample and out-of-graph WNV prediction skill\nacross a variety of scenarios and over all prediction horizons."}
{"id": "2509.22667", "pdf": "https://arxiv.org/pdf/2509.22667", "abs": "https://arxiv.org/abs/2509.22667", "authors": ["Pieterjan Robbe", "Andre Ruybalid", "Arun Hegde", "Christophe Bonneville", "Habib N Najm", "Laurent Capolungo", "Cosmin Safta"], "title": "A Comparison of Surrogate Constitutive Models for Viscoplastic Creep Simulation of HT-9 Steel", "categories": ["physics.comp-ph", "cond-mat.mtrl-sci", "cs.CE", "cs.LG"], "comment": null, "summary": "Mechanistic microstructure-informed constitutive models for the mechanical\nresponse of polycrystals are a cornerstone of computational materials science.\nHowever, as these models become increasingly more complex - often involving\ncoupled differential equations describing the effect of specific deformation\nmodes - their associated computational costs can become prohibitive,\nparticularly in optimization or uncertainty quantification tasks that require\nnumerous model evaluations. To address this challenge, surrogate constitutive\nmodels that balance accuracy and computational efficiency are highly desirable.\nData-driven surrogate models, that learn the constitutive relation directly\nfrom data, have emerged as a promising solution. In this work, we develop two\nlocal surrogate models for the viscoplastic response of a steel: a piecewise\nresponse surface method and a mixture of experts model. These surrogates are\ndesigned to adapt to complex material behavior, which may vary with material\nparameters or operating conditions. The surrogate constitutive models are\napplied to creep simulations of HT-9 steel, an alloy of considerable interest\nto the nuclear energy sector due to its high tolerance to radiation damage,\nusing training data generated from viscoplastic self-consistent (VPSC)\nsimulations. We define a set of test metrics to numerically assess the accuracy\nof our surrogate models for predicting viscoplastic material behavior, and show\nthat the mixture of experts model outperforms the piecewise response surface\nmethod in terms of accuracy."}
{"id": "2509.22668", "pdf": "https://arxiv.org/pdf/2509.22668", "abs": "https://arxiv.org/abs/2509.22668", "authors": ["Aubida A. Al-Hameed", "Mohammed M. H. Qazzaz", "Maryam Hafeez", "Syed A. Zaidi"], "title": "Semantic-Aware Edge Intelligence for UAV Handover in 6G Networks", "categories": ["eess.SY", "cs.LG", "cs.NI", "cs.SY"], "comment": "Paper has been accepted in European Wireless 2025 conference", "summary": "6G wireless networks aim to exploit semantic awareness to optimize radio\nresources. By optimizing the transmission through the lens of the desired goal,\nthe energy consumption of transmissions can also be reduced, and the latency\ncan be improved. To that end, this paper investigates a paradigm in which the\ncapabilities of generative AI (GenAI) on the edge are harnessed for network\noptimization. In particular, we investigate an Unmanned Aerial Vehicle (UAV)\nhandover framework that takes advantage of GenAI and semantic communication to\nmaintain reliable connectivity. To that end, we propose a framework in which a\nlightweight MobileBERT language model, fine-tuned using Low-Rank Adaptation\n(LoRA), is deployed on the UAV. This model processes multi-attribute flight and\nradio measurements and performs multi-label classification to determine\nappropriate handover action. Concurrently, the model identifies an appropriate\nset of contextual \"Reason Tags\" that elucidate the decision's rationale. Our\nmodel, evaluated on a rule-based synthetic dataset of UAV handover scenarios,\ndemonstrates the model's high efficacy in learning these rules, achieving high\naccuracy in predicting the primary handover decision. The model also shows\nstrong performance in identifying supporting reasons, with an F1 micro-score of\napproximately 0.9 for reason tags."}
{"id": "2509.22673", "pdf": "https://arxiv.org/pdf/2509.22673", "abs": "https://arxiv.org/abs/2509.22673", "authors": ["Thalea Schlender", "Catharina J. A. Romme", "Yvette M. van der Linden", "Luc R. C. W. van Lonkhuijzen", "Peter A. N. Bosman", "Tanja Alderliesten"], "title": "PISA: An AI Pipeline for Interpretable-by-design Survival Analysis Providing Multiple Complexity-Accuracy Trade-off Models", "categories": ["stat.AP", "cs.AI", "cs.LG"], "comment": null, "summary": "Survival analysis is central to clinical research, informing patient\nprognoses, guiding treatment decisions, and optimising resource allocation.\nAccurate time-to-event predictions not only improve quality of life but also\nreveal risk factors that shape clinical practice. For these models to be\nrelevant in healthcare, interpretability is critical: predictions must be\ntraceable to patient-specific characteristics, and risk factors should be\nidentifiable to generate actionable insights for both clinicians and\nresearchers. Traditional survival models often fail to capture non-linear\ninteractions, while modern deep learning approaches, though powerful, are\nlimited by poor interpretability.\n  We propose a Pipeline for Interpretable Survival Analysis (PISA) - a pipeline\nthat provides multiple survival analysis models that trade off complexity and\nperformance. Using multiple-feature, multi-objective feature engineering, PISA\ntransforms patient characteristics and time-to-event data into multiple\nsurvival analysis models, providing valuable insights into the survival\nprediction task. Crucially, every model is converted into simple patient\nstratification flowcharts supported by Kaplan-Meier curves, whilst not\ncompromising on performance. While PISA is model-agnostic, we illustrate its\nflexibility through applications of Cox regression and shallow survival trees,\nthe latter avoiding proportional hazards assumptions.\n  Applied to two clinical benchmark datasets, PISA produced interpretable\nsurvival models and intuitive stratification flowcharts whilst achieving\nstate-of-the-art performances. Revisiting a prior departmental study further\ndemonstrated its capacity to automate survival analysis workflows in real-world\nclinical research."}
{"id": "2509.22677", "pdf": "https://arxiv.org/pdf/2509.22677", "abs": "https://arxiv.org/abs/2509.22677", "authors": ["Srijesh Pillai", "Rajesh Kumar Chandrawat"], "title": "Profit over Proxies: A Scalable Bayesian Decision Framework for Optimizing Multi-Variant Online Experiments", "categories": ["stat.AP", "cs.LG", "stat.ML"], "comment": "15 pages, 2 figures, 5 tables. Working Paper", "summary": "Online controlled experiments (A/B tests) are fundamental to data-driven\ndecision-making in the digital economy. However, their real-world application\nis frequently compromised by two critical shortcomings: the use of\nstatistically flawed heuristics like \"p-value peeking\", which inflates false\npositive rates, and an over-reliance on proxy metrics like conversion rates,\nwhich can lead to decisions that inadvertently harm core business\nprofitability. This paper addresses these challenges by introducing a\ncomprehensive and scalable Bayesian decision framework designed for profit\noptimization in multi-variant (A/B/n) experiments.\n  We propose a hierarchical Bayesian model that simultaneously estimates the\nprobability of conversion (using a Beta-Bernoulli model) and the monetary value\nof that conversion (using a robust Bayesian model for the mean transaction\nvalue). Building on this, we employ a decision-theoretic stopping rule based on\nExpected Loss, enabling experiments to be concluded not only when a superior\nvariant is identified but also when it becomes clear that no variant offers a\npractically significant improvement (stopping for futility). The framework\nsuccessfully navigates \"revenue traps\" where a variant with a higher conversion\nrate would have resulted in a net financial loss, correctly terminates futile\nexperiments early to conserve resources, and maintains strict statistical\nintegrity throughout the monitoring process.\n  Ultimately, this work provides a practical and principled methodology for\norganizations to move beyond simple A/B testing towards a mature, profit-driven\nexperimentation culture, ensuring that statistical conclusions translate\ndirectly to strategic business value."}
{"id": "2509.22697", "pdf": "https://arxiv.org/pdf/2509.22697", "abs": "https://arxiv.org/abs/2509.22697", "authors": ["Abhiroop Chatterjee", "Susmita Ghosh"], "title": "Learning Hyperspectral Images with Curated Text Prompts for Efficient Multimodal Alignment", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted at the IEEE/CVF International Conference on Computer Vision\n  (ICCV 2025), Workshop on Curated Data for Efficient Learning", "summary": "As data requirements continue to grow, efficient learning increasingly\ndepends on the curation and distillation of high-value data rather than\nbrute-force scaling of model sizes. In the case of a hyperspectral image (HSI),\nthe challenge is amplified by the high-dimensional 3D voxel structure, where\neach spatial location is associated with hundreds of contiguous spectral\nchannels. While vision and language models have been optimized effectively for\nnatural image or text tasks, their cross-modal alignment in the hyperspectral\ndomain remains an open and underexplored problem. In this article, we make an\nattempt to optimize a Vision-Language Model (VLM) for hyperspectral scene\nunderstanding by exploiting a CLIP-style contrastive training framework. Our\nframework maps voxel-level embeddings from a vision backbone onto the latent\nspace of a frozen large embedding model (LEM), where a trainable probe aligns\nvision features with the model's textual token representations. The two\nmodalities are aligned via a contrastive loss restricted to a curated set of\nhard (closest wrong classes) and semi-hard (random distractors) negatives,\nalong with positive pairs. To further enhance alignment, descriptive prompts\nthat encode class semantics are introduced and act as structured anchors for\nthe HSI embeddings. It is seen that the proposed method updates only 0.07\npercent of the total parameters, yet yields state-of-the-art performance. For\nexample, on Indian Pines (IP) the model produces better results over unimodal\nand multimodal baselines by +0.92 Overall Accuracy (OA) and +1.60 Kappa\n($\\kappa$), while on Pavia University (PU) data it provides gains of +0.69 OA\nand +0.90 $\\kappa$. Moreover, this is achieved with the set of parameters,\nnearly 50$\\times$ smaller than DCTN and 90$\\times$ smaller than SS-TMNet."}
{"id": "2509.22701", "pdf": "https://arxiv.org/pdf/2509.22701", "abs": "https://arxiv.org/abs/2509.22701", "authors": ["Leszek Sliwko", "Jolanta Mizera-Pietraszko"], "title": "Enhancing Cluster Scheduling in HPC: A Continuous Transfer Learning for Real-Time Optimization", "categories": ["cs.DC", "cs.AI", "cs.LG"], "comment": "This is the accepted version of the paper published in 2025 IEEE\n  International Parallel and Distributed Processing Symposium Workshops\n  (IPDPSW). The final version is available at:\n  https://doi.org/10.1109/IPDPSW66978.2025.00056", "summary": "This study presents a machine learning-assisted approach to optimize task\nscheduling in cluster systems, focusing on node-affinity constraints.\nTraditional schedulers like Kubernetes struggle with real-time adaptability,\nwhereas the proposed continuous transfer learning model evolves dynamically\nduring operations, minimizing retraining needs. Evaluated on Google Cluster\nData, the model achieves over 99% accuracy, reducing computational overhead and\nimproving scheduling latency for constrained tasks. This scalable solution\nenables real-time optimization, advancing machine learning integration in\ncluster management and paving the way for future adaptive scheduling\nstrategies."}
{"id": "2509.22707", "pdf": "https://arxiv.org/pdf/2509.22707", "abs": "https://arxiv.org/abs/2509.22707", "authors": ["Jinqi Yan", "Fang He", "Qianlong Sang", "Bifeng Tong", "Peng Sun", "Yili Gong", "Chuang Hu", "Dazhao Cheng"], "title": "Metadata-Guided Adaptable Frequency Scaling across Heterogeneous Applications and Devices", "categories": ["cs.DC", "cs.LG", "stat.ML"], "comment": null, "summary": "Dynamic Voltage and Frequency Scaling is essential for enhancing energy\nefficiency in mobile platforms. However, traditional heuristic-based governors\nare increasingly inadequate for managing the complexity of heterogeneous\nSystem-on-Chip designs and diverse application workloads. Although\nreinforcement learning approaches offer improved performance, their poor\ngeneralization capability and reliance on extensive retraining for each\nhardware and application combination leads to significant deployment costs. In\nthis work, we observe that device and application metadata inherently\nencapsulate valuable knowledge for DVFS, presenting an opportunity to overcome\nthese limitations. We formulate DVFS for heterogeneous devices and applications\nas a multi-task reinforcement learning problem. We introduce MetaDVFS, which is\na metadata-guided framework that systematically leverages metadata to discover\nand transfer shared knowledge across DVFS tasks. MetaDVFS can output a set of\nDVFS models with significant generalization capability for various applications\nof heterogeneous devices. Evaluations on five Google Pixel devices running six\napplications show that MetaDVFS achieves up to 17% improvement in\nPerformance-Power Ratio and up to 26% improvement in Quality of Experience.\nCompared to state-of-the-art methods, MetaDVFS delivers 70.8% faster adaptation\nand 5.8-27.6% higher performance over standalone device-application specific\ntraining, while avoiding negative transfer effects. These results establish\nMetaDVFS as an effective and scalable solution for DVFS deployment in\nheterogeneous mobile environments."}
{"id": "2509.22708", "pdf": "https://arxiv.org/pdf/2509.22708", "abs": "https://arxiv.org/abs/2509.22708", "authors": ["Ahed Alboody"], "title": "GZSL-MoE: Apprentissage G{é}n{é}ralis{é} Z{é}ro-Shot bas{é} sur le M{é}lange d'Experts pour la Segmentation S{é}mantique de Nuages de Points 3DAppliqu{é} {à} un Jeu de Donn{é}es d'Environnement de Collaboration Humain-Robot", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "in French language. 28e Conf{\\'e}rence Nationale en Intelligence\n  Artificielle. Plate-Forme Intelligence Artificielle 2025, Association Fran{\\c\n  c}aise pour l'Intelligence Artificielle, https://pfia2025.u-bourgogne.fr/,\n  Jun 2025, Dijon, France", "summary": "Generative Zero-Shot Learning approach (GZSL) has demonstrated significant\npotential in 3D point cloud semantic segmentation tasks. GZSL leverages\ngenerative models like GANs or VAEs to synthesize realistic features (real\nfeatures) of unseen classes. This allows the model to label unseen classes\nduring testing, despite being trained only on seen classes. In this context, we\nintroduce the Generalized Zero-Shot Learning based-upon Mixture-of-Experts\n(GZSL-MoE) model. This model incorporates Mixture-of-Experts layers (MoE) to\ngenerate fake features that closely resemble real features extracted using a\npre-trained KPConv (Kernel Point Convolution) model on seen classes. The main\ncontribution of this paper is the integration of Mixture-of-Experts into the\nGenerator and Discriminator components of the Generative Zero-Shot Learning\nmodel for 3D point cloud semantic segmentation, applied to the COVERED dataset\n(CollabOratiVE Robot Environment Dataset) for Human-Robot Collaboration (HRC)\nenvironments. By combining the Generative Zero-Shot Learning model with\nMixture-of- Experts, GZSL-MoE for 3D point cloud semantic segmentation provides\na promising solution for understanding complex 3D environments, especially when\ncomprehensive training data for all object classes is unavailable. The\nperformance evaluation of the GZSL-MoE model highlights its ability to enhance\nperformance on both seen and unseen classes. Keywords Generalized Zero-Shot\nLearning (GZSL), 3D Point Cloud, 3D Semantic Segmentation, Human-Robot\nCollaboration, COVERED (CollabOratiVE Robot Environment Dataset), KPConv,\nMixture-of Experts"}
{"id": "2509.22719", "pdf": "https://arxiv.org/pdf/2509.22719", "abs": "https://arxiv.org/abs/2509.22719", "authors": ["Adithya Giri"], "title": "IBiT: Utilizing Inductive Biases to Create a More Data Efficient Attention Mechanism", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "In recent years, Transformer-based architectures have become the dominant\nmethod for Computer Vision applications. While Transformers are explainable and\nscale well with dataset size, they lack the inductive biases of Convolutional\nNeural Networks. While these biases may be learned on large datasets, we show\nthat introducing these inductive biases through learned masks allow Vision\nTransformers to learn on much smaller datasets without Knowledge Distillation.\nThese Transformers, which we call Inductively Biased Image Transformers (IBiT),\nare significantly more accurate on small datasets, while retaining the\nexplainability Transformers."}
{"id": "2509.22720", "pdf": "https://arxiv.org/pdf/2509.22720", "abs": "https://arxiv.org/abs/2509.22720", "authors": ["Zezhong Fan", "Xiaohan Li", "Luyi Ma", "Kai Zhao", "Liang Peng", "Topojoy Biswas", "Evren Korpeoglu", "Kaushiki Nag", "Kannan Achan"], "title": "LayoutAgent: A Vision-Language Agent Guided Compositional Diffusion for Spatial Layout Planning", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "NeurIPS 2025 Workshop on SPACE in Vision, Language, and Embodied AI", "summary": "Designing realistic multi-object scenes requires not only generating images,\nbut also planning spatial layouts that respect semantic relations and physical\nplausibility. On one hand, while recent advances in diffusion models have\nenabled high-quality image generation, they lack explicit spatial reasoning,\nleading to unrealistic object layouts. On the other hand, traditional spatial\nplanning methods in robotics emphasize geometric and relational consistency,\nbut they struggle to capture semantic richness in visual scenes. To bridge this\ngap, in this paper, we propose LayoutAgent, an agentic framework that unifies\nvision-language reasoning with compositional diffusion for layout generation.\nGiven multiple input images with target objects in them, our method first\nemploys visual-language model to preprocess the inputs through segmentation,\nobject size estimation, scene graph construction, and prompt rewriting. Then we\nleverage compositional diffusion-a method traditionally used in robotics-to\nsynthesize bounding boxes that respect object relations encoded in the scene\ngraph for spatial layouts. In the end, a foreground-conditioned image generator\ncomposes the complete scene by rendering the objects into the planned layout\nguided by designed prompts. Experiments demonstrate that LayoutAgent\noutperforms other state-of-the-art layout generation models in layout\ncoherence, spatial realism and aesthetic alignment."}
{"id": "2509.22721", "pdf": "https://arxiv.org/pdf/2509.22721", "abs": "https://arxiv.org/abs/2509.22721", "authors": ["Ángel Lloret", "Jesús Peral", "Antonio Ferrández", "María Auladell", "Rafael Muñoz"], "title": "A Data-Driven Framework for Digital Transformation in Smart Cities: Integrating AI, Dashboards, and IoT Readiness", "categories": ["cs.CY", "cs.AI", "cs.LG", "I.2.0"], "comment": "30 pages, 5 figures", "summary": "Digital transformation (DT) has become a strategic priority for public\nadministrations, particularly due to the need to deliver more efficient and\ncitizen-centered services and respond to societal expectations, ESG\n(Environmental, Social, and Governance) criteria, and the United Nations\nSustainable Development Goals (UN SDGs). In this context, the main objective of\nthis study is to propose an innovative methodology to automatically evaluate\nthe level of digital transformation (DT) in public sector organizations. The\nproposed approach combines traditional assessment methods with Artificial\nIntelligence (AI) techniques. The methodology follows a dual approach: on the\none hand, surveys are conducted using specialized staff from various public\nentities; on the other, AI-based models (including neural networks and\ntransformer architectures) are used to estimate the DT level of the\norganizations automatically. Our approach has been applied to a real-world case\nstudy involving local public administrations in the Valencian Community (Spain)\nand shown effective performance in assessing DT. While the proposed methodology\nhas been validated in a specific local context, its modular structure and\ndual-source data foundation support its international scalability,\nacknowledging that administrative, regulatory, and DT maturity factors may\ncondition its broader applicability. The experiments carried out in this work\ninclude (i) the creation of a domain-specific corpus derived from the surveys\nand websites of several organizations, used to train the proposed models; (ii)\nthe use and comparison of diverse AI methods; and (iii) the validation of our\napproach using real data. The integration of technologies such as the IoT,\nsensor networks, and AI-based analytics can significantly support resilient,\nagile urban environments and the transition towards more effective and\nsustainable Smart City models."}
{"id": "2509.22736", "pdf": "https://arxiv.org/pdf/2509.22736", "abs": "https://arxiv.org/abs/2509.22736", "authors": ["Merve Gülle", "Junno Yun", "Yaşar Utku Alçalar", "Mehmet Akçakaya"], "title": "Consistency Models as Plug-and-Play Priors for Inverse Problems", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG", "physics.med-ph", "stat.ML"], "comment": null, "summary": "Diffusion models have found extensive use in solving numerous inverse\nproblems. Such diffusion inverse problem solvers aim to sample from the\nposterior distribution of data given the measurements, using a combination of\nthe unconditional score function and an approximation of the posterior related\nto the forward process. Recently, consistency models (CMs) have been proposed\nto directly predict the final output from any point on the diffusion ODE\ntrajectory, enabling high-quality sampling in just a few NFEs. CMs have also\nbeen utilized for inverse problems, but existing CM-based solvers either\nrequire additional task-specific training or utilize data fidelity operations\nwith slow convergence, not amenable to large-scale problems. In this work, we\nreinterpret CMs as proximal operators of a prior, enabling their integration\ninto plug-and-play (PnP) frameworks. We propose a solver based on PnP-ADMM,\nwhich enables us to leverage the fast convergence of conjugate gradient method.\nWe further accelerate this with noise injection and momentum, dubbed PnP-CM,\nand show it maintains the convergence properties of the baseline PnP-ADMM. We\nevaluate our approach on a variety of inverse problems, including inpainting,\nsuper-resolution, Gaussian deblurring, and magnetic resonance imaging (MRI)\nreconstruction. To the best of our knowledge, this is the first CM trained for\nMRI datasets. Our results show that PnP-CM achieves high-quality\nreconstructions in as few as 4 NFEs, and can produce meaningful results in 2\nsteps, highlighting its effectiveness in real-world inverse problems while\noutperforming comparable CM-based approaches."}
{"id": "2509.22738", "pdf": "https://arxiv.org/pdf/2509.22738", "abs": "https://arxiv.org/abs/2509.22738", "authors": ["Parikshit Bansal", "Sujay Sanghavi"], "title": "Enabling Approximate Joint Sampling in Diffusion LMs", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "In autoregressive language models, each token is sampled by conditioning on\nall the past tokens; the overall string has thus been sampled from the correct\nunderlying joint distribution represented by the model. In contrast, masked\ndiffusion language models generate text by unmasking tokens out of order and\npotentially in parallel. Generating an overall string sampled from the correct\nunderlying joint distribution would (again) require exactly one token unmasking\nin every full-model forward pass. The more tokens unmasked in parallel, the\nfurther away the string is from the true joint; this can be seen in the\nresulting drop in accuracy (but, increase in speed). In this paper we devise a\nway to {\\em approximately} sample multiple tokens from the joint distribution\nin a single full-model forward pass; we do so by developing a new lightweight\nsingle-layer ``sampler\" on top of an existing large diffusion LM. One forward\npass of the full model can now be followed by multiple forward passes of only\nthis sampler layer, to yield multiple unmasked tokens. Our sampler is trained\nto mimic exact joint sampling from the (frozen) full model. We show the\neffectiveness of our approximate joint sampling for both pretrained-only\n(Dream-7B-Base) and instruction-tuned (Dream-7B-Instruct) models on language\nmodeling and math \\& coding tasks. When four tokens are unmasked for each\nfull-model denoising step, our sampling algorithm achieves a MAUVE score of\n0.87 (vs marginal baseline of 0.31) with respect to the true joint\ndistribution."}
{"id": "2509.22739", "pdf": "https://arxiv.org/pdf/2509.22739", "abs": "https://arxiv.org/abs/2509.22739", "authors": ["Sasha Cui", "Zhongren Chen"], "title": "Painless Activation Steering: An Automated, Lightweight Approach for Post-Training Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML", "I.2.6; I.2.7"], "comment": null, "summary": "Language models (LMs) are typically post-trained for desired capabilities and\nbehaviors via weight-based or prompt-based steering, but the former is\ntime-consuming and expensive, and the latter is not precisely controllable and\noften requires manual trial-and-error. While activation steering (AS) promises\na cheap, fast, and controllable alternative to the two existing post-training\nmethods, current AS techniques require hand-crafted prompt pairs or\nlabor-intensive feature annotation, making them more inconvenient than the\nplug-and-play methods such as Reinforcement Learning (RL) and Supervised\nFine-Tuning (SFT). We introduce Painless Activation Steering (PAS), a family of\nfully automated methods that make AS readily usable with any given labeled\ndataset, with no need for prompt construction, feature labeling, or human\nintervention. We evaluate PAS on three open-weight models\n(Llama3.1-8B-Instruct, DeepSeek-R1-Distill-8B, and Nous-Hermes-2) and 18 tasks;\nwe find that PAS reliably improves performance for behavior tasks, but not for\nintelligence-oriented tasks. The introspective variant (iPAS) delivers the\nstrongest causal steering effects (10.1% on Bias, 5.2% on Morality, and 34.8%\non Alignment). We also show PAS delivers additional gains on top of In-Context\nLearning (ICL) and SFT. PAS constructs a fast, lightweight activation vector\nthat can be cheaply trained, easily stored, and activated at will. Our results\nprovide a characterization of where AS helps, where it fails, and how to deploy\nit as a practical, automated LM post-training option."}
{"id": "2509.22748", "pdf": "https://arxiv.org/pdf/2509.22748", "abs": "https://arxiv.org/abs/2509.22748", "authors": ["Yuqing Liu"], "title": "Generalization Analysis for Classification on Korobov Space", "categories": ["math.ST", "cs.LG", "stat.ML", "stat.TH"], "comment": null, "summary": "In this paper, the classification algorithm arising from Tikhonov\nregularization is discussed. The main intention is to derive learning rates for\nthe excess misclassification error according to the convex $\\eta$-norm loss\nfunction $\\phi(v)=(1 - v)_{+}^{\\eta}$, $\\eta\\geq1$. Following the argument, the\nestimation of error under Tsybakov noise conditions is studied. In addition, we\npropose the rate of $L_p$ approximation of functions from Korobov space $X^{2,\np}([-1,1]^{d})$, $1\\leq p \\leq \\infty$, by the shallow ReLU neural network.\nThis result consists of a novel Fourier analysis"}
{"id": "2509.22751", "pdf": "https://arxiv.org/pdf/2509.22751", "abs": "https://arxiv.org/abs/2509.22751", "authors": ["Kaihua Ding"], "title": "Variance-Bounded Evaluation without Ground Truth: VB-Score", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "Reliable evaluation is a central challenge in machine learning when tasks\nlack ground truth labels or involve ambiguity and noise. Conventional\nframeworks, rooted in the Cranfield paradigm and label-based metrics, fail in\nsuch cases because they cannot assess how robustly a system performs under\nuncertain interpretations. We introduce VB-Score, a variance-bounded evaluation\nframework that measures both effectiveness and robustness without requiring\nground truth. Given a query or input, VB-Score enumerates plausible\ninterpretations, assigns probabilities, and evaluates output by expected\nsuccess penalized by variance, rewarding consistent performance across intents.\nWe provide a formal analysis of VB-Score, establishing range, monotonicity, and\nstability properties, and relate it to risk-sensitive measures such as\nmean-variance utility. Experiments on ambiguous queries and entity-centric\nretrieval tasks show that VB-Score surfaces robustness differences hidden by\nconventional metrics. By enabling reproducible, label-free evaluation, VB-Score\noffers a principled foundation for benchmarking machine learning systems in\nambiguous or label-scarce domains."}
{"id": "2509.22755", "pdf": "https://arxiv.org/pdf/2509.22755", "abs": "https://arxiv.org/abs/2509.22755", "authors": ["Ekkehard Schnoor", "Malik Tiomoko", "Jawher Said", "Alex Jung", "Wojciech Samek"], "title": "Concept activation vectors: a unifying view and adversarial attacks", "categories": ["stat.ML", "cs.LG", "math.PR"], "comment": "5 pages, 4 figures", "summary": "Concept Activation Vectors (CAVs) are a tool from explainable AI, offering a\npromising approach for understanding how human-understandable concepts are\nencoded in a model's latent spaces. They are computed from hidden-layer\nactivations of inputs belonging either to a concept class or to non-concept\nexamples. Adopting a probabilistic perspective, the distribution of the\n(non-)concept inputs induces a distribution over the CAV, making it a random\nvector in the latent space. This enables us to derive mean and covariance for\ndifferent types of CAVs, leading to a unified theoretical view. This\nprobabilistic perspective also reveals a potential vulnerability: CAVs can\nstrongly depend on the rather arbitrary non-concept distribution, a factor\nlargely overlooked in prior work. We illustrate this with a simple yet\neffective adversarial attack, underscoring the need for a more systematic\nstudy."}
{"id": "2509.22760", "pdf": "https://arxiv.org/pdf/2509.22760", "abs": "https://arxiv.org/abs/2509.22760", "authors": ["Achraf Zinihi"], "title": "Identifying Memory Effects in Epidemics via a Fractional SEIRD Model and Physics-Informed Neural Networks", "categories": ["stat.ML", "cs.LG", "q-bio.QM", "92C60, 26A33, 65L05, 68T07"], "comment": null, "summary": "We develop a physics-informed neural network (PINN) framework for parameter\nestimation in fractional-order SEIRD epidemic models. By embedding the Caputo\nfractional derivative into the network residuals via the L1 discretization\nscheme, our method simultaneously reconstructs epidemic trajectories and infers\nboth epidemiological parameters and the fractional memory order $\\alpha$. The\nfractional formulation extends classical integer-order models by capturing\nlong-range memory effects in disease progression, incubation, and recovery. Our\nframework learns the fractional memory order $\\alpha$ as a trainable parameter\nwhile simultaneously estimating the epidemiological rates $(\\beta, \\sigma,\n\\gamma, \\mu)$. A composite loss combining data misfit, physics residuals, and\ninitial conditions, with constraints on positivity and population conservation,\nensures both accuracy and biological consistency. Tests on synthetic Mpox data\nconfirm reliable recovery of $\\alpha$ and parameters under noise, while\napplications to COVID-19 show that optimal $\\alpha \\in (0, 1]$ captures memory\neffects and improves predictive performance over the classical SEIRD model.\nThis work establishes PINNs as a robust tool for learning memory effects in\nepidemic dynamics, with implications for forecasting, control strategies, and\nthe analysis of non-Markovian epidemic processes."}
{"id": "2509.22763", "pdf": "https://arxiv.org/pdf/2509.22763", "abs": "https://arxiv.org/abs/2509.22763", "authors": ["Tangqi Shi", "Pietro Lio"], "title": "UESA-Net: U-Shaped Embedded Multidirectional Shrinkage Attention Network for Ultrasound Nodule Segmentation", "categories": ["cs.CV", "cs.AI", "cs.LG", "68T07, 68U10", "I.4.9; I.4.6"], "comment": "22 pages,2 figures,4 tables", "summary": "Background: Breast and thyroid cancers pose an increasing public-health\nburden. Ultrasound imaging is a cost-effective, real-time modality for lesion\ndetection and segmentation, yet suffers from speckle noise, overlapping\nstructures, and weak global-local feature interactions. Existing networks\nstruggle to reconcile high-level semantics with low-level spatial details. We\naim to develop a segmentation framework that bridges the semantic gap between\nglobal context and local detail in noisy ultrasound images.\n  Methods: We propose UESA-Net, a U-shaped network with multidirectional\nshrinkage attention. The encoder-decoder architecture captures long-range\ndependencies and fine-grained structures of lesions. Within each encoding\nblock, attention modules operate along horizontal, vertical, and depth\ndirections to exploit spatial details, while a shrinkage (threshold) strategy\nintegrates prior knowledge and local features. The decoder mirrors the encoder\nbut applies a pairwise shrinkage mechanism, combining prior low-level physical\ncues with corresponding encoder features to enhance context modeling.\n  Results: On two public datasets - TN3K (3493 images) and BUSI (780 images) -\nUESA-Net achieved state-of-the-art performance with intersection-over-union\n(IoU) scores of 0.8487 and 0.6495, respectively.\n  Conclusions: UESA-Net effectively aggregates multidirectional spatial\ninformation and prior knowledge to improve robustness and accuracy in breast\nand thyroid ultrasound segmentation, demonstrating superior performance to\nexisting methods on multiple benchmarks."}
{"id": "2509.22766", "pdf": "https://arxiv.org/pdf/2509.22766", "abs": "https://arxiv.org/abs/2509.22766", "authors": ["Yang Rao"], "title": "A theoretical guarantee for SyncRank", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "We present a theoretical and empirical analysis of the SyncRank algorithm for\nrecovering a global ranking from noisy pairwise comparisons. By adopting a\ncomplex-valued data model where the true ranking is encoded in the phases of a\nunit-modulus vector, we establish a sharp non-asymptotic recovery guarantee for\nthe associated semidefinite programming (SDP) relaxation. Our main theorem\ncharacterizes a critical noise threshold - scaling as sigma = O(sqrt(n / log\nn)) - below which SyncRank achieves exact ranking recovery with high\nprobability. Extensive experiments under this model confirm the theoretical\npredictions and demonstrate the algorithm's robustness across varying problem\nsizes and noise regimes."}
{"id": "2509.22794", "pdf": "https://arxiv.org/pdf/2509.22794", "abs": "https://arxiv.org/abs/2509.22794", "authors": ["Haodong Liang", "Yanhao Jin", "Krishnakumar Balasubramanian", "Lifeng Lai"], "title": "Differentially Private Two-Stage Gradient Descent for Instrumental Variable Regression", "categories": ["stat.ML", "cs.AI", "cs.LG", "econ.EM", "math.ST", "stat.TH"], "comment": "31 pages, 9 figures", "summary": "We study instrumental variable regression (IVaR) under differential privacy\nconstraints. Classical IVaR methods (like two-stage least squares regression)\nrely on solving moment equations that directly use sensitive covariates and\ninstruments, creating significant risks of privacy leakage and posing\nchallenges in designing algorithms that are both statistically efficient and\ndifferentially private. We propose a noisy two-state gradient descent algorithm\nthat ensures $\\rho$-zero-concentrated differential privacy by injecting\ncarefully calibrated noise into the gradient updates. Our analysis establishes\nfinite-sample convergence rates for the proposed method, showing that the\nalgorithm achieves consistency while preserving privacy. In particular, we\nderive precise bounds quantifying the trade-off among privacy parameters,\nsample size, and iteration-complexity. To the best of our knowledge, this is\nthe first work to provide both privacy guarantees and provable convergence\nrates for instrumental variable regression in linear models. We further\nvalidate our theoretical findings with experiments on both synthetic and real\ndatasets, demonstrating that our method offers practical accuracy-privacy\ntrade-offs."}
{"id": "2509.22796", "pdf": "https://arxiv.org/pdf/2509.22796", "abs": "https://arxiv.org/abs/2509.22796", "authors": ["Xingyu Li", "Juefei Pu", "Yifan Wu", "Xiaochen Zou", "Shitong Zhu", "Xiaochen Zou", "Shitong Zhu", "Qiushi Wu", "Zheng Zhang", "Joshua Hsu", "Yue Dong", "Zhiyun Qian", "Kangjie Lu", "Trent Jaeger", "Michael De Lucia", "Srikanth V. Krishnamurthy"], "title": "What Do They Fix? LLM-Aided Categorization of Security Patches for Critical Memory Bugs", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "Open-source software projects are foundational to modern software ecosystems,\nwith the Linux kernel standing out as a critical exemplar due to its ubiquity\nand complexity. Although security patches are continuously integrated into the\nLinux mainline kernel, downstream maintainers often delay their adoption,\ncreating windows of vulnerability. A key reason for this lag is the difficulty\nin identifying security-critical patches, particularly those addressing\nexploitable vulnerabilities such as out-of-bounds (OOB) accesses and\nuse-after-free (UAF) bugs. This challenge is exacerbated by intentionally\nsilent bug fixes, incomplete or missing CVE assignments, delays in CVE\nissuance, and recent changes to the CVE assignment criteria for the Linux\nkernel. While fine-grained patch classification approaches exist, they exhibit\nlimitations in both coverage and accuracy. In this work, we identify previously\nunexplored opportunities to significantly improve fine-grained patch\nclassification. Specifically, by leveraging cues from commit titles/messages\nand diffs alongside appropriate code context, we develop DUALLM, a dual-method\npipeline that integrates two approaches based on a Large Language Model (LLM)\nand a fine-tuned small language model. DUALLM achieves 87.4% accuracy and an\nF1-score of 0.875, significantly outperforming prior solutions. Notably, DUALLM\nsuccessfully identified 111 of 5,140 recent Linux kernel patches as addressing\nOOB or UAF vulnerabilities, with 90 true positives confirmed by manual\nverification (many do not have clear indications in patch descriptions).\nMoreover, we constructed proof-of-concepts for two identified bugs (one UAF and\none OOB), including one developed to conduct a previously unknown control-flow\nhijack as further evidence of the correctness of the classification."}
{"id": "2509.22819", "pdf": "https://arxiv.org/pdf/2509.22819", "abs": "https://arxiv.org/abs/2509.22819", "authors": ["Sumanth Varambally", "Thomas Voice", "Yanchao Sun", "Zhifeng Chen", "Rose Yu", "Ke Ye"], "title": "Hilbert: Recursively Building Formal Proofs with Informal Reasoning", "categories": ["cs.AI", "cs.FL", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) demonstrate impressive mathematical reasoning\nabilities, but their solutions frequently contain errors that cannot be\nautomatically verified. Formal theorem proving systems such as Lean 4 offer\nautomated verification with complete accuracy, motivating recent efforts to\nbuild specialized prover LLMs that generate verifiable proofs in formal\nlanguages. However, a significant gap remains: current prover LLMs solve\nsubstantially fewer problems than general-purpose LLMs operating in natural\nlanguage. We introduce Hilbert, an agentic framework that bridges this gap by\ncombining the complementary strengths of informal reasoning and formal\nverification. Our system orchestrates four components: an informal LLM that\nexcels at mathematical reasoning, a specialized prover LLM optimized for Lean 4\ntactics, a formal verifier, and a semantic theorem retriever. Given a problem\nthat the prover is unable to solve, Hilbert employs recursive decomposition to\nsplit the problem into subgoals that it solves with the prover or reasoner LLM.\nIt leverages verifier feedback to refine incorrect proofs as necessary.\nExperimental results demonstrate that Hilbert substantially outperforms\nexisting approaches on key benchmarks, achieving 99.2% on miniF2F, 6.6% points\nabove the best publicly available method. Hilbert achieves the best known\nresult on PutnamBench. It solves 462/660 problems (70.0%), outperforming\nproprietary approaches like SeedProver (50.4%) and achieving a 422% improvement\nover the best publicly available baseline. Thus, Hilbert effectively narrows\nthe gap between informal reasoning and formal proof generation."}
{"id": "2509.22832", "pdf": "https://arxiv.org/pdf/2509.22832", "abs": "https://arxiv.org/abs/2509.22832", "authors": ["Biyao Zhang", "Mingkai Zheng", "Debargha Ganguly", "Xuecen Zhang", "Vikash Singh", "Vipin Chaudhary", "Zhao Zhang"], "title": "Efficient Fine-Grained GPU Performance Modeling for Distributed Deep Learning of LLM", "categories": ["cs.DC", "cs.AI", "cs.LG"], "comment": null, "summary": "Training Large Language Models(LLMs) is one of the most compute-intensive\ntasks in high-performance computing. Predicting end-to-end training time for\nmulti-billion parameter models distributed across hundreds of GPUs remains\nchallenging due to complex interactions between transformer components,\nparallelism strategies(data, model, pipeline, tensor), and multi-tier\ncommunication. Learned models require costly sampling, while analytical models\noften struggle with real-world network and hardware complexities. We address\nthis by decomposing LLMs into core computational primitives and modeling them\nwith: (1) operator-level decomposition for fine-grained analysis; (2)\nlightweight sampling based hardware-aware prediction models for key operations;\n(3) an end-to-end prediction system integrating these components across complex\nparallelization strategies. Crucially, our methodology has been validated on\ntwo large-scale HPC systems. Our framework achieves low average prediction\nerrors-4.98\\% on Perlmutter(A100) and 9.38\\% on Vista(GH200)-for models up to\n20B parameters across 128 GPUs. Importantly, it runs entirely on CPUs, enabling\nrapid iteration over hardware configurations and training strategies without\ncostly on-cluster experimentation."}
{"id": "2509.22838", "pdf": "https://arxiv.org/pdf/2509.22838", "abs": "https://arxiv.org/abs/2509.22838", "authors": ["Elliot Q C Garcia", "Nicéias Silva Vilela", "Kátia Pires Nascimento do Sacramento", "Tiago A. E. Ferreira"], "title": "Text-Independent Speaker Identification Using Audio Looping With Margin Based Loss Functions", "categories": ["cs.SD", "cs.LG", "eess.AS"], "comment": "18 pages, 6 figures", "summary": "Speaker identification has become a crucial component in various\napplications, including security systems, virtual assistants, and personalized\nuser experiences. In this paper, we investigate the effectiveness of CosFace\nLoss and ArcFace Loss for text-independent speaker identification using a\nConvolutional Neural Network architecture based on the VGG16 model, modified to\naccommodate mel spectrogram inputs of variable sizes generated from the\nVoxceleb1 dataset. Our approach involves implementing both loss functions to\nanalyze their effects on model accuracy and robustness, where the Softmax loss\nfunction was employed as a comparative baseline. Additionally, we examine how\nthe sizes of mel spectrograms and their varying time lengths influence model\nperformance. The experimental results demonstrate superior identification\naccuracy compared to traditional Softmax loss methods. Furthermore, we discuss\nthe implications of these findings for future research."}
{"id": "2509.22839", "pdf": "https://arxiv.org/pdf/2509.22839", "abs": "https://arxiv.org/abs/2509.22839", "authors": ["Ibrahim Delibasoglu", "Fredrik Heintz"], "title": "Learning Temporal Saliency for Time Series Forecasting with Cross-Scale Attention", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Explainability in time series forecasting is essential for improving model\ntransparency and supporting informed decision-making. In this work, we present\nCrossScaleNet, an innovative architecture that combines a patch-based\ncross-attention mechanism with multi-scale processing to achieve both high\nperformance and enhanced temporal explainability. By embedding attention\nmechanisms into the training process, our model provides intrinsic\nexplainability for temporal saliency, making its decision-making process more\ntransparent. Traditional post-hoc methods for temporal saliency detection are\ncomputationally expensive, particularly when compared to feature importance\ndetection. While ablation techniques may suffice for datasets with fewer\nfeatures, identifying temporal saliency poses greater challenges due to its\ncomplexity. We validate CrossScaleNet on synthetic datasets with known saliency\nground truth and on established public benchmarks, demonstrating the robustness\nof our method in identifying temporal saliency. Experiments on real-world\ndatasets for forecasting task show that our approach consistently outperforms\nmost transformer-based models, offering better explainability without\nsacrificing predictive accuracy. Our evaluations demonstrate superior\nperformance in both temporal saliency detection and forecasting accuracy.\nMoreover, we highlight that existing models claiming explainability often fail\nto maintain strong performance on standard benchmarks. CrossScaleNet addresses\nthis gap, offering a balanced approach that captures temporal saliency\neffectively while delivering state-of-the-art forecasting performance across\ndatasets of varying complexity."}
{"id": "2509.22845", "pdf": "https://arxiv.org/pdf/2509.22845", "abs": "https://arxiv.org/abs/2509.22845", "authors": ["Kai Hua", "Zhiyuan Feng", "Chongyang Tao", "Rui Yan", "Lu Zhang"], "title": "Learning to Detect Relevant Contexts and Knowledge for Response Selection in Retrieval-based Dialogue Systems", "categories": ["cs.CL", "cs.IR", "cs.LG", "H.3.3; I.2.7; I.2.6"], "comment": "10 pages, 4 figures, accepted by CIKM 2020", "summary": "Recently, knowledge-grounded conversations in the open domain gain great\nattention from researchers. Existing works on retrieval-based dialogue systems\nhave paid tremendous efforts to utilize neural networks to build a matching\nmodel, where all of the context and knowledge contents are used to match the\nresponse candidate with various representation methods. Actually, different\nparts of the context and knowledge are differentially important for recognizing\nthe proper response candidate, as many utterances are useless due to the topic\nshift. Those excessive useless information in the context and knowledge can\ninfluence the matching process and leads to inferior performance. To address\nthis problem, we propose a multi-turn \\textbf{R}esponse \\textbf{S}election\n\\textbf{M}odel that can \\textbf{D}etect the relevant parts of the\n\\textbf{C}ontext and \\textbf{K}nowledge collection (\\textbf{RSM-DCK}). Our\nmodel first uses the recent context as a query to pre-select relevant parts of\nthe context and knowledge collection at the word-level and utterance-level\nsemantics. Further, the response candidate interacts with the selected context\nand knowledge collection respectively. In the end, The fused representation of\nthe context and response candidate is utilized to post-select the relevant\nparts of the knowledge collection more confidently for matching. We test our\nproposed model on two benchmark datasets. Evaluation results indicate that our\nmodel achieves better performance than the existing methods, and can\neffectively detect the relevant context and knowledge for response selection."}
{"id": "2509.22849", "pdf": "https://arxiv.org/pdf/2509.22849", "abs": "https://arxiv.org/abs/2509.22849", "authors": ["Vincent Froese", "Moritz Grillo", "Christoph Hertrich", "Moritz Stargalla"], "title": "Parameterized Hardness of Zonotope Containment and Neural Network Verification", "categories": ["cs.CC", "cs.DM", "cs.LG", "cs.NE"], "comment": "19 pages, 5 figures", "summary": "Neural networks with ReLU activations are a widely used model in machine\nlearning. It is thus important to have a profound understanding of the\nproperties of the functions computed by such networks. Recently, there has been\nincreasing interest in the (parameterized) computational complexity of\ndetermining these properties. In this work, we close several gaps and resolve\nan open problem posted by Froese et al. [COLT '25] regarding the parameterized\ncomplexity of various problems related to network verification. In particular,\nwe prove that deciding positivity (and thus surjectivity) of a function\n$f\\colon\\mathbb{R}^d\\to\\mathbb{R}$ computed by a 2-layer ReLU network is\nW[1]-hard when parameterized by $d$. This result also implies that zonotope\n(non-)containment is W[1]-hard with respect to $d$, a problem that is of\nindependent interest in computational geometry, control theory, and robotics.\nMoreover, we show that approximating the maximum within any multiplicative\nfactor in 2-layer ReLU networks, computing the $L_p$-Lipschitz constant for\n$p\\in(0,\\infty]$ in 2-layer networks, and approximating the $L_p$-Lipschitz\nconstant in 3-layer networks are NP-hard and W[1]-hard with respect to $d$.\nNotably, our hardness results are the strongest known so far and imply that the\nnaive enumeration-based methods for solving these fundamental problems are all\nessentially optimal under the Exponential Time Hypothesis."}
{"id": "2509.22853", "pdf": "https://arxiv.org/pdf/2509.22853", "abs": "https://arxiv.org/abs/2509.22853", "authors": ["Irsyad Adam", "Zekai Chen", "David Laub", "Shaun Porwal", "Arda Pekis", "Kevin Brown"], "title": "Patient-specific Biomolecular Instruction Tuning", "categories": ["q-bio.QM", "cs.AI", "cs.CL", "cs.LG", "92C40, 68T07, 62P10", "I.2.7; I.5.1; J.3"], "comment": null, "summary": "Proteomics data is essential to pathogenic understanding of a disease\nphenotype. In cancer, analysis of molecular signatures enables precision\nmedicine through the identification of biological processes that drive\nindividualized tumor progression, therapeutic resistance, and clinical\nheterogeneity. Recent advances in multimodal large language models (LLMs) have\nshown remarkable capacity to integrate and reason across heterogeneous data\nmodalities. However, performing multi-modal language modeling for molecular\nunderstanding of patient-specific proteomics remains a significant challenge\ndue to two barriers: (1) the lack of instruction-tuning datasets that enable\nclinical interpretation from proteomics data, and (2) the absence of language\nmodeling architectures designed to capture the rich heterogeneity of molecular\ndata. In this work, we introduce CPTAC-PROTSTRUCT, the first instruction tuning\ndataset for molecular understanding of oncology, comprising over 400k\nopen-ended examples derived from individualized proteomic profiles curated from\nthe largest national proteomics cancer study (CPTAC). Additionally, we propose\nKRONOS (Knowledge Representation of patient Omics Networks in Oncology via\nStructured tuning), a novel graph-LLM framework that leverages molecular\ninteraction topology with proteomics to learn patient-specific graph\nrepresentations for enhanced clinical reasoning. We show that KRONOS achieves\ncompetitive performance across benchmark clinical tasks, including molecular\nclassification, temporal trajectory modeling, and tumor stage prediction from\nproteomics data. Ultimately, this approach empowers LLMs to understand\npatient-level pathogenesis, advancing precision medicine through more accurate\ndiagnosis, prognosis, and treatment stratification."}
{"id": "2509.22860", "pdf": "https://arxiv.org/pdf/2509.22860", "abs": "https://arxiv.org/abs/2509.22860", "authors": ["Artavazd Maranjyan", "Peter Richtárik"], "title": "Ringleader ASGD: The First Asynchronous SGD with Optimal Time Complexity under Data Heterogeneity", "categories": ["math.OC", "cs.DC", "cs.LG", "stat.ML"], "comment": null, "summary": "Asynchronous stochastic gradient methods are central to scalable distributed\noptimization, particularly when devices differ in computational capabilities.\nSuch settings arise naturally in federated learning, where training takes place\non smartphones and other heterogeneous edge devices. In addition to varying\ncomputation speeds, these devices often hold data from different distributions.\nHowever, existing asynchronous SGD methods struggle in such heterogeneous\nsettings and face two key limitations. First, many rely on unrealistic\nassumptions of similarity across workers' data distributions. Second, methods\nthat relax this assumption still fail to achieve theoretically optimal\nperformance under heterogeneous computation times. We introduce Ringleader\nASGD, the first asynchronous SGD algorithm that attains the theoretical lower\nbounds for parallel first-order stochastic methods in the smooth nonconvex\nregime, thereby achieving optimal time complexity under data heterogeneity and\nwithout restrictive similarity assumptions. Our analysis further establishes\nthat Ringleader ASGD remains optimal under arbitrary and even time-varying\nworker computation speeds, closing a fundamental gap in the theory of\nasynchronous optimization."}
{"id": "2509.22876", "pdf": "https://arxiv.org/pdf/2509.22876", "abs": "https://arxiv.org/abs/2509.22876", "authors": ["Gabriela Pinto", "Palash Goyal", "Yiwen Song", "Souradip Chakraborty", "Zifeng Wang", "Tomas Pfister", "Hamid Palangi"], "title": "HEART: Emotionally-driven test-time scaling of Language Models", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Test-time scaling has shown considerable success in improving the performance\nof language models on complex reasoning tasks without requiring fine-tuning.\nHowever, current strategies such as self-reflection primarily focus on logical\nor structural refinement. They do not leverage the guiding potential of\naffective feedback. Inspired by psychological research showing that emotions\ncan modulate cognitive performance, we introduce HEART--a novel framework that\nuses emotionally-driven prompts for iterative self-correction. HEART provides\nfeedback on a model's incorrect response using a curated set of concise,\nemotionally charged phrases based on the six universal emotions categorized by\nDr. Paul Ekman. By systematically varying the emotional tone of the feedback\nacross iterations, our method guides the model to escape flawed reasoning paths\nand explore more promising alternatives. We evaluate our framework on\nchallenging reasoning benchmarks including OlympiadBench, Humanity's Last Exam,\nand SimpleQA. Our results reveal a significant new phenomenon: when guided by\nan oracle verifier, this affective iteration protocol unlocks significantly\ndeeper reasoning, leading to consistent and substantial increases in accuracy\nover state-of-the-art baselines with the same verifier. However, we also\nidentify a critical bottleneck for practical deployment. In a verifier-free\nsetting, it struggles to harness these gains consistently, highlighting as a\nkey challenge for future work. Our findings suggest that the next frontier in\nmachine reasoning may lie not just in refining logic, but also in understanding\nand leveraging the `HEART' of the models."}
{"id": "2509.22879", "pdf": "https://arxiv.org/pdf/2509.22879", "abs": "https://arxiv.org/abs/2509.22879", "authors": ["Srećko Đurašinović", "Jean-Bernard Lasserre", "Victor Magron"], "title": "Mixtures Closest to a Given Measure: A Semidefinite Programming Approach", "categories": ["math.OC", "cs.LG"], "comment": "22 pages, 2 algorithms, 1 table, 3 figures", "summary": "Mixture models, such as Gaussian mixture models, are widely used in machine\nlearning to represent complex data distributions. A key challenge, especially\nin high-dimensional settings, is to determine the mixture order and estimate\nthe mixture parameters. We study the problem of approximating a target measure,\navailable only through finitely many of its moments, by a mixture of\ndistributions from a parametric family (e.g., Gaussian, exponential, Poisson),\nwith approximation quality measured by the 2-Wasserstein or the total variation\ndistance. Unlike many existing approaches, the parameter set is not assumed to\nbe finite; it is modeled as a compact basic semi-algebraic set. We introduce a\nhierarchy of semidefinite relaxations with asymptotic convergence to the\ndesired optimal value. In addition, when a certain rank condition is satisfied,\nthe convergence is even finite and recovery of an optimal mixing measure is\nobtained. We also present an application to clustering, where our framework\nserves either as a stand-alone method or as a preprocessing step that yields\nboth the number of clusters and strong initial parameter estimates, thereby\naccelerating convergence of standard (local) clustering algorithms."}
{"id": "2509.22889", "pdf": "https://arxiv.org/pdf/2509.22889", "abs": "https://arxiv.org/abs/2509.22889", "authors": ["Federico Chinello", "Giacomo Boracchi"], "title": "Convolutional Set Transformer", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "We introduce the Convolutional Set Transformer (CST), a novel neural\narchitecture designed to process image sets of arbitrary cardinality that are\nvisually heterogeneous yet share high-level semantics - such as a common\ncategory, scene, or concept. Existing set-input networks, e.g., Deep Sets and\nSet Transformer, are limited to vector inputs and cannot directly handle 3D\nimage tensors. As a result, they must be cascaded with a feature extractor,\ntypically a CNN, which encodes images into embeddings before the set-input\nnetwork can model inter-image relationships. In contrast, CST operates directly\non 3D image tensors, performing feature extraction and contextual modeling\nsimultaneously, thereby enabling synergies between the two processes. This\ndesign yields superior performance in tasks such as Set Classification and Set\nAnomaly Detection and further provides native compatibility with CNN\nexplainability methods such as Grad-CAM, unlike competing approaches that\nremain opaque. Finally, we show that CSTs can be pre-trained on large-scale\ndatasets and subsequently adapted to new domains and tasks through standard\nTransfer Learning schemes. To support further research, we release CST-15, a\nCST backbone pre-trained on ImageNet\n(https://github.com/chinefed/convolutional-set-transformer)."}
{"id": "2509.22908", "pdf": "https://arxiv.org/pdf/2509.22908", "abs": "https://arxiv.org/abs/2509.22908", "authors": ["Sergiu Bursuc", "Theodore Ehrenborg", "Shaowei Lin", "Lacramioara Astefanoaei", "Ionel Emilian Chiosa", "Jure Kukovec", "Alok Singh", "Oliver Butterley", "Adem Bizid", "Quinn Dougherty", "Miranda Zhao", "Max Tan", "Max Tegmark"], "title": "A benchmark for vericoding: formally verified program synthesis", "categories": ["cs.SE", "cs.LG", "cs.PL"], "comment": "25 pages, 1 figure; data available at\n  https://github.com/Beneficial-AI-Foundation/vericoding-benchmark", "summary": "We present and test the largest benchmark for vericoding, LLM-generation of\nformally verified code from formal specifications - in contrast to vibe coding,\nwhich generates potentially buggy code from a natural language description. Our\nbenchmark contains 12,504 formal specifications, with 3,029 in Dafny, 2,334 in\nVerus/Rust and 7,141 in Lean. Of these, 6,174 are new unseen problems. We find\nvericoding success rates of 27% in Lean, 44% in Verus/Rust and 82% in Dafny\nusing off-the-shelf LLMs. Adding natural-language descriptions does not\nsignificantly improve performance. We also find that LLM progress has improved\nprogress on pure Dafny verification from 68% to 96% over the past year. The\nbenchmark and vericoding results are shared at\nhttps://github.com/Beneficial-AI-Foundation/vericoding-benchmark"}
{"id": "2509.22909", "pdf": "https://arxiv.org/pdf/2509.22909", "abs": "https://arxiv.org/abs/2509.22909", "authors": ["Abdulkarim Atrash", "Omar Moured", "Yufan Chen", "Jiaming Zhang", "Seyda Ertekin", "Omur Ugur"], "title": "TY-RIST: Tactical YOLO Tricks for Real-time Infrared Small Target Detection", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Acctepted at the ICCV 2025 MIRA workshop, 11 pages, 7 figures", "summary": "Infrared small target detection (IRSTD) is critical for defense and\nsurveillance but remains challenging due to (1) target loss from minimal\nfeatures, (2) false alarms in cluttered environments, (3) missed detections\nfrom low saliency, and (4) high computational costs. To address these issues,\nwe propose TY-RIST, an optimized YOLOv12n architecture that integrates (1) a\nstride-aware backbone with fine-grained receptive fields, (2) a high-resolution\ndetection head, (3) cascaded coordinate attention blocks, and (4) a branch\npruning strategy that reduces computational cost by about 25.5% while\nmarginally improving accuracy and enabling real-time inference. We also\nincorporate the Normalized Gaussian Wasserstein Distance (NWD) to enhance\nregression stability. Extensive experiments on four benchmarks and across 20\ndifferent models demonstrate state-of-the-art performance, improving mAP at 0.5\nIoU by +7.9%, Precision by +3%, and Recall by +10.2%, while achieving up to 123\nFPS on a single GPU. Cross-dataset validation on a fifth dataset further\nconfirms strong generalization capability. Additional results and resources are\navailable at https://www.github.com/moured/TY-RIST"}
{"id": "2509.22919", "pdf": "https://arxiv.org/pdf/2509.22919", "abs": "https://arxiv.org/abs/2509.22919", "authors": ["Jake S. Rhodes", "Adam G. Rustad", "Sofia Pelagalli Maia", "Evan Thacker", "Hyunmi Choi", "Jose Gutierrez", "Tatjana Rundek", "Ben Shaw"], "title": "Label-Guided Imputation via Forest-Based Proximities for Improved Time Series Classification", "categories": ["stat.ML", "cs.LG"], "comment": "6 pages, one figure. Accepted at ICMLA 2025", "summary": "Missing data is a common problem in time series data. Most methods for\nimputation ignore label information pertaining to the time series even if that\ninformation exists. In this paper, we provide a framework for missing data\nimputation in the context of time series classification, where each time series\nis associated with a categorical label. We define a means of imputing missing\nvalues conditional upon labels, the method being guided by powerful, existing\nsupervised models designed for high accuracy in this task. From each model, we\nextract a tree-based proximity measure from which imputation can be applied. We\nshow that imputation using this method generally provides richer information\nleading to higher classification accuracies, despite the imputed values\ndiffering from the true values."}
{"id": "2509.22925", "pdf": "https://arxiv.org/pdf/2509.22925", "abs": "https://arxiv.org/abs/2509.22925", "authors": ["Yuanzhi Zhu", "Xi Wang", "Stéphane Lathuilière", "Vicky Kalogeiton"], "title": "Soft-Di[M]O: Improving One-Step Discrete Image Generation with Soft Embeddings", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "One-step generators distilled from Masked Diffusion Models (MDMs) compress\nmultiple sampling steps into a single forward pass, enabling efficient text and\nimage synthesis. However, they suffer two key limitations: they inherit\nmodeling bias from the teacher, and their discrete token outputs block gradient\nflow, preventing post-distillation refinements such as adversarial training,\nreward-based fine-tuning, and Test-Time Embedding Optimization (TTEO). In this\nwork, we introduce soft embeddings, a simple relaxation that replaces discrete\ntokens with the expected embeddings under the generator's output distribution.\nSoft embeddings preserve representation fidelity for one-step discrete\ngenerator while providing a fully differentiable continuous surrogate that is\ncompatible with teacher backbones and tokenizer decoders. Integrating soft\nembeddings into the Di[M]O distillation framework (denoted Soft-Di[M]O) makes\none-step generators end-to-end trainable and enables straightforward\napplication of GAN-based refinement, differentiable reward fine-tuning, and\nTTEO. Empirically, across multiple MDM teachers (e.g., MaskBit, MaskGen),\nSoft-Di[M]O achieves state-of-the-art one-step results: improved class-to-image\nperformance, a one-step FID of 1.56 on ImageNet-256 with GAN-based refinement,\nalong with higher GenEval and HPS scores on text-to-image with reward\nfine-tuning, and further gains from TTEO."}
{"id": "2509.22928", "pdf": "https://arxiv.org/pdf/2509.22928", "abs": "https://arxiv.org/abs/2509.22928", "authors": ["Jake S. Rhodes", "Scott D. Brown", "J. Riley Wilkinson"], "title": "Localized Uncertainty Quantification in Random Forests via Proximities", "categories": ["stat.ML", "cs.LG"], "comment": "6 pages, 2 tables, 2 figures. Accepted at ICMLA 2025", "summary": "In machine learning, uncertainty quantification helps assess the reliability\nof model predictions, which is important in high-stakes scenarios. Traditional\napproaches often emphasize predictive accuracy, but there is a growing focus on\nincorporating uncertainty measures. This paper addresses localized uncertainty\nquantification in random forests. While current methods often rely on quantile\nregression or Monte Carlo techniques, we propose a new approach using naturally\noccurring test sets and similarity measures (proximities) typically viewed as\nbyproducts of random forests. Specifically, we form localized distributions of\nOOB errors around nearby points, defined using the proximities, to create\nprediction intervals for regression and trust scores for classification. By\nvarying the number of nearby points, our intervals can be adjusted to achieve\nthe desired coverage while retaining the flexibility that reflects the\ncertainty of individual predictions. For classification, excluding points\nidentified as unclassifiable by our method generally enhances the accuracy of\nthe model and provides higher accuracy-rejection AUC scores than competing\nmethods."}
{"id": "2509.22947", "pdf": "https://arxiv.org/pdf/2509.22947", "abs": "https://arxiv.org/abs/2509.22947", "authors": ["Mohammed Sabry", "Anya Belz"], "title": "What Matters More For In-Context Learning under Matched Compute Budgets: Pretraining on Natural Text or Incorporating Targeted Synthetic Examples?", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Does explicitly exercising the induction circuit during pretraining improve\nin-context learning (ICL), or is natural text sufficient when compute is held\nconstant (iso-FLOPs)? To test whether targeted synthetic data can accelerate\ninduction-head emergence and enhance ICL, we introduce Bi-Induct, a lightweight\ncurriculum that injects forward-copy (Induction), backward-copy (Anti), or a\nbalanced mix into the pretraining stream. We train models from 0.13B to 1B\nparameters under iso-FLOPs, evaluating (i) few-shot ICL benchmarks, (ii)\nhead-level telemetry, and (iii) held-out language modeling perplexity. Our\nfindings challenge the assumption that early induction circuit activation\ndirectly improves ICL. While Bi-Induct accelerates induction-head emergence at\nsmall scales, this does not consistently yield stronger generalization. On\nstandard LM benchmarks, Bi-Induct matches natural-only training; on\nfunction-style ICL probes, the 1B natural-only performs best. Stress tests\n(e.g., label permutation, HITS@1 vs. HITS@3, 1 vs. 10 shots) preserve these\ntrends. Telemetry shows larger natural-only models develop broader, earlier\ninduction heads without explicit induction patterns. Anti-induction data fails\nto elicit meaningful activation. Perplexity penalties from synthetic data\nshrink with scale, suggesting larger models can absorb non-natural patterns\nwith minimal cost. Crucially, ablating the top 2% of induction heads degrades\nICL more than random ablations, especially for natural-only models, indicating\nmore centralized, load-bearing circuits. Bi-Induct variants exhibit more\nredundant induction activity, implying different circuit utilization. Overall,\ninducing activation is not sufficient: ICL gains depend on these circuits\nbecoming functionally necessary. These results underscore mechanism-aware\npretraining diagnostics and data mixtures that foster load-bearing, not merely\npresent, structure."}
{"id": "2509.22970", "pdf": "https://arxiv.org/pdf/2509.22970", "abs": "https://arxiv.org/abs/2509.22970", "authors": ["Siheng Zhao", "Jiageng Mao", "Wei Chow", "Zeyu Shangguan", "Tianheng Shi", "Rong Xue", "Yuxi Zheng", "Yijia Weng", "Yang You", "Daniel Seita", "Leonidas Guibas", "Sergey Zakharov", "Vitor Guizilini", "Yue Wang"], "title": "Robot Learning from Any Images", "categories": ["cs.RO", "cs.CV", "cs.LG"], "comment": "CoRL 2025 camera ready", "summary": "We introduce RoLA, a framework that transforms any in-the-wild image into an\ninteractive, physics-enabled robotic environment. Unlike previous methods, RoLA\noperates directly on a single image without requiring additional hardware or\ndigital assets. Our framework democratizes robotic data generation by producing\nmassive visuomotor robotic demonstrations within minutes from a wide range of\nimage sources, including camera captures, robotic datasets, and Internet\nimages. At its core, our approach combines a novel method for single-view\nphysical scene recovery with an efficient visual blending strategy for\nphotorealistic data collection. We demonstrate RoLA's versatility across\napplications like scalable robotic data generation and augmentation, robot\nlearning from Internet images, and single-image real-to-sim-to-real systems for\nmanipulators and humanoids. Video results are available at\nhttps://sihengz02.github.io/RoLA ."}
{"id": "2509.22991", "pdf": "https://arxiv.org/pdf/2509.22991", "abs": "https://arxiv.org/abs/2509.22991", "authors": ["Jasin Cekinmez", "Omid Ghahroodi", "Saad Fowad Chandle", "Dhiman Gupta", "Ehsaneddin Asgari"], "title": "ADAM: A Diverse Archive of Mankind for Evaluating and Enhancing LLMs in Biographical Reasoning", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.IR", "cs.LG"], "comment": null, "summary": "We introduce ADAM (A Diverse Archive of Mankind), a framework for evaluating\nand improving multimodal large language models (MLLMs) in biographical\nreasoning. To the best of our knowledge, this is the first work to\nsystematically examine LLM capabilities in biography, a critical yet\nunderexplored dimension of factual knowledge. At its core, AdamDB is a\nmultilingual and multimodal dataset covering over 4 million individuals across\ngeography, time, and profession, while AdamBench provides cognitively\nstructured evaluations based on Bloom's taxonomy, spanning six reasoning levels\nin both English and native languages. To address hallucinations, particularly\nfor lesser-known individuals, we propose AdamRAG, a retrieval-augmented\ngeneration system tailored to biographical contexts. Experiments show that\nAdamRAG substantially improves open-source models and modestly benefits\nclosed-source ones, with the largest gains on lower-order reasoning. Popularity\nstrongly mediates accuracy, and multimodal input via face images offers\nsmaller, less consistent improvements than retrieval. ADAM establishes the\nfirst benchmark and framework for cognitively, culturally, and multimodally\ngrounded biographical evaluation, advancing the development of multilingual,\naccurate, and hallucination-resistant MLLMs."}
{"id": "2509.23002", "pdf": "https://arxiv.org/pdf/2509.23002", "abs": "https://arxiv.org/abs/2509.23002", "authors": ["Lingyou Pang", "Lei Huang", "Jianyu Lin", "Tianyu Wang", "Akira Horiguchi", "Alexander Aue", "Carey E. Priebe"], "title": "Unsupervised Conformal Inference: Bootstrapping and Alignment to Control LLM Uncertainty", "categories": ["stat.ML", "cs.LG"], "comment": "26 pages including appendix; 3 figures and 5 tables. Under review for\n  ICLR 2026", "summary": "Deploying black-box LLMs requires managing uncertainty in the absence of\ntoken-level probability or true labels. We propose introducing an unsupervised\nconformal inference framework for generation, which integrates: generative\nmodels, incorporating: (i) an LLM-compatible atypical score derived from\nresponse-embedding Gram matrix, (ii) UCP combined with a bootstrapping variant\n(BB-UCP) that aggregates residuals to refine quantile precision while\nmaintaining distribution-free, finite-sample coverage, and (iii) conformal\nalignment, which calibrates a single strictness parameter $\\tau$ so a user\npredicate (e.g., factuality lift) holds on unseen batches with probability $\\ge\n1-\\alpha$. Across different benchmark datasets, our gates achieve\nclose-to-nominal coverage and provide tighter, more stable thresholds than\nsplit UCP, while consistently reducing the severity of hallucination,\noutperforming lightweight per-response detectors with similar computational\ndemands. The result is a label-free, API-compatible gate for test-time\nfiltering that turns geometric signals into calibrated, goal-aligned decisions."}
{"id": "2509.23051", "pdf": "https://arxiv.org/pdf/2509.23051", "abs": "https://arxiv.org/abs/2509.23051", "authors": ["Pirzada Suhail", "Aditya Anand", "Amit Sethi"], "title": "Activation Matching for Explanation Generation", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "In this paper we introduce an activation-matching--based approach to generate\nminimal, faithful explanations for the decision-making of a pretrained\nclassifier on any given image. Given an input image \\(x\\) and a frozen model\n\\(f\\), we train a lightweight autoencoder to output a binary mask \\(m\\) such\nthat the explanation \\(e = m \\odot x\\) preserves both the model's prediction\nand the intermediate activations of \\(x\\). Our objective combines: (i)\nmulti-layer activation matching with KL divergence to align distributions and\ncross-entropy to retain the top-1 label for both the image and the explanation;\n(ii) mask priors -- L1 area for minimality, a binarization penalty for crisp\n0/1 masks, and total variation for compactness; and (iii) abductive constraints\nfor faithfulness and necessity. Together, these objectives yield small,\nhuman-interpretable masks that retain classifier behavior while discarding\nirrelevant input regions, providing practical and faithful minimalist\nexplanations for the decision making of the underlying model."}
{"id": "2509.23056", "pdf": "https://arxiv.org/pdf/2509.23056", "abs": "https://arxiv.org/abs/2509.23056", "authors": ["Ben Liang", "Yuan Liu", "Bingwen Qiu", "Yihong Wang", "Xiubao Sui", "Qian Chen"], "title": "FMC-DETR: Frequency-Decoupled Multi-Domain Coordination for Aerial-View Object Detection", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Aerial-view object detection is a critical technology for real-world\napplications such as natural resource monitoring, traffic management, and\nUAV-based search and rescue. Detecting tiny objects in high-resolution aerial\nimagery presents a long-standing challenge due to their limited visual cues and\nthe difficulty of modeling global context in complex scenes. Existing methods\nare often hampered by delayed contextual fusion and inadequate non-linear\nmodeling, failing to effectively use global information to refine shallow\nfeatures and thus encountering a performance bottleneck. To address these\nchallenges, we propose FMC-DETR, a novel framework with frequency-decoupled\nfusion for aerial-view object detection. First, we introduce the Wavelet\nKolmogorov-Arnold Transformer (WeKat) backbone, which applies cascaded wavelet\ntransforms to enhance global low-frequency context perception in shallow\nfeatures while preserving fine-grained details, and employs Kolmogorov-Arnold\nnetworks to achieve adaptive non-linear modeling of multi-scale dependencies.\nNext, a lightweight Cross-stage Partial Fusion (CPF) module reduces redundancy\nand improves multi-scale feature interaction. Finally, we introduce the\nMulti-Domain Feature Coordination (MDFC) module, which unifies spatial,\nfrequency, and structural priors to to balance detail preservation and global\nenhancement. Extensive experiments on benchmark aerial-view datasets\ndemonstrate that FMC-DETR achieves state-of-the-art performance with fewer\nparameters. On the challenging VisDrone dataset, our model achieves\nimprovements of 6.5% AP and 8.2% AP50 over the baseline, highlighting its\neffectiveness in tiny object detection. The code can be accessed at\nhttps://github.com/bloomingvision/FMC-DETR."}
{"id": "2509.23058", "pdf": "https://arxiv.org/pdf/2509.23058", "abs": "https://arxiv.org/abs/2509.23058", "authors": ["Yikai Wang", "Xiaocheng Li", "Guanting Chen"], "title": "Risk Profiling and Modulation for LLMs", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) are increasingly used for decision-making tasks\nunder uncertainty; however, their risk profiles and how they are influenced by\nprompting and alignment methods remain underexplored. Existing studies have\nprimarily examined personality prompting or multi-agent interactions, leaving\nopen the question of how post-training influences the risk behavior of LLMs. In\nthis work, we propose a new pipeline for eliciting, steering, and modulating\nLLMs' risk profiles, drawing on tools from behavioral economics and finance.\nUsing utility-theoretic models, we compare pre-trained, instruction-tuned, and\nRLHF-aligned LLMs, and find that while instruction-tuned models exhibit\nbehaviors consistent with some standard utility formulations, pre-trained and\nRLHF-aligned models deviate more from any utility models fitted. We further\nevaluate modulation strategies, including prompt engineering, in-context\nlearning, and post-training, and show that post-training provides the most\nstable and effective modulation of risk preference. Our findings provide\ninsights into the risk profiles of different classes and stages of LLMs and\ndemonstrate how post-training modulates these profiles, laying the groundwork\nfor future research on behavioral alignment and risk-aware LLM design."}
{"id": "2509.23068", "pdf": "https://arxiv.org/pdf/2509.23068", "abs": "https://arxiv.org/abs/2509.23068", "authors": ["Yi-Ting Hung", "Li-Hsiang Lin", "Vince D. Calhoun"], "title": "Sparse Deep Additive Model with Interactions: Enhancing Interpretability and Predictability", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Recent advances in deep learning highlight the need for personalized models\nthat can learn from small or moderate samples, handle high dimensional\nfeatures, and remain interpretable. To address this challenge, we propose the\nSparse Deep Additive Model with Interactions (SDAMI), a framework that combines\nsparsity driven feature selection with deep subnetworks for flexible function\napproximation. Unlike conventional deep learning models, which often function\nas black boxes, SDAMI explicitly disentangles main effects and interaction\neffects to enhance interpretability. At the same time, its deep additive\nstructure achieves higher predictive accuracy than classical additive models.\nCentral to SDAMI is the concept of an Effect Footprint, which assumes that\nhigher order interactions project marginally onto main effects. Guided by this\nprinciple, SDAMI adopts a two stage strategy: first, identify strong main\neffects that implicitly carry information about important interactions. second,\nexploit this information through structured regularization such as group lasso\nto distinguish genuine main effects from interaction effects. For each selected\nmain effect, SDAMI constructs a dedicated subnetwork, enabling nonlinear\nfunction approximation while preserving interpretability and providing a\nstructured foundation for modeling interactions. Extensive simulations with\ncomparisons confirm SDAMI$'$s ability to recover effect structures across\ndiverse scenarios, while applications in reliability analysis, neuroscience,\nand medical diagnostics further demonstrate its versatility in addressing\nreal-world high-dimensional modeling challenges."}
{"id": "2509.23091", "pdf": "https://arxiv.org/pdf/2509.23091", "abs": "https://arxiv.org/abs/2509.23091", "authors": ["Xiangchen Meng", "Yangdi Lyu"], "title": "FedBit: Accelerating Privacy-Preserving Federated Learning via Bit-Interleaved Packing and Cross-Layer Co-Design", "categories": ["cs.CR", "cs.AR", "cs.LG"], "comment": null, "summary": "Federated learning (FL) with fully homomorphic encryption (FHE) effectively\nsafeguards data privacy during model aggregation by encrypting local model\nupdates before transmission, mitigating threats from untrusted servers or\neavesdroppers in transmission. However, the computational burden and ciphertext\nexpansion associated with homomorphic encryption can significantly increase\nresource and communication overhead. To address these challenges, we propose\nFedBit, a hardware/software co-designed framework optimized for the\nBrakerski-Fan-Vercauteren (BFV) scheme. FedBit employs bit-interleaved data\npacking to embed multiple model parameters into a single ciphertext\ncoefficient, thereby minimizing ciphertext expansion and maximizing\ncomputational parallelism. Additionally, we integrate a dedicated FPGA\naccelerator to handle cryptographic operations and an optimized dataflow to\nreduce the memory overhead. Experimental results demonstrate that FedBit\nachieves a speedup of two orders of magnitude in encryption and lowers average\ncommunication overhead by 60.7%, while maintaining high accuracy."}
{"id": "2509.23099", "pdf": "https://arxiv.org/pdf/2509.23099", "abs": "https://arxiv.org/abs/2509.23099", "authors": ["Wen Tao", "Jing Tang", "Alvin Chan", "Bryan Hooi", "Baolong Bi", "Nanyun Peng", "Yuansheng Liu", "Yiwei Wang"], "title": "How to Make Large Language Models Generate 100% Valid Molecules?", "categories": ["cs.CL", "cs.LG"], "comment": "EMNLP 2025 Main", "summary": "Molecule generation is key to drug discovery and materials science, enabling\nthe design of novel compounds with specific properties. Large language models\n(LLMs) can learn to perform a wide range of tasks from just a few examples.\nHowever, generating valid molecules using representations like SMILES is\nchallenging for LLMs in few-shot settings. In this work, we explore how LLMs\ncan generate 100% valid molecules. We evaluate whether LLMs can use SELFIES, a\nrepresentation where every string corresponds to a valid molecule, for valid\nmolecule generation but find that LLMs perform worse with SELFIES than with\nSMILES. We then examine LLMs' ability to correct invalid SMILES and find their\ncapacity limited. Finally, we introduce SmiSelf, a cross-chemical language\nframework for invalid SMILES correction. SmiSelf converts invalid SMILES to\nSELFIES using grammatical rules, leveraging SELFIES' mechanisms to correct the\ninvalid SMILES. Experiments show that SmiSelf ensures 100% validity while\npreserving molecular characteristics and maintaining or even enhancing\nperformance on other metrics. SmiSelf helps expand LLMs' practical applications\nin biomedicine and is compatible with all SMILES-based generative models. Code\nis available at https://github.com/wentao228/SmiSelf."}
{"id": "2509.23118", "pdf": "https://arxiv.org/pdf/2509.23118", "abs": "https://arxiv.org/abs/2509.23118", "authors": ["Zeyi Li", "Zhe Tang", "Kyeong Soo Kim", "Sihao Li", "Jeremy S. Smith"], "title": "EKF-Based Fusion of Wi-Fi/LiDAR/IMU for Indoor Localization and Navigation", "categories": ["cs.RO", "cs.LG", "cs.NI"], "comment": "8 pages, 7 figures, 3 tables, and submitted for presentation at a\n  conference", "summary": "Conventional Wi-Fi received signal strength indicator (RSSI) fingerprinting\ncannot meet the growing demand for accurate indoor localization and navigation\ndue to its lower accuracy, while solutions based on light detection and ranging\n(LiDAR) can provide better localization performance but is limited by their\nhigher deployment cost and complexity. To address these issues, we propose a\nnovel indoor localization and navigation framework integrating Wi-Fi RSSI\nfingerprinting, LiDAR-based simultaneous localization and mapping (SLAM), and\ninertial measurement unit (IMU) navigation based on an extended Kalman filter\n(EKF). Specifically, coarse localization by deep neural network (DNN)-based\nWi-Fi RSSI fingerprinting is refined by IMU-based dynamic positioning using a\nGmapping-based SLAM to generate an occupancy grid map and output high-frequency\nattitude estimates, which is followed by EKF prediction-update integrating\nsensor information while effectively suppressing Wi-Fi-induced noise and IMU\ndrift errors. Multi-group real-world experiments conducted on the IR building\nat Xi'an Jiaotong-Liverpool University demonstrates that the proposed\nmulti-sensor fusion framework suppresses the instability caused by individual\napproaches and thereby provides stable accuracy across all path configurations\nwith mean two-dimensional (2D) errors ranging from 0.2449 m to 0.3781 m. In\ncontrast, the mean 2D errors of Wi-Fi RSSI fingerprinting reach up to 1.3404 m\nin areas with severe signal interference, and those of LiDAR/IMU localization\nare between 0.6233 m and 2.8803 m due to cumulative drift."}
{"id": "2509.23125", "pdf": "https://arxiv.org/pdf/2509.23125", "abs": "https://arxiv.org/abs/2509.23125", "authors": ["Yiqing Zhou", "Xule Zhou", "Zecan Cheng", "Chenao Lu", "Junhan Chen", "Jiahong Pan", "Yizhuo Liu", "Sihao Li", "Kyeong Soo Kim"], "title": "Impact of Environmental Factors on LoRa 2.4 GHz Time of Flight Ranging Outdoors", "categories": ["cs.NI", "cs.LG"], "comment": "5 pages, 8 figures, 2 tables, and under review for presentation at a\n  workshop", "summary": "In WSN/IoT, node localization is essential to long-running applications for\naccurate environment monitoring and event detection, often covering a large\narea in the field. Due to the lower time resolution of typical WSN/IoT\nplatforms (e.g., 1 microsecond on ESP32 platforms) and the jitters in\ntimestamping, packet-level localization techniques cannot provide meter-level\nresolution. For high-precision localization as well as world-wide\ninteroperability via 2.4-GHz ISM band, a new variant of LoRa, called LoRa 2.4\nGHz, was proposed by semtech, which provides a radio frequency (RF) time of\nflight (ToF) ranging method for meter-level localization. However, the existing\ndatasets reported in the literature are limited in their coverages and do not\ntake into account varying environmental factors such as temperature and\nhumidity. To address these issues, LoRa 2.4 GHz RF ToF ranging data was\ncollected on a sports field at the XJTLU south campus, where three LoRa nodes\nlogged samples of ranging with a LoRa base station, together with temperature\nand humidity, at reference points arranged as a 3x3 grid covering 400 square\nmeter over three weeks and uploaded all measurement records to the base station\nequipped with an ESP32-based transceiver for machine and user communications.\nThe results of a preliminary investigation based on a simple deep neural\nnetwork (DNN) model demonstrate that the environmental factors, including the\ntemperature and humidity, significantly affect the accuracy of ranging, which\ncalls for advanced methods of compensating for the effects of environmental\nfactors on LoRa RF ToF ranging outdoors."}
{"id": "2509.23127", "pdf": "https://arxiv.org/pdf/2509.23127", "abs": "https://arxiv.org/abs/2509.23127", "authors": ["Haimo Fang", "Kevin Tan", "Giles Hooker"], "title": "Statistical Inference for Gradient Boosting Regression", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.ME", "stat.TH"], "comment": "Accepted to NeurIPS 2025", "summary": "Gradient boosting is widely popular due to its flexibility and predictive\naccuracy. However, statistical inference and uncertainty quantification for\ngradient boosting remain challenging and under-explored. We propose a unified\nframework for statistical inference in gradient boosting regression. Our\nframework integrates dropout or parallel training with a recently proposed\nregularization procedure that allows for a central limit theorem (CLT) for\nboosting. With these enhancements, we surprisingly find that increasing the\ndropout rate and the number of trees grown in parallel at each iteration\nsubstantially enhances signal recovery and overall performance. Our resulting\nalgorithms enjoy similar CLTs, which we use to construct built-in confidence\nintervals, prediction intervals, and rigorous hypothesis tests for assessing\nvariable importance. Numerical experiments demonstrate that our algorithms\nperform well, interpolate between regularized boosting and random forests, and\nconfirm the validity of their built-in statistical inference procedures."}
{"id": "2509.23128", "pdf": "https://arxiv.org/pdf/2509.23128", "abs": "https://arxiv.org/abs/2509.23128", "authors": ["Xinqiao Xie", "Jonathan Yu-Meng Li"], "title": "Conditional Risk Minimization with Side Information: A Tractable, Universal Optimal Transport Framework", "categories": ["stat.ML", "cs.LG", "math.OC", "q-fin.PM", "q-fin.RM"], "comment": null, "summary": "Conditional risk minimization arises in high-stakes decisions where risk must\nbe assessed in light of side information, such as stressed economic conditions,\nspecific customer profiles, or other contextual covariates. Constructing\nreliable conditional distributions from limited data is notoriously difficult,\nmotivating a series of optimal-transport-based proposals that address this\nuncertainty in a distributionally robust manner. Yet these approaches remain\nfragmented, each constrained by its own limitations: some rely on point\nestimates or restrictive structural assumptions, others apply only to narrow\nclasses of risk measures, and their structural connections are unclear. We\nintroduce a universal framework for distributionally robust conditional risk\nminimization, built on a novel union-ball formulation in optimal transport.\nThis framework offers three key advantages: interpretability, by subsuming\nexisting methods as special cases and revealing their deep structural links;\ntractability, by yielding convex reformulations for virtually all major risk\nfunctionals studied in the literature; and scalability, by supporting\ncutting-plane algorithms for large-scale conditional risk problems.\nApplications to portfolio optimization with rank-dependent expected utility\nhighlight the practical effectiveness of the framework, with conditional models\nconverging to optimal solutions where unconditional ones clearly do not."}
{"id": "2509.23143", "pdf": "https://arxiv.org/pdf/2509.23143", "abs": "https://arxiv.org/abs/2509.23143", "authors": ["Charles L. Wang"], "title": "MathBode: Frequency-Domain Fingerprints of LLM Mathematical Reasoning", "categories": ["cs.AI", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "This paper presents MathBode, a dynamic diagnostic for mathematical reasoning\nin large language models (LLMs). Instead of one-shot accuracy, MathBode treats\neach parametric problem as a system: we drive a single parameter sinusoidally\nand fit first-harmonic responses of model outputs and exact solutions. This\nyields interpretable, frequency-resolved metrics -- gain (amplitude tracking)\nand phase (lag) -- that form Bode-style fingerprints. Across five closed-form\nfamilies (linear solve, ratio/saturation, compound interest, 2x2 linear\nsystems, similar triangles), the diagnostic surfaces systematic low-pass\nbehavior and growing phase lag that accuracy alone obscures. We compare several\nmodels against a symbolic baseline that calibrates the instrument ($G \\approx\n1$, $\\phi \\approx 0$). Results separate frontier from mid-tier models on\ndynamics, providing a compact, reproducible protocol that complements standard\nbenchmarks with actionable measurements of reasoning fidelity and consistency.\nWe open-source the dataset and code to enable further research and adoption."}
{"id": "2509.23146", "pdf": "https://arxiv.org/pdf/2509.23146", "abs": "https://arxiv.org/abs/2509.23146", "authors": ["Zichao Yu", "Ming Li", "Wenyi Zhang", "Weiguo Gao"], "title": "Tree Reward-Aligned Search for TReASURe in Masked Diffusion Language Models", "categories": ["cs.CL", "cs.LG"], "comment": "21 pages, 6 figures", "summary": "Tree search has recently emerged as a powerful framework for aligning\ngenerative models with task-specific rewards at test time. Applying tree search\nto Masked Diffusion Language Models, however, introduces two key challenges:\n(i) parallel unmasking yields highly correlated branches, limiting exploration,\nand (ii) reward evaluation via sampled completions produces high-variance\nestimates, making pruning unstable. We propose TReASURe, a tree-search\ntest-time alignment method that addresses these issues. It introduces (i)\nUnmaskBranch, a branching strategy based on first-hitting unmasking that\ndiversifies both token content and reveal order with a single model call per\nparent node, and (ii) ResubstituteScore, a pruning rule that uses deterministic\nresubstitution to score partially masked sequences with low-variance proxy\ncompletions. Theoretically, we quantify branching efficiency gains in NFEs\n(number of function evaluations), show that the scoring rule approximates the\ntrue reward with error bounded by predictive uncertainty, and prove\nimprovements with larger tree widths. Empirically, TReASURe achieves\nstate-of-the-art results on perplexity, linguistic acceptability, and control\nof sentiment and toxicity, outperforming prior methods under matched compute\nbudgets, with especially strong gains in low-NFE regimes."}
{"id": "2509.23154", "pdf": "https://arxiv.org/pdf/2509.23154", "abs": "https://arxiv.org/abs/2509.23154", "authors": ["Jinzhe Pan", "Jingqing Wang", "Yuehui Ouyang", "Wenchi Cheng", "Wei Zhang"], "title": "AI-Enhanced Distributed Channel Access for Collision Avoidance in Future Wi-Fi 8", "categories": ["cs.AI", "cs.LG", "cs.NI"], "comment": "6 pages,6 figures, accepted by Globalcom 2025", "summary": "The exponential growth of wireless devices and stringent reliability\nrequirements of emerging applications demand fundamental improvements in\ndistributed channel access mechanisms for unlicensed bands. Current Wi-Fi\nsystems, which rely on binary exponential backoff (BEB), suffer from suboptimal\ncollision resolution in dense deployments and persistent fairness challenges\ndue to inherent randomness. This paper introduces a multi-agent reinforcement\nlearning framework that integrates artificial intelligence (AI) optimization\nwith legacy device coexistence. We first develop a dynamic backoff selection\nmechanism that adapts to real-time channel conditions through access deferral\nevents while maintaining full compatibility with conventional CSMA/CA\noperations. Second, we introduce a fairness quantification metric aligned with\nenhanced distributed channel access (EDCA) principles to ensure equitable\nmedium access opportunities. Finally, we propose a centralized training\ndecentralized execution (CTDE) architecture incorporating neighborhood activity\npatterns as observational inputs, optimized via constrained multi-agent\nproximal policy optimization (MAPPO) to jointly minimize collisions and\nguarantee fairness. Experimental results demonstrate that our solution\nsignificantly reduces collision probability compared to conventional BEB while\npreserving backward compatibility with commercial Wi-Fi devices. The proposed\nfairness metric effectively eliminates starvation risks in heterogeneous\nscenarios."}
{"id": "2509.23157", "pdf": "https://arxiv.org/pdf/2509.23157", "abs": "https://arxiv.org/abs/2509.23157", "authors": ["Yanqing Fu", "Chao Huang", "Chenrun Wang", "Zhuping Wang"], "title": "Grouped Satisficing Paths in Pure Strategy Games: a Topological Perspective", "categories": ["cs.GT", "cs.LG", "cs.MA"], "comment": null, "summary": "In game theory and multi-agent reinforcement learning (MARL), each agent\nselects a strategy, interacts with the environment and other agents, and\nsubsequently updates its strategy based on the received payoff. This process\ngenerates a sequence of joint strategies $(s^t)_{t \\geq 0}$, where $s^t$\nrepresents the strategy profile of all agents at time step $t$. A widely\nadopted principle in MARL algorithms is \"win-stay, lose-shift\", which dictates\nthat an agent retains its current strategy if it achieves the best response.\nThis principle exhibits a fixed-point property when the joint strategy has\nbecome an equilibrium. The sequence of joint strategies under this principle is\nreferred to as a satisficing path, a concept first introduced in [40] and\nexplored in the context of $N$-player games in [39]. A fundamental question\narises regarding this principle: Under what conditions does every initial joint\nstrategy $s$ admit a finite-length satisficing path $(s^t)_{0 \\leq t \\leq T}$\nwhere $s^0=s$ and $s^T$ is an equilibrium? This paper establishes a sufficient\ncondition for such a property, and demonstrates that any finite-state Markov\ngame, as well as any $N$-player game, guarantees the existence of a\nfinite-length satisficing path from an arbitrary initial strategy to some\nequilibrium. These results provide a stronger theoretical foundation for the\ndesign of MARL algorithms."}
{"id": "2509.23186", "pdf": "https://arxiv.org/pdf/2509.23186", "abs": "https://arxiv.org/abs/2509.23186", "authors": ["Qimin Zhong", "Hao Liao", "Siwei Wang", "Mingyang Zhou", "Xiaoqun Wu", "Rui Mao", "Wei Chen"], "title": "Understanding and Enhancing the Planning Capability of Language Models via Multi-Token Prediction", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have achieved impressive performance across\ndiverse tasks but continue to struggle with learning transitive relations, a\ncornerstone for complex planning. To address this issue, we investigate the\nMulti-Token Prediction (MTP) paradigm and its impact to transitive relation\nlearning. We theoretically analyze the MTP paradigm using a Transformer\narchitecture composed of a shared output head and a transfer layer. Our\nanalysis reveals that the transfer layer gradually learns the multi-step\nadjacency information, which in turn enables the backbone model to capture\nunobserved transitive reachability relations beyond those directly present in\nthe training data, albeit with some inevitable noise in adjacency estimation.\nBuilding on this foundation, we propose two strategies to enhance the transfer\nlayer and overall learning quality: Next-Token Injection (NTI) and a\nTransformer-based transfer layer. Our experiments on both synthetic graphs and\nthe Blocksworld planning benchmark validate our theoretical findings and\ndemonstrate that the improvements significantly enhance the model's\npath-planning capability. These findings deepen our understanding of how\nTransformers with MTP learn in complex planning tasks, and provide practical\nstrategies to overcome the transitivity bottleneck, paving the way toward\nstructurally aware and general-purpose planning models."}
{"id": "2509.23225", "pdf": "https://arxiv.org/pdf/2509.23225", "abs": "https://arxiv.org/abs/2509.23225", "authors": ["Alisher Myrgyyassov", "Zhen Song", "Yu Sun", "Bruce Xiao Wang", "Min Ney Wong", "Yongping Zheng"], "title": "UltraUNet: Real-Time Ultrasound Tongue Segmentation for Diverse Linguistic and Imaging Conditions", "categories": ["cs.CV", "cs.LG"], "comment": "16 pages, 8 figures", "summary": "Ultrasound tongue imaging (UTI) is a non-invasive and cost-effective tool for\nstudying speech articulation, motor control, and related disorders. However,\nreal-time tongue contour segmentation remains challenging due to low\nsignal-to-noise ratios, imaging variability, and computational demands. We\npropose UltraUNet, a lightweight encoder-decoder architecture optimized for\nreal-time segmentation of tongue contours in ultrasound images. UltraUNet\nincorporates domain-specific innovations such as lightweight\nSqueeze-and-Excitation blocks, Group Normalization for small-batch stability,\nand summation-based skip connections to reduce memory and computational\noverhead. It achieves 250 frames per second and integrates ultrasound-specific\naugmentations like denoising and blur simulation. Evaluations on 8 datasets\ndemonstrate high accuracy and robustness, with single-dataset Dice = 0.855 and\nMSD = 0.993px, and cross-dataset Dice averaging 0.734 and 0.761. UltraUNet\nprovides a fast, accurate solution for speech research, clinical diagnostics,\nand analysis of speech motor disorders."}
{"id": "2509.23230", "pdf": "https://arxiv.org/pdf/2509.23230", "abs": "https://arxiv.org/abs/2509.23230", "authors": ["Haoyu Wang", "Renyuan Ma", "Gonzalo Mateos", "Luana Ruiz"], "title": "A Generative Model for Controllable Feature Heterophily in Graphs", "categories": ["stat.ML", "cs.LG", "eess.SP"], "comment": null, "summary": "We introduce a principled generative framework for graph signals that enables\nexplicit control of feature heterophily, a key property underlying the\neffectiveness of graph learning methods. Our model combines a Lipschitz\ngraphon-based random graph generator with Gaussian node features filtered\nthrough a smooth spectral function of the rescaled Laplacian. We establish new\ntheoretical guarantees: (i) a concentration result for the empirical\nheterophily score; and (ii) almost-sure convergence of the feature heterophily\nmeasure to a deterministic functional of the graphon degree profile, based on a\ngraphon-limit law for polynomial averages of Laplacian eigenvalues. These\nresults elucidate how the interplay between the graphon and the filter governs\nthe limiting level of feature heterophily, providing a tunable mechanism for\ndata modeling and generation. We validate the theory through experiments\ndemonstrating precise control of homophily across graph families and spectral\nfilters."}
{"id": "2509.23247", "pdf": "https://arxiv.org/pdf/2509.23247", "abs": "https://arxiv.org/abs/2509.23247", "authors": ["Michele Romani", "Francesco Paissan", "Andrea Fossà", "Elisabetta Farella"], "title": "Explicit modelling of subject dependency in BCI decoding", "categories": ["cs.HC", "cs.LG", "H.1.2; I.2.6; I.5.2"], "comment": "5 pages, 3 figures, conference paper", "summary": "Brain-Computer Interfaces (BCIs) suffer from high inter-subject variability\nand limited labeled data, often requiring lengthy calibration phases. In this\nwork, we present an end-to-end approach that explicitly models the subject\ndependency using lightweight convolutional neural networks (CNNs) conditioned\non the subject's identity. Our method integrates hyperparameter optimization\nstrategies that prioritize class imbalance and evaluates two conditioning\nmechanisms to adapt pre-trained models to unseen subjects with minimal\ncalibration data. We benchmark three lightweight architectures on a\ntime-modulated Event-Related Potentials (ERP) classification task, providing\ninterpretable evaluation metrics and explainable visualizations of the learned\nrepresentations. Results demonstrate improved generalization and data-efficient\ncalibration, highlighting the scalability and practicality of subject-adaptive\nBCIs."}
{"id": "2509.23267", "pdf": "https://arxiv.org/pdf/2509.23267", "abs": "https://arxiv.org/abs/2509.23267", "authors": ["Swaib Ilias Mazumder", "Manish Kumar", "Aparajita Khan"], "title": "Learning Regional Monsoon Patterns with a Multimodal Attention U-Net", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted in Geospatial AI and Applications with Foundation Models\n  (GAIA) 2025, INSAIT and ELLIS Unit Sofia, Bulgaria", "summary": "Accurate monsoon rainfall prediction is vital for India's agriculture, water\nmanagement, and climate risk planning, yet remains challenging due to sparse\nground observations and complex regional variability. We present a multimodal\ndeep learning framework for high-resolution precipitation classification that\nleverages satellite and Earth observation data. Unlike previous rainfall\nprediction models based on coarse 5-50 km grids, we curate a new 1 km\nresolution dataset for five Indian states, integrating seven key geospatial\nmodalities: land surface temperature, vegetation (NDVI), soil moisture,\nrelative humidity, wind speed, elevation, and land use, covering the\nJune-September 2024 monsoon season. Our approach uses an attention-guided U-Net\narchitecture to capture spatial patterns and temporal dependencies across\nmodalities, combined with focal and dice loss functions to handle rainfall\nclass imbalance defined by the India Meteorological Department (IMD).\nExperiments demonstrate that our multimodal framework consistently outperforms\nunimodal baselines and existing deep learning methods, especially in extreme\nrainfall categories. This work contributes a scalable framework, benchmark\ndataset, and state-of-the-art results for regional monsoon forecasting, climate\nresilience, and geospatial AI applications in India."}
{"id": "2509.23291", "pdf": "https://arxiv.org/pdf/2509.23291", "abs": "https://arxiv.org/abs/2509.23291", "authors": ["Joseph Marvin Imperial", "Harish Tayyar Madabushi"], "title": "Scaling Policy Compliance Assessment in Language Models with Policy Reasoning Traces", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Policy compliance assessment is a fundamental task of evaluating whether an\ninput case strictly complies with a set of human-defined rules, more generally\nknown as policies. In practice, human experts follow a systematic, step-by-step\nprocess to identify violations with respect to specific stipulations outlined\nin the policy. However, such documentation of gold-standard, expert-level\nreasoning processes is costly to acquire. In this paper, we introduce Policy\nReasoning Traces (PRT), a form of specialized generated reasoning chains that\nserve as a reasoning bridge to improve an LLM's policy compliance assessment\ncapabilities. Our empirical evaluations demonstrate that the use of PRTs for\nboth inference-time and training-time scenarios significantly enhances the\nperformance of open-weight and commercial models, setting a new\nstate-of-the-art for HIPAA and GDPR policies. Beyond accuracy gains, we also\nhighlight how PRTs can improve an LLM's ability to accurately cite policy\nclauses, as well as influence compliance decisions through their high\nutilization from the raw chains of thought."}
{"id": "2509.23317", "pdf": "https://arxiv.org/pdf/2509.23317", "abs": "https://arxiv.org/abs/2509.23317", "authors": ["A. Maluckov", "D. Stojanovic", "M. Miletic", "Lj. Hadzievski", "J. Petrovic"], "title": "Multifractal features of multimodal cardiac signals: Nonlinear dynamics of exercise recovery", "categories": ["nlin.PS", "cs.LG", "physics.med-ph"], "comment": "10 pages, 7 Figures", "summary": "We investigate the recovery dynamics of healthy cardiac activity after\nphysical exertion using multimodal biosignals recorded with a polycardiograph.\nMultifractal features derived from the singularity spectrum capture the\nscale-invariant properties of cardiovascular regulation. Five supervised\nclassification algorithms - Logistic Regression (LogReg), Suport Vector Machine\nwith RBF kernel (SVM-RBF), k-Nearest Neighbors (kNN), Decision Tree (DT), and\nRandom Forest (RF) - were evaluated to distinguish recovery states in a small,\nimbalanced dataset. Our results show that multifractal analysis, combined with\nmultimodal sensing, yields reliable features for characterizing recovery and\npoints toward nonlinear diagnostic methods for heart conditions."}
{"id": "2509.23328", "pdf": "https://arxiv.org/pdf/2509.23328", "abs": "https://arxiv.org/abs/2509.23328", "authors": ["Andrej Orsula", "Matthieu Geist", "Miguel Olivares-Mendez", "Carol Martinez"], "title": "Space Robotics Bench: Robot Learning Beyond Earth", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "The source code is available at\n  https://github.com/AndrejOrsula/space_robotics_bench", "summary": "The growing ambition for space exploration demands robust autonomous systems\nthat can operate in unstructured environments under extreme extraterrestrial\nconditions. The adoption of robot learning in this domain is severely hindered\nby the prohibitive cost of technology demonstrations and the limited\navailability of data. To bridge this gap, we introduce the Space Robotics\nBench, an open-source simulation framework for robot learning in space. It\noffers a modular architecture that integrates on-demand procedural generation\nwith massively parallel simulation environments to support the creation of vast\nand diverse training distributions for learning-based agents. To ground\nresearch and enable direct comparison, the framework includes a comprehensive\nsuite of benchmark tasks that span a wide range of mission-relevant scenarios.\nWe establish performance baselines using standard reinforcement learning\nalgorithms and present a series of experimental case studies that investigate\nkey challenges in generalization, end-to-end learning, adaptive control, and\nsim-to-real transfer. Our results reveal insights into the limitations of\ncurrent methods and demonstrate the utility of the framework in producing\npolicies capable of real-world operation. These contributions establish the\nSpace Robotics Bench as a valuable resource for developing, benchmarking, and\ndeploying the robust autonomous systems required for the final frontier."}
{"id": "2509.23333", "pdf": "https://arxiv.org/pdf/2509.23333", "abs": "https://arxiv.org/abs/2509.23333", "authors": ["Nikolas McNeal", "N. Apurva Ratan Murty"], "title": "Targeted perturbations reveal brain-like local coding axes in robustified, but not standard, ANN-based brain models", "categories": ["q-bio.NC", "cs.CV", "cs.LG"], "comment": "9 pages, 4 figures, preprint", "summary": "Artificial neural networks (ANNs) have become the de facto standard for\nmodeling the human visual system, primarily due to their success in predicting\nneural responses. However, with many models now achieving similar predictive\naccuracy, we need a stronger criterion. Here, we use small-scale adversarial\nprobes to characterize the local representational geometry of many highly\npredictive ANN-based brain models. We report four key findings. First, we show\nthat most contemporary ANN-based brain models are unexpectedly fragile. Despite\nhigh prediction scores, their response predictions are highly sensitive to\nsmall, imperceptible perturbations, revealing unreliable local coding\ndirections. Second, we demonstrate that a model's sensitivity to adversarial\nprobes can better discriminate between candidate neural encoding models than\nprediction accuracy alone. Third, we find that standard models rely on distinct\nlocal coding directions that do not transfer across model architectures.\nFinally, we show that adversarial probes from robustified models produce\ngeneralizable and semantically meaningful changes, suggesting that they capture\nthe local coding dimensions of the visual system. Together, our work shows that\nlocal representational geometry provides a stronger criterion for brain model\nevaluation. We also provide empirical grounds for favoring robust models, whose\nmore stable coding axes not only align better with neural selectivity but also\ngenerate concrete, testable predictions for future experiments."}
{"id": "2509.23338", "pdf": "https://arxiv.org/pdf/2509.23338", "abs": "https://arxiv.org/abs/2509.23338", "authors": ["Wei Zhou", "Guoliang Li", "Haoyu Wang", "Yuxing Han", "Xufei Wu", "Fan Wu", "Xuanhe Zhou"], "title": "PARROT: A Benchmark for Evaluating LLMs in Cross-System SQL Translation", "categories": ["cs.DB", "cs.AI", "cs.CL", "cs.IR", "cs.LG"], "comment": "To appear in NeurIPS 2025. Welcome your submission to challenge our\n  leaderboard at: https://code4db.github.io/parrot-bench/. Also visit our code\n  repository at: https://github.com/weAIDB/PARROT", "summary": "Large language models (LLMS) have shown increasing effectiveness in\nText-to-SQL tasks. However, another closely related problem, Cross-System SQL\nTranslation (a.k.a., SQL-to-SQL), which adapts a query written for one database\nsystem (e.g., MySQL) into its equivalent one for another system (e.g.,\nClickHouse), is of great practical importance but remains underexplored.\nExisting SQL benchmarks are not well-suited for SQL-to-SQL evaluation, which\n(1) focus on a limited set of database systems (often just SQLite) and (2)\ncannot capture many system-specific SQL dialects (e.g., customized functions,\ndata types, and syntax rules). Thus, in this paper, we introduce PARROT, a\nPractical And Realistic BenchmaRk for CrOss-System SQL Translation. PARROT\ncomprises 598 translation pairs from 38 open-source benchmarks and real-world\nbusiness services, specifically prepared to challenge system-specific SQL\nunderstanding (e.g., LLMS achieve lower than 38.53% accuracy on average). We\nalso provide multiple benchmark variants, including PARROT-Diverse with 28,003\ntranslations (for extensive syntax testing) and PARROT-Simple with 5,306\nrepresentative samples (for focused stress testing), covering 22\nproduction-grade database systems. To promote future research, we release a\npublic leaderboard and source code at: https://code4db.github.io/parrot-bench/."}
{"id": "2509.23340", "pdf": "https://arxiv.org/pdf/2509.23340", "abs": "https://arxiv.org/abs/2509.23340", "authors": ["Emma Kondrup", "Sebastian Sabry", "Hussein Abdallah", "Zachary Yang", "James Zhou", "Kellin Pelrine", "Jean-François Godbout", "Michael M. Bronstein", "Reihaneh Rabbany", "Shenyang Huang"], "title": "CrediBench: Building Web-Scale Network Datasets for Information Integrity", "categories": ["cs.SI", "cs.DC", "cs.LG"], "comment": null, "summary": "Online misinformation poses an escalating threat, amplified by the Internet's\nopen nature and increasingly capable LLMs that generate persuasive yet\ndeceptive content. Existing misinformation detection methods typically focus on\neither textual content or network structure in isolation, failing to leverage\nthe rich, dynamic interplay between website content and hyperlink relationships\nthat characterizes real-world misinformation ecosystems. We introduce\nCrediBench: a large-scale data processing pipeline for constructing temporal\nweb graphs that jointly model textual content and hyperlink structure for\nmisinformation detection. Unlike prior work, our approach captures the dynamic\nevolution of general misinformation domains, including changes in both content\nand inter-site references over time. Our processed one-month snapshot extracted\nfrom the Common Crawl archive in December 2024 contains 45 million nodes and 1\nbillion edges, representing the largest web graph dataset made publicly\navailable for misinformation research to date. From our experiments on this\ngraph snapshot, we demonstrate the strength of both structural and webpage\ncontent signals for learning credibility scores, which measure source\nreliability. The pipeline and experimentation code are all available here, and\nthe dataset is in this folder."}
{"id": "2509.23364", "pdf": "https://arxiv.org/pdf/2509.23364", "abs": "https://arxiv.org/abs/2509.23364", "authors": ["Francesca Ronchini", "Luca Comanducci", "Simone Marcucci", "Fabio Antonacci"], "title": "AI-Assisted Music Production: A User Study on Text-to-Music Models", "categories": ["eess.AS", "cs.LG", "cs.SD", "eess.SP"], "comment": "Accepted at 17th International Symposium on Computer Music\n  Multidisciplinary Research (CMMR 25)", "summary": "Text-to-music models have revolutionized the creative landscape, offering new\npossibilities for music creation. Yet their integration into musicians\nworkflows remains underexplored. This paper presents a case study on how TTM\nmodels impact music production, based on a user study of their effect on\nproducers creative workflows. Participants produce tracks using a custom tool\ncombining TTM and source separation models. Semi-structured interviews and\nthematic analysis reveal key challenges, opportunities, and ethical\nconsiderations. The findings offer insights into the transformative potential\nof TTMs in music production, as well as challenges in their real-world\nintegration."}
{"id": "2509.23371", "pdf": "https://arxiv.org/pdf/2509.23371", "abs": "https://arxiv.org/abs/2509.23371", "authors": ["Junming Yang", "Ning Xu", "Biao Liu", "Shiqi Qiao", "Xin Geng"], "title": "Alignment through Meta-Weighted Online Sampling: Bridging the Gap between Data Generation and Preference Optimization", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Preference optimization is crucial for aligning large language models (LLMs)\nwith human values and intentions. A significant challenge in this process is\nthe distribution mismatch between pre-collected offline preference data and the\nevolving model policy. Existing methods attempt to reduce this gap using static\nheuristics or decoupled online sampling strategies, but they often fail to\nadapt to the model's dynamic learning state. To bridge this gap, we propose\nMeta-Weighted Adaptive Preference Optimization (MetaAPO), a novel framework\nthat dynamically couples data generation with model training. MetaAPO employs a\nlightweight meta-learner, as an \"alignment gap estimator\", to evaluate the\npotential benefits of on-policy sampling in relation to offline data. This\nguides targeted online generation and assigns sample-wise meta-weights to the\noptimization objective, dynamically balancing the quality and distribution of\nonline and offline data. Experiments on AlpacaEval 2, Arena-Hard and MT-Bench\ndemonstrate that MetaAPO consistently outperforms existing preference\noptimization approaches across various settings, while reducing 42% in online\nannotation costs."}
{"id": "2509.23374", "pdf": "https://arxiv.org/pdf/2509.23374", "abs": "https://arxiv.org/abs/2509.23374", "authors": ["Maryam Boubekraoui", "Ridwane Tahiri"], "title": "An Accelerated Newton-GMRES Method for Multilinear PageRank", "categories": ["math.NA", "cs.LG", "cs.NA"], "comment": null, "summary": "Modeling complex multiway relationships in large-scale networks is becoming\nmore and more challenging in data science. The multilinear PageRank problem,\narising naturally in the study of higher-order Markov chains, is a powerful\nframework for capturing such interactions, with applications in web ranking,\nrecommendation systems, and social network analysis. It extends the classical\nGoogle PageRank model to a tensor-based formulation, leading to a nonlinear\nsystem that captures multi-way dependencies between states. Newton-based\nmethods can achieve local quadratic convergence for this problem, but they\nrequire solving a large linear system at each iteration, which becomes too\ncostly for large-scale applications. To address this challenge, we present an\naccelerated Newton-GMRES method that leverages Krylov subspace techniques to\napproximate the Newton step without explicitly forming the large Jacobian\nmatrix. We further employ vector extrapolation methods, including Minimal\nPolynomial Extrapolation (MPE), Reduced Rank Extrapolation (RRE), and Anderson\nAcceleration (AA), to improve the convergence rate and enhance numerical\nstability. Extensive experiments on synthetic and real-world data demonstrate\nthat the proposed approach significantly outperforms classical Newton-based\nsolvers in terms of efficiency, robustness, and scalability."}
{"id": "2509.23383", "pdf": "https://arxiv.org/pdf/2509.23383", "abs": "https://arxiv.org/abs/2509.23383", "authors": ["Sebastian Bordt", "Martin Pawelczyk"], "title": "Train Once, Answer All: Many Pretraining Experiments for the Cost of One", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Recent work has demonstrated that controlled pretraining experiments are a\npowerful tool for understanding learning, reasoning, and memorization in large\nlanguage models (LLMs). However, the computational cost of pretraining presents\na significant constraint. To overcome this constraint, we propose to conduct\nmultiple pretraining experiments simultaneously during a single training run.\nWe demonstrate the feasibility of this approach by conducting ten experiments\nduring the training of a 1.5B parameter model on 210B tokens. Although we only\ntrain a single model, we can replicate the results from multiple previous works\non data contamination, poisoning, and memorization. We also conduct novel\ninvestigations into knowledge acquisition, mathematical reasoning, and\nwatermarking. For example, we dynamically update the training data until the\nmodel acquires a particular piece of knowledge. Remarkably, the influence of\nthe ten experiments on the model's training dynamics and overall performance is\nminimal. However, interactions between different experiments may act as a\npotential confounder in our approach. We propose to test for interactions with\ncontinual pretraining experiments, finding them to be negligible in our setup.\nOverall, our findings suggest that performing multiple pretraining experiments\nin a single training run can enable rigorous scientific experimentation with\nlarge models on a compute budget."}
{"id": "2509.23385", "pdf": "https://arxiv.org/pdf/2509.23385", "abs": "https://arxiv.org/abs/2509.23385", "authors": ["Pierre-Louis Ruhlmann", "Pedro L. C. Rodrigues", "Michael Arbel", "Florence Forbes"], "title": "Flow Matching for Robust Simulation-Based Inference under Model Misspecification", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Simulation-based inference (SBI) is transforming experimental sciences by\nenabling parameter estimation in complex non-linear models from simulated data.\nA persistent challenge, however, is model misspecification: simulators are only\napproximations of reality, and mismatches between simulated and real data can\nyield biased or overconfident posteriors. We address this issue by introducing\nFlow Matching Corrected Posterior Estimation (FMCPE), a framework that\nleverages the flow matching paradigm to refine simulation-trained posterior\nestimators using a small set of real calibration samples. Our approach proceeds\nin two stages: first, a posterior approximator is trained on abundant simulated\ndata; second, flow matching transports its predictions toward the true\nposterior supported by real observations, without requiring explicit knowledge\nof the misspecification. This design enables FMCPE to combine the scalability\nof SBI with robustness to distributional shift. Across synthetic benchmarks and\nreal-world datasets, we show that our proposal consistently mitigates the\neffects of misspecification, delivering improved inference accuracy and\nuncertainty calibration compared to standard SBI baselines, while remaining\ncomputationally efficient."}
{"id": "2509.23391", "pdf": "https://arxiv.org/pdf/2509.23391", "abs": "https://arxiv.org/abs/2509.23391", "authors": ["Sahand Tangerami", "Nicholas A. Mecholsky", "Francesco Sorrentino"], "title": "Optimizing the Network Topology of a Linear Reservoir Computer", "categories": ["eess.SY", "cs.LG", "cs.SY", "nlin.CD"], "comment": null, "summary": "Machine learning has become a fundamental approach for modeling, prediction,\nand control, enabling systems to learn from data and perform complex tasks.\nReservoir computing is a machine learning tool that leverages high-dimensional\ndynamical systems to efficiently process temporal data for prediction and\nobservation tasks. Traditionally, the connectivity of a reservoir computer (RC)\nis generated at random, lacking a principled design. Here, we focus on\noptimizing the topology of a linear RC to improve its performance and\ninterpretability, which we achieve by decoupling the RC dynamics into a number\nof independent modes. We then proceed to optimize each one of these modes to\nperform a given task, which corresponds to selecting an optimal RC connectivity\nin terms of a given set of eigenvalues of the RC adjacency matrix. Simulations\non networks of varying sizes show that the optimized RC significantly\noutperforms randomly constructed reservoirs in both the training and testing\nphases and also often surpasses nonlinear reservoirs of comparable size. This\napproach provides both practical performance advantages and theoretical\nguidelines for designing efficient, task-specific, and analytically transparent\nRC architectures."}
{"id": "2509.23412", "pdf": "https://arxiv.org/pdf/2509.23412", "abs": "https://arxiv.org/abs/2509.23412", "authors": ["Haowei Hua", "Hong Jiao", "Dan Song"], "title": "Comparison of Scoring Rationales Between Large Language Models and Human Raters", "categories": ["cs.CL", "cs.LG"], "comment": "23 Pages, 4 Tables, 13 Figures", "summary": "Advances in automated scoring are closely aligned with advances in\nmachine-learning and natural-language-processing techniques. With recent\nprogress in large language models (LLMs), the use of ChatGPT, Gemini, Claude,\nand other generative-AI chatbots for automated scoring has been explored. Given\ntheir strong reasoning capabilities, LLMs can also produce rationales to\nsupport the scores they assign. Thus, evaluating the rationales provided by\nboth human and LLM raters can help improve the understanding of the reasoning\nthat each type of rater applies when assigning a score. This study investigates\nthe rationales of human and LLM raters to identify potential causes of scoring\ninconsistency. Using essays from a large-scale test, the scoring accuracy of\nGPT-4o, Gemini, and other LLMs is examined based on quadratic weighted kappa\nand normalized mutual information. Cosine similarity is used to evaluate the\nsimilarity of the rationales provided. In addition, clustering patterns in\nrationales are explored using principal component analysis based on the\nembeddings of the rationales. The findings of this study provide insights into\nthe accuracy and ``thinking'' of LLMs in automated scoring, helping to improve\nthe understanding of the rationales behind both human scoring and LLM-based\nautomated scoring."}
{"id": "2509.23426", "pdf": "https://arxiv.org/pdf/2509.23426", "abs": "https://arxiv.org/abs/2509.23426", "authors": ["Shanghua Gao", "Richard Zhu", "Pengwei Sui", "Zhenglun Kong", "Sufian Aldogom", "Yepeng Huang", "Ayush Noori", "Reza Shamji", "Krishna Parvataneni", "Theodoros Tsiligkaridis", "Marinka Zitnik"], "title": "Democratizing AI scientists using ToolUniverse", "categories": ["cs.AI", "cs.LG"], "comment": "https://aiscientist.tools", "summary": "AI scientists are emerging computational systems that serve as collaborative\npartners in discovery. These systems remain difficult to build because they are\nbespoke, tied to rigid workflows, and lack shared environments that unify\ntools, data, and analyses into a common ecosystem. In omics, unified ecosystems\nhave transformed research by enabling interoperability, reuse, and\ncommunity-driven development; AI scientists require comparable infrastructure.\nWe present ToolUniverse, an ecosystem for building AI scientists from any\nlanguage or reasoning model, whether open or closed. TOOLUNIVERSE standardizes\nhow AI scientists identify and call tools, integrating more than 600 machine\nlearning models, datasets, APIs, and scientific packages for data analysis,\nknowledge retrieval, and experimental design. It automatically refines tool\ninterfaces for correct use by AI scientists, creates new tools from natural\nlanguage descriptions, iteratively optimizes tool specifications, and composes\ntools into agentic workflows. In a case study of hypercholesterolemia,\nToolUniverse was used to create an AI scientist to identify a potent analog of\na drug with favorable predicted properties. The open-source ToolUniverse is\navailable at https://aiscientist.tools."}
{"id": "2509.23439", "pdf": "https://arxiv.org/pdf/2509.23439", "abs": "https://arxiv.org/abs/2509.23439", "authors": ["Saeed Ghadimi", "Woosuk L. Jung", "Arnesh Sujanani", "David Torregrosa-Belén", "Henry Wolkowicz"], "title": "New Insights and Algorithms for Optimal Diagonal Preconditioning", "categories": ["math.OC", "cs.LG", "cs.NA", "math.NA", "15A12, 65F35, 49J52, 49K10, 90C32, 90C26"], "comment": null, "summary": "Preconditioning (scaling) is essential in many areas of mathematics, and in\nparticular in optimization. In this work, we study the problem of finding an\noptimal diagonal preconditioner. We focus on minimizing two different notions\nof condition number: the classical, worst-case type, $\\kappa$-condition number,\nand the more averaging motivated $\\omega$-condition number. We provide affine\nbased pseudoconvex reformulations of both optimization problems. The advantage\nof our formulations is that the gradient of the objective is inexpensive to\ncompute and the optimization variable is just an $n\\times 1$ vector. We also\nprovide elegant characterizations of the optimality conditions of both\nproblems.\n  We develop a competitive subgradient method, with convergence guarantees, for\n$\\kappa$-optimal diagonal preconditioning that scales much better and is more\nefficient than existing SDP-based approaches. We also show that the\npreconditioners found by our subgradient method leads to better PCG performance\nfor solving linear systems than other approaches. Finally, we show the\ninteresting phenomenon that we can apply the $\\omega$-optimal preconditioner to\nthe exact $\\kappa$-optimally diagonally preconditioned matrix $A$ and get\nconsistent, significantly improved convergence results for PCG methods."}
{"id": "2509.23442", "pdf": "https://arxiv.org/pdf/2509.23442", "abs": "https://arxiv.org/abs/2509.23442", "authors": ["Md. Saiful Bari Siddiqui", "Mohammed Imamul Hassan Bhuiyan"], "title": "S$^3$F-Net: A Multi-Modal Approach to Medical Image Classification via Spatial-Spectral Summarizer Fusion Network", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG", "eess.SP"], "comment": "Submitted to IEEE Journal of Biomedical and Health Informatics\n  (JBHI). This preprint includes few additional details not present in the\n  journal submission", "summary": "Convolutional Neural Networks have become a cornerstone of medical image\nanalysis due to their proficiency in learning hierarchical spatial features.\nHowever, this focus on a single domain is inefficient at capturing global,\nholistic patterns and fails to explicitly model an image's frequency-domain\ncharacteristics. To address these challenges, we propose the Spatial-Spectral\nSummarizer Fusion Network (S$^3$F-Net), a dual-branch framework that learns\nfrom both spatial and spectral representations simultaneously. The S$^3$F-Net\nperforms a fusion of a deep spatial CNN with our proposed shallow spectral\nencoder, SpectraNet. SpectraNet features the proposed SpectralFilter layer,\nwhich leverages the Convolution Theorem by applying a bank of learnable filters\ndirectly to an image's full Fourier spectrum via a computation-efficient\nelement-wise multiplication. This allows the SpectralFilter layer to attain a\nglobal receptive field instantaneously, with its output being distilled by a\nlightweight summarizer network. We evaluate S$^3$F-Net across four medical\nimaging datasets spanning different modalities to validate its efficacy and\ngeneralizability. Our framework consistently and significantly outperforms its\nstrong spatial-only baseline in all cases, with accuracy improvements of up to\n5.13%. With a powerful Bilinear Fusion, S$^3$F-Net achieves a SOTA competitive\naccuracy of 98.76% on the BRISC2025 dataset. Concatenation Fusion performs\nbetter on the texture-dominant Chest X-Ray Pneumonia dataset, achieving 93.11%\naccuracy, surpassing many top-performing, much deeper models. Our\nexplainability analysis also reveals that the S$^3$F-Net learns to dynamically\nadjust its reliance on each branch based on the input pathology. These results\nverify that our dual-domain approach is a powerful and generalizable paradigm\nfor medical image analysis."}
{"id": "2509.23454", "pdf": "https://arxiv.org/pdf/2509.23454", "abs": "https://arxiv.org/abs/2509.23454", "authors": ["Md. Saiful Bari Siddiqui", "Utsab Saha"], "title": "AudioFuse: Unified Spectral-Temporal Learning via a Hybrid ViT-1D CNN Architecture for Robust Phonocardiogram Classification", "categories": ["eess.AS", "cs.AI", "cs.LG", "cs.SD", "eess.SP"], "comment": "Submitted to ICASSP 2026. This preprint includes some additional\n  details beyond the conference submission", "summary": "Biomedical audio signals, such as phonocardiograms (PCG), are inherently\nrhythmic and contain diagnostic information in both their spectral (tonal) and\ntemporal domains. Standard 2D spectrograms provide rich spectral features but\ncompromise the phase information and temporal precision of the 1D waveform. We\npropose AudioFuse, an architecture that simultaneously learns from both\ncomplementary representations to classify PCGs. To mitigate the overfitting\nrisk common in fusion models, we integrate a custom, wide-and-shallow Vision\nTransformer (ViT) for spectrograms with a shallow 1D CNN for raw waveforms. On\nthe PhysioNet 2016 dataset, AudioFuse achieves a state-of-the-art competitive\nROC-AUC of 0.8608 when trained from scratch, outperforming its spectrogram\n(0.8066) and waveform (0.8223) baselines. Moreover, it demonstrates superior\nrobustness to domain shift on the challenging PASCAL dataset, maintaining an\nROC-AUC of 0.7181 while the spectrogram baseline collapses (0.4873). Fusing\ncomplementary representations thus provides a strong inductive bias, enabling\nthe creation of efficient, generalizable classifiers without requiring\nlarge-scale pre-training."}
{"id": "2509.23455", "pdf": "https://arxiv.org/pdf/2509.23455", "abs": "https://arxiv.org/abs/2509.23455", "authors": ["Tharindu Ekanayake", "Constantino Álvarez Casado", "Miguel Bordallo López"], "title": "3DPCNet: Pose Canonicalization for Robust Viewpoint-Invariant 3D Kinematic Analysis from Monocular RGB cameras", "categories": ["cs.CV", "cs.LG"], "comment": "8 pages, 6 figures, 1 table, 21 references, conference, Code\n  available at: https://github.com/tharindu326/3DPCNet", "summary": "Monocular 3D pose estimators produce camera-centered skeletons, creating\nview-dependent kinematic signals that complicate comparative analysis in\napplications such as health and sports science. We present 3DPCNet, a compact,\nestimator-agnostic module that operates directly on 3D joint coordinates to\nrectify any input pose into a consistent, body-centered canonical frame. Its\nhybrid encoder fuses local skeletal features from a graph convolutional network\nwith global context from a transformer via a gated cross-attention mechanism.\nFrom this representation, the model predicts a continuous 6D rotation that is\nmapped to an $SO(3)$ matrix to align the pose. We train the model in a\nself-supervised manner on the MM-Fi dataset using synthetically rotated poses,\nguided by a composite loss ensuring both accurate rotation and pose\nreconstruction. On the MM-Fi benchmark, 3DPCNet reduces the mean rotation error\nfrom over 20$^{\\circ}$ to 3.4$^{\\circ}$ and the Mean Per Joint Position Error\nfrom ~64 mm to 47 mm compared to a geometric baseline. Qualitative evaluations\non the TotalCapture dataset further demonstrate that our method produces\nacceleration signals from video that show strong visual correspondence to\nground-truth IMU sensor data, confirming that our module removes viewpoint\nvariability to enable physically plausible motion analysis."}
{"id": "2509.23468", "pdf": "https://arxiv.org/pdf/2509.23468", "abs": "https://arxiv.org/abs/2509.23468", "authors": ["Haonan Chen", "Jiaming Xu", "Hongyu Chen", "Kaiwen Hong", "Binghao Huang", "Chaoqi Liu", "Jiayuan Mao", "Yunzhu Li", "Yilun Du", "Katherine Driggs-Campbell"], "title": "Multi-Modal Manipulation via Multi-Modal Policy Consensus", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "9 pages, 7 figures", "summary": "Effectively integrating diverse sensory modalities is crucial for robotic\nmanipulation. However, the typical approach of feature concatenation is often\nsuboptimal: dominant modalities such as vision can overwhelm sparse but\ncritical signals like touch in contact-rich tasks, and monolithic architectures\ncannot flexibly incorporate new or missing modalities without retraining. Our\nmethod factorizes the policy into a set of diffusion models, each specialized\nfor a single representation (e.g., vision or touch), and employs a router\nnetwork that learns consensus weights to adaptively combine their\ncontributions, enabling incremental of new representations. We evaluate our\napproach on simulated manipulation tasks in {RLBench}, as well as real-world\ntasks such as occluded object picking, in-hand spoon reorientation, and puzzle\ninsertion, where it significantly outperforms feature-concatenation baselines\non scenarios requiring multimodal reasoning. Our policy further demonstrates\nrobustness to physical perturbations and sensor corruption. We further conduct\nperturbation-based importance analysis, which reveals adaptive shifts between\nmodalities."}
{"id": "2509.23497", "pdf": "https://arxiv.org/pdf/2509.23497", "abs": "https://arxiv.org/abs/2509.23497", "authors": ["Bruno M. Henrique", "Eugene Santos Jr"], "title": "Dynamic Trust Calibration Using Contextual Bandits", "categories": ["cs.AI", "cs.HC", "cs.LG"], "comment": null, "summary": "Trust calibration between humans and Artificial Intelligence (AI) is crucial\nfor optimal decision-making in collaborative settings. Excessive trust can lead\nusers to accept AI-generated outputs without question, overlooking critical\nflaws, while insufficient trust may result in disregarding valuable insights\nfrom AI systems, hindering performance. Despite its importance, there is\ncurrently no definitive and objective method for measuring trust calibration\nbetween humans and AI. Current approaches lack standardization and consistent\nmetrics that can be broadly applied across various contexts, and they don't\ndistinguish between the formation of opinions and subsequent human decisions.\nIn this work, we propose a novel and objective method for dynamic trust\ncalibration, introducing a standardized trust calibration measure and an\nindicator. By utilizing Contextual Bandits-an adaptive algorithm that\nincorporates context into decision-making-our indicator dynamically assesses\nwhen to trust AI contributions based on learned contextual information. We\nevaluate this indicator across three diverse datasets, demonstrating that\neffective trust calibration results in significant improvements in\ndecision-making performance, as evidenced by 10 to 38% increase in reward\nmetrics. These findings not only enhance theoretical understanding but also\nprovide practical guidance for developing more trustworthy AI systems\nsupporting decisions in critical domains, for example, disease diagnoses and\ncriminal justice."}
{"id": "2509.23499", "pdf": "https://arxiv.org/pdf/2509.23499", "abs": "https://arxiv.org/abs/2509.23499", "authors": ["Divyam Madaan", "Varshan Muhunthan", "Kyunghyun Cho", "Sumit Chopra"], "title": "Multi-modal Data Spectrum: Multi-modal Datasets are Multi-dimensional", "categories": ["cs.CV", "cs.CL", "cs.LG"], "comment": null, "summary": "Understanding the interplay between intra-modality dependencies (the\ncontribution of an individual modality to a target task) and inter-modality\ndependencies (the relationships between modalities and the target task) is\nfundamental to advancing multi-modal learning. However, the nature of and\ninteraction between these dependencies within current benchmark evaluations\nremains poorly characterized. In this work, we present a large-scale empirical\nstudy to quantify these dependencies across 23 visual question-answering\nbenchmarks using multi-modal large language models (MLLMs) covering domains\nsuch as general and expert knowledge reasoning, optical character recognition,\nand document understanding. Our findings show that the reliance on vision,\nquestion (text), and their interaction varies significantly, both across and\nwithin benchmarks. We discover that numerous benchmarks intended to mitigate\ntext-only biases have inadvertently amplified image-only dependencies. This\ncharacterization persists across model sizes, as larger models often use these\nintra-modality dependencies to achieve high performance that mask an underlying\nlack of multi-modal reasoning. We provide a quantitative characterization of\nmulti-modal datasets, enabling a principled approach to multi-modal benchmark\ndesign and evaluation."}
{"id": "2509.23516", "pdf": "https://arxiv.org/pdf/2509.23516", "abs": "https://arxiv.org/abs/2509.23516", "authors": ["Muhammad Bilal"], "title": "Network-Optimised Spiking Neural Network for Event-Driven Networking", "categories": ["cs.NE", "cs.LG", "cs.NI", "math.OC", "90B18, 60K25, 68M10, 68T07", "C.2; C.2.1; C.4; I.2.6"], "comment": "52 pages, 16 figures, 9 tables", "summary": "Spiking neural networks offer event-driven computation suited to\ntime-critical networking tasks such as anomaly detection, local routing\ncontrol, and congestion management at the edge. Classical units, including\nHodgkin-Huxley, Izhikevich, and the Random Neural Network, map poorly to these\nneeds. We introduce Network-Optimised Spiking (NOS), a compact two-variable\nunit whose state encodes normalised queue occupancy and a recovery resource.\nThe model uses a saturating nonlinearity to enforce finite buffers, a\nservice-rate leak, and graph-local inputs with delays and optional per link\ngates. It supports two differentiable reset schemes for training and\ndeployment. We give conditions for equilibrium existence and uniqueness, local\nstability tests from the Jacobian trace and determinant, and a network\nthreshold that scales with the Perron eigenvalue of the coupling matrix. The\nanalysis yields an operational rule g* ~ k* rho(W) linking damping and offered\nload, shows how saturation enlarges the stable region, and explains finite-size\nsmoothing of synchrony onsets. Stochastic arrivals follow a Poisson shot-noise\nmodel aligned with telemetry smoothing. Against queueing baselines, NOS matches\nM/M/1 mean by calibration while truncating deep tails under bursty input. In\nclosed loop it gives, low-jitte with short settling. In zero-shot, label-free\nforecasting NOS is calibrated per node from arrival statistics. Its NOS\ndynamics yield high AUROC/AUPRC, enabling timely detection of congestion onsets\nwith few false positives. Under a train-calibrated residual protocol across\nchain, star, and scale-free topologies, NOS improves early-warning F1 and\ndetection latency over MLP, RNN, GRU, and tGNN. We provide guidance for\ndata-driven initialisation, surrogate-gradient training with a homotopy on\nreset sharpness, and explicit stability checks with topology-aware bounds for\nresource constrained deployments."}
{"id": "2509.23542", "pdf": "https://arxiv.org/pdf/2509.23542", "abs": "https://arxiv.org/abs/2509.23542", "authors": ["Janvijay Singh", "Austin Xu", "Yilun Zhou", "Yefan Zhou", "Dilek Hakkani-Tur", "Shafiq Joty"], "title": "On the Shelf Life of Fine-Tuned LLM Judges: Future Proofing, Backward Compatibility, and Question Generalization", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "21 pages", "summary": "The LLM-as-a-judge paradigm is widely used in both evaluating free-text model\nresponses and reward modeling for model alignment and finetuning. Recently,\nfinetuning judges with judge-specific data has emerged as an often preferred\nchoice over directly prompting frontier models as judges, as the former\nachieves better performance with smaller model sizes while being more robust to\ncommon biases. However, the standard evaluation ignores several practical\nconcerns of finetuned judges regarding their real world deployment. In this\npaper, we identify and formalize three aspects that affect the shelf life of\nthese judges: future proofing and backward compatibility -- how well judges\nfinetuned on responses by today's generator models perform on responses by\nfuture models or past models, as well as question generalization -- how well\njudges generalize to unseen questions at test time. We study these three\naspects in the math domain under a unified framework with varying train and\ntest distributions, three SFT- and DPO-based finetuning algorithms and three\ndifferent base models. Experiments suggest that future-proofing is challenging\nfor most models, while backward compatibility is relatively easy, with\nDPO-trained models consistently improving performance. We further find that\ncontinual learning provides a more balanced adaptation to shifts between older\nand newer response distributions than training solely on stronger or weaker\nresponses. Moreover, all models observe certain degrees of performance\ndegradation when moving from questions seen during training to unseen ones,\nshowing that current judges do not fully generalize to unseen questions. These\nfindings provide insights into practical considerations for developing and\ndeploying judge models in the face of ever-changing generators."}
{"id": "2509.23544", "pdf": "https://arxiv.org/pdf/2509.23544", "abs": "https://arxiv.org/abs/2509.23544", "authors": ["Yidong Zhou", "Su I Iao", "Hans-Georg Müller"], "title": "End-to-End Deep Learning for Predicting Metric Space-Valued Outputs", "categories": ["stat.ML", "cs.AI", "cs.LG", "stat.ME"], "comment": "45 pages, 2 figures, 7 tables", "summary": "Many modern applications involve predicting structured, non-Euclidean outputs\nsuch as probability distributions, networks, and symmetric positive-definite\nmatrices. These outputs are naturally modeled as elements of general metric\nspaces, where classical regression techniques that rely on vector space\nstructure no longer apply. We introduce E2M (End-to-End Metric regression), a\ndeep learning framework for predicting metric space-valued outputs. E2M\nperforms prediction via a weighted Fr\\'echet means over training outputs, where\nthe weights are learned by a neural network conditioned on the input. This\nconstruction provides a principled mechanism for geometry-aware prediction that\navoids surrogate embeddings and restrictive parametric assumptions, while fully\npreserving the intrinsic geometry of the output space. We establish theoretical\nguarantees, including a universal approximation theorem that characterizes the\nexpressive capacity of the model and a convergence analysis of the\nentropy-regularized training objective. Through extensive simulations involving\nprobability distributions, networks, and symmetric positive-definite matrices,\nwe show that E2M consistently achieves state-of-the-art performance, with its\nadvantages becoming more pronounced at larger sample sizes. Applications to\nhuman mortality distributions and New York City taxi networks further\ndemonstrate the flexibility and practical utility of the framework."}
{"id": "2509.23563", "pdf": "https://arxiv.org/pdf/2509.23563", "abs": "https://arxiv.org/abs/2509.23563", "authors": ["Seungchan Kim", "Omar Alama", "Dmytro Kurdydyk", "John Keller", "Nikhil Keetha", "Wenshan Wang", "Yonatan Bisk", "Sebastian Scherer"], "title": "RAVEN: Resilient Aerial Navigation via Open-Set Semantic Memory and Behavior Adaptation", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Aerial outdoor semantic navigation requires robots to explore large,\nunstructured environments to locate target objects. Recent advances in semantic\nnavigation have demonstrated open-set object-goal navigation in indoor\nsettings, but these methods remain limited by constrained spatial ranges and\nstructured layouts, making them unsuitable for long-range outdoor search. While\noutdoor semantic navigation approaches exist, they either rely on reactive\npolicies based on current observations, which tend to produce short-sighted\nbehaviors, or precompute scene graphs offline for navigation, limiting\nadaptability to online deployment. We present RAVEN, a 3D memory-based,\nbehavior tree framework for aerial semantic navigation in unstructured outdoor\nenvironments. It (1) uses a spatially consistent semantic voxel-ray map as\npersistent memory, enabling long-horizon planning and avoiding purely reactive\nbehaviors, (2) combines short-range voxel search and long-range ray search to\nscale to large environments, (3) leverages a large vision-language model to\nsuggest auxiliary cues, mitigating sparsity of outdoor targets. These\ncomponents are coordinated by a behavior tree, which adaptively switches\nbehaviors for robust operation. We evaluate RAVEN in 10 photorealistic outdoor\nsimulation environments over 100 semantic tasks, encompassing single-object\nsearch, multi-class, multi-instance navigation and sequential task changes.\nResults show RAVEN outperforms baselines by 85.25% in simulation and\ndemonstrate its real-world applicability through deployment on an aerial robot\nin outdoor field tests."}
{"id": "2509.23568", "pdf": "https://arxiv.org/pdf/2509.23568", "abs": "https://arxiv.org/abs/2509.23568", "authors": ["Eunho Koo", "Tongseok Lim"], "title": "Node Classification via Simplicial Interaction with Augmented Maximal Clique Selection", "categories": ["cs.SI", "cs.AI", "cs.LG"], "comment": "To appear in Neurocomputing", "summary": "Considering higher-order interactions allows for a more comprehensive\nunderstanding of network structures beyond simple pairwise connections. While\nleveraging all cliques in a network to handle higher-order interactions is\nintuitive, it often leads to computational inefficiencies due to overlapping\ninformation between higher-order and lower-order cliques. To address this\nissue, we propose an augmented maximal clique strategy. Although using only\nmaximal cliques can reduce unnecessary overlap and provide a concise\nrepresentation of the network, certain nodes may still appear in multiple\nmaximal cliques, resulting in imbalanced training data. Therefore, our\naugmented maximal clique approach selectively includes some non-maximal cliques\nto mitigate the overrepresentation of specific nodes and promote more balanced\nlearning across the network. Comparative analyses on synthetic networks and\nreal-world citation datasets demonstrate that our method outperforms approaches\nbased on pairwise interactions, all cliques, or only maximal cliques. Finally,\nby integrating this strategy into GNN-based semi-supervised learning, we\nestablish a link between maximal clique-based methods and GNNs, showing that\nincorporating higher-order structures improves predictive accuracy. As a\nresult, the augmented maximal clique strategy offers a computationally\nefficient and effective solution for higher-order network learning."}
{"id": "2509.23589", "pdf": "https://arxiv.org/pdf/2509.23589", "abs": "https://arxiv.org/abs/2509.23589", "authors": ["Shu Liu", "Wenlin Chen", "Weihao Li", "Zheng Wang", "Lijin Yang", "Jianing Huang", "Yipin Zhang", "Zhongzhan Huang", "Ze Cheng", "Hao Yang"], "title": "BridgeDrive: Diffusion Bridge Policy for Closed-Loop Trajectory Planning in Autonomous Driving", "categories": ["cs.AI", "cs.CV", "cs.LG"], "comment": "16 pages, 7 figures, 6 tables", "summary": "Diffusion-based planners have shown great promise for autonomous driving due\nto their ability to capture multi-modal driving behaviors. However, guiding\nthese models effectively in reactive, closed-loop environments remains a\nsignificant challenge. Simple conditioning often fails to provide sufficient\nguidance in complex and dynamic driving scenarios. Recent work attempts to use\ntypical expert driving behaviors (i.e., anchors) to guide diffusion models but\nrelies on a truncated schedule, which introduces theoretical inconsistencies\nand can compromise performance. To address this, we introduce BridgeDrive, a\nnovel anchor-guided diffusion bridge policy for closed-loop trajectory\nplanning. Our approach provides a principled diffusion framework that\neffectively translates anchors into fine-grained trajectory plans,\nappropriately responding to varying traffic conditions. Our planner is\ncompatible with efficient ODE solvers, a critical factor for real-time\nautonomous driving deployment. We achieve state-of-the-art performance on the\nBench2Drive benchmark, improving the success rate by 5% over prior arts."}
{"id": "2509.23609", "pdf": "https://arxiv.org/pdf/2509.23609", "abs": "https://arxiv.org/abs/2509.23609", "authors": ["Yuhan Cheng", "Heyang Zhou", "Yanchu Liu"], "title": "Large Language Models and Futures Price Factors in China", "categories": ["q-fin.PR", "cs.LG"], "comment": "46 pages;1 figure", "summary": "We leverage the capacity of large language models such as Generative\nPre-trained Transformer (GPT) in constructing factor models for Chinese futures\nmarkets. We successfully obtain 40 factors to design single-factor and\nmulti-factor portfolios through long-short and long-only strategies, conducting\nbacktests during the in-sample and out-of-sample period. Comprehensive\nempirical analysis reveals that GPT-generated factors deliver remarkable Sharpe\nratios and annualized returns while maintaining acceptable maximum drawdowns.\nNotably, the GPT-based factor models also achieve significant alphas over the\nIPCA benchmark. Moreover, these factors demonstrate significant performance\nacross extensive robustness tests, particularly excelling after the cutoff date\nof GPT's training data."}
{"id": "2509.23611", "pdf": "https://arxiv.org/pdf/2509.23611", "abs": "https://arxiv.org/abs/2509.23611", "authors": ["Jianwei Qin", "Yanbing Liu", "Yan Liu", "Xun Liu", "Wei Li", "Fangwei Ye"], "title": "Spatially Parallel All-optical Neural Networks", "categories": ["physics.optics", "cs.LG"], "comment": "13 pages, 4 figures", "summary": "All-optical neural networks (AONNs) have emerged as a promising paradigm for\nultrafast and energy-efficient computation. These networks typically consist of\nmultiple serially connected layers between input and output layers--a\nconfiguration we term spatially series AONNs, with deep neural networks (DNNs)\nbeing the most prominent examples. However, such series architectures suffer\nfrom progressive signal degradation during information propagation and\ncritically require additional nonlinearity designs to model complex\nrelationships effectively. Here we propose a spatially parallel architecture\nfor all-optical neural networks (SP-AONNs). Unlike series architecture that\nsequentially processes information through consecutively connected optical\nlayers, SP-AONNs divide the input signal into identical copies fed\nsimultaneously into separate optical layers. Through coherent interference\nbetween these parallel linear sub-networks, SP-AONNs inherently enable\nnonlinear computation without relying on active nonlinear components or\niterative updates. We implemented a modular 4F optical system for SP-AONNs and\nevaluated its performance across multiple image classification benchmarks.\nExperimental results demonstrate that increasing the number of parallel\nsub-networks consistently enhances accuracy, improves noise robustness, and\nexpands model expressivity. Our findings highlight spatial parallelism as a\npractical and scalable strategy for advancing the capabilities of optical\nneural computing."}
{"id": "2509.23620", "pdf": "https://arxiv.org/pdf/2509.23620", "abs": "https://arxiv.org/abs/2509.23620", "authors": ["Kyung-bin Kwon", "Lintao Ye", "Vijay Gupta", "Hao Zhu"], "title": "Communication-aware Wide-Area Damping Control using Risk-Constrained Reinforcement Learning", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": "12 pages, 14 figures, Accepted for publication in IEEE Transactions\n  on Smart Grid, 2025", "summary": "Non-ideal communication links, especially delays, critically affect fast\nnetworked controls in power systems, such as the wide-area damping control\n(WADC). Traditionally, a delay estimation and compensation approach is adopted\nto address this cyber-physical coupling, but it demands very high accuracy for\nthe fast WADC and cannot handle other cyber concerns like link failures or\n{cyber perturbations}. Hence, we propose a new risk-constrained framework that\ncan target the communication delays, yet amenable to general uncertainty under\nthe cyber-physical couplings. Our WADC model includes the synchronous\ngenerators (SGs), and also voltage source converters (VSCs) for additional\ndamping capabilities. To mitigate uncertainty, a mean-variance risk constraint\nis introduced to the classical optimal control cost of the linear quadratic\nregulator (LQR). Unlike estimating delays, our approach can effectively\nmitigate large communication delays by improving the worst-case performance. A\nreinforcement learning (RL)-based algorithm, namely, stochastic\ngradient-descent with max-oracle (SGDmax), is developed to solve the\nrisk-constrained problem. We further show its guaranteed convergence to\nstationarity at a high probability, even using the simple zero-order policy\ngradient (ZOPG). Numerical tests on the IEEE 68-bus system not only verify\nSGDmax's convergence and VSCs' damping capabilities, but also demonstrate that\nour approach outperforms conventional delay compensator-based methods under\nestimation error. While focusing on performance improvement under large delays,\nour proposed risk-constrained design can effectively mitigate the worst-case\noscillations, making it equally effective for addressing other communication\nissues and cyber perturbations."}
{"id": "2509.23625", "pdf": "https://arxiv.org/pdf/2509.23625", "abs": "https://arxiv.org/abs/2509.23625", "authors": ["YuQian Li", "Limeng Qiao", "Lin Ma"], "title": "RIV: Recursive Introspection Mask Diffusion Vision Language Model", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Mask Diffusion-based Vision Language Models (MDVLMs) have achieved remarkable\nprogress in multimodal understanding tasks. However, these models are unable to\ncorrect errors in generated tokens, meaning they lack self-correction\ncapability. In this paper, we propose Recursive Introspection Mask Diffusion\nVision Language Model (RIV), which equips the model with self-correction\nability through two novel mechanisms. The first is Introspection Training,\nwhere an Introspection Model is introduced to identify errors within generated\nsequences. Introspection Training enables the model to detect not only\ngrammatical and spelling mistakes, but more importantly, logical errors. The\nsecond is Recursive Inference. Beginning with the standard unmasking step, the\nlearned Introspection Model helps to identify errors in the output sequence and\nremask them. This alternating\n($\\text{unmask}\\rightarrow\\text{introspection}\\rightarrow\\text{remask}$)\nprocess is repeated recursively until reliable results are obtained.\nExperimental results on multiple benchmarks demonstrate that the proposed RIV\nachieves state-of-the-art performance, outperforming most existing MDVLMs."}
{"id": "2509.23629", "pdf": "https://arxiv.org/pdf/2509.23629", "abs": "https://arxiv.org/abs/2509.23629", "authors": ["Sihan Hu", "Xiansheng Cai", "Yuan Huang", "Zhiyuan Yao", "Linfeng Zhang", "Pan Zhang", "Youjin Deng", "Kun Chen"], "title": "How LLMs Learn to Reason: A Complex Network Perspective", "categories": ["cs.AI", "cond-mat.dis-nn", "cond-mat.stat-mech", "cs.LG", "physics.soc-ph"], "comment": "24 pages, 11 figures, 1 table, under review as a conference paper at\n  ICLR 2026", "summary": "Training large language models with Reinforcement Learning from Verifiable\nRewards (RLVR) exhibits a set of distinctive and puzzling behaviors that remain\npoorly understood, including a two-stage learning curve, V-shaped\nresponse-length trajectories, and a pronounced vulnerability to catastrophic\nforgetting. In this work, we propose that these seemingly disparate phenomena\ncan be explained using a single unifying theory: the model's reasoning process\nmaps to the self-organization of a semantic complex network whose topology\nremains persistently sparse, with the average degree pinned close to two. This\ntopology imposes a fundamental mechanism for forgetting and learning: it first\ndrives the system into a maximally frustrated state where ``skill islands''\nform, slow-learning happens, and forgetting is induced; then it enters a sharp\ngrowth phase where the new skills are ``bolted on'', driven by\nphase-transition-like learning at the web's frontier. Equipped with the theory,\nwe propose \\textit{Annealed-RLVR}, a principled algorithm that introduces an\nSFT-based ``heating'' step at the point of maximal frustration to resolve the\ncompetitive bottleneck and enhance the reasoning capability of the model.\nExperiments on a 1.5B-parameter model demonstrate that the approach outperforms\nstandard RLVR on both in-distribution and out-of-distribution benchmarks. By\nrecasting RLVR from black-box optimization into a predictable process of\nstructural self-organization, our work provides a new physical intuition for\nengineering the emergent reasoning capabilities of future AI systems."}
{"id": "2509.23639", "pdf": "https://arxiv.org/pdf/2509.23639", "abs": "https://arxiv.org/abs/2509.23639", "authors": ["Boyu Han", "Qianqian Xu", "Shilong Bao", "Zhiyong Yang", "Kangli Zi", "Qingming Huang"], "title": "LightFair: Towards an Efficient Alternative for Fair T2I Diffusion via Debiasing Pre-trained Text Encoders", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "This paper explores a novel lightweight approach LightFair to achieve fair\ntext-to-image diffusion models (T2I DMs) by addressing the adverse effects of\nthe text encoder. Most existing methods either couple different parts of the\ndiffusion model for full-parameter training or rely on auxiliary networks for\ncorrection. They incur heavy training or sampling burden and unsatisfactory\nperformance. Since T2I DMs consist of multiple components, with the text\nencoder being the most fine-tunable and front-end module, this paper focuses on\nmitigating bias by fine-tuning text embeddings. To validate feasibility, we\nobserve that the text encoder's neutral embedding output shows substantial\nskewness across image embeddings of various attributes in the CLIP space. More\nimportantly, the noise prediction network further amplifies this imbalance. To\nfinetune the text embedding, we propose a collaborative distance-constrained\ndebiasing strategy that balances embedding distances to improve fairness\nwithout auxiliary references. However, mitigating bias can compromise the\noriginal generation quality. To address this, we introduce a two-stage\ntext-guided sampling strategy to limit when the debiased text encoder\nintervenes. Extensive experiments demonstrate that LightFair is effective and\nefficient. Notably, on Stable Diffusion v1.5, our method achieves SOTA\ndebiasing at just $1/4$ of the training burden, with virtually no increase in\nsampling burden. The code is available at https://github.com/boyuh/LightFair."}
{"id": "2509.23655", "pdf": "https://arxiv.org/pdf/2509.23655", "abs": "https://arxiv.org/abs/2509.23655", "authors": ["Rokas Bendikas", "Daniel Dijkman", "Markus Peschl", "Sanjay Haresh", "Pietro Mazzaglia"], "title": "Focusing on What Matters: Object-Agent-centric Tokenization for Vision Language Action models", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "comment": "Presented at 9th Conference on Robot Learning (CoRL 2025), Seoul,\n  Korea", "summary": "Vision-Language-Action (VLA) models offer a pivotal approach to learning\nrobotic manipulation at scale by repurposing large pre-trained\nVision-Language-Models (VLM) to output robotic actions. However, adapting VLMs\nfor robotic domains comes with an unnecessarily high computational cost, which\nwe attribute to the tokenization scheme of visual inputs. In this work, we aim\nto enable efficient VLA training by proposing Oat-VLA, an Object-Agent-centric\nTokenization for VLAs. Building on the insights of object-centric\nrepresentation learning, our method introduces an inductive bias towards scene\nobjects and the agent's own visual information. As a result, we find that\nOat-VLA can drastically reduce the number of visual tokens to just a few tokens\nwithout sacrificing performance. We reveal that Oat-VLA converges at least\ntwice as fast as OpenVLA on the LIBERO suite, as well as outperform OpenVLA in\ndiverse real-world pick and place tasks."}
{"id": "2509.23697", "pdf": "https://arxiv.org/pdf/2509.23697", "abs": "https://arxiv.org/abs/2509.23697", "authors": ["Atharva Jadhav", "Arush Karekar", "Manas Divekar", "Shachi Natu"], "title": "Confidence Aware SSD Ensemble with Weighted Boxes Fusion for Weapon Detection", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "The safety and security of public spaces is of vital importance, driving the\nneed for sophisticated surveillance systems capable of accurately detecting\nweapons, which are often hampered by issues like partial occlusion, varying\nlighting, and cluttered backgrounds. While single-model detectors are advanced,\nthey often lack robustness in these challenging conditions. This paper presents\nthe hypothesis that ensemble of Single Shot Multibox Detector (SSD) models with\ndiverse feature extraction backbones can significantly enhance detection\nrobustness. To leverage diverse feature representations, individual SSD models\nwere trained using a selection of backbone networks: VGG16, ResNet50,\nEfficientNet, and MobileNetV3. The study is conducted on a dataset consisting\nof images of three distinct weapon classes: guns, heavy weapons and knives. The\npredictions from these models are combined using the Weighted Boxes Fusion\n(WBF) method, an ensemble technique designed to optimize bounding box accuracy.\nOur key finding is that the fusion strategy is as critical as the ensemble's\ndiversity, a WBF approach using a 'max' confidence scoring strategy achieved a\nmean Average Precision (mAP) of 0.838. This represents a 2.948% relative\nimprovement over the best-performing single model and consistently outperforms\nother fusion heuristics. This research offers a robust approach to enhancing\nreal-time weapon detection capabilities in surveillance applications by\ndemonstrating that confidence-aware fusion is a key mechanism for improving\naccuracy metrics of ensembles."}
{"id": "2509.23703", "pdf": "https://arxiv.org/pdf/2509.23703", "abs": "https://arxiv.org/abs/2509.23703", "authors": ["Zhenyu Shu", "Jian Yao", "Shiqing Xin"], "title": "DFG-PCN: Point Cloud Completion with Degree-Flexible Point Graph", "categories": ["cs.GR", "cs.CV", "cs.LG"], "comment": null, "summary": "Point cloud completion is a vital task focused on reconstructing complete\npoint clouds and addressing the incompleteness caused by occlusion and limited\nsensor resolution. Traditional methods relying on fixed local region\npartitioning, such as k-nearest neighbors, which fail to account for the highly\nuneven distribution of geometric complexity across different regions of a\nshape. This limitation leads to inefficient representation and suboptimal\nreconstruction, especially in areas with fine-grained details or structural\ndiscontinuities. This paper proposes a point cloud completion framework called\nDegree-Flexible Point Graph Completion Network (DFG-PCN). It adaptively assigns\nnode degrees using a detail-aware metric that combines feature variation and\ncurvature, focusing on structurally important regions. We further introduce a\ngeometry-aware graph integration module that uses Manhattan distance for edge\naggregation and detail-guided fusion of local and global features to enhance\nrepresentation. Extensive experiments on multiple benchmark datasets\ndemonstrate that our method consistently outperforms state-of-the-art\napproaches."}
{"id": "2509.23709", "pdf": "https://arxiv.org/pdf/2509.23709", "abs": "https://arxiv.org/abs/2509.23709", "authors": ["Zhenyu Shu", "Jiajun Shen", "Zhongui Chen", "Xiaoguang Han", "Shiqing Xin"], "title": "StrucADT: Generating Structure-controlled 3D Point Clouds with Adjacency Diffusion Transformer", "categories": ["cs.GR", "cs.CV", "cs.LG"], "comment": null, "summary": "In the field of 3D point cloud generation, numerous 3D generative models have\ndemonstrated the ability to generate diverse and realistic 3D shapes. However,\nthe majority of these approaches struggle to generate controllable 3D point\ncloud shapes that meet user-specific requirements, hindering the large-scale\napplication of 3D point cloud generation. To address the challenge of lacking\ncontrol in 3D point cloud generation, we are the first to propose controlling\nthe generation of point clouds by shape structures that comprise part\nexistences and part adjacency relationships. We manually annotate the adjacency\nrelationships between the segmented parts of point cloud shapes, thereby\nconstructing a StructureGraph representation. Based on this StructureGraph\nrepresentation, we introduce StrucADT, a novel structure-controllable point\ncloud generation model, which consists of StructureGraphNet module to extract\nstructure-aware latent features, cCNF Prior module to learn the distribution of\nthe latent features controlled by the part adjacency, and Diffusion Transformer\nmodule conditioned on the latent features and part adjacency to generate\nstructure-consistent point cloud shapes. Experimental results demonstrate that\nour structure-controllable 3D point cloud generation method produces\nhigh-quality and diverse point cloud shapes, enabling the generation of\ncontrollable point clouds based on user-specified shape structures and\nachieving state-of-the-art performance in controllable point cloud generation\non the ShapeNet dataset."}
{"id": "2509.23715", "pdf": "https://arxiv.org/pdf/2509.23715", "abs": "https://arxiv.org/abs/2509.23715", "authors": ["Eduard Barbu", "Adrian Marius Dumitran"], "title": "Do LLMs Understand Romanian Driving Laws? A Study on Multimodal and Fine-Tuned Question Answering", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted@ CONSILR 2025 Bucharest Romania 9-10 October", "summary": "Ensuring that both new and experienced drivers master current traffic rules\nis critical to road safety. This paper evaluates Large Language Models (LLMs)\non Romanian driving-law QA with explanation generation. We release a\n1{,}208-question dataset (387 multimodal) and compare text-only and multimodal\nSOTA systems, then measure the impact of domain-specific fine-tuning for Llama\n3.1-8B-Instruct and RoLlama 3.1-8B-Instruct. SOTA models perform well, but\nfine-tuned 8B models are competitive. Textual descriptions of images outperform\ndirect visual input. Finally, an LLM-as-a-Judge assesses explanation quality,\nrevealing self-preference bias. The study informs explainable QA for\nless-resourced languages."}
{"id": "2509.23718", "pdf": "https://arxiv.org/pdf/2509.23718", "abs": "https://arxiv.org/abs/2509.23718", "authors": ["Zhenyu Shu", "Jiawei Wen", "Shiyang Li", "Shiqing Xin", "Ligang Liu"], "title": "Diff-3DCap: Shape Captioning with Diffusion Models", "categories": ["cs.GR", "cs.CV", "cs.LG"], "comment": null, "summary": "The task of 3D shape captioning occupies a significant place within the\ndomain of computer graphics and has garnered considerable interest in recent\nyears. Traditional approaches to this challenge frequently depend on the\nutilization of costly voxel representations or object detection techniques, yet\noften fail to deliver satisfactory outcomes. To address the above challenges,\nin this paper, we introduce Diff-3DCap, which employs a sequence of projected\nviews to represent a 3D object and a continuous diffusion model to facilitate\nthe captioning process. More precisely, our approach utilizes the continuous\ndiffusion model to perturb the embedded captions during the forward phase by\nintroducing Gaussian noise and then predicts the reconstructed annotation\nduring the reverse phase. Embedded within the diffusion framework is a\ncommitment to leveraging a visual embedding obtained from a pre-trained\nvisual-language model, which naturally allows the embedding to serve as a\nguiding signal, eliminating the need for an additional classifier. Extensive\nresults of our experiments indicate that Diff-3DCap can achieve performance\ncomparable to that of the current state-of-the-art methods."}
{"id": "2509.23729", "pdf": "https://arxiv.org/pdf/2509.23729", "abs": "https://arxiv.org/abs/2509.23729", "authors": ["Shubhang Bhatnagar", "Andy Xu", "Kar-Han Tan", "Narendra Ahuja"], "title": "LUQ: Layerwise Ultra-Low Bit Quantization for Multimodal Large Language Models", "categories": ["cs.CV", "cs.AI", "cs.LG", "eess.IV"], "comment": null, "summary": "Large Language Models (LLMs) with multimodal capabilities have revolutionized\nvision-language tasks, but their deployment often requires huge memory and\ncomputational resources. While post-training quantization (PTQ) has\nsuccessfully compressed language models to as low as 1-bit precision without\nsignificant performance loss, its effectiveness for multimodal LLMs (MLLMs)\nremains relatively unexplored. In this paper, we present the first study on\nultra-low bit (<4-bit) quantization for multimodal LLMs. Our analysis reveals\nthat multimodal tokens and intermediate layer activations produced by them\nexhibit significantly higher statistical variance and entropy compared to text\ntokens, making them less tolerant to ultra-low bit quantization. However, the\nactivation distributions of multimodal tokens varies significantly over\ndifferent layers, with some layers having lower entropy activation\ndistributions. We empirically show that such layers in these models can better\ntolerate ultra-low bit quantization. Building on these insights, we propose a\nnovel strategy for MLLM quantization, LUQ: Layerwise Ultra-Low Bit\nQuantization, which selectively applies ultra-low bit quantization to layers\nthat are more resilient to it. Additionally, we also show that using a mix of\nmultimodal tokens (image and text) for PTQ boosts VQA performance in the\nultra-low bit regime. We evaluate our method on LLaVA-1.5 and Qwen-2.5-VL\nacross 9 popular VQA benchmarks. The resulting LUQ models use 40% and 31% less\nmemory than their 4-bit counterparts, respectively, while exhibiting a\nperformance degradation of less than 10% on the MME benchmark."}
{"id": "2509.23759", "pdf": "https://arxiv.org/pdf/2509.23759", "abs": "https://arxiv.org/abs/2509.23759", "authors": ["Ting-Kang Wang", "Yueh-Po Peng", "Li Su", "Vincent K. M. Cheung"], "title": "VioPTT: Violin Technique-Aware Transcription from Synthetic Data Augmentation", "categories": ["cs.SD", "cs.LG"], "comment": null, "summary": "While automatic music transcription is well-established in music information\nretrieval, most models are limited to transcribing pitch and timing information\nfrom audio, and thus omit crucial expressive and instrument-specific nuances.\nOne example is playing technique on the violin, which affords its distinct\npalette of timbres for maximal emotional impact. Here, we propose\n\\textbf{VioPTT} (Violin Playing Technique-aware Transcription), a lightweight,\nend-to-end model that directly transcribes violin playing technique in addition\nto pitch onset and offset. Furthermore, we release \\textbf{MOSA-VPT}, a novel,\nhigh-quality synthetic violin playing technique dataset to circumvent the need\nfor manually labeled annotations. Leveraging this dataset, our model\ndemonstrated strong generalization to real-world note-level violin technique\nrecordings in addition to achieving state-of-the-art transcription performance.\nTo our knowledge, VioPTT is the first to jointly combine violin transcription\nand playing technique prediction within a unified framework."}
{"id": "2509.23765", "pdf": "https://arxiv.org/pdf/2509.23765", "abs": "https://arxiv.org/abs/2509.23765", "authors": ["Junliang Li", "Yucheng Wang", "Yan Chen", "Yu Ran", "Ruiqing Zhang", "Jing Liu", "Hua Wu", "Haifeng Wang"], "title": "Knowledge-Level Consistency Reinforcement Learning: Dual-Fact Alignment for Long-Form Factuality", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Hallucination and factuality deficits remain key obstacles to the reliability\nof large language models (LLMs) in long-form generation. Existing reinforcement\nlearning from human feedback (RLHF) frameworks primarily rely on preference\nrewards, yet they often overlook the model's internal knowledge boundaries,\nexacerbating the so-called \"hallucination tax\". To address this challenge, we\npropose Knowledge-Level Consistency Reinforcement Learning Framework (KLCF), a\nnovel framework that focuses on the knowledge consistency between the policy\nmodel's expressed knowledge and the base model's parametric knowledge, and\nintroduces a Dual-Fact Alignment mechanism to jointly optimize factual recall\nand precision. Specifically, KLCF leverages pretrained knowledge boundaries to\nconstruct fact checklist, guiding online reinforcement learning to improve\nfactual coverage and recall; simultaneously, it trains a self-assessment module\nbased on the base model's internal knowledge to enhance factual precision\nduring generation. Unlike prior methods that rely on external retrieval or\nheavy verification, our reward design is fully external-knowledge-free and\nlightweight, making KLCF efficient and easily scalable to large-scale training.\nExperimental results demonstrate that KLCF substantially improves factuality\nmetrics across multiple long-form benchmarks and effectively alleviates model\nhallucinations."}
{"id": "2509.23778", "pdf": "https://arxiv.org/pdf/2509.23778", "abs": "https://arxiv.org/abs/2509.23778", "authors": ["Zeyuan Zhang", "Chaoran Li", "Shao Zhang", "Ying Wen"], "title": "Sequence Pathfinder for Multi-Agent Pickup and Delivery in the Warehouse", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.MA"], "comment": "Preprint Under Review", "summary": "Multi-Agent Pickup and Delivery (MAPD) is a challenging extension of\nMulti-Agent Path Finding (MAPF), where agents are required to sequentially\ncomplete tasks with fixed-location pickup and delivery demands. Although\nlearning-based methods have made progress in MAPD, they often perform poorly in\nwarehouse-like environments with narrow pathways and long corridors when\nrelying only on local observations for distributed decision-making.\nCommunication learning can alleviate the lack of global information but\nintroduce high computational complexity due to point-to-point communication. To\naddress this challenge, we formulate MAPF as a sequence modeling problem and\nprove that path-finding policies under sequence modeling possess\norder-invariant optimality, ensuring its effectiveness in MAPD. Building on\nthis, we propose the Sequential Pathfinder (SePar), which leverages the\nTransformer paradigm to achieve implicit information exchange, reducing\ndecision-making complexity from exponential to linear while maintaining\nefficiency and global awareness. Experiments demonstrate that SePar\nconsistently outperforms existing learning-based methods across various MAPF\ntasks and their variants, and generalizes well to unseen environments.\nFurthermore, we highlight the necessity of integrating imitation learning in\ncomplex maps like warehouses."}
{"id": "2509.23800", "pdf": "https://arxiv.org/pdf/2509.23800", "abs": "https://arxiv.org/abs/2509.23800", "authors": ["Samuel Willis", "Alexandru I. Stere", "Dragos D. Margineantu", "Henry T. Oldroyd", "John A. Fozard", "Carl Henrik Ek", "Henry Moss", "Erik Bodin"], "title": "Define latent spaces by example: optimisation over the outputs of generative models", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Modern generative AI models such as diffusion and flow matching can sample\nfrom rich data distributions, but many downstream tasks -- such as experimental\ndesign or creative content generation -- require a higher level of control than\nunconstrained sampling. The challenge is to efficiently identify outputs that\nare both probable under the model and satisfy task-specific constraints. We\naddress this by introducing surrogate latent spaces: non-parametric,\nlow-dimensional Euclidean embeddings that can be extracted from any generative\nmodel without additional training. The axes in the Euclidean space can be\ndefined via examples, providing a simple and interpretable approach to define\ncustom latent spaces that both express intended features and are convenient to\nuse in downstream tasks. The representation is Euclidean and has controllable\ndimensionality, permitting direct application of standard optimisation\nalgorithms to traverse the outputs of generative models. Our approach is\narchitecture-agnostic, incurs almost no additional computational cost, and\ngeneralises across modalities, including images, audio, videos, and structured\nobjects like proteins."}
{"id": "2509.23806", "pdf": "https://arxiv.org/pdf/2509.23806", "abs": "https://arxiv.org/abs/2509.23806", "authors": ["Chih-Duo Hong", "Yu Wang", "Yao-Chen Chang", "Fang Yu"], "title": "Influence-Guided Concolic Testing of Transformer Robustness", "categories": ["cs.SE", "cs.LG"], "comment": null, "summary": "Concolic testing for deep neural networks alternates concrete execution with\nconstraint solving to search for inputs that flip decisions. We present an\n{influence-guided} concolic tester for Transformer classifiers that ranks path\npredicates by SHAP-based estimates of their impact on the model output. To\nenable SMT solving on modern architectures, we prototype a solver-compatible,\npure-Python semantics for multi-head self-attention and introduce practical\nscheduling heuristics that temper constraint growth on deeper models. In a\nwhite-box study on compact Transformers under small $L_0$ budgets, influence\nguidance finds label-flip inputs more efficiently than a FIFO baseline and\nmaintains steady progress on deeper networks. Aggregating successful attack\ninstances with a SHAP-based critical decision path analysis reveals recurring,\ncompact decision logic shared across attacks. These observations suggest that\n(i) influence signals provide a useful search bias for symbolic exploration,\nand (ii) solver-friendly attention semantics paired with lightweight scheduling\nmake concolic testing feasible for contemporary Transformer models, offering\npotential utility for debugging and model auditing."}
{"id": "2509.23815", "pdf": "https://arxiv.org/pdf/2509.23815", "abs": "https://arxiv.org/abs/2509.23815", "authors": ["Ali Nazeri", "Shashank Mishra", "Achim Wagner", "Martin Ruskowski", "Didier Stricker", "Jason Rambach"], "title": "A Multi-Camera Vision-Based Approach for Fine-Grained Assembly Quality Control", "categories": ["cs.CV", "cs.AI", "cs.LG", "68T45", "I.4.8; I.4.1; I.2.10"], "comment": "6 pages, 3 figures. Accepted for presentation at EUSIPCO 2025\n  (European Signal Processing Conference)", "summary": "Quality control is a critical aspect of manufacturing, particularly in\nensuring the proper assembly of small components in production lines. Existing\nsolutions often rely on single-view imaging or manual inspection, which are\nprone to errors due to occlusions, restricted perspectives, or lighting\ninconsistencies. These limitations require the installation of additional\ninspection stations, which could disrupt the assembly line and lead to\nincreased downtime and costs. This paper introduces a novel multi-view quality\ncontrol module designed to address these challenges, integrating a multi-camera\nimaging system with advanced object detection algorithms. By capturing images\nfrom three camera views, the system provides comprehensive visual coverage of\ncomponents of an assembly process. A tailored image fusion methodology combines\nresults from multiple views, effectively resolving ambiguities and enhancing\ndetection reliability. To support this system, we developed a unique dataset\ncomprising annotated images across diverse scenarios, including varied lighting\nconditions, occlusions, and angles, to enhance applicability in real-world\nmanufacturing environments. Experimental results show that our approach\nsignificantly outperforms single-view methods, achieving high precision and\nrecall rates in the identification of improperly fastened small assembly parts\nsuch as screws. This work contributes to industrial automation by overcoming\nsingle-view limitations, and providing a scalable, cost-effective, and accurate\nquality control mechanism that ensures the reliability and safety of the\nassembly line. The dataset used in this study is publicly available to\nfacilitate further research in this domain."}
{"id": "2509.23827", "pdf": "https://arxiv.org/pdf/2509.23827", "abs": "https://arxiv.org/abs/2509.23827", "authors": ["Efthymios Tsaprazlis", "Tiantian Feng", "Anil Ramakrishna", "Rahul Gupta", "Shrikanth Narayanan"], "title": "Assessing Visual Privacy Risks in Multimodal AI: A Novel Taxonomy-Grounded Evaluation of Vision-Language Models", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Artificial Intelligence have profoundly transformed the technological\nlandscape in recent years. Large Language Models (LLMs) have demonstrated\nimpressive abilities in reasoning, text comprehension, contextual pattern\nrecognition, and integrating language with visual understanding. While these\nadvances offer significant benefits, they also reveal critical limitations in\nthe models' ability to grasp the notion of privacy. There is hence substantial\ninterest in determining if and how these models can understand and enforce\nprivacy principles, particularly given the lack of supporting resources to test\nsuch a task. In this work, we address these challenges by examining how legal\nframeworks can inform the capabilities of these emerging technologies. To this\nend, we introduce a comprehensive, multi-level Visual Privacy Taxonomy that\ncaptures a wide range of privacy issues, designed to be scalable and adaptable\nto existing and future research needs. Furthermore, we evaluate the\ncapabilities of several state-of-the-art Vision-Language Models (VLMs),\nrevealing significant inconsistencies in their understanding of contextual\nprivacy. Our work contributes both a foundational taxonomy for future research\nand a critical benchmark of current model limitations, demonstrating the urgent\nneed for more robust, privacy-aware AI systems."}
{"id": "2509.23871", "pdf": "https://arxiv.org/pdf/2509.23871", "abs": "https://arxiv.org/abs/2509.23871", "authors": ["Yukun Chen", "Boheng Li", "Yu Yuan", "Leyi Qi", "Yiming Li", "Tianwei Zhang", "Zhan Qin", "Kui Ren"], "title": "Taught Well Learned Ill: Towards Distillation-conditional Backdoor Attack", "categories": ["cs.CR", "cs.AI", "cs.CV", "cs.LG"], "comment": "The first three authors contributed equally to this work. To appear\n  in NeurIPS 2025. 35 pages", "summary": "Knowledge distillation (KD) is a vital technique for deploying deep neural\nnetworks (DNNs) on resource-constrained devices by transferring knowledge from\nlarge teacher models to lightweight student models. While teacher models from\nthird-party platforms may undergo security verification (\\eg, backdoor\ndetection), we uncover a novel and critical threat: distillation-conditional\nbackdoor attacks (DCBAs). DCBA injects dormant and undetectable backdoors into\nteacher models, which become activated in student models via the KD process,\neven with clean distillation datasets. While the direct extension of existing\nmethods is ineffective for DCBA, we implement this attack by formulating it as\na bilevel optimization problem and proposing a simple yet effective method\n(\\ie, SCAR). Specifically, the inner optimization simulates the KD process by\noptimizing a surrogate student model, while the outer optimization leverages\noutputs from this surrogate to optimize the teacher model for implanting the\nconditional backdoor. Our SCAR addresses this complex optimization utilizing an\nimplicit differentiation algorithm with a pre-optimized trigger injection\nfunction. Extensive experiments across diverse datasets, model architectures,\nand KD techniques validate the effectiveness of our SCAR and its resistance\nagainst existing backdoor detection, highlighting a significant yet previously\noverlooked vulnerability in the KD process. Our code is available at\nhttps://github.com/WhitolfChen/SCAR."}
{"id": "2509.23961", "pdf": "https://arxiv.org/pdf/2509.23961", "abs": "https://arxiv.org/abs/2509.23961", "authors": ["Sheikh Md Mushfiqur Rahman", "Nasir Eisty"], "title": "Learning-Based Testing for Deep Learning: Enhancing Model Robustness with Adversarial Input Prioritization", "categories": ["cs.SE", "cs.LG"], "comment": null, "summary": "Context: Deep Neural Networks (DNNs) are increasingly deployed in critical\napplications, where resilience against adversarial inputs is paramount.\nHowever, whether coverage-based or confidence-based, existing test\nprioritization methods often fail to efficiently identify the most\nfault-revealing inputs, limiting their practical effectiveness. Aims: This\nproject aims to enhance fault detection and model robustness in DNNs by\nintegrating Learning-Based Testing (LBT) with hypothesis and mutation testing\nto efficiently prioritize adversarial test cases. Methods: Our method selects a\nsubset of adversarial inputs with a high likelihood of exposing model faults,\nwithout relying on architecture-specific characteristics or formal\nverification, making it adaptable across diverse DNNs. Results: Our results\ndemonstrate that the proposed LBT method consistently surpasses baseline\napproaches in prioritizing fault-revealing inputs and accelerating fault\ndetection. By efficiently organizing test permutations, it uncovers all\npotential faults significantly faster across various datasets, model\narchitectures, and adversarial attack techniques. Conclusion: Beyond improving\nfault detection, our method preserves input diversity and provides effective\nguidance for model retraining, further enhancing robustness. These advantages\nestablish our approach as a powerful and practical solution for adversarial\ntest prioritization in real-world DNN applications."}
{"id": "2509.23975", "pdf": "https://arxiv.org/pdf/2509.23975", "abs": "https://arxiv.org/abs/2509.23975", "authors": ["Gianluca Fabiani", "Constantinos Siettos", "Ioannis G. Kevrekidis"], "title": "Equation-Free Coarse Control of Distributed Parameter Systems via Local Neural Operators", "categories": ["eess.SY", "cs.LG", "cs.NA", "cs.SY", "math.NA", "math.OC", "93B52, 93C20, 47N70, 65J15, 65M32, 68T07, 68T20, 68T05,"], "comment": "8 pages, 2 figures", "summary": "The control of high-dimensional distributed parameter systems (DPS) remains a\nchallenge when explicit coarse-grained equations are unavailable. Classical\nequation-free (EF) approaches rely on fine-scale simulators treated as\nblack-box timesteppers. However, repeated simulations for steady-state\ncomputation, linearization, and control design are often computationally\nprohibitive, or the microscopic timestepper may not even be available, leaving\nus with data as the only resource. We propose a data-driven alternative that\nuses local neural operators, trained on spatiotemporal microscopic/mesoscopic\ndata, to obtain efficient short-time solution operators. These surrogates are\nemployed within Krylov subspace methods to compute coarse steady and\nunsteady-states, while also providing Jacobian information in a matrix-free\nmanner. Krylov-Arnoldi iterations then approximate the dominant eigenspectrum,\nyielding reduced models that capture the open-loop slow dynamics without\nexplicit Jacobian assembly. Both discrete-time Linear Quadratic Regulator\n(dLQR) and pole-placement (PP) controllers are based on this reduced system and\nlifted back to the full nonlinear dynamics, thereby closing the feedback loop."}
{"id": "2509.23982", "pdf": "https://arxiv.org/pdf/2509.23982", "abs": "https://arxiv.org/abs/2509.23982", "authors": ["Lucio La Cava", "Andrea Tagarelli"], "title": "Toward Preference-aligned Large Language Models via Residual-based Model Steering", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG", "cs.NE"], "comment": null, "summary": "Preference alignment is a critical step in making Large Language Models\n(LLMs) useful and aligned with (human) preferences. Existing approaches such as\nReinforcement Learning from Human Feedback or Direct Preference Optimization\ntypically require curated data and expensive optimization over billions of\nparameters, and eventually lead to persistent task-specific models. In this\nwork, we introduce Preference alignment of Large Language Models via Residual\nSteering (PaLRS), a training-free method that exploits preference signals\nencoded in the residual streams of LLMs. From as few as one hundred preference\npairs, PaLRS extracts lightweight, plug-and-play steering vectors that can be\napplied at inference time to push models toward preferred behaviors. We\nevaluate PaLRS on various small-to-medium-scale open-source LLMs, showing that\nPaLRS-aligned models achieve consistent gains on mathematical reasoning and\ncode generation benchmarks while preserving baseline general-purpose\nperformance. Moreover, when compared to DPO-aligned models, they perform better\nwith huge time savings. Our findings highlight that PaLRS offers an effective,\nmuch more efficient and flexible alternative to standard preference\noptimization pipelines, offering a training-free, plug-and-play mechanism for\nalignment with minimal data."}
{"id": "2509.23999", "pdf": "https://arxiv.org/pdf/2509.23999", "abs": "https://arxiv.org/abs/2509.23999", "authors": ["Diane Kim", "Minh Nguyen Nhat To", "Sherif Abdalla", "Teresa S. M. Tsang", "Purang Abolmaesumi", "and Christina Luong"], "title": "TREAT-Net: Tabular-Referenced Echocardiography Analysis for Acute Coronary Syndrome Treatment Prediction", "categories": ["cs.CV", "cs.LG"], "comment": "11 pages, 2 figures, MICCAI ASMUS 2025 paper", "summary": "Coronary angiography remains the gold standard for diagnosing Acute Coronary\nSyndrome (ACS). However, its resource-intensive and invasive nature can expose\npatients to procedural risks and diagnostic delays, leading to postponed\ntreatment initiation. In this work, we introduce TREAT-Net, a multimodal deep\nlearning framework for ACS treatment prediction that leverages non-invasive\nmodalities, including echocardiography videos and structured clinical records.\nTREAT-Net integrates tabular-guided cross-attention to enhance video\ninterpretation, along with a late fusion mechanism to align predictions across\nmodalities. Trained on a dataset of over 9000 ACS cases, the model outperforms\nunimodal and non-fused baselines, achieving a balanced accuracy of 67.6% and an\nAUROC of 71.1%. Cross-modality agreement analysis demonstrates 88.6% accuracy\nfor intervention prediction. These findings highlight the potential of\nTREAT-Net as a non-invasive tool for timely and accurate patient triage,\nparticularly in underserved populations with limited access to coronary\nangiography."}
{"id": "2509.24007", "pdf": "https://arxiv.org/pdf/2509.24007", "abs": "https://arxiv.org/abs/2509.24007", "authors": ["Yangzhou Liu", "Yue Cao", "Hao Li", "Gen Luo", "Zhe Chen", "Weiyun Wang", "Xiaobo Liang", "Biqing Qi", "Lijun Wu", "Changyao Tian", "Yanting Zhang", "Yuqiang Li", "Tong Lu", "Yu Qiao", "Jifeng Dai", "Wenhai Wang"], "title": "Sequential Diffusion Language Models", "categories": ["cs.CL", "cs.LG"], "comment": "14 pages, 5 figures, technical report", "summary": "Diffusion language models (DLMs) have strong theoretical efficiency but are\nlimited by fixed-length decoding and incompatibility with key-value (KV)\ncaches. Block diffusion mitigates these issues, yet still enforces a fixed\nblock size and requires expensive training. We introduce Next Sequence\nPrediction (NSP), which unifies next-token and next-block prediction, enabling\nthe model to adaptively determine the generation length at each step. When the\nlength is fixed to 1, NSP reduces to standard next-token prediction. Building\non NSP, we propose Sequential Diffusion Language Model (SDLM), which can\nretrofit pre-trained autoregressive language models (ALMs) at minimal cost.\nSpecifically, SDLM performs diffusion inference within fixed-size mask blocks,\nbut dynamically decodes consecutive subsequences based on model confidence,\nthereby preserving KV-cache compatibility and improving robustness to varying\nuncertainty and semantics across the sequence. Experiments show that SDLM\nmatches or surpasses strong autoregressive baselines using only 3.5M training\nsamples, while achieving 2.1 higher throughput than Qwen-2.5. Notably, the\nSDLM-32B model delivers even more pronounced efficiency gains, demonstrating\nthe strong scalability potential of our modeling paradigm. Project page and\ncodes: https://github.com/OpenGVLab/SDLM"}
{"id": "2509.24024", "pdf": "https://arxiv.org/pdf/2509.24024", "abs": "https://arxiv.org/abs/2509.24024", "authors": ["Anthony W. Lin", "Pablo Barcelo"], "title": "The Role of Logic and Automata in Understanding Transformers", "categories": ["cs.FL", "cs.CL", "cs.LG", "cs.LO"], "comment": "Preprint of invited paper for RP'25", "summary": "The advent of transformers has in recent years led to powerful and\nrevolutionary Large Language Models (LLMs). Despite this, our understanding on\nthe capability of transformers is still meager. In this invited contribution,\nwe recount the rapid progress in the last few years to the question of what\ntransformers can do. In particular, we will see the integral role of logic and\nautomata (also with some help from circuit complexity) in answering this\nquestion. We also mention several open problems at the intersection of logic,\nautomata, verification and transformers."}
{"id": "2509.24095", "pdf": "https://arxiv.org/pdf/2509.24095", "abs": "https://arxiv.org/abs/2509.24095", "authors": ["Tao Wang", "Yan Sun", "Edgar Dobriban"], "title": "Singleton-Optimized Conformal Prediction", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Conformal prediction can be used to construct prediction sets that cover the\ntrue outcome with a desired probability, but can sometimes lead to large\nprediction sets that are costly in practice. The most useful outcome is a\nsingleton prediction-an unambiguous decision-yet existing efficiency-oriented\nmethods primarily optimize average set size. Motivated by this, we propose a\nnew nonconformity score that aims to minimize the probability of producing\nnon-singleton sets. Starting from a non-convex constrained optimization problem\nas a motivation, we provide a geometric reformulation and associated algorithm\nfor computing the nonconformity score and associated split conformal prediction\nsets in O(K) time for K-class problems. Using this score in split conformal\nprediction leads to our proposed Singleton-Optimized Conformal Prediction\n(SOCOP) method. We evaluate our method in experiments on image classification\nand LLM multiple-choice question-answering, comparing with standard\nnonconformity scores such as the (negative) label probability estimates and\ntheir cumulative distribution function; both of which are motivated by\noptimizing length. The results show that SOCOP increases singleton frequency\n(sometimes by over 20%) compared to the above scores, with minimal impact on\naverage set size."}
{"id": "2509.24096", "pdf": "https://arxiv.org/pdf/2509.24096", "abs": "https://arxiv.org/abs/2509.24096", "authors": ["Kaiyu He", "Peilin Wu", "Mian Zhang", "Kun Wan", "Wentian Zhao", "Xinya Du", "Zhiyu Chen"], "title": "GEAR: A General Evaluation Framework for Abductive Reasoning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Coda and Data:\n  https://github.com/KaiyuHe998/GEAR-Abduction_evaluation", "summary": "Since the advent of large language models (LLMs), research has focused on\ninstruction following and deductive reasoning. A central question remains: can\nthese models discover new knowledge, and how can we evaluate this ability? We\naddress this by studying abductive reasoning-the generation of plausible\nhypotheses to explain observations-and introduce GEAR (General Evaluation for\nAbductive Reasoning), a general-purpose, fully automated, transparent, and\nlabel-free evaluation paradigm. GEAR scores hypothesis sets by three metrics:\nconsistency (each hypothesis explains the observations), generalizability\n(consistent hypotheses make meaningful predictions on unseen inputs), and\ndiversity (the set covers distinct predictions and patterns). Built this way,\nGEAR is scalable (no human gold answers), reliable (deterministic scoring\naligned with classical abduction), and open-ended (scores improve only when\nmodels produce new plausible hypotheses, unlike static benchmarks that saturate\nonce accuracy is high). Using GEAR, we conduct a fine-grained study of nine\nLLMs on four abduction benchmarks with 1,500 problems, generating over 50,000\ncandidate hypotheses and revealing model differences obscured by gold-answer or\npurely human evaluations. We further propose a momentum-based curriculum that\nadjusts GEAR-derived training data by learning velocity: it starts with what\nthe model learns quickly and shifts toward harder objectives such as generating\ndiverse hypotheses once the model is confident on foundational objectives.\nWithout gold-label supervision, this strategy improves all GEAR objectives and\nthese gains transfer to established abductive reasoning benchmarks. Taken\ntogether, GEAR provides a principled framework that evaluates abduction and\nsupplies label-free, scalable training signals that help LLMs produce more\ndiverse and reliable hypotheses."}
{"id": "2509.24100", "pdf": "https://arxiv.org/pdf/2509.24100", "abs": "https://arxiv.org/abs/2509.24100", "authors": ["Yeo Jin Jung", "Yating Liu", "Zixuan Wu", "So Won Jeong", "Claire Donnat"], "title": "SpeedCP: Fast Kernel-based Conditional Conformal Prediction", "categories": ["stat.ME", "cs.LG"], "comment": null, "summary": "Conformal prediction provides distribution-free prediction sets with\nfinite-sample conditional guarantees. We build upon the RKHS-based framework of\nGibbs et al. (2023), which leverages families of covariate shifts to provide\napproximate conditional conformal prediction intervals, an approach with strong\ntheoretical promise, but with prohibitive computational cost. To bridge this\ngap, we develop a stable and efficient algorithm that computes the full\nsolution path of the regularized RKHS conformal optimization problem, at\nessentially the same cost as a single kernel quantile fit. Our path-tracing\nframework simultaneously tunes hyperparameters, providing smoothness control\nand data-adaptive calibration. To extend the method to high-dimensional\nsettings, we further integrate our approach with low-rank latent embeddings\nthat capture conditional validity in a data-driven latent space. Empirically,\nour method provides reliable conditional coverage across a variety of modern\nblack-box predictors, improving the interval length of Gibbs et al. (2023) by\n30%, while achieving a 40-fold speedup."}
{"id": "2509.24107", "pdf": "https://arxiv.org/pdf/2509.24107", "abs": "https://arxiv.org/abs/2509.24107", "authors": ["Shreyas Singh", "Kunal Singh", "Pradeep Moturi"], "title": "Fathom-DeepResearch: Unlocking Long Horizon Information Retrieval and Synthesis for SLMs", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Tool-integrated reasoning has emerged as a key focus for enabling agentic\napplications. Among these, DeepResearch Agents have gained significant\nattention for their strong performance on complex, open-ended\ninformation-seeking tasks. We introduce Fathom-DeepResearch, an agentic system\ncomposed of two specialized models. The first is Fathom-Search-4B, a DeepSearch\nmodel trained from Qwen3-4B and optimized for evidence-based investigation\nthrough live web search and targeted webpage querying. Its training combines\nthree advances: (i) DUETQA, a 5K-sample dataset generated via multi-agent\nself-play that enforces strict web-search dependence and heterogeneous source\ngrounding; (ii) RAPO, a zero-overhead extension of GRPO that stabilizes\nmulti-turn Reinforcement Learning with Verifiable Rewards through curriculum\npruning, reward-aware advantage scaling, and per-prompt replay buffers; and\n(iii) a steerable step-level reward that classifies each tool call by cognitive\nbehavior and marginal utility, enabling explicit control over search trajectory\nbreadth, depth, and horizon. These improvements enable reliable extension of\ntool-calling beyond 20 calls when warranted. The second is\nFathom-Synthesizer-4B, trained from Qwen3-4B, which converts multi-turn\nDeepSearch traces into structured, citation-dense DeepResearch Reports for\ncomprehensive synthesis. Evaluated on DeepSearch benchmarks (SimpleQA, FRAMES,\nWebWalker, Seal0, MuSiQue) and DeepResearch-Bench, the system achieves\nstate-of-the-art performance in the open-weights category while demonstrating\nstrong generalization to diverse reasoning tasks including HLE, AIME-25,\nGPQA-Diamond, and MedQA."}
{"id": "2509.24124", "pdf": "https://arxiv.org/pdf/2509.24124", "abs": "https://arxiv.org/abs/2509.24124", "authors": ["Ilari Vallivaara", "Bingnan Duan", "Yinhuan Dong", "Tughrul Arslan"], "title": "Ancestry Tree Clustering for Particle Filter Diversity Maintenance", "categories": ["cs.RO", "cs.AI", "cs.LG", "F.2.2; G.3; I.5.3; F.2.2; I.2.9; G.3; I.5.3"], "comment": "15th International Conference on Indoor Positioning and Indoor\n  Navigation, 15-18 September 2025, Tampere, Finland Originally 8 pages. The\n  online version with appendices is 14 pages", "summary": "We propose a method for linear-time diversity maintenance in particle\nfiltering. It clusters particles based on ancestry tree topology: closely\nrelated particles in sufficiently large subtrees are grouped together. The main\nidea is that the tree structure implicitly encodes similarity without the need\nfor spatial or other domain-specific metrics. This approach, when combined with\nintra-cluster fitness sharing and the protection of particles not included in a\ncluster, effectively prevents premature convergence in multimodal environments\nwhile maintaining estimate compactness. We validate our approach in a\nmultimodal robotics simulation and a real-world multimodal indoor environment.\nWe compare the performance to several diversity maintenance algorithms from the\nliterature, including Deterministic Resampling and Particle Gaussian Mixtures.\nOur algorithm achieves high success rates with little to no negative effect on\ncompactness, showing particular robustness to different domains and challenging\ninitial conditions."}
{"id": "2509.24134", "pdf": "https://arxiv.org/pdf/2509.24134", "abs": "https://arxiv.org/abs/2509.24134", "authors": ["Antony Tan", "Pavlos Protopapas", "Martina Cádiz-Leyton", "Guillermo Cabrera-Vives", "Cristobal Donoso-Oliva", "Ignacio Becker"], "title": "ASTROCO: Self-Supervised Conformer-Style Transformers for Light-Curve Embeddings", "categories": ["astro-ph.IM", "cs.AI", "cs.LG"], "comment": "Accepted at the NeurIPS 2025 Workshop on Machine Learning and the\n  Physical Sciences (ML4PS), camera-ready version in progress", "summary": "We present AstroCo, a Conformer-style encoder for irregular stellar light\ncurves. By combining attention with depthwise convolutions and gating, AstroCo\ncaptures both global dependencies and local features. On MACHO R-band, AstroCo\noutperforms Astromer v1 and v2, yielding 70 percent and 61 percent lower error\nrespectively and a relative macro-F1 gain of about 7 percent, while producing\nembeddings that transfer effectively to few-shot classification. These results\nhighlight AstroCo's potential as a strong and label-efficient foundation for\ntime-domain astronomy."}
{"id": "2509.24136", "pdf": "https://arxiv.org/pdf/2509.24136", "abs": "https://arxiv.org/abs/2509.24136", "authors": ["Youssef Sabiri", "Walid Houmaidi", "Amine Abouaomar"], "title": "EYE-DEX: Eye Disease Detection and EXplanation System", "categories": ["cs.CV", "cs.AI", "cs.LG", "60G35, 62M10, 62P35, 65C20, 68T45, 68U10, 92C35, 92C40, 92C42, 93E10", "I.4; I.4.8; I.4.9; I.4.10; I.2; I.2.6; I.2.10; J.3; C.2.4; C.3;\n  H.2.8; H.3.4; H.3.5; I.2.4; I.5; I.5.1; I.5.4; K.6.1"], "comment": "6 pages, 4 figures, 3 tables. Accepted at the 12th International\n  Conference on Wireless Networks and Mobile Communications 2025 (WINCOM 2025)", "summary": "Retinal disease diagnosis is critical in preventing vision loss and reducing\nsocioeconomic burdens. Globally, over 2.2 billion people are affected by some\nform of vision impairment, resulting in annual productivity losses estimated at\n$411 billion. Traditional manual grading of retinal fundus images by\nophthalmologists is time-consuming and subjective. In contrast, deep learning\nhas revolutionized medical diagnostics by automating retinal image analysis and\nachieving expert-level performance. In this study, we present EYE-DEX, an\nautomated framework for classifying 10 retinal conditions using the large-scale\nRetinal Disease Dataset comprising 21,577 eye fundus images. We benchmark three\npre-trained Convolutional Neural Network (CNN) models--VGG16, VGG19, and\nResNet50--with our finetuned VGG16 achieving a state-of-the-art global\nbenchmark test accuracy of 92.36%. To enhance transparency and explainability,\nwe integrate the Gradient-weighted Class Activation Mapping (Grad-CAM)\ntechnique to generate visual explanations highlighting disease-specific\nregions, thereby fostering clinician trust and reliability in AI-assisted\ndiagnostics."}
{"id": "2509.24147", "pdf": "https://arxiv.org/pdf/2509.24147", "abs": "https://arxiv.org/abs/2509.24147", "authors": ["Yida Chen", "Yuning Mao", "Xianjun Yang", "Suyu Ge", "Shengjie Bi", "Lijuan Liu", "Saghar Hosseini", "Liang Tan", "Yixin Nie", "Shaoliang Nie"], "title": "Your thoughts tell who you are: Characterize the reasoning patterns of LRMs", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "32 pages, 28 figures", "summary": "Current comparisons of large reasoning models (LRMs) focus on macro-level\nstatistics such as task accuracy or reasoning length. Whether different LRMs\nreason differently remains an open question. To address this gap, we introduce\nthe LLM-proposed Open Taxonomy (LOT), a classification method that uses a\ngenerative language model to compare reasoning traces from two LRMs and\narticulate their distinctive features in words. LOT then models how these\nfeatures predict the source LRM of a reasoning trace based on their empirical\ndistributions across LRM outputs. Iterating this process over a dataset of\nreasoning traces yields a human-readable taxonomy that characterizes how models\nthink. We apply LOT to compare the reasoning of 12 open-source LRMs on tasks in\nmath, science, and coding. LOT identifies systematic differences in their\nthoughts, achieving 80-100% accuracy in distinguishing reasoning traces from\nLRMs that differ in scale, base model family, or objective domain. Beyond\nclassification, LOT's natural-language taxonomy provides qualitative\nexplanations of how LRMs think differently. Finally, in a case study, we link\nthe reasoning differences to performance: aligning the reasoning style of\nsmaller Qwen3 models with that of the largest Qwen3 during test time improves\ntheir accuracy on GPQA by 3.3-5.7%."}
{"id": "2509.24149", "pdf": "https://arxiv.org/pdf/2509.24149", "abs": "https://arxiv.org/abs/2509.24149", "authors": ["Walid Houmaidi", "Youssef Sabiri", "Salmane El Mansour Billah", "Amine Abouaomar"], "title": "Accelerating Cerebral Diagnostics with BrainFusion: A Comprehensive MRI Tumor Framework", "categories": ["cs.CV", "cs.AI", "cs.LG", "60G35, 62M10, 62P35, 65C20, 68T45, 68U10, 92C35, 92C40, 92C42, 93E10", "I.4; I.4.8; I.4.9; I.4.10; I.2; I.2.6; I.2.10; J.3; C.2.4; C.3;\n  H.2.8; H.3.4; H.3.5; I.2.4; I.5; I.5.1; I.5.4; K.6.1"], "comment": "6 pages, 4 figures, 3 tables. Accepted at the 12th International\n  Conference on Wireless Networks and Mobile Communications 2025 (WINCOM 2025)", "summary": "The early and accurate classification of brain tumors is crucial for guiding\neffective treatment strategies and improving patient outcomes. This study\npresents BrainFusion, a significant advancement in brain tumor analysis using\nmagnetic resonance imaging (MRI) by combining fine-tuned convolutional neural\nnetworks (CNNs) for tumor classification--including VGG16, ResNet50, and\nXception--with YOLOv8 for precise tumor localization with bounding boxes.\nLeveraging the Brain Tumor MRI Dataset, our experiments reveal that the\nfine-tuned VGG16 model achieves test accuracy of 99.86%, substantially\nexceeding previous benchmarks. Beyond setting a new accuracy standard, the\nintegration of bounding-box localization and explainable AI techniques further\nenhances both the clinical interpretability and trustworthiness of the system's\noutputs. Overall, this approach underscores the transformative potential of\ndeep learning in delivering faster, more reliable diagnoses, ultimately\ncontributing to improved patient care and survival rates."}
{"id": "2509.24151", "pdf": "https://arxiv.org/pdf/2509.24151", "abs": "https://arxiv.org/abs/2509.24151", "authors": ["Mingshu Li", "Dhruv Desai", "Jerinsh Jeyapaulraj", "Philip Sommer", "Riya Jain", "Peter Chu", "Dhagash Mehta"], "title": "STRAPSim: A Portfolio Similarity Metric for ETF Alignment and Portfolio Trades", "categories": ["q-fin.ST", "cs.LG"], "comment": null, "summary": "Accurately measuring portfolio similarity is critical for a wide range of\nfinancial applications, including Exchange-traded Fund (ETF) recommendation,\nportfolio trading, and risk alignment. Existing similarity measures often rely\non exact asset overlap or static distance metrics, which fail to capture\nsimilarities among the constituents (e.g., securities within the portfolio) as\nwell as nuanced relationships between partially overlapping portfolios with\nheterogeneous weights. We introduce STRAPSim (Semantic, Two-level,\nResidual-Aware Portfolio Similarity), a novel method that computes portfolio\nsimilarity by matching constituents based on semantic similarity, weighting\nthem according to their portfolio share, and aggregating results via\nresidual-aware greedy alignment. We benchmark our approach against Jaccard,\nweighted Jaccard, as well as BERTScore-inspired variants across public\nclassification, regression, and recommendation tasks, as well as on corporate\nbond ETF datasets. Empirical results show that our method consistently\noutperforms baselines in predictive accuracy and ranking alignment, achieving\nthe highest Spearman correlation with return-based similarity. By leveraging\nconstituent-aware matching and dynamic reweighting, portfolio similarity offers\na scalable, interpretable framework for comparing structured asset baskets,\ndemonstrating its utility in ETF benchmarking, portfolio construction, and\nsystematic execution."}
{"id": "2509.24160", "pdf": "https://arxiv.org/pdf/2509.24160", "abs": "https://arxiv.org/abs/2509.24160", "authors": ["Tomoyuki Kagaya", "Subramanian Lakshmi", "Yuxuan Lou", "Thong Jing Yuan", "Jayashree Karlekar", "Sugiri Pranata", "Natsuki Murakami", "Akira Kinose", "Yang You"], "title": "Memory Transfer Planning: LLM-driven Context-Aware Code Adaptation for Robot Manipulation", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) are increasingly explored in robot manipulation,\nbut many existing methods struggle to adapt to new environments. Many systems\nrequire either environment-specific policy training or depend on fixed prompts\nand single-shot code generation, leading to limited transferability and manual\nre-tuning. We introduce Memory Transfer Planning (MTP), a framework that\nleverages successful control-code examples from different environments as\nprocedural knowledge, using them as in-context guidance for LLM-driven\nplanning. Specifically, MTP (i) generates an initial plan and code using LLMs,\n(ii) retrieves relevant successful examples from a code memory, and (iii)\ncontextually adapts the retrieved code to the target setting for re-planning\nwithout updating model parameters. We evaluate MTP on RLBench, CALVIN, and a\nphysical robot, demonstrating effectiveness beyond simulation. Across these\nsettings, MTP consistently improved success rate and adaptability compared with\nfixed-prompt code generation, naive retrieval, and memory-free re-planning.\nFurthermore, in hardware experiments, leveraging a memory constructed in\nsimulation proved effective. MTP provides a practical approach that exploits\nprocedural knowledge to realize robust LLM-based planning across diverse\nrobotic manipulation scenarios, enhancing adaptability to novel environments\nand bridging simulation and real-world deployment."}
{"id": "2509.24183", "pdf": "https://arxiv.org/pdf/2509.24183", "abs": "https://arxiv.org/abs/2509.24183", "authors": ["Ran Xu", "Kaixin Ma", "Wenhao Yu", "Hongming Zhang", "Joyce C. Ho", "Carl Yang", "Dong Yu"], "title": "Retrieval-augmented GUI Agents with Generative Guidelines", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted to EMNLP 2025 (Main Conference)", "summary": "GUI agents powered by vision-language models (VLMs) show promise in\nautomating complex digital tasks. However, their effectiveness in real-world\napplications is often limited by scarce training data and the inherent\ncomplexity of these tasks, which frequently require long-tailed knowledge\ncovering rare, unseen scenarios. We propose RAG-GUI , a lightweight VLM that\nleverages web tutorials at inference time. RAG-GUI is first warm-started via\nsupervised finetuning (SFT) and further refined through self-guided rejection\nsampling finetuning (RSF). Designed to be model-agnostic, RAG-GUI functions as\na generic plug-in that enhances any VLM-based agent. Evaluated across three\ndistinct tasks, it consistently outperforms baseline agents and surpasses other\ninference baselines by 2.6% to 13.3% across two model sizes, demonstrating\nstrong generalization and practical plug-and-play capabilities in real-world\nscenarios."}
{"id": "2509.24193", "pdf": "https://arxiv.org/pdf/2509.24193", "abs": "https://arxiv.org/abs/2509.24193", "authors": ["Ran Xu", "Yuchen Zhuang", "Zihan Dong", "Jonathan Wang", "Yue Yu", "Joyce C. Ho", "Linjun Zhang", "Haoyu Wang", "Wenqi Shi", "Carl Yang"], "title": "AceSearcher: Bootstrapping Reasoning and Search for LLMs via Reinforced Self-Play", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "comment": "Accepted to NeurIPS 2025 (Spotlight)", "summary": "Search-augmented LLMs often struggle with complex reasoning tasks due to\nineffective multi-hop retrieval and limited reasoning ability. We propose\nAceSearcher, a cooperative self-play framework that trains a single large\nlanguage model (LLM) to alternate between two roles: a decomposer that breaks\ndown complex queries and a solver that integrates retrieved contexts for answer\ngeneration. AceSearcher couples supervised fine-tuning on a diverse mixture of\nsearch, reasoning, and decomposition tasks with reinforcement fine-tuning\noptimized for final answer accuracy, eliminating the need for intermediate\nannotations. Extensive experiments on three reasoning-intensive tasks across 10\ndatasets show that AceSearcher outperforms state-of-the-art baselines,\nachieving an average exact match improvement of 7.6%. Remarkably, on\ndocument-level finance reasoning tasks, AceSearcher-32B matches the performance\nof the DeepSeek-V3 model using less than 5% of its parameters. Even at smaller\nscales (1.5B and 8B), AceSearcher often surpasses existing search-augmented\nLLMs with up to 9x more parameters, highlighting its exceptional efficiency and\neffectiveness in tackling complex reasoning tasks. Our code will be published\nat https://github.com/ritaranx/AceSearcher and\nhttps://huggingface.co/AceSearcher."}
{"id": "2509.24210", "pdf": "https://arxiv.org/pdf/2509.24210", "abs": "https://arxiv.org/abs/2509.24210", "authors": ["Gaurav Srivastava", "Aafiya Hussain", "Zhenyu Bi", "Swastik Roy", "Priya Pitre", "Meng Lu", "Morteza Ziyadi", "Xuan Wang"], "title": "BeyondBench: Benchmark-Free Evaluation of Reasoning in Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "113 pages, 5 figures, 30 tables", "summary": "Evaluating language models fairly is becoming harder as static benchmarks\navailable on the internet risk contamination by training data. This makes it\nunclear whether models are truly reasoning or just recalling answers. In this\npaper, we introduce BeyondBench, an evaluation framework that avoids this\nproblem by using algorithmic problem generation. Unlike traditional benchmarks\nthat risk contamination from internet-scale training data, BeyondBench creates\nmathematically grounded problems on the fly, ensuring each test remains fresh\nand uncontaminated. Our framework covers 44 algorithmic tasks with a total of\n117 variations, grouped into three difficulty levels: the Easy Suite (29 tasks)\nfor basic arithmetic and statistics, the Medium Suite (5 tasks, 49 variations)\nfor sequence patterns and reasoning, and the Hard Suite (10 tasks, 68\nvariations) tackling NP-complete and constraint satisfaction problems. Each\ntask generates problems from a combinatorial space larger than 10^15 unique\ninstances, with solutions verified deterministically by mathematical proofs. We\nevaluated 101 language models, including 85 open-source and 16 closed-source\nmodels, spanning sizes from 0.5B to 141B parameters and multiple quantization\nschemes. Our results show consistent reasoning deficiencies across model\nfamilies, with performance degrading sharply as problem complexity increases\nfrom polynomial to exponential. In our Hard Suite evaluations, models such as\nGemini-2.5-pro, Llama-3.3-70B, and Qwen2.5-72B achieved average accuracies of\n56.38%, 26.91%, and 33.60%, respectively. Moreover, we observe that performance\ndrops drastically without tool usage, with GPT-5, GPT-5-mini, and GPT-5-nano\nshowing a decline of 16.81%, 28.05%, and 47.59% accuracy on the hard suite. Our\nleaderboard is publicly available at https://ctrl-gaurav.github.io/BeyondBench/"}
{"id": "2509.24219", "pdf": "https://arxiv.org/pdf/2509.24219", "abs": "https://arxiv.org/abs/2509.24219", "authors": ["Tomoyuki Kagaya", "Subramanian Lakshmi", "Anbang Ye", "Thong Jing Yuan", "Jayashree Karlekar", "Sugiri Pranata", "Natsuki Murakami", "Akira Kinose", "Yang You"], "title": "ViReSkill: Vision-Grounded Replanning with Skill Memory for LLM-Based Planning in Lifelong Robot Learning", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "Robots trained via Reinforcement Learning (RL) or Imitation Learning (IL)\noften adapt slowly to new tasks, whereas recent Large Language Models (LLMs)\nand Vision-Language Models (VLMs) promise knowledge-rich planning from minimal\ndata. Deploying LLMs/VLMs for motion planning, however, faces two key\nobstacles: (i) symbolic plans are rarely grounded in scene geometry and object\nphysics, and (ii) model outputs can vary for identical prompts, undermining\nexecution reliability. We propose ViReSkill, a framework that pairs\nvision-grounded replanning with a skill memory for accumulation and reuse. When\na failure occurs, the replanner generates a new action sequence conditioned on\nthe current scene, tailored to the observed state. On success, the executed\nplan is stored as a reusable skill and replayed in future encounters without\nadditional calls to LLMs/VLMs. This feedback loop enables autonomous continual\nlearning: each attempt immediately expands the skill set and stabilizes\nsubsequent executions. We evaluate ViReSkill on simulators such as LIBERO and\nRLBench as well as on a physical robot. Across all settings, it consistently\noutperforms conventional baselines in task success rate, demonstrating robust\nsim-to-real generalization."}
{"id": "2509.24222", "pdf": "https://arxiv.org/pdf/2509.24222", "abs": "https://arxiv.org/abs/2509.24222", "authors": ["Zhisheng Chen", "Yingwei Zhang", "Qizhen Lan", "Tianyu Liu", "Huacan Wang", "Yi Ding", "Ziyu Jia", "Ronghao Chen", "Kun Wang", "Xinliang Zhou"], "title": "Uni-NTFM: A Unified Foundation Model for EEG Signal Representation Learning", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": null, "summary": "Foundation models pretrained on various and unlabeled data have demonstrated\nsignificant success in natural language and vision, but their application to\nelectroencephalography (EEG) remains challenged due to the signal's unique\nproperties. Existing brain foundation models that inherit architectures\ndesigned for text or images lead to three limitations in pre-training: 1)\nconflating time-domain waveform patterns with frequency-domain rhythmic\nfeatures in a single processing stream, 2) ignoring the critical spatial\ntopology of electrodes with different standards, and 3) reliance on the\ninflexible, dense network to process functionally distinct EEG patterns. To\naddress these challenges, we introduce the Unified Neural Topological\nFoundation Model (Uni-NTFM), which is designed based on neuroscience principles\nto produce universal and interpretable representations. Uni-NTFM integrates\nthree core innovations: 1) a decoupled architecture parallelly encodes time,\nfrequency, and raw signal representations before performing cross-domain\nfeature integration; 2) a topological embedding mechanism to unify electrodes\nfrom different international standards and generate structured input sequences\nfor brain regions; and 3) a Mixture-of-Experts neural Transformer that\nefficiently scales model capacity by routing signal patterns to specialized\nsubnetworks. The largest model, Uni-NTFM$_{large}$, has a record-breaking 1.9B\nparameters and was pretrained on over 28,000 hours of diverse EEG data via a\ndual-domain masked reconstruction objective. Uni-NTFM significantly outperforms\nexisting task-specific methods and foundation models across nine distinct\ndownstream tasks under both linear probing and fine-tuning settings,\ndemonstrating a superior ability to learn universal representations of brain\nactivity."}
{"id": "2509.24227", "pdf": "https://arxiv.org/pdf/2509.24227", "abs": "https://arxiv.org/abs/2509.24227", "authors": ["Baltasar Ramos", "Cristian Garrido", "Paulette Narv'aez", "Santiago Gelerstein Claro", "Haotian Li", "Rafael Salvador", "Constanza V'asquez-Venegas", "Iv'an Gallegos", "Yi Zhang", "V'ictor Casta~neda", "Cristian Acevedo", "Dan Wu", "Gonzalo C'ardenas", "Camilo G. Sotomayor"], "title": "Non-Invasive Detection of PROState Cancer with Novel Time-Dependent Diffusion MRI and AI-Enhanced Quantitative Radiological Interpretation: PROS-TD-AI", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": "Study protocol preprint (not peer reviewed). Prepared with the MDPI\n  Journal of Imaging Word author template. Primary category: eess.IV. Code and\n  patient data are not publicly available due to privacy; requests will be\n  considered under a data-use agreement", "summary": "Prostate cancer (PCa) is the most frequently diagnosed malignancy in men and\nthe eighth leading cause of cancer death worldwide. Multiparametric MRI (mpMRI)\nhas become central to the diagnostic pathway for men at intermediate risk,\nimproving de-tection of clinically significant PCa (csPCa) while reducing\nunnecessary biopsies and over-diagnosis. However, mpMRI remains limited by\nfalse positives, false negatives, and moderate to substantial interobserver\nagreement. Time-dependent diffusion (TDD) MRI, a novel sequence that enables\ntissue microstructure characterization, has shown encouraging preclinical\nperformance in distinguishing clinically significant from insignificant PCa.\nCombining TDD-derived metrics with machine learning may provide robust,\nzone-specific risk prediction with less dependence on reader training and\nimproved accuracy compared to current standard-of-care. This study protocol\nout-lines the rationale and describes the prospective evaluation of a\nhome-developed AI-enhanced TDD-MRI software (PROSTDAI) in routine diagnostic\ncare, assessing its added value against PI-RADS v2.1 and validating results\nagainst MRI-guided prostate biopsy."}
{"id": "2509.24248", "pdf": "https://arxiv.org/pdf/2509.24248", "abs": "https://arxiv.org/abs/2509.24248", "authors": ["Rubing Yang", "Huajun Bai", "Song Liu", "Guanghua Yu", "Runzhi Fan", "Yanbin Dang", "Jiejing Zhang", "Kai Liu", "Jianchen Zhu", "Peng Chen"], "title": "SpecExit: Accelerating Large Reasoning Model via Speculative Exit", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Despite their strong performance on reasoning tasks, large reasoning models\n(LRMs) often suffer from overthinking, producing unnecessarily long outputs and\nincurring high end-to-end latency, a significant limitation to their real-world\ndeployment. To address overthinking, early-exit mechanisms have been proposed\nto terminate reasoning before typical completion, showing that this approach\ncan effectively shorten generation length with minimal impact on accuracy.\nHowever, their reliance on probing mechanisms introduces a detection overhead\nthat limits their end-to-end latency gains and compromises their\ngeneralizability across diverse problems. Inspired by the use of hidden states\nin speculative decoding, we propose SpecExit, a novel framework that predicts\nboth future tokens and an early-exit signal directly from a lightweight draft\nmodel without probing overhead. Our method offers significant improvements,\nreducing average generation length by 66\\% and achieving a 2.5x speedup in\nend-to-end latency compared to the speculative decoding baseline, without\ncompromising accuracy. Our method leverages the inherent signals from hidden\nstates to provide effective early-exit signals, suggesting broader use of\nhidden states for efficient reasoning. Our code is available at\nhttps://github.com/Tencent/AngelSlim."}
{"id": "2509.24250", "pdf": "https://arxiv.org/pdf/2509.24250", "abs": "https://arxiv.org/abs/2509.24250", "authors": ["Edward Kim", "Daniel He", "Jorge Chao", "Wiktor Rajca", "Mohammed Amin", "Nishant Malpani", "Ruta Desai", "Antti Oulasvirta", "Bjoern Hartmann", "Sanjit Seshia"], "title": "Interactive Program Synthesis for Modeling Collaborative Physical Activities from Narrated Demonstrations", "categories": ["cs.AI", "cs.HC", "cs.LG"], "comment": null, "summary": "Teaching systems physical tasks is a long standing goal in HCI, yet most\nprior work has focused on non collaborative physical activities. Collaborative\ntasks introduce added complexity, requiring systems to infer users assumptions\nabout their teammates intent, which is an inherently ambiguous and dynamic\nprocess. This necessitates representations that are interpretable and\ncorrectable, enabling users to inspect and refine system behavior. We address\nthis challenge by framing collaborative task learning as a program synthesis\nproblem. Our system represents behavior as editable programs and uses narrated\ndemonstrations, i.e. paired physical actions and natural language, as a unified\nmodality for teaching, inspecting, and correcting system logic without\nrequiring users to see or write code. The same modality is used for the system\nto communicate its learning to users. In a within subjects study, 20 users\ntaught multiplayer soccer tactics to our system. 70 percent (14/20) of\nparticipants successfully refined learned programs to match their intent and 90\npercent (18/20) found it easy to correct the programs. The study surfaced\nunique challenges in representing learning as programs and in enabling users to\nteach collaborative physical activities. We discuss these issues and outline\nmitigation strategies."}
{"id": "2509.24254", "pdf": "https://arxiv.org/pdf/2509.24254", "abs": "https://arxiv.org/abs/2509.24254", "authors": ["Yuntao Wu", "Ege Mert Akin", "Charles Martineau", "Vincent Grégoire", "Andreas Veneris"], "title": "Extracting the Structure of Press Releases for Predicting Earnings Announcement Returns", "categories": ["q-fin.CP", "cs.CE", "cs.CL", "cs.LG", "J.4; I.2.7"], "comment": "9 pages, 4 figures, 6 tables, Accepted by The 6th ACM International\n  Conference on AI in Finance", "summary": "We examine how textual features in earnings press releases predict stock\nreturns on earnings announcement days. Using over 138,000 press releases from\n2005 to 2023, we compare traditional bag-of-words and BERT-based embeddings. We\nfind that press release content (soft information) is as informative as\nearnings surprise (hard information), with FinBERT yielding the highest\npredictive power. Combining models enhances explanatory strength and\ninterpretability of the content of press releases. Stock prices fully reflect\nthe content of press releases at market open. If press releases are leaked, it\noffers predictive advantage. Topic analysis reveals self-serving bias in\nmanagerial narratives. Our framework supports real-time return prediction\nthrough the integration of online learning, provides interpretability and\nreveals the nuanced role of language in price formation."}
{"id": "2509.24255", "pdf": "https://arxiv.org/pdf/2509.24255", "abs": "https://arxiv.org/abs/2509.24255", "authors": ["Kaiang Wen", "Mark Roman Miller"], "title": "Understanding Cognitive States from Head & Hand Motion Data", "categories": ["cs.HC", "cs.LG"], "comment": null, "summary": "As virtual reality (VR) and augmented reality (AR) continue to gain\npopularity, head and hand motion data captured by consumer VR systems have\nbecome ubiquitous. Prior work shows that such telemetry can be highly\nidentifying and reflect broad user traits, often aligning with intuitive \"folk\ntheories\" of body language. However, it remains unclear to what extent motion\nkinematics encode more nuanced cognitive states, such as confusion, hesitation,\nand readiness, which lack clear correlates with motion. To investigate this, we\nintroduce a novel dataset of head and hand motion with frame-level annotations\nof these states collected during structured decision-making tasks. Our findings\nsuggest that deep temporal models can infer subtle cognitive states from motion\nalone, achieving comparable performance with human observers. This work\ndemonstrates that standard VR telemetry contains strong patterns related to\nusers' internal cognitive processes, which opens the door for a new generation\nof adaptive virtual environments. To enhance reproducibility and support future\nwork, we will make our dataset and modeling framework publicly available."}
{"id": "2509.24257", "pdf": "https://arxiv.org/pdf/2509.24257", "abs": "https://arxiv.org/abs/2509.24257", "authors": ["Ke Wang", "Felix Qu", "Libin Xia", "Zishuo Zhao", "Chris Tong", "Lynn Ai", "Eric Yang"], "title": "VeriLLM: A Lightweight Framework for Publicly Verifiable Decentralized Inference", "categories": ["cs.CR", "cs.LG", "C.2.1"], "comment": "13 pages, 4 figures, 2 tables", "summary": "Decentralized inference is an appealing paradigm for serving large language\nmodels (LLMs), offering strong security, high efficiency, and lower operating\ncosts. Yet the permissionless setting admits no a priori trust in participating\nnodes, making output verifiability a prerequisite for secure deployment. We\npresent VeriLLM, a publicly verifiable protocol for decentralized LLM inference\nthat (i) achieves security under a one-honest-verifier assumption, (ii) attains\nnear-negligible verification cost (about 1% of the underlying inference) via a\nlightweight verification algorithm designed explicitly for LLMs, and (iii)\nenforces honest checking through a peer-prediction mechanism that mitigates\nlazy verification in naive voting. We further introduce an isomorphic\ninference-verification network that multiplexes both roles on the same set of\nGPU workers. This architecture (i) increases GPU utilization and thereby\nimproves end-to-end throughput for both inference and verification, (ii)\nexpands the effective pool of available validators, strengthening robustness\nand security, and (iii) enforces task indistinguishability at the worker\nboundary to prevent job-type-conditioned behavior. Finally, we provide a formal\ngame-theoretic analysis and prove that, under our incentives, honest inference\nand verification constitute a Nash equilibrium, ensuring incentive\ncompatibility against rational adversaries. To our knowledge, this is the first\ndecentralized inference verification protocol with an end-to-end game-theoretic\nsecurity proof."}
{"id": "2509.24261", "pdf": "https://arxiv.org/pdf/2509.24261", "abs": "https://arxiv.org/abs/2509.24261", "authors": ["Yuhua Jiang", "Jiawei Huang", "Yufeng Yuan", "Xin Mao", "Yu Yue", "Qianchuan Zhao", "Lin Yan"], "title": "Risk-Sensitive RL for Alleviating Exploration Dilemmas in Large Language Models", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has proven effective\nfor enhancing Large Language Models (LLMs) on complex reasoning tasks. However,\nexisting methods suffer from an exploration dilemma: the sharply peaked initial\npolicies of pre-trained LLMs confine standard RL algorithms to a narrow set of\nsolutions, boosting single-solution accuracy (pass@1) but suppressing solution\ndiversity and multi-solution performance (pass@k). As a result, RLVR often\ndistills existing capabilities rather than discovering new reasoning\nstrategies. To overcome this, we introduce a Risk-Sensitive Reinforcement\nLearning framework. Our approach employs a risk-seeking objective that\ninterpolates between mean and maximum rewards, leading to a novel algorithm,\nRisk-Sensitive GRPO (RS-GRPO), which drives deeper exploration by amplifying\nlearning from challenging prompts. Remarkably, RS-GRPO is simple to implement,\nrequiring only minor code modifications. On six mathematical reasoning\nbenchmarks and with five different LLMs, RS-GRPO consistently improves pass@k\nperformance while maintaining or enhancing pass@1 accuracy."}
{"id": "2509.24262", "pdf": "https://arxiv.org/pdf/2509.24262", "abs": "https://arxiv.org/abs/2509.24262", "authors": ["Nimisha Ghosh", "Dheeran Sankaran", "Rahul Balakrishnan Adhi", "Sharath S", "Amrut Anand"], "title": "LAMP-PRo: Label-aware Attention for Multi-label Prediction of DNA- and RNA-binding Proteins using Protein Language Models", "categories": ["q-bio.QM", "cs.AI", "cs.LG"], "comment": null, "summary": "Identifying DNA- (DBPs) and RNA-binding proteins (RBPs) is crucial for the\nunderstanding of cell function, molecular interactions as well as regulatory\nfunctions. Owing to their high similarity, most of the existing approaches face\nchallenges in differentiating between DBPs and RBPs leading to high\ncross-prediction errors. Moreover, identifying proteins which bind to both DNA\nand RNA (DRBPs) is also quite a challenging task. In this regard, we propose a\nnovel framework viz. LAMP-PRo which is based on pre-trained protein language\nmodel (PLM), attention mechanisms and multi-label learning to mitigate these\nissues. First, pre-trained PLM such ESM-2 is used for embedding the protein\nsequences followed by convolutional neural network (CNN). Subsequently\nmulti-head self-attention mechanism is applied for the contextual information\nwhile label-aware attention is used to compute class-specific representations\nby attending to the sequence in a way that is tailored to each label (DBP, RBP\nand non-NABP) in a multi-label setup. We have also included a novel cross-label\nattention mechanism to explicitly capture dependencies between DNA- and\nRNA-binding proteins, enabling more accurate prediction of DRBP. Finally, a\nlinear layer followed by a sigmoid function are used for the final prediction.\nExtensive experiments are carried out to compare LAMP-PRo with the existing\nmethods wherein the proposed model shows consistent competent performance.\nFurthermore, we also provide visualization to showcase model interpretability,\nhighlighting which parts of the sequence are most relevant for a predicted\nlabel. The original datasets are available at http://bliulab.net/iDRBP\\_MMC and\nthe codes are available at https://github.com/NimishaGhosh/LAMP-PRo."}
{"id": "2509.24264", "pdf": "https://arxiv.org/pdf/2509.24264", "abs": "https://arxiv.org/abs/2509.24264", "authors": ["Hyo-Jin Kim", "Jaekwang Kim", "Hyung-Jun Park"], "title": "Graph-Based Learning of Free Surface Dynamics in Generalized Newtonian Fluids using Smoothed Particle Hydrodynamics", "categories": ["physics.flu-dyn", "cs.LG", "physics.comp-ph"], "comment": null, "summary": "In this study, we propose a graph neural network (GNN) model for efficiently\npredicting the flow behavior of non-Newtonian fluids with free surface\ndynamics. The numerical analysis of non-Newtonian fluids presents significant\nchallenges, as traditional algorithms designed for Newtonian fluids with\nconstant viscosity often struggle to converge when applied to non-Newtonian\ncases, where rheological properties vary dynamically with flow conditions.\nAmong these, power-law fluids exhibit viscosity that decreases exponentially as\nthe shear rate increases, making numerical simulations particularly difficult.\nThe complexity further escalates in free surface flow scenarios, where\ncomputational challenges intensify. In such cases, particle-based methods like\nsmoothed particle hydrodynamics (SPH) provide advantages over traditional\ngrid-based techniques, such as the finite element method (FEM). Building on\nthis approach, we introduce a novel GNN-based numerical model to enhance the\ncomputational efficiency of non-Newtonian power-law fluid flow simulations. Our\nmodel is trained on SPH simulation data, learning the effects of particle\naccelerations in the presence of SPH interactions based on the fluid's\npower-law parameters. The GNN significantly accelerates computations while\nmaintaining reliable accuracy in benchmark tests, including dam-break and\ndroplet impact simulations. The results underscore the potential of GNN-based\nsimulation frameworks for efficiently modeling non-Newtonian fluid behavior,\npaving the way for future advancements in data-driven fluid simulations."}
{"id": "2509.24273", "pdf": "https://arxiv.org/pdf/2509.24273", "abs": "https://arxiv.org/abs/2509.24273", "authors": ["Yongqiang Wang", "Weigang Li", "Wenping Liu", "Zhiqiang Tian", "Jinling Li"], "title": "Skeleton-based Robust Registration Framework for Corrupted 3D Point Clouds", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Point cloud registration is fundamental in 3D vision applications, including\nautonomous driving, robotics, and medical imaging, where precise alignment of\nmultiple point clouds is essential for accurate environment reconstruction.\nHowever, real-world point clouds are often affected by sensor limitations,\nenvironmental noise, and preprocessing errors, making registration challenging\ndue to density distortions, noise contamination, and geometric deformations.\nExisting registration methods rely on direct point matching or surface feature\nextraction, which are highly susceptible to these corruptions and lead to\nreduced alignment accuracy. To address these challenges, a skeleton-based\nrobust registration framework is presented, which introduces a\ncorruption-resilient skeletal representation to improve registration robustness\nand accuracy. The framework integrates skeletal structures into the\nregistration process and combines the transformations obtained from both the\ncorrupted point cloud alignment and its skeleton alignment to achieve optimal\nregistration. In addition, a distribution distance loss function is designed to\nenforce the consistency between the source and target skeletons, which\nsignificantly improves the registration performance. This framework ensures\nthat the alignment considers both the original local geometric features and the\nglobal stability of the skeleton structure, resulting in robust and accurate\nregistration results. Experimental evaluations on diverse corrupted datasets\ndemonstrate that SRRF consistently outperforms state-of-the-art registration\nmethods across various corruption scenarios, including density distortions,\nnoise contamination, and geometric deformations. The results confirm the\nrobustness of SRRF in handling corrupted point clouds, making it a potential\napproach for 3D perception tasks in real-world scenarios."}
{"id": "2509.24285", "pdf": "https://arxiv.org/pdf/2509.24285", "abs": "https://arxiv.org/abs/2509.24285", "authors": ["Shenghe Zheng", "Chenyu Huang", "Fangchen Yu", "Junchi Yao", "Jingqi Ye", "Tao Chen", "Yun Luo", "Ning Ding", "LEI BAI", "Ganqu Cui", "Peng Ye"], "title": "SCI-Verifier: Scientific Verifier with Thinking", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "This paper focuses on LLM-as-a-Judge, and the project is currently in\n  progress", "summary": "As large language models (LLMs) are increasingly applied to scientific\nreasoning, the complexity of answer formats and the diversity of equivalent\nexpressions make answer verification a critical yet challenging task. Existing\nverification studies in scientific domains suffer from two major limitations:\n(a) the absence of systematic evaluation standards and insufficient\ndisciplinary coverage, which hinders their comprehensive assessment; and (b)\nheavy reliance on cumbersome rule design or prompt engineering, which reduces\ntheir effectiveness in complex reasoning scenarios or limits their\ncross-disciplinary generalization. To address these challenges, we propose\nsolutions at both the data and model levels. On the data side, we construct\nSCI-VerifyBench, a cross-disciplinary benchmark covering mathematics, physics,\nbiology, chemistry, and general scientific QA. The benchmark is built from real\nLLM responses and enhanced with domain-specific equivalence transformations\nthat generate challenging and realistic data. Model-based and expert\nannotations ensure both quality and diversity, enabling rigorous evaluation of\nverification ability. On the model side, we emphasize the importance of\nreasoning for verification and introduce SCI-Verifier, a unified\nreasoning-augmented verifier for scientific domains. Through post-training,\nSCI-Verifier demonstrates strong logical reasoning and equivalence judgment\ncapabilities while maintaining concise and stable outputs. Together,\nSCI-VerifyBench and SCI-Verifier provide a principled framework for scientific\nverification, offering both systematic evaluation and practical pathways to\nenhance the reliability and applicability of LLMs in scientific domains."}
{"id": "2509.24293", "pdf": "https://arxiv.org/pdf/2509.24293", "abs": "https://arxiv.org/abs/2509.24293", "authors": ["Erdun Gao", "Dino Sejdinovic"], "title": "ActiveCQ: Active Estimation of Causal Quantities", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Estimating causal quantities (CQs) typically requires large datasets, which\ncan be expensive to obtain, especially when measuring individual outcomes is\ncostly. This challenge highlights the importance of sample-efficient active\nlearning strategies. To address the narrow focus of prior work on the\nconditional average treatment effect, we formalize the broader task of Actively\nestimating Causal Quantities (ActiveCQ) and propose a unified framework for\nthis general problem. Built upon the insight that many CQs are integrals of\nregression functions, our framework models the regression function with a\nGaussian Process. For the distribution component, we explore both a baseline\nusing explicit density estimators and a more integrated method using\nconditional mean embeddings in a reproducing kernel Hilbert space. This latter\napproach offers key advantages: it bypasses explicit density estimation,\noperates within the same function space as the GP, and adaptively refines the\ndistributional model after each update. Our framework enables the principled\nderivation of acquisition strategies from the CQ's posterior uncertainty; we\ninstantiate this principle with two utility functions based on information gain\nand total variance reduction. A range of simulated and semi-synthetic\nexperiments demonstrate that our principled framework significantly outperforms\nrelevant baselines, achieving substantial gains in sample efficiency across a\nvariety of CQs."}
{"id": "2509.24312", "pdf": "https://arxiv.org/pdf/2509.24312", "abs": "https://arxiv.org/abs/2509.24312", "authors": ["Wenhui Li", "Shijin Gong", "Xinyu Zhang"], "title": "PEARL: Performance-Enhanced Aggregated Representation Learning", "categories": ["stat.ML", "cs.LG"], "comment": "23 pages, 1 figure, 5 tables", "summary": "Representation learning is a key technique in modern machine learning that\nenables models to identify meaningful patterns in complex data. However,\ndifferent methods tend to extract distinct aspects of the data, and relying on\na single approach may overlook important insights relevant to downstream tasks.\nThis paper proposes a performance-enhanced aggregated representation learning\nmethod, which combines multiple representation learning approaches to improve\nthe performance of downstream tasks. The framework is designed to be general\nand flexible, accommodating a wide range of loss functions commonly used in\nmachine learning models. To ensure computational efficiency, we use surrogate\nloss functions to facilitate practical weight estimation. Theoretically, we\nprove that our method asymptotically achieves optimal performance in downstream\ntasks, meaning that the risk of our predictor is asymptotically equivalent to\nthe theoretical minimum. Additionally, we derive that our method asymptotically\nassigns nonzero weights to correctly specified models. We evaluate our method\non diverse tasks by comparing it with advanced machine learning models. The\nexperimental results demonstrate that our method consistently outperforms\nbaseline methods, showing its effectiveness and broad applicability in\nreal-world machine learning scenarios."}
{"id": "2509.24327", "pdf": "https://arxiv.org/pdf/2509.24327", "abs": "https://arxiv.org/abs/2509.24327", "authors": ["Hai Siong Tan"], "title": "Inferring Cosmological Parameters with Evidential Physics-Informed Neural Networks", "categories": ["astro-ph.CO", "cs.LG", "gr-qc"], "comment": "25 pages, 11 figures", "summary": "We examine the use of a novel variant of Physics-Informed Neural Networks to\npredict cosmological parameters from recent supernovae and baryon acoustic\noscillations (BAO) datasets. Our machine learning framework generates\nuncertainty estimates for target variables and the inferred unknown parameters\nof the underlying PDE descriptions. Built upon a hybrid of the principles of\nEvidential Deep Learning, Physics-Informed Neural Networks, Bayesian Neural\nNetworks and Gaussian Processes, our model enables learning of the posterior\ndistribution of the unknown PDE parameters through standard gradient-descent\nbased training. We apply our model to an up-to-date BAO dataset (Bousis et al.\n2024) calibrated with the CMB-inferred sound horizon, and the Pantheon$+$ Sne\nIa distances (Scolnic et al. 2018), examining the relative effectiveness and\nmutual consistency among the standard $\\Lambda$CDM, $w$CDM and $\\Lambda_s$CDM\nmodels. Unlike previous results arising from the standard approach of\nminimizing an appropriate $\\chi^2$ function, the posterior distributions for\nparameters in various models trained purely on Pantheon$+$ data were found to\nbe largely contained within the $2\\sigma$ contours of their counterparts\ntrained on BAO data. Their posterior medians for $h_0$ were within about\n$2\\sigma$ of one another, indicating that our machine learning-guided approach\nprovides a different measure of the Hubble tension."}
{"id": "2509.24335", "pdf": "https://arxiv.org/pdf/2509.24335", "abs": "https://arxiv.org/abs/2509.24335", "authors": ["Guolin Ke", "Hui Xue"], "title": "Hyperspherical Latents Improve Continuous-Token Autoregressive Generation", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Autoregressive (AR) models are promising for image generation, yet\ncontinuous-token AR variants often trail latent diffusion and masked-generation\nmodels. The core issue is heterogeneous variance in VAE latents, which is\namplified during AR decoding, especially under classifier-free guidance (CFG),\nand can cause variance collapse. We propose SphereAR to address this issue. Its\ncore design is to constrain all AR inputs and outputs -- including after CFG --\nto lie on a fixed-radius hypersphere (constant $\\ell_2$ norm), leveraging\nhyperspherical VAEs. Our theoretical analysis shows that hyperspherical\nconstraint removes the scale component (the primary cause of variance\ncollapse), thereby stabilizing AR decoding. Empirically, on ImageNet\ngeneration, SphereAR-H (943M) sets a new state of the art for AR models,\nachieving FID 1.34. Even at smaller scales, SphereAR-L (479M) reaches FID 1.54\nand SphereAR-B (208M) reaches 1.92, matching or surpassing much larger\nbaselines such as MAR-H (943M, 1.55) and VAR-d30 (2B, 1.92). To our knowledge,\nthis is the first time a pure next-token AR image generator with raster order\nsurpasses diffusion and masked-generation models at comparable parameter\nscales."}
{"id": "2509.24359", "pdf": "https://arxiv.org/pdf/2509.24359", "abs": "https://arxiv.org/abs/2509.24359", "authors": ["Amira Guesmi", "Muhammad Shafique"], "title": "DRIFT: Divergent Response in Filtered Transformations for Robust Adversarial Defense", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Deep neural networks remain highly vulnerable to adversarial examples, and\nmost defenses collapse once gradients can be reliably estimated. We identify\n\\emph{gradient consensus} -- the tendency of randomized transformations to\nyield aligned gradients -- as a key driver of adversarial transferability.\nAttackers exploit this consensus to construct perturbations that remain\neffective across transformations. We introduce \\textbf{DRIFT} (Divergent\nResponse in Filtered Transformations), a stochastic ensemble of lightweight,\nlearnable filters trained to actively disrupt gradient consensus. Unlike prior\nrandomized defenses that rely on gradient masking, DRIFT enforces\n\\emph{gradient dissonance} by maximizing divergence in Jacobian- and\nlogit-space responses while preserving natural predictions. Our contributions\nare threefold: (i) we formalize gradient consensus and provide a theoretical\nanalysis linking consensus to transferability; (ii) we propose a\nconsensus-divergence training strategy combining prediction consistency,\nJacobian separation, logit-space separation, and adversarial robustness; and\n(iii) we show that DRIFT achieves substantial robustness gains on ImageNet\nacross CNNs and Vision Transformers, outperforming state-of-the-art\npreprocessing, adversarial training, and diffusion-based defenses under\nadaptive white-box, transfer-based, and gradient-free attacks. DRIFT delivers\nthese improvements with negligible runtime and memory cost, establishing\ngradient divergence as a practical and generalizable principle for adversarial\ndefense."}
{"id": "2509.24373", "pdf": "https://arxiv.org/pdf/2509.24373", "abs": "https://arxiv.org/abs/2509.24373", "authors": ["Matteo Zecchin", "Unnikrishnan Kunnath Ganesan", "Giuseppe Durisi", "Petar Popovski", "Osvaldo Simeone"], "title": "Prediction-Powered Communication with Distortion Guarantees", "categories": ["cs.IT", "cs.LG", "eess.SP", "math.IT"], "comment": null, "summary": "The development of 6G wireless systems is taking place alongside the\ndevelopment of increasingly intelligent wireless devices and network nodes. The\nchanging technological landscape is motivating a rethinking of classical\nShannon information theory that emphasizes semantic and task-oriented\nparadigms. In this paper, we study a prediction-powered communication setting,\nin which devices, equipped with artificial intelligence (AI)-based predictors,\ncommunicate under zero-delay constraints with strict distortion guarantees. Two\nclasses of distortion measures are considered: (i) outage-based metrics,\nsuitable for tasks tolerating occasional packet losses, such as real-time\ncontrol or monitoring; and (ii) bounded distortion metrics, relevant to\nsemantic-rich tasks like text or video transmission. We propose two zero-delay\ncompression algorithms leveraging online conformal prediction to provide\nper-sequence guarantees on the distortion of reconstructed sequences over\nerror-free and packet-erasure channels with feedback. For erasure channels, we\nintroduce a doubly-adaptive conformal update to compensate for channel-induced\nerrors and derive sufficient conditions on erasure statistics to ensure\ndistortion constraints. Experiments on semantic text compression validate the\napproach, showing significant bit rate reductions while strictly meeting\ndistortion guarantees compared to state-of-the-art prediction-powered\ncompression methods."}
{"id": "2509.24404", "pdf": "https://arxiv.org/pdf/2509.24404", "abs": "https://arxiv.org/abs/2509.24404", "authors": ["Song-Ze Yu"], "title": "From Sound to Setting: AI-Based Equalizer Parameter Prediction for Piano Tone Replication", "categories": ["cs.SD", "cs.LG", "eess.AS"], "comment": "Undergraduate project technical preprint. 4 pages, 6 figures. Code &\n  data: https://github.com/vaclisinc/Vaclis_Tone_Replication Primary: cs.SD,\n  Secondary: cs.LG", "summary": "This project presents an AI-based system for tone replication in music\nproduction, focusing on predicting EQ parameter settings directly from audio\nfeatures. Unlike traditional audio-to-audio methods, our approach outputs\ninterpretable parameter values (e.g., EQ band gains) that musicians can further\nadjust in their workflow. Using a dataset of piano recordings with\nsystematically varied EQ settings, we evaluate both regression and neural\nnetwork models. The neural network achieves a mean squared error of 0.0216 on\nmulti-band tasks. The system enables practical, flexible, and automated tone\nmatching for music producers and lays the foundation for extensions to more\ncomplex audio effects."}
{"id": "2509.24408", "pdf": "https://arxiv.org/pdf/2509.24408", "abs": "https://arxiv.org/abs/2509.24408", "authors": ["Yuzhen Long", "Songze Li"], "title": "FuncPoison: Poisoning Function Library to Hijack Multi-agent Autonomous Driving Systems", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "Autonomous driving systems increasingly rely on multi-agent architectures\npowered by large language models (LLMs), where specialized agents collaborate\nto perceive, reason, and plan. A key component of these systems is the shared\nfunction library, a collection of software tools that agents use to process\nsensor data and navigate complex driving environments. Despite its critical\nrole in agent decision-making, the function library remains an under-explored\nvulnerability. In this paper, we introduce FuncPoison, a novel poisoning-based\nattack targeting the function library to manipulate the behavior of LLM-driven\nmulti-agent autonomous systems. FuncPoison exploits two key weaknesses in how\nagents access the function library: (1) agents rely on text-based instructions\nto select tools; and (2) these tools are activated using standardized command\nformats that attackers can replicate. By injecting malicious tools with\ndeceptive instructions, FuncPoison manipulates one agent s decisions--such as\nmisinterpreting road conditions--triggering cascading errors that mislead other\nagents in the system. We experimentally evaluate FuncPoison on two\nrepresentative multi-agent autonomous driving systems, demonstrating its\nability to significantly degrade trajectory accuracy, flexibly target specific\nagents to induce coordinated misbehavior, and evade diverse defense mechanisms.\nOur results reveal that the function library, often considered a simple\ntoolset, can serve as a critical attack surface in LLM-based autonomous driving\nsystems, raising elevated concerns on their reliability."}
{"id": "2509.24424", "pdf": "https://arxiv.org/pdf/2509.24424", "abs": "https://arxiv.org/abs/2509.24424", "authors": ["Mingshi Xu", "Haoren Zhu", "Wilfred Siu Hung Ng"], "title": "Multi-Item-Query Attention for Stable Sequential Recommendation", "categories": ["cs.IR", "cs.AI", "cs.LG"], "comment": null, "summary": "The inherent instability and noise in user interaction data challenge\nsequential recommendation systems. Prevailing masked attention models, relying\non a single query from the most recent item, are sensitive to this noise,\nreducing prediction reliability. We propose the Multi-Item-Query attention\nmechanism (MIQ-Attn) to enhance model stability and accuracy. MIQ-Attn\nconstructs multiple diverse query vectors from user interactions, effectively\nmitigating noise and improving consistency. It is designed for easy adoption as\na drop-in replacement for existing single-query attention. Experiments show\nMIQ-Attn significantly improves performance on benchmark datasets."}
{"id": "2509.24446", "pdf": "https://arxiv.org/pdf/2509.24446", "abs": "https://arxiv.org/abs/2509.24446", "authors": ["Jeremias Dötterl"], "title": "Contrastive Learning for Correlating Network Incidents", "categories": ["cs.NI", "cs.LG"], "comment": "Accepted at The 26th International Conference on Intelligent Data\n  Engineering and Automated Learning (IDEAL 2025). This work was partially\n  funded by the German Federal Ministry of Research, Technology and Space\n  (BMFTR) in the FRONT-RUNNER project (Grant 16KISR005K)", "summary": "Internet service providers monitor their networks to detect, triage, and\nremediate service impairments. When an incident is detected, it is important to\ndetermine whether similar incidents have occurred in the past or are happening\nconcurrently elsewhere in the network. Manual correlation of such incidents is\ninfeasible due to the scale of the networks under observation, making automated\ncorrelation a necessity. This paper presents a self-supervised learning method\nfor similarity-based correlation of network situations. Using this method, a\ndeep neural network is trained on a large unlabeled dataset of network\nsituations using contrastive learning. High precision achieved in experiments\non real-world network monitoring data suggests that contrastive learning is a\npromising approach to network incident correlation."}
{"id": "2509.24473", "pdf": "https://arxiv.org/pdf/2509.24473", "abs": "https://arxiv.org/abs/2509.24473", "authors": ["Shijie Lian", "Changti Wu", "Laurence Tianruo Yang", "Hang Yuan", "Bin Yu", "Lei Zhang", "Kai Chen"], "title": "Euclid's Gift: Enhancing Spatial Perception and Reasoning in Vision-Language Models via Geometric Surrogate Tasks", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Spatial intelligence spans a rich suite of abilities, including visualising\nand transforming shapes, mentally rotating objects, judging relational\npositions and containment, and estimating numerosity. However, it still remains\na critical unresolved challenge for Multimodal Large Language Models (MLLMs).To\nfill this gap, we propose to treat Euclidean geometry problem-solving as a\nsurrogate task. Specifically, we meticulously constructed a curated multimodal\ndataset, called Euclid30K, comprising approximately 30K plane and solid\ngeometry problems. To enable the model to acquire and apply Euclidean\nprinciples from these geometry problems, we employed Group Relative Policy\nOptimization (GRPO) to finetune the Qwen2.5VL family and RoboBrain2.0 family,\ninspiring the models to identify shapes, count, and relate entities, and\nperform multi-step deductive reasoning using Euclidean principles. Our\nexperiments demonstrate that the resulting models achieve substantial zero-shot\ngains across four spatial reasoning benchmarks (Super-CLEVR, Omni3DBench,\nVSI-Bench, and MindCube) without any task-specific adaptations. Notably, after\ntraining on the Euclid30K, the mean VSI-Bench accuracy of all evaluated models\nrose from 34.5% to 40.5%, improving by 5.5 percentage points. Among them,\nRoboBrain2.0-Euclid-7B achieves 49.6\\% accuracy, surpassing the previous\nstate-of-the-art model, Spatial-MLLM.To our knowledge, this is the first\nsystematic study showing that geometry-centric fine-tuning can confer\nvision-language models with broadly transferable spatial skills. Code and\nEuclid30K dataset can be found in https://zgca-ai4edu.github.io/Euclids_Gift."}
{"id": "2509.24488", "pdf": "https://arxiv.org/pdf/2509.24488", "abs": "https://arxiv.org/abs/2509.24488", "authors": ["Wenjie Fu", "Huandong Wang", "Junyao Gao", "Guoan Wan", "Tao Jiang"], "title": "Sanitize Your Responses: Mitigating Privacy Leakage in Large Language Models", "categories": ["cs.CL", "cs.CR", "cs.LG"], "comment": null, "summary": "As Large Language Models (LLMs) achieve remarkable success across a wide\nrange of applications, such as chatbots and code copilots, concerns surrounding\nthe generation of harmful content have come increasingly into focus. Despite\nsignificant advances in aligning LLMs with safety and ethical standards,\nadversarial prompts can still be crafted to elicit undesirable responses.\nExisting mitigation strategies are predominantly based on post-hoc filtering,\nwhich introduces substantial latency or computational overhead, and is\nincompatible with token-level streaming generation. In this work, we introduce\nSelf-Sanitize, a novel LLM-driven mitigation framework inspired by cognitive\npsychology, which emulates human self-monitor and self-repair behaviors during\nconversations. Self-Sanitize comprises a lightweight Self-Monitor module that\ncontinuously inspects high-level intentions within the LLM at the token level\nvia representation engineering, and a Self-Repair module that performs in-place\ncorrection of harmful content without initiating separate review dialogues.\nThis design allows for real-time streaming monitoring and seamless repair, with\nnegligible impact on latency and resource utilization. Given that\nprivacy-invasive content has often been insufficiently focused in previous\nstudies, we perform extensive experiments on four LLMs across three privacy\nleakage scenarios. The results demonstrate that Self-Sanitize achieves superior\nmitigation performance with minimal overhead and without degrading the utility\nof LLMs, offering a practical and robust solution for safer LLM deployments.\nOur code is available at the following link:\nhttps://github.com/wjfu99/LLM_Self_Sanitize"}
{"id": "2509.24489", "pdf": "https://arxiv.org/pdf/2509.24489", "abs": "https://arxiv.org/abs/2509.24489", "authors": ["Vasileios Balafas", "Dimos Tsouros", "Nikolaos Ploskas", "Kostas Stergiou"], "title": "Overcoming Over-Fitting in Constraint Acquisition via Query-Driven Interactive Refinement", "categories": ["cs.AI", "cs.LG", "cs.LO", "68T20, 68Q25", "I.2.8; F.2.2"], "comment": "Preprint. Uses the International Journal on Artificial Intelligence\n  Tools (World Scientific) template. Includes figures, tables, and algorithms.\n  Submitted to IJAIT", "summary": "Manual modeling in Constraint Programming is a substantial bottleneck, which\nConstraint Acquisition (CA) aims to automate. However, passive CA methods are\nprone to over-fitting, often learning models that include spurious global\nconstraints when trained on limited data, while purely active methods can be\nquery-intensive. We introduce a hybrid CA framework specifically designed to\naddress the challenge of over-fitting in CA. Our approach integrates passive\nlearning for initial candidate generation, a query-driven interactive\nrefinement phase that utilizes probabilistic confidence scores (initialized by\nmachine learning priors) to systematically identify over-fitted constraints,\nand a specialized subset exploration mechanism to recover valid substructures\nfrom rejected candidates. A final active learning phase ensures model\ncompleteness. Extensive experiments on diverse benchmarks demonstrate that our\ninteractive refinement phase is crucial for achieving high target model\ncoverage and overall model accuracy from limited examples, doing so with\nmanageable query complexity. This framework represents a substantial\nadvancement towards robust and practical constraint acquisition in data-limited\nscenarios."}
{"id": "2509.24493", "pdf": "https://arxiv.org/pdf/2509.24493", "abs": "https://arxiv.org/abs/2509.24493", "authors": ["Nan Lu", "Jian Shi", "Xin-Yu Tian"], "title": "Preference-Based Dynamic Ranking Structure Recognition", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": null, "summary": "Preference-based data often appear complex and noisy but may conceal\nunderlying homogeneous structures. This paper introduces a novel framework of\nranking structure recognition for preference-based data. We first develop an\napproach to identify dynamic ranking groups by incorporating temporal penalties\ninto a spectral estimation for the celebrated Bradley-Terry model. To detect\nstructural changes, we introduce an innovative objective function and present a\npracticable algorithm based on dynamic programming. Theoretically, we establish\nthe consistency of ranking group recognition by exploiting properties of a\nrandom `design matrix' induced by a reversible Markov chain. We also tailor a\ngroup inverse technique to quantify the uncertainty in item ability estimates.\nAdditionally, we prove the consistency of structure change recognition,\nensuring the robustness of the proposed framework. Experiments on both\nsynthetic and real-world datasets demonstrate the practical utility and\ninterpretability of our approach."}
{"id": "2509.24495", "pdf": "https://arxiv.org/pdf/2509.24495", "abs": "https://arxiv.org/abs/2509.24495", "authors": ["Mateusz Żarski", "Sławomir Nowaczyk"], "title": "Neuroplasticity-inspired dynamic ANNs for multi-task demand forecasting", "categories": ["cs.AI", "cs.LG"], "comment": "14 pages, 3 figures, 2 tables", "summary": "This paper introduces a novel approach to Dynamic Artificial Neural Networks\n(D-ANNs) for multi-task demand forecasting called Neuroplastic Multi-Task\nNetwork (NMT-Net). Unlike conventional methods focusing on inference-time\ndynamics or computational efficiency, our proposed method enables structural\nadaptability of the computational graph during training, inspired by\nneuroplasticity as seen in biological systems. Each new task triggers a dynamic\nnetwork adaptation, including similarity-based task identification and\nselective training of candidate ANN heads, which are then assessed and\nintegrated into the model based on their performance. We evaluated our\nframework using three real-world multi-task demand forecasting datasets from\nKaggle. We demonstrated its superior performance and consistency, achieving\nlower RMSE and standard deviation compared to traditional baselines and\nstate-of-the-art multi-task learning methods. NMT-Net offers a scalable,\nadaptable solution for multi-task and continual learning in time series\nprediction. The complete code for NMT-Net is available from our GitHub\nrepository."}
{"id": "2509.24526", "pdf": "https://arxiv.org/pdf/2509.24526", "abs": "https://arxiv.org/abs/2509.24526", "authors": ["Zheyuan Hu", "Chieh-Hsin Lai", "Yuki Mitsufuji", "Stefano Ermon"], "title": "CMT: Mid-Training for Efficient Learning of Consistency, Mean Flow, and Flow Map Models", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Preprint", "summary": "Flow map models such as Consistency Models (CM) and Mean Flow (MF) enable\nfew-step generation by learning the long jump of the ODE solution of diffusion\nmodels, yet training remains unstable, sensitive to hyperparameters, and\ncostly. Initializing from a pre-trained diffusion model helps, but still\nrequires converting infinitesimal steps into a long-jump map, leaving\ninstability unresolved. We introduce mid-training, the first concept and\npractical method that inserts a lightweight intermediate stage between the\n(diffusion) pre-training and the final flow map training (i.e., post-training)\nfor vision generation. Concretely, Consistency Mid-Training (CMT) is a compact\nand principled stage that trains a model to map points along a solver\ntrajectory from a pre-trained model, starting from a prior sample, directly to\nthe solver-generated clean sample. It yields a trajectory-consistent and stable\ninitialization. This initializer outperforms random and diffusion-based\nbaselines and enables fast, robust convergence without heuristics. Initializing\npost-training with CMT weights further simplifies flow map learning.\nEmpirically, CMT achieves state of the art two step FIDs: 1.97 on CIFAR-10,\n1.32 on ImageNet 64x64, and 1.84 on ImageNet 512x512, while using up to 98%\nless training data and GPU time, compared to CMs. On ImageNet 256x256, CMT\nreaches 1-step FID 3.34 while cutting total training time by about 50% compared\nto MF from scratch (FID 3.43). This establishes CMT as a principled, efficient,\nand general framework for training flow map models."}
{"id": "2509.24527", "pdf": "https://arxiv.org/pdf/2509.24527", "abs": "https://arxiv.org/abs/2509.24527", "authors": ["Danijar Hafner", "Wilson Yan", "Timothy Lillicrap"], "title": "Training Agents Inside of Scalable World Models", "categories": ["cs.AI", "cs.LG", "cs.RO", "stat.ML"], "comment": "Website: https://danijar.com/dreamer4/", "summary": "World models learn general knowledge from videos and simulate experience for\ntraining behaviors in imagination, offering a path towards intelligent agents.\nHowever, previous world models have been unable to accurately predict object\ninteractions in complex environments. We introduce Dreamer 4, a scalable agent\nthat learns to solve control tasks by reinforcement learning inside of a fast\nand accurate world model. In the complex video game Minecraft, the world model\naccurately predicts object interactions and game mechanics, outperforming\nprevious world models by a large margin. The world model achieves real-time\ninteractive inference on a single GPU through a shortcut forcing objective and\nan efficient transformer architecture. Moreover, the world model learns general\naction conditioning from only a small amount of data, allowing it to extract\nthe majority of its knowledge from diverse unlabeled videos. We propose the\nchallenge of obtaining diamonds in Minecraft from only offline data, aligning\nwith practical applications such as robotics where learning from environment\ninteraction can be unsafe and slow. This task requires choosing sequences of\nover 20,000 mouse and keyboard actions from raw pixels. By learning behaviors\nin imagination, Dreamer 4 is the first agent to obtain diamonds in Minecraft\npurely from offline data, without environment interaction. Our work provides a\nscalable recipe for imagination training, marking a step towards intelligent\nagents."}
{"id": "2509.24544", "pdf": "https://arxiv.org/pdf/2509.24544", "abs": "https://arxiv.org/abs/2509.24544", "authors": ["Eloy Mosig", "Andrea Agazzi", "Dario Trevisan"], "title": "Quantitative convergence of trained single layer neural networks to Gaussian processes", "categories": ["stat.ML", "cs.LG", "math.PR"], "comment": "Submitted and accepted at NeurIPS 2025, main body of 10 pages, 3\n  figures, 28 pages of supplementary material", "summary": "In this paper, we study the quantitative convergence of shallow neural\nnetworks trained via gradient descent to their associated Gaussian processes in\nthe infinite-width limit.\n  While previous work has established qualitative convergence under broad\nsettings, precise, finite-width estimates remain limited, particularly during\ntraining.\n  We provide explicit upper bounds on the quadratic Wasserstein distance\nbetween the network output and its Gaussian approximation at any training time\n$t \\ge 0$, demonstrating polynomial decay with network width.\n  Our results quantify how architectural parameters, such as width and input\ndimension, influence convergence, and how training dynamics affect the\napproximation error."}
{"id": "2509.24569", "pdf": "https://arxiv.org/pdf/2509.24569", "abs": "https://arxiv.org/abs/2509.24569", "authors": ["Josep Lumbreras"], "title": "Bandits roaming Hilbert space", "categories": ["quant-ph", "cs.AI", "cs.LG", "stat.ML"], "comment": "PhD thesis, Centre for Quantum Technologies, National University of\n  Singapore", "summary": "This thesis studies the exploration and exploitation trade-off in online\nlearning of properties of quantum states using multi-armed bandits. Given\nstreaming access to an unknown quantum state, in each round we select an\nobservable from a set of actions to maximize its expectation value. Using past\ninformation, we refine actions to minimize regret; the cumulative gap between\ncurrent reward and the maximum possible. We derive information-theoretic lower\nbounds and optimal strategies with matching upper bounds, showing regret\ntypically scales as the square root of rounds. As an application, we reframe\nquantum state tomography to both learn the state efficiently and minimize\nmeasurement disturbance. For pure states and continuous actions, we achieve\npolylogarithmic regret using a sample-optimal algorithm based on a weighted\nonline least squares estimator. The algorithm relies on the optimistic\nprinciple and controls the eigenvalues of the design matrix. We also apply our\nframework to quantum recommender systems and thermodynamic work extraction from\nunknown states. In this last setting, our results demonstrate an exponential\nadvantage in work dissipation over tomography-based protocols."}
{"id": "2509.24575", "pdf": "https://arxiv.org/pdf/2509.24575", "abs": "https://arxiv.org/abs/2509.24575", "authors": ["Nicolas Pfitzer", "Eduardo Sebastián", "Ajay Shankar", "Amanda Prorok"], "title": "Prompting Robot Teams with Natural Language", "categories": ["cs.RO", "cs.LG", "cs.MA"], "comment": null, "summary": "This paper presents a framework towards prompting multi-robot teams with\nhigh-level tasks using natural language expressions. Our objective is to use\nthe reasoning capabilities demonstrated by recent language models in\nunderstanding and decomposing human expressions of intent, and repurpose these\nfor multi-robot collaboration and decision-making. The key challenge is that an\nindividual's behavior in a collective can be hard to specify and interpret, and\nmust continuously adapt to actions from others. This necessitates a framework\nthat possesses the representational capacity required by the logic and\nsemantics of a task, and yet supports decentralized and interactive real-time\noperation. We solve this dilemma by recognizing that a task can be represented\nas a deterministic finite automaton (DFA), and that recurrent neural networks\n(RNNs) can encode numerous automata. This allows us to distill the logic and\nsequential decompositions of sub-tasks obtained from a language model into an\nRNN, and align its internal states with the semantics of a given task. By\ntraining a graph neural network (GNN) control policy that is conditioned on the\nhidden states of the RNN and the language embeddings, our method enables robots\nto execute task-relevant actions in a decentralized manner. We present\nevaluations of this single light-weight interpretable model on various\nsimulated and real-world multi-robot tasks that require sequential and\ncollaborative behavior by the team -- sites.google.com/view/prompting-teams."}
{"id": "2509.24597", "pdf": "https://arxiv.org/pdf/2509.24597", "abs": "https://arxiv.org/abs/2509.24597", "authors": ["Melika Honarmand", "Ayati Sharma", "Badr AlKhamissi", "Johannes Mehrer", "Martin Schrimpf"], "title": "Inducing Dyslexia in Vision Language Models", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Dyslexia, a neurodevelopmental disorder characterized by persistent reading\ndifficulties, is often linked to reduced activity of the visual word form area\nin the ventral occipito-temporal cortex. Traditional approaches to studying\ndyslexia, such as behavioral and neuroimaging methods, have provided valuable\ninsights but remain limited in their ability to test causal hypotheses about\nthe underlying mechanisms of reading impairments. In this study, we use\nlarge-scale vision-language models (VLMs) to simulate dyslexia by functionally\nidentifying and perturbing artificial analogues of word processing. Using\nstimuli from cognitive neuroscience, we identify visual-word-form-selective\nunits within VLMs and demonstrate that targeted ablation of these units, unlike\nablation of random units, leads to selective impairments in reading tasks while\ngeneral visual and language comprehension abilities remain intact. In\nparticular, the resulting model matches dyslexic humans' phonological deficits\nwithout a significant change in orthographic processing. Taken together, our\nmodeling results replicate key characteristics of dyslexia and establish a\ncomputational framework for investigating reading disorders."}
{"id": "2509.24607", "pdf": "https://arxiv.org/pdf/2509.24607", "abs": "https://arxiv.org/abs/2509.24607", "authors": ["Igor V. Netay"], "title": "Algorithms and data structures for automatic precision estimation of neural networks", "categories": ["cs.DS", "cs.AI", "cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "We describe algorithms and data structures to extend a neural network library\nwith automatic precision estimation for floating point computations. We also\ndiscuss conditions to make estimations exact and preserve high computation\nperformance of neural networks training and inference. Numerical experiments\nshow the consequences of significant precision loss for particular values such\nas inference, gradients and deviations from mathematically predicted behavior.\n  It turns out that almost any neural network accumulates computational\ninaccuracies. As a result, its behavior does not coincide with predicted by the\nmathematical model of neural network. This shows that tracking of computational\ninaccuracies is important for reliability of inference, training and\ninterpretability of results."}
{"id": "2509.24638", "pdf": "https://arxiv.org/pdf/2509.24638", "abs": "https://arxiv.org/abs/2509.24638", "authors": ["Bojan Batalo", "Erica K. Shimomoto", "Neil Millar"], "title": "Hype or not? Formalizing Automatic Promotional Language Detection in Biomedical Research", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "In science, promotional language ('hype') is increasing and can undermine\nobjective evaluation of evidence, impede research development, and erode trust\nin science. In this paper, we introduce the task of automatic detection of\nhype, which we define as hyperbolic or subjective language that authors use to\nglamorize, promote, embellish, or exaggerate aspects of their research. We\npropose formalized guidelines for identifying hype language and apply them to\nannotate a portion of the National Institutes of Health (NIH) grant application\ncorpus. We then evaluate traditional text classifiers and language models on\nthis task, comparing their performance with a human baseline. Our experiments\nshow that formalizing annotation guidelines can help humans reliably annotate\ncandidate hype adjectives and that using our annotated dataset to train machine\nlearning models yields promising results. Our findings highlight the linguistic\ncomplexity of the task, and the potential need for domain knowledge and\ntemporal awareness of the facts. While some linguistic works address hype\ndetection, to the best of our knowledge, we are the first to approach it as a\nnatural language processing task."}
{"id": "2509.24663", "pdf": "https://arxiv.org/pdf/2509.24663", "abs": "https://arxiv.org/abs/2509.24663", "authors": ["Weilin Zhao", "Zihan Zhou", "Zhou Su", "Chaojun Xiao", "Yuxuan Li", "Yanghao Li", "Yudi Zhang", "Weilun Zhao", "Zhen Li", "Yuxiang Huang", "Ao Sun", "Xu Han", "Zhiyuan Liu"], "title": "InfLLM-V2: Dense-Sparse Switchable Attention for Seamless Short-to-Long Adaptation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Long-sequence processing is a critical capability for modern large language\nmodels. However, the self-attention mechanism in the standard Transformer\narchitecture faces severe computational and memory bottlenecks when processing\nlong sequences. While trainable sparse attention methods offer a promising\nsolution, existing approaches such as NSA introduce excessive extra parameters\nand disrupt the conventional \\textit{pretrain-on-short, finetune-on-long}\nworkflow, resulting in slow convergence and difficulty in acceleration. To\novercome these limitations, we introduce dense-sparse switchable attention\nframework, termed as InfLLM-V2. InfLLM-V2 is a trainable sparse attention that\nseamlessly adapts models from short to long sequences. Specifically, InfLLM-V2\nreuses dense attention parameters through parameter-free architecture\nmodification, maintaining consistency between short and long sequence\nprocessing. Additionally, InfLLM-V2 ensures computational efficiency across all\nsequence lengths, by using dense attention for short inputs and smoothly\ntransitioning to sparse attention for long sequences. To achieve practical\nacceleration, we further introduce an efficient implementation of InfLLM-V2\nthat significantly reduces the computational overhead. Our experiments on\nlong-context understanding and chain-of-thought reasoning demonstrate that\nInfLLM-V2 is 4$\\times$ faster than dense attention while retaining 98.1% and\n99.7% of the performance, respectively. Based on the InfLLM-V2 framework, we\nhave trained and open-sourced MiniCPM4.1\n(https://huggingface.co/openbmb/MiniCPM4.1-8B), a hybrid reasoning model,\nproviding a reproducible implementation for the research community."}
{"id": "2509.24678", "pdf": "https://arxiv.org/pdf/2509.24678", "abs": "https://arxiv.org/abs/2509.24678", "authors": ["Leander Girrbach", "Chi-Ping Su", "Tankred Saanum", "Richard Socher", "Eric Schulz", "Zeynep Akata"], "title": "Reference-Free Rating of LLM Responses via Latent Information", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "21 pages", "summary": "How reliable are single-response LLM-as-a-judge ratings without references,\nand can we obtain fine-grained, deterministic scores in this setting? We study\nthe common practice of asking a judge model to assign Likert-scale scores to\nfree-text responses and show two systematic issues: scores are unstable under\nsampling and poorly calibrated, leading to compression near the top of the\nscale and frequent ties. We then propose and evaluate Latent Judges, which\nderive scalar ratings from internal model signals: (i) probability-weighted\nscores over integer ratings, (ii) verifier-style probabilities of \"yes\", and\n(iii) linear probes trained on model activations at the rating position. Across\na broad suite of pairwise and single-rating benchmarks, latent methods match or\nsurpass standard prompting, with consistent gains on pairwise accuracy and\nlistwise ranking relevant to Best-of-N selection. Probability-weighted scores\nachieve the strongest single-rating correlations, while probes recover useful\nsignals when output logits are miscalibrated. These results indicate that\nlatent information provides deterministic and more discriminative signals for\nreference-free evaluation, and can improve selection and training approaches\nlike Best-of-$N$, multi-teacher distillation, and routing."}
{"id": "2509.24697", "pdf": "https://arxiv.org/pdf/2509.24697", "abs": "https://arxiv.org/abs/2509.24697", "authors": ["Evelyn D'Elia", "Paolo Maria Viceconte", "Lorenzo Rapetti", "Diego Ferigo", "Giulio Romualdi", "Giuseppe L'Erario", "Raffaello Camoriano", "Daniele Pucci"], "title": "Stabilizing Humanoid Robot Trajectory Generation via Physics-Informed Learning and Control-Informed Steering", "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY"], "comment": "This paper has been accepted for publication at the IEEE/RSJ\n  International Conference on Intelligent Robots and Systems (IROS), Hangzhou,\n  China, 2025", "summary": "Recent trends in humanoid robot control have successfully employed imitation\nlearning to enable the learned generation of smooth, human-like trajectories\nfrom human data. While these approaches make more realistic motions possible,\nthey are limited by the amount of available motion data, and do not incorporate\nprior knowledge about the physical laws governing the system and its\ninteractions with the environment. Thus they may violate such laws, leading to\ndivergent trajectories and sliding contacts which limit real-world stability.\nWe address such limitations via a two-pronged learning strategy which leverages\nthe known physics of the system and fundamental control principles. First, we\nencode physics priors during supervised imitation learning to promote\ntrajectory feasibility. Second, we minimize drift at inference time by applying\na proportional-integral controller directly to the generated output state. We\nvalidate our method on various locomotion behaviors for the ergoCub humanoid\nrobot, where a physics-informed loss encourages zero contact foot velocity. Our\nexperiments demonstrate that the proposed approach is compatible with multiple\ncontrollers on a real robot and significantly improves the accuracy and\nphysical constraint conformity of generated trajectories."}
{"id": "2509.24710", "pdf": "https://arxiv.org/pdf/2509.24710", "abs": "https://arxiv.org/abs/2509.24710", "authors": ["Dennis Elbrächter", "Giovanni S. Alberti", "Matteo Santacesaria"], "title": "MAD: Manifold Attracted Diffusion", "categories": ["stat.ML", "cs.LG", "cs.NA", "math.NA"], "comment": "21 pages, 13 figures", "summary": "Score-based diffusion models are a highly effective method for generating\nsamples from a distribution of images. We consider scenarios where the training\ndata comes from a noisy version of the target distribution, and present an\nefficiently implementable modification of the inference procedure to generate\nnoiseless samples. Our approach is motivated by the manifold hypothesis,\naccording to which meaningful data is concentrated around some low-dimensional\nmanifold of a high-dimensional ambient space. The central idea is that noise\nmanifests as low magnitude variation in off-manifold directions in contrast to\nthe relevant variation of the desired distribution which is mostly confined to\non-manifold directions. We introduce the notion of an extended score and show\nthat, in a simplified setting, it can be used to reduce small variations to\nzero, while leaving large variations mostly unchanged. We describe how its\napproximation can be computed efficiently from an approximation to the standard\nscore and demonstrate its efficacy on toy problems, synthetic data, and real\ndata."}
{"id": "2509.24736", "pdf": "https://arxiv.org/pdf/2509.24736", "abs": "https://arxiv.org/abs/2509.24736", "authors": ["Francesca Demelas", "Joseph Le Roux", "Antonio Frangioni", "Mathieu Lacroix", "Emiliano Traversi", "Roberto Wolfler Calvo"], "title": "Bundle Network: a Machine Learning-Based Bundle Method", "categories": ["math.OC", "cs.LG"], "comment": null, "summary": "This paper presents Bundle Network, a learning-based algorithm inspired by\nthe Bundle Method for convex non-smooth minimization problems. Unlike classical\napproaches that rely on heuristic tuning of a regularization parameter, our\nmethod automatically learns to adjust it from data. Furthermore, we replace the\niterative resolution of the optimization problem that provides the search\ndirection-traditionally computed as a convex combination of gradients at\nvisited points-with a recurrent neural model equipped with an attention\nmechanism. By leveraging the unrolled graph of computation, our Bundle Network\ncan be trained end-to-end via automatic differentiation. Experiments on\nLagrangian dual relaxations of the Multi-Commodity Network Design and\nGeneralized Assignment problems demonstrate that our approach consistently\noutperforms traditional methods relying on grid search for parameter tuning,\nwhile generalizing effectively across datasets."}
{"id": "2509.24745", "pdf": "https://arxiv.org/pdf/2509.24745", "abs": "https://arxiv.org/abs/2509.24745", "authors": ["Yixuan Wang", "Huang He", "Siqi Bao", "Hua Wu", "Haifeng Wang", "Qingfu Zhu", "Wanxiang Che"], "title": "ProxyAttn: Guided Sparse Attention via Representative Heads", "categories": ["cs.CL", "cs.LG"], "comment": "14pages, 5figures", "summary": "The quadratic complexity of attention mechanisms limits the efficiency of\nLarge Language Models (LLMs) on long-text tasks. Recently, methods that\ndynamically estimate block importance have enabled efficient block sparse\nattention, leading to significant acceleration in long-text pre-filling of\nLLMs. However, their coarse-grained estimation inevitably leads to performance\ndegradation at high sparsity rates. In this work, we propose ProxyAttn, a\ntraining-free sparse attention algorithm that achieves more precise block\nestimation by compressing the dimension of attention heads. Based on our\nobservation of the similarity among multiple attention heads, we use the scores\nof pooled representative heads to approximate the scores for all heads. To\naccount for the varying sparsity among heads, we also propose a block-aware\ndynamic budget estimation method. By combining the scores from representative\nproxy heads with multi-head dynamic budgets, we achieve a more fine-grained\nblock importance evaluation at low computational cost. Experiments on a variety\nof mainstream models and extensive benchmarks confirm the underlying similarity\namong attention heads. Leveraging a fine-grained estimation, the proposed\nmethod achieves substantial gains in performance and efficiency compared to\nexisting methods. More precisely, ProxyAttn can achieve up to 10.3x attention\nacceleration and 2.4x prefilling acceleration without significant performance\nloss. Our code is available at https://github.com/wyxstriker/ProxyAttn."}
{"id": "2509.24761", "pdf": "https://arxiv.org/pdf/2509.24761", "abs": "https://arxiv.org/abs/2509.24761", "authors": ["Yueming Sun", "Long Yang"], "title": "Spatial-Functional awareness Transformer-based graph archetype contrastive learning for Decoding Visual Neural Representations from EEG", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Decoding visual neural representations from Electroencephalography (EEG)\nsignals remains a formidable challenge due to their high-dimensional, noisy,\nand non-Euclidean nature. In this work, we propose a Spatial-Functional\nAwareness Transformer-based Graph Archetype Contrastive Learning (SFTG)\nframework to enhance EEG-based visual decoding. Specifically, we introduce the\nEEG Graph Transformer (EGT), a novel graph-based neural architecture that\nsimultaneously encodes spatial brain connectivity and temporal neural dynamics.\nTo mitigate high intra-subject variability, we propose Graph Archetype\nContrastive Learning (GAC), which learns subject-specific EEG graph archetypes\nto improve feature consistency and class separability. Furthermore, we conduct\ncomprehensive subject-dependent and subject-independent evaluations on the\nThings-EEG dataset, demonstrating that our approach significantly outperforms\nprior state-of-the-art EEG decoding methods.The results underscore the\ntransformative potential of integrating graph-based learning with contrastive\nobjectives to enhance EEG-based brain decoding, paving the way for more\ngeneralizable and robust neural representations."}
{"id": "2509.24793", "pdf": "https://arxiv.org/pdf/2509.24793", "abs": "https://arxiv.org/abs/2509.24793", "authors": ["Théo Mariotte", "Martin Lebourdais", "Antonio Almudévar", "Marie Tahon", "Alfonso Ortega", "Nicolas Dugué"], "title": "Sparse Autoencoders Make Audio Foundation Models more Explainable", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "comment": "5 pages, 5 figures, 1 table, submitted to ICASSP 2026", "summary": "Audio pretrained models are widely employed to solve various tasks in speech\nprocessing, sound event detection, or music information retrieval. However, the\nrepresentations learned by these models are unclear, and their analysis mainly\nrestricts to linear probing of the hidden representations. In this work, we\nexplore the use of Sparse Autoencoders (SAEs) to analyze the hidden\nrepresentations of pretrained models, focusing on a case study in singing\ntechnique classification. We first demonstrate that SAEs retain both\ninformation about the original representations and class labels, enabling their\ninternal structure to provide insights into self-supervised learning systems.\nFurthermore, we show that SAEs enhance the disentanglement of vocal attributes,\nestablishing them as an effective tool for identifying the underlying factors\nencoded in the representations."}
{"id": "2509.24797", "pdf": "https://arxiv.org/pdf/2509.24797", "abs": "https://arxiv.org/abs/2509.24797", "authors": ["Zizhao Tong", "Di Chen", "Sicheng Hu", "Hongwei Fan", "Liliang Chen", "Guanghui Ren", "Hao Tang", "Hao Dong", "Ling Shao"], "title": "Fidelity-Aware Data Composition for Robust Robot Generalization", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "33 pages", "summary": "Generalist robot policies trained on large-scale, visually homogeneous\ndatasets can be susceptible to shortcut learning, which impairs their\nout-of-distribution (OOD) generalization. While generative data augmentation is\na common approach to introduce diversity, it presents a subtle challenge: data\ncomposition. Naively mixing real and synthetic data can corrupt the learning\nsignal, as this process often prioritizes visual diversity at the expense of\ninformation fidelity. This paper suggests that robust generalization depends on\nprincipled, fidelity-aware data composition. We introduce Coherent Information\nFidelity Tuning (CIFT), a framework that treats data composition as an\noptimization problem. CIFT uses a practical proxy for Information Fidelity\nbased on the feature-space geometry of a dataset. This enables the\nidentification of a phase transition, termed the Decoherence Point, where\ntraining stability degrades. The framework includes a generative engine,\nMulti-View Video Augmentation (MVAug), to synthesize a causally disentangled\ndata spectrum for this tuning process. Applying CIFT to policy architectures\nsuch as $\\pi_0$ and Diffusion Policy improves OOD success rates by over 54\\%.\nThese results indicate that fidelity-aware composition, beyond data synthesis\nalone, is an important component for developing robust, general-purpose robots."}
{"id": "2509.24802", "pdf": "https://arxiv.org/pdf/2509.24802", "abs": "https://arxiv.org/abs/2509.24802", "authors": ["Anirban Ghosh", "Ayan Dutta"], "title": "TACO-Net: Topological Signatures Triumph in 3D Object Classification", "categories": ["cs.CV", "cs.CG", "cs.LG"], "comment": null, "summary": "3D object classification is a crucial problem due to its significant\npractical relevance in many fields, including computer vision, robotics, and\nautonomous driving. Although deep learning methods applied to point clouds\nsampled on CAD models of the objects and/or captured by LiDAR or RGBD cameras\nhave achieved remarkable success in recent years, achieving high classification\naccuracy remains a challenging problem due to the unordered point clouds and\ntheir irregularity and noise. To this end, we propose a novel state-of-the-art\n(SOTA) 3D object classification technique that combines topological data\nanalysis with various image filtration techniques to classify objects when they\nare represented using point clouds. We transform every point cloud into a\nvoxelized binary 3D image to extract distinguishing topological features. Next,\nwe train a lightweight one-dimensional Convolutional Neural Network (1D CNN)\nusing the extracted feature set from the training dataset. Our framework,\nTACO-Net, sets a new state-of-the-art by achieving $99.05\\%$ and $99.52\\%$\naccuracy on the widely used synthetic benchmarks ModelNet40 and ModelNet10, and\nfurther demonstrates its robustness on the large-scale real-world OmniObject3D\ndataset. When tested with ten different kinds of corrupted ModelNet40 inputs,\nthe proposed TACO-Net demonstrates strong resiliency overall."}
{"id": "2509.24814", "pdf": "https://arxiv.org/pdf/2509.24814", "abs": "https://arxiv.org/abs/2509.24814", "authors": ["Sahana Rayan", "Yash Patel", "Ambuj Tewari"], "title": "A Greedy PDE Router for Blending Neural Operators and Classical Methods", "categories": ["stat.ME", "cs.LG", "stat.ML"], "comment": null, "summary": "When solving PDEs, classical numerical solvers are often computationally\nexpensive, while machine learning methods can suffer from spectral bias,\nfailing to capture high-frequency components. Designing an optimal hybrid\niterative solver--where, at each iteration, a solver is selected from an\nensemble of solvers to leverage their complementary strengths--poses a\nchallenging combinatorial problem. While the greedy selection strategy is\ndesirable for its constant-factor approximation guarantee to the optimal\nsolution, it requires knowledge of the true error at each step, which is\ngenerally unavailable in practice. We address this by proposing an approximate\ngreedy router that efficiently mimics a greedy approach to solver selection.\nEmpirical results on the Poisson and Helmholtz equations demonstrate that our\nmethod outperforms single-solver baselines and existing hybrid solver\napproaches, such as HINTS, achieving faster and more stable convergence."}
{"id": "2509.24815", "pdf": "https://arxiv.org/pdf/2509.24815", "abs": "https://arxiv.org/abs/2509.24815", "authors": ["Sebastian Bruch", "Franco Maria Nardini", "Cosimo Rulli", "Rossano Venturini"], "title": "Efficient Sketching and Nearest Neighbor Search Algorithms for Sparse Vector Sets", "categories": ["cs.DS", "cs.IR", "cs.LG"], "comment": null, "summary": "Sparse embeddings of data form an attractive class due to their inherent\ninterpretability: Every dimension is tied to a term in some vocabulary, making\nit easy to visually decipher the latent space. Sparsity, however, poses unique\nchallenges for Approximate Nearest Neighbor Search (ANNS) which finds, from a\ncollection of vectors, the k vectors closest to a query. To encourage research\non this underexplored topic, sparse ANNS featured prominently in a BigANN\nChallenge at NeurIPS 2023, where approximate algorithms were evaluated on large\nbenchmark datasets by throughput and accuracy. In this work, we introduce a set\nof novel data structures and algorithmic methods, a combination of which leads\nto an elegant, effective, and highly efficient solution to sparse ANNS. Our\ncontributions range from a theoretically-grounded sketching algorithm for\nsparse vectors to reduce their effective dimensionality while preserving inner\nproduct-induced ranks; a geometric organization of the inverted index; and the\nblending of local and global information to improve the efficiency and efficacy\nof ANNS. Empirically, our final algorithm, dubbed Seismic, reaches\nsub-millisecond per-query latency with high accuracy on a large-scale benchmark\ndataset using a single CPU."}
{"id": "2509.24823", "pdf": "https://arxiv.org/pdf/2509.24823", "abs": "https://arxiv.org/abs/2509.24823", "authors": ["Benedetta Tondi", "Andrea Costanzo", "Mauro Barni"], "title": "Of-SemWat: High-payload text embedding for semantic watermarking of AI-generated images with arbitrary size", "categories": ["cs.CR", "cs.AI", "cs.CV", "cs.LG"], "comment": "5 pages, 2 figures", "summary": "We propose a high-payload image watermarking method for textual embedding,\nwhere a semantic description of the image - which may also correspond to the\ninput text prompt-, is embedded inside the image. In order to be able to\nrobustly embed high payloads in large-scale images - such as those produced by\nmodern AI generators - the proposed approach builds upon a traditional\nwatermarking scheme that exploits orthogonal and turbo codes for improved\nrobustness, and integrates frequency-domain embedding and perceptual masking\ntechniques to enhance watermark imperceptibility. Experiments show that the\nproposed method is extremely robust against a wide variety of image processing,\nand the embedded text can be retrieved also after traditional and AI\ninpainting, permitting to unveil the semantic modification the image has\nundergone via image-text mismatch analysis."}
{"id": "2509.24836", "pdf": "https://arxiv.org/pdf/2509.24836", "abs": "https://arxiv.org/abs/2509.24836", "authors": ["Zhen Bi", "Zhenlin Hu", "Jinnan Yang", "Mingyang Chen", "Cheng Deng", "Yida Xue", "Zeyu Yang", "Qing Shen", "Zhenfang Liu", "Kang Zhao", "Ningyu Zhang", "Jungang Lou"], "title": "Pushing LLMs to Their Logical Reasoning Bound: The Role of Data Reasoning Intensity", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Recent advances in large language models (LLMs) highlight the importance of\ntraining data structure and quality in shaping reasoning behavior. However,\nmost existing approaches focus on transforming data formats while neglecting\nthe internal reasoning complexity of training samples, leaving the reasoning\npotential of data under-explored and underutilized. In this work, we posit that\nLLM logical reasoning performance is jointly constrained by the potential of\nthe training data and the cognitive capacity of the model. To make this\nrelationship measurable, we introduce Data Reasoning Intensity (DRI), a novel\nmetric that quantifies the latent logical reasoning complexity of samples by\ndecomposing and aggregating their logical structures. This allows us to analyze\nhow well current LLMs utilize logical reasoning signals and identify\nperformance gaps relative to data potential. Based on this insight, we\nintroduce a re-cognizing optimization strategy that systematically enhances the\nlogical reasoning intensity of training data.Rather than increasing data\nvolume, our method re-optimizes existing samples to better align with the LLM's\nlogical reasoning boundary. Extensive experiments show that our approach\nsignificantly improves performance and generalization over data-centric\nstrategies. We further validate our method under a reinforcement learning\nframework. Our results indicate that prioritizing reasoning complexity in data\nrather than sheer scale or superficial form is essential to realizing LLMs'\nfull cognitive potential."}
{"id": "2509.24875", "pdf": "https://arxiv.org/pdf/2509.24875", "abs": "https://arxiv.org/abs/2509.24875", "authors": ["Nikos Kostagiolas", "Pantelis Georgiades", "Yannis Panagakis", "Mihalis A. Nicolaou"], "title": "Environment-Aware Satellite Image Generation with Diffusion Models", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Diffusion-based foundation models have recently garnered much attention in\nthe field of generative modeling due to their ability to generate images of\nhigh quality and fidelity. Although not straightforward, their recent\napplication to the field of remote sensing signaled the first successful trials\ntowards harnessing the large volume of publicly available datasets containing\nmultimodal information. Despite their success, existing methods face\nconsiderable limitations: they rely on limited environmental context, struggle\nwith missing or corrupted data, and often fail to reliably reflect user\nintentions in generated outputs. In this work, we propose a novel diffusion\nmodel conditioned on environmental context, that is able to generate satellite\nimages by conditioning from any combination of three different control signals:\na) text, b) metadata, and c) visual data. In contrast to previous works, the\nproposed method is i) to our knowledge, the first of its kind to condition\nsatellite image generation on dynamic environmental conditions as part of its\ncontrol signals, and ii) incorporating a metadata fusion strategy that models\nattribute embedding interactions to account for partially corrupt and/or\nmissing observations. Our method outperforms previous methods both\nqualitatively (robustness to missing metadata, higher responsiveness to control\ninputs) and quantitatively (higher fidelity, accuracy, and quality of\ngenerations measured using 6 different metrics) in the trials of single-image\nand temporal generation. The reported results support our hypothesis that\nconditioning on environmental context can improve the performance of foundation\nmodels for satellite imagery, and render our model a promising candidate for\nusage in downstream tasks. The collected 3-modal dataset is to our knowledge,\nthe first publicly-available dataset to combine data from these three different\nmediums."}
{"id": "2509.24891", "pdf": "https://arxiv.org/pdf/2509.24891", "abs": "https://arxiv.org/abs/2509.24891", "authors": ["Mostafa Mohaimen Akand Faisal", "Rabeya Amin Jhuma"], "title": "VAGUEGAN: Stealthy Poisoning and Backdoor Attacks on Image Generative Pipelines", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Generative models such as GANs and diffusion models are widely used to\nsynthesize photorealistic images and to support downstream creative and editing\ntasks. While adversarial attacks on discriminative models are well studied,\nattacks targeting generative pipelines where small, stealthy perturbations in\ninputs lead to controlled changes in outputs are less explored. This study\nintroduces VagueGAN, an attack pipeline combining a modular perturbation\nnetwork PoisonerNet with a Generator Discriminator pair to craft stealthy\ntriggers that cause targeted changes in generated images. Attack efficacy is\nevaluated using a custom proxy metric, while stealth is analyzed through\nperceptual and frequency domain measures. The transferability of the method to\na modern diffusion based pipeline is further examined through ControlNet guided\nediting. Interestingly, the experiments show that poisoned outputs can display\nhigher visual quality compared to clean counterparts, challenging the\nassumption that poisoning necessarily reduces fidelity. Unlike conventional\npixel level perturbations, latent space poisoning in GANs and diffusion\npipelines can retain or even enhance output aesthetics, exposing a blind spot\nin pixel level defenses. Moreover, carefully optimized perturbations can\nproduce consistent, stealthy effects on generator outputs while remaining\nvisually inconspicuous, raising concerns for the integrity of image generation\npipelines."}
{"id": "2509.24894", "pdf": "https://arxiv.org/pdf/2509.24894", "abs": "https://arxiv.org/abs/2509.24894", "authors": ["Egor Gladin", "Alexey Kroshnin", "Jia-Jie Zhu", "Pavel Dvurechensky"], "title": "Improved Stochastic Optimization of LogSumExp", "categories": ["math.OC", "cs.LG"], "comment": "16 pages, 5 figures", "summary": "The LogSumExp function, also known as the free energy, plays a central role\nin many important optimization problems, including entropy-regularized optimal\ntransport and distributionally robust optimization (DRO). It is also the dual\nto the Kullback-Leibler (KL) divergence, which is widely used in machine\nlearning. In practice, when the number of exponential terms inside the\nlogarithm is large or infinite, optimization becomes challenging since\ncomputing the gradient requires differentiating every term. Previous approaches\nthat replace the full sum with a small batch introduce significant bias. We\npropose a novel approximation to LogSumExp that can be efficiently optimized\nusing stochastic gradient methods. This approximation is rooted in a sound\nmodification of the KL divergence in the dual, resulting in a new\n$f$-divergence called the safe KL divergence. The accuracy of the approximation\nis controlled by a tunable parameter and can be made arbitrarily small. Like\nthe LogSumExp, our approximation preserves convexity. Moreover, when applied to\nan $L$-smooth function bounded from below, the smoothness constant of the\nresulting objective scales linearly with $L$. Experiments in DRO and continuous\noptimal transport demonstrate the advantages of our approach over\nstate-of-the-art baselines and the effective treatment of numerical issues\nassociated with the standard LogSumExp and KL."}
{"id": "2509.24901", "pdf": "https://arxiv.org/pdf/2509.24901", "abs": "https://arxiv.org/abs/2509.24901", "authors": ["Lukas Rauch", "René Heinrich", "Houtan Ghaffari", "Lukas Miklautz", "Ilyass Moummad", "Bernhard Sick", "Christoph Scholz"], "title": "Unmute the Patch Tokens: Rethinking Probing in Multi-Label Audio Classification", "categories": ["cs.SD", "cs.LG"], "comment": "Currently under review @ICLR2026", "summary": "Although probing frozen models has become a standard evaluation paradigm,\nself-supervised learning in audio defaults to fine-tuning. A key reason is that\nglobal pooling creates an information bottleneck causing linear probes to\nmisrepresent the embedding quality: The $\\texttt{cls}$-token discards crucial\ntoken information about dispersed, localized events in multi-label audio. This\nweakness is rooted in the mismatch between the pretraining objective (operating\nglobally) and the downstream task (localized events). Across a comprehensive\nbenchmark of 13 datasets and 6 spectrogram-based encoders, we first investigate\nthe global pooling bottleneck. We then introduce binarized prototypical probes:\na lightweight and simple pooling method that learns prototypes to perform\nclass-wise information aggregation. Despite its simplicity, our method notably\noutperforms linear and attentive probing. Our work establishes probing as a\ncompetitive and efficient paradigm for evaluating audio SSL models, challenging\nthe reliance on costly fine-tuning."}
{"id": "2509.24912", "pdf": "https://arxiv.org/pdf/2509.24912", "abs": "https://arxiv.org/abs/2509.24912", "authors": ["Xiang Li", "Zebang Shen", "Ya-Ping Hsieh", "Niao He"], "title": "When Scores Learn Geometry: Rate Separations under the Manifold Hypothesis", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Score-based methods, such as diffusion models and Bayesian inverse problems,\nare often interpreted as learning the data distribution in the low-noise limit\n($\\sigma \\to 0$). In this work, we propose an alternative perspective: their\nsuccess arises from implicitly learning the data manifold rather than the full\ndistribution. Our claim is based on a novel analysis of scores in the\nsmall-$\\sigma$ regime that reveals a sharp separation of scales: information\nabout the data manifold is $\\Theta(\\sigma^{-2})$ stronger than information\nabout the distribution. We argue that this insight suggests a paradigm shift\nfrom the less practical goal of distributional learning to the more attainable\ntask of geometric learning, which provably tolerates $O(\\sigma^{-2})$ larger\nerrors in score approximation. We illustrate this perspective through three\nconsequences: i) in diffusion models, concentration on data support can be\nachieved with a score error of $o(\\sigma^{-2})$, whereas recovering the\nspecific data distribution requires a much stricter $o(1)$ error; ii) more\nsurprisingly, learning the uniform distribution on the manifold-an especially\nstructured and useful object-is also $O(\\sigma^{-2})$ easier; and iii) in\nBayesian inverse problems, the maximum entropy prior is $O(\\sigma^{-2})$ more\nrobust to score errors than generic priors. Finally, we validate our\ntheoretical findings with preliminary experiments on large-scale models,\nincluding Stable Diffusion."}
{"id": "2509.24914", "pdf": "https://arxiv.org/pdf/2509.24914", "abs": "https://arxiv.org/abs/2509.24914", "authors": ["Fabrizio Boncoraglio", "Vittorio Erba", "Emanuele Troiani", "Florent Krzakala", "Lenka Zdeborová"], "title": "Inductive Bias and Spectral Properties of Single-Head Attention in High Dimensions", "categories": ["stat.ML", "cond-mat.dis-nn", "cs.IT", "cs.LG", "math.IT"], "comment": null, "summary": "We study empirical risk minimization in a single-head tied-attention layer\ntrained on synthetic high-dimensional sequence tasks, given by the recently\nintroduced attention-indexed model. Using tools from random matrix theory,\nspin-glass physics, and approximate message passing, we derive sharp\nasymptotics for training and test errors, locate interpolation and recovery\nthresholds, and characterize the limiting spectral distribution of the learned\nweights. Weight decay induces an implicit nuclear-norm regularization, favoring\nlow-rank query and key matrices. Leveraging this, we compare the standard\nfactorized training of query and key matrices with a direct parameterization in\nwhich their product is trained element-wise, revealing the inductive bias\nintroduced by the factorized form. Remarkably, the predicted spectral\ndistribution echoes empirical trends reported in large-scale transformers,\noffering a theoretical perspective consistent with these phenomena."}
{"id": "2509.24917", "pdf": "https://arxiv.org/pdf/2509.24917", "abs": "https://arxiv.org/abs/2509.24917", "authors": ["Markus Peschl", "Pietro Mazzaglia", "Daniel Dijkman"], "title": "From Code to Action: Hierarchical Learning of Diffusion-VLM Policies", "categories": ["cs.RO", "cs.LG"], "comment": "19 pages including references, 6 figures. Accepted to CoRL LEAP 2025", "summary": "Imitation learning for robotic manipulation often suffers from limited\ngeneralization and data scarcity, especially in complex, long-horizon tasks. In\nthis work, we introduce a hierarchical framework that leverages code-generating\nvision-language models (VLMs) in combination with low-level diffusion policies\nto effectively imitate and generalize robotic behavior. Our key insight is to\ntreat open-source robotic APIs not only as execution interfaces but also as\nsources of structured supervision: the associated subtask functions - when\nexposed - can serve as modular, semantically meaningful labels. We train a VLM\nto decompose task descriptions into executable subroutines, which are then\ngrounded through a diffusion policy trained to imitate the corresponding robot\nbehavior. To handle the non-Markovian nature of both code execution and certain\nreal-world tasks, such as object swapping, our architecture incorporates a\nmemory mechanism that maintains subtask context across time. We find that this\ndesign enables interpretable policy decomposition, improves generalization when\ncompared to flat policies and enables separate evaluation of high-level\nplanning and low-level control."}
{"id": "2509.24920", "pdf": "https://arxiv.org/pdf/2509.24920", "abs": "https://arxiv.org/abs/2509.24920", "authors": ["Thibaut Germain", "Rémi Flamary", "Vladimir R. Kostic", "Karim Lounici"], "title": "A Spectral-Grassmann Wasserstein metric for operator representations of dynamical systems", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "The geometry of dynamical systems estimated from trajectory data is a major\nchallenge for machine learning applications. Koopman and transfer operators\nprovide a linear representation of nonlinear dynamics through their spectral\ndecomposition, offering a natural framework for comparison. We propose a novel\napproach representing each system as a distribution of its joint operator\neigenvalues and spectral projectors and defining a metric between systems\nleveraging optimal transport. The proposed metric is invariant to the sampling\nfrequency of trajectories. It is also computationally efficient, supported by\nfinite-sample convergence guarantees, and enables the computation of Fr\\'echet\nmeans, providing interpolation between dynamical systems. Experiments on\nsimulated and real-world datasets show that our approach consistently\noutperforms standard operator-based distances in machine learning applications,\nincluding dimensionality reduction and classification, and provides meaningful\ninterpolation between dynamical systems."}
{"id": "2509.24932", "pdf": "https://arxiv.org/pdf/2509.24932", "abs": "https://arxiv.org/abs/2509.24932", "authors": ["Fardis Nadimi", "Payam Abdisarabshali", "Jacob Chakareski", "Nicholas Mastronarde", "Seyyedali Hosseinalipour"], "title": "Graph Theory Meets Federated Learning over Satellite Constellations: Spanning Aggregations, Network Formation, and Performance Optimization", "categories": ["cs.DC", "cs.LG", "cs.NI"], "comment": "8 Figures, 6 Appendix", "summary": "We introduce Fed-Span, a novel federated/distributed learning framework\ndesigned for low Earth orbit satellite constellations. By leveraging\ngraph-theoretic principles, Fed-Span addresses critical challenges inherent to\ndistributed learning in dynamic satellite networks, including intermittent\nsatellite connectivity, heterogeneous computational capabilities of satellites,\nand time-varying satellites' datasets. At its core, Fed-Span builds upon\nminimum spanning tree (MST) and minimum spanning forest (MSF) topologies,\nenabling spanning model aggregation and dispatching processes for distributed\nlearning. To formalize Fed-Span, we offer a fresh perspective on MST/MSF\ntopologies by formulating them through a set of continuous constraint\nrepresentations (CCRs), thereby devising graph-theoretical abstractions into an\noptimizable framework for satellite networks. Using these CCRs, we obtain the\nenergy consumption and latency of operations in Fed-Span. Moreover, we derive\nnovel convergence bounds for non-convex machine learning loss functions,\naccommodating the key system characteristics and degrees of freedom of\nFed-Span. Finally, we propose a comprehensive optimization problem that jointly\nminimizes model prediction loss, energy consumption, and latency of Fed-Span.\nWe unveil that this problem is NP-hard and develop a systematic approach to\ntransform it into a geometric programming formulation, solved via successive\nconvex optimization with performance guarantees. Through evaluations on\nreal-world datasets, we demonstrate that Fed-Span outperforms existing methods,\nwith faster model convergence, greater energy efficiency, and reduced latency.\nThese results highlight Fed-Span as a novel solution for efficient distributed\nlearning in satellite networks."}
{"id": "2509.24935", "pdf": "https://arxiv.org/pdf/2509.24935", "abs": "https://arxiv.org/abs/2509.24935", "authors": ["Sangeek Hyun", "MinKyu Lee", "Jae-Pil Heo"], "title": "Scalable GANs with Transformers", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Scalability has driven recent advances in generative modeling, yet its\nprinciples remain underexplored for adversarial learning. We investigate the\nscalability of Generative Adversarial Networks (GANs) through two design\nchoices that have proven to be effective in other types of generative models:\ntraining in a compact Variational Autoencoder latent space and adopting purely\ntransformer-based generators and discriminators. Training in latent space\nenables efficient computation while preserving perceptual fidelity, and this\nefficiency pairs naturally with plain transformers, whose performance scales\nwith computational budget. Building on these choices, we analyze failure modes\nthat emerge when naively scaling GANs. Specifically, we find issues as\nunderutilization of early layers in the generator and optimization instability\nas the network scales. Accordingly, we provide simple and scale-friendly\nsolutions as lightweight intermediate supervision and width-aware learning-rate\nadjustment. Our experiments show that GAT, a purely transformer-based and\nlatent-space GANs, can be easily trained reliably across a wide range of\ncapacities (S through XL). Moreover, GAT-XL/2 achieves state-of-the-art\nsingle-step, class-conditional generation performance (FID of 2.96) on\nImageNet-256 in just 40 epochs, 6x fewer epochs than strong baselines."}
{"id": "2509.24956", "pdf": "https://arxiv.org/pdf/2509.24956", "abs": "https://arxiv.org/abs/2509.24956", "authors": ["Jan Ole von Hartz", "Lukas Schweizer", "Joschka Boedecker", "Abhinav Valada"], "title": "MSG: Multi-Stream Generative Policies for Sample-Efficient Robotic Manipulation", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "Generative robot policies such as Flow Matching offer flexible, multi-modal\npolicy learning but are sample-inefficient. Although object-centric policies\nimprove sample efficiency, it does not resolve this limitation. In this work,\nwe propose Multi-Stream Generative Policy (MSG), an inference-time composition\nframework that trains multiple object-centric policies and combines them at\ninference to improve generalization and sample efficiency. MSG is\nmodel-agnostic and inference-only, hence widely applicable to various\ngenerative policies and training paradigms. We perform extensive experiments\nboth in simulation and on a real robot, demonstrating that our approach learns\nhigh-quality generative policies from as few as five demonstrations, resulting\nin a 95% reduction in demonstrations, and improves policy performance by 89\npercent compared to single-stream approaches. Furthermore, we present\ncomprehensive ablation studies on various composition strategies and provide\npractical recommendations for deployment. Finally, MSG enables zero-shot object\ninstance transfer. We make our code publicly available at\nhttps://msg.cs.uni-freiburg.de."}
{"id": "2509.24992", "pdf": "https://arxiv.org/pdf/2509.24992", "abs": "https://arxiv.org/abs/2509.24992", "authors": ["Till Aust", "Christoph Karl Heck", "Eduard Buss", "Heiko Hamann"], "title": "Embedded Deep Learning for Bio-hybrid Plant Sensors to Detect Increased Heat and Ozone Levels", "categories": ["cs.ET", "cs.LG"], "comment": "Submitted to IEEE Sensors 2025", "summary": "We present a bio-hybrid environmental sensor system that integrates natural\nplants and embedded deep learning for real-time, on-device detection of\ntemperature and ozone level changes. Our system, based on the low-power\nPhytoNode platform, records electric differential potential signals from Hedera\nhelix and processes them onboard using an embedded deep learning model. We\ndemonstrate that our sensing device detects changes in temperature and ozone\nwith good sensitivity of up to 0.98. Daily and inter-plant variability, as well\nas limited precision, could be mitigated by incorporating additional training\ndata, which is readily integrable in our data-driven framework. Our approach\nalso has potential to scale to new environmental factors and plant species. By\nintegrating embedded deep learning onboard our biological sensing device, we\noffer a new, low-power solution for continuous environmental monitoring and\npotentially other fields of application."}
{"id": "2509.25001", "pdf": "https://arxiv.org/pdf/2509.25001", "abs": "https://arxiv.org/abs/2509.25001", "authors": ["Tooba Imtiaz", "Lucy Chai", "Kathryn Heal", "Xuan Luo", "Jungyeon Park", "Jennifer Dy", "John Flynn"], "title": "LVT: Large-Scale Scene Reconstruction via Local View Transformers", "categories": ["cs.CV", "cs.LG"], "comment": "SIGGRAPH Asia 2025 camera-ready version; project page\n  https://toobaimt.github.io/lvt/", "summary": "Large transformer models are proving to be a powerful tool for 3D vision and\nnovel view synthesis. However, the standard Transformer's well-known quadratic\ncomplexity makes it difficult to scale these methods to large scenes. To\naddress this challenge, we propose the Local View Transformer (LVT), a\nlarge-scale scene reconstruction and novel view synthesis architecture that\ncircumvents the need for the quadratic attention operation. Motivated by the\ninsight that spatially nearby views provide more useful signal about the local\nscene composition than distant views, our model processes all information in a\nlocal neighborhood around each view. To attend to tokens in nearby views, we\nleverage a novel positional encoding that conditions on the relative geometric\ntransformation between the query and nearby views. We decode the output of our\nmodel into a 3D Gaussian Splat scene representation that includes both color\nand opacity view-dependence. Taken together, the Local View Transformer enables\nreconstruction of arbitrarily large, high-resolution scenes in a single forward\npass. See our project page for results and interactive demos\nhttps://toobaimt.github.io/lvt/."}
{"id": "2509.25016", "pdf": "https://arxiv.org/pdf/2509.25016", "abs": "https://arxiv.org/abs/2509.25016", "authors": ["Max Curie", "Paulo da Costa"], "title": "CLASP: Adaptive Spectral Clustering for Unsupervised Per-Image Segmentation", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "We introduce CLASP (Clustering via Adaptive Spectral Processing), a\nlightweight framework for unsupervised image segmentation that operates without\nany labeled data or finetuning. CLASP first extracts per patch features using a\nself supervised ViT encoder (DINO); then, it builds an affinity matrix and\napplies spectral clustering. To avoid manual tuning, we select the segment\ncount automatically with a eigengap silhouette search, and we sharpen the\nboundaries with a fully connected DenseCRF. Despite its simplicity and training\nfree nature, CLASP attains competitive mIoU and pixel accuracy on COCO Stuff\nand ADE20K, matching recent unsupervised baselines. The zero training design\nmakes CLASP a strong, easily reproducible baseline for large unannotated\ncorpora especially common in digital advertising and marketing workflows such\nas brand safety screening, creative asset curation, and social media content\nmoderation"}
{"id": "2509.25033", "pdf": "https://arxiv.org/pdf/2509.25033", "abs": "https://arxiv.org/abs/2509.25033", "authors": ["Wenhao Li", "Qiangchang Wang", "Xianjing Meng", "Zhibin Wu", "Yilong Yin"], "title": "VT-FSL: Bridging Vision and Text with LLMs for Few-Shot Learning", "categories": ["cs.CV", "cs.LG", "I.4.9"], "comment": "Accepted by NeurIPS 2025", "summary": "Few-shot learning (FSL) aims to recognize novel concepts from only a few\nlabeled support samples. Recent studies enhance support features by\nincorporating additional semantic information or designing complex semantic\nfusion modules. However, they still suffer from hallucinating semantics that\ncontradict the visual evidence due to the lack of grounding in actual\ninstances, resulting in noisy guidance and costly corrections. To address these\nissues, we propose a novel framework, bridging Vision and Text with LLMs for\nFew-Shot Learning (VT-FSL), which constructs precise cross-modal prompts\nconditioned on Large Language Models (LLMs) and support images, seamlessly\nintegrating them through a geometry-aware alignment. It mainly consists of\nCross-modal Iterative Prompting (CIP) and Cross-modal Geometric Alignment\n(CGA). Specifically, the CIP conditions an LLM on both class names and support\nimages to generate precise class descriptions iteratively in a single\nstructured reasoning pass. These descriptions not only enrich the semantic\nunderstanding of novel classes but also enable the zero-shot synthesis of\nsemantically consistent images. The descriptions and synthetic images act\nrespectively as complementary textual and visual prompts, providing high-level\nclass semantics and low-level intra-class diversity to compensate for limited\nsupport data. Furthermore, the CGA jointly aligns the fused textual, support,\nand synthetic visual representations by minimizing the kernelized volume of the\n3-dimensional parallelotope they span. It captures global and nonlinear\nrelationships among all representations, enabling structured and consistent\nmultimodal integration. The proposed VT-FSL method establishes new\nstate-of-the-art performance across ten diverse benchmarks, including standard,\ncross-domain, and fine-grained few-shot learning scenarios. Code is available\nat https://github.com/peacelwh/VT-FSL."}
{"id": "2509.25035", "pdf": "https://arxiv.org/pdf/2509.25035", "abs": "https://arxiv.org/abs/2509.25035", "authors": ["Haoyang Zheng", "Xinyang Liu", "Cindy Xiangrui Kong", "Nan Jiang", "Zheyuan Hu", "Weijian Luo", "Wei Deng", "Guang Lin"], "title": "Ultra-Fast Language Generation via Discrete Diffusion Divergence Instruct", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "56 pages, 7 figures, 7 tables", "summary": "Fast generation of language texts is the holy grail that people pursue in the\nAI era. In this work, we introduced Discrete Diffusion Divergence Instruct\n(DiDi-Instruct), a training-based method that leads to fast language generation\nmodels by initializing from a pre-trained (masked) discrete diffusion language\nmodel (dLLM). The resulting DiDi-Instruct model outperforms the dLLM\ncounterparts and the GPT-2 baseline with 64x acceleration. In the theoretical\npart of the paper, we build the foundation of DiDi-Instruct in a framework of\nintegral KL-divergence minimization, with practical training algorithms. We\nalso introduce techniques like grouped reward normalization, intermediate-state\nmatching, and the reward-guided ancestral sampler (RGAS) that significantly\nimprove the training stability, the model coverage, and the inference\nperformances. On OpenWebText, DiDi-Instruct outperforms all accelerated\nlanguage generation models as well as the GPT-2 baseline and the standard\ndLLMs, achieving sample perplexities ranging from 62.2 (8 NFEs) to 18.4 (128\nNFEs). These performance gains are accomplished with a negligible entropy loss\nof about 1% and 20x less additional training wall-clock time. We further\nvalidate the robustness and effectiveness of DiDi-Instruct through extensive\nablation studies, model scaling, and the generation of discrete protein\nsequences. In conclusion, DiDi-Instruct is an efficient yet effective\ndistillation method, enabling language generation in the blink of an eye. We\nwill release both code and models at github.com/haoyangzheng-ai/didi-instruct."}
{"id": "2509.25045", "pdf": "https://arxiv.org/pdf/2509.25045", "abs": "https://arxiv.org/abs/2509.25045", "authors": ["Marco Bronzini", "Carlo Nicolini", "Bruno Lepri", "Jacopo Staiano", "Andrea Passerini"], "title": "Hyperdimensional Probe: Decoding LLM Representations via Vector Symbolic Architectures", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Despite their capabilities, Large Language Models (LLMs) remain opaque with\nlimited understanding of their internal representations. Current\ninterpretability methods, such as direct logit attribution (DLA) and sparse\nautoencoders (SAEs), provide restricted insight due to limitations such as the\nmodel's output vocabulary or unclear feature names. This work introduces\nHyperdimensional Probe, a novel paradigm for decoding information from the LLM\nvector space. It combines ideas from symbolic representations and neural\nprobing to project the model's residual stream into interpretable concepts via\nVector Symbolic Architectures (VSAs). This probe combines the strengths of SAEs\nand conventional probes while overcoming their key limitations. We validate our\ndecoding paradigm with controlled input-completion tasks, probing the model's\nfinal state before next-token prediction on inputs spanning syntactic pattern\nrecognition, key-value associations, and abstract inference. We further assess\nit in a question-answering setting, examining the state of the model both\nbefore and after text generation. Our experiments show that our probe reliably\nextracts meaningful concepts across varied LLMs, embedding sizes, and input\ndomains, also helping identify LLM failures. Our work advances information\ndecoding in LLM vector space, enabling extracting more informative,\ninterpretable, and structured features from neural representations."}
{"id": "2509.25051", "pdf": "https://arxiv.org/pdf/2509.25051", "abs": "https://arxiv.org/abs/2509.25051", "authors": ["Anthony Bardou", "Antoine Gonon", "Aryan Ahadinia", "Patrick Thiran"], "title": "Symmetry-Aware Bayesian Optimization via Max Kernels", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Bayesian Optimization (BO) is a powerful framework for optimizing noisy,\nexpensive-to-evaluate black-box functions. When the objective exhibits\ninvariances under a group action, exploiting these symmetries can substantially\nimprove BO efficiency. While using maximum similarity across group orbits has\nlong been considered in other domains, the fact that the max kernel is not\npositive semidefinite (PSD) has prevented its use in BO. In this work, we\nrevisit this idea by considering a PSD projection of the max kernel. Compared\nto existing invariant (and non-invariant) kernels, we show it achieves\nsignificantly lower regret on both synthetic and real-world BO benchmarks,\nwithout increasing computational complexity."}
{"id": "2509.25052", "pdf": "https://arxiv.org/pdf/2509.25052", "abs": "https://arxiv.org/abs/2509.25052", "authors": ["Sai Wang", "Yu Wu", "Zhongwen Xu"], "title": "Cogito, Ergo Ludo: An Agent that Learns to Play by Reasoning and Planning", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "The pursuit of artificial agents that can learn to master complex\nenvironments has led to remarkable successes, yet prevailing deep reinforcement\nlearning methods often rely on immense experience, encoding their knowledge\nopaquely within neural network weights. We propose a different paradigm, one in\nwhich an agent learns to play by reasoning and planning. We introduce Cogito,\nergo ludo (CEL), a novel agent architecture that leverages a Large Language\nModel (LLM) to build an explicit, language-based understanding of its\nenvironment's mechanics and its own strategy. Starting from a tabula rasa state\nwith no prior knowledge (except action set), CEL operates on a cycle of\ninteraction and reflection. After each episode, the agent analyzes its complete\ntrajectory to perform two concurrent learning processes: Rule Induction, where\nit refines its explicit model of the environment's dynamics, and Strategy and\nPlaybook Summarization, where it distills experiences into an actionable\nstrategic playbook. We evaluate CEL on diverse grid-world tasks (i.e.,\nMinesweeper, Frozen Lake, and Sokoban), and show that the CEL agent\nsuccessfully learns to master these games by autonomously discovering their\nrules and developing effective policies from sparse rewards. Ablation studies\nconfirm that the iterative process is critical for sustained learning. Our work\ndemonstrates a path toward more general and interpretable agents that not only\nact effectively but also build a transparent and improving model of their world\nthrough explicit reasoning on raw experience."}
{"id": "2509.25072", "pdf": "https://arxiv.org/pdf/2509.25072", "abs": "https://arxiv.org/abs/2509.25072", "authors": ["Yaman Jandali", "Ruisi Zhang", "Nojan Sheybani", "Farinaz Koushanfar"], "title": "Optimizing Privacy-Preserving Primitives to Support LLM-Scale Applications", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "Privacy-preserving technologies have introduced a paradigm shift that allows\nfor realizable secure computing in real-world systems. The significant barrier\nto the practical adoption of these primitives is the computational and\ncommunication overhead that is incurred when applied at scale. In this paper,\nwe present an overview of our efforts to bridge the gap between this overhead\nand practicality for privacy-preserving learning systems using multi-party\ncomputation (MPC), zero-knowledge proofs (ZKPs), and fully homomorphic\nencryption (FHE). Through meticulous hardware/software/algorithm co-design, we\nshow progress towards enabling LLM-scale applications in privacy-preserving\nsettings. We demonstrate the efficacy of our solutions in several contexts,\nincluding DNN IP ownership, ethical LLM usage enforcement, and transformer\ninference."}
{"id": "2509.25084", "pdf": "https://arxiv.org/pdf/2509.25084", "abs": "https://arxiv.org/abs/2509.25084", "authors": ["Shuofei Qiao", "Yanqiu Zhao", "Zhisong Qiu", "Xiaobin Wang", "Jintian Zhang", "Zhao Bin", "Ningyu Zhang", "Yong Jiang", "Pengjun Xie", "Fei Huang", "Huajun Chen"], "title": "Scaling Generalist Data-Analytic Agents", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "comment": "Work in progress", "summary": "Data-analytic agents are emerging as a key catalyst for automated scientific\ndiscovery and for the vision of Innovating AI. Current approaches, however,\nrely heavily on prompt engineering over proprietary models, while open-source\nmodels struggle to face diverse-format, large-scale data files and\nlong-horizon, multi-step reasoning that real-world analytics demands. This\npaper introduces DataMind, a scalable data synthesis and agent training recipe\ndesigned to build generalist data-analytic agents. DataMind tackles three key\nchallenges in building open-source data-analytic agents, including insufficient\ndata resources, improper training strategy, and unstable code-based multi-turn\nrollout. Concretely, DataMind applies 1) a fine-grained task taxonomy and a\nrecursive easy-to-hard task composition mechanism to increase the diversity and\ndifficulty of synthesized queries; 2) a knowledge-augmented trajectory sampling\nstrategy followed by model-based and rule-based filtering; 3) a dynamically\nadjustable training objective combining both SFT and RL losses; 4) a\nmemory-frugal and stable code-based multi-turn rollout framework. Built on\nDataMind, we curate DataMind-12K, a high-quality trajectory set spanning\ndiverse domains, task categories, and data file formats for data-analytic\ntasks. Trained on DataMind-12K, our DataMind-14B achieves state-of-the-art with\nan average score of 71.16% on multiple data analysis benchmarks, outperforming\nthe strongest proprietary baselines DeepSeek-V3.1 and GPT-5. Our DataMind-7B\nalso performs best among all open-source models with a score of 68.10%. We also\nincorporate some empirical insights gained from our exploratory trials into the\nanalysis experiments, aiming to provide actionable insights about agentic\ntraining for the community. We will release DataMind-12K and DataMind-7B,14B\nfor the community's future research."}
{"id": "2509.25095", "pdf": "https://arxiv.org/pdf/2509.25095", "abs": "https://arxiv.org/abs/2509.25095", "authors": ["M A Al-Masud", "Juan Miguel Lopez Alcaraz", "Nils Strodthoff"], "title": "Benchmarking ECG Foundational Models: A Reality Check Across Clinical Tasks", "categories": ["eess.SP", "cs.LG"], "comment": "26 pages, 3 figures source code under\n  https://github.com/AI4HealthUOL/ecg-fm-benchmarking", "summary": "The 12-lead electrocardiogram (ECG) is a long-standing diagnostic tool. Yet\nmachine learning for ECG interpretation remains fragmented, often limited to\nnarrow tasks or datasets. Foundation models promise broader adaptability, but\ntheir generalization across diverse ECG tasks is not well understood. We\nbenchmarked eight ECG foundation models on 26 clinically relevant tasks using\n12 public datasets comprising 1,650 regression and classification targets.\nModels were evaluated under fine-tuning and frozen settings, with scaling\nanalyses across dataset sizes. Results show heterogeneous performance across\ndomains: in the most widely studied domain, adult ECG interpretation, three\nfoundation models consistently outperformed strong supervised baselines. In\ncontrast, ECG-CPC, a compact structured state-space model pretrained on HEEDB,\ndominated other categories where most foundation models failed to surpass\nsupervised learning. Foundation models also displayed distinct scaling\nbehaviors with dataset size, which are critical for small-scale clinical\napplications. Overall, while foundation models show promise for adult ECG\nanalysis, substantial gaps remain in cardiac structure, outcome prediction, and\npatient characterization. Notably, ECG-CPC's strong performance despite being\norders of magnitude smaller and consuming minimal computational resources\nhighlights untapped opportunities for advancing ECG foundation models."}
{"id": "2509.25097", "pdf": "https://arxiv.org/pdf/2509.25097", "abs": "https://arxiv.org/abs/2509.25097", "authors": ["Jesús Roche", "Eduardo Sebastián", "Eduardo Montijano"], "title": "Curriculum Imitation Learning of Distributed Multi-Robot Policies", "categories": ["cs.RO", "cs.LG", "cs.MA"], "comment": "Accepted and presented at the Eight Iberian Robotics Conference, 2025", "summary": "Learning control policies for multi-robot systems (MRS) remains a major\nchallenge due to long-term coordination and the difficulty of obtaining\nrealistic training data. In this work, we address both limitations within an\nimitation learning framework. First, we shift the typical role of Curriculum\nLearning in MRS, from scalability with the number of robots, to focus on\nimproving long-term coordination. We propose a curriculum strategy that\ngradually increases the length of expert trajectories during training,\nstabilizing learning and enhancing the accuracy of long-term behaviors. Second,\nwe introduce a method to approximate the egocentric perception of each robot\nusing only third-person global state demonstrations. Our approach transforms\nidealized trajectories into locally available observations by filtering\nneighbors, converting reference frames, and simulating onboard sensor\nvariability. Both contributions are integrated into a physics-informed\ntechnique to produce scalable, distributed policies from observations. We\nconduct experiments across two tasks with varying team sizes and noise levels.\nResults show that our curriculum improves long-term accuracy, while our\nperceptual estimation method yields policies that are robust to realistic\nuncertainty. Together, these strategies enable the learning of robust,\ndistributed controllers from global demonstrations, even in the absence of\nexpert actions or onboard measurements."}
{"id": "2509.25126", "pdf": "https://arxiv.org/pdf/2509.25126", "abs": "https://arxiv.org/abs/2509.25126", "authors": ["Arnab Auddy", "Ming Yuan"], "title": "On Spectral Learning for Odeco Tensors: Perturbation, Initialization, and Algorithms", "categories": ["stat.ML", "cs.LG", "cs.NA", "math.NA", "math.ST", "stat.TH"], "comment": null, "summary": "We study spectral learning for orthogonally decomposable (odeco) tensors,\nemphasizing the interplay between statistical limits, optimization geometry,\nand initialization. Unlike matrices, recovery for odeco tensors does not hinge\non eigengaps, yielding improved robustness under noise. While iterative methods\nsuch as tensor power iterations can be statistically efficient, initialization\nemerges as the main computational bottleneck. We investigate perturbation\nbounds, non-convex optimization analysis, and initialization strategies,\nclarifying when efficient algorithms attain statistical limits and when\nfundamental barriers remain."}
{"id": "2509.25127", "pdf": "https://arxiv.org/pdf/2509.25127", "abs": "https://arxiv.org/abs/2509.25127", "authors": ["Mingyuan Zhou", "Yi Gu", "Huangjie Zheng", "Liangchen Song", "Guande He", "Yizhe Zhang", "Wenze Hu", "Yinfei Yang"], "title": "Score Distillation of Flow Matching Models", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Diffusion models achieve high-quality image generation but are limited by\nslow iterative sampling. Distillation methods alleviate this by enabling one-\nor few-step generation. Flow matching, originally introduced as a distinct\nframework, has since been shown to be theoretically equivalent to diffusion\nunder Gaussian assumptions, raising the question of whether distillation\ntechniques such as score distillation transfer directly. We provide a simple\nderivation -- based on Bayes' rule and conditional expectations -- that unifies\nGaussian diffusion and flow matching without relying on ODE/SDE formulations.\nBuilding on this view, we extend Score identity Distillation (SiD) to\npretrained text-to-image flow-matching models, including SANA, SD3-Medium,\nSD3.5-Medium/Large, and FLUX.1-dev, all with DiT backbones. Experiments show\nthat, with only modest flow-matching- and DiT-specific adjustments, SiD works\nout of the box across these models, in both data-free and data-aided settings,\nwithout requiring teacher finetuning or architectural changes. This provides\nthe first systematic evidence that score distillation applies broadly to\ntext-to-image flow matching models, resolving prior concerns about stability\nand soundness and unifying acceleration techniques across diffusion- and\nflow-based generators. We will make the PyTorch implementation publicly\navailable."}
{"id": "2509.25137", "pdf": "https://arxiv.org/pdf/2509.25137", "abs": "https://arxiv.org/abs/2509.25137", "authors": ["Chuanyang Jin", "Jing Xu", "Bo Liu", "Leitian Tao", "Olga Golovneva", "Tianmin Shu", "Wenting Zhao", "Xian Li", "Jason Weston"], "title": "The Era of Real-World Human Interaction: RL from User Conversations", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "We posit that to achieve continual model improvement and multifaceted\nalignment, future models must learn from natural human interaction. Current\nconversational models are aligned using pre-annotated, expert-generated human\nfeedback. In this work, we introduce Reinforcement Learning from Human\nInteraction (RLHI), a paradigm that learns directly from in-the-wild user\nconversations. We develop two complementary methods: (1) RLHI with User-Guided\nRewrites, which revises unsatisfactory model outputs based on users'\nnatural-language follow-up responses, (2) RLHI with User-Based Rewards, which\nlearns via a reward model conditioned on knowledge of the user's long-term\ninteraction history (termed persona). Together, these methods link long-term\nuser personas to turn-level preferences via persona-conditioned preference\noptimization. Trained on conversations derived from WildChat, both RLHI\nvariants outperform strong baselines in personalization and\ninstruction-following, and similar feedback enhances performance on reasoning\nbenchmarks. These results suggest organic human interaction offers scalable,\neffective supervision for personalized alignment."}
{"id": "2509.25144", "pdf": "https://arxiv.org/pdf/2509.25144", "abs": "https://arxiv.org/abs/2509.25144", "authors": ["Yen-Ju Lu", "Thomas Thebaud", "Laureano Moro-Velazquez", "Najim Dehak", "Jesus Villalba"], "title": "Paired by the Teacher: Turning Unpaired Data into High-Fidelity Pairs for Low-Resource Text Generation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted at EMNLP 2025 (Main Conference)", "summary": "We present Paired by the Teacher (PbT), a two-stage teacher-student pipeline\nthat synthesizes accurate input-output pairs without human labels or parallel\ndata. In many low-resource natural language generation (NLG) scenarios,\npractitioners may have only raw outputs, like highlights, recaps, or questions,\nor only raw inputs, such as articles, dialogues, or paragraphs, but seldom\nboth. This mismatch forces small models to learn from very few examples or rely\non costly, broad-scope synthetic examples produced by large LLMs. PbT addresses\nthis by asking a teacher LLM to compress each unpaired example into a concise\nintermediate representation (IR), and training a student to reconstruct inputs\nfrom IRs. This enables outputs to be paired with student-generated inputs,\nyielding high-quality synthetic data. We evaluate PbT on five\nbenchmarks-document summarization (XSum, CNNDM), dialogue summarization\n(SAMSum, DialogSum), and question generation (SQuAD)-as well as an unpaired\nsetting on SwitchBoard (paired with DialogSum summaries). An 8B student trained\nonly on PbT data outperforms models trained on 70 B teacher-generated corpora\nand other unsupervised baselines, coming within 1.2 ROUGE-L of human-annotated\npairs and closing 82% of the oracle gap at one-third the annotation cost of\ndirect synthesis. Human evaluation on SwitchBoard further confirms that only\nPbT produces concise, faithful summaries aligned with the target style,\nhighlighting its advantage of generating in-domain sources that avoid the\nmismatch, limiting direct synthesis."}
{"id": "2509.25146", "pdf": "https://arxiv.org/pdf/2509.25146", "abs": "https://arxiv.org/abs/2509.25146", "authors": ["Richeek Das", "Kostas Daniilidis", "Pratik Chaudhari"], "title": "Fast Feature Field ($\\text{F}^3$): A Predictive Representation of Events", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "comment": "39 pages, 9 figures", "summary": "This paper develops a mathematical argument and algorithms for building\nrepresentations of data from event-based cameras, that we call Fast Feature\nField ($\\text{F}^3$). We learn this representation by predicting future events\nfrom past events and show that it preserves scene structure and motion\ninformation. $\\text{F}^3$ exploits the sparsity of event data and is robust to\nnoise and variations in event rates. It can be computed efficiently using ideas\nfrom multi-resolution hash encoding and deep sets - achieving 120 Hz at HD and\n440 Hz at VGA resolutions. $\\text{F}^3$ represents events within a contiguous\nspatiotemporal volume as a multi-channel image, enabling a range of downstream\ntasks. We obtain state-of-the-art performance on optical flow estimation,\nsemantic segmentation, and monocular metric depth estimation, on data from\nthree robotic platforms (a car, a quadruped robot and a flying platform),\nacross different lighting conditions (daytime, nighttime), environments\n(indoors, outdoors, urban, as well as off-road) and dynamic vision sensors\n(resolutions and event rates). Our implementations can predict these tasks at\n25-75 Hz at HD resolution."}
{"id": "2509.25149", "pdf": "https://arxiv.org/pdf/2509.25149", "abs": "https://arxiv.org/abs/2509.25149", "authors": ["NVIDIA", "Felix Abecassis", "Anjulie Agrusa", "Dong Ahn", "Jonah Alben", "Stefania Alborghetti", "Michael Andersch", "Sivakumar Arayandi", "Alexis Bjorlin", "Aaron Blakeman", "Evan Briones", "Ian Buck", "Bryan Catanzaro", "Jinhang Choi", "Mike Chrzanowski", "Eric Chung", "Victor Cui", "Steve Dai", "Bita Darvish Rouhani", "Carlo del Mundo", "Deena Donia", "Burc Eryilmaz", "Henry Estela", "Abhinav Goel", "Oleg Goncharov", "Yugi Guvvala", "Robert Hesse", "Russell Hewett", "Herbert Hum", "Ujval Kapasi", "Brucek Khailany", "Mikail Khona", "Nick Knight", "Alex Kondratenko", "Ronny Krashinsky", "Ben Lanir", "Simon Layton", "Michael Lightstone", "Daniel Lo", "Paulius Micikevicius", "Asit Mishra", "Tim Moon", "Deepak Narayanan", "Chao Ni", "Abhijit Paithankar", "Satish Pasumarthi", "Ankit Patel", "Mostofa Patwary", "Ashwin Poojary", "Gargi Prasad", "Sweta Priyadarshi", "Yigong Qin", "Xiaowei Ren", "Oleg Rybakov", "Charbel Sakr", "Sanjeev Satheesh", "Stas Sergienko", "Pasha Shamis", "Kirthi Shankar", "Nishant Sharma", "Mohammad Shoeybi", "Michael Siu", "Misha Smelyanskiy", "Darko Stosic", "Dusan Stosic", "Bor-Yiing Su", "Frank Sun", "Nima Tajbakhsh", "Shelby Thomas", "Przemek Tredak", "Evgeny Tsykunov", "Gandhi Vaithilingam", "Aditya Vavre", "Rangharajan Venkatesan", "Roger Waleffe", "Qiyu Wan", "Hexin Wang", "Mengdi Wang", "Lizzie Wei", "Hao Wu", "Evan Wu", "Keith Wyss", "Ning Xu", "Jinze Xue", "Charlene Yang", "Yujia Zhai", "Ruoxi Zhang", "Jingyang Zhu", "Zhongbo Zhu"], "title": "Pretraining Large Language Models with NVFP4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) today are powerful problem solvers across many\ndomains, and they continue to get stronger as they scale in model size,\ntraining set size, and training set quality, as shown by extensive research and\nexperimentation across the industry. Training a frontier model today requires\non the order of tens to hundreds of yottaflops, which is a massive investment\nof time, compute, and energy. Improving pretraining efficiency is therefore\nessential to enable the next generation of even more capable LLMs. While 8-bit\nfloating point (FP8) training is now widely adopted, transitioning to even\nnarrower precision, such as 4-bit floating point (FP4), could unlock additional\nimprovements in computational speed and resource utilization. However,\nquantization at this level poses challenges to training stability, convergence,\nand implementation, notably for large-scale models trained on long token\nhorizons.\n  In this study, we introduce a novel approach for stable and accurate training\nof large language models (LLMs) using the NVFP4 format. Our method integrates\nRandom Hadamard transforms (RHT) to bound block-level outliers, employs a\ntwo-dimensional quantization scheme for consistent representations across both\nthe forward and backward passes, utilizes stochastic rounding for unbiased\ngradient estimation, and incorporates selective high-precision layers. We\nvalidate our approach by training a 12-billion-parameter model on 10 trillion\ntokens -- the longest publicly documented training run in 4-bit precision to\ndate. Our results show that the model trained with our NVFP4-based pretraining\ntechnique achieves training loss and downstream task accuracies comparable to\nan FP8 baseline. These findings highlight that NVFP4, when combined with our\ntraining approach, represents a major step forward in narrow-precision LLM\ntraining algorithms."}
{"id": "2509.25155", "pdf": "https://arxiv.org/pdf/2509.25155", "abs": "https://arxiv.org/abs/2509.25155", "authors": ["Neelesh Gupta", "Rakshith Jayanth", "Dhruv Parikh", "Viktor Prasanna"], "title": "Context-Driven Performance Modeling for Causal Inference Operators on Neural Processing Units", "categories": ["cs.DC", "cs.LG"], "comment": "IEEE HiPC 2025", "summary": "The proliferation of large language models (LLMs) has driven demand for long\ncontext inference on resource constrained edge devices. However, deploying\nthese models on Neural Processing Units (NPUs) presents significant challenges\ndue to the architectural mismatch: quadratic complexity of standard attention\nmechanisms conflicts with memory and compute patterns of edge accelerators.\nThis paper presents a comprehensive performance analysis of various causal\ninference operators on a modern NPU. We benchmark standard quadratic attention\nagainst several sub-quadratic alternatives, including structured state-space\nand linear attention models. Our analysis reveals that while sub-quadratic\nmethods offer superior scalability, they introduce distinct computational\nbottlenecks on the NPU's specialized execution units. We identify that\nquadratic attention becomes severely memory-bound, suffering from cache\ninefficiency and pipeline stalls exceeding 95% at long contexts. In contrast,\nsub-quadratic models can become compute-bound on programmable vector cores.\nThese findings provide critical insights for the co-design of hardware-aware\nmodels and optimization strategies to enable on-device AI inference with\nlong-contexts."}
{"id": "2509.25172", "pdf": "https://arxiv.org/pdf/2509.25172", "abs": "https://arxiv.org/abs/2509.25172", "authors": ["Yuxin Jiang", "Yuchao Gu", "Yiren Song", "Ivor Tsang", "Mike Zheng Shou"], "title": "Personalized Vision via Visual In-Context Learning", "categories": ["cs.CV", "cs.LG"], "comment": "Project page: https://yuxinn-j.github.io/projects/PICO", "summary": "Modern vision models, trained on large-scale annotated datasets, excel at\npredefined tasks but struggle with personalized vision -- tasks defined at test\ntime by users with customized objects or novel objectives. Existing\npersonalization approaches rely on costly fine-tuning or synthetic data\npipelines, which are inflexible and restricted to fixed task formats. Visual\nin-context learning (ICL) offers a promising alternative, yet prior methods\nconfine to narrow, in-domain tasks and fail to generalize to open-ended\npersonalization. We introduce Personalized In-Context Operator (PICO), a simple\nfour-panel framework that repurposes diffusion transformers as visual\nin-context learners. Given a single annotated exemplar, PICO infers the\nunderlying transformation and applies it to new inputs without retraining. To\nenable this, we construct VisRel, a compact yet diverse tuning dataset, showing\nthat task diversity, rather than scale, drives robust generalization. We\nfurther propose an attention-guided seed scorer that improves reliability via\nefficient inference scaling. Extensive experiments demonstrate that PICO (i)\nsurpasses fine-tuning and synthetic-data baselines, (ii) flexibly adapts to\nnovel user-defined tasks, and (iii) generalizes across both recognition and\ngeneration."}
{"id": "2509.25178", "pdf": "https://arxiv.org/pdf/2509.25178", "abs": "https://arxiv.org/abs/2509.25178", "authors": ["Aryan Yazdan Parast", "Parsa Hosseini", "Hesam Asadollahzadeh", "Arshia Soltani Moakhar", "Basim Azam", "Soheil Feizi", "Naveed Akhtar"], "title": "GHOST: Hallucination-Inducing Image Generation for Multimodal LLMs", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Object hallucination in Multimodal Large Language Models (MLLMs) is a\npersistent failure mode that causes the model to perceive objects absent in the\nimage. This weakness of MLLMs is currently studied using static benchmarks with\nfixed visual scenarios, which preempts the possibility of uncovering\nmodel-specific or unanticipated hallucination vulnerabilities. We introduce\nGHOST (Generating Hallucinations via Optimizing Stealth Tokens), a method\ndesigned to stress-test MLLMs by actively generating images that induce\nhallucination. GHOST is fully automatic and requires no human supervision or\nprior knowledge. It operates by optimizing in the image embedding space to\nmislead the model while keeping the target object absent, and then guiding a\ndiffusion model conditioned on the embedding to generate natural-looking\nimages. The resulting images remain visually natural and close to the original\ninput, yet introduce subtle misleading cues that cause the model to\nhallucinate. We evaluate our method across a range of models, including\nreasoning models like GLM-4.1V-Thinking, and achieve a hallucination success\nrate exceeding 28%, compared to around 1% in prior data-driven discovery\nmethods. We confirm that the generated images are both high-quality and\nobject-free through quantitative metrics and human evaluation. Also, GHOST\nuncovers transferable vulnerabilities: images optimized for Qwen2.5-VL induce\nhallucinations in GPT-4o at a 66.5% rate. Finally, we show that fine-tuning on\nour images mitigates hallucination, positioning GHOST as both a diagnostic and\ncorrective tool for building more reliable multimodal systems."}
