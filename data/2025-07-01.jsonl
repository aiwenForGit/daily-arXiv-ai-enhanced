{"id": "2506.22441", "pdf": "https://arxiv.org/pdf/2506.22441", "abs": "https://arxiv.org/abs/2506.22441", "authors": ["Lei Yang"], "title": "Latent Factorization of Tensors with Threshold Distance Weighted Loss for Traffic Data Estimation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Intelligent transportation systems (ITS) rely heavily on complete and\nhigh-quality spatiotemporal traffic data to achieve optimal performance.\nNevertheless, in real-word traffic data collection processes, issues such as\ncommunication failures and sensor malfunctions often lead to incomplete or\ncorrupted datasets, thereby posing significant challenges to the advancement of\nITS. Among various methods for imputing missing spatiotemporal traffic data,\nthe latent factorization of tensors (LFT) model has emerged as a widely adopted\nand effective solution. However, conventional LFT models typically employ the\nstandard L2-norm in their learning objective, which makes them vulnerable to\nthe influence of outliers. To overcome this limitation, this paper proposes a\nthreshold distance weighted (TDW) loss-incorporated Latent Factorization of\nTensors (TDWLFT) model. The proposed loss function effectively reduces the\nmodel's sensitivity to outliers by assigning differentiated weights to\nindividual samples. Extensive experiments conducted on two traffic speed\ndatasets sourced from diverse urban environments confirm that the proposed\nTDWLFT model consistently outperforms state-of-the-art approaches in terms of\nboth in both prediction accuracy and computational efficiency."}
{"id": "2506.22442", "pdf": "https://arxiv.org/pdf/2506.22442", "abs": "https://arxiv.org/abs/2506.22442", "authors": ["Piotr Makarevich"], "title": "Features-based embedding or Feature-grounding", "categories": ["cs.LG"], "comment": "13 pages, 12 figures", "summary": "In everyday reasoning, when we think about a particular object, we associate\nit with a unique set of expected properties such as weight, size, or more\nabstract attributes like density or horsepower. These expectations are shaped\nby our prior knowledge and the conceptual categories we have formed through\nexperience. This paper investigates how such knowledge-based structured\nthinking can be reproduced in deep learning models using features based\nembeddings. Specially, it introduces an specific approach to build\nfeature-grounded embedding, aiming to align shareable representations of\noperable dictionary with interpretable domain-specific conceptual features."}
{"id": "2506.22443", "pdf": "https://arxiv.org/pdf/2506.22443", "abs": "https://arxiv.org/abs/2506.22443", "authors": ["Sarah Seifi", "Tobias Sukianto", "Cecilia Carbonelli", "Lorenzo Servadei", "Robert Wille"], "title": "Learning Interpretable Rules from Neural Networks: Neurosymbolic AI for Radar Hand Gesture Recognition", "categories": ["cs.LG", "cs.HC"], "comment": "8 pages, 3 figures, accepted at the late-breaking work track at the\n  XAI-2025 third World Conference of Explainable AI", "summary": "Rule-based models offer interpretability but struggle with complex data,\nwhile deep neural networks excel in performance yet lack transparency. This\nwork investigates a neuro-symbolic rule learning neural network named RL-Net\nthat learns interpretable rule lists through neural optimization, applied for\nthe first time to radar-based hand gesture recognition (HGR). We benchmark\nRL-Net against a fully transparent rule-based system (MIRA) and an explainable\nblack-box model (XentricAI), evaluating accuracy, interpretability, and user\nadaptability via transfer learning. Our results show that RL-Net achieves a\nfavorable trade-off, maintaining strong performance (93.03% F1) while\nsignificantly reducing rule complexity. We identify optimization challenges\nspecific to rule pruning and hierarchy bias and propose stability-enhancing\nmodifications. Compared to MIRA and XentricAI, RL-Net emerges as a practical\nmiddle ground between transparency and performance. This study highlights the\nreal-world feasibility of neuro-symbolic models for interpretable HGR and\noffers insights for extending explainable AI to edge-deployable sensing\nsystems."}
{"id": "2506.22444", "pdf": "https://arxiv.org/pdf/2506.22444", "abs": "https://arxiv.org/abs/2506.22444", "authors": ["Jing Wang", "Amar Sra", "Jeremy C. Weiss"], "title": "Active Learning for Forecasting Severity among Patients with Post Acute Sequelae of SARS-CoV-2", "categories": ["cs.LG", "cs.CY"], "comment": null, "summary": "The long-term effects of Postacute Sequelae of SARS-CoV-2, known as PASC,\npose a significant challenge to healthcare systems worldwide. Accurate\nidentification of progression events, such as hospitalization and reinfection,\nis essential for effective patient management and resource allocation. However,\ntraditional models trained on structured data struggle to capture the nuanced\nprogression of PASC. In this study, we introduce the first publicly available\ncohort of 18 PASC patients, with text time series features based on Large\nLanguage Model Llama-3.1-70B-Instruct and clinical risk annotated by clinical\nexpert. We propose an Active Attention Network to predict the clinical risk and\nidentify progression events related to the risk. By integrating human expertise\nwith active learning, we aim to enhance clinical risk prediction accuracy and\nenable progression events identification with fewer number of annotation. The\nultimate goal is to improves patient care and decision-making for SARS-CoV-2\npatient."}
{"id": "2506.22445", "pdf": "https://arxiv.org/pdf/2506.22445", "abs": "https://arxiv.org/abs/2506.22445", "authors": ["Saad Alqithami"], "title": "Hierarchical Adversarially-Resilient Multi-Agent Reinforcement Learning for Cyber-Physical Systems Security", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.MA"], "comment": null, "summary": "Cyber-Physical Systems play a critical role in the infrastructure of various\nsectors, including manufacturing, energy distribution, and autonomous\ntransportation systems. However, their increasing connectivity renders them\nhighly vulnerable to sophisticated cyber threats, such as adaptive and zero-day\nattacks, against which traditional security methods like rule-based intrusion\ndetection and single-agent reinforcement learning prove insufficient. To\novercome these challenges, this paper introduces a novel Hierarchical\nAdversarially-Resilient Multi-Agent Reinforcement Learning (HAMARL) framework.\nHAMARL employs a hierarchical structure consisting of local agents dedicated to\nsubsystem security and a global coordinator that oversees and optimizes\ncomprehensive, system-wide defense strategies. Furthermore, the framework\nincorporates an adversarial training loop designed to simulate and anticipate\nevolving cyber threats, enabling proactive defense adaptation. Extensive\nexperimental evaluations conducted on a simulated industrial IoT testbed\nindicate that HAMARL substantially outperforms traditional multi-agent\nreinforcement learning approaches, significantly improving attack detection\naccuracy, reducing response times, and ensuring operational continuity. The\nresults underscore the effectiveness of combining hierarchical multi-agent\ncoordination with adversarially-aware training to enhance the resilience and\nsecurity of next-generation CPS."}
{"id": "2506.22446", "pdf": "https://arxiv.org/pdf/2506.22446", "abs": "https://arxiv.org/abs/2506.22446", "authors": ["Aakash Tripathi", "Asim Waqas", "Matthew B. Schabath", "Yasin Yilmaz", "Ghulam Rasool"], "title": "EAGLE: Efficient Alignment of Generalized Latent Embeddings for Multimodal Survival Prediction with Interpretable Attribution Analysis", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Accurate cancer survival prediction requires integration of diverse data\nmodalities that reflect the complex interplay between imaging, clinical\nparameters, and textual reports. However, existing multimodal approaches suffer\nfrom simplistic fusion strategies, massive computational requirements, and lack\nof interpretability-critical barriers to clinical adoption. We present EAGLE\n(Efficient Alignment of Generalized Latent Embeddings), a novel deep learning\nframework that addresses these limitations through attention-based multimodal\nfusion with comprehensive attribution analysis. EAGLE introduces four key\ninnovations: (1) dynamic cross-modal attention mechanisms that learn\nhierarchical relationships between modalities, (2) massive dimensionality\nreduction (99.96%) while maintaining predictive performance, (3) three\ncomplementary attribution methods providing patient-level interpretability, and\n(4) a unified pipeline enabling seamless adaptation across cancer types. We\nevaluated EAGLE on 911 patients across three distinct malignancies:\nglioblastoma (GBM, n=160), intraductal papillary mucinous neoplasms (IPMN,\nn=171), and non-small cell lung cancer (NSCLC, n=580). Patient-level analysis\nshowed high-risk individuals relied more heavily on adverse imaging features,\nwhile low-risk patients demonstrated balanced modality contributions. Risk\nstratification identified clinically meaningful groups with 4-fold (GBM) to\n5-fold (NSCLC) differences in median survival, directly informing treatment\nintensity decisions. By combining state-of-the-art performance with clinical\ninterpretability, EAGLE bridges the gap between advanced AI capabilities and\npractical healthcare deployment, offering a scalable solution for multimodal\nsurvival prediction that enhances both prognostic accuracy and physician trust\nin automated predictions."}
{"id": "2506.22447", "pdf": "https://arxiv.org/pdf/2506.22447", "abs": "https://arxiv.org/abs/2506.22447", "authors": ["Fabio Merizzi", "Harilaos Loukos"], "title": "Vision Transformers for Multi-Variable Climate Downscaling: Emulating Regional Climate Models with a Shared Encoder and Multi-Decoder Architecture", "categories": ["cs.LG", "cs.AI", "eess.IV"], "comment": null, "summary": "Global Climate Models (GCMs) are critical for simulating large-scale climate\ndynamics, but their coarse spatial resolution limits their applicability in\nregional studies. Regional Climate Models (RCMs) refine this through dynamic\ndownscaling, albeit at considerable computational cost and with limited\nflexibility. While deep learning has emerged as an efficient data-driven\nalternative, most existing studies have focused on single-variable models that\ndownscale one variable at a time. This approach can lead to limited contextual\nawareness, redundant computation, and lack of cross-variable interaction. Our\nstudy addresses these limitations by proposing a multi-task, multi-variable\nVision Transformer (ViT) architecture with a shared encoder and\nvariable-specific decoders (1EMD). The proposed architecture jointly predicts\nthree key climate variables: surface temperature (tas), wind speed (sfcWind),\nand 500 hPa geopotential height (zg500), directly from GCM-resolution inputs,\nemulating RCM-scale downscaling over Europe. We show that our multi-variable\napproach achieves positive cross-variable knowledge transfer and consistently\noutperforms single-variable baselines trained under identical conditions, while\nalso improving computational efficiency. These results demonstrate the\neffectiveness of multi-variable modeling for high-resolution climate\ndownscaling."}
{"id": "2506.22502", "pdf": "https://arxiv.org/pdf/2506.22502", "abs": "https://arxiv.org/abs/2506.22502", "authors": ["Matvei Anoshin", "Olga Tsurkan", "Vadim Lopatkin", "Leonid Fedichkin"], "title": "Stabilization of industrial processes with time series machine learning", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "The stabilization of time series processes is a crucial problem that is\nubiquitous in various industrial fields. The application of machine learning to\nits solution can have a decisive impact, improving both the quality of the\nresulting stabilization with less computational resources required. In this\nwork, we present a simple pipeline consisting of two neural networks: the\noracle predictor and the optimizer, proposing a substitution of the point-wise\nvalues optimization to the problem of the neural network training, which\nsuccessfully improves stability in terms of the temperature control by about 3\ntimes compared to ordinary solvers."}
{"id": "2506.22530", "pdf": "https://arxiv.org/pdf/2506.22530", "abs": "https://arxiv.org/abs/2506.22530", "authors": ["Jakub Peleška", "Gustav Šír"], "title": "Task-Agnostic Contrastive Pretraining for Relational Deep Learning", "categories": ["cs.LG", "cs.DB"], "comment": "arXiv admin note: text overlap with arXiv:2506.22199", "summary": "Relational Deep Learning (RDL) is an emerging paradigm that leverages Graph\nNeural Network principles to learn directly from relational databases by\nrepresenting them as heterogeneous graphs. However, existing RDL models\ntypically rely on task-specific supervised learning, requiring training\nseparate models for each predictive task, which may hamper scalability and\nreuse.\n  In this work, we propose a novel task-agnostic contrastive pretraining\napproach for RDL that enables database-wide representation learning. For that\naim, we introduce three levels of contrastive objectives$-$row-level,\nlink-level, and context-level$-$designed to capture the structural and semantic\nheterogeneity inherent to relational data. We implement the respective\npretraining approach through a modular RDL architecture and an efficient\nsampling strategy tailored to the heterogeneous database setting. Our\npreliminary results on standard RDL benchmarks demonstrate that fine-tuning the\npretrained models measurably outperforms training from scratch, validating the\npromise of the proposed methodology in learning transferable representations\nfor relational data."}
{"id": "2506.22566", "pdf": "https://arxiv.org/pdf/2506.22566", "abs": "https://arxiv.org/abs/2506.22566", "authors": ["Jacob Adamczyk"], "title": "Exploration Behavior of Untrained Policies", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "High-dimensional Learning Dynamics Workshop at ICML-2025", "summary": "Exploration remains a fundamental challenge in reinforcement learning (RL),\nparticularly in environments with sparse or adversarial reward structures. In\nthis work, we study how the architecture of deep neural policies implicitly\nshapes exploration before training. We theoretically and empirically\ndemonstrate strategies for generating ballistic or diffusive trajectories from\nuntrained policies in a toy model. Using the theory of infinite-width networks\nand a continuous-time limit, we show that untrained policies return correlated\nactions and result in non-trivial state-visitation distributions. We discuss\nthe distributions of the corresponding trajectories for a standard\narchitecture, revealing insights into inductive biases for tackling\nexploration. Our results establish a theoretical and experimental framework for\nusing policy initialization as a design tool to understand exploration behavior\nin early training."}
{"id": "2506.22578", "pdf": "https://arxiv.org/pdf/2506.22578", "abs": "https://arxiv.org/abs/2506.22578", "authors": ["Xufei Lv", "Haoyuan Sun", "Xuefeng Bai", "Min Zhang", "Houde Liu", "Kehai Chen"], "title": "The Hidden Link Between RLHF and Contrastive Learning", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Alignment of large language models (LLMs) with human values has recently\ngarnered significant attention, with prominent examples including the canonical\nyet costly Reinforcement Learning from Human Feedback (RLHF) and the simple\nDirect Preference Optimization (DPO). In this work, we demonstrate that both\nRLHF and DPO can be interpreted from the perspective of mutual information (MI)\nmaximization, uncovering a profound connection to contrastive learning. Within\nthis framework, both RLHF and DPO can be viewed as methods that perform\ncontrastive learning based on the positive and negative samples derived from\nthe base model, leveraging the Donsker-Varadhan (DV) lower bound on MI\n(equivalently, the MINE estimator). This paradigm further explains why RLHF may\nnot intrinsically incentivize reasoning capacities in LLMs beyond what is\nalready present in the base model. Building on this perspective, we replace the\nDV/MINE bound with the Jensen-Shannon MI estimator and propose Mutual\nInformation Optimization (MIO). Comprehensive theoretical analysis and\nextensive empirical evaluations demonstrate that MIO mitigates the late-stage\ndecline in chosen-likelihood observed in DPO, achieving competitive or superior\nperformance across various challenging reasoning and mathematical benchmarks.\nWe will release the model and code upon acceptance."}
{"id": "2506.22602", "pdf": "https://arxiv.org/pdf/2506.22602", "abs": "https://arxiv.org/abs/2506.22602", "authors": ["Joshua C. Zhao", "Saurabh Bagchi"], "title": "Are Fast Methods Stable in Adversarially Robust Transfer Learning?", "categories": ["cs.LG", "stat.ML"], "comment": "13 pages", "summary": "Transfer learning is often used to decrease the computational cost of model\ntraining, as fine-tuning a model allows a downstream task to leverage the\nfeatures learned from the pre-training dataset and quickly adapt them to a new\ntask. This is particularly useful for achieving adversarial robustness, as\nadversarially training models from scratch is very computationally expensive.\nHowever, high robustness in transfer learning still requires adversarial\ntraining during the fine-tuning phase, which requires up to an order of\nmagnitude more time than standard fine-tuning. In this work, we revisit the use\nof the fast gradient sign method (FGSM) in robust transfer learning to improve\nthe computational cost of adversarial fine-tuning. We surprisingly find that\nFGSM is much more stable in adversarial fine-tuning than when training from\nscratch. In particular, FGSM fine-tuning does not suffer from any issues with\ncatastrophic overfitting at standard perturbation budgets of $\\varepsilon=4$ or\n$\\varepsilon=8$. This stability is further enhanced with parameter-efficient\nfine-tuning methods, where FGSM remains stable even up to $\\varepsilon=32$ for\nlinear probing. We demonstrate how this stability translates into performance\nacross multiple datasets. Compared to fine-tuning with the more commonly used\nmethod of projected gradient descent (PGD), on average, FGSM only loses 0.39%\nand 1.39% test robustness for $\\varepsilon=4$ and $\\varepsilon=8$ while using\n$4\\times$ less training time. Surprisingly, FGSM may not only be a\nsignificantly more efficient alternative to PGD in adversarially robust\ntransfer learning but also a well-performing one."}
{"id": "2506.22621", "pdf": "https://arxiv.org/pdf/2506.22621", "abs": "https://arxiv.org/abs/2506.22621", "authors": ["Paul Saves", "Edward Hallé-Hannan", "Jasper Bussemaker", "Youssef Diouane", "Nathalie Bartoli"], "title": "Hierarchical Modeling and Architecture Optimization: Review and Unified Framework", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": null, "summary": "Simulation-based problems involving mixed-variable inputs frequently feature\ndomains that are hierarchical, conditional, heterogeneous, or tree-structured.\nThese characteristics pose challenges for data representation, modeling, and\noptimization. This paper reviews extensive literature on these structured input\nspaces and proposes a unified framework that generalizes existing approaches.\nIn this framework, input variables may be continuous, integer, or categorical.\nA variable is described as meta if its value governs the presence of other\ndecreed variables, enabling the modeling of conditional and hierarchical\nstructures.\n  We further introduce the concept of partially-decreed variables, whose\nactivation depends on contextual conditions. To capture these inter-variable\nhierarchical relationships, we introduce design space graphs, combining\nprinciples from feature modeling and graph theory. This allows the definition\nof general hierarchical domains suitable for describing complex system\narchitectures. The framework supports the use of surrogate models over such\ndomains and integrates hierarchical kernels and distances for efficient\nmodeling and optimization. The proposed methods are implemented in the\nopen-source Surrogate Modeling Toolbox (SMT 2.0), and their capabilities are\ndemonstrated through applications in Bayesian optimization for complex system\ndesign, including a case study in green aircraft architecture."}
{"id": "2506.22631", "pdf": "https://arxiv.org/pdf/2506.22631", "abs": "https://arxiv.org/abs/2506.22631", "authors": ["Dmitry B. Rokhlin"], "title": "A hierarchical Vovk-Azoury-Warmuth forecaster with discounting for online regression in RKHS", "categories": ["cs.LG", "stat.ML", "68Q32, 68W27, 68W20"], "comment": null, "summary": "We study the problem of online regression with the unconstrained quadratic\nloss against a time-varying sequence of functions from a Reproducing Kernel\nHilbert Space (RKHS). Recently, Jacobsen and Cutkosky (2024) introduced a\ndiscounted Vovk-Azoury-Warmuth (DVAW) forecaster that achieves optimal dynamic\nregret in the finite-dimensional case. In this work, we lift their approach to\nthe non-parametric domain by synthesizing the DVAW framework with a random\nfeature approximation. We propose a fully adaptive, hierarchical algorithm,\nwhich we call H-VAW-D (Hierarchical Vovk-Azoury-Warmuth with Discounting), that\nlearns both the discount factor and the number of random features. We prove\nthat this algorithm, which has a per-iteration computational complexity of\n$O(T\\ln T)$, achieves an expected dynamic regret of $O(T^{2/3}P_T^{1/3} +\n\\sqrt{T}\\ln T)$, where $P_T$ is the functional path length of a comparator\nsequence."}
{"id": "2506.22638", "pdf": "https://arxiv.org/pdf/2506.22638", "abs": "https://arxiv.org/abs/2506.22638", "authors": ["Aadim Nepal", "Safal Shrestha", "Anubhav Shrestha", "Minwu Kim", "Keith Ross"], "title": "Layer Importance for Mathematical Reasoning is Forged in Pre-Training and Invariant after Post-Training", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models can exhibit improved mathematical reasoning\ncapabilities following post-training with instruction tuning, reinforcement\nlearning, or knowledge distillation. However, it remains unclear whether these\nimprovements are driven by major changes in transformer layers or from minor\nadjustments that leave the relative layer importance structures of the base\nmodel largely unchanged. We investigate this question through systematic\nlayer-wise ablation experiments, examining base, instruction-tuned,\nknowledge-distilled, and reinforcement learning variants on mathematical\nreasoning benchmarks. Our findings show that mathematical reasoning gives rise\nto a specific layer importance structure, and this structure persists across\nall post-training paradigms. Removal of such layers causes accuracy drops of up\nto 80%. In contrast, non-mathematical tasks like factual recall exhibit no\ncritical layers. This distinction suggests that mathematical reasoning requires\nspecialized layers that emerge during pre-training, while other non-reasoning\ntasks do not. From an information-theoretic perspective, we also observe that\nthese critical layers are the same layers where major representational\ntransformation occurs."}
{"id": "2506.22645", "pdf": "https://arxiv.org/pdf/2506.22645", "abs": "https://arxiv.org/abs/2506.22645", "authors": ["Amir Hossein Rahmati", "Nathan M. Urban", "Byung-Jun Yoon", "Xiaoning Qian"], "title": "Cost-effective Reduced-Order Modeling via Bayesian Active Learning", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Machine Learning surrogates have been developed to accelerate solving systems\ndynamics of complex processes in different science and engineering\napplications. To faithfully capture governing systems dynamics, these methods\nrely on large training datasets, hence restricting their applicability in\nreal-world problems. In this work, we propose BayPOD-AL, an active learning\nframework based on an uncertainty-aware Bayesian proper orthogonal\ndecomposition (POD) approach, which aims to effectively learn reduced-order\nmodels from high-fidelity full-order models representing complex systems.\nExperimental results on predicting the temperature evolution over a rod\ndemonstrate BayPOD-AL's effectiveness in suggesting the informative data and\nreducing computational cost related to constructing a training dataset compared\nto other uncertainty-guided active learning strategies. Furthermore, we\ndemonstrate BayPOD-AL's generalizability and efficiency by evaluating its\nperformance on a dataset of higher temporal resolution than the training\ndataset."}
{"id": "2506.22655", "pdf": "https://arxiv.org/pdf/2506.22655", "abs": "https://arxiv.org/abs/2506.22655", "authors": ["Andrew F. Ilersich", "Prasanth B. Nair"], "title": "Learning Stochastic Multiscale Models", "categories": ["cs.LG"], "comment": "Body is 9 pages, 13 including acknowledgements and references, 35\n  including appendix. 21 figures and 6 tables. Submitted to NeurIPS 2025", "summary": "The physical sciences are replete with dynamical systems that require the\nresolution of a wide range of length and time scales. This presents significant\ncomputational challenges since direct numerical simulation requires\ndiscretization at the finest relevant scales, leading to a high-dimensional\nstate space. In this work, we propose an approach to learn stochastic\nmultiscale models in the form of stochastic differential equations directly\nfrom observational data. Our method resolves the state on a coarse mesh while\nintroducing an auxiliary state to capture the effects of unresolved scales. We\nlearn the parameters of the multiscale model using a modern forward-solver-free\namortized variational inference method. Our approach draws inspiration from\nphysics-based multiscale modeling approaches, such as large-eddy simulation in\nfluid dynamics, while learning directly from data. We present numerical studies\nto demonstrate that our learned multiscale models achieve superior predictive\naccuracy compared to direct numerical simulation and closure-type models at\nequivalent resolution."}
{"id": "2506.22668", "pdf": "https://arxiv.org/pdf/2506.22668", "abs": "https://arxiv.org/abs/2506.22668", "authors": ["Selahattin Akkas", "Aditya Devarakonda", "Ariful Azad"], "title": "DistShap: Scalable GNN Explanations with Distributed Shapley Values", "categories": ["cs.LG", "cs.AI", "cs.DC", "stat.ML"], "comment": "12 pages", "summary": "With the growing adoption of graph neural networks (GNNs), explaining their\npredictions has become increasingly important. However, attributing predictions\nto specific edges or features remains computationally expensive. For example,\nclassifying a node with 100 neighbors using a 3-layer GNN may involve\nidentifying important edges from millions of candidates contributing to the\nprediction. To address this challenge, we propose DistShap, a parallel\nalgorithm that distributes Shapley value-based explanations across multiple\nGPUs. DistShap operates by sampling subgraphs in a distributed setting,\nexecuting GNN inference in parallel across GPUs, and solving a distributed\nleast squares problem to compute edge importance scores. DistShap outperforms\nmost existing GNN explanation methods in accuracy and is the first to scale to\nGNN models with millions of features by using up to 128 GPUs on the NERSC\nPerlmutter supercomputer."}
{"id": "2506.22685", "pdf": "https://arxiv.org/pdf/2506.22685", "abs": "https://arxiv.org/abs/2506.22685", "authors": ["Anh Bui", "Trang Vu", "Trung Le", "Junae Kim", "Tamas Abraham", "Rollin Omari", "Amar Kaur", "Dinh Phung"], "title": "Mitigating Semantic Collapse in Generative Personalization with a Surprisingly Simple Test-Time Embedding Adjustment", "categories": ["cs.LG", "cs.GR"], "comment": null, "summary": "In this paper, we investigate the semantic collapsing problem in generative\npersonalization, an under-explored topic where the learned visual concept\n($V^*$) gradually shifts from its original textual meaning and comes to\ndominate other concepts in multi-concept input prompts. This issue not only\nreduces the semantic richness of complex input prompts like \"a photo of $V^*$\nwearing glasses and playing guitar\" into simpler, less contextually rich forms\nsuch as \"a photo of $V^*$\" but also leads to simplified output images that fail\nto capture the intended concept.\n  We identify the root cause as unconstrained optimisation, which allows the\nlearned embedding $V^*$ to drift arbitrarily in the embedding space, both in\ndirection and magnitude. To address this, we propose a simple yet effective\ntraining-free method that adjusts the magnitude and direction of pre-trained\nembedding at inference time, effectively mitigating the semantic collapsing\nproblem. Our method is broadly applicable across different personalization\nmethods and demonstrates significant improvements in text-image alignment in\ndiverse use cases. Our code is anonymously published at\nhttps://anonymous.4open.science/r/Embedding-Adjustment."}
{"id": "2506.22696", "pdf": "https://arxiv.org/pdf/2506.22696", "abs": "https://arxiv.org/abs/2506.22696", "authors": ["Brian Mak", "Jeffrey Flanigan"], "title": "Residual Matrix Transformers: Scaling the Size of the Residual Stream", "categories": ["cs.LG", "cs.CL"], "comment": "Accepted to ICML 2025", "summary": "The residual stream acts as a memory bus where transformer layers both store\nand access features (Elhage et al., 2021). We consider changing the mechanism\nfor retrieving and storing information in the residual stream, and replace the\nresidual stream of the transformer with an outer product memory matrix\n(Kohonen, 1972, Anderson, 1972). We call this model the Residual Matrix\nTransformer (RMT). We find that the RMT enjoys a number of attractive\nproperties: 1) the size of the residual stream can be scaled independently of\ncompute and model size, improving performance, 2) the RMT can achieve the same\nloss as the transformer with 58% fewer FLOPS, 25% fewer parameters, and 41%\nfewer training tokens tokens, and 3) the RMT outperforms the transformer on\ndownstream evaluations. We theoretically analyze the transformer and the RMT,\nand show that the RMT allows for more efficient scaling of the residual stream,\nas well as improved variance propagation properties. Code for this project can\nbe found at https://github.com/bmac3/residual-matrix-transformer."}
{"id": "2506.22708", "pdf": "https://arxiv.org/pdf/2506.22708", "abs": "https://arxiv.org/abs/2506.22708", "authors": ["Shrenik Jadhav", "Birva Sevak", "Srijita Das", "Akhtar Hussain", "Wencong Su", "Van-Hai Bui"], "title": "FairMarket-RL: LLM-Guided Fairness Shaping for Multi-Agent Reinforcement Learning in Peer-to-Peer Markets", "categories": ["cs.LG", "cs.SY", "econ.GN", "eess.SY", "q-fin.EC"], "comment": null, "summary": "Peer-to-peer (P2P) trading is increasingly recognized as a key mechanism for\ndecentralized market regulation, yet existing approaches often lack robust\nframeworks to ensure fairness. This paper presents FairMarket-RL, a novel\nhybrid framework that combines Large Language Models (LLMs) with Reinforcement\nLearning (RL) to enable fairness-aware trading agents. In a simulated P2P\nmicrogrid with multiple sellers and buyers, the LLM acts as a real-time\nfairness critic, evaluating each trading episode using two metrics:\nFairness-To-Buyer (FTB) and Fairness-Between-Sellers (FBS). These fairness\nscores are integrated into agent rewards through scheduled\n{\\lambda}-coefficients, forming an adaptive LLM-guided reward shaping loop that\nreplaces brittle, rule-based fairness constraints. Agents are trained using\nIndependent Proximal Policy Optimization (IPPO) and achieve equitable outcomes,\nfulfilling over 90% of buyer demand, maintaining fair seller margins, and\nconsistently reaching FTB and FBS scores above 0.80. The training process\ndemonstrates that fairness feedback improves convergence, reduces buyer\nshortfalls, and narrows profit disparities between sellers. With its\nlanguage-based critic, the framework scales naturally, and its extension to a\nlarge power distribution system with household prosumers illustrates its\npractical applicability. FairMarket-RL thus offers a scalable, equity-driven\nsolution for autonomous trading in decentralized energy systems."}
{"id": "2506.22712", "pdf": "https://arxiv.org/pdf/2506.22712", "abs": "https://arxiv.org/abs/2506.22712", "authors": ["Alexander Theus", "Alessandro Cabodi", "Sotiris Anagnostidis", "Antonio Orvieto", "Sidak Pal Singh", "Valentina Boeva"], "title": "Generalized Linear Mode Connectivity for Transformers", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Understanding the geometry of neural network loss landscapes is a central\nquestion in deep learning, with implications for generalization and\noptimization. A striking phenomenon is linear mode connectivity (LMC), where\nindependently trained models can be connected by low- or zero-loss paths,\ndespite appearing to lie in separate loss basins. However, this is often\nobscured by symmetries in parameter space -- such as neuron permutations --\nwhich make functionally equivalent models appear dissimilar. Prior work has\npredominantly focused on neuron re-ordering through permutations, but such\napproaches are limited in scope and fail to capture the richer symmetries\nexhibited by modern architectures such as Transformers. In this work, we\nintroduce a unified framework that captures four symmetry classes:\npermutations, semi-permutations, orthogonal transformations, and general\ninvertible maps -- broadening the set of valid reparameterizations and\nsubsuming many previous approaches as special cases. Crucially, this\ngeneralization enables, for the first time, the discovery of low- and\nzero-barrier linear interpolation paths between independently trained Vision\nTransformers and GPT-2 models. These results reveal deeper structure in the\nloss landscape and underscore the importance of symmetry-aware analysis for\nunderstanding model space geometry."}
{"id": "2506.22716", "pdf": "https://arxiv.org/pdf/2506.22716", "abs": "https://arxiv.org/abs/2506.22716", "authors": ["Dujian Ding", "Ankur Mallick", "Shaokun Zhang", "Chi Wang", "Daniel Madrigal", "Mirian Del Carmen Hipolito Garcia", "Menglin Xia", "Laks V. S. Lakshmanan", "Qingyun Wu", "Victor Rühle"], "title": "BEST-Route: Adaptive LLM Routing with Test-Time Optimal Compute", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.DB"], "comment": "Accepted to ICML 2025 (main conference)", "summary": "Large language models (LLMs) are powerful tools but are often expensive to\ndeploy at scale. LLM query routing mitigates this by dynamically assigning\nqueries to models of varying cost and quality to obtain a desired trade-off.\nPrior query routing approaches generate only one response from the selected\nmodel and a single response from a small (inexpensive) model was often not good\nenough to beat a response from a large (expensive) model due to which they end\nup overusing the large model and missing out on potential cost savings.\nHowever, it is well known that for small models, generating multiple responses\nand selecting the best can enhance quality while remaining cheaper than a\nsingle large-model response. We leverage this idea to propose BEST-Route, a\nnovel routing framework that chooses a model and the number of responses to\nsample from it based on query difficulty and the quality thresholds.\nExperiments on real-world datasets demonstrate that our method reduces costs by\nup to 60% with less than 1% performance drop."}
{"id": "2506.22732", "pdf": "https://arxiv.org/pdf/2506.22732", "abs": "https://arxiv.org/abs/2506.22732", "authors": ["Hao Shu", "Jicheng Li", "Tianyv Lei", "Lijun Sun"], "title": "Robust Tensor Completion via Gradient Tensor Nulclear L1-L2 Norm for Traffic Data Recovery", "categories": ["cs.LG", "eess.SP", "stat.ML"], "comment": null, "summary": "In real-world scenarios, spatiotemporal traffic data frequently experiences\ndual degradation from missing values and noise caused by sensor malfunctions\nand communication failures. Therefore, effective data recovery methods are\nessential to ensure the reliability of downstream data-driven applications.\nwhile classical tensor completion methods have been widely adopted, they are\nincapable of modeling noise, making them unsuitable for complex scenarios\ninvolving simultaneous data missingness and noise interference. Existing Robust\nTensor Completion (RTC) approaches offer potential solutions by separately\nmodeling the actual tensor data and noise. However, their effectiveness is\noften constrained by the over-relaxation of convex rank surrogates and the\nsuboptimal utilization of local consistency, leading to inadequate model\naccuracy. To address these limitations, we first introduce the tensor L1-L2\nnorm, a novel non-convex tensor rank surrogate that functions as an effective\nlow-rank representation tool. Leveraging an advanced feature fusion strategy,\nwe further develop the gradient tensor L1-L2 norm by incorporating the tensor\nL1-L2 norm in the gradient domain. By integrating the gradient tensor nuclear\nL1-L2 norm into the RTC framework, we propose the Robust Tensor Completion via\nGradient Tensor Nuclear L1-L2 Norm (RTC-GTNLN) model, which not only fully\nexploits both global low-rankness and local consistency without trade-off\nparameter, but also effectively handles the dual degradation challenges of\nmissing data and noise in traffic data. Extensive experiments conducted on\nmultiple real-world traffic datasets demonstrate that the RTC-GTNLN model\nconsistently outperforms existing state-of-the-art methods in complex recovery\nscenarios involving simultaneous missing values and noise."}
{"id": "2506.22771", "pdf": "https://arxiv.org/pdf/2506.22771", "abs": "https://arxiv.org/abs/2506.22771", "authors": ["Jingxiao Ma", "Priyadarshini Panda", "Sherief Reda"], "title": "FF-INT8: Efficient Forward-Forward DNN Training on Edge Devices with INT8 Precision", "categories": ["cs.LG", "cs.AI", "cs.NE", "I.2.0; I.2.6"], "comment": "To be published in the 62nd Design Automation Conference (DAC), 2025", "summary": "Backpropagation has been the cornerstone of neural network training for\ndecades, yet its inefficiencies in time and energy consumption limit its\nsuitability for resource-constrained edge devices. While low-precision neural\nnetwork quantization has been extensively researched to speed up model\ninference, its application in training has been less explored. Recently, the\nForward-Forward (FF) algorithm has emerged as a promising alternative to\nbackpropagation, replacing the backward pass with an additional forward pass.\nBy avoiding the need to store intermediate activations for backpropagation, FF\ncan reduce memory footprint, making it well-suited for embedded devices. This\npaper presents an INT8 quantized training approach that leverages FF's\nlayer-by-layer strategy to stabilize gradient quantization. Furthermore, we\npropose a novel \"look-ahead\" scheme to address limitations of FF and improve\nmodel accuracy. Experiments conducted on NVIDIA Jetson Orin Nano board\ndemonstrate 4.6% faster training, 8.3% energy savings, and 27.0% reduction in\nmemory usage, while maintaining competitive accuracy compared to the\nstate-of-the-art."}
{"id": "2506.22780", "pdf": "https://arxiv.org/pdf/2506.22780", "abs": "https://arxiv.org/abs/2506.22780", "authors": ["Dibyajyoti Chakraborty", "Haiwen Guan", "Jason Stock", "Troy Arcomano", "Guido Cervone", "Romit Maulik"], "title": "Multimodal Atmospheric Super-Resolution With Deep Generative Models", "categories": ["cs.LG", "physics.geo-ph"], "comment": null, "summary": "Score-based diffusion modeling is a generative machine learning algorithm\nthat can be used to sample from complex distributions. They achieve this by\nlearning a score function, i.e., the gradient of the log-probability density of\nthe data, and reversing a noising process using the same. Once trained,\nscore-based diffusion models not only generate new samples but also enable\nzero-shot conditioning of the generated samples on observed data. This promises\na novel paradigm for data and model fusion, wherein the implicitly learned\ndistributions of pretrained score-based diffusion models can be updated given\nthe availability of online data in a Bayesian formulation. In this article, we\napply such a concept to the super-resolution of a high-dimensional dynamical\nsystem, given the real-time availability of low-resolution and experimentally\nobserved sparse sensor measurements from multimodal data. Additional analysis\non how score-based sampling can be used for uncertainty estimates is also\nprovided. Our experiments are performed for a super-resolution task that\ngenerates the ERA5 atmospheric dataset given sparse observations from a\ncoarse-grained representation of the same and/or from unstructured experimental\nobservations of the IGRA radiosonde dataset. We demonstrate accurate recovery\nof the high dimensional state given multiple sources of low-fidelity\nmeasurements. We also discover that the generative model can balance the\ninfluence of multiple dataset modalities during spatiotemporal reconstructions."}
{"id": "2506.22802", "pdf": "https://arxiv.org/pdf/2506.22802", "abs": "https://arxiv.org/abs/2506.22802", "authors": ["Hae Jin Song", "Laurent Itti"], "title": "Riemannian-Geometric Fingerprints of Generative Models", "categories": ["cs.LG", "cs.CR", "cs.CV", "I.2.6"], "comment": null, "summary": "Recent breakthroughs and rapid integration of generative models (GMs) have\nsparked interest in the problem of model attribution and their fingerprints.\nFor instance, service providers need reliable methods of authenticating their\nmodels to protect their IP, while users and law enforcement seek to verify the\nsource of generated content for accountability and trust. In addition, a\ngrowing threat of model collapse is arising, as more model-generated data are\nbeing fed back into sources (e.g., YouTube) that are often harvested for\ntraining (\"regurgitative training\"), heightening the need to differentiate\nsynthetic from human data. Yet, a gap still exists in understanding generative\nmodels' fingerprints, we believe, stemming from the lack of a formal framework\nthat can define, represent, and analyze the fingerprints in a principled way.\nTo address this gap, we take a geometric approach and propose a new definition\nof artifact and fingerprint of GMs using Riemannian geometry, which allows us\nto leverage the rich theory of differential geometry. Our new definition\ngeneralizes previous work (Song et al., 2024) to non-Euclidean manifolds by\nlearning Riemannian metrics from data and replacing the Euclidean distances and\nnearest-neighbor search with geodesic distances and kNN-based Riemannian center\nof mass. We apply our theory to a new gradient-based algorithm for computing\nthe fingerprints in practice. Results show that it is more effective in\ndistinguishing a large array of GMs, spanning across 4 different datasets in 2\ndifferent resolutions (64 by 64, 256 by 256), 27 model architectures, and 2\nmodalities (Vision, Vision-Language). Using our proposed definition\nsignificantly improves the performance on model attribution, as well as a\ngeneralization to unseen datasets, model types, and modalities, suggesting its\npractical efficacy."}
{"id": "2506.22809", "pdf": "https://arxiv.org/pdf/2506.22809", "abs": "https://arxiv.org/abs/2506.22809", "authors": ["Cooper Doyle"], "title": "BayesLoRA: Task-Specific Uncertainty in Low-Rank Adapters", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "13 pages, 3 figures, 1 table", "summary": "We propose BayesLoRA, a task-specific uncertainty quantification framework\nthat integrates MC-Dropout into Low-Rank Adapters (LoRA). Unlike\ngeneral-purpose transformer uncertainty methods, BayesLoRA provides guardrails\ntailored to downstream workflows, enabling agents to introspect and modulate\nbehavior under uncertainty. We demonstrate mathematically and empirically that\nLoRA adapters exhibit amplified variance outside fine-tuning distributions,\nyielding reliable confidence estimates for agentic decision-making."}
{"id": "2506.22821", "pdf": "https://arxiv.org/pdf/2506.22821", "abs": "https://arxiv.org/abs/2506.22821", "authors": ["Thomas Gaskin", "Guy J. Abel"], "title": "Deep learning 40 years of human migration", "categories": ["cs.LG", "68T07", "I.2.6"], "comment": null, "summary": "We present a novel and detailed dataset on origin-destination annual\nmigration flows and stocks between 230 countries and regions, spanning the\nperiod from 1990 to the present. Our flow estimates are further disaggregated\nby country of birth, providing a comprehensive picture of migration over the\nlast 43 years. The estimates are obtained by training a deep recurrent neural\nnetwork to learn flow patterns from 18 covariates for all countries, including\ngeographic, economic, cultural, societal, and political information. The\nrecurrent architecture of the neural network means that the entire past can\ninfluence current migration patterns, allowing us to learn long-range temporal\ncorrelations. By training an ensemble of neural networks and additionally\npushing uncertainty on the covariates through the trained network, we obtain\nconfidence bounds for all our estimates, allowing researchers to pinpoint the\ngeographic regions most in need of additional data collection. We validate our\napproach on various test sets of unseen data, demonstrating that it\nsignificantly outperforms traditional methods estimating five-year flows while\ndelivering a significant increase in temporal resolution. The model is fully\nopen source: all training data, neural network weights, and training code are\nmade public alongside the migration estimates, providing a valuable resource\nfor future studies of human migration."}
{"id": "2506.22837", "pdf": "https://arxiv.org/pdf/2506.22837", "abs": "https://arxiv.org/abs/2506.22837", "authors": ["Kamil Faber", "Marcin Pietroń", "Dominik Żurek", "Roberto Corizzo"], "title": "xLSTMAD: A Powerful xLSTM-based Method for Anomaly Detection", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The recently proposed xLSTM is a powerful model that leverages expressive\nmultiplicative gating and residual connections, providing the temporal capacity\nneeded for long-horizon forecasting and representation learning. This\narchitecture has demonstrated success in time series forecasting, lossless\ncompression, and even large-scale language modeling tasks, where its linear\nmemory footprint and fast inference make it a viable alternative to\nTransformers. Despite its growing popularity, no prior work has explored xLSTM\nfor anomaly detection. In this work, we fill this gap by proposing xLSTMAD, the\nfirst anomaly detection method that integrates a full encoder-decoder xLSTM\narchitecture, purpose-built for multivariate time series data. Our encoder\nprocesses input sequences to capture historical context, while the decoder is\ndevised in two separate variants of the method. In the forecasting approach,\nthe decoder iteratively generates forecasted future values xLSTMAD-F, while the\nreconstruction approach reconstructs the input time series from its encoded\ncounterpart xLSTMAD-R. We investigate the performance of two loss functions:\nMean Squared Error (MSE), and Soft Dynamic Time Warping (SoftDTW) to consider\nlocal reconstruction fidelity and global sequence alignment, respectively. We\nevaluate our method on the comprehensive TSB-AD-M benchmark, which spans 17\nreal-world datasets, using state-of-the-art challenging metrics such as VUS-PR.\nIn our results, xLSTM showcases state-of-the-art accuracy, outperforming 23\npopular anomaly detection baselines. Our paper is the first work revealing the\npowerful modeling capabilities of xLSTM for anomaly detection, paving the way\nfor exciting new developments on this subject. Our code is available at:\nhttps://github.com/Nyderx/xlstmad"}
{"id": "2506.22845", "pdf": "https://arxiv.org/pdf/2506.22845", "abs": "https://arxiv.org/abs/2506.22845", "authors": ["Batuhan Hangun", "Oguz Altun", "Onder Eyecioglu"], "title": "Quantum Neural Networks for Wind Energy Forecasting: A Comparative Study of Performance and Scalability with Classical Models", "categories": ["cs.LG", "cs.AI", "cs.PF"], "comment": null, "summary": "Quantum Neural Networks (QNNs), a prominent approach in Quantum Machine\nLearning (QML), are emerging as a powerful alternative to classical machine\nlearning methods. Recent studies have focused on the applicability of QNNs to\nvarious tasks, such as time-series forecasting, prediction, and classification,\nacross a wide range of applications, including cybersecurity and medical\nimaging. With the increased use of smart grids driven by the integration of\nrenewable energy systems, machine learning plays an important role in\npredicting power demand and detecting system disturbances. This study provides\nan in-depth investigation of QNNs for predicting the power output of a wind\nturbine. We assess the predictive performance and simulation time of six QNN\nconfigurations that are based on the Z Feature Map for data encoding and\nvarying ansatz structures. Through detailed cross-validation experiments and\ntests on an unseen hold-out dataset, we experimentally demonstrate that QNNs\ncan achieve predictive performance that is competitive with, and in some cases\nmarginally better than, the benchmarked classical approaches. Our results also\nreveal the effects of dataset size and circuit complexity on predictive\nperformance and simulation time. We believe our findings will offer valuable\ninsights for researchers in the energy domain who wish to incorporate quantum\nmachine learning into their work."}
{"id": "2506.22848", "pdf": "https://arxiv.org/pdf/2506.22848", "abs": "https://arxiv.org/abs/2506.22848", "authors": ["Shengcai Liu", "Hui Ou-yang", "Zhiyuan Wang", "Cheng Chen", "Qijun Cai", "Yew-Soon Ong", "Ke Tang"], "title": "Scalable Structure Learning of Bayesian Networks by Learning Algorithm Ensembles", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Learning the structure of Bayesian networks (BNs) from data is challenging,\nespecially for datasets involving a large number of variables. The recently\nproposed divide-and-conquer (D\\&D) strategies present a promising approach for\nlearning large BNs. However, they still face a main issue of unstable learning\naccuracy across subproblems. In this work, we introduce the idea of employing\nstructure learning ensemble (SLE), which combines multiple BN structure\nlearning algorithms, to consistently achieve high learning accuracy. We further\npropose an automatic approach called Auto-SLE for learning near-optimal SLEs,\naddressing the challenge of manually designing high-quality SLEs. The learned\nSLE is then integrated into a D\\&D method. Extensive experiments firmly show\nthe superiority of our method over D\\&D methods with single BN structure\nlearning algorithm in learning large BNs, achieving accuracy improvement\nusually by 30\\%$\\sim$225\\% on datasets involving 10,000 variables. Furthermore,\nour method generalizes well to datasets with many more (e.g., 30000) variables\nand different network characteristics than those present in the training data\nfor learning the SLE. These results indicate the significant potential of\nemploying (automatic learning of) SLEs for scalable BN structure learning."}
{"id": "2506.22871", "pdf": "https://arxiv.org/pdf/2506.22871", "abs": "https://arxiv.org/abs/2506.22871", "authors": ["Homayun Afrabandpey", "Hamed Rezazadegan Tavakoli"], "title": "P$^2$U: Progressive Precision Update For Efficient Model Distribution", "categories": ["cs.LG", "cs.MM", "I.2.6"], "comment": null, "summary": "Efficient model distribution is becoming increasingly critical in\nbandwidth-constrained environments. In this paper, we propose a simple yet\neffective approach called Progressive Precision Update (P$^2$U) to address this\nproblem. Instead of transmitting the original high-precision model, P$^2$U\ntransmits a lower-bit precision model, coupled with a model update representing\nthe difference between the original high-precision model and the transmitted\nlow precision version. With extensive experiments on various model\narchitectures, ranging from small models ($1 - 6$ million parameters) to a\nlarge model (more than $100$ million parameters) and using three different data\nsets, e.g., chest X-Ray, PASCAL-VOC, and CIFAR-100, we demonstrate that P$^2$U\nconsistently achieves better tradeoff between accuracy, bandwidth usage and\nlatency. Moreover, we show that when bandwidth or startup time is the priority,\naggressive quantization (e.g., 4-bit) can be used without severely compromising\nperformance. These results establish P$^2$U as an effective and practical\nsolution for scalable and efficient model distribution in low-resource\nsettings, including federated learning, edge computing, and IoT deployments.\nGiven that P$^2$U complements existing compression techniques and can be\nimplemented alongside any compression method, e.g., sparsification,\nquantization, pruning, etc., the potential for improvement is even greater."}
{"id": "2506.22895", "pdf": "https://arxiv.org/pdf/2506.22895", "abs": "https://arxiv.org/abs/2506.22895", "authors": ["Xinyu Chen", "Vassilis Digalakis Jr", "Lijun Ding", "Dingyi Zhuang", "Jinhua Zhao"], "title": "Interpretable Time Series Autoregression for Periodicity Quantification", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Time series autoregression is a classical statistical model for capturing\nauto-correlations and identifying temporal patterns such as periodicity and\nseasonality. In this work, we propose a novel sparse autoregression framework\nfrom an interpretable machine learning perspective and the model\ninterpretability for periodicity quantification is reinforced by $\\ell_0$-norm\ninduced sparsity constraints. On the time-varying time series data, we\nreformulate the sparse autoregression and convert the involved optimization\nproblem into a mixed-integer optimization (MIO). To accelerate it, we develop a\nsubspace pursuit based decision variable pruning (DVP) strategy to reduce the\nsearch space. On the multidimensional time series that involves complicated\nspatial and temporal dimensions, we propose a spatially- and time-varying\nsparse autoregression model and resolve the corresponding MIO problem by\ndeveloping a two-stage optimization scheme. In particular, the proposed scheme\nmakes the model scalable to large problems even with millions of decision\nvariables. Empirically, we conduct extensive experiments to evaluate the\nproposed models on real-world time series data. First, we demonstrate that the\nMIO solver can be drastically accelerated through the DVP strategy, while\nmaintaining the same solution quality as a full MIO solver. Applying the\ntime-varying sparse autoregression model to ridesharing trip data, we uncover\nboth daily and weekly periodicities and reveal long-term changes in regularity\nof human mobility. Second, we demonstrate the spatial patterns of yearly\nseasonality in climate variable time series such as temperature and\nprecipitation across the past four decades, and our model allows to discover\ndynamic climate patterns and identify climate phenomena such as El Nino in sea\nsurface temperature."}
{"id": "2506.22901", "pdf": "https://arxiv.org/pdf/2506.22901", "abs": "https://arxiv.org/abs/2506.22901", "authors": ["Sina Tabakhi", "Haiping Lu"], "title": "Missing-Modality-Aware Graph Neural Network for Cancer Classification", "categories": ["cs.LG", "cs.AI", "q-bio.BM", "q-bio.GN"], "comment": "15 pages, 7 figures", "summary": "A key challenge in learning from multimodal biological data is missing\nmodalities, where all data from some modalities are missing for some patients.\nCurrent fusion methods address this by excluding patients with missing\nmodalities, imputing missing modalities, or making predictions directly with\npartial modalities. However, they often struggle with diverse missing-modality\npatterns and the exponential growth of the number of such patterns as the\nnumber of modalities increases. To address these limitations, we propose MAGNET\n(Missing-modality-Aware Graph neural NETwork) for direct prediction with\npartial modalities, which introduces a patient-modality multi-head attention\nmechanism to fuse lower-dimensional modality embeddings based on their\nimportance and missingness. MAGNET's complexity increases linearly with the\nnumber of modalities while adapting to missing-pattern variability. To generate\npredictions, MAGNET further constructs a patient graph with fused multimodal\nembeddings as node features and the connectivity determined by the modality\nmissingness, followed by a conventional graph neural network. Experiments on\nthree public multiomics datasets for cancer classification, with real-world\ninstead of artificial missingness, show that MAGNET outperforms the\nstate-of-the-art fusion methods. The data and code are available at\nhttps://github.com/SinaTabakhi/MAGNET."}
{"id": "2506.22927", "pdf": "https://arxiv.org/pdf/2506.22927", "abs": "https://arxiv.org/abs/2506.22927", "authors": ["Jaeyun Woo", "Jiseok Lee", "Brian Kenji Iwana"], "title": "Towards Time Series Generation Conditioned on Unstructured Natural Language", "categories": ["cs.LG"], "comment": null, "summary": "Generative Artificial Intelligence (AI) has rapidly become a powerful tool,\ncapable of generating various types of data, such as images and text. However,\ndespite the significant advancement of generative AI, time series generative AI\nremains underdeveloped, even though the application of time series is essential\nin finance, climate, and numerous fields. In this research, we propose a novel\nmethod of generating time series conditioned on unstructured natural language\ndescriptions. We use a diffusion model combined with a language model to\ngenerate time series from the text. Through the proposed method, we demonstrate\nthat time series generation based on natural language is possible. The proposed\nmethod can provide various applications such as custom forecasting, time series\nmanipulation, data augmentation, and transfer learning. Furthermore, we\nconstruct and propose a new public dataset for time series generation,\nconsisting of 63,010 time series-description pairs."}
{"id": "2506.22929", "pdf": "https://arxiv.org/pdf/2506.22929", "abs": "https://arxiv.org/abs/2506.22929", "authors": ["Chen Zhang"], "title": "Mathematical Computation on High-dimensional Data via Array Programming and Parallel Acceleration", "categories": ["cs.LG", "cs.AI", "eess.IV", "eess.SP"], "comment": null, "summary": "While deep learning excels in natural image and language processing, its\napplication to high-dimensional data faces computational challenges due to the\ndimensionality curse. Current large-scale data tools focus on business-oriented\ndescriptive statistics, lacking mathematical statistics support for advanced\nanalysis. We propose a parallel computation architecture based on space\ncompleteness, decomposing high-dimensional data into dimension-independent\nstructures for distributed processing. This framework enables seamless\nintegration of data mining and parallel-optimized machine learning methods,\nsupporting scientific computations across diverse data types like medical and\nnatural images within a unified system."}
{"id": "2506.22950", "pdf": "https://arxiv.org/pdf/2506.22950", "abs": "https://arxiv.org/abs/2506.22950", "authors": ["Liangyu Wang", "Huanyi Xie", "Xinhai Wang", "Tianjin Huang", "Mengdi Li", "Di Wang"], "title": "Infinite Sampling: Efficient and Stable Grouped RL Training for Large Language Models", "categories": ["cs.LG"], "comment": null, "summary": "Group-based reinforcement learning algorithms such as Group Reward Policy\nOptimization (GRPO) have proven effective for fine-tuning large language models\n(LLMs) with human feedback. However, generating and storing multiple responses\nper prompt incurs substantial memory overhead, especially as the sample group\nsize increases, limiting scalability under constrained hardware.\n  We propose Infinite Sampling, a framework that enables efficient and stable\nGRPO training by decoupling group size from GPU memory usage. It consists of:\n(1) micro sampling groups that decompose large groups into memory-feasible\nrounds; (2) continuous sampling that interleaves generation across groups to\nimprove utilization; and (3) a length-aware scheduler combining\ntoken-conditioned sequence length prediction with a two-stage plan: global\ngrouping via FPTAS and runtime refill via SJF.\n  Experiments show that our Micro Sampling Groups reduce peak memory usage by\nover 50% compared to full-group decoding (e.g., from 21.55 GB to 10.64 GB on\nQwen3-1.7B). Building on this, Infinite Sampling improves throughput by over\n25% compared to the naive micro sampling group method, reducing decoding steps\nwhile maintaining full-length completions and memory usage. Our hybrid\nscheduling ensures efficient and stable GRPO training with larger groups under\nrealistic GPU memory constraints."}
{"id": "2506.22984", "pdf": "https://arxiv.org/pdf/2506.22984", "abs": "https://arxiv.org/abs/2506.22984", "authors": ["Prathyush Kumar Reddy Lebaku", "Lu Gao", "Yunpeng Zhang", "Zhixia Li", "Yongxin Liu", "Tanvir Arafin"], "title": "Cybersecurity-Focused Anomaly Detection in Connected Autonomous Vehicles Using Machine Learning", "categories": ["cs.LG"], "comment": null, "summary": "Anomaly detection in connected autonomous vehicles (CAVs) is crucial for\nmaintaining safe and reliable transportation networks, as CAVs can be\nsusceptible to sensor malfunctions, cyber-attacks, and unexpected environmental\ndisruptions. This study explores an anomaly detection approach by simulating\nvehicle behavior, generating a dataset that represents typical and atypical\nvehicular interactions. The dataset includes time-series data of position,\nspeed, and acceleration for multiple connected autonomous vehicles. We utilized\nmachine learning models to effectively identify abnormal driving patterns.\nFirst, we applied a stacked Long Short-Term Memory (LSTM) model to capture\ntemporal dependencies and sequence-based anomalies. The stacked LSTM model\nprocessed the sequential data to learn standard driving behaviors.\nAdditionally, we deployed a Random Forest model to support anomaly detection by\noffering ensemble-based predictions, which enhanced model interpretability and\nperformance. The Random Forest model achieved an R2 of 0.9830, MAE of 5.746,\nand a 95th percentile anomaly threshold of 14.18, while the stacked LSTM model\nattained an R2 of 0.9998, MAE of 82.425, and a 95th percentile anomaly\nthreshold of 265.63. These results demonstrate the models' effectiveness in\naccurately predicting vehicle trajectories and detecting anomalies in\nautonomous driving scenarios."}
{"id": "2506.22994", "pdf": "https://arxiv.org/pdf/2506.22994", "abs": "https://arxiv.org/abs/2506.22994", "authors": ["Can Hakan Dağıdır", "Mia Hubert", "Peter J. Rousseeuw"], "title": "Kernel Outlier Detection", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "A new anomaly detection method called kernel outlier detection (KOD) is\nproposed. It is designed to address challenges of outlier detection in\nhigh-dimensional settings. The aim is to overcome limitations of existing\nmethods, such as dependence on distributional assumptions or on hyperparameters\nthat are hard to tune. KOD starts with a kernel transformation, followed by a\nprojection pursuit approach. Its novelties include a new ensemble of directions\nto search over, and a new way to combine results of different direction types.\nThis provides a flexible and lightweight approach for outlier detection. Our\nempirical evaluations illustrate the effectiveness of KOD on three small\ndatasets with challenging structures, and on four large benchmark datasets."}
{"id": "2506.22995", "pdf": "https://arxiv.org/pdf/2506.22995", "abs": "https://arxiv.org/abs/2506.22995", "authors": ["Davide Salaorni", "Federico Bianchi", "Francesco Trovò", "Marcello Restelli"], "title": "A Reinforcement Learning Approach for Optimal Control in Microgrids", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": "8 pages, accepted to International Joint Conference on Neural\n  Networks 2025", "summary": "The increasing integration of renewable energy sources (RESs) is transforming\ntraditional power grid networks, which require new approaches for managing\ndecentralized energy production and consumption. Microgrids (MGs) provide a\npromising solution by enabling localized control over energy generation,\nstorage, and distribution. This paper presents a novel reinforcement learning\n(RL)-based methodology for optimizing microgrid energy management.\nSpecifically, we propose an RL agent that learns optimal energy trading and\nstorage policies by leveraging historical data on energy production,\nconsumption, and market prices. A digital twin (DT) is used to simulate the\nenergy storage system dynamics, incorporating degradation factors to ensure a\nrealistic emulation of the analysed setting. Our approach is validated through\nan experimental campaign using real-world data from a power grid located in the\nItalian territory. The results indicate that the proposed RL-based strategy\noutperforms rule-based methods and existing RL benchmarks, offering a robust\nsolution for intelligent microgrid management."}
{"id": "2506.23024", "pdf": "https://arxiv.org/pdf/2506.23024", "abs": "https://arxiv.org/abs/2506.23024", "authors": ["Jerry Liu", "Yasa Baig", "Denise Hui Jean Lee", "Rajat Vadiraj Dwaraknath", "Atri Rudra", "Chris Ré"], "title": "BWLer: Barycentric Weight Layer Elucidates a Precision-Conditioning Tradeoff for PINNs", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA"], "comment": "Workshop for the Theory of AI for Scientific Computing @ COLT 2025\n  (Best Paper). 39 pages, 24 figures", "summary": "Physics-informed neural networks (PINNs) offer a flexible way to solve\npartial differential equations (PDEs) with machine learning, yet they still\nfall well short of the machine-precision accuracy many scientific tasks demand.\nIn this work, we investigate whether the precision ceiling comes from the\nill-conditioning of the PDEs or from the typical multi-layer perceptron (MLP)\narchitecture. We introduce the Barycentric Weight Layer (BWLer), which models\nthe PDE solution through barycentric polynomial interpolation. A BWLer can be\nadded on top of an existing MLP (a BWLer-hat) or replace it completely\n(explicit BWLer), cleanly separating how we represent the solution from how we\ntake derivatives for the PDE loss. Using BWLer, we identify fundamental\nprecision limitations within the MLP: on a simple 1-D interpolation task, even\nMLPs with O(1e5) parameters stall around 1e-8 RMSE -- about eight orders above\nfloat64 machine precision -- before any PDE terms are added. In PDE learning,\nadding a BWLer lifts this ceiling and exposes a tradeoff between achievable\naccuracy and the conditioning of the PDE loss. For linear PDEs we fully\ncharacterize this tradeoff with an explicit error decomposition and navigate it\nduring training with spectral derivatives and preconditioning. Across five\nbenchmark PDEs, adding a BWLer on top of an MLP improves RMSE by up to 30x for\nconvection, 10x for reaction, and 1800x for wave equations while remaining\ncompatible with first-order optimizers. Replacing the MLP entirely lets an\nexplicit BWLer reach near-machine-precision on convection, reaction, and wave\nproblems (up to 10 billion times better than prior results) and match the\nperformance of standard PINNs on stiff Burgers' and irregular-geometry Poisson\nproblems. Together, these findings point to a practical path for combining the\nflexibility of PINNs with the precision of classical spectral solvers."}
{"id": "2506.23025", "pdf": "https://arxiv.org/pdf/2506.23025", "abs": "https://arxiv.org/abs/2506.23025", "authors": ["Tejas Vaidhya", "Ayush Kaushal", "Vineet Jain", "Francis Couture Harpin", "Prashant Shishodia", "Majid Behbahani", "Yuriy Nevmyvaka", "Irina Rish"], "title": "Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) are increasingly used across research and\nindustry applications, yet their inference efficiency remains a significant\nchallenge. As the computational power of modern GPU architectures continuously\nimproves, their memory bandwidth and capacity have not scaled proportionally,\ncreating a critical bottleneck during inference. To address this, we\ninvestigate ternary language models (TriLMs) that employ quantization-aware\ntraining to significantly reduce memory requirements. We first analyze the\nscalability of TriLMs by conducting a scaling law analysis, revealing that\nTriLMs benefit more from increasing training data than from scaling model\nparameters. Based on this observation, we introduce Spectra-1.1, an open suite\nof TriLMs trained on up to 1.2 trillion tokens, demonstrating sustained\nperformance gains at scale. Furthermore, to improve inference efficiency, we\npropose novel 2-bit and 1.6-bit packing schemes for ternary weights, which\ndemonstrate accelerated inference across various CPU architectures. Also,\nbuilding on the 2-bit packing, we develop a GPU kernel called TriRun that\naccelerates end-to-end model inference by up to 5 times compared to\nfloating-point baselines. To encourage further exploration and development of\nTriLMs, we will release the Spectra-1.1 suite and TriRun inference kernels.\nOverall, our work lays the foundation for building and deploying efficient\nLLMs, providing a valuable resource for the research community."}
{"id": "2506.23033", "pdf": "https://arxiv.org/pdf/2506.23033", "abs": "https://arxiv.org/abs/2506.23033", "authors": ["Yash Vardhan Tomar"], "title": "Feature-Wise Mixing for Mitigating Contextual Bias in Predictive Supervised Learning", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Bias in predictive machine learning (ML) models is a fundamental challenge\ndue to the skewed or unfair outcomes produced by biased models. Existing\nmitigation strategies rely on either post-hoc corrections or rigid constraints.\nHowever, emerging research claims that these techniques can limit scalability\nand reduce generalizability. To address this, this paper introduces a\nfeature-wise mixing framework to mitigate contextual bias. This was done by\nredistributing feature representations across multiple contextual datasets. To\nassess feature-wise mixing's effectiveness, four ML classifiers were trained\nusing cross-validation and evaluated with bias-sensitive loss functions,\nincluding disparity metrics and mean squared error (MSE), which served as a\nstandard measure of predictive performance. The proposed method achieved an\naverage bias reduction of 43.35% and a statistically significant decrease in\nMSE across all classifiers trained on mixed datasets. Additionally,\nbenchmarking against established bias mitigation techniques found that\nfeature-wise mixing consistently outperformed SMOTE oversampling and\ndemonstrated competitive effectiveness without requiring explicit bias\nattribute identification. Feature-wise mixing efficiently avoids the\ncomputational overhead typically associated with fairness-aware learning\nalgorithms. Future work could explore applying feature-wise mixing for\nreal-world fields where accurate predictions are necessary."}
{"id": "2506.23036", "pdf": "https://arxiv.org/pdf/2506.23036", "abs": "https://arxiv.org/abs/2506.23036", "authors": ["Zain ul Abdeen", "Ming Jin"], "title": "Fragile, Robust, and Antifragile: A Perspective from Parameter Responses in Reinforcement Learning Under Stress", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "This paper explores Reinforcement learning (RL) policy robustness by\nsystematically analyzing network parameters under internal and external\nstresses. Inspired by synaptic plasticity in neuroscience, synaptic filtering\nintroduces internal stress by selectively perturbing parameters, while\nadversarial attacks apply external stress through modified agent observations.\nThis dual approach enables the classification of parameters as fragile, robust,\nor antifragile, based on their influence on policy performance in clean and\nadversarial settings. Parameter scores are defined to quantify these\ncharacteristics, and the framework is validated on PPO-trained agents in Mujoco\ncontinuous control environments. The results highlight the presence of\nantifragile parameters that enhance policy performance under stress,\ndemonstrating the potential of targeted filtering techniques to improve RL\npolicy adaptability. These insights provide a foundation for future\nadvancements in the design of robust and antifragile RL systems."}
{"id": "2506.23041", "pdf": "https://arxiv.org/pdf/2506.23041", "abs": "https://arxiv.org/abs/2506.23041", "authors": ["Chengyu Dong", "Huan Gui", "Noveen Sachdeva", "Long Jin", "Ke Yin", "Jingbo Shang", "Lichan Hong", "Ed H. Chi", "Zhe Zhao"], "title": "ReMem: Mutual Information-Aware Fine-tuning of Pretrained Vision Transformers for Effective Knowledge Distillation", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Knowledge distillation from pretrained visual representation models offers an\neffective approach to improve small, task-specific production models. However,\nthe effectiveness of such knowledge transfer drops significantly when\ndistilling from strong models that are pretrained in a large scale. In this\npaper, we address this challenge for pretrained Vision Transformers (ViTs) by\nexploring methods to fine-tune them for more effective knowledge transfer.\nMotivated by the connection between mutual information and distillation\neffectiveness, we propose to employ mutual information-aware optimization\nduring finetuning. For small or highly-imbalanced downstream datasets where\nsuch optimization becomes less effective, we introduce a simple yet effective\nheuristic of reweighting MLP blocks. This approach is inspired by our\nobservation that top MLP blocks are primarily responsible for mutual\ninformation loss. Our method enables small student models to benefit from those\npretrained models among the strongest."}
{"id": "2506.23053", "pdf": "https://arxiv.org/pdf/2506.23053", "abs": "https://arxiv.org/abs/2506.23053", "authors": ["Hanlin Dong", "Arian Prabowo", "Hao Xue", "Flora D. Salim"], "title": "Double-Diffusion: Diffusion Conditioned Diffusion Probabilistic Model For Air Quality Prediction", "categories": ["cs.LG"], "comment": null, "summary": "Air quality prediction is a challenging forecasting task due to its\nspatio-temporal complexity and the inherent dynamics as well as uncertainty.\nMost of the current models handle these two challenges by applying Graph Neural\nNetworks or known physics principles, and quantifying stochasticity through\nprobabilistic networks like Diffusion models. Nevertheless, finding the right\nbalancing point between the certainties and uncertainties remains an open\nquestion. Therefore, we propose Double-Diffusion, a novel diffusion\nprobabilistic model that harnesses the power of known physics to guide air\nquality forecasting with stochasticity. To the best of our knowledge, while\nprecedents have been made of using conditional diffusion models to predict air\npollution, this is the first attempt to use physics as a conditional generative\napproach for air quality prediction. Along with a sampling strategy adopted\nfrom image restoration and a new denoiser architecture, Double-Diffusion ranks\nfirst in most evaluation scenarios across two real-life datasets compared with\nother probabilistic models, it also cuts inference time by 50% to 30% while\nenjoying an increase between 3-12% in Continuous Ranked Probabilistic Score\n(CRPS)."}
{"id": "2506.23055", "pdf": "https://arxiv.org/pdf/2506.23055", "abs": "https://arxiv.org/abs/2506.23055", "authors": ["Hiro Taiyo Hamada", "Ippei Fujisawa", "Genji Kawakita", "Yuki Yamada"], "title": "Measuring How LLMs Internalize Human Psychological Concepts: A preliminary analysis", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) such as ChatGPT have shown remarkable abilities\nin producing human-like text. However, it is unclear how accurately these\nmodels internalize concepts that shape human thought and behavior. Here, we\ndeveloped a quantitative framework to assess concept alignment between LLMs and\nhuman psychological dimensions using 43 standardized psychological\nquestionnaires, selected for their established validity in measuring distinct\npsychological constructs. Our method evaluates how accurately language models\nreconstruct and classify questionnaire items through pairwise similarity\nanalysis. We compared resulting cluster structures with the original\ncategorical labels using hierarchical clustering. A GPT-4 model achieved\nsuperior classification accuracy (66.2\\%), significantly outperforming GPT-3.5\n(55.9\\%) and BERT (48.1\\%), all exceeding random baseline performance (31.9\\%).\nWe also demonstrated that the estimated semantic similarity from GPT-4 is\nassociated with Pearson's correlation coefficients of human responses in\nmultiple psychological questionnaires. This framework provides a novel approach\nto evaluate the alignment of the human-LLM concept and identify potential\nrepresentational biases. Our findings demonstrate that modern LLMs can\napproximate human psychological constructs with measurable accuracy, offering\ninsights for developing more interpretable AI systems."}
{"id": "2506.23068", "pdf": "https://arxiv.org/pdf/2506.23068", "abs": "https://arxiv.org/abs/2506.23068", "authors": ["Zhiyu Zhao", "Haoxuan Li", "Haifeng Zhang", "Jun Wang", "Francesco Faccio", "Jürgen Schmidhuber", "Mengyue Yang"], "title": "Curious Causality-Seeking Agents Learn Meta Causal World", "categories": ["cs.LG", "cs.AI", "stat.AP"], "comment": "33 pages", "summary": "When building a world model, a common assumption is that the environment has\na single, unchanging underlying causal rule, like applying Newton's laws to\nevery situation. In reality, what appears as a drifting causal mechanism is\noften the manifestation of a fixed underlying mechanism seen through a narrow\nobservational window. This brings about a problem that, when building a world\nmodel, even subtle shifts in policy or environment states can alter the very\nobserved causal mechanisms. In this work, we introduce the \\textbf{Meta-Causal\nGraph} as world models, a minimal unified representation that efficiently\nencodes the transformation rules governing how causal structures shift across\ndifferent latent world states. A single Meta-Causal Graph is composed of\nmultiple causal subgraphs, each triggered by meta state, which is in the latent\nstate space. Building on this representation, we introduce a\n\\textbf{Causality-Seeking Agent} whose objectives are to (1) identify the meta\nstates that trigger each subgraph, (2) discover the corresponding causal\nrelationships by agent curiosity-driven intervention policy, and (3)\niteratively refine the Meta-Causal Graph through ongoing curiosity-driven\nexploration and agent experiences. Experiments on both synthetic tasks and a\nchallenging robot arm manipulation task demonstrate that our method robustly\ncaptures shifts in causal dynamics and generalizes effectively to previously\nunseen contexts."}
{"id": "2506.23145", "pdf": "https://arxiv.org/pdf/2506.23145", "abs": "https://arxiv.org/abs/2506.23145", "authors": ["Shahad Hardan", "Darya Taratynova", "Abdelmajid Essofi", "Karthik Nandakumar", "Mohammad Yaqub"], "title": "Forget-MI: Machine Unlearning for Forgetting Multimodal Information in Healthcare Settings", "categories": ["cs.LG", "cs.CR", "cs.CV"], "comment": null, "summary": "Privacy preservation in AI is crucial, especially in healthcare, where models\nrely on sensitive patient data. In the emerging field of machine unlearning,\nexisting methodologies struggle to remove patient data from trained multimodal\narchitectures, which are widely used in healthcare. We propose Forget-MI, a\nnovel machine unlearning method for multimodal medical data, by establishing\nloss functions and perturbation techniques. Our approach unlearns unimodal and\njoint representations of the data requested to be forgotten while preserving\nknowledge from the remaining data and maintaining comparable performance to the\noriginal model. We evaluate our results using performance on the forget\ndataset, performance on the test dataset, and Membership Inference Attack\n(MIA), which measures the attacker's ability to distinguish the forget dataset\nfrom the training dataset. Our model outperforms the existing approaches that\naim to reduce MIA and the performance on the forget dataset while keeping an\nequivalent performance on the test set. Specifically, our approach reduces MIA\nby 0.202 and decreases AUC and F1 scores on the forget set by 0.221 and 0.305,\nrespectively. Additionally, our performance on the test set matches that of the\nretrained model, while allowing forgetting. Code is available at\nhttps://github.com/BioMedIA-MBZUAI/Forget-MI.git"}
{"id": "2506.23147", "pdf": "https://arxiv.org/pdf/2506.23147", "abs": "https://arxiv.org/abs/2506.23147", "authors": ["Jonathan Schuster", "Fabian Transchel"], "title": "maneuverRecognition -- A Python package for Timeseries Classification in the domain of Vehicle Telematics", "categories": ["cs.LG", "cs.CV"], "comment": "6 pages, 2 figures", "summary": "In the domain of vehicle telematics the automated recognition of driving\nmaneuvers is used to classify and evaluate driving behaviour. This not only\nserves as a component to enhance the personalization of insurance policies, but\nalso to increase road safety, reduce accidents and the associated costs as well\nas to reduce fuel consumption and support environmentally friendly driving. In\nthis context maneuver recognition technically requires a continuous application\nof time series classification which poses special challenges to the transfer,\npreprocessing and storage of telematic sensor data, the training of predictive\nmodels, and the prediction itself. Although much research has been done in the\nfield of gathering relevant data or regarding the methods to build predictive\nmodels for the task of maneuver recognition, there is a practical need for\npython packages and functions that allow to quickly transform data into the\nrequired structure as well as to build and evaluate such models. The\nmaneuverRecognition package was therefore developed to provide the necessary\nfunctions for preprocessing, modelling and evaluation and also includes a ready\nto use LSTM based network structure that can be modified. The implementation of\nthe package is demonstrated using real driving data of three different persons\nrecorded via smartphone sensors."}
{"id": "2506.23165", "pdf": "https://arxiv.org/pdf/2506.23165", "abs": "https://arxiv.org/abs/2506.23165", "authors": ["David Bossens", "Atsushi Nitanda"], "title": "Mirror Descent Policy Optimisation for Robust Constrained Markov Decision Processes", "categories": ["cs.LG", "cs.NE"], "comment": null, "summary": "Safety is an essential requirement for reinforcement learning systems. The\nnewly emerging framework of robust constrained Markov decision processes allows\nlearning policies that satisfy long-term constraints while providing guarantees\nunder epistemic uncertainty. This paper presents mirror descent policy\noptimisation for robust constrained Markov decision processes (RCMDPs), making\nuse of policy gradient techniques to optimise both the policy (as a maximiser)\nand the transition kernel (as an adversarial minimiser) on the Lagrangian\nrepresenting a constrained MDP. In the oracle-based RCMDP setting, we obtain an\n$\\mathcal{O}\\left(\\frac{1}{T}\\right)$ convergence rate for the squared distance\nas a Bregman divergence, and an $\\mathcal{O}\\left(e^{-T}\\right)$ convergence\nrate for entropy-regularised objectives. In the sample-based RCMDP setting, we\nobtain an $\\tilde{\\mathcal{O}}\\left(\\frac{1}{T^{1/3}}\\right)$ convergence rate.\nExperiments confirm the benefits of mirror descent policy optimisation in\nconstrained and unconstrained optimisation, and significant improvements are\nobserved in robustness tests when compared to baseline policy optimisation\nalgorithms."}
{"id": "2506.23174", "pdf": "https://arxiv.org/pdf/2506.23174", "abs": "https://arxiv.org/abs/2506.23174", "authors": ["Chen Gong", "Bo Liang", "Wei Gao", "Chenren Xu"], "title": "Data Can Speak for Itself: Quality-guided Utilization of Wireless Synthetic Data", "categories": ["cs.LG", "cs.AI"], "comment": "Published in MobiSys 2025", "summary": "Generative models have gained significant attention for their ability to\nproduce realistic synthetic data that supplements the quantity of real-world\ndatasets. While recent studies show performance improvements in wireless\nsensing tasks by incorporating all synthetic data into training sets, the\nquality of synthetic data remains unpredictable and the resulting performance\ngains are not guaranteed. To address this gap, we propose tractable and\ngeneralizable metrics to quantify quality attributes of synthetic data -\naffinity and diversity. Our assessment reveals prevalent affinity limitation in\ncurrent wireless synthetic data, leading to mislabeled data and degraded task\nperformance. We attribute the quality limitation to generative models' lack of\nawareness of untrained conditions and domain-specific processing. To mitigate\nthese issues, we introduce SynCheck, a quality-guided synthetic data\nutilization scheme that refines synthetic data quality during task model\ntraining. Our evaluation demonstrates that SynCheck consistently outperforms\nquality-oblivious utilization of synthetic data, and achieves 4.3% performance\nimprovement even when the previous utilization degrades performance by 13.4%."}
{"id": "2506.23182", "pdf": "https://arxiv.org/pdf/2506.23182", "abs": "https://arxiv.org/abs/2506.23182", "authors": ["Robert Frank", "Michael Widrich", "Rahmad Akbar", "Günter Klambauer", "Geir Kjetil Sandve", "Philippe A. Robert", "Victor Greiff"], "title": "Attribution assignment for deep-generative sequence models enables interpretability analysis using positive-only data", "categories": ["cs.LG", "q-bio.QM"], "comment": null, "summary": "Generative machine learning models offer a powerful framework for therapeutic\ndesign by efficiently exploring large spaces of biological sequences enriched\nfor desirable properties. Unlike supervised learning methods, which require\nboth positive and negative labeled data, generative models such as LSTMs can be\ntrained solely on positively labeled sequences, for example, high-affinity\nantibodies. This is particularly advantageous in biological settings where\nnegative data are scarce, unreliable, or biologically ill-defined. However, the\nlack of attribution methods for generative models has hindered the ability to\nextract interpretable biological insights from such models. To address this\ngap, we developed Generative Attribution Metric Analysis (GAMA), an attribution\nmethod for autoregressive generative models based on Integrated Gradients. We\nassessed GAMA using synthetic datasets with known ground truths to characterize\nits statistical behavior and validate its ability to recover biologically\nrelevant features. We further demonstrated the utility of GAMA by applying it\nto experimental antibody-antigen binding data. GAMA enables model\ninterpretability and the validation of generative sequence design strategies\nwithout the need for negative training data."}
{"id": "2506.23186", "pdf": "https://arxiv.org/pdf/2506.23186", "abs": "https://arxiv.org/abs/2506.23186", "authors": ["Marco Bressan", "Victor Chepoi", "Emmanuel Esposito", "Maximilian Thiessen"], "title": "Efficient Algorithms for Learning and Compressing Monophonic Halfspaces in Graphs", "categories": ["cs.LG", "cs.DM", "math.CO", "stat.ML"], "comment": null, "summary": "Abstract notions of convexity over the vertices of a graph, and corresponding\nnotions of halfspaces, have recently gained attention from the machine learning\ncommunity. In this work we study monophonic halfspaces, a notion of graph\nhalfspaces defined through closure under induced paths. Our main result is a\n$2$-satisfiability based decomposition theorem, which allows one to represent\nmonophonic halfspaces as a disjoint union of certain vertex subsets. Using this\ndecomposition, we achieve efficient and (nearly) optimal algorithms for various\nlearning problems, such as teaching, active, and online learning. Most notably,\nwe obtain a polynomial-time algorithm for empirical risk minimization.\nIndependently of the decomposition theorem, we obtain an efficient, stable, and\nproper sample compression scheme. This makes monophonic halfspaces efficiently\nlearnable with proper learners and linear error rate $1/\\varepsilon$ in the\nrealizable PAC setting. Our results answer open questions from the literature,\nand show a stark contrast with geodesic halfspaces, for which most of the said\nlearning problems are NP-hard."}
{"id": "2506.23201", "pdf": "https://arxiv.org/pdf/2506.23201", "abs": "https://arxiv.org/abs/2506.23201", "authors": ["Haoran Li", "Muhao Guo", "Marija Ilic", "Yang Weng", "Guangchun Ruan"], "title": "External Data-Enhanced Meta-Representation for Adaptive Probabilistic Load Forecasting", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": "10 pages", "summary": "Accurate residential load forecasting is critical for power system\nreliability with rising renewable integration and demand-side flexibility.\nHowever, most statistical and machine learning models treat external factors,\nsuch as weather, calendar effects, and pricing, as extra input, ignoring their\nheterogeneity, and thus limiting the extraction of useful external information.\nWe propose a paradigm shift: external data should serve as meta-knowledge to\ndynamically adapt the forecasting model itself. Based on this idea, we design a\nmeta-representation framework using hypernetworks that modulate selected\nparameters of a base Deep Learning (DL) model in response to external\nconditions. This provides both expressivity and adaptability. We further\nintegrate a Mixture-of-Experts (MoE) mechanism to enhance efficiency through\nselective expert activation, while improving robustness by filtering redundant\nexternal inputs. The resulting model, dubbed as a Meta Mixture of Experts for\nExternal data (M2oE2), achieves substantial improvements in accuracy and\nrobustness with limited additional overhead, outperforming existing\nstate-of-the-art methods in diverse load datasets. The dataset and source code\nare publicly available at\nhttps://github.com/haorandd/M2oE2\\_load\\_forecast.git."}
{"id": "2506.23210", "pdf": "https://arxiv.org/pdf/2506.23210", "abs": "https://arxiv.org/abs/2506.23210", "authors": ["Taehwan Yoon", "Bongjun Choi"], "title": "FedRef: Communication-Efficient Bayesian Fine Tuning with Reference Model", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": "6 pages,14 equation", "summary": "Federated learning(FL) is used for distributed scenarios to train artificial\nintelligence(AI) models while ensuring users' privacy. In federated learning\nscenario, the server generally never knows about users' data. This type of\nconcept makes the AI training process efficient in terms of data privacy.\nHowever, regarding model performance, federated AI models may not sufficiently\nsatisfy AI users' expectations. Furthermore, AI users have a wide range of\ndifferent needs. It is not easy to satisfy the whole users needs. These types\nof issues can be addressed through AI model optimization, fine-tuning, or\npersonalization to achieve optimal model performance. To address model\noptimization challenges, we propose reference model-based federated learning\nfor optimal fine-tuning, which overcomes catastrophic forgetting in each round.\nThis method is derived from Bayesian parameter-efficient transfer learning,\nwhich includes an optimal proximal term and enables overcoming the catastrophic\nforgetting issue in each round by utilizing a reference model that incorporates\nprevious model parameters. As a result, this method achieves both high model\nperformance and low computing cost."}
{"id": "2506.23221", "pdf": "https://arxiv.org/pdf/2506.23221", "abs": "https://arxiv.org/abs/2506.23221", "authors": ["Bálint Horváth", "Balázs Csanád Csáji"], "title": "Single Image Inpainting and Super-Resolution with Simultaneous Uncertainty Guarantees by Universal Reproducing Kernels", "categories": ["cs.LG", "cs.CV"], "comment": "23 pages, 8 figures, 6 tables", "summary": "The paper proposes a statistical learning approach to the problem of\nestimating missing pixels of images, crucial for image inpainting and\nsuper-resolution problems. One of the main novelties of the method is that it\nalso provides uncertainty quantifications together with the estimated values.\nOur core assumption is that the underlying data-generating function comes from\na Reproducing Kernel Hilbert Space (RKHS). A special emphasis is put on\nband-limited functions, central to signal processing, which form Paley-Wiener\ntype RKHSs. The proposed method, which we call Simultaneously Guaranteed Kernel\nInterpolation (SGKI), is an extension and refinement of a recently developed\nkernel method. An advantage of SGKI is that it not only estimates the missing\npixels, but also builds non-asymptotic confidence bands for the unobserved\nvalues, which are simultaneously guaranteed for all missing pixels. We also\nshow how to compute these bands efficiently using Schur complements, we discuss\na generalization to vector-valued functions, and we present a series of\nnumerical experiments on various datasets containing synthetically generated\nand benchmark images, as well."}
{"id": "2506.23225", "pdf": "https://arxiv.org/pdf/2506.23225", "abs": "https://arxiv.org/abs/2506.23225", "authors": ["Yukito Tajima", "Nakamasa Inoue", "Yusuke Sekikawa", "Ikuro Sato", "Rio Yokota"], "title": "Masked Gated Linear Unit", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Gated Linear Units (GLUs) have become essential components in the\nfeed-forward networks of state-of-the-art Large Language Models (LLMs).\nHowever, they require twice as many memory reads compared to feed-forward\nlayers without gating, due to the use of separate weight matrices for the gate\nand value streams. To address this bottleneck, we introduce Masked Gated Linear\nUnits (MGLUs), a novel family of GLUs with an efficient kernel implementation.\nThe core contribution of MGLUs include: (1) the Mixture of Element-wise Gating\n(MoEG) architecture that learns multiple binary masks, each determining gate or\nvalue assignments at the element level on a single shared weight matrix\nresulting in reduced memory transfer, and (2) FlashMGLU, a hardware-friendly\nkernel that yields up to a 19.7 $\\times$ inference-time speed-up over a naive\nPyTorch MGLU and is 47% more memory-efficient and 34% faster than standard GLUs\ndespite added architectural complexity on an RTX5090 GPU. In LLM experiments,\nthe Swish-activated variant SwiMGLU preserves its memory advantages while\nmatching - or even surpassing - the downstream accuracy of the SwiGLU baseline."}
{"id": "2506.23266", "pdf": "https://arxiv.org/pdf/2506.23266", "abs": "https://arxiv.org/abs/2506.23266", "authors": ["Lujun Li", "Zhu Qiyuan", "Jiacheng Wang", "Wei Li", "Hao Gu", "Sirui Han", "Yike Guo"], "title": "Sub-MoE: Efficient Mixture-of-Expert LLMs Compression via Subspace Expert Merging", "categories": ["cs.LG"], "comment": "Work in progress, revisions ongoing", "summary": "Mixture of Experts (MoE) LLMs face significant obstacles due to their massive\nparameter scale, which imposes memory, storage, and deployment challenges.\nAlthough recent expert merging methods promise greater efficiency by\nconsolidating multiple experts, they are fundamentally hindered by parameter\nconflicts arising from expert specialization. In this paper, we present\nSub-MoE, a novel MoE compression framework via Subspace Expert Merging. Our key\ninsight is to perform joint Singular Value Decomposition (SVD) on concatenated\nexpert weights, reducing conflicting parameters by extracting shared\n$U$-matrices while enabling effective merging of the expert-specific $V$\ncomponents. Specifically, Sub-MoE consists of two innovative phases: (1)\nAdaptive Expert Clustering, which groups functionally coherent experts via\nK-means clustering based on cosine similarity of expert outputs; and (2)\nSubspace Expert Merging, which first enforces Experts Union Decomposition to\nderive the shared $U$-matrix across experts in the same group, then pursues\nfrequency-based merging for individual $V$-matrices, and finalizes expert\nreconstruction using the merged $V$-matrix. In this way, we align and fuse\nexperts in a shared subspace, and can be extended with intra-expert compression\nfor further inference optimization. Extensive experiments on Mixtral, DeepSeek,\nand Qwen-1.5|3 MoE LLMs demonstrate that our Sub-MoE significantly outperforms\nexisting expert pruning and merging methods. Notably, our Sub-MoE maintains\n96\\%|86\\% of original performance with 25\\%|50\\% expert reduction on\nMixtral-8x7B in zero-shot benchmarks. Code will be released at\nhttps://github.com/lliai/MoERazor."}
{"id": "2506.23274", "pdf": "https://arxiv.org/pdf/2506.23274", "abs": "https://arxiv.org/abs/2506.23274", "authors": ["Hans Peter Lynsgøe Raaschou-jensen", "Constanza Fierro", "Anders Søgaard"], "title": "Predicting thinking time in Reasoning models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reasoning models that produce long, hidden chains of thought have emerged as\npowerful tools for complex, reasoning-intensive\ntasks\\citep{deepseekai2025deepseekr1incentivizingreasoningcapability,\nopenai2024openaio1card}. However, this paradigm introduces a new user\nexperience challenge: users have little insight into how much time the model\nwill spend reasoning before returning an answer. This unpredictability, can\nlead to user frustration and is likely to compound as LLMs can produce\nincreasingly long tasks asynchronously\n\\citep{kwa2025measuringaiabilitycomplete}. In this paper, we introduce and\nevaluate methods for both online and offline prediction of model \"thinking\ntime,\" aiming to develop a practical \"progress bar for reasoning.\" We discuss\nthe implications for user interaction and future research directions."}
{"id": "2506.23280", "pdf": "https://arxiv.org/pdf/2506.23280", "abs": "https://arxiv.org/abs/2506.23280", "authors": ["Chaoqun Du", "Yulin Wang", "Shiji Song", "Gao Huang"], "title": "BAPE: Learning an Explicit Bayes Classifier for Long-tailed Visual Recognition", "categories": ["cs.LG"], "comment": null, "summary": "Bayesian decision theory advocates the Bayes classifier as the optimal\napproach for minimizing the risk in machine learning problems. Current deep\nlearning algorithms usually solve for the optimal classifier by\n\\emph{implicitly} estimating the posterior probabilities, \\emph{e.g.}, by\nminimizing the Softmax cross-entropy loss. This simple methodology has been\nproven effective for meticulously balanced academic benchmark datasets.\nHowever, it is not applicable to the long-tailed data distributions in the real\nworld, where it leads to the gradient imbalance issue and fails to ensure the\nBayes optimal decision rule. To address these challenges, this paper presents a\nnovel approach (BAPE) that provides a more precise theoretical estimation of\nthe data distributions by \\emph{explicitly} modeling the parameters of the\nposterior probabilities and solving them with point estimation. Consequently,\nour method directly learns the Bayes classifier without gradient descent based\non Bayes' theorem, simultaneously alleviating the gradient imbalance and\nensuring the Bayes optimal decision rule. Furthermore, we propose a\nstraightforward yet effective \\emph{distribution adjustment} technique. This\nmethod enables the Bayes classifier trained from the long-tailed training set\nto effectively adapt to the test data distribution with an arbitrary imbalance\nfactor, thereby enhancing performance without incurring additional\ncomputational costs. In addition, we demonstrate the gains of our method are\northogonal to existing learning approaches for long-tailed scenarios, as they\nare mostly designed under the principle of \\emph{implicitly} estimating the\nposterior probabilities. Extensive empirical evaluations on CIFAR-10-LT,\nCIFAR-100-LT, ImageNet-LT, and iNaturalist demonstrate that our method\nsignificantly improves the generalization performance of popular deep networks,\ndespite its simplicity."}
{"id": "2506.23286", "pdf": "https://arxiv.org/pdf/2506.23286", "abs": "https://arxiv.org/abs/2506.23286", "authors": ["Alan Jeffares", "Mihaela van der Schaar"], "title": "Not All Explanations for Deep Learning Phenomena Are Equally Valuable", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Accepted at ICML 2025 for oral presentation", "summary": "Developing a better understanding of surprising or counterintuitive phenomena\nhas constituted a significant portion of deep learning research in recent\nyears. These include double descent, grokking, and the lottery ticket\nhypothesis -- among many others. Works in this area often develop ad hoc\nhypotheses attempting to explain these observed phenomena on an isolated,\ncase-by-case basis. This position paper asserts that, in many prominent cases,\nthere is little evidence to suggest that these phenomena appear in real-world\napplications and these efforts may be inefficient in driving progress in the\nbroader field. Consequently, we argue against viewing them as isolated puzzles\nthat require bespoke resolutions or explanations. However, despite this, we\nsuggest that deep learning phenomena do still offer research value by providing\nunique settings in which we can refine our broad explanatory theories of more\ngeneral deep learning principles. This position is reinforced by analyzing the\nresearch outcomes of several prominent examples of these phenomena from the\nrecent literature. We revisit the current norms in the research community in\napproaching these problems and propose practical recommendations for future\nresearch, aiming to ensure that progress on deep learning phenomena is well\naligned with the ultimate pragmatic goal of progress in the broader field of\ndeep learning."}
{"id": "2506.23287", "pdf": "https://arxiv.org/pdf/2506.23287", "abs": "https://arxiv.org/abs/2506.23287", "authors": ["Zelin Zang", "WenZhe Li", "Fei Chen", "Yongjie Xu", "Chang Yu", "Zhen Lei", "Stan Z. Li"], "title": "Hierarchical Quantized Diffusion Based Tree Generation Method for Hierarchical Representation and Lineage Analysis", "categories": ["cs.LG", "q-bio.QM"], "comment": "9 pages, 6 figures, under review", "summary": "In single-cell research, tracing and analyzing high-throughput single-cell\ndifferentiation trajectories is crucial for understanding complex biological\nprocesses. Key to this is the modeling and generation of hierarchical data that\nrepresents the intrinsic structure within datasets. Traditional methods face\nlimitations in terms of computational cost, performance, generative capacity,\nand stability. Recent VAEs based approaches have made strides in addressing\nthese challenges but still require specialized network modules for each tree\nbranch, limiting their stability and ability to capture deep hierarchical\nrelationships. To overcome these challenges, we introduce diffusion-based\napproach called HDTree. HDTree captures tree relationships within a\nhierarchical latent space using a unified hierarchical codebook and quantized\ndiffusion processes to model tree node transitions. This method improves\nstability by eliminating branch-specific modules and enhancing generative\ncapacity through gradual hierarchical changes simulated by the diffusion\nprocess. HDTree's effectiveness is demonstrated through comparisons on both\ngeneral-purpose and single-cell datasets, where it outperforms existing methods\nin terms of accuracy and performance. These contributions provide a new tool\nfor hierarchical lineage analysis, enabling more accurate and efficient\nmodeling of cellular differentiation paths and offering insights for downstream\nbiological tasks. The code of HDTree is available at anonymous link\nhttps://anonymous.4open.science/r/code_HDTree_review-A8DB."}
{"id": "2506.23339", "pdf": "https://arxiv.org/pdf/2506.23339", "abs": "https://arxiv.org/abs/2506.23339", "authors": ["Malikussaid", "Hilal Hudan Nuha"], "title": "VALID-Mol: a Systematic Framework for Validated LLM-Assisted Molecular Design", "categories": ["cs.LG", "cs.AI", "physics.chem-ph", "q-bio.QM"], "comment": "16 pages, 1 figure, 5 algorithms, 7 tables, to be published in ICSECS\n  Conference 2025, unabridged version", "summary": "Large Language Models (LLMs) demonstrate remarkable potential for scientific\ndiscovery, but their application in domains requiring factual accuracy and\ndomain-specific constraints remains challenging. In molecular design for drug\ndiscovery, LLMs can suggest creative molecular modifications but often produce\nchemically invalid or impractical structures. We present VALID-Mol, a\nsystematic framework for integrating chemical validation with LLM-driven\nmolecular design that increases the rate of generating valid chemical\nstructures from 3% to 83%. Our approach combines methodical prompt engineering,\nautomated chemical validation, and a fine-tuned domain-adapted LLM to ensure\nreliable generation of synthesizable molecules with improved properties. Beyond\nthe specific implementation, we contribute a generalizable methodology for\nscientifically-constrained LLM applications, with quantifiable reliability\nimprovements. Computational predictions suggest our framework can generate\npromising candidates for synthesis with up to 17-fold computationally predicted\nimprovements in target affinity while maintaining synthetic accessibility. We\nprovide a detailed analysis of our prompt engineering process, validation\narchitecture, and fine-tuning approach, offering a reproducible blueprint for\napplying LLMs to other scientific domains where domain-specific validation is\nessential."}
{"id": "2506.23349", "pdf": "https://arxiv.org/pdf/2506.23349", "abs": "https://arxiv.org/abs/2506.23349", "authors": ["Keziah Naggita", "Julienne LaChance"], "title": "A case for data valuation transparency via DValCards", "categories": ["cs.LG"], "comment": null, "summary": "Following the rise in popularity of data-centric machine learning (ML),\nvarious data valuation methods have been proposed to quantify the contribution\nof each datapoint to desired ML model performance metrics (e.g., accuracy).\nBeyond the technical applications of data valuation methods (e.g., data\ncleaning, data acquisition, etc.), it has been suggested that within the\ncontext of data markets, data buyers might utilize such methods to fairly\ncompensate data owners. Here we demonstrate that data valuation metrics are\ninherently biased and unstable under simple algorithmic design choices,\nresulting in both technical and ethical implications. By analyzing 9 tabular\nclassification datasets and 6 data valuation methods, we illustrate how (1)\ncommon and inexpensive data pre-processing techniques can drastically alter\nestimated data values; (2) subsampling via data valuation metrics may increase\nclass imbalance; and (3) data valuation metrics may undervalue underrepresented\ngroup data. Consequently, we argue in favor of increased transparency\nassociated with data valuation in-the-wild and introduce the novel Data\nValuation Cards (DValCards) framework towards this aim. The proliferation of\nDValCards will reduce misuse of data valuation metrics, including in data\npricing, and build trust in responsible ML systems."}
{"id": "2506.23358", "pdf": "https://arxiv.org/pdf/2506.23358", "abs": "https://arxiv.org/abs/2506.23358", "authors": ["Pawel Renc", "Michal K. Grzeszczyk", "Linglong Qian", "Nassim Oufattole", "Jeff Rasley", "Arkadiusz Sitek"], "title": "Federated Timeline Synthesis: Scalable and Private Methodology For Model Training and Deployment", "categories": ["cs.LG", "cs.AI"], "comment": "conference paper", "summary": "We present Federated Timeline Synthesis (FTS), a novel framework for training\ngenerative foundation models across distributed timeseries data applied to\nelectronic health records (EHR). At its core, FTS represents patient history as\ntokenized Patient Health Timelines (PHTs), language-agnostic sequences encoding\ntemporal, categorical, and continuous clinical information. Each institution\ntrains an autoregressive transformer on its local PHTs and transmits only model\nweights to a central server. The server uses the generators to synthesize a\nlarge corpus of trajectories and train a Global Generator (GG), enabling\nzero-shot inference via Monte Carlo simulation of future PHTs. We evaluate FTS\non five clinically meaningful prediction tasks using MIMIC-IV data, showing\nthat models trained on synthetic data generated by GG perform comparably to\nthose trained on real data. FTS offers strong privacy guarantees, scalability\nacross institutions, and extensibility to diverse prediction and simulation\ntasks especially in healthcare, including counterfactual inference, early\nwarning detection, and synthetic trial design."}
{"id": "2506.23374", "pdf": "https://arxiv.org/pdf/2506.23374", "abs": "https://arxiv.org/abs/2506.23374", "authors": ["Dominik Meier", "Sujai Hiremath", "Promit Ghosal", "Kyra Gan"], "title": "When Additive Noise Meets Unobserved Mediators: Bivariate Denoising Diffusion for Causal Discovery", "categories": ["cs.LG"], "comment": null, "summary": "Distinguishing cause and effect from bivariate observational data is a\nfoundational problem in many disciplines, but challenging without additional\nassumptions. Additive noise models (ANMs) are widely used to enable\nsample-efficient bivariate causal discovery. However, conventional ANM-based\nmethods fail when unobserved mediators corrupt the causal relationship between\nvariables. This paper makes three key contributions: first, we rigorously\ncharacterize why standard ANM approaches break down in the presence of\nunmeasured mediators. Second, we demonstrate that prior solutions for hidden\nmediation are brittle in finite sample settings, limiting their practical\nutility. To address these gaps, we propose Bivariate Denoising Diffusion (BiDD)\nfor causal discovery, a method designed to handle latent noise introduced by\nunmeasured mediators. Unlike prior methods that infer directionality through\nmean squared error loss comparisons, our approach introduces a novel\nindependence test statistic: during the noising and denoising processes for\neach variable, we condition on the other variable as input and evaluate the\nindependence of the predicted noise relative to this input. We prove asymptotic\nconsistency of BiDD under the ANM, and conjecture that it performs well under\nhidden mediation. Experiments on synthetic and real-world data demonstrate\nconsistent performance, outperforming existing methods in mediator-corrupted\nsettings while maintaining strong performance in mediator-free settings."}
{"id": "2506.23408", "pdf": "https://arxiv.org/pdf/2506.23408", "abs": "https://arxiv.org/abs/2506.23408", "authors": ["Claudionor Coelho Jr", "Yanen Li", "Philip Tee"], "title": "Do LLMs Dream of Discrete Algorithms?", "categories": ["cs.LG", "cs.LO"], "comment": null, "summary": "Large Language Models (LLMs) have rapidly transformed the landscape of\nartificial intelligence, enabling natural language interfaces and dynamic\norchestration of software components. However, their reliance on probabilistic\ninference limits their effectiveness in domains requiring strict logical\nreasoning, discrete decision-making, and robust interpretability. This paper\ninvestigates these limitations and proposes a neurosymbolic approach that\naugments LLMs with logic-based reasoning modules, particularly leveraging\nProlog predicates and composable toolsets. By integrating first-order logic and\nexplicit rule systems, our framework enables LLMs to decompose complex queries\ninto verifiable sub-tasks, orchestrate reliable solutions, and mitigate common\nfailure modes such as hallucination and incorrect step decomposition. We\ndemonstrate the practical benefits of this hybrid architecture through\nexperiments on the DABStep benchmark, showing improved precision, coverage, and\nsystem documentation in multi-step reasoning tasks. Our results indicate that\ncombining LLMs with modular logic reasoning restores engineering rigor,\nenhances system reliability, and offers a scalable path toward trustworthy,\ninterpretable AI agents across complex domains."}
{"id": "2506.23419", "pdf": "https://arxiv.org/pdf/2506.23419", "abs": "https://arxiv.org/abs/2506.23419", "authors": ["Amanda S Barnard"], "title": "BenchMake: Turn any scientific data set into a reproducible benchmark", "categories": ["cs.LG", "cs.AI", "cs.DL", "62G09", "J.1"], "comment": "10 pages, 15 pages in Appendix, 15 figures, 5 tables, 57 references", "summary": "Benchmark data sets are a cornerstone of machine learning development and\napplications, ensuring new methods are robust, reliable and competitive. The\nrelative rarity of benchmark sets in computational science, due to the\nuniqueness of the problems and the pace of change in the associated domains,\nmakes evaluating new innovations difficult for computational scientists. In\nthis paper a new tool is developed and tested to potentially turn any of the\nincreasing numbers of scientific data sets made openly available into a\nbenchmark accessible to the community. BenchMake uses non-negative matrix\nfactorisation to deterministically identify and isolate challenging edge cases\non the convex hull (the smallest convex set that contains all existing data\ninstances) and partitions a required fraction of matched data instances into a\ntesting set that maximises divergence and statistical significance, across\ntabular, graph, image, signal and textual modalities. BenchMake splits are\ncompared to establish splits and random splits using ten publicly available\nbenchmark sets from different areas of science, with different sizes, shapes,\ndistributions."}
{"id": "2506.23424", "pdf": "https://arxiv.org/pdf/2506.23424", "abs": "https://arxiv.org/abs/2506.23424", "authors": ["Heitor R. Medeiros", "Hossein Sharifi-Noghabi", "Gabriel L. Oliveira", "Saghar Irandoust"], "title": "Accurate Parameter-Efficient Test-Time Adaptation for Time Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": "Second Workshop on Test-Time Adaptation: Putting Updates to the Test!\n  at ICML 2025, Vancouver, Canada. 2025", "summary": "Real-world time series often exhibit a non-stationary nature, degrading the\nperformance of pre-trained forecasting models. Test-Time Adaptation (TTA)\naddresses this by adjusting models during inference, but existing methods\ntypically update the full model, increasing memory and compute costs. We\npropose PETSA, a parameter-efficient method that adapts forecasters at test\ntime by only updating small calibration modules on the input and output. PETSA\nuses low-rank adapters and dynamic gating to adjust representations without\nretraining. To maintain accuracy despite limited adaptation capacity, we\nintroduce a specialized loss combining three components: (1) a robust term, (2)\na frequency-domain term to preserve periodicity, and (3) a patch-wise\nstructural term for structural alignment. PETSA improves the adaptability of\nvarious forecasting backbones while requiring fewer parameters than baselines.\nExperimental results on benchmark datasets show that PETSA achieves competitive\nor better performance across all horizons. Our code is available at:\nhttps://github.com/BorealisAI/PETSA"}
{"id": "2506.23446", "pdf": "https://arxiv.org/pdf/2506.23446", "abs": "https://arxiv.org/abs/2506.23446", "authors": ["Mohamed Elbasheer", "Adewale Akinfaderin"], "title": "Enhancing Insider Threat Detection Using User-Based Sequencing and Transformer Encoders", "categories": ["cs.LG"], "comment": null, "summary": "Insider threat detection presents unique challenges due to the authorized\nstatus of malicious actors and the subtlety of anomalous behaviors. Existing\nmachine learning methods often treat user activity as isolated events, thereby\nfailing to leverage sequential dependencies in user behavior. In this study, we\npropose a User-Based Sequencing (UBS) methodology, transforming the CERT\ninsider threat dataset into structured temporal sequences suitable for deep\nsequential modeling. We deploy a Transformer Encoder architecture to model\nbenign user activity and employ its reconstruction errors as anomaly scores.\nThese scores are subsequently evaluated using three unsupervised outlier\ndetection algorithms: One-Class SVM (OCSVM), Local Outlier Factor (LOF), and\nIsolation Forest (iForest). Across four rigorously designed test sets,\nincluding combinations of multiple CERT dataset releases, our UBS-Transformer\npipeline consistently achieves state-of-the-art performance - notably 96.61%\naccuracy, 99.43% recall, 96.38% F1-score, 95.00% AUROC, and exceptionally low\nfalse negative (0.0057) and false positive (0.0571) rates. Comparative analyses\ndemonstrate that our approach substantially outperforms tabular and\nconventional autoencoder baselines, underscoring the efficacy of sequential\nuser modeling and advanced anomaly detection in the insider threat domain."}
{"id": "2506.23462", "pdf": "https://arxiv.org/pdf/2506.23462", "abs": "https://arxiv.org/abs/2506.23462", "authors": ["Manaswi Kulahara", "Gautam Siddharth Kashyap", "Nipun Joshi", "Arpita Soni"], "title": "Can We Predict the Unpredictable? Leveraging DisasterNet-LLM for Multimodal Disaster Classification", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted in the 2025 IEEE International Geoscience and Remote Sensing\n  Symposium (IGARSS 2025), scheduled for 3 - 8 August 2025 in Brisbane,\n  Australia", "summary": "Effective disaster management requires timely and accurate insights, yet\ntraditional methods struggle to integrate multimodal data such as images,\nweather records, and textual reports. To address this, we propose\nDisasterNet-LLM, a specialized Large Language Model (LLM) designed for\ncomprehensive disaster analysis. By leveraging advanced pretraining,\ncross-modal attention mechanisms, and adaptive transformers, DisasterNet-LLM\nexcels in disaster classification. Experimental results demonstrate its\nsuperiority over state-of-the-art models, achieving higher accuracy of 89.5%,\nan F1 score of 88.0%, AUC of 0.92%, and BERTScore of 0.88% in multimodal\ndisaster classification tasks."}
{"id": "2506.23469", "pdf": "https://arxiv.org/pdf/2506.23469", "abs": "https://arxiv.org/abs/2506.23469", "authors": ["Chunjing Xiao", "Jiahui Lu", "Xovee Xu", "Fan Zhou", "Tianshu Xie", "Wei Lu", "Lifeng Xu"], "title": "Reconciling Attribute and Structural Anomalies for Improved Graph Anomaly Detection", "categories": ["cs.LG", "cs.SI"], "comment": "Accepted by IEEE Transactions on Neural Networks and Learning Systems\n  (TNNLS); DOI: https://doi.org/10.1109/TNNLS.2025.3561172", "summary": "Graph anomaly detection is critical in domains such as healthcare and\neconomics, where identifying deviations can prevent substantial losses.\nExisting unsupervised approaches strive to learn a single model capable of\ndetecting both attribute and structural anomalies. However, they confront the\ntug-of-war problem between two distinct types of anomalies, resulting in\nsuboptimal performance. This work presents TripleAD, a mutual\ndistillation-based triple-channel graph anomaly detection framework. It\nincludes three estimation modules to identify the attribute, structural, and\nmixed anomalies while mitigating the interference between different types of\nanomalies. In the first channel, we design a multiscale attribute estimation\nmodule to capture extensive node interactions and ameliorate the over-smoothing\nissue. To better identify structural anomalies, we introduce a link-enhanced\nstructure estimation module in the second channel that facilitates information\nflow to topologically isolated nodes. The third channel is powered by an\nattribute-mixed curvature, a new indicator that encapsulates both attribute and\nstructural information for discriminating mixed anomalies. Moreover, a mutual\ndistillation strategy is introduced to encourage communication and\ncollaboration between the three channels. Extensive experiments demonstrate the\neffectiveness of the proposed TripleAD model against strong baselines."}
{"id": "2506.23492", "pdf": "https://arxiv.org/pdf/2506.23492", "abs": "https://arxiv.org/abs/2506.23492", "authors": ["Haolan Guo", "Linwei Tao", "Haoyang Luo", "Minjing Dong", "Chang Xu"], "title": "Sample Margin-Aware Recalibration of Temperature Scaling", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Recent advances in deep learning have significantly improved predictive\naccuracy. However, modern neural networks remain systematically overconfident,\nposing risks for deployment in safety-critical scenarios. Current post-hoc\ncalibration methods face a fundamental dilemma: global approaches like\nTemperature Scaling apply uniform adjustments across all samples, introducing\nhigh bias despite computational efficiency, while more expressive methods that\noperate on full logit distributions suffer from high variance due to noisy\nhigh-dimensional inputs and insufficient validation data. To address these\nchallenges, we propose Sample Margin-Aware Recalibration of Temperature\n(SMART), a lightweight, data-efficient recalibration method that precisely\nscales logits based on the margin between the top two logits -- termed the\nlogit gap. Specifically, the logit gap serves as a denoised, scalar signal\ndirectly tied to decision boundary uncertainty, providing a robust indicator\nthat avoids the noise inherent in high-dimensional logit spaces while\npreserving model prediction invariance. Meanwhile, SMART employs a novel\nsoft-binned Expected Calibration Error (SoftECE) objective that balances model\nbias and variance through adaptive binning, enabling stable parameter updates\neven with extremely limited calibration data. Extensive evaluations across\ndiverse datasets and architectures demonstrate that SMART achieves\nstate-of-the-art calibration performance even with substantially fewer\nparameters compared to existing parametric methods, offering a principled,\nrobust, and highly efficient solution for practical uncertainty quantification\nin neural network predictions. The source code is available at:\nhttps://anonymous.4open.science/r/SMART-8B11."}
{"id": "2506.23516", "pdf": "https://arxiv.org/pdf/2506.23516", "abs": "https://arxiv.org/abs/2506.23516", "authors": ["Seung-Wook Kim", "Seongyeol Kim", "Jiah Kim", "Seowon Ji", "Se-Ho Lee"], "title": "FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Federated learning (FL) often suffers from performance degradation due to key\nchallenges such as data heterogeneity and communication constraints. To address\nthese limitations, we present a novel FL framework called FedWSQ, which\nintegrates weight standardization (WS) and the proposed distribution-aware\nnon-uniform quantization (DANUQ). WS enhances FL performance by filtering out\nbiased components in local updates during training, thereby improving the\nrobustness of the model against data heterogeneity and unstable client\nparticipation. In addition, DANUQ minimizes quantization errors by leveraging\nthe statistical properties of local model updates. As a result, FedWSQ\nsignificantly reduces communication overhead while maintaining superior model\naccuracy. Extensive experiments on FL benchmark datasets demonstrate that\nFedWSQ consistently outperforms existing FL methods across various challenging\nFL settings, including extreme data heterogeneity and ultra-low-bit\ncommunication scenarios."}
{"id": "2506.23544", "pdf": "https://arxiv.org/pdf/2506.23544", "abs": "https://arxiv.org/abs/2506.23544", "authors": ["Kento Imaizumi", "Hideaki Iiduka"], "title": "Both Asymptotic and Non-Asymptotic Convergence of Quasi-Hyperbolic Momentum using Increasing Batch Size", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Momentum methods were originally introduced for their superiority to\nstochastic gradient descent (SGD) in deterministic settings with convex\nobjective functions. However, despite their widespread application to deep\nneural networks -- a representative case of stochastic nonconvex optimization\n-- the theoretical justification for their effectiveness in such settings\nremains limited. Quasi-hyperbolic momentum (QHM) is an algorithm that\ngeneralizes various momentum methods and has been studied to better understand\nthe class of momentum-based algorithms as a whole. In this paper, we provide\nboth asymptotic and non-asymptotic convergence results for mini-batch QHM with\nan increasing batch size. We show that achieving asymptotic convergence\nrequires either a decaying learning rate or an increasing batch size. Since a\ndecaying learning rate adversely affects non-asymptotic convergence, we\ndemonstrate that using mini-batch QHM with an increasing batch size -- without\ndecaying the learning rate -- can be a more effective strategy. Our experiments\nshow that even a finite increase in batch size can provide benefits for\ntraining neural networks."}
{"id": "2506.23551", "pdf": "https://arxiv.org/pdf/2506.23551", "abs": "https://arxiv.org/abs/2506.23551", "authors": ["Jingpu Cheng", "Qianxiao Li", "Ting Lin", "Zuowei Shen"], "title": "A unified framework on the universal approximation of transformer-type architectures", "categories": ["cs.LG"], "comment": null, "summary": "We investigate the universal approximation property (UAP) of transformer-type\narchitectures, providing a unified theoretical framework that extends prior\nresults on residual networks to models incorporating attention mechanisms. Our\nwork identifies token distinguishability as a fundamental requirement for UAP\nand introduces a general sufficient condition that applies to a broad class of\narchitectures. Leveraging an analyticity assumption on the attention layer, we\ncan significantly simplify the verification of this condition, providing a\nnon-constructive approach in establishing UAP for such architectures. We\ndemonstrate the applicability of our framework by proving UAP for transformers\nwith various attention mechanisms, including kernel-based and sparse attention\nmechanisms. The corollaries of our results either generalize prior works or\nestablish UAP for architectures not previously covered. Furthermore, our\nframework offers a principled foundation for designing novel transformer\narchitectures with inherent UAP guarantees, including those with specific\nfunctional symmetries. We propose examples to illustrate these insights."}
{"id": "2506.23589", "pdf": "https://arxiv.org/pdf/2506.23589", "abs": "https://arxiv.org/abs/2506.23589", "authors": ["Neta Shaul", "Uriel Singer", "Itai Gat", "Yaron Lipman"], "title": "Transition Matching: Scalable and Flexible Generative Modeling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Diffusion and flow matching models have significantly advanced media\ngeneration, yet their design space is well-explored, somewhat limiting further\nimprovements. Concurrently, autoregressive (AR) models, particularly those\ngenerating continuous tokens, have emerged as a promising direction for\nunifying text and media generation. This paper introduces Transition Matching\n(TM), a novel discrete-time, continuous-state generative paradigm that unifies\nand advances both diffusion/flow models and continuous AR generation. TM\ndecomposes complex generation tasks into simpler Markov transitions, allowing\nfor expressive non-deterministic probability transition kernels and arbitrary\nnon-continuous supervision processes, thereby unlocking new flexible design\navenues. We explore these choices through three TM variants: (i) Difference\nTransition Matching (DTM), which generalizes flow matching to discrete-time by\ndirectly learning transition probabilities, yielding state-of-the-art image\nquality and text adherence as well as improved sampling efficiency. (ii)\nAutoregressive Transition Matching (ARTM) and (iii) Full History Transition\nMatching (FHTM) are partially and fully causal models, respectively, that\ngeneralize continuous AR methods. They achieve continuous causal AR generation\nquality comparable to non-causal approaches and potentially enable seamless\nintegration with existing AR text generation techniques. Notably, FHTM is the\nfirst fully causal model to match or surpass the performance of flow-based\nmethods on text-to-image task in continuous domains. We demonstrate these\ncontributions through a rigorous large-scale comparison of TM variants and\nrelevant baselines, maintaining a fixed architecture, training data, and\nhyperparameters."}
{"id": "2506.23596", "pdf": "https://arxiv.org/pdf/2506.23596", "abs": "https://arxiv.org/abs/2506.23596", "authors": ["Min-Yeong Park", "Won-Jeong Lee", "Seong Tae Kim", "Gyeong-Moon Park"], "title": "When Will It Fail?: Anomaly to Prompt for Forecasting Future Anomalies in Time Series", "categories": ["cs.LG", "cs.AI"], "comment": "18 pages, 10 figures, 12 tables, ICML 2025", "summary": "Recently, forecasting future abnormal events has emerged as an important\nscenario to tackle real-world necessities. However, the solution of predicting\nspecific future time points when anomalies will occur, known as Anomaly\nPrediction (AP), remains under-explored. Existing methods dealing with time\nseries data fail in AP, focusing only on immediate anomalies or failing to\nprovide precise predictions for future anomalies. To address the AP task, we\npropose a novel framework called Anomaly to Prompt (A2P), comprised of\nAnomaly-Aware Forecasting (AAF) and Synthetic Anomaly Prompting (SAP). To\nenable the forecasting model to forecast abnormal time points, we adopt a\nstrategy to learn the relationships of anomalies. For the robust detection of\nanomalies, our proposed SAP introduces a learnable Anomaly Prompt Pool (APP)\nthat simulates diverse anomaly patterns using signal adaptive prompt.\nComprehensive experiments on multiple real-world datasets demonstrate the\nsuperiority of A2P over state-of-the-art methods, showcasing its ability to\npredict future anomalies. Our implementation code is available at\nhttps://github.com/KU-VGI/AP."}
{"id": "2506.23629", "pdf": "https://arxiv.org/pdf/2506.23629", "abs": "https://arxiv.org/abs/2506.23629", "authors": ["Xin Liao", "Bing Yang", "Cai Yu"], "title": "A Nonlinear Low-rank Representation Model with Convolutional Neural Network for Imputing Water Quality Data", "categories": ["cs.LG", "cs.AI", "68T07(Primary) 62M10, 65C60 (Secondary)", "I.2.7"], "comment": "7 pages, 2 figures, conference", "summary": "The integrity of Water Quality Data (WQD) is critical in environmental\nmonitoring for scientific decision-making and ecological protection. However,\nwater quality monitoring systems are often challenged by large amounts of\nmissing data due to unavoidable problems such as sensor failures and\ncommunication delays, which further lead to water quality data becoming\nHigh-Dimensional and Sparse (HDS). Traditional data imputation methods are\ndifficult to depict the potential dynamics and fail to capture the deep data\nfeatures, resulting in unsatisfactory imputation performance. To effectively\naddress the above issues, this paper proposes a Nonlinear Low-rank\nRepresentation model (NLR) with Convolutional Neural Networks (CNN) for\nimputing missing WQD, which utilizes CNNs to implement two ideas: a) fusing\ntemporal features to model the temporal dependence of data between time slots,\nand b) Extracting nonlinear interactions and local patterns to mine\nhigher-order relationships features and achieve deep fusion of multidimensional\ninformation. Experimental studies on three real water quality datasets\ndemonstrate that the proposed model significantly outperforms existing\nstate-of-the-art data imputation models in terms of estimation accuracy. It\nprovides an effective approach for handling water quality monitoring data in\ncomplex dynamic environments."}
{"id": "2506.23679", "pdf": "https://arxiv.org/pdf/2506.23679", "abs": "https://arxiv.org/abs/2506.23679", "authors": ["David Demitri Africa", "Sara M. Kapoor", "Theo Simon Sorg"], "title": "Learning Modular Exponentiation with Transformers", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Modular exponentiation is crucial to number theory and cryptography, yet\nremains largely unexplored from a mechanistic interpretability standpoint. We\ntrain a 4-layer encoder-decoder Transformer model to perform this operation and\ninvestigate the emergence of numerical reasoning during training. Utilizing\nprincipled sampling strategies, PCA-based embedding analysis, and activation\npatching, we examine how number-theoretic properties are encoded within the\nmodel. We find that reciprocal operand training leads to strong performance\ngains, with sudden generalization across related moduli. These synchronized\naccuracy surges reflect grokking-like dynamics, suggesting the model\ninternalizes shared arithmetic structure. We also find a subgraph consisting\nentirely of attention heads in the final layer sufficient to achieve full\nperformance on the task of regular exponentiation. These results suggest that\ntransformer models learn modular arithmetic through specialized computational\ncircuits, paving the way for more interpretable and efficient neural approaches\nto modular exponentiation."}
{"id": "2506.23719", "pdf": "https://arxiv.org/pdf/2506.23719", "abs": "https://arxiv.org/abs/2506.23719", "authors": ["Alex Egg", "Martin Iglesias Goyanes", "Friso Kingma", "Andreu Mora", "Leandro von Werra", "Thomas Wolf"], "title": "DABstep: Data Agent Benchmark for Multi-step Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": "13 pages, 5 figures", "summary": "We introduce DABstep, a novel benchmark for evaluating AI agents on realistic\nmulti-step data analysis tasks. DABstep comprises over 450 real-world\nchallenges derived from a financial analytics platform, requiring models to\ncombine code-based data processing with contextual reasoning over heterogeneous\ndocumentation. Each task demands an iterative, multi-step problem-solving\napproach, testing capabilities in data manipulation, cross-referencing multiple\nsources, and precise result reporting. The benchmark provides a factoid-style\nanswer format with automatic correctness checks for objective scoring at scale.\nWe evaluate leading LLM-based agents, revealing a substantial performance gap:\neven the best agent achieves only 14.55% accuracy on the hardest tasks. We\ndetail our benchmark's design, dataset composition, task formulation,\nevaluation protocol, report baseline results and analyze failure modes. DABstep\nis released with a public leaderboard and toolkit to accelerate research in\nautonomous data analysis."}
{"id": "2506.23726", "pdf": "https://arxiv.org/pdf/2506.23726", "abs": "https://arxiv.org/abs/2506.23726", "authors": ["Bartlomiej Sobieski", "Matthew Tivnan", "Yuang Wang", "Siyeop Yoon", "Pengfei Jin", "Dufan Wu", "Quanzheng Li", "Przemyslaw Biecek"], "title": "System-Embedded Diffusion Bridge Models", "categories": ["cs.LG", "cs.AI"], "comment": "Preprint", "summary": "Solving inverse problems -- recovering signals from incomplete or noisy\nmeasurements -- is fundamental in science and engineering. Score-based\ngenerative models (SGMs) have recently emerged as a powerful framework for this\ntask. Two main paradigms have formed: unsupervised approaches that adapt\npretrained generative models to inverse problems, and supervised bridge methods\nthat train stochastic processes conditioned on paired clean and corrupted data.\nWhile the former typically assume knowledge of the measurement model, the\nlatter have largely overlooked this structural information. We introduce System\nembedded Diffusion Bridge Models (SDBs), a new class of supervised bridge\nmethods that explicitly embed the known linear measurement system into the\ncoefficients of a matrix-valued SDE. This principled integration yields\nconsistent improvements across diverse linear inverse problems and demonstrates\nrobust generalization under system misspecification between training and\ndeployment, offering a promising solution to real-world applications."}
{"id": "2506.23731", "pdf": "https://arxiv.org/pdf/2506.23731", "abs": "https://arxiv.org/abs/2506.23731", "authors": ["Michel Meintz", "Jan Dubiński", "Franziska Boenisch", "Adam Dziedzic"], "title": "Radioactive Watermarks in Diffusion and Autoregressive Image Generative Models", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Image generative models have become increasingly popular, but training them\nrequires large datasets that are costly to collect and curate. To circumvent\nthese costs, some parties may exploit existing models by using the generated\nimages as training data for their own models. In general, watermarking is a\nvaluable tool for detecting unauthorized use of generated images. However, when\nthese images are used to train a new model, watermarking can only enable\ndetection if the watermark persists through training and remains identifiable\nin the outputs of the newly trained model - a property known as radioactivity.\nWe analyze the radioactivity of watermarks in images generated by diffusion\nmodels (DMs) and image autoregressive models (IARs). We find that existing\nwatermarking methods for DMs fail to retain radioactivity, as watermarks are\neither erased during encoding into the latent space or lost in the\nnoising-denoising process (during the training in the latent space). Meanwhile,\ndespite IARs having recently surpassed DMs in image generation quality and\nefficiency, no radioactive watermarking methods have been proposed for them. To\novercome this limitation, we propose the first watermarking method tailored for\nIARs and with radioactivity in mind - drawing inspiration from techniques in\nlarge language models (LLMs), which share IARs' autoregressive paradigm. Our\nextensive experimental evaluation highlights our method's effectiveness in\npreserving radioactivity within IARs, enabling robust provenance tracking, and\npreventing unauthorized use of their generated images."}
{"id": "2506.23757", "pdf": "https://arxiv.org/pdf/2506.23757", "abs": "https://arxiv.org/abs/2506.23757", "authors": ["Dan Yao", "Steve McLaughlin", "Yoann Altmann"], "title": "Training of Spiking Neural Networks with Expectation-Propagation", "categories": ["cs.LG", "stat.ME", "stat.ML"], "comment": "10 pages", "summary": "In this paper, we propose a unifying message-passing framework for training\nspiking neural networks (SNNs) using Expectation-Propagation. Our gradient-free\nmethod is capable of learning the marginal distributions of network parameters\nand simultaneously marginalizes nuisance parameters, such as the outputs of\nhidden layers. This framework allows for the first time, training of discrete\nand continuous weights, for deterministic and stochastic spiking networks,\nusing batches of training samples. Although its convergence is not ensured, the\nalgorithm converges in practice faster than gradient-based methods, without\nrequiring a large number of passes through the training data. The\nclassification and regression results presented pave the way for new efficient\ntraining methods for deep Bayesian networks."}
{"id": "2506.23776", "pdf": "https://arxiv.org/pdf/2506.23776", "abs": "https://arxiv.org/abs/2506.23776", "authors": ["Jari Peeperkorn", "Johannes De Smedt", "Jochen De Weerdt"], "title": "Model-driven Stochastic Trace Clustering", "categories": ["cs.LG"], "comment": null, "summary": "Process discovery algorithms automatically extract process models from event\nlogs, but high variability often results in complex and hard-to-understand\nmodels. To mitigate this issue, trace clustering techniques group process\nexecutions into clusters, each represented by a simpler and more understandable\nprocess model. Model-driven trace clustering improves on this by assigning\ntraces to clusters based on their conformity to cluster-specific process\nmodels. However, most existing clustering techniques rely on either no process\nmodel discovery, or non-stochastic models, neglecting the frequency or\nprobability of activities and transitions, thereby limiting their capability to\ncapture real-world execution dynamics. We propose a novel model-driven trace\nclustering method that optimizes stochastic process models within each cluster.\nOur approach uses entropic relevance, a stochastic conformance metric based on\ndirectly-follows probabilities, to guide trace assignment. This allows\nclustering decisions to consider both structural alignment with a cluster's\nprocess model and the likelihood that a trace originates from a given\nstochastic process model. The method is computationally efficient, scales\nlinearly with input size, and improves model interpretability by producing\nclusters with clearer control-flow patterns. Extensive experiments on public\nreal-life datasets show that our method outperforms existing alternatives in\nrepresenting process behavior and reveals how clustering performance rankings\ncan shift when stochasticity is considered."}
{"id": "2506.23782", "pdf": "https://arxiv.org/pdf/2506.23782", "abs": "https://arxiv.org/abs/2506.23782", "authors": ["Xiaoyang Li", "Linwei Tao", "Haohui Lu", "Minjing Dong", "Junbin Gao", "Chang Xu"], "title": "Calibrating Graph Neural Networks with Wavelet-Aware Temperature Scaling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph Neural Networks (GNNs) have demonstrated strong predictive performance\non relational data; however, their confidence estimates often misalign with\nactual predictive correctness, posing significant limitations for deployment in\nsafety-critical settings. While existing graph-aware calibration methods seek\nto mitigate this limitation, they primarily depend on coarse one-hop\nstatistics, such as neighbor-predicted confidence, or latent node embeddings,\nthereby neglecting the fine-grained structural heterogeneity inherent in graph\ntopology. In this work, we propose Wavelet-Aware Temperature Scaling (WATS), a\npost-hoc calibration framework that assigns node-specific temperatures based on\ntunable heat-kernel graph wavelet features. Specifically, WATS harnesses the\nscalability and topology sensitivity of graph wavelets to refine confidence\nestimates, all without necessitating model retraining or access to neighboring\nlogits or predictions. Extensive evaluations across seven benchmark datasets\nwith varying graph structures and two GNN backbones demonstrate that WATS\nachieves the lowest Expected Calibration Error (ECE) among all compared\nmethods, outperforming both classical and graph-specific baselines by up to\n42.3\\% in ECE and reducing calibration variance by 17.24\\% on average compared\nwith graph-specific methods. Moreover, WATS remains computationally efficient,\nscaling well across graphs of diverse sizes and densities. Code will be\nreleased based on publication."}
{"id": "2506.23799", "pdf": "https://arxiv.org/pdf/2506.23799", "abs": "https://arxiv.org/abs/2506.23799", "authors": ["Jiongli Zhu", "Parjanya Prajakta Prashant", "Alex Cloninger", "Babak Salimi"], "title": "KAIROS: Scalable Model-Agnostic Data Valuation", "categories": ["cs.LG"], "comment": "19 pages, 9 figures", "summary": "Training data increasingly shapes not only model accuracy but also regulatory\ncompliance and market valuation of AI assets. Yet existing valuation methods\nremain inadequate: model-based techniques depend on a single fitted model and\ninherit its biases, while algorithm-based approaches such as Data Shapley\nrequire costly retrainings at web scale. Recent Wasserstein-based\nmodel-agnostic methods rely on approximations that misrank examples relative to\ntheir true leave-one-out (LOO) utility. We introduce KAIROS, a scalable,\nmodel-agnostic valuation framework that assigns each example a distributional\ninfluence score: its contribution to the Maximum Mean Discrepancy (MMD) between\nthe empirical training distribution and a clean reference set. Unlike\nWasserstein surrogates, our MMD-based influence admits a closed-form solution\nthat faithfully approximates the exact LOO ranking within $O(1/N^2)$ error,\nrequires no retraining, and naturally extends to conditional kernels for\nunified label- and feature-error detection. Moreover, KAIROS supports efficient\nonline updates: when a new batch of size m arrives, all scores can be updated\nin $O(mN)$ time, delivering up to 50x speedup without compromising ranking\nquality. Empirical evaluations on noise, mislabeling, and poisoning benchmarks\nshow that KAIROS consistently outperforms state-of-the-art model-, Shapley-,\nand Wasserstein-based baselines in both accuracy and runtime. We provide\nrigorous theoretical guarantees, including symmetry for reproducible rankings\nand density-separation for interpretable thresholds."}
{"id": "2506.23800", "pdf": "https://arxiv.org/pdf/2506.23800", "abs": "https://arxiv.org/abs/2506.23800", "authors": ["Chang Qi", "Matteo Forasassi", "Thomas Lukasiewicz", "Tommaso Salvatori"], "title": "Towards the Training of Deeper Predictive Coding Neural Networks", "categories": ["cs.LG"], "comment": "18 Pages, 7 figures", "summary": "Predictive coding networks trained with equilibrium propagation are neural\nmodels that perform inference through an iterative energy minimization process.\nPrevious studies have demonstrated their effectiveness in shallow\narchitectures, but show significant performance degradation when depth exceeds\nfive to seven layers. In this work, we show that the reason behind this\ndegradation is due to exponentially imbalanced errors between layers during\nweight updates, and predictions from the previous layer not being effective in\nguiding updates in deeper layers. We address the first issue by introducing two\nnovel methods to optimize the latent variables that use precision-weighting to\nre-balance the distribution of energy among layers during the `relaxation\nphase', and the second issue by proposing a novel weight update mechanism that\nreduces error accumulation in deeper layers. Empirically, we test our methods\non a large number of image classification tasks, resulting in large\nimprovements in test accuracy across networks with more than seven layers, with\nperformances comparable to those of backprop on similar models. These findings\nsuggest that a better understanding of the relaxation phase is important to\ntrain models using equilibrium propagation at scale, and open new possibilities\nfor their application in complex tasks."}
{"id": "2506.23802", "pdf": "https://arxiv.org/pdf/2506.23802", "abs": "https://arxiv.org/abs/2506.23802", "authors": ["Konstantinos Bourazas", "Savvas Papaioannou", "Panayiotis Kolios"], "title": "Adaptive Out-of-Control Point Pattern Detection in Sequential Random Finite Set Observations", "categories": ["cs.LG"], "comment": "23rd European Control Conference (ECC 2025), Thessaloniki, Greece,\n  24-27 June 2025", "summary": "In this work we introduce a novel adaptive anomaly detection framework\nspecifically designed for monitoring sequential random finite set (RFS)\nobservations. Our approach effectively distinguishes between In-Control data\n(normal) and Out-Of-Control data (anomalies) by detecting deviations from the\nexpected statistical behavior of the process. The primary contributions of this\nstudy include the development of an innovative RFS-based framework that not\nonly learns the normal behavior of the data-generating process online but also\ndynamically adapts to behavioral shifts to accurately identify abnormal point\npatterns. To achieve this, we introduce a new class of RFS-based posterior\ndistributions, named Power Discounting Posteriors (PD), which facilitate\nadaptation to systematic changes in data while enabling anomaly detection of\npoint pattern data through a novel predictive posterior density function. The\neffectiveness of the proposed approach is demonstrated by extensive qualitative\nand quantitative simulation experiments."}
{"id": "2506.23803", "pdf": "https://arxiv.org/pdf/2506.23803", "abs": "https://arxiv.org/abs/2506.23803", "authors": ["Dmitry Kovalev"], "title": "SGD with Adaptive Preconditioning: Unified Analysis and Momentum Acceleration", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "In this paper, we revisit stochastic gradient descent (SGD) with AdaGrad-type\npreconditioning. Our contributions are twofold. First, we develop a unified\nconvergence analysis of SGD with adaptive preconditioning under anisotropic or\nmatrix smoothness and noise assumptions. This allows us to recover\nstate-of-the-art convergence results for several popular adaptive gradient\nmethods, including AdaGrad-Norm, AdaGrad, and ASGO/One-sided Shampoo. In\naddition, we establish the fundamental connection between two recently proposed\nalgorithms, Scion and DASGO, and provide the first theoretical guarantees for\nthe latter. Second, we show that the convergence of methods like AdaGrad and\nDASGO can be provably accelerated beyond the best-known rates using Nesterov\nmomentum. Consequently, we obtain the first theoretical justification that\nAdaGrad-type algorithms can simultaneously benefit from both diagonal\npreconditioning and momentum, which may provide an ultimate explanation for the\npractical efficiency of Adam."}
{"id": "2506.23824", "pdf": "https://arxiv.org/pdf/2506.23824", "abs": "https://arxiv.org/abs/2506.23824", "authors": ["Durgesh Singh", "Ahcene Boubekki", "Robert Jenssen", "Michael C. Kampffmeyer"], "title": "Supercm: Revisiting Clustering for Semi-Supervised Learning", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "The development of semi-supervised learning (SSL) has in recent years largely\nfocused on the development of new consistency regularization or entropy\nminimization approaches, often resulting in models with complex training\nstrategies to obtain the desired results. In this work, we instead propose a\nnovel approach that explicitly incorporates the underlying clustering\nassumption in SSL through extending a recently proposed differentiable\nclustering module. Leveraging annotated data to guide the cluster centroids\nresults in a simple end-to-end trainable deep SSL approach. We demonstrate that\nthe proposed model improves the performance over the supervised-only baseline\nand show that our framework can be used in conjunction with other SSL methods\nto further boost their performance."}
{"id": "2506.23843", "pdf": "https://arxiv.org/pdf/2506.23843", "abs": "https://arxiv.org/abs/2506.23843", "authors": ["Joris Bekkers"], "title": "EFPI: Elastic Formation and Position Identification in Football (Soccer) using Template Matching and Linear Assignment", "categories": ["cs.LG"], "comment": null, "summary": "Understanding team formations and player positioning is crucial for tactical\nanalysis in football (soccer). This paper presents a flexible method for\nformation recognition and player position assignment in football using\npredefined static formation templates and cost minimization from spatiotemporal\ntracking data, called EFPI. Our approach employs linear sum assignment to\noptimally match players to positions within a set of template formations by\nminimizing the total distance between actual player locations and template\npositions, subsequently selecting the formation with the lowest assignment\ncost. To improve accuracy, we scale actual player positions to match the\ndimensions of these formation templates in both width and length. While the\nmethod functions effectively on individual frames, it extends naturally to\nlarger game segments such as complete periods, possession sequences or specific\nintervals (e.g. 10 second intervals, 5 minute intervals etc.). Additionally, we\nincorporate an optional stability parameter that prevents unnecessary formation\nchanges when assignment costs differ only marginally between time segments.\nEFPI is available as open-source code through the unravelsports Python package."}
{"id": "2506.23845", "pdf": "https://arxiv.org/pdf/2506.23845", "abs": "https://arxiv.org/abs/2506.23845", "authors": ["Kenny Peng", "Rajiv Movva", "Jon Kleinberg", "Emma Pierson", "Nikhil Garg"], "title": "Use Sparse Autoencoders to Discover Unknown Concepts, Not to Act on Known Concepts", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CY"], "comment": null, "summary": "While sparse autoencoders (SAEs) have generated significant excitement, a\nseries of negative results have added to skepticism about their usefulness.\nHere, we establish a conceptual distinction that reconciles competing\nnarratives surrounding SAEs. We argue that while SAEs may be less effective for\nacting on known concepts, SAEs are powerful tools for discovering unknown\nconcepts. This distinction cleanly separates existing negative and positive\nresults, and suggests several classes of SAE applications. Specifically, we\noutline use cases for SAEs in (i) ML interpretability, explainability,\nfairness, auditing, and safety, and (ii) social and health sciences."}
{"id": "2506.23872", "pdf": "https://arxiv.org/pdf/2506.23872", "abs": "https://arxiv.org/abs/2506.23872", "authors": ["Eduard Buss", "Till Aust", "Heiko Hamann"], "title": "When Plants Respond: Electrophysiology and Machine Learning for Green Monitoring Systems", "categories": ["cs.LG"], "comment": "Submitted and Accepted at the 14th international conference on\n  biomimetic and biohybrid systems (Living Machines)", "summary": "Living plants, while contributing to ecological balance and climate\nregulation, also function as natural sensors capable of transmitting\ninformation about their internal physiological states and surrounding\nconditions. This rich source of data provides potential for applications in\nenvironmental monitoring and precision agriculture. With integration into\nbiohybrid systems, we establish novel channels of physiological signal flow\nbetween living plants and artificial devices. We equipped *Hedera helix* with a\nplant-wearable device called PhytoNode to continuously record the plant's\nelectrophysiological activity. We deployed plants in an uncontrolled outdoor\nenvironment to map electrophysiological patterns to environmental conditions.\nOver five months, we collected data that we analyzed using state-of-the-art and\nautomated machine learning (AutoML). Our classification models achieve high\nperformance, reaching macro F1 scores of up to 95 percent in binary tasks.\nAutoML approaches outperformed manual tuning, and selecting subsets of\nstatistical features further improved accuracy. Our biohybrid living system\nmonitors the electrophysiology of plants in harsh, real-world conditions. This\nwork advances scalable, self-sustaining, and plant-integrated living biohybrid\nsystems for sustainable environmental monitoring."}
{"id": "2506.23875", "pdf": "https://arxiv.org/pdf/2506.23875", "abs": "https://arxiv.org/abs/2506.23875", "authors": ["Yuta Sato", "Kazuhiko Kawamoto", "Hiroshi Kera"], "title": "Chain of Thought in Order: Discovering Learning-Friendly Orders for Arithmetic", "categories": ["cs.LG", "cs.AI"], "comment": "14 pages, 10 figures", "summary": "The chain of thought is fundamental in Transformers, which is to perform\nstep-by-step reasoning. Besides what intermediate steps work, the order of\nthese steps critically affects the difficulty of the reasoning. This study\naddresses a novel task of unraveling chain of thought - reordering decoder\ninput tokens to a learning-friendly sequence for Transformers to learn\narithmetic tasks. The proposed pipeline first trains a Transformer on a mixture\nof target sequences arranged in different orders and then identifies benign\norders as those with fast loss drops in the early stage. As the search space\ngrows factorially with sequence length, we propose a two-stage hierarchical\napproach for inter- and intra-block reordering. Experiments on four\norder-sensitive arithmetic tasks show that our method identifies a\nlearning-friendly order out of a few billion candidates. Notably, on the\nmultiplication task, it recovered the reverse-digit order reported in prior\nstudies."}
{"id": "2506.23923", "pdf": "https://arxiv.org/pdf/2506.23923", "abs": "https://arxiv.org/abs/2506.23923", "authors": ["Miguel Camacho-Sánchez", "Fernando García-Torres", "Jesper John Lisegaard", "Rocío del Amor", "Sankhya Mohanty", "Valery Naranjo"], "title": "Reinforcement Learning for Synchronised Flow Control in a Dual-Gate Resin Infusion System", "categories": ["cs.LG", "cs.AI"], "comment": "11 pages, 4 figures, 45th Ris{\\o} International Symposium on\n  Materials Science", "summary": "Resin infusion (RI) and resin transfer moulding (RTM) are critical processes\nfor the manufacturing of high-performance fibre-reinforced polymer composites,\nparticularly for large-scale applications such as wind turbine blades.\nControlling the resin flow dynamics in these processes is critical to ensure\nthe uniform impregnation of the fibre reinforcements, thereby preventing\nresidual porosities and dry spots that impact the consequent structural\nintegrity of the final component. This paper presents a reinforcement learning\n(RL) based strategy, established using process simulations, for synchronising\nthe different resin flow fronts in an infusion scenario involving two resin\ninlets and a single outlet. Using Proximal Policy Optimisation (PPO), our\napproach addresses the challenge of managing the fluid dynamics in a partially\nobservable environment. The results demonstrate the effectiveness of the RL\napproach in achieving an accurate flow convergence, highlighting its potential\ntowards improving process control and product quality in composites\nmanufacturing."}
{"id": "2506.23958", "pdf": "https://arxiv.org/pdf/2506.23958", "abs": "https://arxiv.org/abs/2506.23958", "authors": ["Ikechukwu Ogbonna", "Lesley Davidson", "Soumya Banerjee", "Abhishek Dasgupta", "Laurence Kenney", "Vikranth Harthikote Nagaraja"], "title": "Bridging the Gap with Retrieval-Augmented Generation: Making Prosthetic Device User Manuals Available in Marginalised Languages", "categories": ["cs.LG"], "comment": "5 pages, 0 figures, 0 tables", "summary": "Millions of people in African countries face barriers to accessing healthcare\ndue to language and literacy gaps. This research tackles this challenge by\ntransforming complex medical documents -- in this case, prosthetic device user\nmanuals -- into accessible formats for underserved populations. This case study\nin cross-cultural translation is particularly pertinent/relevant for\ncommunities that receive donated prosthetic devices but may not receive the\naccompanying user documentation. Or, if available online, may only be available\nin formats (e.g., language and readability) that are inaccessible to local\npopulations (e.g., English-language, high resource settings/cultural context).\nThe approach is demonstrated using the widely spoken Pidgin dialect, but our\nopen-source framework has been designed to enable rapid and easy extension to\nother languages/dialects. This work presents an AI-powered framework designed\nto process and translate complex medical documents, e.g., user manuals for\nprosthetic devices, into marginalised languages. The system enables users --\nsuch as healthcare workers or patients -- to upload English-language medical\nequipment manuals, pose questions in their native language, and receive\naccurate, localised answers in real time. Technically, the system integrates a\nRetrieval-Augmented Generation (RAG) pipeline for processing and semantic\nunderstanding of the uploaded manuals. It then employs advanced Natural\nLanguage Processing (NLP) models for generative question-answering and\nmultilingual translation. Beyond simple translation, it ensures accessibility\nto device instructions, treatment protocols, and safety information, empowering\npatients and clinicians to make informed healthcare decisions."}
{"id": "2506.23960", "pdf": "https://arxiv.org/pdf/2506.23960", "abs": "https://arxiv.org/abs/2506.23960", "authors": ["Mingfei Cheng", "Xiaofei Xie", "Renzhi Wang", "Yuan Zhou", "Ming Hu"], "title": "ADReFT: Adaptive Decision Repair for Safe Autonomous Driving via Reinforcement Fine-Tuning", "categories": ["cs.LG", "cs.AI", "cs.SE"], "comment": null, "summary": "Autonomous Driving Systems (ADSs) continue to face safety-critical risks due\nto the inherent limitations in their design and performance capabilities.\nOnline repair plays a crucial role in mitigating such limitations, ensuring the\nruntime safety and reliability of ADSs. Existing online repair solutions\nenforce ADS compliance by transforming unacceptable trajectories into\nacceptable ones based on predefined specifications, such as rule-based\nconstraints or training datasets. However, these approaches often lack\ngeneralizability, adaptability and tend to be overly conservative, resulting in\nineffective repairs that not only fail to mitigate safety risks sufficiently\nbut also degrade the overall driving experience. To address this issue, we\npropose Adaptive Decision Repair (ADReFT), a novel and effective repair method\nthat identifies safety-critical states through offline learning from failed\ntests and generates appropriate mitigation actions to improve ADS safety.\nSpecifically, ADReFT incorporates a transformer-based model with two joint\nheads, State Monitor and Decision Adapter, designed to capture complex driving\nenvironment interactions to evaluate state safety severity and generate\nadaptive repair actions. Given the absence of oracles for state safety\nidentification, we first pretrain ADReFT using supervised learning with coarse\nannotations, i.e., labeling states preceding violations as positive samples and\nothers as negative samples. It establishes ADReFT's foundational capability to\nmitigate safety-critical violations, though it may result in somewhat\nconservative mitigation strategies. Therefore, we subsequently finetune ADReFT\nusing reinforcement learning to improve its initial capability and generate\nmore precise and contextually appropriate repair decisions. Our evaluation\nresults illustrate that ADReFT achieves better repair performance."}
{"id": "2506.23971", "pdf": "https://arxiv.org/pdf/2506.23971", "abs": "https://arxiv.org/abs/2506.23971", "authors": ["Brandon M. Wood", "Misko Dzamba", "Xiang Fu", "Meng Gao", "Muhammed Shuaibi", "Luis Barroso-Luque", "Kareem Abdelmaqsoud", "Vahe Gharakhanyan", "John R. Kitchin", "Daniel S. Levine", "Kyle Michel", "Anuroop Sriram", "Taco Cohen", "Abhishek Das", "Ammar Rizvi", "Sushree Jagriti Sahoo", "Zachary W. Ulissi", "C. Lawrence Zitnick"], "title": "UMA: A Family of Universal Models for Atoms", "categories": ["cs.LG"], "comment": "29 pages, 5 figures", "summary": "The ability to quickly and accurately compute properties from atomic\nsimulations is critical for advancing a large number of applications in\nchemistry and materials science including drug discovery, energy storage, and\nsemiconductor manufacturing. To address this need, Meta FAIR presents a family\nof Universal Models for Atoms (UMA), designed to push the frontier of speed,\naccuracy, and generalization. UMA models are trained on half a billion unique\n3D atomic structures (the largest training runs to date) by compiling data\nacross multiple chemical domains, e.g. molecules, materials, and catalysts. We\ndevelop empirical scaling laws to help understand how to increase model\ncapacity alongside dataset size to achieve the best accuracy. The UMA small and\nmedium models utilize a novel architectural design we refer to as mixture of\nlinear experts that enables increasing model capacity without sacrificing\nspeed. For example, UMA-medium has 1.4B parameters but only ~50M active\nparameters per atomic structure. We evaluate UMA models on a diverse set of\napplications across multiple domains and find that, remarkably, a single model\nwithout any fine-tuning can perform similarly or better than specialized\nmodels. We are releasing the UMA code, weights, and associated data to\naccelerate computational workflows and enable the community to continue to\nbuild increasingly capable AI models."}
{"id": "2506.23977", "pdf": "https://arxiv.org/pdf/2506.23977", "abs": "https://arxiv.org/abs/2506.23977", "authors": ["Zain ul Abdeen", "Vassilis Kekatos", "Ming Jin"], "title": "A Scalable Approach for Safe and Robust Learning via Lipschitz-Constrained Networks", "categories": ["cs.LG"], "comment": null, "summary": "Certified robustness is a critical property for deploying neural networks\n(NN) in safety-critical applications. A principle approach to achieving such\nguarantees is to constrain the global Lipschitz constant of the network.\nHowever, accurate methods for Lipschitz-constrained training often suffer from\nnon-convex formulations and poor scalability due to reliance on global\nsemidefinite programs (SDPs). In this letter, we propose a convex training\nframework that enforces global Lipschitz constraints via semidefinite\nrelaxation. By reparameterizing the NN using loop transformation, we derive a\nconvex admissibility condition that enables tractable and certifiable training.\nWhile the resulting formulation guarantees robustness, its scalability is\nlimited by the size of global SDP. To overcome this, we develop a randomized\nsubspace linear matrix inequalities (RS-LMI) approach that decomposes the\nglobal constraints into sketched layerwise constraints projected onto\nlow-dimensional subspaces, yielding a smooth and memory-efficient training\nobjective. Empirical results on MNIST, CIFAR-10, and ImageNet demonstrate that\nthe proposed framework achieves competitive accuracy with significantly\nimproved Lipschitz bounds and runtime performance."}
{"id": "2506.23978", "pdf": "https://arxiv.org/pdf/2506.23978", "abs": "https://arxiv.org/abs/2506.23978", "authors": ["Samuele Marro", "Philip Torr"], "title": "LLM Agents Are the Antidote to Walled Gardens", "categories": ["cs.LG", "cs.CL", "cs.CY", "cs.SI", "68T50, 68M10, 91B26", "I.2.11; I.2.7; H.4.5"], "comment": null, "summary": "While the Internet's core infrastructure was designed to be open and\nuniversal, today's application layer is dominated by closed, proprietary\nplatforms. Open and interoperable APIs require significant investment, and\nmarket leaders have little incentive to enable data exchange that could erode\ntheir user lock-in. We argue that LLM-based agents fundamentally disrupt this\nstatus quo. Agents can automatically translate between data formats and\ninteract with interfaces designed for humans: this makes interoperability\ndramatically cheaper and effectively unavoidable. We name this shift universal\ninteroperability: the ability for any two digital services to exchange data\nseamlessly using AI-mediated adapters. Universal interoperability undermines\nmonopolistic behaviours and promotes data portability. However, it can also\nlead to new security risks and technical debt. Our position is that the ML\ncommunity should embrace this development while building the appropriate\nframeworks to mitigate the downsides. By acting now, we can harness AI to\nrestore user freedom and competitive markets without sacrificing security."}
{"id": "2506.23996", "pdf": "https://arxiv.org/pdf/2506.23996", "abs": "https://arxiv.org/abs/2506.23996", "authors": ["Juan Maroñas"], "title": "The Jacobian and Hessian of the Kullback-Leibler Divergence between Multivariate Gaussian Distributions (Technical Report)", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "This document shows how to obtain the Jacobian and Hessian matrices of the\nKullback-Leibler divergence between two multivariate Gaussian distributions,\nusing the first and second-order differentials. The presented derivations are\nbased on the theory presented by \\cite{magnus99}. I've also got great\ninspiration from some of the derivations in \\cite{minka}.\n  Since I pretend to be at most didactic, the document is split into a summary\nof results and detailed derivations on each of the elements involved, with\nspecific references to the tricks used in the derivations, and to many of the\nunderlying concepts."}
{"id": "2506.24000", "pdf": "https://arxiv.org/pdf/2506.24000", "abs": "https://arxiv.org/abs/2506.24000", "authors": ["Lijun Sheng", "Jian Liang", "Ran He", "Zilei Wang", "Tieniu Tan"], "title": "The Illusion of Progress? A Critical Look at Test-Time Adaptation for Vision-Language Models", "categories": ["cs.LG", "cs.CV"], "comment": "Github link: https://github.com/TomSheng21/tta-vlm", "summary": "Test-time adaptation (TTA) methods have gained significant attention for\nenhancing the performance of vision-language models (VLMs) such as CLIP during\ninference, without requiring additional labeled data. However, current TTA\nresearches generally suffer from major limitations such as duplication of\nbaseline results, limited evaluation metrics, inconsistent experimental\nsettings, and insufficient analysis. These problems hinder fair comparisons\nbetween TTA methods and obscure their practical strengths and weaknesses. To\naddress these challenges, we introduce TTA-VLM, a comprehensive benchmark for\nevaluating TTA methods on VLMs. Our benchmark implements 8 episodic TTA and 7\nonline TTA methods within a unified and reproducible framework, and evaluates\nthem across 15 widely used datasets. Unlike prior studies focused solely on\nCLIP, we extend the evaluation to SigLIP--a model trained with a Sigmoid\nloss--and include training-time tuning methods such as CoOp, MaPLe, and TeCoA\nto assess generality. Beyond classification accuracy, TTA-VLM incorporates\nvarious evaluation metrics, including robustness, calibration,\nout-of-distribution detection, and stability, enabling a more holistic\nassessment of TTA methods. Through extensive experiments, we find that 1)\nexisting TTA methods produce limited gains compared to the previous pioneering\nwork; 2) current TTA methods exhibit poor collaboration with training-time\nfine-tuning methods; 3) accuracy gains frequently come at the cost of reduced\nmodel trustworthiness. We release TTA-VLM to provide fair comparison and\ncomprehensive evaluation of TTA methods for VLMs, and we hope it encourages the\ncommunity to develop more reliable and generalizable TTA strategies."}
{"id": "2506.24005", "pdf": "https://arxiv.org/pdf/2506.24005", "abs": "https://arxiv.org/abs/2506.24005", "authors": ["He Wang", "Xingyu Xu", "Yuejie Chi"], "title": "Provably Efficient and Agile Randomized Q-Learning", "categories": ["cs.LG"], "comment": null, "summary": "While Bayesian-based exploration often demonstrates superior empirical\nperformance compared to bonus-based methods in model-based reinforcement\nlearning (RL), its theoretical understanding remains limited for model-free\nsettings. Existing provable algorithms either suffer from computational\nintractability or rely on stage-wise policy updates which reduce responsiveness\nand slow down the learning process. In this paper, we propose a novel variant\nof Q-learning algorithm, refereed to as RandomizedQ, which integrates\nsampling-based exploration with agile, step-wise, policy updates, for episodic\ntabular RL. We establish an $\\widetilde{O}(\\sqrt{H^5SAT})$ regret bound, where\n$S$ is the number of states, $A$ is the number of actions, $H$ is the episode\nlength, and $T$ is the total number of episodes. In addition, we present a\nlogarithmic regret bound under a mild positive sub-optimality condition on the\noptimal Q-function. Empirically, RandomizedQ exhibits outstanding performance\ncompared to existing Q-learning variants with both bonus-based and\nBayesian-based exploration on standard benchmarks."}
{"id": "2506.24018", "pdf": "https://arxiv.org/pdf/2506.24018", "abs": "https://arxiv.org/abs/2506.24018", "authors": ["Veronica Lachi", "Francesco Ferrini", "Antonio Longa", "Bruno Lepri", "Andrea Passerini", "Manfred Jaeger"], "title": "Bridging Theory and Practice in Link Representation with Graph Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph Neural Networks (GNNs) are widely used to compute representations of\nnode pairs for downstream tasks such as link prediction. Yet, theoretical\nunderstanding of their expressive power has focused almost entirely on\ngraph-level representations. In this work, we shift the focus to links and\nprovide the first comprehensive study of GNN expressiveness in link\nrepresentation. We introduce a unifying framework, the $k_\\phi$-$k_\\rho$-$m$\nframework, that subsumes existing message-passing link models and enables\nformal expressiveness comparisons. Using this framework, we derive a hierarchy\nof state-of-the-art methods and offer theoretical tools to analyze future\narchitectures. To complement our analysis, we propose a synthetic evaluation\nprotocol comprising the first benchmark specifically designed to assess\nlink-level expressiveness. Finally, we ask: does expressiveness matter in\npractice? We use a graph symmetry metric that quantifies the difficulty of\ndistinguishing links and show that while expressive models may underperform on\nstandard benchmarks, they significantly outperform simpler ones as symmetry\nincreases, highlighting the need for dataset-aware model selection."}
{"id": "2506.24042", "pdf": "https://arxiv.org/pdf/2506.24042", "abs": "https://arxiv.org/abs/2506.24042", "authors": ["Gen Li", "Yuchen Zhou", "Yuting Wei", "Yuxin Chen"], "title": "Faster Diffusion Models via Higher-Order Approximation", "categories": ["cs.LG", "cs.NA", "math.NA", "math.ST", "stat.ML", "stat.TH"], "comment": null, "summary": "In this paper, we explore provable acceleration of diffusion models without\nany additional retraining. Focusing on the task of approximating a target data\ndistribution in $\\mathbb{R}^d$ to within $\\varepsilon$ total-variation\ndistance, we propose a principled, training-free sampling algorithm that\nrequires only the order of\n  $$ d^{1+2/K} \\varepsilon^{-1/K} $$\n  score function evaluations (up to log factor) in the presence of accurate\nscores, where $K$ is an arbitrarily large fixed integer. This result applies to\na broad class of target data distributions, without the need for assumptions\nsuch as smoothness or log-concavity. Our theory is robust vis-a-vis inexact\nscore estimation, degrading gracefully as the score estimation error increases\n-- without demanding higher-order smoothness on the score estimates as assumed\nin previous work. The proposed algorithm draws insight from high-order ODE\nsolvers, leveraging high-order Lagrange interpolation and successive refinement\nto approximate the integral derived from the probability flow ODE."}
{"id": "2506.24093", "pdf": "https://arxiv.org/pdf/2506.24093", "abs": "https://arxiv.org/abs/2506.24093", "authors": ["Paul Wachter", "Lukas Niehaus", "Julius Schöning"], "title": "Development of Hybrid Artificial Intelligence Training on Real and Synthetic Data: Benchmark on Two Mixed Training Strategies", "categories": ["cs.LG", "cs.AI", "I.2.1; I.2.0; F.2.3"], "comment": "21pages, 14 figures, 2 tables", "summary": "Synthetic data has emerged as a cost-effective alternative to real data for\ntraining artificial neural networks (ANN). However, the disparity between\nsynthetic and real data results in a domain gap. That gap leads to poor\nperformance and generalization of the trained ANN when applied to real-world\nscenarios. Several strategies have been developed to bridge this gap, which\ncombine synthetic and real data, known as mixed training using hybrid datasets.\nWhile these strategies have been shown to mitigate the domain gap, a systematic\nevaluation of their generalizability and robustness across various tasks and\narchitectures remains underexplored. To address this challenge, our study\ncomprehensively analyzes two widely used mixing strategies on three prevalent\narchitectures and three distinct hybrid datasets. From these datasets, we\nsample subsets with varying proportions of synthetic to real data to\ninvestigate the impact of synthetic and real components. The findings of this\npaper provide valuable insights into optimizing the use of synthetic data in\nthe training process of any ANN, contributing to enhancing robustness and\nefficacy."}
{"id": "2506.24120", "pdf": "https://arxiv.org/pdf/2506.24120", "abs": "https://arxiv.org/abs/2506.24120", "authors": ["Yuqing Wang", "Shangding Gu"], "title": "Data Uniformity Improves Training Efficiency and More, with a Convergence Framework Beyond the NTK Regime", "categories": ["cs.LG", "cs.AI", "math.OC", "stat.ML"], "comment": null, "summary": "Data selection plays a crucial role in data-driven decision-making, including\nin large language models (LLMs), and is typically task-dependent. Properties\nsuch as data quality and diversity have been extensively studied and are known\nto enhance model performance. However, it remains unclear whether there exist\nother quantitative and general principles of data selection that can\nconsistently improve performance, especially for complex tasks with limited\nprior knowledge. In this paper, we demonstrate that selecting more uniformly\ndistributed data can improve training efficiency while enhancing performance.\nSpecifically, we establish that more uniform (less biased) distribution leads\nto a larger minimum pairwise distance between data points, denoted by\n$h_{\\min}$, and prove that a smaller $h_{\\min}$ can slow down the training\ndynamics of gradient descent (GD). Moreover, we theoretically show that the\napproximation error of neural networks decreases as $h_{\\min}$ increases. Our\nanalysis introduces a convergence framework for GD beyond the Neural Tangent\nKernel (NTK) regime, applicable to a broad class of architectures, including\ntransformers, without requiring Lipschitz smoothness. This framework further\nprovides theoretical justification for the use of residual connections and\nfunction compositions in deep neural architectures. In the end, we conduct\ncomprehensive experiments for supervised fine-tuning across various settings,\nincluding different optimization strategies, model sizes, and training\ndatasets. The results consistently demonstrate that selecting data by\nmaximizing pairwise distance significantly accelerates training and achieves\ncomparable or better performance in LLMs across diverse datasets. Code and\nDatasets are available at the link:\nhttps://github.com/SafeRL-Lab/data-uniformity."}
{"id": "2506.24124", "pdf": "https://arxiv.org/pdf/2506.24124", "abs": "https://arxiv.org/abs/2506.24124", "authors": ["Dong Sixun", "Fan Wei", "Teresa Wu", "Fu Yanjie"], "title": "Teaching Time Series to See and Speak: Forecasting with Aligned Visual and Textual Perspectives", "categories": ["cs.LG", "cs.CV"], "comment": "Code: https://github.com/Ironieser/TimesCLIP", "summary": "Time series forecasting traditionally relies on unimodal numerical inputs,\nwhich often struggle to capture high-level semantic patterns due to their dense\nand unstructured nature. While recent approaches have explored representing\ntime series as text using large language models (LLMs), these methods remain\nlimited by the discrete nature of token sequences and lack the perceptual\nintuition humans typically apply, such as interpreting visual patterns. In this\npaper, we propose a multimodal contrastive learning framework that transforms\nraw time series into structured visual and textual perspectives. Rather than\nusing natural language or real-world images, we construct both modalities\ndirectly from numerical sequences. We then align these views in a shared\nsemantic space via contrastive learning, enabling the model to capture richer\nand more complementary representations. Furthermore, we introduce a variate\nselection module that leverages the aligned representations to identify the\nmost informative variables for multivariate forecasting. Extensive experiments\non fifteen short-term and six long-term forecasting benchmarks demonstrate that\nour approach consistently outperforms strong unimodal and cross-modal\nbaselines, highlighting the effectiveness of multimodal alignment in enhancing\ntime series forecasting. Code is available at:\nhttps://github.com/Ironieser/TimesCLIP."}
{"id": "2504.15071", "pdf": "https://arxiv.org/pdf/2504.15071", "abs": "https://arxiv.org/abs/2504.15071", "authors": ["Louis Bradshaw", "Simon Colton"], "title": "Aria-MIDI: A Dataset of Piano MIDI Files for Symbolic Music Modeling", "categories": ["cs.SD", "cs.AI", "cs.LG"], "comment": null, "summary": "We introduce an extensive new dataset of MIDI files, created by transcribing\naudio recordings of piano performances into their constituent notes. The data\npipeline we use is multi-stage, employing a language model to autonomously\ncrawl and score audio recordings from the internet based on their metadata,\nfollowed by a stage of pruning and segmentation using an audio classifier. The\nresulting dataset contains over one million distinct MIDI files, comprising\nroughly 100,000 hours of transcribed audio. We provide an in-depth analysis of\nour techniques, offering statistical insights, and investigate the content by\nextracting metadata tags, which we also provide. Dataset available at\nhttps://github.com/loubbrad/aria-midi."}
{"id": "2506.22440", "pdf": "https://arxiv.org/pdf/2506.22440", "abs": "https://arxiv.org/abs/2506.22440", "authors": ["Sharique Hasan", "Alexander Oettl", "Sampsa Samila"], "title": "From Model Design to Organizational Design: Complexity Redistribution and Trade-Offs in Generative AI", "categories": ["cs.CY", "cs.LG", "cs.MA", "econ.GN", "q-fin.EC"], "comment": null, "summary": "This paper introduces the Generality-Accuracy-Simplicity (GAS) framework to\nanalyze how large language models (LLMs) are reshaping organizations and\ncompetitive strategy. We argue that viewing AI as a simple reduction in input\ncosts overlooks two critical dynamics: (a) the inherent trade-offs among\ngenerality, accuracy, and simplicity, and (b) the redistribution of complexity\nacross stakeholders. While LLMs appear to defy the traditional trade-off by\noffering high generality and accuracy through simple interfaces, this\nuser-facing simplicity masks a significant shift of complexity to\ninfrastructure, compliance, and specialized personnel. The GAS trade-off,\ntherefore, does not disappear but is relocated from the user to the\norganization, creating new managerial challenges, particularly around accuracy\nin high-stakes applications. We contend that competitive advantage no longer\nstems from mere AI adoption, but from mastering this redistributed complexity\nthrough the design of abstraction layers, workflow alignment, and complementary\nexpertise. This study advances AI strategy by clarifying how scalable cognition\nrelocates complexity and redefines the conditions for technology integration."}
{"id": "2506.22450", "pdf": "https://arxiv.org/pdf/2506.22450", "abs": "https://arxiv.org/abs/2506.22450", "authors": ["Jens Winkler", "Michael Denhard"], "title": "Arnoldi Singular Vector perturbations for machine learning weather prediction", "categories": ["physics.ao-ph", "cs.LG"], "comment": "dynamical systems, atmospheric physics, machine learing weather\n  prediction, forecast uncertainity, 42 pages with 29 figures (inkl. appendix)", "summary": "Since weather forecasts are fundamentally uncertain, reliable decision making\nrequires information on the likelihoods of future weather scenarios. We explore\nthe sensitivity of machine learning weather prediction (MLWP) using the 24h\nPangu Weather ML model of Huawei to errors in the initial conditions with a\nspecific kind of Singular Vector (SV) perturbations. Our Arnoldi-SV (A-SV)\nmethod does not need linear nor adjoint model versions and is applicable to\nnumerical weather prediction (NWP) as well as MLWP. It observes error growth\nwithin a given optimization time window by iteratively applying a forecast\nmodel to perturbed model states. This creates a Krylov subspace, implicitly\nbased on a matrix operator, which approximates the local error growth. Each\niteration adds new dimensions to the Krylov space and its leading right SVs are\nexpected to turn into directions of growing errors. We show that A-SV indeed\nfinds dynamically meaningful perturbation patterns for the 24h Pangu Weather\nmodel, which grow right from the beginning of the forecast rollout. These\nperturbations describe local unstable modes and could be a basis to initialize\nMLWP ensembles. Since we start A-SV from random noise perturbations, the\nalgorithm transforms noise into perturbations conditioned on a given reference\nstate - a process that is akin to the denoising process of the generic\ndiffusion based ML model of GenCast, therefor we briefly discuss similarities\nand differences."}
{"id": "2506.22454", "pdf": "https://arxiv.org/pdf/2506.22454", "abs": "https://arxiv.org/abs/2506.22454", "authors": ["Ana Luiza S. Tavares", "Artur Pedro M. Neto", "Francinaldo L. Gomes", "Paul Rodrigo dos Reis", "Arthur G. da Silva", "Antonio P. Junior", "Bruno D. Gomes"], "title": "Microelectrode Signal Dynamics as Biomarkers of Subthalamic Nucleus Entry on Deep Brain Stimulation: A Nonlinear Feature Approach", "categories": ["eess.SP", "cs.LG"], "comment": "8 pages, 5 figures", "summary": "Accurate intraoperative localization of the subthalamic nucleus (STN) is\nessential for the efficacy of Deep Brain Stimulation (DBS) in patients with\nParkinson's disease. While microelectrode recordings (MERs) provide rich\nelectrophysiological information during DBS electrode implantation, current\nlocalization practices often rely on subjective interpretation of signal\nfeatures. In this study, we propose a quantitative framework that leverages\nnonlinear dynamics and entropy-based metrics to classify neural activity\nrecorded inside versus outside the STN. MER data from three patients were\npreprocessed using a robust artifact correction pipeline, segmented, and\nlabelled based on surgical annotations. A comprehensive set of recurrence\nquantification analysis, nonlinear, and entropy features were extracted from\neach segment. Multiple supervised classifiers were trained on every combination\nof feature domains using stratified 10-fold cross-validation, followed by\nstatistical comparison using paired Wilcoxon signed-rank tests with\nHolm-Bonferroni correction. The combination of entropy and nonlinear features\nyielded the highest discriminative power, and the Extra Trees classifier\nemerged as the best model with a cross-validated F1-score of 0.902+/-0.027 and\nROC AUC of 0.887+/-0.055. Final evaluation on a 20% hold-out test set confirmed\nrobust generalization (F1= 0.922, ROC AUC = 0.941). These results highlight the\npotential of nonlinear and entropy signal descriptors in supporting real-time,\ndata-driven decision-making during DBS surgeries"}
{"id": "2506.22455", "pdf": "https://arxiv.org/pdf/2506.22455", "abs": "https://arxiv.org/abs/2506.22455", "authors": ["Dung Truong", "Arnaud Delorme"], "title": "Data Normalization Strategies for EEG Deep Learning", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "Normalization is a critical yet often overlooked component in the\npreprocessing pipeline for EEG deep learning applications. The rise of\nlarge-scale pretraining paradigms such as self-supervised learning (SSL)\nintroduces a new set of tasks whose nature is substantially different from\nsupervised training common in EEG deep learning applications. This raises new\nquestions about optimal normalization strategies for the applicable task. In\nthis study, we systematically evaluate the impact of normalization granularity\n(recording vs. window level) and scope (cross-channel vs. within-channel) on\nboth supervised (age and gender prediction) and self-supervised (Contrastive\nPredictive Coding) tasks. Using high-density resting-state EEG from 2,836\nsubjects in the Healthy Brain Network dataset, we show that optimal\nnormalization strategies differ significantly between training paradigms.\nWindow-level within-channel normalization yields the best performance in\nsupervised tasks, while minimal or cross-channel normalization at the window\nlevel is more effective for SSL. These results underscore the necessity of\ntask-specific normalization choices and challenge the assumption that a\nuniversal normalization strategy can generalize across learning settings. Our\nfindings provide practical insights for developing robust EEG deep learning\npipelines as the field shifts toward large-scale, foundation model training."}
{"id": "2506.22459", "pdf": "https://arxiv.org/pdf/2506.22459", "abs": "https://arxiv.org/abs/2506.22459", "authors": ["Wending Heng", "Chaoyuan Liang", "Yihui Zhao", "Zhiqiang Zhang", "Glen Cooper", "Zhenhong Li"], "title": "Physics-Embedded Neural Networks for sEMG-based Continuous Motion Estimation", "categories": ["eess.SP", "cs.LG"], "comment": "Accepted by 2025 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS)", "summary": "Accurately decoding human motion intentions from surface electromyography\n(sEMG) is essential for myoelectric control and has wide applications in\nrehabilitation robotics and assistive technologies. However, existing\nsEMG-based motion estimation methods often rely on subject-specific\nmusculoskeletal (MSK) models that are difficult to calibrate, or purely\ndata-driven models that lack physiological consistency. This paper introduces a\nnovel Physics-Embedded Neural Network (PENN) that combines interpretable MSK\nforward-dynamics with data-driven residual learning, thereby preserving\nphysiological consistency while achieving accurate motion estimation. The PENN\nemploys a recursive temporal structure to propagate historical estimates and a\nlightweight convolutional neural network for residual correction, leading to\nrobust and temporally coherent estimations. A two-phase training strategy is\ndesigned for PENN. Experimental evaluations on six healthy subjects show that\nPENN outperforms state-of-the-art baseline methods in both root mean square\nerror (RMSE) and $R^2$ metrics."}
{"id": "2506.22463", "pdf": "https://arxiv.org/pdf/2506.22463", "abs": "https://arxiv.org/abs/2506.22463", "authors": ["Weizhi Gao", "Zhichao Hou", "Junqi Yin", "Feiyi Wang", "Linyu Peng", "Xiaorui Liu"], "title": "Modulated Diffusion: Accelerating Generative Modeling with Modulated Quantization", "categories": ["cs.CV", "cs.LG"], "comment": "26 pages, accepted by ICML 2025", "summary": "Diffusion models have emerged as powerful generative models, but their high\ncomputation cost in iterative sampling remains a significant bottleneck. In\nthis work, we present an in-depth and insightful study of state-of-the-art\nacceleration techniques for diffusion models, including caching and\nquantization, revealing their limitations in computation error and generation\nquality. To break these limits, this work introduces Modulated Diffusion\n(MoDiff), an innovative, rigorous, and principled framework that accelerates\ngenerative modeling through modulated quantization and error compensation.\nMoDiff not only inherents the advantages of existing caching and quantization\nmethods but also serves as a general framework to accelerate all diffusion\nmodels. The advantages of MoDiff are supported by solid theoretical insight and\nanalysis. In addition, extensive experiments on CIFAR-10 and LSUN demonstrate\nthat MoDiff significant reduces activation quantization from 8 bits to 3 bits\nwithout performance degradation in post-training quantization (PTQ). Our code\nimplementation is available at https://github.com/WeizhiGao/MoDiff."}
{"id": "2506.22476", "pdf": "https://arxiv.org/pdf/2506.22476", "abs": "https://arxiv.org/abs/2506.22476", "authors": ["A. Subedi", "S. De", "L. Cavuoto", "S. Schwaitzberg", "M. Hackett", "J. Norfleet"], "title": "An Interpretable Transformer-Based Foundation Model for Cross-Procedural Skill Assessment Using Raw fNIRS Signals", "categories": ["eess.SP", "cs.ET", "cs.HC", "cs.LG", "q-bio.NC", "I.2.6; J.3; H.1.2"], "comment": null, "summary": "Objective skill assessment in high-stakes procedural environments requires\nmodels that not only decode underlying cognitive and motor processes but also\ngeneralize across tasks, individuals, and experimental contexts. While prior\nwork has demonstrated the potential of functional near-infrared spectroscopy\n(fNIRS) for evaluating cognitive-motor performance, existing approaches are\noften task-specific, rely on extensive preprocessing, and lack robustness to\nnew procedures or conditions. Here, we introduce an interpretable\ntransformer-based foundation model trained on minimally processed fNIRS signals\nfor cross-procedural skill assessment. Pretrained using self-supervised\nlearning on data from laparoscopic surgical tasks and endotracheal intubation\n(ETI), the model achieves greater than 88% classification accuracy on all\ntasks, with Matthews Correlation Coefficient exceeding 0.91 on ETI. It\ngeneralizes to a novel emergency airway procedure--cricothyrotomy--using fewer\nthan 30 labeled samples and a lightweight (less than 2k parameter) adapter\nmodule, attaining an AUC greater than 87%. Interpretability is achieved via a\nnovel channel attention mechanism--developed specifically for fNIRS--that\nidentifies functionally coherent prefrontal sub-networks validated through\nablation studies. Temporal attention patterns align with task-critical phases\nand capture stress-induced changes in neural variability, offering insight into\ndynamic cognitive states."}
{"id": "2506.22479", "pdf": "https://arxiv.org/pdf/2506.22479", "abs": "https://arxiv.org/abs/2506.22479", "authors": ["Krisanu Sarkar"], "title": "Hindsight-Guided Momentum (HGM) Optimizer: An Approach to Adaptive Learning Rate", "categories": ["math.OC", "cs.AI", "cs.LG"], "comment": null, "summary": "We introduce Hindsight-Guided Momentum (HGM), a first-order optimization\nalgorithm that adaptively scales learning rates based on the directional\nconsistency of recent updates. Traditional adaptive methods, such as Adam or\nRMSprop , adapt learning dynamics using only the magnitude of gradients, often\noverlooking important geometric cues.Geometric cues refer to directional\ninformation, such as the alignment between current gradients and past updates,\nwhich reflects the local curvature and consistency of the optimization path.\nHGM addresses this by incorporating a hindsight mechanism that evaluates the\ncosine similarity between the current gradient and accumulated momentum. This\nallows it to distinguish between coherent and conflicting gradient directions,\nincreasing the learning rate when updates align and reducing it in regions of\noscillation or noise. The result is a more responsive optimizer that\naccelerates convergence in smooth regions of the loss surface while maintaining\nstability in sharper or more erratic areas. Despite this added adaptability,\nthe method preserves the computational and memory efficiency of existing\noptimizers.By more intelligently responding to the structure of the\noptimization landscape, HGM provides a simple yet effective improvement over\nexisting approaches, particularly in non-convex settings like that of deep\nneural network training."}
{"id": "2506.22480", "pdf": "https://arxiv.org/pdf/2506.22480", "abs": "https://arxiv.org/abs/2506.22480", "authors": ["Mariam Yahya", "Aydin Sezgin", "Setareh Maghsudi"], "title": "Service Placement in Small Cell Networks Using Distributed Best Arm Identification in Linear Bandits", "categories": ["cs.NI", "cs.DC", "cs.LG"], "comment": null, "summary": "As users in small cell networks increasingly rely on computation-intensive\nservices, cloud-based access often results in high latency. Multi-access edge\ncomputing (MEC) mitigates this by bringing computational resources closer to\nend users, with small base stations (SBSs) serving as edge servers to enable\nlow-latency service delivery. However, limited edge capacity makes it\nchallenging to decide which services to deploy locally versus in the cloud,\nespecially under unknown service demand and dynamic network conditions. To\ntackle this problem, we model service demand as a linear function of service\nattributes and formulate the service placement task as a linear bandit problem,\nwhere SBSs act as agents and services as arms. The goal is to identify the\nservice that, when placed at the edge, offers the greatest reduction in total\nuser delay compared to cloud deployment. We propose a distributed and adaptive\nmulti-agent best-arm identification (BAI) algorithm under a fixed-confidence\nsetting, where SBSs collaborate to accelerate learning. Simulations show that\nour algorithm identifies the optimal service with the desired confidence and\nachieves near-optimal speedup, as the number of learning rounds decreases\nproportionally with the number of SBSs. We also provide theoretical analysis of\nthe algorithm's sample complexity and communication overhead."}
{"id": "2506.22488", "pdf": "https://arxiv.org/pdf/2506.22488", "abs": "https://arxiv.org/abs/2506.22488", "authors": ["Xi Fu", "Weibang Jiang", "Rui Liu", "Gernot R. Müller-Putz", "Cuntai Guan"], "title": "Zero-Shot EEG-to-Gait Decoding via Phase-Aware Representation Learning", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "Accurate decoding of lower-limb motion from EEG signals is essential for\nadvancing brain-computer interface (BCI) applications in movement intent\nrecognition and control. However, challenges persist in achieving causal,\nphase-consistent predictions and in modeling both inter- and intra-subject\nvariability. To address these issues, we propose NeuroDyGait, a\ndomain-generalizable EEG-to-motion decoding framework that leverages structured\ncontrastive representation learning and relational domain modeling. The\nproposed method employs relative contrastive learning to achieve semantic\nalignment between EEG and motion embeddings. Furthermore, a multi-cycle gait\nreconstruction objective is introduced to enforce temporal coherence and\nmaintain biomechanical consistency. To promote inter-session generalization,\nduring fine-tuning, a domain dynamic decoding mechanism adaptively assigns\nsession-specific prediction heads and learns to mix their outputs based on\ninter-session relationships. NeuroDyGait enables zero-shot motion prediction\nfor unseen individuals without requiring adaptation and achieves superior\nperformance in cross-subject gait decoding on benchmark datasets. Additionally,\nit demonstrates strong phase-detection capabilities even without explicit phase\nsupervision during training. These findings highlight the potential of\nrelational domain learning in enabling scalable, target-free deployment of\nBCIs."}
{"id": "2506.22490", "pdf": "https://arxiv.org/pdf/2506.22490", "abs": "https://arxiv.org/abs/2506.22490", "authors": ["Zhenke Duan", "Jiqun Pan", "Jiani Tu"], "title": "MENGLAN: Multiscale Enhanced Nonparametric Gas Analyzer with Lightweight Architecture and Networks", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "Accurate detection of ethylene concentrations in mixed gases is crucial in\nchemical production for safety and health purposes. Traditional methods are\nhindered by high cost and complexity, limiting their practical application.\nThis study proposes MENGLAN, a Multiscale Enhanced Nonparametric Gas Analyzer\nthat integrates a dual-stream structure, a Hybrid Multi-Head Attention\nmechanism, and a Feature Reactivation Module to enable real-time, lightweight,\nand high-precision ethylene concentration prediction. Results show that MENGLAN\nachieves superior performance, reduced computational demand, and enhanced\ndeployability compared to existing methods."}
{"id": "2506.22493", "pdf": "https://arxiv.org/pdf/2506.22493", "abs": "https://arxiv.org/abs/2506.22493", "authors": ["Sadia Kamal", "Lalu Prasad Yadav Prakash", "S M Rafiuddin", "Mohammed Rakib", "Arunkumar Bagavathi", "Atriya Sen", "Sagnik Ray Choudhury"], "title": "A Detailed Factor Analysis for the Political Compass Test: Navigating Ideologies of Large Language Models", "categories": ["cs.CY", "cs.CL", "cs.LG"], "comment": null, "summary": "Political Compass Test (PCT) or similar questionnaires have been used to\nquantify LLM's political leanings. Building on a recent line of work that\nexamines the validity of PCT tests, we demonstrate that variation in standard\ngeneration parameters does not significantly impact the models' PCT scores.\nHowever, external factors such as prompt variations and fine-tuning\nindividually and in combination affect the same. Finally, we demonstrate that\nwhen models are fine-tuned on text datasets with higher political content than\nothers, the PCT scores are not differentially affected. This calls for a\nthorough investigation into the validity of PCT and similar tests, as well as\nthe mechanism by which political leanings are encoded in LLMs."}
{"id": "2506.22494", "pdf": "https://arxiv.org/pdf/2506.22494", "abs": "https://arxiv.org/abs/2506.22494", "authors": ["Shihong Ling", "Yue Wan", "Xiaowei Jia", "Na Du"], "title": "DriveBLIP2: Attention-Guided Explanation Generation for Complex Driving Scenarios", "categories": ["cs.RO", "cs.CV", "cs.LG"], "comment": "Accepted to IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS) 2025. 7 pages, 3 figures", "summary": "This paper introduces a new framework, DriveBLIP2, built upon the BLIP2-OPT\narchitecture, to generate accurate and contextually relevant explanations for\nemerging driving scenarios. While existing vision-language models perform well\nin general tasks, they encounter difficulties in understanding complex,\nmulti-object environments, particularly in real-time applications such as\nautonomous driving, where the rapid identification of key objects is crucial.\nTo address this limitation, an Attention Map Generator is proposed to highlight\nsignificant objects relevant to driving decisions within critical video frames.\nBy directing the model's focus to these key regions, the generated attention\nmap helps produce clear and relevant explanations, enabling drivers to better\nunderstand the vehicle's decision-making process in critical situations.\nEvaluations on the DRAMA dataset reveal significant improvements in explanation\nquality, as indicated by higher BLEU, ROUGE, CIDEr, and SPICE scores compared\nto baseline models. These findings underscore the potential of targeted\nattention mechanisms in vision-language models for enhancing explainability in\nreal-time autonomous driving."}
{"id": "2506.22495", "pdf": "https://arxiv.org/pdf/2506.22495", "abs": "https://arxiv.org/abs/2506.22495", "authors": ["He-Yang Xu", "Hongxiang Gao", "Yuwen Li", "Xiu-Shen Wei", "Chengyu Liu"], "title": "Masked Autoencoders that Feel the Heart: Unveiling Simplicity Bias for ECG Analyses", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": null, "summary": "The diagnostic value of electrocardiogram (ECG) lies in its dynamic\ncharacteristics, ranging from rhythm fluctuations to subtle waveform\ndeformations that evolve across time and frequency domains. However, supervised\nECG models tend to overfit dominant and repetitive patterns, overlooking\nfine-grained but clinically critical cues, a phenomenon known as Simplicity\nBias (SB), where models favor easily learnable signals over subtle but\ninformative ones. In this work, we first empirically demonstrate the presence\nof SB in ECG analyses and its negative impact on diagnostic performance, while\nsimultaneously discovering that self-supervised learning (SSL) can alleviate\nit, providing a promising direction for tackling the bias. Following the SSL\nparadigm, we propose a novel method comprising two key components: 1)\nTemporal-Frequency aware Filters to capture temporal-frequency features\nreflecting the dynamic characteristics of ECG signals, and 2) building on this,\nMulti-Grained Prototype Reconstruction for coarse and fine representation\nlearning across dual domains, further mitigating SB. To advance SSL in ECG\nanalyses, we curate a large-scale multi-site ECG dataset with 1.53 million\nrecordings from over 300 clinical centers. Experiments on three downstream\ntasks across six ECG datasets demonstrate that our method effectively reduces\nSB and achieves state-of-the-art performance. Code and dataset will be released\npublicly."}
{"id": "2506.22503", "pdf": "https://arxiv.org/pdf/2506.22503", "abs": "https://arxiv.org/abs/2506.22503", "authors": ["Michiel Schepers", "Pieter Robberechts", "Jan Van Haaren", "Jesse Davis"], "title": "What Makes a Dribble Successful? Insights From 3D Pose Tracking Data", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Data analysis plays an increasingly important role in soccer, offering new\nways to evaluate individual and team performance. One specific application is\nthe evaluation of dribbles: one-on-one situations where an attacker attempts to\nbypass a defender with the ball. While previous research has primarily relied\non 2D positional tracking data, this fails to capture aspects like balance,\norientation, and ball control, limiting the depth of current insights. This\nstudy explores how pose tracking data (capturing players' posture and movement\nin three dimensions) can improve our understanding of dribbling skills. We\nextract novel pose-based features from 1,736 dribbles in the 2022/23 Champions\nLeague season and evaluate their impact on dribble success. Our results\nindicate that features capturing the attacker's balance and the alignment of\nthe orientation between the attacker and defender are informative for\npredicting dribble success. Incorporating these pose-based features on top of\nfeatures derived from traditional 2D positional data leads to a measurable\nimprovement in model performance."}
{"id": "2506.22504", "pdf": "https://arxiv.org/pdf/2506.22504", "abs": "https://arxiv.org/abs/2506.22504", "authors": ["Hassan Baker", "Austin J. Brockmeier"], "title": "Patch2Loc: Learning to Localize Patches for Unsupervised Brain Lesion Detection", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Detecting brain lesions as abnormalities observed in magnetic resonance\nimaging (MRI) is essential for diagnosis and treatment. In the search of\nabnormalities, such as tumors and malformations, radiologists may benefit from\ncomputer-aided diagnostics that use computer vision systems trained with\nmachine learning to segment normal tissue from abnormal brain tissue. While\nsupervised learning methods require annotated lesions, we propose a new\nunsupervised approach (Patch2Loc) that learns from normal patches taken from\nstructural MRI. We train a neural network model to map a patch back to its\nspatial location within a slice of the brain volume. During inference, abnormal\npatches are detected by the relatively higher error and/or variance of the\nlocation prediction. This generates a heatmap that can be integrated into\npixel-wise methods to achieve finer-grained segmentation. We demonstrate the\nability of our model to segment abnormal brain tissues by applying our approach\nto the detection of tumor tissues in MRI on T2-weighted images from BraTS2021\nand MSLUB datasets and T1-weighted images from ATLAS and WMH datasets. We show\nthat it outperforms the state-of-the art in unsupervised segmentation. The\ncodebase for this work can be found on our\n\\href{https://github.com/bakerhassan/Patch2Loc}{GitHub page}."}
{"id": "2506.22505", "pdf": "https://arxiv.org/pdf/2506.22505", "abs": "https://arxiv.org/abs/2506.22505", "authors": ["Hassan Baker", "Matthew S. Emigh", "Austin J. Brockmeier"], "title": "Weakly Supervised Object Segmentation by Background Conditional Divergence", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "As a computer vision task, automatic object segmentation remains challenging\nin specialized image domains without massive labeled data, such as synthetic\naperture sonar images, remote sensing, biomedical imaging, etc. In any domain,\nobtaining pixel-wise segmentation masks is expensive. In this work, we propose\na method for training a masking network to perform binary object segmentation\nusing weak supervision in the form of image-wise presence or absence of an\nobject of interest, which provides less information but may be obtained more\nquickly from manual or automatic labeling. A key step in our method is that the\nsegmented objects can be placed into background-only images to create\nrealistic, images of the objects with counterfactual backgrounds. To create a\ncontrast between the original and counterfactual background images, we propose\nto first cluster the background-only images, and then during learning create\ncounterfactual images that blend objects segmented from their original source\nbackgrounds to backgrounds chosen from a targeted cluster. One term in the\ntraining loss is the divergence between these counterfactual images and the\nreal object images with backgrounds of the target cluster. The other term is a\nsupervised loss for background-only images. While an adversarial critic could\nprovide the divergence, we use sample-based divergences. We conduct experiments\non side-scan and synthetic aperture sonar in which our approach succeeds\ncompared to previous unsupervised segmentation baselines that were only tested\non natural images. Furthermore, to show generality we extend our experiments to\nnatural images, obtaining reasonable performance with our method that avoids\npretrained networks, generative networks, and adversarial critics. The basecode\nfor this work can be found at\n\\href{GitHub}{https://github.com/bakerhassan/WSOS}."}
{"id": "2506.22532", "pdf": "https://arxiv.org/pdf/2506.22532", "abs": "https://arxiv.org/abs/2506.22532", "authors": ["Mark Wrobel", "Michele Pascale", "Tina Yao", "Ruaraidh Campbell", "Elena Milano", "Michael Quail", "Jennifer Steeden", "Vivek Muthurangu"], "title": "High Resolution Isotropic 3D Cine imaging with Automated Segmentation using Concatenated 2D Real-time Imaging and Deep Learning", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": null, "summary": "Background: Conventional cardiovascular magnetic resonance (CMR) in\npaediatric and congenital heart disease uses 2D, breath-hold, balanced steady\nstate free precession (bSSFP) cine imaging for assessment of function and\ncardiac-gated, respiratory-navigated, static 3D bSSFP whole-heart imaging for\nanatomical assessment. Our aim is to concatenate a stack 2D free-breathing\nreal-time cines and use Deep Learning (DL) to create an isotropic a fully\nsegmented 3D cine dataset from these images. Methods: Four DL models were\ntrained on open-source data that performed: a) Interslice contrast correction;\nb) Interslice respiratory motion correction; c) Super-resolution (slice\ndirection); and d) Segmentation of right and left atria and ventricles (RA, LA,\nRV, and LV), thoracic aorta (Ao) and pulmonary arteries (PA). In 10 patients\nundergoing routine cardiovascular examination, our method was validated on\nprospectively acquired sagittal stacks of real-time cine images. Quantitative\nmetrics (ventricular volumes and vessel diameters) and image quality of the 3D\ncines were compared to conventional breath hold cine and whole heart imaging.\nResults: All real-time data were successfully transformed into 3D cines with a\ntotal post-processing time of <1 min in all cases. There were no significant\nbiases in any LV or RV metrics with reasonable limits of agreement and\ncorrelation. There is also reasonable agreement for all vessel diameters,\nalthough there was a small but significant overestimation of RPA diameter.\nConclusion: We have demonstrated the potential of creating a 3D-cine data from\nconcatenated 2D real-time cine images using a series of DL models. Our method\nhas short acquisition and reconstruction times with fully segmented data being\navailable within 2 minutes. The good agreement with conventional imaging\nsuggests that our method could help to significantly speed up CMR in clinical\npractice."}
{"id": "2506.22536", "pdf": "https://arxiv.org/pdf/2506.22536", "abs": "https://arxiv.org/abs/2506.22536", "authors": ["Yu Zhang", "Shanshan Zhao", "Bokui Wan", "Jinjuan Wang", "Xiaodong Yan"], "title": "Strategic A/B testing via Maximum Probability-driven Two-armed Bandit", "categories": ["stat.ML", "cs.LG", "math.PR"], "comment": "25 pages, 14 figures", "summary": "Detecting a minor average treatment effect is a major challenge in\nlarge-scale applications, where even minimal improvements can have a\nsignificant economic impact. Traditional methods, reliant on normal\ndistribution-based or expanded statistics, often fail to identify such minor\neffects because of their inability to handle small discrepancies with\nsufficient sensitivity. This work leverages a counterfactual outcome framework\nand proposes a maximum probability-driven two-armed bandit (TAB) process by\nweighting the mean volatility statistic, which controls Type I error. The\nimplementation of permutation methods further enhances the robustness and\nefficacy. The established strategic central limit theorem (SCLT) demonstrates\nthat our approach yields a more concentrated distribution under the null\nhypothesis and a less concentrated one under the alternative hypothesis,\ngreatly improving statistical power. The experimental results indicate a\nsignificant improvement in the A/B testing, highlighting the potential to\nreduce experimental costs while maintaining high statistical power."}
{"id": "2506.22552", "pdf": "https://arxiv.org/pdf/2506.22552", "abs": "https://arxiv.org/abs/2506.22552", "authors": ["Fabrizio Falasca"], "title": "Neural models of multiscale systems: conceptual limitations, stochastic parametrizations, and a climate application", "categories": ["nlin.CD", "cond-mat.stat-mech", "cs.LG", "physics.ao-ph"], "comment": null, "summary": "This work explores key conceptual limitations in data-driven modeling of\nmultiscale dynamical systems, focusing on neural emulators and stochastic\nclimate modeling. A skillful climate model should capture both stationary\nstatistics and responses to external perturbations. While current\nautoregressive neural models often reproduce the former, they typically\nstruggle with the latter. We begin by analyzing a low-dimensional dynamical\nsystem to expose, by analogy, fundamental limitations that persist in\nhigh-dimensional settings. Specifically, we construct neural stochastic models\nunder two scenarios: one where the full state vector is observed, and another\nwith only partial observations (i.e. a subset of variables). In the first case,\nthe models accurately capture both equilibrium statistics and forced responses\nin ensemble mean and variance. In the more realistic case of partial\nobservations, two key challenges emerge: (i) identifying the \\textit{proper}\nvariables to model, and (ii) parameterizing the influence of unobserved degrees\nof freedom. These issues are not specific to neural networks but reflect\nfundamental limitations of data-driven modeling and the need to target the slow\ndynamics of the system. We argue that physically grounded strategies -- such as\ncoarse-graining and stochastic parameterizations -- are critical, both\nconceptually and practically, for the skillful emulation of complex systems\nlike the coupled climate system. Building on these insights, we turn to a more\nrealistic application: a stochastic reduced neural model of the sea surface\ntemperature field and the net radiative flux at the top of the atmosphere,\nassessing its stationary statistics, response to temperature forcing, and\ninterpretability."}
{"id": "2506.22555", "pdf": "https://arxiv.org/pdf/2506.22555", "abs": "https://arxiv.org/abs/2506.22555", "authors": ["Callum Duffy", "Marcin Jastrzebski"], "title": "Spectral Bias in Variational Quantum Machine Learning", "categories": ["quant-ph", "cs.LG"], "comment": "12 pages, 8 figures", "summary": "In this work, we investigate the phenomenon of spectral bias in quantum\nmachine learning, where, in classical settings, models tend to fit\nlow-frequency components of a target function earlier during training than\nhigh-frequency ones, demonstrating a frequency-dependent rate of convergence.\nWe study this effect specifically in parameterised quantum circuits (PQCs).\nLeveraging the established formulation of PQCs as Fourier series, we prove that\nspectral bias in this setting arises from the ``redundancy'' of the Fourier\ncoefficients, which denotes the number of terms in the analytical form of the\nmodel contributing to the same frequency component. The choice of data encoding\nscheme dictates the degree of redundancy for a Fourier coefficient. We find\nthat the magnitude of the Fourier coefficients' gradients during training\nstrongly correlates with the coefficients' redundancy. We then further\ndemonstrate this empirically with three different encoding schemes.\nAdditionally, we demonstrate that PQCs with greater redundancy exhibit\nincreased robustness to random perturbations in their parameters at the\ncorresponding frequencies. We investigate how design choices affect the ability\nof PQCs to learn Fourier sums, focusing on parameter initialization scale and\nentanglement structure, finding large initializations and low-entanglement\nschemes tend to slow convergence."}
{"id": "2506.22557", "pdf": "https://arxiv.org/pdf/2506.22557", "abs": "https://arxiv.org/abs/2506.22557", "authors": ["Boyuan Chen", "Minghao Shao", "Abdul Basit", "Siddharth Garg", "Muhammad Shafique"], "title": "MetaCipher: A General and Extensible Reinforcement Learning Framework for Obfuscation-Based Jailbreak Attacks on Black-Box LLMs", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "The growing capabilities of large language models (LLMs) have exposed them to\nincreasingly sophisticated jailbreak attacks. Among these, obfuscation-based\nattacks -- which encrypt malicious content to evade detection -- remain highly\neffective. By leveraging the reasoning ability of advanced LLMs to interpret\nencrypted prompts, such attacks circumvent conventional defenses that rely on\nkeyword detection or context filtering. These methods are very difficult to\ndefend against, as existing safety mechanisms are not designed to interpret or\ndecode ciphered content. In this work, we propose \\textbf{MetaCipher}, a novel\nobfuscation-based jailbreak framework, along with a reinforcement\nlearning-based dynamic cipher selection mechanism that adaptively chooses\noptimal encryption strategies from a cipher pool. This approach enhances\njailbreak effectiveness and generalizability across diverse task types, victim\nLLMs, and safety guardrails. Our framework is modular and extensible by design,\nsupporting arbitrary cipher families and accommodating evolving adversarial\nstrategies. We complement our method with a large-scale empirical analysis of\ncipher performance across multiple victim LLMs. Within as few as 10 queries,\nMetaCipher achieves over 92\\% attack success rate (ASR) on most recent standard\nmalicious prompt benchmarks against state-of-the-art non-reasoning LLMs, and\nover 74\\% ASR against reasoning-capable LLMs, outperforming all existing\nobfuscation-based jailbreak methods. These results highlight the long-term\nrobustness and adaptability of our approach, making it more resilient than\nprior methods in the face of advancing safety measures."}
{"id": "2506.22565", "pdf": "https://arxiv.org/pdf/2506.22565", "abs": "https://arxiv.org/abs/2506.22565", "authors": ["Guan-Horng Liu", "Jaemoo Choi", "Yongxin Chen", "Benjamin Kurt Miller", "Ricky T. Q. Chen"], "title": "Adjoint Schrödinger Bridge Sampler", "categories": ["stat.ML", "cs.LG", "math.OC"], "comment": null, "summary": "Computational methods for learning to sample from the Boltzmann distribution\n-- where the target distribution is known only up to an unnormalized energy\nfunction -- have advanced significantly recently. Due to the lack of explicit\ntarget samples, however, prior diffusion-based methods, known as diffusion\nsamplers, often require importance-weighted estimation or complicated learning\nprocesses. Both trade off scalability with extensive evaluations of the energy\nand model, thereby limiting their practical usage. In this work, we propose\nAdjoint Schr\\\"odinger Bridge Sampler (ASBS), a new diffusion sampler that\nemploys simple and scalable matching-based objectives yet without the need to\nestimate target samples during training. ASBS is grounded on a mathematical\nmodel -- the Schr\\\"odinger Bridge -- which enhances sampling efficiency via\nkinetic-optimal transportation. Through a new lens of stochastic optimal\ncontrol theory, we demonstrate how SB-based diffusion samplers can be learned\nat scale via Adjoint Matching and prove convergence to the global solution.\nNotably, ASBS generalizes the recent Adjoint Sampling (Havens et al., 2025) to\narbitrary source distributions by relaxing the so-called memoryless condition\nthat largely restricts the design space. Through extensive experiments, we\ndemonstrate the effectiveness of ASBS on sampling from classical energy\nfunctions, amortized conformer generation, and molecular Boltzmann\ndistributions."}
{"id": "2506.22606", "pdf": "https://arxiv.org/pdf/2506.22606", "abs": "https://arxiv.org/abs/2506.22606", "authors": ["Osama Zafar", "Mina Namazi", "Yuqiao Xu", "Youngjin Yoo", "Erman Ayday"], "title": "A User-Centric, Privacy-Preserving, and Verifiable Ecosystem for Personal Data Management and Utilization", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "In the current paradigm of digital personalized services, the centralized\nmanagement of personal data raises significant privacy concerns, security\nvulnerabilities, and diminished individual autonomy over sensitive information.\nDespite their efficiency, traditional centralized architectures frequently fail\nto satisfy rigorous privacy requirements and expose users to data breaches and\nunauthorized access risks. This pressing challenge calls for a fundamental\nparadigm shift in methodologies for collecting, storing, and utilizing personal\ndata across diverse sectors, including education, healthcare, and finance.\n  This paper introduces a novel decentralized, privacy-preserving architecture\nthat handles heterogeneous personal information, ranging from educational\ncredentials to health records and financial data. Unlike traditional models,\nour system grants users complete data ownership and control, allowing them to\nselectively share information without compromising privacy. The architecture's\nfoundation comprises advanced privacy-enhancing technologies, including secure\nenclaves and federated learning, enabling secure computation, verification, and\ndata sharing. The system supports diverse functionalities, including local\ncomputation, model training, and privacy-preserving data sharing, while\nensuring data credibility and robust user privacy."}
{"id": "2506.22607", "pdf": "https://arxiv.org/pdf/2506.22607", "abs": "https://arxiv.org/abs/2506.22607", "authors": ["Daniel Ciganda", "Ignacio Campón", "Iñaki Permanyer", "Jakob H Macke"], "title": "Learning Individual Reproductive Behavior from Aggregate Fertility Rates via Neural Posterior Estimation", "categories": ["stat.AP", "cs.LG"], "comment": null, "summary": "While age-specific fertility rates (ASFRs) provide the most extensive record\nof reproductive change, their aggregate nature masks the underlying behavioral\nmechanisms that ultimately drive fertility trends. To recover these mechanisms,\nwe develop a likelihood-free Bayesian framework that couples an\nindividual-level model of the reproductive process with Sequential Neural\nPosterior Estimation (SNPE). This allows us to infer eight behavioral and\nbiological parameters from just two aggregate series: ASFRs and the age-profile\nof planned versus unplanned births. Applied to U.S. National Survey of Family\nGrowth cohorts and to Demographic and Health Survey cohorts from Colombia, the\nDominican Republic, and Peru, the method reproduces observed fertility\nschedules and, critically, predicts out-of-sample micro-level distributions of\nage at first sex, inter-birth intervals, and family-size ideals, none of which\ninform the estimation step. Because the fitted model yields complete synthetic\nlife histories, it enables behaviorally explicit population forecasts and\nsupports the construction of demographic digital twins."}
{"id": "2506.22611", "pdf": "https://arxiv.org/pdf/2506.22611", "abs": "https://arxiv.org/abs/2506.22611", "authors": ["Yuming Ma"], "title": "Deep Hedging to Manage Tail Risk", "categories": ["q-fin.PM", "cs.LG", "math.OC", "q-fin.CP", "q-fin.RM", "91G70 91G20 91G60"], "comment": "59 pages", "summary": "Extending Buehler et al.'s 2019 Deep Hedging paradigm, we innovatively employ\ndeep neural networks to parameterize convex-risk minimization (CVaR/ES) for the\nportfolio tail-risk hedging problem. Through comprehensive numerical\nexperiments on crisis-era bootstrap market simulators -- customizable with\ntransaction costs, risk budgets, liquidity constraints, and market impact --\nour end-to-end framework not only achieves significant one-day 99% CVaR\nreduction but also yields practical insights into friction-aware strategy\nadaptation, demonstrating robustness and operational viability in realistic\nmarkets."}
{"id": "2506.22641", "pdf": "https://arxiv.org/pdf/2506.22641", "abs": "https://arxiv.org/abs/2506.22641", "authors": ["Gabriel M. Mejia", "Henry E. Miller", "Francis J. A. Leblanc", "Bo Wang", "Brendan Swain", "Lucas Paulo de Lima Camillo"], "title": "Diversity by Design: Addressing Mode Collapse Improves scRNA-seq Perturbation Modeling on Well-Calibrated Metrics", "categories": ["q-bio.GN", "cs.LG", "q-bio.MN", "stat.ML"], "comment": null, "summary": "Recent benchmarks reveal that models for single-cell perturbation response\nare often outperformed by simply predicting the dataset mean. We trace this\nanomaly to a metric artifact: control-referenced deltas and unweighted error\nmetrics reward mode collapse whenever the control is biased or the biological\nsignal is sparse. Large-scale \\textit{in silico} simulations and analysis of\ntwo real-world perturbation datasets confirm that shared reference shifts, not\ngenuine biological change, drives high performance in these evaluations. We\nintroduce differentially expressed gene (DEG)-aware metrics, weighted\nmean-squared error (WMSE) and weighted delta $R^{2}$ ($R^{2}_{w}(\\Delta)$) with\nrespect to all perturbations, that measure error in niche signals with high\nsensitivity. We further introduce negative and positive performance baselines\nto calibrate these metrics. With these improvements, the mean baseline sinks to\nnull performance while genuine predictors are correctly rewarded. Finally, we\nshow that using WMSE as a loss function reduces mode collapse and improves\nmodel performance."}
{"id": "2506.22648", "pdf": "https://arxiv.org/pdf/2506.22648", "abs": "https://arxiv.org/abs/2506.22648", "authors": ["Pedro R. Pires", "Tiago A. Almeida"], "title": "Interact2Vec -- An efficient neural network-based model for simultaneously learning users and items embeddings in recommender systems", "categories": ["cs.IR", "cs.LG"], "comment": "Accepted for publication in Applied Soft Computing (ASOC), 49 pages,\n  14 figures", "summary": "Over the past decade, recommender systems have experienced a surge in\npopularity. Despite notable progress, they grapple with challenging issues,\nsuch as high data dimensionality and sparseness. Representing users and items\nas low-dimensional embeddings learned via neural networks has become a leading\nsolution. However, while recent studies show promising results, many approaches\nrely on complex architectures or require content data, which may not always be\navailable. This paper presents Interact2Vec, a novel neural network-based model\nthat simultaneously learns distributed embeddings for users and items while\ndemanding only implicit feedback. The model employs state-of-the-art strategies\nthat natural language processing models commonly use to optimize the training\nphase and enhance the final embeddings. Two types of experiments were conducted\nregarding the extrinsic and intrinsic quality of the model. In the former, we\nbenchmarked the recommendations generated by Interact2Vec's embeddings in a\ntop-$N$ ranking problem, comparing them with six other recommender algorithms.\nThe model achieved the second or third-best results in 30\\% of the datasets,\nbeing competitive with other recommenders, and has proven to be very efficient\nwith an average training time reduction of 274\\% compared to other\nembedding-based models. Later, we analyzed the intrinsic quality of the\nembeddings through similarity tables. Our findings suggest that Interact2Vec\ncan achieve promising results, especially on the extrinsic task, and is an\nexcellent embedding-generator model for scenarios of scarce computing\nresources, enabling the learning of item and user embeddings simultaneously and\nefficiently."}
{"id": "2506.22666", "pdf": "https://arxiv.org/pdf/2506.22666", "abs": "https://arxiv.org/abs/2506.22666", "authors": ["Anamika Lochab", "Lu Yan", "Patrick Pynadath", "Xiangyu Zhang", "Ruqi Zhang"], "title": "VERA: Variational Inference Framework for Jailbreaking Large Language Models", "categories": ["cs.CR", "cs.CL", "cs.LG", "stat.ML"], "comment": null, "summary": "The rise of API-only access to state-of-the-art LLMs highlights the need for\neffective black-box jailbreak methods to identify model vulnerabilities in\nreal-world settings. Without a principled objective for gradient-based\noptimization, most existing approaches rely on genetic algorithms, which are\nlimited by their initialization and dependence on manually curated prompt\npools. Furthermore, these methods require individual optimization for each\nprompt, failing to provide a comprehensive characterization of model\nvulnerabilities. To address this gap, we introduce VERA: Variational infErence\nfRamework for jAilbreaking. VERA casts black-box jailbreak prompting as a\nvariational inference problem, training a small attacker LLM to approximate the\ntarget LLM's posterior over adversarial prompts. Once trained, the attacker can\ngenerate diverse, fluent jailbreak prompts for a target query without\nre-optimization. Experimental results show that VERA achieves strong\nperformance across a range of target LLMs, highlighting the value of\nprobabilistic inference for adversarial prompt generation."}
{"id": "2506.22675", "pdf": "https://arxiv.org/pdf/2506.22675", "abs": "https://arxiv.org/abs/2506.22675", "authors": ["Luhuan Wu", "Mingzhang Yin", "Yixin Wang", "John P. Cunningham", "David M. Blei"], "title": "Bayesian Invariance Modeling of Multi-Environment Data", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Invariant prediction [Peters et al., 2016] analyzes feature/outcome data from\nmultiple environments to identify invariant features - those with a stable\npredictive relationship to the outcome. Such features support generalization to\nnew environments and help reveal causal mechanisms. Previous methods have\nprimarily tackled this problem through hypothesis testing or regularized\noptimization. Here we develop Bayesian Invariant Prediction (BIP), a\nprobabilistic model for invariant prediction. BIP encodes the indices of\ninvariant features as a latent variable and recover them by posterior\ninference. Under the assumptions of Peters et al. [2016], the BIP posterior\ntargets the true invariant features. We prove that the posterior is consistent\nand that greater environment heterogeneity leads to faster posterior\ncontraction. To handle many features, we design an efficient variational\napproximation called VI-BIP. In simulations and real data, we find that BIP and\nVI-BIP are more accurate and scalable than existing methods for invariant\nprediction."}
{"id": "2506.22701", "pdf": "https://arxiv.org/pdf/2506.22701", "abs": "https://arxiv.org/abs/2506.22701", "authors": ["Shi Jie Yu"], "title": "Lower bounds for trace estimation via Block Krylov and other methods", "categories": ["math.ST", "cs.DS", "cs.LG", "cs.NA", "math.NA", "stat.TH"], "comment": null, "summary": "This paper studies theoretical lower bounds for estimating the trace of a\nmatrix function, $\\text{tr}(f(A))$, focusing on methods that use Hutchinson's\nmethod along with Block Krylov techniques. These methods work by approximating\nmatrix-vector products like $f(A)V$ using a Block Krylov subspace. This is\nclosely related to approximating functions with polynomials. We derive\ntheoretical upper bounds on how many Krylov steps are needed for functions such\nas $A^{-1/2}$ and $A^{-1}$ by analyzing the upper bounds from the polynomial\napproximation of their scalar equivalent. In addition, we also develop lower\nlimits on the number of queries needed for trace estimation, specifically for\n$\\text{tr}(W^{-p})$ where $W$ is a Wishart matrix. Our study clarifies the\nconnection between the number of steps in Block Krylov methods and the degree\nof the polynomial used for approximation. This links the total cost of trace\nestimation to basic limits in polynomial approximation and how much information\nis needed for the computation."}
{"id": "2506.22714", "pdf": "https://arxiv.org/pdf/2506.22714", "abs": "https://arxiv.org/abs/2506.22714", "authors": ["Jinliang Shi", "Shigang Li", "Youxuan Xu", "Xueying Wang", "Rongtian Fu", "Zhi Ma", "Tong Wu"], "title": "Libra: Synergizing CUDA and Tensor Cores for High-Performance Sparse Matrix Multiplication", "categories": ["cs.DC", "cs.LG", "cs.PF", "C.1.4; I.2.11"], "comment": null, "summary": "Sparse matrix multiplication operators (i.e., SpMM and SDDMM) are widely used\nin deep learning and scientific computing. Modern accelerators are commonly\nequipped with Tensor cores and CUDA cores to accelerate sparse operators. The\nformer brings superior computing power but only for structured matrix\nmultiplication, while the latter has relatively lower performance but with\nhigher programming flexibility. In this work, we discover that utilizing one\nresource alone leads to inferior performance for sparse matrix multiplication,\ndue to their respective limitations. To this end, we propose Libra, a\nsystematic approach that enables synergistic computation between CUDA and\nTensor cores to achieve the best performance for sparse matrix multiplication.\nSpecifically, we propose a 2D-aware workload distribution strategy to find out\nthe sweet point of task mapping for different sparse operators, leveraging both\nthe high performance of Tensor cores and the low computational redundancy on\nCUDA cores. In addition, Libra incorporates systematic optimizations for\nheterogeneous computing, including hybrid load-balancing, finely optimized\nkernel implementations, and GPU-accelerated preprocessing. Extensive\nexperimental results on H100 and RTX 4090 GPUs show that Libra outperforms the\nstate-of-the-art by on average 3.1x (up to 9.23x) over DTC-SpMM and 2.9x (up to\n3.9x) for end-to-end GNN applications. Libra opens up a new perspective for\nsparse operator acceleration by fully exploiting the heterogeneous computing\nresources on GPUs."}
{"id": "2506.22726", "pdf": "https://arxiv.org/pdf/2506.22726", "abs": "https://arxiv.org/abs/2506.22726", "authors": ["Yu Zhang", "Xi Zhang", "Hualin zhou", "Xinyuan Chen", "Shang Gao", "Hong Jia", "Jianfei Yang", "Yuankai Qi", "Tao Gu"], "title": "XTransfer: Cross-Modality Model Transfer for Human Sensing with Few Data at the Edge", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Deep learning for human sensing on edge systems offers significant\nopportunities for smart applications. However, its training and development are\nhindered by the limited availability of sensor data and resource constraints of\nedge systems. Current methods that rely on transferring pre-trained models\noften encounter issues such as modality shift and high resource demands,\nresulting in substantial accuracy loss, resource overhead, and poor\nadaptability across different sensing applications. In this paper, we propose\nXTransfer, a first-of-its-kind method for resource-efficient, modality-agnostic\nmodel transfer. XTransfer freely leverages single or multiple pre-trained\nmodels and transfers knowledge across different modalities by (i) model\nrepairing that safely repairs modality shift in pre-trained model layers with\nonly few sensor data, and (ii) layer recombining that efficiently searches and\nrecombines layers of interest from source models in a layer-wise manner to\ncreate compact models. We benchmark various baselines across diverse human\nsensing datasets spanning different modalities. Comprehensive results\ndemonstrate that XTransfer achieves state-of-the-art performance on human\nsensing tasks while significantly reducing the costs of sensor data collection,\nmodel training, and edge deployment."}
{"id": "2506.22729", "pdf": "https://arxiv.org/pdf/2506.22729", "abs": "https://arxiv.org/abs/2506.22729", "authors": ["Honglin Bao", "Kai Li"], "title": "Persistence Paradox in Dynamic Science", "categories": ["cs.DL", "cs.CY", "cs.LG"], "comment": null, "summary": "Persistence is often regarded as a virtue in science. In this paper, however,\nwe challenge this conventional view by highlighting its contextual nature,\nparticularly how persistence can become a liability during periods of paradigm\nshift. We focus on the deep learning revolution catalyzed by AlexNet in 2012.\nAnalyzing the 20-year career trajectories of over 5,000 scientists who were\nactive in top machine learning venues during the preceding decade, we examine\nhow their research focus and output evolved. We first uncover a dynamic period\nin which leading venues increasingly prioritized cutting-edge deep learning\ndevelopments that displaced relatively traditional statistical learning\nmethods. Scientists responded to these changes in markedly different ways.\nThose who were previously successful or affiliated with old teams adapted more\nslowly, experiencing what we term a rigidity penalty - a reluctance to embrace\nnew directions leading to a decline in scientific impact, as measured by\ncitation percentile rank. In contrast, scientists who pursued strategic\nadaptation - selectively pivoting toward emerging trends while preserving weak\nconnections to prior expertise - reaped the greatest benefits. Taken together,\nour macro- and micro-level findings show that scientific breakthroughs act as\nmechanisms that reconfigure power structures within a field."}
{"id": "2506.22763", "pdf": "https://arxiv.org/pdf/2506.22763", "abs": "https://arxiv.org/abs/2506.22763", "authors": ["Fiona Xiao Jingyi", "Lili Liu"], "title": "Can We Reliably Predict the Fed's Next Move? A Multi-Modal Approach to U.S. Monetary Policy Forecasting", "categories": ["q-fin.PM", "cs.LG", "q-fin.CP"], "comment": "9 pages, 15 figures", "summary": "Forecasting central bank policy decisions remains a persistent challenge for\ninvestors, financial institutions, and policymakers due to the wide-reaching\nimpact of monetary actions. In particular, anticipating shifts in the U.S.\nfederal funds rate is vital for risk management and trading strategies.\nTraditional methods relying only on structured macroeconomic indicators often\nfall short in capturing the forward-looking cues embedded in central bank\ncommunications.\n  This study examines whether predictive accuracy can be enhanced by\nintegrating structured data with unstructured textual signals from Federal\nReserve communications. We adopt a multi-modal framework, comparing traditional\nmachine learning models, transformer-based language models, and deep learning\narchitectures in both unimodal and hybrid settings.\n  Our results show that hybrid models consistently outperform unimodal\nbaselines. The best performance is achieved by combining TF-IDF features of\nFOMC texts with economic indicators in an XGBoost classifier, reaching a test\nAUC of 0.83. FinBERT-based sentiment features marginally improve ranking but\nperform worse in classification, especially under class imbalance. SHAP\nanalysis reveals that sparse, interpretable features align more closely with\npolicy-relevant signals.\n  These findings underscore the importance of integrating textual and\nstructured signals transparently. For monetary policy forecasting, simpler\nhybrid models can offer both accuracy and interpretability, delivering\nactionable insights for researchers and decision-makers."}
{"id": "2506.22773", "pdf": "https://arxiv.org/pdf/2506.22773", "abs": "https://arxiv.org/abs/2506.22773", "authors": ["Yanran Wu", "Inez Hua", "Yi Ding"], "title": "Not All Water Consumption Is Equal: A Water Stress Weighted Metric for Sustainable Computing", "categories": ["cs.DC", "cs.AR", "cs.CY", "cs.LG"], "comment": "7 pages, 9 figures, HotCarbon '25: Proceedings of the 4th Workshop on\n  Sustainable Computer Systems, Cambridge, Massachusetts (USA), July 10-11th,\n  2025", "summary": "Water consumption is an increasingly critical dimension of computing\nsustainability, especially as AI workloads rapidly scale. However, current\nwater impact assessment often overlooks where and when water stress is more\nsevere. To fill in this gap, we present SCARF, the first general framework that\nevaluates water impact of computing by factoring in both spatial and temporal\nvariations in water stress. SCARF calculates an Adjusted Water Impact (AWI)\nmetric that considers both consumption volume and local water stress over time.\nThrough three case studies on LLM serving, datacenters, and semiconductor\nfabrication plants, we show the hidden opportunities for reducing water impact\nby optimizing location and time choices, paving the way for water-sustainable\ncomputing. The code is available at https://github.com/jojacola/SCARF."}
{"id": "2506.22799", "pdf": "https://arxiv.org/pdf/2506.22799", "abs": "https://arxiv.org/abs/2506.22799", "authors": ["Minchao Jiang", "Shunyu Jia", "Jiaming Gu", "Xiaoyuan Lu", "Guangming Zhu", "Anqi Dong", "Liang Zhang"], "title": "VoteSplat: Hough Voting Gaussian Splatting for 3D Scene Understanding", "categories": ["cs.GR", "cs.CV", "cs.LG"], "comment": "Accepted to ICCV 2025", "summary": "3D Gaussian Splatting (3DGS) has become horsepower in high-quality, real-time\nrendering for novel view synthesis of 3D scenes. However, existing methods\nfocus primarily on geometric and appearance modeling, lacking deeper scene\nunderstanding while also incurring high training costs that complicate the\noriginally streamlined differentiable rendering pipeline. To this end, we\npropose VoteSplat, a novel 3D scene understanding framework that integrates\nHough voting with 3DGS. Specifically, Segment Anything Model (SAM) is utilized\nfor instance segmentation, extracting objects, and generating 2D vote maps. We\nthen embed spatial offset vectors into Gaussian primitives. These offsets\nconstruct 3D spatial votes by associating them with 2D image votes, while depth\ndistortion constraints refine localization along the depth axis. For\nopen-vocabulary object localization, VoteSplat maps 2D image semantics to 3D\npoint clouds via voting points, reducing training costs associated with\nhigh-dimensional CLIP features while preserving semantic unambiguity. Extensive\nexperiments demonstrate effectiveness of VoteSplat in open-vocabulary 3D\ninstance localization, 3D point cloud understanding, click-based 3D object\nlocalization, hierarchical segmentation, and ablation studies. Our code is\navailable at https://sy-ja.github.io/votesplat/"}
{"id": "2506.22803", "pdf": "https://arxiv.org/pdf/2506.22803", "abs": "https://arxiv.org/abs/2506.22803", "authors": ["Nuoye Xiong", "Anqi Dong", "Ning Wang", "Cong Hua", "Guangming Zhu", "Mei Lin", "Peiyi Shen", "Liang Zhang"], "title": "Intervening in Black Box: Concept Bottleneck Model for Enhancing Human Neural Network Mutual Understanding", "categories": ["cs.CV", "cs.HC", "cs.LG"], "comment": "Accepted by ICCV 2025", "summary": "Recent advances in deep learning have led to increasingly complex models with\ndeeper layers and more parameters, reducing interpretability and making their\ndecisions harder to understand. While many methods explain black-box reasoning,\nmost lack effective interventions or only operate at sample-level without\nmodifying the model itself. To address this, we propose the Concept Bottleneck\nModel for Enhancing Human-Neural Network Mutual Understanding (CBM-HNMU).\nCBM-HNMU leverages the Concept Bottleneck Model (CBM) as an interpretable\nframework to approximate black-box reasoning and communicate conceptual\nunderstanding. Detrimental concepts are automatically identified and refined\n(removed/replaced) based on global gradient contributions. The modified CBM\nthen distills corrected knowledge back into the black-box model, enhancing both\ninterpretability and accuracy. We evaluate CBM-HNMU on various CNN and\ntransformer-based models across Flower-102, CIFAR-10, CIFAR-100, FGVC-Aircraft,\nand CUB-200, achieving a maximum accuracy improvement of 2.64% and a maximum\nincrease in average accuracy across 1.03%. Source code is available at:\nhttps://github.com/XiGuaBo/CBM-HNMU."}
{"id": "2506.22806", "pdf": "https://arxiv.org/pdf/2506.22806", "abs": "https://arxiv.org/abs/2506.22806", "authors": ["Byung Hyun Lee", "Sungjin Lim", "Seunggyu Lee", "Dong Un Kang", "Se Young Chun"], "title": "Concept Pinpoint Eraser for Text-to-image Diffusion Models via Residual Attention Gate", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Remarkable progress in text-to-image diffusion models has brought a major\nconcern about potentially generating images on inappropriate or trademarked\nconcepts. Concept erasing has been investigated with the goals of deleting\ntarget concepts in diffusion models while preserving other concepts with\nminimal distortion. To achieve these goals, recent concept erasing methods\nusually fine-tune the cross-attention layers of diffusion models. In this work,\nwe first show that merely updating the cross-attention layers in diffusion\nmodels, which is mathematically equivalent to adding \\emph{linear} modules to\nweights, may not be able to preserve diverse remaining concepts. Then, we\npropose a novel framework, dubbed Concept Pinpoint Eraser (CPE), by adding\n\\emph{nonlinear} Residual Attention Gates (ResAGs) that selectively erase (or\ncut) target concepts while safeguarding remaining concepts from broad\ndistributions by employing an attention anchoring loss to prevent the\nforgetting. Moreover, we adversarially train CPE with ResAG and learnable text\nembeddings in an iterative manner to maximize erasing performance and enhance\nrobustness against adversarial attacks. Extensive experiments on the erasure of\ncelebrities, artistic styles, and explicit contents demonstrated that the\nproposed CPE outperforms prior arts by keeping diverse remaining concepts while\ndeleting the target concepts with robustness against attack prompts. Code is\navailable at https://github.com/Hyun1A/CPE"}
{"id": "2506.22819", "pdf": "https://arxiv.org/pdf/2506.22819", "abs": "https://arxiv.org/abs/2506.22819", "authors": ["Ramya Hebbalaguppe", "Tamoghno Kandar", "Abhinav Nagpal", "Chetan Arora"], "title": "Prompting without Panic: Attribute-aware, Zero-shot, Test-Time Calibration", "categories": ["cs.CV", "cs.LG"], "comment": "26 pages", "summary": "Vision-language models (VLM) have demonstrated impressive performance in\nimage recognition by leveraging self-supervised training on large datasets.\nTheir performance can be further improved by adapting to the test sample using\ntest-time prompt tuning (TPT). Unfortunately, the singular focus of TPT\napproaches on improving the accuracy suffers from tunnel vision, and leads to\ndegradation in confidence calibration. This limits the applicability of TPT in\ncritical applications.\n  We make three contributions in this work. (1) We posit that random or naive\ninitialization of prompts leads to overfitting on a particular test sample, and\nis the main reason for miscalibration of the VLM after TPT. To mitigate the\nproblem, we propose careful initialization of test time prompt using prior\nknowledge about the target label attributes from a large language model (LLM);\n(2) To further maintain the quality of prompts during \\tpt, we propose a novel\nregularization loss to reduce intraclass distance, and increase inter-class\ndistance between the learnt\n  Through extensive experiments on different CLIP architectures and 15\ndatasets, we show that our approach can effectively improve the calibration\nafter TPT. We report an average expected calibration error (ECE) of 4.11 with\nour method, TCA, compared to 11.7 for vanilla TPT, 6.12 for C-TPT (ICLR'24),\n6.78 for DiffTPT (CVPR'23), and 8.43 for PromptAlign (NeurIPS'23). The code is\npublicly accessible at:\nhttps://github.com/rhebbalaguppe/TCA_PromptWithoutPanic."}
{"id": "2506.22851", "pdf": "https://arxiv.org/pdf/2506.22851", "abs": "https://arxiv.org/abs/2506.22851", "authors": ["Arnulf Jentzen", "Konrad Kleinberg", "Thomas Kruse"], "title": "Deep neural networks can provably solve Bellman equations for Markov decision processes without the curse of dimensionality", "categories": ["math.OC", "cs.LG", "cs.NA", "math.NA", "math.PR", "stat.ML", "90C40, 90C39, 60J05, 93E20, 65C05, 68T07"], "comment": null, "summary": "Discrete time stochastic optimal control problems and Markov decision\nprocesses (MDPs) are fundamental models for sequential decision-making under\nuncertainty and as such provide the mathematical framework underlying\nreinforcement learning theory. A central tool for solving MDPs is the Bellman\nequation and its solution, the so-called $Q$-function. In this article, we\nconstruct deep neural network (DNN) approximations for $Q$-functions associated\nto MDPs with infinite time horizon and finite control set $A$. More\nspecifically, we show that if the the payoff function and the random transition\ndynamics of the MDP can be suitably approximated by DNNs with leaky rectified\nlinear unit (ReLU) activation, then the solutions $Q_d\\colon \\mathbb R^d\\to\n\\mathbb R^{|A|}$, $d\\in \\mathbb{N}$, of the associated Bellman equations can\nalso be approximated in the $L^2$-sense by DNNs with leaky ReLU activation\nwhose numbers of parameters grow at most polynomially in both the dimension\n$d\\in \\mathbb{N}$ of the state space and the reciprocal $1/\\varepsilon$ of the\nprescribed error $\\varepsilon\\in (0,1)$. Our proof relies on the recently\nintroduced full-history recursive multilevel fixed-point (MLFP) approximation\nscheme."}
{"id": "2506.22882", "pdf": "https://arxiv.org/pdf/2506.22882", "abs": "https://arxiv.org/abs/2506.22882", "authors": ["Qilong Xing", "Zikai Song", "Yuteng Ye", "Yuke Chen", "Youjia Zhang", "Na Feng", "Junqing Yu", "Wei Yang"], "title": "CA-Diff: Collaborative Anatomy Diffusion for Brain Tissue Segmentation", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": "ICME 2025", "summary": "Segmentation of brain structures from MRI is crucial for evaluating brain\nmorphology, yet existing CNN and transformer-based methods struggle to\ndelineate complex structures accurately. While current diffusion models have\nshown promise in image segmentation, they are inadequate when applied directly\nto brain MRI due to neglecting anatomical information. To address this, we\npropose Collaborative Anatomy Diffusion (CA-Diff), a framework integrating\nspatial anatomical features to enhance segmentation accuracy of the diffusion\nmodel. Specifically, we introduce distance field as an auxiliary anatomical\ncondition to provide global spatial context, alongside a collaborative\ndiffusion process to model its joint distribution with anatomical structures,\nenabling effective utilization of anatomical features for segmentation.\nFurthermore, we introduce a consistency loss to refine relationships between\nthe distance field and anatomical structures and design a time adapted channel\nattention module to enhance the U-Net feature fusion procedure. Extensive\nexperiments show that CA-Diff outperforms state-of-the-art (SOTA) methods."}
{"id": "2506.22899", "pdf": "https://arxiv.org/pdf/2506.22899", "abs": "https://arxiv.org/abs/2506.22899", "authors": ["Ehsan Pajouheshgar", "Yitao Xu", "Ali Abbasi", "Alexander Mordvintsev", "Wenzel Jakob", "Sabine Süsstrunk"], "title": "Neural Cellular Automata: From Cells to Pixels", "categories": ["cs.CV", "cs.GR", "cs.LG", "cs.MA", "eess.IV"], "comment": "6 pages, 5 figures, first draft", "summary": "Neural Cellular Automata (NCAs) are bio-inspired systems in which identical\ncells self-organize to form complex and coherent patterns by repeatedly\napplying simple local rules. NCAs display striking emergent behaviors including\nself-regeneration, generalization and robustness to unseen situations, and\nspontaneous motion. Despite their success in texture synthesis and\nmorphogenesis, NCAs remain largely confined to low-resolution grids. This\nlimitation stems from (1) training time and memory requirements that grow\nquadratically with grid size, (2) the strictly local propagation of information\nwhich impedes long-range cell communication, and (3) the heavy compute demands\nof real-time inference at high resolution. In this work, we overcome this\nlimitation by pairing NCA with a tiny, shared implicit decoder, inspired by\nrecent advances in implicit neural representations. Following NCA evolution on\na coarse grid, a lightweight decoder renders output images at arbitrary\nresolution. We also propose novel loss functions for both morphogenesis and\ntexture synthesis tasks, specifically tailored for high-resolution output with\nminimal memory and computation overhead. Combining our proposed architecture\nand loss functions brings substantial improvement in quality, efficiency, and\nperformance. NCAs equipped with our implicit decoder can generate full-HD\noutputs in real time while preserving their self-organizing, emergent\nproperties. Moreover, because each MLP processes cell states independently,\ninference remains highly parallelizable and efficient. We demonstrate the\napplicability of our approach across multiple NCA variants (on 2D, 3D grids,\nand 3D meshes) and multiple tasks, including texture generation and\nmorphogenesis (growing patterns from a seed), showing that with our proposed\nframework, NCAs seamlessly scale to high-resolution outputs with minimal\ncomputational overhead."}
{"id": "2506.22911", "pdf": "https://arxiv.org/pdf/2506.22911", "abs": "https://arxiv.org/abs/2506.22911", "authors": ["Yunxuan Ma", "Siqiang Wang", "Zhijian Duan", "Yukun Cheng", "Xiaotie Deng"], "title": "Learning Truthful Mechanisms without Discretization", "categories": ["cs.GT", "cs.AI", "cs.LG"], "comment": "66 pages", "summary": "This paper introduces TEDI (Truthful, Expressive, and Dimension-Insensitive\napproach), a discretization-free algorithm to learn truthful and\nutility-maximizing mechanisms. Existing learning-based approaches often rely on\ndiscretization of outcome spaces to ensure truthfulness, which leads to\ninefficiency with increasing problem size. To address this limitation, we\nformalize the concept of pricing rules, defined as functions that map outcomes\nto prices. Based on this concept, we propose a novel menu mechanism, which can\nbe equivalent to a truthful direct mechanism under specific conditions. The\ncore idea of TEDI lies in its parameterization of pricing rules using Partial\nGroupMax Network, a new network architecture designed to universally\napproximate partial convex functions. To learn optimal pricing rules, we\ndevelop novel training techniques, including covariance trick and continuous\nsampling, to derive unbiased gradient estimators compatible with first-order\noptimization. Theoretical analysis establishes that TEDI guarantees\ntruthfulness, full expressiveness, and dimension-insensitivity. Experimental\nevaluation in the studied auction setting demonstrates that TEDI achieves\nstrong performance, competitive with or exceeding state-of-the-art methods.\n  This work presents the first approaches to learn truthful mechanisms without\noutcome discretization, thereby enhancing algorithmic efficiency. The proposed\nconcepts, network architecture, and learning techniques might offer potential\nvalue and provide new insights for automated mechanism design and\ndifferentiable economics."}
{"id": "2506.22935", "pdf": "https://arxiv.org/pdf/2506.22935", "abs": "https://arxiv.org/abs/2506.22935", "authors": ["Marc Bara Iniesta"], "title": "Differentiable Radar Ambiguity Functions: Mathematical Formulation and Computational Implementation", "categories": ["eess.SP", "cs.LG", "cs.NA", "math.NA", "94A12, 65T50, 68T05", "F.2.1; I.2.6; G.1.0"], "comment": "16 pages, 4 figures, source code available at\n  https://github.com/marcbara/graf-psl-lpi (DOI: 10.5281/zenodo.15763301)", "summary": "The ambiguity function is fundamental to radar waveform design,\ncharacterizing range and Doppler resolution capabilities. However, its\ntraditional formulation involves non-differentiable operations, preventing\nintegration with gradient-based optimization methods and modern machine\nlearning frameworks. This paper presents the first complete mathematical\nframework and computational implementation for differentiable radar ambiguity\nfunctions. Our approach addresses the fundamental technical challenges that\nhave prevented the radar community from leveraging automatic differentiation:\nproper handling of complex-valued gradients using Wirtinger calculus, efficient\ncomputation through parallelized FFT operations, numerical stability throughout\ncascaded operations, and composability with arbitrary differentiable\noperations. We term this approach GRAF (Gradient-based Radar Ambiguity\nFunctions), which reformulates the ambiguity function computation to maintain\nmathematical equivalence while enabling gradient flow through the entire\npipeline. The resulting implementation provides a general-purpose\ndifferentiable ambiguity function compatible with modern automatic\ndifferentiation frameworks, enabling new research directions including neural\nnetwork-based waveform generation with ambiguity constraints, end-to-end\noptimization of radar systems, and integration of classical radar theory with\nmodern deep learning. We provide complete implementation details and\ndemonstrate computational efficiency suitable for practical applications. This\nwork establishes the mathematical and computational foundation for applying\nmodern machine learning techniques to radar waveform design, bridging classical\nradar signal processing with automatic differentiation frameworks."}
{"id": "2506.22938", "pdf": "https://arxiv.org/pdf/2506.22938", "abs": "https://arxiv.org/abs/2506.22938", "authors": ["Zaydon L. Ali", "Wassan Saad Abduljabbar Hayale", "Israa Ibraheem Al_Barazanchi", "Ravi Sekhar", "Pritesh Shah", "Sushma Parihar"], "title": "Efficient Cybersecurity Assessment Using SVM and Fuzzy Evidential Reasoning for Resilient Infrastructure", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "With current advancement in hybermedia knowledges, the privacy of digital\ninformation has developed a critical problem. To overawed the susceptibilities\nof present security protocols, scholars tend to focus mainly on efforts on\nalternation of current protocols. Over past decade, various proposed encoding\nmodels have been shown insecurity, leading to main threats against significant\ndata. Utilizing the suitable encryption model is very vital means of guard\nagainst various such, but algorithm is selected based on the dependency of data\nwhich need to be secured. Moreover, testing potentiality of the security\nassessment one by one to identify the best choice can take a vital time for\nprocessing. For faster and precisive identification of assessment algorithm, we\nsuggest a security phase exposure model for cipher encryption technique by\ninvoking Support Vector Machine (SVM). In this work, we form a dataset using\nusual security components like contrast, homogeneity. To overcome the\nuncertainty in analysing the security and lack of ability of processing data to\na risk assessment mechanism. To overcome with such complications, this paper\nproposes an assessment model for security issues using fuzzy evidential\nreasoning (ER) approaches. Significantly, the model can be utilised to process\nand assemble risk assessment data on various aspects in systematic ways. To\nestimate the performance of our framework, we have various analyses like,\nrecall, F1 score and accuracy."}
{"id": "2506.22939", "pdf": "https://arxiv.org/pdf/2506.22939", "abs": "https://arxiv.org/abs/2506.22939", "authors": ["Ghufran A. Omran", "Wassan Saad Abduljabbar Hayale", "Ahmad AbdulQadir AlRababah", "Israa Ibraheem Al-Barazanchi", "Ravi Sekhar", "Pritesh Shah", "Sushma Parihar", "Harshavardhan Reddy Penubadi"], "title": "Utilizing a Novel Deep Learning Method for Scene Categorization in Remote Sensing Data", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Scene categorization (SC) in remotely acquired images is an important subject\nwith broad consequences in different fields, including catastrophe control,\necological observation, architecture for cities, and more. Nevertheless, its\nseveral apps, reaching a high degree of accuracy in SC from distant observation\ndata has demonstrated to be difficult. This is because traditional conventional\ndeep learning models require large databases with high variety and high levels\nof noise to capture important visual features. To address these problems, this\ninvestigation file introduces an innovative technique referred to as the\nCuttlefish Optimized Bidirectional Recurrent Neural Network (CO- BRNN) for type\nof scenes in remote sensing data. The investigation compares the execution of\nCO-BRNN with current techniques, including Multilayer Perceptron- Convolutional\nNeural Network (MLP-CNN), Convolutional Neural Network-Long Short Term Memory\n(CNN-LSTM), and Long Short Term Memory-Conditional Random Field (LSTM-CRF),\nGraph-Based (GB), Multilabel Image Retrieval Model (MIRM-CF), Convolutional\nNeural Networks Data Augmentation (CNN-DA). The results demonstrate that\nCO-BRNN attained the maximum accuracy of 97%, followed by LSTM-CRF with 90%,\nMLP-CNN with 85%, and CNN-LSTM with 80%. The study highlights the significance\nof physical confirmation to ensure the efficiency of satellite data."}
{"id": "2506.22949", "pdf": "https://arxiv.org/pdf/2506.22949", "abs": "https://arxiv.org/abs/2506.22949", "authors": ["Ehsan Hallaji", "Vaishnavi Shanmugam", "Roozbeh Razavi-Far", "Mehrdad Saif"], "title": "A Study on Semi-Supervised Detection of DDoS Attacks under Class Imbalance", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": "Accepted for publication in IEEE CCECE 2025", "summary": "One of the most difficult challenges in cybersecurity is eliminating\nDistributed Denial of Service (DDoS) attacks. Automating this task using\nartificial intelligence is a complex process due to the inherent class\nimbalance and lack of sufficient labeled samples of real-world datasets. This\nresearch investigates the use of Semi-Supervised Learning (SSL) techniques to\nimprove DDoS attack detection when data is imbalanced and partially labeled. In\nthis process, 13 state-of-the-art SSL algorithms are evaluated for detecting\nDDoS attacks in several scenarios. We evaluate their practical efficacy and\nshortcomings, including the extent to which they work in extreme environments.\nThe results will offer insight into designing intelligent Intrusion Detection\nSystems (IDSs) that are robust against class imbalance and handle partially\nlabeled data."}
{"id": "2506.22963", "pdf": "https://arxiv.org/pdf/2506.22963", "abs": "https://arxiv.org/abs/2506.22963", "authors": ["Kevin Lam", "William Daniels", "J Maxwell Douglas", "Daniel Lai", "Samuel Aparicio", "Benjamin Bloem-Reddy", "Yongjin Park"], "title": "CN-SBM: Categorical Block Modelling For Primary and Residual Copy Number Variation", "categories": ["stat.ML", "cs.LG", "q-bio.GN"], "comment": "8 pages, 4 figures", "summary": "Cancer is a genetic disorder whose clonal evolution can be monitored by\ntracking noisy genome-wide copy number variants. We introduce the Copy Number\nStochastic Block Model (CN-SBM), a probabilistic framework that jointly\nclusters samples and genomic regions based on discrete copy number states using\na bipartite categorical block model. Unlike models relying on Gaussian or\nPoisson assumptions, CN-SBM respects the discrete nature of CNV calls and\ncaptures subpopulation-specific patterns through block-wise structure. Using a\ntwo-stage approach, CN-SBM decomposes CNV data into primary and residual\ncomponents, enabling detection of both large-scale chromosomal alterations and\nfiner aberrations. We derive a scalable variational inference algorithm for\napplication to large cohorts and high-resolution data. Benchmarks on simulated\nand real datasets show improved model fit over existing methods. Applied to\nTCGA low-grade glioma data, CN-SBM reveals clinically relevant subtypes and\nstructured residual variation, aiding patient stratification in survival\nanalysis. These results establish CN-SBM as an interpretable, scalable\nframework for CNV analysis with direct relevance for tumor heterogeneity and\nprognosis."}
{"id": "2506.22967", "pdf": "https://arxiv.org/pdf/2506.22967", "abs": "https://arxiv.org/abs/2506.22967", "authors": ["Amir Aghdam", "Vincent Tao Hu"], "title": "ActAlign: Zero-Shot Fine-Grained Video Classification via Language-Guided Sequence Alignment", "categories": ["cs.CV", "cs.LG", "cs.MM", "I.2.10; I.2.7"], "comment": "Preprint manuscript - Project page:\n  https://github.com/aghdamamir/act-align", "summary": "We address the task of zero-shot fine-grained video classification, where no\nvideo examples or temporal annotations are available for unseen action classes.\nWhile contrastive vision-language models such as SigLIP demonstrate strong\nopen-set recognition via mean-pooled image-text similarity, they fail to\ncapture the temporal structure critical for distinguishing fine-grained\nactivities. We introduce ActAlign, a zero-shot framework that formulates video\nclassification as sequence alignment. For each class, a large language model\ngenerates an ordered sub-action sequence, which is aligned with video frames\nusing Dynamic Time Warping (DTW) in a shared embedding space. Without any\nvideo-text supervision or fine-tuning, ActAlign achieves 30.5% accuracy on the\nextremely challenging ActionAtlas benchmark, where human accuracy is only\n61.6%. ActAlign outperforms billion-parameter video-language models while using\napproximately 8x less parameters. These results demonstrate that structured\nlanguage priors, combined with classical alignment techniques, offer a scalable\nand general approach to unlocking the open-set recognition potential of\nvision-language models for fine-grained video understanding."}
{"id": "2506.22971", "pdf": "https://arxiv.org/pdf/2506.22971", "abs": "https://arxiv.org/abs/2506.22971", "authors": ["Kesav Kazam Ramachandran Anantharaman", "Rahul Meshram"], "title": "Hierarchical Decentralized Stochastic Control for Cyber-Physical Systems", "categories": ["eess.SY", "cs.LG", "cs.MA", "cs.SY", "math.OC"], "comment": "6 pages, 2 figures", "summary": "This paper presents a two-timescale hierarchical decentralized architecture\nfor control of Cyber-Physical Systems. The architecture consists of $N$\nindependent sub-processes, a global controller, and $N$ local controllers, each\nformulated as a Markov Decision Process (MDP). The global controller, operating\nat a slower timescale optimizes the infinite-horizon discounted cumulative\nreward under budget constraints. For the local controllers, operating at a\nfaster timescale, we propose two different optimization frameworks, namely the\nCOpt and FOpt. In the COpt framework, the local controller also optimizes an\ninfinite-horizon MDP, while in the FOpt framework, the local controller\noptimizes a finite-horizon MDP. The FOpt framework mimics a federal structure,\nwhere the local controllers have more autonomy in their decision making. First,\nthe existence of stationary deterministic optimal policies for both these\nframeworks is established. Then, various relationships between the two\nframeworks are studied, including a bound on the difference between the two\noptimal value functions. Additionally, sufficiency conditions are provided such\nthat the two frameworks lead to the same optimal values."}
{"id": "2506.22977", "pdf": "https://arxiv.org/pdf/2506.22977", "abs": "https://arxiv.org/abs/2506.22977", "authors": ["Asen Dotsinski", "Udit Thakur", "Marko Ivanov", "Mohammad Hafeez Khan", "Maria Heuss"], "title": "On the Generalizability of \"Competition of Mechanisms: Tracing How Language Models Handle Facts and Counterfactuals\"", "categories": ["cs.CL", "cs.LG"], "comment": "22 pages, 25 figures. For an interactive dashboard with all figures,\n  see https://comp-mech-generalizability.streamlit.app/ . For the accompanying\n  code, see https://github.com/asendotsinski/comp-mech-generalizability . To be\n  published in proceedings of the 2025 Machine Learning Reproducibility\n  Challenge", "summary": "We present a reproduction study of \"Competition of Mechanisms: Tracing How\nLanguage Models Handle Facts and Counterfactuals\" (Ortu et al., 2024), which\ninvestigates competition of mechanisms in language models between factual\nrecall and counterfactual in-context repetition. Our study successfully\nreproduces their primary findings regarding the localization of factual and\ncounterfactual information, the dominance of attention blocks in mechanism\ncompetition, and the specialization of attention heads in handling competing\ninformation. We reproduce their results on both GPT-2 (Radford et al., 2019)\nand Pythia 6.9B (Biderman et al., 2023). We extend their work in three\nsignificant directions. First, we explore the generalizability of these\nfindings to even larger models by replicating the experiments on Llama 3.1 8B\n(Grattafiori et al., 2024), discovering greatly reduced attention head\nspecialization. Second, we investigate the impact of prompt structure by\nintroducing variations where we avoid repeating the counterfactual statement\nverbatim or we change the premise word, observing a marked decrease in the\nlogit for the counterfactual token. Finally, we test the validity of the\nauthors' claims for prompts of specific domains, discovering that certain\ncategories of prompts skew the results by providing the factual prediction\ntoken as part of the subject of the sentence. Overall, we find that the\nattention head ablation proposed in Ortu et al. (2024) is ineffective for\ndomains that are underrepresented in their dataset, and that the effectiveness\nvaries based on model architecture, prompt structure, domain and task."}
{"id": "2506.23010", "pdf": "https://arxiv.org/pdf/2506.23010", "abs": "https://arxiv.org/abs/2506.23010", "authors": ["Max Lovig", "Tianhao Wang", "Zhou Fan"], "title": "On Universality of Non-Separable Approximate Message Passing Algorithms", "categories": ["math.ST", "cs.IT", "cs.LG", "math.IT", "math.PR", "stat.TH"], "comment": null, "summary": "Mean-field characterizations of first-order iterative algorithms -- including\nApproximate Message Passing (AMP), stochastic and proximal gradient descent,\nand Langevin diffusions -- have enabled a precise understanding of learning\ndynamics in many statistical applications. For algorithms whose non-linearities\nhave a coordinate-separable form, it is known that such characterizations enjoy\na degree of universality with respect to the underlying data distribution.\nHowever, mean-field characterizations of non-separable algorithm dynamics have\nlargely remained restricted to i.i.d. Gaussian or rotationally-invariant data.\n  In this work, we initiate a study of universality for non-separable AMP\nalgorithms. We identify a general condition for AMP with polynomial\nnon-linearities, in terms of a Bounded Composition Property (BCP) for their\nrepresenting tensors, to admit a state evolution that holds universally for\nmatrices with non-Gaussian entries. We then formalize a condition of\nBCP-approximability for Lipschitz AMP algorithms to enjoy a similar universal\nguarantee. We demonstrate that many common classes of non-separable\nnon-linearities are BCP-approximable, including local denoisers, spectral\ndenoisers for generic signals, and compositions of separable functions with\ngeneric linear maps, implying the universality of state evolution for AMP\nalgorithms employing these non-linearities."}
{"id": "2506.23023", "pdf": "https://arxiv.org/pdf/2506.23023", "abs": "https://arxiv.org/abs/2506.23023", "authors": ["M. Youssef Abdelhamid", "Lennart Vater", "Zlatan Ajanovic"], "title": "Scenario-Based Hierarchical Reinforcement Learning for Automated Driving Decision Making", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "6 pages, 10 figures, submitted to a conference", "summary": "Developing decision-making algorithms for highly automated driving systems\nremains challenging, since these systems have to operate safely in an open and\ncomplex environments. Reinforcement Learning (RL) approaches can learn\ncomprehensive decision policies directly from experience and already show\npromising results in simple driving tasks. However, current approaches fail to\nachieve generalizability for more complex driving tasks and lack learning\nefficiency. Therefore, we present Scenario-based Automated Driving\nReinforcement Learning (SAD-RL), the first framework that integrates\nReinforcement Learning (RL) of hierarchical policy in a scenario-based\nenvironment. A high-level policy selects maneuver templates that are evaluated\nand executed by a low-level control logic. The scenario-based environment\nallows to control the training experience for the agent and to explicitly\nintroduce challenging, but rate situations into the training process. Our\nexperiments show that an agent trained using the SAD-RL framework can achieve\nsafe behaviour in easy as well as challenging situations efficiently. Our\nablation studies confirmed that both HRL and scenario diversity are essential\nfor achieving these results."}
{"id": "2506.23030", "pdf": "https://arxiv.org/pdf/2506.23030", "abs": "https://arxiv.org/abs/2506.23030", "authors": ["Alejandro Romero Amezcua", "Mariano José Juan Rivera Meraz"], "title": "VisionScores -- A system-segmented image score dataset for deep learning tasks", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.SD", "eess.AS"], "comment": "Comments: 5 pages, 3 figures. Accepted for presentation at the 2025\n  IEEE International Conference on Image Processing (ICIP). \\c{opyright} 2025\n  IEEE. Personal use of this material is permitted. Permission from IEEE must\n  be obtained for any other use", "summary": "VisionScores presents a novel proposal being the first system-segmented image\nscore dataset, aiming to offer structure-rich, high information-density images\nfor machine and deep learning tasks. Delimited to two-handed piano pieces, it\nwas built to consider not only certain graphic similarity but also composition\npatterns, as this creative process is highly instrument-dependent. It provides\ntwo scenarios in relation to composer and composition type. The first, formed\nby 14k samples, considers works from different authors but the same composition\ntype, specifically, Sonatinas. The latter, consisting of 10.8K samples,\npresents the opposite case, various composition types from the same author,\nbeing the one selected Franz Liszt. All of the 24.8k samples are formatted as\ngrayscale jpg images of $128 \\times 512$ pixels. VisionScores supplies the\nusers not only the formatted samples but the systems' order and pieces'\nmetadata. Moreover, unsegmented full-page scores and the pre-formatted images\nare included for further analysis."}
{"id": "2506.23074", "pdf": "https://arxiv.org/pdf/2506.23074", "abs": "https://arxiv.org/abs/2506.23074", "authors": ["Yu Zheng", "Boyang Gong", "Fanye Kong", "Yueqi Duan", "Bingyao Yu", "Wenzhao Zheng", "Lei Chen", "Jiwen Lu", "Jie Zhou"], "title": "Learning Counterfactually Decoupled Attention for Open-World Model Attribution", "categories": ["cs.CV", "cs.CR", "cs.LG"], "comment": "Accepted by ICCV 2025. Code: \\url{https://github.com/yzheng97/CDAL}", "summary": "In this paper, we propose a Counterfactually Decoupled Attention Learning\n(CDAL) method for open-world model attribution. Existing methods rely on\nhandcrafted design of region partitioning or feature space, which could be\nconfounded by the spurious statistical correlations and struggle with novel\nattacks in open-world scenarios. To address this, CDAL explicitly models the\ncausal relationships between the attentional visual traces and source model\nattribution, and counterfactually decouples the discriminative model-specific\nartifacts from confounding source biases for comparison. In this way, the\nresulting causal effect provides a quantification on the quality of learned\nattention maps, thus encouraging the network to capture essential generation\npatterns that generalize to unseen source models by maximizing the effect.\nExtensive experiments on existing open-world model attribution benchmarks show\nthat with minimal computational overhead, our method consistently improves\nstate-of-the-art models by large margins, particularly for unseen novel\nattacks. Source code: https://github.com/yzheng97/CDAL."}
{"id": "2506.23075", "pdf": "https://arxiv.org/pdf/2506.23075", "abs": "https://arxiv.org/abs/2506.23075", "authors": ["Yuchen Zhou", "Jiamin Wu", "Zichen Ren", "Zhouheng Yao", "Weiheng Lu", "Kunyu Peng", "Qihao Zheng", "Chunfeng Song", "Wanli Ouyang", "Chao Gou"], "title": "CSBrain: A Cross-scale Spatiotemporal Brain Foundation Model for EEG Decoding", "categories": ["cs.HC", "cs.LG", "eess.SP", "q-bio.NC"], "comment": null, "summary": "Understanding and decoding brain activity from electroencephalography (EEG)\nsignals is a fundamental challenge in neuroscience and AI, with applications in\ncognition, emotion recognition, diagnosis, and brain-computer interfaces. While\nrecent EEG foundation models advance generalized decoding via unified\narchitectures and large-scale pretraining, they adopt a scale-agnostic dense\nmodeling paradigm inherited from NLP and vision. This design neglects a core\nproperty of neural activity: cross-scale spatiotemporal structure. EEG task\npatterns span a wide range of temporal and spatial scales, from short bursts to\nslow rhythms, and from localized cortical responses to distributed\ninteractions. Ignoring this diversity leads to suboptimal representations and\nweak generalization. We propose CSBrain, a Cross-scale Spatiotemporal Brain\nfoundation model for generalized EEG decoding. CSBrain introduces: (i)\nCross-scale Spatiotemporal Tokenization (CST), which aggregates multi-scale\nfeatures from localized temporal windows and anatomical brain regions into\ncompact scale-aware tokens; and (ii) Structured Sparse Attention (SSA), which\ncaptures cross-window and cross-region dependencies, enhancing scale diversity\nwhile removing spurious correlations. CST and SSA are alternately stacked to\nprogressively integrate multi-scale dependencies. Experiments on 11 EEG tasks\nacross 16 datasets show that CSBrain consistently outperforms task-specific and\nfoundation model baselines. These results establish cross-scale modeling as a\nkey inductive bias and position CSBrain as a robust backbone for future\nbrain-AI research."}
{"id": "2506.23090", "pdf": "https://arxiv.org/pdf/2506.23090", "abs": "https://arxiv.org/abs/2506.23090", "authors": ["Langming Liu", "Wanyu Wang", "Chi Zhang", "Bo Li", "Hongzhi Yin", "Xuetao Wei", "Wenbo Su", "Bo Zheng", "Xiangyu Zhao"], "title": "Multi-task Offline Reinforcement Learning for Online Advertising in Recommender Systems", "categories": ["cs.IR", "cs.LG"], "comment": "KDD 2025", "summary": "Online advertising in recommendation platforms has gained significant\nattention, with a predominant focus on channel recommendation and budget\nallocation strategies. However, current offline reinforcement learning (RL)\nmethods face substantial challenges when applied to sparse advertising\nscenarios, primarily due to severe overestimation, distributional shifts, and\noverlooking budget constraints. To address these issues, we propose MTORL, a\nnovel multi-task offline RL model that targets two key objectives. First, we\nestablish a Markov Decision Process (MDP) framework specific to the nuances of\nadvertising. Then, we develop a causal state encoder to capture dynamic user\ninterests and temporal dependencies, facilitating offline RL through\nconditional sequence modeling. Causal attention mechanisms are introduced to\nenhance user sequence representations by identifying correlations among causal\nstates. We employ multi-task learning to decode actions and rewards,\nsimultaneously addressing channel recommendation and budget allocation.\nNotably, our framework includes an automated system for integrating these tasks\ninto online advertising. Extensive experiments on offline and online\nenvironments demonstrate MTORL's superiority over state-of-the-art methods."}
{"id": "2506.23170", "pdf": "https://arxiv.org/pdf/2506.23170", "abs": "https://arxiv.org/abs/2506.23170", "authors": ["Jaime Hieu Do", "Trung-Hoang Le", "Hady W. Lauw"], "title": "Compositions of Variant Experts for Integrating Short-Term and Long-Term Preferences", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "In the online digital realm, recommendation systems are ubiquitous and play a\ncrucial role in enhancing user experience. These systems leverage user\npreferences to provide personalized recommendations, thereby helping users\nnavigate through the paradox of choice. This work focuses on personalized\nsequential recommendation, where the system considers not only a user's\nimmediate, evolving session context, but also their cumulative historical\nbehavior to provide highly relevant and timely recommendations. Through an\nempirical study conducted on diverse real-world datasets, we have observed and\nquantified the existence and impact of both short-term (immediate and\ntransient) and long-term (enduring and stable) preferences on users' historical\ninteractions. Building on these insights, we propose a framework that combines\nshort- and long-term preferences to enhance recommendation performance, namely\nCompositions of Variant Experts (CoVE). This novel framework dynamically\nintegrates short- and long-term preferences through the use of different\nspecialized recommendation models (i.e., experts). Extensive experiments\nshowcase the effectiveness of the proposed methods and ablation studies further\ninvestigate the impact of variant expert types."}
{"id": "2506.23173", "pdf": "https://arxiv.org/pdf/2506.23173", "abs": "https://arxiv.org/abs/2506.23173", "authors": ["Tomer Slor", "Dean Oren", "Shira Baneth", "Tom Coen", "Haim Suchowski"], "title": "Deep Learning for Optical Misalignment Diagnostics in Multi-Lens Imaging Systems", "categories": ["physics.optics", "cs.AI", "cs.LG"], "comment": null, "summary": "In the rapidly evolving field of optical engineering, precise alignment of\nmulti-lens imaging systems is critical yet challenging, as even minor\nmisalignments can significantly degrade performance. Traditional alignment\nmethods rely on specialized equipment and are time-consuming processes,\nhighlighting the need for automated and scalable solutions. We present two\ncomplementary deep learning-based inverse-design methods for diagnosing\nmisalignments in multi-element lens systems using only optical measurements.\nFirst, we use ray-traced spot diagrams to predict five-degree-of-freedom\n(5-DOF) errors in a 6-lens photographic prime, achieving a mean absolute error\nof 0.031mm in lateral translation and 0.011$^\\circ$ in tilt. We also introduce\na physics-based simulation pipeline that utilizes grayscale synthetic camera\nimages, enabling a deep learning model to estimate 4-DOF, decenter and tilt\nerrors in both two- and six-lens multi-lens systems. These results show the\npotential to reshape manufacturing and quality control in precision imaging."}
{"id": "2506.23192", "pdf": "https://arxiv.org/pdf/2506.23192", "abs": "https://arxiv.org/abs/2506.23192", "authors": ["Gabriel Iturra-Bocaz", "Felipe Bravo-Marquez"], "title": "RiverText: A Python Library for Training and Evaluating Incremental Word Embeddings from Text Data Streams", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted at SIGIR'23", "summary": "Word embeddings have become essential components in various information\nretrieval and natural language processing tasks, such as ranking, document\nclassification, and question answering. However, despite their widespread use,\ntraditional word embedding models present a limitation in their static nature,\nwhich hampers their ability to adapt to the constantly evolving language\npatterns that emerge in sources such as social media and the web (e.g., new\nhashtags or brand names). To overcome this problem, incremental word embedding\nalgorithms are introduced, capable of dynamically updating word representations\nin response to new language patterns and processing continuous data streams.\n  This paper presents RiverText, a Python library for training and evaluating\nincremental word embeddings from text data streams. Our tool is a resource for\nthe information retrieval and natural language processing communities that work\nwith word embeddings in streaming scenarios, such as analyzing social media.\nThe library implements different incremental word embedding techniques, such as\nSkip-gram, Continuous Bag of Words, and Word Context Matrix, in a standardized\nframework. In addition, it uses PyTorch as its backend for neural network\ntraining. We have implemented a module that adapts existing intrinsic static\nword embedding evaluation tasks for word similarity and word categorization to\na streaming setting. Finally, we compare the implemented methods with different\nhyperparameter settings and discuss the results. Our open-source library is\navailable at https://github.com/dccuchile/rivertext."}
{"id": "2506.23247", "pdf": "https://arxiv.org/pdf/2506.23247", "abs": "https://arxiv.org/abs/2506.23247", "authors": ["James Hinns", "David Martens"], "title": "Aggregating Local Saliency Maps for Semi-Global Explainable Image Classification", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Deep learning dominates image classification tasks, yet understanding how\nmodels arrive at predictions remains a challenge. Much research focuses on\nlocal explanations of individual predictions, such as saliency maps, which\nvisualise the influence of specific pixels on a model's prediction. However,\nreviewing many of these explanations to identify recurring patterns is\ninfeasible, while global methods often oversimplify and miss important local\nbehaviours. To address this, we propose Segment Attribution Tables (SATs), a\nmethod for summarising local saliency explanations into (semi-)global insights.\nSATs take image segments (such as \"eyes\" in Chihuahuas) and leverage saliency\nmaps to quantify their influence. These segments highlight concepts the model\nrelies on across instances and reveal spurious correlations, such as reliance\non backgrounds or watermarks, even when out-of-distribution test performance\nsees little change. SATs can explain any classifier for which a form of\nsaliency map can be produced, using segmentation maps that provide named\nsegments. SATs bridge the gap between oversimplified global summaries and\noverly detailed local explanations, offering a practical tool for analysing and\ndebugging image classifiers."}
{"id": "2506.23270", "pdf": "https://arxiv.org/pdf/2506.23270", "abs": "https://arxiv.org/abs/2506.23270", "authors": ["Yi Li", "Hualiang Wang", "Xinpeng Ding", "Haonan Wang", "Xiaomeng Li"], "title": "Token Activation Map to Visually Explain Multimodal LLMs", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "ICCV2025 Accepted", "summary": "Multimodal large language models (MLLMs) are broadly empowering various\nfields. Despite their advancements, the explainability of MLLMs remains less\nexplored, hindering deeper understanding, model credibility, and effective\nvisualization. Unlike conventional vision models (e.g., CNNs, ViTs, CLIP) that\nproduce a single output, MLLMs generate sequences of tokens progressively,\nwhere each generated token depends on the previous context. Therefore, earlier\ncontext tokens can introduce redundant activations that interfere with the\nexplanation of later tokens beyond their original information. Existing studies\noften overlook this issue, but our observations reveal that these redundant\ncorrelations can significantly hurt the reliability of explanations. To address\nthis, we propose an estimated causal inference method to mitigate the\ninterference of context to achieve high-quality MLLM explanation, with a novel\nrank Gaussian filter to further reduce activation noises. We term this method\nToken Activation Map (TAM) to highlight the consideration of interactions\nbetween tokens. TAM also indicates that it excels at explaining multiple tokens\nof MLLM, which is different from the Class Activation Map (CAM) for a single\nprediction. Our TAM method significantly outperforms existing SoTA methods,\nshowcasing high-quality visualization results that can be utilized for various\nscenarios, such as object localization, failure case analysis, video\nvisualization, MLLMs visual comparison, and model understanding (e.g., color,\nshape, action, location, visual reasoning, multi-turn conversation, etc). The\ncode is available atgithub.com/xmed-lab/TAM."}
{"id": "2506.23293", "pdf": "https://arxiv.org/pdf/2506.23293", "abs": "https://arxiv.org/abs/2506.23293", "authors": ["P. Myles Eugenio"], "title": "Objective-Free Local Learning and Emergent Language Structure in Thinking Machines", "categories": ["cs.CL", "cs.AI", "cs.LG", "q-bio.NC"], "comment": "22 pages, 7 figures", "summary": "We present a neuro-symbolic framework for generative language modeling based\non local, event-driven emergent learning. At its core is a hierarchical\nHopfield memory chain acting as a compositional short-term memory and dynamic\ntokenizer (retokenizer). Rather than relying on predefined tokens or\nsupervision, the model builds structure from scratch, learning symbol sequences\nas multi-scale representations. It constructs projection tensors that bind\nco-occurring features into hierarchical tokens, introducing redundancy (i.e an\nemergent gauge structure) and enabling compression of local activations into\nlong-range dependencies. Curiously, we find that the retokenizer can filter\nnatural language patterns from noise, generating synthetic languages with\ncoherent internal morphology -- quantifiably the same as human language.\nLanguage is learned in a local (Hebbian) fashion, where model constraints\ndictate allowed emergent structure, and new information is retained in\nalignment with this structure. The absence of a global objective enables a form\nof plasticity not found in conventional language models, allowing the system to\ngeneralize beyond its initial inference class -- even without explicit data. We\ndemonstrate that briefly activating a new neuron during inference binds\ndistributed multi-scale token features into a symbolic embedding. These\nemergent embedding neurons act as long-term memory and support a key-value\nmechanism for compositional inference and generalization. This architecture\nprovides a methodological foundation for studying how symbolic structure can\nemerge from local neural learning. It offers a new pathway for building\nscalable, interpretable neuro-symbolic systems -- where tokens, grammar, and\nreasoning arise as compressed memory traces within a Hopfield hierarchy. This\napproach advances the development of neuromorphic architectures for generative\nlanguage models."}
{"id": "2506.23311", "pdf": "https://arxiv.org/pdf/2506.23311", "abs": "https://arxiv.org/abs/2506.23311", "authors": ["Perla Mayo", "Carolin M. Pirkl", "Alin Achim", "Bjoern Menze", "Mohammad Golbabaee"], "title": "Physics informed guided diffusion for accelerated multi-parametric MRI reconstruction", "categories": ["eess.IV", "cs.LG", "physics.med-ph"], "comment": "11 pages, 1 figure, 1 algorithm, 3 tables. Accepted to MICCAI 2025.\n  This is a version prior peer-review", "summary": "We introduce MRF-DiPh, a novel physics informed denoising diffusion approach\nfor multiparametric tissue mapping from highly accelerated, transient-state\nquantitative MRI acquisitions like Magnetic Resonance Fingerprinting (MRF). Our\nmethod is derived from a proximal splitting formulation, incorporating a\npretrained denoising diffusion model as an effective image prior to regularize\nthe MRF inverse problem. Further, during reconstruction it simultaneously\nenforces two key physical constraints: (1) k-space measurement consistency and\n(2) adherence to the Bloch response model. Numerical experiments on in-vivo\nbrain scans data show that MRF-DiPh outperforms deep learning and compressed\nsensing MRF baselines, providing more accurate parameter maps while better\npreserving measurement fidelity and physical model consistency-critical for\nsolving reliably inverse problems in medical imaging."}
{"id": "2506.23315", "pdf": "https://arxiv.org/pdf/2506.23315", "abs": "https://arxiv.org/abs/2506.23315", "authors": ["Shouvon Sarker", "Xishuang Dong", "Lijun Qian"], "title": "Ensemble BERT for Medication Event Classification on Electronic Health Records (EHRs)", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Identification of key variables such as medications, diseases, relations from\nhealth records and clinical notes has a wide range of applications in the\nclinical domain. n2c2 2022 provided shared tasks on challenges in natural\nlanguage processing for clinical data analytics on electronic health records\n(EHR), where it built a comprehensive annotated clinical data Contextualized\nMedication Event Dataset (CMED). This study focuses on subtask 2 in Track 1 of\nthis challenge that is to detect and classify medication events from clinical\nnotes through building a novel BERT-based ensemble model. It started with\npretraining BERT models on different types of big data such as Wikipedia and\nMIMIC. Afterwards, these pretrained BERT models were fine-tuned on CMED\ntraining data. These fine-tuned BERT models were employed to accomplish\nmedication event classification on CMED testing data with multiple predictions.\nThese multiple predictions generated by these fine-tuned BERT models were\nintegrated to build final prediction with voting strategies. Experimental\nresults demonstrated that BERT-based ensemble models can effectively improve\nstrict Micro-F score by about 5% and strict Macro-F score by about 6%,\nrespectively."}
{"id": "2506.23319", "pdf": "https://arxiv.org/pdf/2506.23319", "abs": "https://arxiv.org/abs/2506.23319", "authors": ["Norman Knyazev", "Harrie Oosterhuis"], "title": "Learning to Rank with Variable Result Presentation Lengths", "categories": ["cs.IR", "cs.LG"], "comment": "SIGIR 2025", "summary": "Learning to Rank (LTR) methods generally assume that each document in a top-K\nranking is presented in an equal format. However, previous work has shown that\nusers' perceptions of relevance can be changed by varying presentations, i.e.,\nallocating more vertical space to some documents to provide additional textual\nor image information. Furthermore, presentation length can also redirect\nattention, as users are more likely to notice longer presentations when\nscrolling through results. Deciding on the document presentation lengths in a\nfixed vertical space ranking is an important problem that has not been\naddressed by existing LTR methods.\n  We address this gap by introducing the variable presentation length ranking\ntask, where simultaneously the ordering of documents and their presentation\nlength is decided. Despite being a generalization of standard ranking, we show\nthat this setting brings significant new challenges: Firstly, the probability\nranking principle no longer applies to this setting, and secondly, the problem\ncannot be divided into separate ordering and length selection tasks.\n  We therefore propose VLPL - a new family of Plackett-Luce list-wise gradient\nestimation methods for the joint optimization of document ordering and lengths.\nOur semi-synthetic experiments show that VLPL can effectively balance the\nexpected exposure and attractiveness of all documents, achieving the best\nperformance across different ranking settings. Furthermore, we observe that\neven simple length-aware methods can achieve significant performance\nimprovements over fixed-length models. Altogether, our theoretical and\nempirical results highlight the importance and difficulties of combining\ndocument presentation with LTR."}
{"id": "2506.23344", "pdf": "https://arxiv.org/pdf/2506.23344", "abs": "https://arxiv.org/abs/2506.23344", "authors": ["Difeng Cai", "Paulina Sepúlveda"], "title": "Data-Driven Self-Supervised Learning for the Discovery of Solution Singularity for Partial Differential Equations", "categories": ["math.NA", "cs.LG", "cs.NA", "stat.ML"], "comment": null, "summary": "The appearance of singularities in the function of interest constitutes a\nfundamental challenge in scientific computing. It can significantly undermine\nthe effectiveness of numerical schemes for function approximation, numerical\nintegration, and the solution of partial differential equations (PDEs), etc.\nThe problem becomes more sophisticated if the location of the singularity is\nunknown, which is often encountered in solving PDEs. Detecting the singularity\nis therefore critical for developing efficient adaptive methods to reduce\ncomputational costs in various applications. In this paper, we consider\nsingularity detection in a purely data-driven setting. Namely, the input only\ncontains given data, such as the vertex set from a mesh. To overcome the\nlimitation of the raw unlabeled data, we propose a self-supervised learning\n(SSL) framework for estimating the location of the singularity. A key component\nis a filtering procedure as the pretext task in SSL, where two filtering\nmethods are presented, based on $k$ nearest neighbors and kernel density\nestimation, respectively. We provide numerical examples to illustrate the\npotential pathological or inaccurate results due to the use of raw data without\nfiltering. Various experiments are presented to demonstrate the ability of the\nproposed approach to deal with input perturbation, label corruption, and\ndifferent kinds of singularities such interior circle, boundary layer,\nconcentric semicircles, etc."}
{"id": "2506.23351", "pdf": "https://arxiv.org/pdf/2506.23351", "abs": "https://arxiv.org/abs/2506.23351", "authors": ["Tianxing Chen", "Kaixuan Wang", "Zhaohui Yang", "Yuhao Zhang", "Zanxin Chen", "Baijun Chen", "Wanxi Dong", "Ziyuan Liu", "Dong Chen", "Tianshuo Yang", "Haibao Yu", "Xiaokang Yang", "Yusen Qin", "Zhiqiang Xie", "Yao Mu", "Ping Luo", "Tian Nian", "Weiliang Deng", "Yiheng Ge", "Yibin Liu", "Zixuan Li", "Dehui Wang", "Zhixuan Liang", "Haohui Xie", "Rijie Zeng", "Yunfei Ge", "Peiqing Cong", "Guannan He", "Zhaoming Han", "Ruocheng Yin", "Jingxiang Guo", "Lunkai Lin", "Tianling Xu", "Hongzhe Bi", "Xuewu Lin", "Tianwei Lin", "Shujie Luo", "Keyu Li", "Ziyan Zhao", "Ke Fan", "Heyang Xu", "Bo Peng", "Wenlong Gao", "Dongjiang Li", "Feng Jin", "Hui Shen", "Jinming Li", "Chaowei Cui", "Yuchen", "Yaxin Peng", "Lingdong Zeng", "Wenlong Dong", "Tengfei Li", "Weijie Ke", "Jun Chen", "Erdemt Bao", "Tian Lan", "Tenglong Liu", "Jin Yang", "Huiping Zhuang", "Baozhi Jia", "Shuai Zhang", "Zhengfeng Zou", "Fangheng Guan", "Tianyi Jia", "Ke Zhou", "Hongjiu Zhang", "Yating Han", "Cheng Fang", "Yixian Zou", "Chongyang Xu", "Qinglun Zhang", "Shen Cheng", "Xiaohe Wang", "Ping Tan", "Haoqiang Fan", "Shuaicheng Liu", "Jiaheng Chen", "Chuxuan Huang", "Chengliang Lin", "Kaijun Luo", "Boyu Yue", "Yi Liu", "Jinyu Chen", "Zichang Tan", "Liming Deng", "Shuo Xu", "Zijian Cai", "Shilong Yin", "Hao Wang", "Hongshan Liu", "Tianyang Li", "Long Shi", "Ran Xu", "Huilin Xu", "Zhengquan Zhang", "Congsheng Xu", "Jinchang Yang", "Feng Xu"], "title": "Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.MA"], "comment": "Challenge Webpage:\n  https://robotwin-benchmark.github.io/cvpr-2025-challenge/", "summary": "Embodied Artificial Intelligence (Embodied AI) is an emerging frontier in\nrobotics, driven by the need for autonomous systems that can perceive, reason,\nand act in complex physical environments. While single-arm systems have shown\nstrong task performance, collaborative dual-arm systems are essential for\nhandling more intricate tasks involving rigid, deformable, and\ntactile-sensitive objects. To advance this goal, we launched the RoboTwin\nDual-Arm Collaboration Challenge at the 2nd MEIS Workshop, CVPR 2025. Built on\nthe RoboTwin Simulation platform (1.0 and 2.0) and the AgileX COBOT-Magic Robot\nplatform, the competition consisted of three stages: Simulation Round 1,\nSimulation Round 2, and a final Real-World Round. Participants totally tackled\n17 dual-arm manipulation tasks, covering rigid, deformable, and tactile-based\nscenarios. The challenge attracted 64 global teams and over 400 participants,\nproducing top-performing solutions like SEM and AnchorDP3 and generating\nvaluable insights into generalizable bimanual policy learning. This report\noutlines the competition setup, task design, evaluation methodology, key\nfindings and future direction, aiming to support future research on robust and\ngeneralizable bimanual manipulation policies. The Challenge Webpage is\navailable at https://robotwin-benchmark.github.io/cvpr-2025-challenge/."}
{"id": "2506.23371", "pdf": "https://arxiv.org/pdf/2506.23371", "abs": "https://arxiv.org/abs/2506.23371", "authors": ["Frank Cwitkowitz", "Zhiyao Duan"], "title": "Investigating an Overfitting and Degeneration Phenomenon in Self-Supervised Multi-Pitch Estimation", "categories": ["eess.AS", "cs.LG", "cs.SD"], "comment": "Accepted to ISMIR 2025", "summary": "Multi-Pitch Estimation (MPE) continues to be a sought after capability of\nMusic Information Retrieval (MIR) systems, and is critical for many\napplications and downstream tasks involving pitch, including music\ntranscription. However, existing methods are largely based on supervised\nlearning, and there are significant challenges in collecting annotated data for\nthe task. Recently, self-supervised techniques exploiting intrinsic properties\nof pitch and harmonic signals have shown promise for both monophonic and\npolyphonic pitch estimation, but these still remain inferior to supervised\nmethods. In this work, we extend the classic supervised MPE paradigm by\nincorporating several self-supervised objectives based on pitch-invariant and\npitch-equivariant properties. This joint training results in a substantial\nimprovement under closed training conditions, which naturally suggests that\napplying the same objectives to a broader collection of data will yield further\nimprovements. However, in doing so we uncover a phenomenon whereby our model\nsimultaneously overfits to the supervised data while degenerating on data used\nfor self-supervision only. We demonstrate and investigate this and offer our\ninsights on the underlying problem."}
{"id": "2506.23382", "pdf": "https://arxiv.org/pdf/2506.23382", "abs": "https://arxiv.org/abs/2506.23382", "authors": ["Vikram Rangarajan", "Shishira Maiya", "Max Ehrlich", "Abhinav Shrivastava"], "title": "SIEDD: Shared-Implicit Encoder with Discrete Decoders", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Project page at https://vikramrangarajan.github.io/SIEDD . Project\n  code at https://github.com/VikramRangarajan/SIEDD", "summary": "Implicit Neural Representations (INRs) offer exceptional fidelity for video\ncompression by learning per-video optimized functions, but their adoption is\ncrippled by impractically slow encoding times. Existing attempts to accelerate\nINR encoding often sacrifice reconstruction quality or crucial coordinate-level\ncontrol essential for adaptive streaming and transcoding. We introduce SIEDD\n(Shared-Implicit Encoder with Discrete Decoders), a novel architecture that\nfundamentally accelerates INR encoding without these compromises. SIEDD first\nrapidly trains a shared, coordinate-based encoder on sparse anchor frames to\nefficiently capture global, low-frequency video features. This encoder is then\nfrozen, enabling massively parallel training of lightweight, discrete decoders\nfor individual frame groups, further expedited by aggressive coordinate-space\nsampling. This synergistic design delivers a remarkable 20-30X encoding\nspeed-up over state-of-the-art INR codecs on HD and 4K benchmarks, while\nmaintaining competitive reconstruction quality and compression ratios.\nCritically, SIEDD retains full coordinate-based control, enabling continuous\nresolution decoding and eliminating costly transcoding. Our approach\nsignificantly advances the practicality of high-fidelity neural video\ncompression, demonstrating a scalable and efficient path towards real-world\ndeployment. Our codebase is available at\nhttps://github.com/VikramRangarajan/SIEDD ."}
{"id": "2506.23396", "pdf": "https://arxiv.org/pdf/2506.23396", "abs": "https://arxiv.org/abs/2506.23396", "authors": ["Kay Giesecke", "Enguerrand Horel", "Chartsiri Jirachotkulthorn"], "title": "AICO: Feature Significance Tests for Supervised Learning", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "The opacity of many supervised learning algorithms remains a key challenge,\nhindering scientific discovery and limiting broader deployment -- particularly\nin high-stakes domains. This paper develops model- and distribution-agnostic\nsignificance tests to assess the influence of input features in any regression\nor classification algorithm. Our method evaluates a feature's incremental\ncontribution to model performance by masking its values across samples. Under\nthe null hypothesis, the distribution of performance differences across a test\nset has a non-positive median. We construct a uniformly most powerful,\nrandomized sign test for this median, yielding exact p-values for assessing\nfeature significance and confidence intervals with exact coverage for\nestimating population-level feature importance. The approach requires minimal\nassumptions, avoids model retraining or auxiliary models, and remains\ncomputationally efficient even for large-scale, high-dimensional settings.\nExperiments on synthetic tasks validate its statistical and computational\nadvantages, and applications to real-world data illustrate its practical\nutility."}
{"id": "2506.23411", "pdf": "https://arxiv.org/pdf/2506.23411", "abs": "https://arxiv.org/abs/2506.23411", "authors": ["Jiale Zhang", "Zichong Wang", "Avash Palikhe", "Zhipeng Yin", "Wenbin Zhang"], "title": "Datasets for Fairness in Language Models: An In-Depth Survey", "categories": ["cs.CL", "cs.CY", "cs.LG"], "comment": null, "summary": "Fairness benchmarks play a central role in shaping how we evaluate language\nmodels, yet surprisingly little attention has been given to examining the\ndatasets that these benchmarks rely on. This survey addresses that gap by\npresenting a broad and careful review of the most widely used fairness datasets\nin current language model research, characterizing them along several key\ndimensions including their origin, scope, content, and intended use to help\nresearchers better appreciate the assumptions and limitations embedded in these\nresources. To support more meaningful comparisons and analyses, we introduce a\nunified evaluation framework that reveals consistent patterns of demographic\ndisparities across datasets and scoring methods. Applying this framework to\ntwenty four common benchmarks, we highlight the often overlooked biases that\ncan influence conclusions about model fairness and offer practical guidance for\nselecting, combining, and interpreting these datasets. We also point to\nopportunities for creating new fairness benchmarks that reflect more diverse\nsocial contexts and encourage more thoughtful use of these tools going forward.\nAll code, data, and detailed results are publicly available at\nhttps://github.com/vanbanTruong/Fairness-in-Large-Language-Models/tree/main/datasets\nto promote transparency and reproducibility across the research community."}
{"id": "2506.23426", "pdf": "https://arxiv.org/pdf/2506.23426", "abs": "https://arxiv.org/abs/2506.23426", "authors": ["Menna Taha", "Aya Ahmed", "Mohammed Karmoose", "Yasser Gadallah"], "title": "Detecting What Matters: A Novel Approach for Out-of-Distribution 3D Object Detection in Autonomous Vehicles", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Autonomous vehicles (AVs) use object detection models to recognize their\nsurroundings and make driving decisions accordingly. Conventional object\ndetection approaches classify objects into known classes, which limits the AV's\nability to detect and appropriately respond to Out-of-Distribution (OOD)\nobjects. This problem is a significant safety concern since the AV may fail to\ndetect objects or misclassify them, which can potentially lead to hazardous\nsituations such as accidents. Consequently, we propose a novel object detection\napproach that shifts the emphasis from conventional class-based classification\nto object harmfulness determination. Instead of object detection by their\nspecific class, our method identifies them as either 'harmful' or 'harmless'\nbased on whether they pose a danger to the AV. This is done based on the object\nposition relative to the AV and its trajectory. With this metric, our model can\neffectively detect previously unseen objects to enable the AV to make safer\nreal-time decisions. Our results demonstrate that the proposed model\neffectively detects OOD objects, evaluates their harmfulness, and classifies\nthem accordingly, thus enhancing the AV decision-making effectiveness in\ndynamic environments."}
{"id": "2506.23429", "pdf": "https://arxiv.org/pdf/2506.23429", "abs": "https://arxiv.org/abs/2506.23429", "authors": ["Yingyuan Li", "Aokun Wang", "Zhongjian Wang"], "title": "DPOT: A DeepParticle method for Computation of Optimal Transport with convergence guarantee", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "In this work, we propose a novel machine learning approach to compute the\noptimal transport map between two continuous distributions from their unpaired\nsamples, based on the DeepParticle methods. The proposed method leads to a\nmin-min optimization during training and does not impose any restriction on the\nnetwork structure. Theoretically we establish a weak convergence guarantee and\na quantitative error bound between the learned map and the optimal transport\nmap. Our numerical experiments validate the theoretical results and the\neffectiveness of the new approach, particularly on real-world tasks."}
{"id": "2506.23453", "pdf": "https://arxiv.org/pdf/2506.23453", "abs": "https://arxiv.org/abs/2506.23453", "authors": ["Zhen Zhang", "Xin Liu", "Shaoli Wang", "Jiaye Teng"], "title": "Minimax Optimal Two-Stage Algorithm For Moment Estimation Under Covariate Shift", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Covariate shift occurs when the distribution of input features differs\nbetween the training and testing phases. In covariate shift, estimating an\nunknown function's moment is a classical problem that remains under-explored,\ndespite its common occurrence in real-world scenarios. In this paper, we\ninvestigate the minimax lower bound of the problem when the source and target\ndistributions are known. To achieve the minimax optimal bound (up to a\nlogarithmic factor), we propose a two-stage algorithm. Specifically, it first\ntrains an optimal estimator for the function under the source distribution, and\nthen uses a likelihood ratio reweighting procedure to calibrate the moment\nestimator. In practice, the source and target distributions are typically\nunknown, and estimating the likelihood ratio may be unstable. To solve this\nproblem, we propose a truncated version of the estimator that ensures double\nrobustness and provide the corresponding upper bound. Extensive numerical\nstudies on synthetic examples confirm our theoretical findings and further\nillustrate the effectiveness of our proposed method."}
{"id": "2506.23456", "pdf": "https://arxiv.org/pdf/2506.23456", "abs": "https://arxiv.org/abs/2506.23456", "authors": ["William Gay", "William He", "Nicholas Kocurek", "Ryan O'Donnell"], "title": "Sampling and Identity-Testing Without Approximate Tensorization of Entropy", "categories": ["math.ST", "cs.DS", "cs.LG", "stat.ML", "stat.TH"], "comment": null, "summary": "Certain tasks in high-dimensional statistics become easier when the\nunderlying distribution satisfies a local-to-global property called approximate\ntensorization of entropy (ATE). For example, the Glauber dynamics Markov chain\nof an ATE distribution mixes fast and can produce approximate samples in a\nsmall amount of time, since such a distribution satisfies a modified\nlog-Sobolev inequality. Moreover, identity-testing for an ATE distribution\nrequires few samples if the tester is given coordinate conditional access to\nthe unknown distribution, as shown by Blanca, Chen, \\v{S}tefankovi\\v{c}, and\nVigoda (COLT 2023).\n  A natural class of distributions that do not satisfy ATE consists of mixtures\nof (few) distributions that do satisfy ATE. We study the complexity of\nidentity-testing and sampling for these distributions. Our main results are the\nfollowing:\n  1. We show fast mixing of Glauber dynamics from a data-based initialization,\nwith optimal sample complexity, for mixtures of distributions satisfying\nmodified log-Sobolev inequalities. This extends work of Huang, Koehler, Lee,\nMohanty, Rajaraman, Vuong, and Wu (STOC 2025, COLT 2025) for mixtures of\ndistributions satisfying Poincar\\'e inequalities.\n  2. Answering an open question posed by Blanca et al., we give efficient\nidentity-testers for mixtures of ATE distributions in the\ncoordinate-conditional sampling access model. We also give some simplifications\nand improvements to the original algorithm of Blanca et al."}
{"id": "2506.23458", "pdf": "https://arxiv.org/pdf/2506.23458", "abs": "https://arxiv.org/abs/2506.23458", "authors": ["Xiaoxiao Yang", "Chan Feng", "Jiancheng Chen"], "title": "Neuro-Informed Joint Learning Enhances Cognitive Workload Decoding in Portable BCIs", "categories": ["cs.HC", "cs.LG"], "comment": "2 pages short paper", "summary": "Portable and wearable consumer-grade electroencephalography (EEG) devices,\nlike Muse headbands, offer unprecedented mobility for daily brain-computer\ninterface (BCI) applications, including cognitive load detection. However, the\nexacerbated non-stationarity in portable EEG signals constrains data fidelity\nand decoding accuracy, creating a fundamental trade-off between portability and\nperformance. To mitigate such limitation, we propose MuseCogNet (Muse-based\nCognitive Network), a unified joint learning framework integrating\nself-supervised and supervised training paradigms. In particular, we introduce\nan EEG-grounded self-supervised reconstruction loss based on average pooling to\ncapture robust neurophysiological patterns, while cross-entropy loss refines\ntask-specific cognitive discriminants. This joint learning framework resembles\nthe bottom-up and top-down attention in humans, enabling MuseCogNet to\nsignificantly outperform state-of-the-art methods on a publicly available Muse\ndataset and establish an implementable pathway for neurocognitive monitoring in\necological settings."}
{"id": "2506.23467", "pdf": "https://arxiv.org/pdf/2506.23467", "abs": "https://arxiv.org/abs/2506.23467", "authors": ["Chenlang Yi", "Zizhan Xiong", "Qi Qi", "Xiyuan Wei", "Girish Bathla", "Ching-Long Lin", "Bobak Jack Mortazavi", "Tianbao Yang"], "title": "AdFair-CLIP: Adversarial Fair Contrastive Language-Image Pre-training for Chest X-rays", "categories": ["cs.CV", "cs.LG"], "comment": "This preprint has been accepted by MICCAI 2025", "summary": "Contrastive Language-Image Pre-training (CLIP) models have demonstrated\nsuperior performance across various visual tasks including medical image\nclassification. However, fairness concerns, including demographic biases, have\nreceived limited attention for CLIP models. This oversight leads to critical\nissues, particularly those related to race and gender, resulting in disparities\nin diagnostic outcomes and reduced reliability for underrepresented groups. To\naddress these challenges, we introduce AdFair-CLIP, a novel framework employing\nadversarial feature intervention to suppress sensitive attributes, thereby\nmitigating spurious correlations and improving prediction fairness. We conduct\ncomprehensive experiments on chest X-ray (CXR) datasets, and show that\nAdFair-CLIP significantly enhances both fairness and diagnostic accuracy, while\nmaintaining robust generalization in zero-shot and few-shot scenarios. These\nresults establish new benchmarks for fairness-aware learning in CLIP-based\nmedical diagnostic models, particularly for CXR analysis."}
{"id": "2506.23487", "pdf": "https://arxiv.org/pdf/2506.23487", "abs": "https://arxiv.org/abs/2506.23487", "authors": ["Haoshu Xu", "Hongzhe Li"], "title": "Test of partial effects for Frechet regression on Bures-Wasserstein manifolds", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We propose a novel test for assessing partial effects in Frechet regression\non Bures Wasserstein manifolds. Our approach employs a sample splitting\nstrategy: the first subsample is used to fit the Frechet regression model,\nyielding estimates of the covariance matrices and their associated optimal\ntransport maps, while the second subsample is used to construct the test\nstatistic. We prove that this statistic converges in distribution to a weighted\nmixture of chi squared components, where the weights correspond to the\neigenvalues of an integral operator defined by an appropriate RKHS kernel. We\nestablish that our procedure achieves the nominal asymptotic size and\ndemonstrate that its worst-case power converges uniformly to one. Through\nextensive simulations and a real data application, we illustrate the test's\nfinite-sample accuracy and practical utility."}
{"id": "2506.23529", "pdf": "https://arxiv.org/pdf/2506.23529", "abs": "https://arxiv.org/abs/2506.23529", "authors": ["Jisu Han", "Jihee Park", "Dongyoon Han", "Wonjun Hwang"], "title": "When Test-Time Adaptation Meets Self-Supervised Models", "categories": ["cs.CV", "cs.LG"], "comment": "15 pages, 7 figures", "summary": "Training on test-time data enables deep learning models to adapt to dynamic\nenvironmental changes, enhancing their practical applicability. Online\nadaptation from source to target domains is promising but it remains highly\nreliant on the performance of source pretrained model. In this paper, we\ninvestigate whether test-time adaptation (TTA) methods can continuously improve\nmodels trained via self-supervised learning (SSL) without relying on source\npretraining. We introduce a self-supervised TTA protocol after observing that\nexisting TTA approaches struggle when directly applied to self-supervised\nmodels with low accuracy on the source domain. Furthermore, we propose a\ncollaborative learning framework that integrates SSL and TTA models, leveraging\ncontrastive learning and knowledge distillation for stepwise representation\nrefinement. We validate our method on diverse self-supervised models, including\nDINO, MoCo, and iBOT, across TTA benchmarks. Extensive experiments validate the\neffectiveness of our approach in SSL, showing that it achieves competitive\nperformance even without source pretraining."}
{"id": "2506.23532", "pdf": "https://arxiv.org/pdf/2506.23532", "abs": "https://arxiv.org/abs/2506.23532", "authors": ["Jefferson Hernandez", "Ruozhen He", "Guha Balakrishnan", "Alexander C. Berg", "Vicente Ordonez"], "title": "GViT: Representing Images as Gaussians for Visual Recognition", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "We introduce GVIT, a classification framework that abandons conventional\npixel or patch grid input representations in favor of a compact set of\nlearnable 2D Gaussians. Each image is encoded as a few hundred Gaussians whose\npositions, scales, orientations, colors, and opacities are optimized jointly\nwith a ViT classifier trained on top of these representations. We reuse the\nclassifier gradients as constructive guidance, steering the Gaussians toward\nclass-salient regions while a differentiable renderer optimizes an image\nreconstruction loss. We demonstrate that by 2D Gaussian input representations\ncoupled with our GVIT guidance, using a relatively standard ViT architecture,\nclosely matches the performance of a traditional patch-based ViT, reaching a\n76.9% top-1 accuracy on Imagenet-1k using a ViT-B architecture."}
{"id": "2506.23538", "pdf": "https://arxiv.org/pdf/2506.23538", "abs": "https://arxiv.org/abs/2506.23538", "authors": ["Yuhao Huang", "Yueyue Xu", "Haoran Dou", "Jiaxiao Deng", "Xin Yang", "Hongyu Zheng", "Dong Ni"], "title": "Uncertainty-aware Diffusion and Reinforcement Learning for Joint Plane Localization and Anomaly Diagnosis in 3D Ultrasound", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted by MICCAI 2025;10 pages, 3 figures", "summary": "Congenital uterine anomalies (CUAs) can lead to infertility, miscarriage,\npreterm birth, and an increased risk of pregnancy complications. Compared to\ntraditional 2D ultrasound (US), 3D US can reconstruct the coronal plane,\nproviding a clear visualization of the uterine morphology for assessing CUAs\naccurately. In this paper, we propose an intelligent system for simultaneous\nautomated plane localization and CUA diagnosis. Our highlights are: 1) we\ndevelop a denoising diffusion model with local (plane) and global (volume/text)\nguidance, using an adaptive weighting strategy to optimize attention allocation\nto different conditions; 2) we introduce a reinforcement learning-based\nframework with unsupervised rewards to extract the key slice summary from\nredundant sequences, fully integrating information across multiple planes to\nreduce learning difficulty; 3) we provide text-driven uncertainty modeling for\ncoarse prediction, and leverage it to adjust the classification probability for\noverall performance improvement. Extensive experiments on a large 3D uterine US\ndataset show the efficacy of our method, in terms of plane localization and CUA\ndiagnosis. Code is available at https://github.com/yuhoo0302/CUA-US."}
{"id": "2506.23546", "pdf": "https://arxiv.org/pdf/2506.23546", "abs": "https://arxiv.org/abs/2506.23546", "authors": ["Zhendong Yu", "Weizhong Huang", "Haiping Huang"], "title": "Neural Langevin Machine: a local asymmetric learning rule can be creative", "categories": ["q-bio.NC", "cond-mat.dis-nn", "cs.LG", "cs.NE"], "comment": "15 pages, 3 figures, with Github link in the paper", "summary": "Fixed points of recurrent neural networks can be leveraged to store and\ngenerate information. These fixed points can be captured by the Boltzmann-Gibbs\nmeasure, which leads to neural Langevin dynamics that can be used for sampling\nand learning a real dataset. We call this type of generative model neural\nLangevin machine, which is interpretable due to its analytic form of\ndistribution and is simple to train. Moreover, the learning process is derived\nas a local asymmetric plasticity rule, bearing biological relevance. Therefore,\none can realize a continuous sampling of creative dynamics in a neural network,\nmimicking an imagination process in brain circuits. This neural Langevin\nmachine may be another promising generative model, at least in its strength in\ncircuit-based sampling and biologically plausible learning rule."}
{"id": "2506.23549", "pdf": "https://arxiv.org/pdf/2506.23549", "abs": "https://arxiv.org/abs/2506.23549", "authors": ["Huai-Chih Wang", "Hsiang-Chun Chuang", "Hsi-Chun Cheng", "Dai-Jie Wu", "Shao-Hua Sun"], "title": "CooT: Learning to Coordinate In-Context with Coordination Transformers", "categories": ["cs.AI", "cs.HC", "cs.LG"], "comment": "23 pages, 10 tables, 8 figures", "summary": "Effective coordination among artificial agents in dynamic and uncertain\nenvironments remains a significant challenge in multi-agent systems. Existing\napproaches, such as self-play and population-based methods, either generalize\npoorly to unseen partners or require extensive training. To overcome these\nlimitations, we propose Coordination Transformers (CooT), a novel in-context\ncoordination framework that uses recent interaction histories to adapt to\nunseen partners rapidly. Unlike previous approaches that primarily aim to\nincrease the diversity of training partners, CooT explicitly focuses on\nadapting to new partner behaviors by predicting actions aligned with observed\npartner interactions. Trained on interaction trajectories collected from\ndiverse pairs of agents with complementary behaviors, CooT quickly learns\neffective coordination strategies without explicit supervision or fine-tuning.\nEvaluations on the Overcooked benchmark demonstrate that CooT significantly\noutperforms baseline methods in coordination tasks involving previously unseen\npartners. Human evaluations further confirm CooT as the most effective\ncollaborative partner, while extensive ablations highlight its robustness,\nflexibility, and sensitivity to context in multi-agent scenarios."}
{"id": "2506.23550", "pdf": "https://arxiv.org/pdf/2506.23550", "abs": "https://arxiv.org/abs/2506.23550", "authors": ["Ryui Kaneko", "Shimpei Goto"], "title": "Seeding neural network quantum states with tensor network states", "categories": ["cond-mat.str-el", "cs.LG", "cs.NA", "math.NA", "quant-ph"], "comment": "13 pages, 13 figures", "summary": "We find an efficient approach to approximately convert matrix product states\n(MPSs) into restricted Boltzmann machine wave functions consisting of a\nmultinomial hidden unit through a canonical polyadic (CP) decomposition of the\nMPSs. This method allows us to generate well-behaved initial neural network\nquantum states for quantum many-body ground-state calculations in polynomial\ntime of the number of variational parameters and systematically shorten the\ndistance between the initial states and the ground states with increasing the\nrank of the CP decomposition. We demonstrate the efficiency of our method by\ntaking the transverse-field Ising model as an example and discuss possible\napplications of our method to more general quantum many-body systems in which\nthe ground-state wave functions possess complex nodal structures."}
{"id": "2506.23566", "pdf": "https://arxiv.org/pdf/2506.23566", "abs": "https://arxiv.org/abs/2506.23566", "authors": ["Luigi Sigillo", "Renato Giamba", "Danilo Comminiello"], "title": "Metadata, Wavelet, and Time Aware Diffusion Models for Satellite Image Super Resolution", "categories": ["cs.CV", "cs.LG"], "comment": "ICLR 2025 Workshop on Machine Learning for Remote Sensing (ML4RS)", "summary": "The acquisition of high-resolution satellite imagery is often constrained by\nthe spatial and temporal limitations of satellite sensors, as well as the high\ncosts associated with frequent observations. These challenges hinder\napplications such as environmental monitoring, disaster response, and\nagricultural management, which require fine-grained and high-resolution data.\nIn this paper, we propose MWT-Diff, an innovative framework for satellite image\nsuper-resolution (SR) that combines latent diffusion models with wavelet\ntransforms to address these challenges. At the core of the framework is a novel\nmetadata-, wavelet-, and time-aware encoder (MWT-Encoder), which generates\nembeddings that capture metadata attributes, multi-scale frequency information,\nand temporal relationships. The embedded feature representations steer the\nhierarchical diffusion dynamics, through which the model progressively\nreconstructs high-resolution satellite imagery from low-resolution inputs. This\nprocess preserves critical spatial characteristics including textural patterns,\nboundary discontinuities, and high-frequency spectral components essential for\ndetailed remote sensing analysis. The comparative analysis of MWT-Diff across\nmultiple datasets demonstrated favorable performance compared to recent\napproaches, as measured by standard perceptual quality metrics including FID\nand LPIPS."}
{"id": "2506.23573", "pdf": "https://arxiv.org/pdf/2506.23573", "abs": "https://arxiv.org/abs/2506.23573", "authors": ["Siddhartha Mondal", "Avik Mitra", "Chayan Sarkar"], "title": "Online Human Action Detection during Escorting", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "Accepted in IEEE RO-MAN '25", "summary": "The deployment of robot assistants in large indoor spaces has seen\nsignificant growth, with escorting tasks becoming a key application. However,\nmost current escorting robots primarily rely on navigation-focused strategies,\nassuming that the person being escorted will follow without issue. In crowded\nenvironments, this assumption often falls short, as individuals may struggle to\nkeep pace, become obstructed, get distracted, or need to stop unexpectedly. As\na result, conventional robotic systems are often unable to provide effective\nescorting services due to their limited understanding of human movement\ndynamics. To address these challenges, an effective escorting robot must\ncontinuously detect and interpret human actions during the escorting process\nand adjust its movement accordingly. However, there is currently no existing\ndataset designed specifically for human action detection in the context of\nescorting. Given that escorting often occurs in crowded environments, where\nother individuals may enter the robot's camera view, the robot also needs to\nidentify the specific human it is escorting (the subject) before predicting\ntheir actions. Since no existing model performs both person re-identification\nand action prediction in real-time, we propose a novel neural network\narchitecture that can accomplish both tasks. This enables the robot to adjust\nits speed dynamically based on the escortee's movements and seamlessly resume\nescorting after any disruption. In comparative evaluations against strong\nbaselines, our system demonstrates superior efficiency and effectiveness,\nshowcasing its potential to significantly improve robotic escorting services in\ncomplex, real-world scenarios."}
{"id": "2506.23581", "pdf": "https://arxiv.org/pdf/2506.23581", "abs": "https://arxiv.org/abs/2506.23581", "authors": ["Xiao Li", "Yiming Zhu", "Yifan Huang", "Wei Zhang", "Yingzhe He", "Jie Shi", "Xiaolin Hu"], "title": "PBCAT: Patch-based composite adversarial training against physically realizable attacks on object detection", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted by ICCV 2025", "summary": "Object detection plays a crucial role in many security-sensitive\napplications. However, several recent studies have shown that object detectors\ncan be easily fooled by physically realizable attacks, \\eg, adversarial patches\nand recent adversarial textures, which pose realistic and urgent threats.\nAdversarial Training (AT) has been recognized as the most effective defense\nagainst adversarial attacks. While AT has been extensively studied in the\n$l_\\infty$ attack settings on classification models, AT against physically\nrealizable attacks on object detectors has received limited exploration. Early\nattempts are only performed to defend against adversarial patches, leaving AT\nagainst a wider range of physically realizable attacks under-explored. In this\nwork, we consider defending against various physically realizable attacks with\na unified AT method. We propose PBCAT, a novel Patch-Based Composite\nAdversarial Training strategy. PBCAT optimizes the model by incorporating the\ncombination of small-area gradient-guided adversarial patches and imperceptible\nglobal adversarial perturbations covering the entire image. With these designs,\nPBCAT has the potential to defend against not only adversarial patches but also\nunseen physically realizable attacks such as adversarial textures. Extensive\nexperiments in multiple settings demonstrated that PBCAT significantly improved\nrobustness against various physically realizable attacks over state-of-the-art\ndefense methods. Notably, it improved the detection accuracy by 29.7\\% over\nprevious defense methods under one recent adversarial texture attack."}
{"id": "2506.23583", "pdf": "https://arxiv.org/pdf/2506.23583", "abs": "https://arxiv.org/abs/2506.23583", "authors": ["Marvin Xhemrishi", "Alexandre Graell i Amat", "Balázs Pejó"], "title": "Detect \\& Score: Privacy-Preserving Misbehaviour Detection and Contribution Evaluation in Federated Learning", "categories": ["cs.CR", "cs.DC", "cs.LG"], "comment": "The shorter version is accepted at FL-AsiaCCS 25", "summary": "Federated learning with secure aggregation enables private and collaborative\nlearning from decentralised data without leaking sensitive client information.\nHowever, secure aggregation also complicates the detection of malicious client\nbehaviour and the evaluation of individual client contributions to the\nlearning. To address these challenges, QI (Pejo et al.) and FedGT (Xhemrishi et\nal.) were proposed for contribution evaluation (CE) and misbehaviour detection\n(MD), respectively. QI, however, lacks adequate MD accuracy due to its reliance\non the random selection of clients in each training round, while FedGT lacks\nthe CE ability. In this work, we combine the strengths of QI and FedGT to\nachieve both robust MD and accurate CE. Our experiments demonstrate superior\nperformance compared to using either method independently."}
{"id": "2506.23619", "pdf": "https://arxiv.org/pdf/2506.23619", "abs": "https://arxiv.org/abs/2506.23619", "authors": ["Guillaume Coqueret", "Martial Laguerre"], "title": "Overparametrized models with posterior drift", "categories": ["q-fin.ST", "cs.LG", "econ.EM", "stat.ML"], "comment": null, "summary": "This paper investigates the impact of posterior drift on out-of-sample\nforecasting accuracy in overparametrized machine learning models. We document\nthe loss in performance when the loadings of the data generating process change\nbetween the training and testing samples. This matters crucially in settings in\nwhich regime changes are likely to occur, for instance, in financial markets.\nApplied to equity premium forecasting, our results underline the sensitivity of\na market timing strategy to sub-periods and to the bandwidth parameters that\ncontrol the complexity of the model. For the average investor, we find that\nfocusing on holding periods of 15 years can generate very heterogeneous\nreturns, especially for small bandwidths. Large bandwidths yield much more\nconsistent outcomes, but are far less appealing from a risk-adjusted return\nstandpoint. All in all, our findings tend to recommend cautiousness when\nresorting to large linear models for stock market predictions."}
{"id": "2506.23627", "pdf": "https://arxiv.org/pdf/2506.23627", "abs": "https://arxiv.org/abs/2506.23627", "authors": ["Roham Maiti", "Debasmita Bhoumik"], "title": "Brain Tumor Detection through Thermal Imaging and MobileNET", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Brain plays a crucial role in regulating body functions and cognitive\nprocesses, with brain tumors posing significant risks to human health. Precise\nand prompt detection is a key factor in proper treatment and better patient\noutcomes. Traditional methods for detecting brain tumors, that include\nbiopsies, MRI, and CT scans often face challenges due to their high costs and\nthe need for specialized medical expertise. Recent developments in machine\nlearning (ML) and deep learning (DL) has exhibited strong capabilities in\nautomating the identification and categorization of brain tumors from medical\nimages, especially MRI scans. However, these classical ML models have\nlimitations, such as high computational demands, the need for large datasets,\nand long training times, which hinder their accessibility and efficiency. Our\nresearch uses MobileNET model for efficient detection of these tumors. The\nnovelty of this project lies in building an accurate tumor detection model\nwhich use less computing re-sources and runs in less time followed by efficient\ndecision making through the use of image processing technique for accurate\nresults. The suggested method attained an average accuracy of 98.5%."}
{"id": "2506.23640", "pdf": "https://arxiv.org/pdf/2506.23640", "abs": "https://arxiv.org/abs/2506.23640", "authors": ["Ximeng Liu", "Shizhen Zhao", "Xinbing Wang"], "title": "Geminet: Learning the Duality-based Iterative Process for Lightweight Traffic Engineering in Changing Topologies", "categories": ["cs.NI", "cs.LG"], "comment": null, "summary": "Recently, researchers have explored ML-based Traffic Engineering (TE),\nleveraging neural networks to solve TE problems traditionally addressed by\noptimization. However, existing ML-based TE schemes remain impractical: they\neither fail to handle topology changes or suffer from poor scalability due to\nexcessive computational and memory overhead. To overcome these limitations, we\npropose Geminet, a lightweight and scalable ML-based TE framework that can\nhandle changing topologies. Geminet is built upon two key insights: (i) a\nmethodology that decouples neural networks from topology by learning an\niterative gradient-descent-based adjustment process, as the update rule of\ngradient descent is topology-agnostic, relying only on a few gradient-related\nquantities; (ii) shifting optimization from path-level routing weights to\nedge-level dual variables, reducing memory consumption by leveraging the fact\nthat edges are far fewer than paths. Evaluations on WAN and data center\ndatasets show that Geminet significantly improves scalability. Its neural\nnetwork size is only 0.04% to 7% of existing schemes, while handling topology\nvariations as effectively as HARP, a state-of-the-art ML-based TE approach,\nwithout performance degradation. When trained on large-scale topologies,\nGeminet consumes under 10 GiB of memory, more than eight times less than the\n80-plus GiB required by HARP, while achieving 5.45 times faster convergence\nspeed, demonstrating its potential for large-scale deployment."}
{"id": "2506.23663", "pdf": "https://arxiv.org/pdf/2506.23663", "abs": "https://arxiv.org/abs/2506.23663", "authors": ["Mario Koddenbrock", "Rudolf Hoffmann", "David Brodmann", "Erik Rodner"], "title": "On the Domain Robustness of Contrastive Vision-Language Models", "categories": ["cs.CV", "cs.LG", "I.4"], "comment": "Deepbench is available at https://github.com/ml-lab-htw/deepbench", "summary": "In real-world vision-language applications, practitioners increasingly rely\non large, pretrained foundation models rather than custom-built solutions,\ndespite limited transparency regarding their training data and processes. While\nthese models achieve impressive performance on general benchmarks, their\neffectiveness can decline notably under specialized domain shifts, such as\nunique imaging conditions or environmental variations. In this work, we\nintroduce Deepbench, a framework designed to assess domain-specific robustness\nof vision-language models (VLMs). Deepbench leverages a large language model\n(LLM) to generate realistic, context-aware image corruptions tailored to\nspecific deployment domains without requiring labeled data. We evaluate a range\nof contrastive vision-language architectures and architectural variants across\nsix real-world domains and observe substantial variability in robustness,\nhighlighting the need for targeted, domain-aware evaluation. Deepbench is\nreleased as open-source software to support further research into domain-aware\nrobustness assessment."}
{"id": "2506.23717", "pdf": "https://arxiv.org/pdf/2506.23717", "abs": "https://arxiv.org/abs/2506.23717", "authors": ["Xingting Yao", "Qinghao Hu", "Fei Zhou", "Tielong Liu", "Gang Li", "Peisong Wang", "Jian Cheng"], "title": "Towards Efficient and Accurate Spiking Neural Networks via Adaptive Bit Allocation", "categories": ["cs.NE", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Multi-bit spiking neural networks (SNNs) have recently become a heated\nresearch spot, pursuing energy-efficient and high-accurate AI. However, with\nmore bits involved, the associated memory and computation demands escalate to\nthe point where the performance improvements become disproportionate. Based on\nthe insight that different layers demonstrate different importance and extra\nbits could be wasted and interfering, this paper presents an adaptive bit\nallocation strategy for direct-trained SNNs, achieving fine-grained layer-wise\nallocation of memory and computation resources. Thus, SNN's efficiency and\naccuracy can be improved. Specifically, we parametrize the temporal lengths and\nthe bit widths of weights and spikes, and make them learnable and controllable\nthrough gradients. To address the challenges caused by changeable bit widths\nand temporal lengths, we propose the refined spiking neuron, which can handle\ndifferent temporal lengths, enable the derivation of gradients for temporal\nlengths, and suit spike quantization better. In addition, we theoretically\nformulate the step-size mismatch problem of learnable bit widths, which may\nincur severe quantization errors to SNN, and accordingly propose the step-size\nrenewal mechanism to alleviate this issue. Experiments on various datasets,\nincluding the static CIFAR and ImageNet and the dynamic CIFAR-DVS and\nDVS-GESTURE, demonstrate that our methods can reduce the overall memory and\ncomputation cost while achieving higher accuracy. Particularly, our\nSEWResNet-34 can achieve a 2.69\\% accuracy gain and 4.16$\\times$ lower bit\nbudgets over the advanced baseline work on ImageNet. This work will be fully\nopen-sourced."}
{"id": "2506.23721", "pdf": "https://arxiv.org/pdf/2506.23721", "abs": "https://arxiv.org/abs/2506.23721", "authors": ["Gijs Luijten", "Roberto Maria Scardigno", "Lisle Faray de Paiva", "Peter Hoyer", "Jens Kleesiek", "Domenico Buongiorno", "Vitoantonio Bevilacqua", "Jan Egger"], "title": "Deep Learning-Based Semantic Segmentation for Real-Time Kidney Imaging and Measurements with Augmented Reality-Assisted Ultrasound", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.HC", "cs.LG"], "comment": null, "summary": "Ultrasound (US) is widely accessible and radiation-free but has a steep\nlearning curve due to its dynamic nature and non-standard imaging planes.\nAdditionally, the constant need to shift focus between the US screen and the\npatient poses a challenge. To address these issues, we integrate deep learning\n(DL)-based semantic segmentation for real-time (RT) automated kidney volumetric\nmeasurements, which are essential for clinical assessment but are traditionally\ntime-consuming and prone to fatigue. This automation allows clinicians to\nconcentrate on image interpretation rather than manual measurements.\nComplementing DL, augmented reality (AR) enhances the usability of US by\nprojecting the display directly into the clinician's field of view, improving\nergonomics and reducing the cognitive load associated with screen-to-patient\ntransitions. Two AR-DL-assisted US pipelines on HoloLens-2 are proposed: one\nstreams directly via the application programming interface for a wireless\nsetup, while the other supports any US device with video output for broader\naccessibility. We evaluate RT feasibility and accuracy using the Open Kidney\nDataset and open-source segmentation models (nnU-Net, Segmenter, YOLO with\nMedSAM and LiteMedSAM). Our open-source GitHub pipeline includes model\nimplementations, measurement algorithms, and a Wi-Fi-based streaming solution,\nenhancing US training and diagnostics, especially in point-of-care settings."}
{"id": "2506.23767", "pdf": "https://arxiv.org/pdf/2506.23767", "abs": "https://arxiv.org/abs/2506.23767", "authors": ["Xue Wen Tan", "Stanley Kok"], "title": "Explainable AI for Comprehensive Risk Assessment for Financial Reports: A Lightweight Hierarchical Transformer Network Approach", "categories": ["q-fin.RM", "cs.LG"], "comment": null, "summary": "Every publicly traded U.S. company files an annual 10-K report containing\ncritical insights into financial health and risk. We propose Tiny eXplainable\nRisk Assessor (TinyXRA), a lightweight and explainable transformer-based model\nthat automatically assesses company risk from these reports. Unlike prior work\nthat relies solely on the standard deviation of excess returns (adjusted for\nthe Fama-French model), which indiscriminately penalizes both upside and\ndownside risk, TinyXRA incorporates skewness, kurtosis, and the Sortino ratio\nfor more comprehensive risk assessment. We leverage TinyBERT as our encoder to\nefficiently process lengthy financial documents, coupled with a novel dynamic,\nattention-based word cloud mechanism that provides intuitive risk visualization\nwhile filtering irrelevant terms. This lightweight design ensures scalable\ndeployment across diverse computing environments with real-time processing\ncapabilities for thousands of financial documents which is essential for\nproduction systems with constrained computational resources. We employ triplet\nloss for risk quartile classification, improving over pairwise loss approaches\nin existing literature by capturing both the direction and magnitude of risk\ndifferences. Our TinyXRA achieves state-of-the-art predictive accuracy across\nseven test years on a dataset spanning 2013-2024, while providing transparent\nand interpretable risk assessments. We conduct comprehensive ablation studies\nto evaluate our contributions and assess model explanations both quantitatively\nby systematically removing highly attended words and sentences, and\nqualitatively by examining explanation coherence. The paper concludes with\nfindings, practical implications, limitations, and future research directions."}
{"id": "2506.23783", "pdf": "https://arxiv.org/pdf/2506.23783", "abs": "https://arxiv.org/abs/2506.23783", "authors": ["Shiao Wang", "Ju Huang", "Qingchuan Ma", "Jinfeng Gao", "Chunyi Xu", "Xiao Wang", "Lan Chen", "Bo Jiang"], "title": "Mamba-FETrack V2: Revisiting State Space Model for Frame-Event based Visual Object Tracking", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Journal extension of Mamba-FETrack which was published on Pattern\n  Recognition and Computer Vision (PRCV) 2024", "summary": "Combining traditional RGB cameras with bio-inspired event cameras for robust\nobject tracking has garnered increasing attention in recent years. However,\nmost existing multimodal tracking algorithms depend heavily on high-complexity\nVision Transformer architectures for feature extraction and fusion across\nmodalities. This not only leads to substantial computational overhead but also\nlimits the effectiveness of cross-modal interactions. In this paper, we propose\nan efficient RGB-Event object tracking framework based on the linear-complexity\nVision Mamba network, termed Mamba-FETrack V2. Specifically, we first design a\nlightweight Prompt Generator that utilizes embedded features from each\nmodality, together with a shared prompt pool, to dynamically generate\nmodality-specific learnable prompt vectors. These prompts, along with the\nmodality-specific embedded features, are then fed into a Vision Mamba-based\nFEMamba backbone, which facilitates prompt-guided feature extraction,\ncross-modal interaction, and fusion in a unified manner. Finally, the fused\nrepresentations are passed to the tracking head for accurate target\nlocalization. Extensive experimental evaluations on multiple RGB-Event tracking\nbenchmarks, including short-term COESOT dataset and long-term datasets, i.e.,\nFE108 and FELT V2, demonstrate the superior performance and efficiency of the\nproposed tracking framework. The source code and pre-trained models will be\nreleased on https://github.com/Event-AHU/Mamba_FETrack"}
{"id": "2506.23784", "pdf": "https://arxiv.org/pdf/2506.23784", "abs": "https://arxiv.org/abs/2506.23784", "authors": ["Parosh Aziz Abdulla", "Mohamed Faouzi Atig", "Julie Cailler", "Chencheng Liang", "Philipp Rümmer"], "title": "When GNNs Met a Word Equations Solver: Learning to Rank Equations (Extended Technical Report)", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Nielsen transformation is a standard approach for solving word equations: by\nrepeatedly splitting equations and applying simplification steps, equations are\nrewritten until a solution is reached. When solving a conjunction of word\nequations in this way, the performance of the solver will depend considerably\non the order in which equations are processed. In this work, the use of Graph\nNeural Networks (GNNs) for ranking word equations before and during the solving\nprocess is explored. For this, a novel graph-based representation for word\nequations is presented, preserving global information across conjuncts,\nenabling the GNN to have a holistic view during ranking. To handle the variable\nnumber of conjuncts, three approaches to adapt a multi-classification task to\nthe problem of ranking equations are proposed. The training of the GNN is done\nwith the help of minimum unsatisfiable subsets (MUSes) of word equations. The\nexperimental results show that, compared to state-of-the-art string solvers,\nthe new framework solves more problems in benchmarks where each variable\nappears at most once in each equation."}
{"id": "2506.23793", "pdf": "https://arxiv.org/pdf/2506.23793", "abs": "https://arxiv.org/abs/2506.23793", "authors": ["Anton Andreychuk", "Konstantin Yakovlev", "Aleksandr Panov", "Alexey Skrynnik"], "title": "Advancing Learnable Multi-Agent Pathfinding Solvers with Active Fine-Tuning", "categories": ["cs.AI", "cs.LG", "cs.MA"], "comment": null, "summary": "Multi-agent pathfinding (MAPF) is a common abstraction of multi-robot\ntrajectory planning problems, where multiple homogeneous robots simultaneously\nmove in the shared environment. While solving MAPF optimally has been proven to\nbe NP-hard, scalable, and efficient, solvers are vital for real-world\napplications like logistics, search-and-rescue, etc. To this end, decentralized\nsuboptimal MAPF solvers that leverage machine learning have come on stage.\nBuilding on the success of the recently introduced MAPF-GPT, a pure imitation\nlearning solver, we introduce MAPF-GPT-DDG. This novel approach effectively\nfine-tunes the pre-trained MAPF model using centralized expert data. Leveraging\na novel delta-data generation mechanism, MAPF-GPT-DDG accelerates training\nwhile significantly improving performance at test time. Our experiments\ndemonstrate that MAPF-GPT-DDG surpasses all existing learning-based MAPF\nsolvers, including the original MAPF-GPT, regarding solution quality across\nmany testing scenarios. Remarkably, it can work with MAPF instances involving\nup to 1 million agents in a single environment, setting a new milestone for\nscalability in MAPF domains."}
{"id": "2506.23836", "pdf": "https://arxiv.org/pdf/2506.23836", "abs": "https://arxiv.org/abs/2506.23836", "authors": ["Alexander Tyurin"], "title": "Proving the Limited Scalability of Centralized Distributed Optimization via a New Lower Bound Construction", "categories": ["math.OC", "cs.DC", "cs.LG"], "comment": null, "summary": "We consider centralized distributed optimization in the classical federated\nlearning setup, where $n$ workers jointly find an $\\varepsilon$-stationary\npoint of an $L$-smooth, $d$-dimensional nonconvex function $f$, having access\nonly to unbiased stochastic gradients with variance $\\sigma^2$. Each worker\nrequires at most $h$ seconds to compute a stochastic gradient, and the\ncommunication times from the server to the workers and from the workers to the\nserver are $\\tau_{s}$ and $\\tau_{w}$ seconds per coordinate, respectively. One\nof the main motivations for distributed optimization is to achieve scalability\nwith respect to $n$. For instance, it is well known that the distributed\nversion of SGD has a variance-dependent runtime term $\\frac{h \\sigma^2 L\n\\Delta}{n \\varepsilon^2},$ which improves with the number of workers $n,$ where\n$\\Delta = f(x^0) - f^*,$ and $x^0 \\in R^d$ is the starting point. Similarly,\nusing unbiased sparsification compressors, it is possible to reduce both the\nvariance-dependent runtime term and the communication runtime term. However,\nonce we account for the communication from the server to the workers\n$\\tau_{s}$, we prove that it becomes infeasible to design a method using\nunbiased random sparsification compressors that scales both the server-side\ncommunication runtime term $\\tau_{s} d \\frac{L \\Delta}{\\varepsilon}$ and the\nvariance-dependent runtime term $\\frac{h \\sigma^2 L \\Delta}{\\varepsilon^2},$\nbetter than poly-logarithmically in $n$, even in the homogeneous (i.i.d.) case,\nwhere all workers access the same distribution. To establish this result, we\nconstruct a new \"worst-case\" function and develop a new lower bound framework\nthat reduces the analysis to the concentration of a random sum, for which we\nprove a concentration bound. These results reveal fundamental limitations in\nscaling distributed optimization, even under the homogeneous assumption."}
{"id": "2506.23855", "pdf": "https://arxiv.org/pdf/2506.23855", "abs": "https://arxiv.org/abs/2506.23855", "authors": ["Travis Dick", "Alessandro Epasto", "Adel Javanmard", "Josh Karlin", "Andres Munoz Medina", "Vahab Mirrokni", "Sergei Vassilvitskii", "Peilin Zhong"], "title": "Differentially Private Synthetic Data Release for Topics API Outputs", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": "20 pages, 8 figures", "summary": "The analysis of the privacy properties of Privacy-Preserving Ads APIs is an\narea of research that has received strong interest from academics, industry,\nand regulators. Despite this interest, the empirical study of these methods is\nhindered by the lack of publicly available data. Reliable empirical analysis of\nthe privacy properties of an API, in fact, requires access to a dataset\nconsisting of realistic API outputs; however, privacy concerns prevent the\ngeneral release of such data to the public.\n  In this work, we develop a novel methodology to construct synthetic API\noutputs that are simultaneously realistic enough to enable accurate study and\nprovide strong privacy protections. We focus on one Privacy-Preserving Ads\nAPIs: the Topics API, part of Google Chrome's Privacy Sandbox. We developed a\nmethodology to generate a differentially-private dataset that closely matches\nthe re-identification risk properties of the real Topics API data. The use of\ndifferential privacy provides strong theoretical bounds on the leakage of\nprivate user information from this release.\n  Our methodology is based on first computing a large number of\ndifferentially-private statistics describing how output API traces evolve over\ntime. Then, we design a parameterized distribution over sequences of API traces\nand optimize its parameters so that they closely match the statistics obtained.\nFinally, we create the synthetic data by drawing from this distribution.\n  Our work is complemented by an open-source release of the anonymized dataset\nobtained by this methodology. We hope this will enable external researchers to\nanalyze the API in-depth and replicate prior and future work on a realistic\nlarge-scale dataset. We believe that this work will contribute to fostering\ntransparency regarding the privacy properties of Privacy-Preserving Ads APIs."}
{"id": "2506.23869", "pdf": "https://arxiv.org/pdf/2506.23869", "abs": "https://arxiv.org/abs/2506.23869", "authors": ["Louis Bradshaw", "Honglu Fan", "Alexander Spangher", "Stella Biderman", "Simon Colton"], "title": "Scaling Self-Supervised Representation Learning for Symbolic Piano Performance", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "comment": "ISMIR (2025)", "summary": "We study the capabilities of generative autoregressive transformer models\ntrained on large amounts of symbolic solo-piano transcriptions. After first\npretraining on approximately 60,000 hours of music, we use a comparatively\nsmaller, high-quality subset, to finetune models to produce musical\ncontinuations, perform symbolic classification tasks, and produce\ngeneral-purpose contrastive MIDI embeddings by adapting the SimCLR framework to\nsymbolic music. When evaluating piano continuation coherence, our generative\nmodel outperforms leading symbolic generation techniques and remains\ncompetitive with proprietary audio generation models. On MIR classification\nbenchmarks, frozen representations from our contrastive model achieve\nstate-of-the-art results in linear probe experiments, while direct finetuning\ndemonstrates the generalizability of pretrained representations, often\nrequiring only a few hundred labeled examples to specialize to downstream\ntasks."}
{"id": "2506.23873", "pdf": "https://arxiv.org/pdf/2506.23873", "abs": "https://arxiv.org/abs/2506.23873", "authors": ["Yuexuan Kong", "Gabriel Meseguer-Brocal", "Vincent Lostanlen", "Mathieu Lagrange", "Romain Hennequin"], "title": "Emergent musical properties of a transformer under contrastive self-supervised learning", "categories": ["cs.SD", "cs.IR", "cs.LG", "eess.AS"], "comment": "Accepted at ISMIR 2025", "summary": "In music information retrieval (MIR), contrastive self-supervised learning\nfor general-purpose representation models is effective for global tasks such as\nautomatic tagging. However, for local tasks such as chord estimation, it is\nwidely assumed that contrastively trained general-purpose self-supervised\nmodels are inadequate and that more sophisticated SSL is necessary; e.g.,\nmasked modeling. Our paper challenges this assumption by revealing the\npotential of contrastive SSL paired with a transformer in local MIR tasks. We\nconsider a lightweight vision transformer with one-dimensional patches in the\ntime--frequency domain (ViT-1D) and train it with simple contrastive SSL\nthrough normalized temperature-scaled cross-entropy loss (NT-Xent). Although\nNT-Xent operates only over the class token, we observe that, potentially thanks\nto weight sharing, informative musical properties emerge in ViT-1D's sequence\ntokens. On global tasks, the temporal average of class and sequence tokens\noffers a performance increase compared to the class token alone, showing useful\nproperties in the sequence tokens. On local tasks, sequence tokens perform\nunexpectedly well, despite not being specifically trained for. Furthermore,\nhigh-level musical features such as onsets emerge from layer-wise attention\nmaps and self-similarity matrices show different layers capture different\nmusical dimensions. Our paper does not focus on improving performance but\nadvances the musical interpretation of transformers and sheds light on some\noverlooked abilities of contrastive SSL paired with transformers for sequence\nmodeling in MIR."}
{"id": "2506.23881", "pdf": "https://arxiv.org/pdf/2506.23881", "abs": "https://arxiv.org/abs/2506.23881", "authors": ["Reihaneh Zohrabi", "Hosein Hasani", "Mahdieh Soleymani Baghshah", "Anna Rohrbach", "Marcus Rohrbach", "Mohammad Hossein Rohban"], "title": "Spurious-Aware Prototype Refinement for Reliable Out-of-Distribution Detection", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Out-of-distribution (OOD) detection is crucial for ensuring the reliability\nand safety of machine learning models in real-world applications, where they\nfrequently face data distributions unseen during training. Despite progress,\nexisting methods are often vulnerable to spurious correlations that mislead\nmodels and compromise robustness. To address this, we propose SPROD, a novel\nprototype-based OOD detection approach that explicitly addresses the challenge\nposed by unknown spurious correlations. Our post-hoc method refines class\nprototypes to mitigate bias from spurious features without additional data or\nhyperparameter tuning, and is broadly applicable across diverse backbones and\nOOD detection settings. We conduct a comprehensive spurious correlation OOD\ndetection benchmarking, comparing our method against existing approaches and\ndemonstrating its superior performance across challenging OOD datasets, such as\nCelebA, Waterbirds, UrbanCars, Spurious Imagenet, and the newly introduced\nAnimals MetaCoCo. On average, SPROD improves AUROC by 4.7% and FPR@95 by 9.3%\nover the second best."}
{"id": "2506.23908", "pdf": "https://arxiv.org/pdf/2506.23908", "abs": "https://arxiv.org/abs/2506.23908", "authors": ["András György", "Tor Lattimore", "Nevena Lazić", "Csaba Szepesvári"], "title": "Beyond Statistical Learning: Exact Learning Is Essential for General Intelligence", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Sound deductive reasoning -- the ability to derive new knowledge from\nexisting facts and rules -- is an indisputably desirable aspect of general\nintelligence. Despite the major advances of AI systems in areas such as math\nand science, especially since the introduction of transformer architectures, it\nis well-documented that even the most advanced frontier systems regularly and\nconsistently falter on easily-solvable deductive reasoning tasks. Hence, these\nsystems are unfit to fulfill the dream of achieving artificial general\nintelligence capable of sound deductive reasoning. We argue that their unsound\nbehavior is a consequence of the statistical learning approach powering their\ndevelopment. To overcome this, we contend that to achieve reliable deductive\nreasoning in learning-based AI systems, researchers must fundamentally shift\nfrom optimizing for statistical performance against distributions on reasoning\nproblems and algorithmic tasks to embracing the more ambitious exact learning\nparadigm, which demands correctness on all inputs. We argue that exact learning\nis both essential and possible, and that this ambitious objective should guide\nalgorithm design."}
{"id": "2506.23909", "pdf": "https://arxiv.org/pdf/2506.23909", "abs": "https://arxiv.org/abs/2506.23909", "authors": ["David Bálik", "Martin Jureček", "Mark Stamp"], "title": "RawMal-TF: Raw Malware Dataset Labeled by Type and Family", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "This work addresses the challenge of malware classification using machine\nlearning by developing a novel dataset labeled at both the malware type and\nfamily levels. Raw binaries were collected from sources such as VirusShare, VX\nUnderground, and MalwareBazaar, and subsequently labeled with family\ninformation parsed from binary names and type-level labels integrated from\nClarAVy. The dataset includes 14 malware types and 17 malware families, and was\nprocessed using a unified feature extraction pipeline based on static analysis,\nparticularly extracting features from Portable Executable headers, to support\nadvanced classification tasks. The evaluation was focused on three key\nclassification tasks. In the binary classification of malware versus benign\nsamples, Random Forest and XGBoost achieved high accuracy on the full datasets,\nreaching 98.5% for type-based detection and 98.98% for family-based detection.\nWhen using truncated datasets of 1,000 samples to assess performance under\nlimited data conditions, both models still performed strongly, achieving 97.6%\nfor type-based detection and 98.66% for family-based detection. For interclass\nclassification, which distinguishes between malware types or families, the\nmodels reached up to 97.5% accuracy on type-level tasks and up to 93.7% on\nfamily-level tasks. In the multiclass classification setting, which assigns\nsamples to the correct type or family, SVM achieved 81.1% accuracy on type\nlabels, while Random Forest and XGBoost reached approximately 73.4% on family\nlabels. The results highlight practical trade-offs between accuracy and\ncomputational cost, and demonstrate that labeling at both the type and family\nlevels enables more fine-grained and insightful malware classification. The\nwork establishes a robust foundation for future research on advanced malware\ndetection and classification."}
{"id": "2506.23914", "pdf": "https://arxiv.org/pdf/2506.23914", "abs": "https://arxiv.org/abs/2506.23914", "authors": ["Evan Bell", "Daniel A. Serino", "Ben S. Southworth", "Trevor Wilcox", "Marc L. Klasky"], "title": "Learning robust parameter inference and density reconstruction in flyer plate impact experiments", "categories": ["physics.comp-ph", "cs.LG"], "comment": "24 pages, 21 figures", "summary": "Estimating physical parameters or material properties from experimental\nobservations is a common objective in many areas of physics and material\nscience. In many experiments, especially in shock physics, radiography is the\nprimary means of observing the system of interest. However, radiography does\nnot provide direct access to key state variables, such as density, which\nprevents the application of traditional parameter estimation approaches. Here\nwe focus on flyer plate impact experiments on porous materials, and resolving\nthe underlying parameterized equation of state (EoS) and crush porosity model\nparameters given radiographic observation(s). We use machine learning as a tool\nto demonstrate with high confidence that using only high impact velocity data\ndoes not provide sufficient information to accurately infer both EoS and crush\nmodel parameters, even with fully resolved density fields or a dynamic sequence\nof images. We thus propose an observable data set consisting of low and high\nimpact velocity experiments/simulations that capture different regimes of\ncompaction and shock propagation, and proceed to introduce a generative machine\nlearning approach which produces a posterior distribution of physical\nparameters directly from radiographs. We demonstrate the effectiveness of the\napproach in estimating parameters from simulated flyer plate impact\nexperiments, and show that the obtained estimates of EoS and crush model\nparameters can then be used in hydrodynamic simulations to obtain accurate and\nphysically admissible density reconstructions. Finally, we examine the\nrobustness of the approach to model mismatches, and find that the learned\napproach can provide useful parameter estimates in the presence of\nout-of-distribution radiographic noise and previously unseen physics, thereby\npromoting a potential breakthrough in estimating material properties from\nexperimental radiographic images."}
{"id": "2506.23921", "pdf": "https://arxiv.org/pdf/2506.23921", "abs": "https://arxiv.org/abs/2506.23921", "authors": ["Germans Savcisens", "Tina Eliassi-Rad"], "title": "The Trilemma of Truth in Large Language Models", "categories": ["cs.CL", "cs.LG", "stat.ML"], "comment": null, "summary": "We often attribute human characteristics to large language models (LLMs) and\nclaim that they \"know\" certain things. LLMs have an internal probabilistic\nknowledge that represents information retained during training. How can we\nassess the veracity of this knowledge? We examine two common methods for\nprobing the veracity of LLMs and discover several assumptions that are flawed.\nTo address these flawed assumptions, we introduce sAwMIL (short for Sparse\nAware Multiple-Instance Learning), a probing method that utilizes the internal\nactivations of LLMs to separate statements into true, false, and neither.\nsAwMIL is based on multiple-instance learning and conformal prediction. We\nevaluate sAwMIL on 5 validity criteria across 16 open-source LLMs, including\nboth default and chat-based variants, as well as on 3 new datasets. Among the\ninsights we provide are: (1) the veracity signal is often concentrated in the\nthird quarter of an LLM's depth; (2) truth and falsehood signals are not always\nsymmetric; (3) linear probes perform better on chat models than on default\nmodels; (4) nonlinear probes may be required to capture veracity signals for\nsome LLMs with reinforcement learning from human feedback or knowledge\ndistillation; and (5) LLMs capture a third type of signal that is distinct from\ntrue and false and is neither true nor false. These findings provide a reliable\nmethod for verifying what LLMs \"know\" and how certain they are of their\nprobabilistic internal knowledge."}
{"id": "2506.23926", "pdf": "https://arxiv.org/pdf/2506.23926", "abs": "https://arxiv.org/abs/2506.23926", "authors": ["Junping Wang", "Bicheng Wang", "Yibo Xuea", "Yuan Xie"], "title": "Industrial brain: a human-like autonomous neuro-symbolic cognitive decision-making system", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Resilience non-equilibrium measurement, the ability to maintain fundamental\nfunctionality amidst failures and errors, is crucial for scientific management\nand engineering applications of industrial chain. The problem is particularly\nchallenging when the number or types of multiple co-evolution of resilience\n(for example, randomly placed) are extremely chaos. Existing end-to-end deep\nlearning ordinarily do not generalize well to unseen full-feld reconstruction\nof spatiotemporal co-evolution structure, and predict resilience of network\ntopology, especially in multiple chaos data regimes typically seen in\nreal-world applications. To address this challenge, here we propose industrial\nbrain, a human-like autonomous cognitive decision-making and planning framework\nintegrating higher-order activity-driven neuro network and CT-OODA symbolic\nreasoning to autonomous plan resilience directly from observational data of\nglobal variable. The industrial brain not only understands and model structure\nof node activity dynamics and network co-evolution topology without simplifying\nassumptions, and reveal the underlying laws hidden behind complex networks, but\nalso enabling accurate resilience prediction, inference, and planning.\nExperimental results show that industrial brain significantly outperforms\nresilience prediction and planning methods, with an accurate improvement of up\nto 10.8\\% over GoT and OlaGPT framework and 11.03\\% over spectral dimension\nreduction. It also generalizes to unseen topologies and dynamics and maintains\nrobust performance despite observational disturbances. Our findings suggest\nthat industrial brain addresses an important gap in resilience prediction and\nplanning for industrial chain."}
{"id": "2506.23934", "pdf": "https://arxiv.org/pdf/2506.23934", "abs": "https://arxiv.org/abs/2506.23934", "authors": ["Xiangchen Li", "Saeid Ghafouri", "Bo Ji", "Hans Vandierendonck", "Deepu John", "Dimitrios S. Nikolopoulos"], "title": "QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference", "categories": ["cs.DC", "cs.AI", "cs.LG", "cs.PF"], "comment": null, "summary": "As machine learning inferences increasingly move to edge devices, adapting to\ndiverse computational capabilities, hardware, and memory constraints becomes\nmore critical. Instead of relying on a pre-trained model fixed for all future\ninference queries across diverse edge devices, we argue that planning an\ninference pattern with a request-specific model tailored to the device's\ncomputational capacity, accuracy requirements, and time constraints is more\ncost-efficient and robust to diverse scenarios. To this end, we propose an\naccuracy-aware and workload-balanced inference system that integrates joint\nmodel quantization and inference partitioning. In this approach, the server\ndynamically responds to inference queries by sending a quantized model and\nadaptively sharing the inference workload with the device. Meanwhile, the\ndevice's computational power, channel capacity, and accuracy requirements are\nconsidered when deciding.\n  Furthermore, we introduce a new optimization framework for the inference\nsystem, incorporating joint model quantization and partitioning. Our approach\noptimizes layer-wise quantization bit width and partition points to minimize\ntime consumption and cost while accounting for varying accuracy requirements of\ntasks through an accuracy degradation metric in our optimization model. To our\nknowledge, this work represents the first exploration of optimizing\nquantization layer-wise bit-width in the inference serving system, by\nintroducing theoretical measurement of accuracy degradation. Simulation results\ndemonstrate a substantial reduction in overall time and power consumption, with\ncomputation payloads decreasing by over 80% and accuracy degradation kept below\n1%."}
{"id": "2506.23952", "pdf": "https://arxiv.org/pdf/2506.23952", "abs": "https://arxiv.org/abs/2506.23952", "authors": ["Stefan Buijsman", "Sarah Carter", "Juan Pablo Bermúdez"], "title": "Autonomy by Design: Preserving Human Autonomy in AI Decision-Support", "categories": ["cs.HC", "cs.AI", "cs.LG", "econ.GN", "q-fin.EC"], "comment": null, "summary": "AI systems increasingly support human decision-making across domains of\nprofessional, skill-based, and personal activity. While previous work has\nexamined how AI might affect human autonomy globally, the effects of AI on\ndomain-specific autonomy -- the capacity for self-governed action within\ndefined realms of skill or expertise -- remain understudied. We analyze how AI\ndecision-support systems affect two key components of domain-specific autonomy:\nskilled competence (the ability to make informed judgments within one's domain)\nand authentic value-formation (the capacity to form genuine domain-relevant\nvalues and preferences). By engaging with prior investigations and analyzing\nempirical cases across medical, financial, and educational domains, we\ndemonstrate how the absence of reliable failure indicators and the potential\nfor unconscious value shifts can erode domain-specific autonomy both\nimmediately and over time. We then develop a constructive framework for\nautonomy-preserving AI support systems. We propose specific socio-technical\ndesign patterns -- including careful role specification, implementation of\ndefeater mechanisms, and support for reflective practice -- that can help\nmaintain domain-specific autonomy while leveraging AI capabilities. This\nframework provides concrete guidance for developing AI systems that enhance\nrather than diminish human agency within specialized domains of action."}
{"id": "2506.23964", "pdf": "https://arxiv.org/pdf/2506.23964", "abs": "https://arxiv.org/abs/2506.23964", "authors": ["Hongyu Hè", "Minhao Jin", "Maria Apostolaki"], "title": "Learning Constraints Directly from Network Data", "categories": ["cs.NI", "cs.LG", "C.2.3; I.2.6; I.2.3"], "comment": "13 pages, 15 figures", "summary": "Network data conforms to a wide range of rules that arise from protocols,\ndesign principles, and deployment decisions (e.g., a packet's queuing delay\nmust be less than its end-to-end delay). Formalizing such rules as logic\nconstraints can (i) improve the quality of synthetic data, (ii) reduce the\nbrittleness of machine learning (ML) models, and (iii) improve semantic\nunderstanding of network measurements. However, these benefits remain out of\nreach if rule extraction is manual or solely reliant on ML, as both approaches\nyield incomplete, unreliable, and/or inaccurate rules.\n  This paper formulates rule extraction as a constraint modeling problem and\nintroduces NetNomos that learns propositional logic constraints directly from\nraw network measurements. Constraint modeling in this domain is uniquely\nchallenging due to the scale of the data, the inherent learning complexity and\npassive environment, and the lack of ground truth supervision. NetNomos\naddresses these challenges via a lattice-based search structured by constraint\nspecificity and succinctness. Our approach reduces learning complexity from\nsuperquadratic to logarithmic and enables efficient traversal in combinatorial\nsearch space.\n  Our evaluations on diverse network datasets show that NetNomos learns all\nbenchmark rules, including those associated with as little as 0.01% of data\npoints, in under three hours. In contrast, baseline methods discover less than\n25% of the rules and require several days to run. Through three case studies,\nwe show that: NetNomos (i) finds rule violations in the outputs of all seven\nsynthetic traffic generators, hence can be used to assess and guide their\ngeneration process; (ii) detects semantic differences in traffic, hence can be\nused for anomaly detection; and (iii) automatically finds rules used for\ntelemetry imputation, hence can support monitoring through inference."}
{"id": "2506.23990", "pdf": "https://arxiv.org/pdf/2506.23990", "abs": "https://arxiv.org/abs/2506.23990", "authors": ["Dustin Wright"], "title": "Machine Understanding of Scientific Language", "categories": ["cs.CL", "cs.LG"], "comment": "PhD Thesis, 210 pages", "summary": "Scientific information expresses human understanding of nature. This\nknowledge is largely disseminated in different forms of text, including\nscientific papers, news articles, and discourse among people on social media.\nWhile important for accelerating our pursuit of knowledge, not all scientific\ntext is faithful to the underlying science. As the volume of this text has\nburgeoned online in recent years, it has become a problem of societal\nimportance to be able to identify the faithfulness of a given piece of\nscientific text automatically. This thesis is concerned with the cultivation of\ndatasets, methods, and tools for machine understanding of scientific language,\nin order to analyze and understand science communication at scale. To arrive at\nthis, I present several contributions in three areas of natural language\nprocessing and machine learning: automatic fact checking, learning with limited\ndata, and scientific text processing. These contributions include new methods\nand resources for identifying check-worthy claims, adversarial claim\ngeneration, multi-source domain adaptation, learning from crowd-sourced labels,\ncite-worthiness detection, zero-shot scientific fact checking, detecting\nexaggerated scientific claims, and modeling degrees of information change in\nscience communication. Critically, I demonstrate how the research outputs of\nthis thesis are useful for effectively learning from limited amounts of\nscientific text in order to identify misinformative scientific statements and\ngenerate new insights into the science communication process"}
{"id": "2506.24007", "pdf": "https://arxiv.org/pdf/2506.24007", "abs": "https://arxiv.org/abs/2506.24007", "authors": ["Masahiro Kato"], "title": "Minimax and Bayes Optimal Best-arm Identification: Adaptive Experimental Design for Treatment Choice", "categories": ["econ.EM", "cs.LG", "math.ST", "stat.ME", "stat.ML", "stat.TH"], "comment": null, "summary": "This study investigates adaptive experimental design for treatment choice,\nalso known as fixed-budget best-arm identification. We consider an adaptive\nprocedure consisting of a treatment-allocation phase followed by a\ntreatment-choice phase, and we design an adaptive experiment for this setup to\nefficiently identify the best treatment arm, defined as the one with the\nhighest expected outcome. In our designed experiment, the treatment-allocation\nphase consists of two stages. The first stage is a pilot phase, where we\nallocate each treatment arm uniformly with equal proportions to eliminate\nclearly suboptimal arms and estimate outcome variances. In the second stage, we\nallocate treatment arms in proportion to the variances estimated in the first\nstage. After the treatment-allocation phase, the procedure enters the\ntreatment-choice phase, where we choose the treatment arm with the highest\nsample mean as our estimate of the best treatment arm. We prove that this\nsingle design is simultaneously asymptotically minimax and Bayes optimal for\nthe simple regret, with upper bounds that match our lower bounds up to exact\nconstants. Therefore, our designed experiment achieves the sharp efficiency\nlimits without requiring separate tuning for minimax and Bayesian objectives."}
{"id": "2506.24024", "pdf": "https://arxiv.org/pdf/2506.24024", "abs": "https://arxiv.org/abs/2506.24024", "authors": ["Nicolas Heintz", "Tom Francart", "Alexander Bertrand"], "title": "Post-processing of EEG-based Auditory Attention Decoding Decisions via Hidden Markov Models", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "Auditory attention decoding (AAD) algorithms exploit brain signals, such as\nelectroencephalography (EEG), to identify which speaker a listener is focusing\non in a multi-speaker environment. While state-of-the-art AAD algorithms can\nidentify the attended speaker on short time windows, their predictions are\noften too inaccurate for practical use. In this work, we propose augmenting AAD\nwith a hidden Markov model (HMM) that models the temporal structure of\nattention. More specifically, the HMM relies on the fact that a subject is much\nless likely to switch attention than to keep attending the same speaker at any\nmoment in time. We show how a HMM can significantly improve existing AAD\nalgorithms in both causal (real-time) and non-causal (offline) settings. We\nfurther demonstrate that HMMs outperform existing postprocessing approaches in\nboth accuracy and responsiveness, and explore how various factors such as\nwindow length, switching frequency, and AAD accuracy influence overall\nperformance. The proposed method is computationally efficient, intuitive to use\nand applicable in both real-time and offline settings."}
{"id": "2506.24041", "pdf": "https://arxiv.org/pdf/2506.24041", "abs": "https://arxiv.org/abs/2506.24041", "authors": ["Alexis Melot", "Sean U. N. Wood", "Yannick Coffinier", "Pierre Yger", "Fabien Alibart"], "title": "Unsupervised Sparse Coding-based Spiking Neural Network for Real-time Spike Sorting", "categories": ["cs.NE", "cs.LG"], "comment": "Main article : 16 pages, 7 figures and 4 tables. Supplementary\n  Material starts at page 17 with 7 figures", "summary": "Spike sorting is a crucial step in decoding multichannel extracellular neural\nsignals, enabling the identification of individual neuronal activity. A key\nchallenge in brain-machine interfaces (BMIs) is achieving real-time, low-power\nspike sorting at the edge while keeping high neural decoding performance. This\nstudy introduces the Neuromorphic Sparse Sorter (NSS), a compact two-layer\nspiking neural network optimized for efficient spike sorting. NSS leverages the\nLocally Competitive Algorithm (LCA) for sparse coding to extract relevant\nfeatures from noisy events with reduced computational demands. NSS learns to\nsort detected spike waveforms in an online fashion and operates entirely\nunsupervised. To exploit multi-bit spike coding capabilities of neuromorphic\nplatforms like Intel's Loihi 2, a custom neuron model was implemented, enabling\nflexible power-performance trade-offs via adjustable spike bit-widths.\nEvaluations on simulated and real-world tetrode signals with biological drift\nshowed NSS outperformed established pipelines such as WaveClus3 and PCA+KMeans.\nWith 2-bit graded spikes, NSS on Loihi 2 outperformed NSS implemented with\nleaky integrate-and-fire neuron and achieved an F1-score of 77% (+10%\nimprovement) while consuming 8.6mW (+1.65mW) when tested on a drifting\nrecording, with a computational processing time of 0.25ms (+60 us) per\ninference."}
{"id": "2506.24045", "pdf": "https://arxiv.org/pdf/2506.24045", "abs": "https://arxiv.org/abs/2506.24045", "authors": ["Xinming Wei", "Jiahao Zhang", "Haoran Li", "Jiayu Chen", "Rui Qu", "Maoliang Li", "Xiang Chen", "Guojie Luo"], "title": "Agent.xpu: Efficient Scheduling of Agentic LLM Workloads on Heterogeneous SoC", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "The proliferation of agentic Large Language Models (LLMs) on personal devices\nintroduces a new class of workloads characterized by a dichotomy of objectives.\nReactive tasks, initiated by users, demand immediate, low-latency responses,\nwhile proactive tasks operate invisibly and prioritize throughput. Existing\non-device LLM engines, designed for isolated inferences, fail to efficiently\nmanage these concurrent and conflicting requests on consumer-grade\nheterogeneous SoCs with CPU, integrated GPU, and NPU. This paper introduces\nAgent.xpu, an efficient serving system for agentic LLM workloads on\nmemory-unified heterogeneous SoCs. With dedicated offline profiling, Agent.xpu\nfirst constructs a heterogeneous execution graph, which fuses and chunks model\nkernels for affinity-guided, elastic accelerator mapping with predictive kernel\nannotation. At runtime, its online scheduler enables fine-grained, kernel-level\npreemption to guarantee the responsiveness of reactive tasks. To maximize SoC\nutilization, it adopts slack-aware kernel backfill to opportunistically append\nproactive tasks, and mitigates NPU-iGPU contention via bandwidth-aware\ndispatch. Evaluation on an Intel Core Ultra SoC shows that Agent.xpu achieves\n4.6$\\times$ lower latency for reactive tasks and sustains\n1.6$\\times$-6.8$\\times$ higher throughput for proactive tasks compared to\nstate-of-the-art inference engines."}
{"id": "2506.24048", "pdf": "https://arxiv.org/pdf/2506.24048", "abs": "https://arxiv.org/abs/2506.24048", "authors": ["Tim Roith", "Leon Bungert", "Philipp Wacker"], "title": "Consensus-based optimization for closed-box adversarial attacks and a connection to evolution strategies", "categories": ["math.OC", "cs.LG", "65K10, 68Q32, 65K15, 90C26"], "comment": null, "summary": "Consensus-based optimization (CBO) has established itself as an efficient\ngradient-free optimization scheme, with attractive mathematical properties,\nsuch as mean-field convergence results for non-convex loss functions. In this\nwork, we study CBO in the context of closed-box adversarial attacks, which are\nimperceptible input perturbations that aim to fool a classifier, without\naccessing its gradient. Our contribution is to establish a connection between\nthe so-called consensus hopping as introduced by Riedl et al. and natural\nevolution strategies (NES) commonly applied in the context of adversarial\nattacks and to rigorously relate both methods to gradient-based optimization\nschemes. Beyond that, we provide a comprehensive experimental study that shows\nthat despite the conceptual similarities, CBO can outperform NES and other\nevolutionary strategies in certain scenarios."}
{"id": "2506.24056", "pdf": "https://arxiv.org/pdf/2506.24056", "abs": "https://arxiv.org/abs/2506.24056", "authors": ["Tung-Ling Li", "Hongliang Liu"], "title": "Logit-Gap Steering: Efficient Short-Suffix Jailbreaks for Aligned Large Language Models", "categories": ["cs.CR", "cs.CL", "cs.LG"], "comment": null, "summary": "We introduce logit-gap steering, a fast jailbreak framework that casts the\nrefusal-affirmation gap of RLHF-aligned language models as a single pass over\nthe vocabulary. A forward-computable score blends gap reduction with\nlightweight proxies for KL penalty and reward shift, allowing a \"sort-sum-stop\"\nsweep to complete in under a second and return a short suffix--two orders of\nmagnitude fewer model calls than beam or gradient attacks. The same suffix\ngeneralises to unseen prompts and scales from 0.5 B to 70 B checkpoints,\nlifting one-shot attack success from baseline levels to 80-100% while\npreserving topical coherence. Beyond efficiency, these suffixes expose\nsentence-boundary reward cliffs and other alignment artefacts, offering a\nlightweight probe into how safety tuning reshapes internal representations."}
{"id": "2506.24081", "pdf": "https://arxiv.org/pdf/2506.24081", "abs": "https://arxiv.org/abs/2506.24081", "authors": ["Rahul Kumar", "Wenqi Wei", "Ying Mao", "Junaid Farooq", "Ying Wang", "Juntao Chen"], "title": "SQUASH: A SWAP-Based Quantum Attack to Sabotage Hybrid Quantum Neural Networks", "categories": ["quant-ph", "cs.AI", "cs.LG"], "comment": "Keywords: Quantum Machine Learning, Hybrid Quantum Neural Networks,\n  SWAP Test, Fidelity, Circuit-level Attack", "summary": "We propose a circuit-level attack, SQUASH, a SWAP-Based Quantum Attack to\nsabotage Hybrid Quantum Neural Networks (HQNNs) for classification tasks.\nSQUASH is executed by inserting SWAP gate(s) into the variational quantum\ncircuit of the victim HQNN. Unlike conventional noise-based or adversarial\ninput attacks, SQUASH directly manipulates the circuit structure, leading to\nqubit misalignment and disrupting quantum state evolution. This attack is\nhighly stealthy, as it does not require access to training data or introduce\ndetectable perturbations in input states. Our results demonstrate that SQUASH\nsignificantly degrades classification performance, with untargeted SWAP attacks\nreducing accuracy by up to 74.08\\% and targeted SWAP attacks reducing target\nclass accuracy by up to 79.78\\%. These findings reveal a critical vulnerability\nin HQNN implementations, underscoring the need for more resilient architectures\nagainst circuit-level adversarial interventions."}
{"id": "2506.24108", "pdf": "https://arxiv.org/pdf/2506.24108", "abs": "https://arxiv.org/abs/2506.24108", "authors": ["Shai Yehezkel", "Omer Dahary", "Andrey Voynov", "Daniel Cohen-Or"], "title": "Navigating with Annealing Guidance Scale in Diffusion Space", "categories": ["cs.GR", "cs.AI", "cs.CV", "cs.LG"], "comment": "Project page:\n  https://annealing-guidance.github.io/annealing-guidance/", "summary": "Denoising diffusion models excel at generating high-quality images\nconditioned on text prompts, yet their effectiveness heavily relies on careful\nguidance during the sampling process. Classifier-Free Guidance (CFG) provides a\nwidely used mechanism for steering generation by setting the guidance scale,\nwhich balances image quality and prompt alignment. However, the choice of the\nguidance scale has a critical impact on the convergence toward a visually\nappealing and prompt-adherent image. In this work, we propose an annealing\nguidance scheduler which dynamically adjusts the guidance scale over time based\non the conditional noisy signal. By learning a scheduling policy, our method\naddresses the temperamental behavior of CFG. Empirical results demonstrate that\nour guidance scheduler significantly enhances image quality and alignment with\nthe text prompt, advancing the performance of text-to-image generation.\nNotably, our novel scheduler requires no additional activations or memory\nconsumption, and can seamlessly replace the common classifier-free guidance,\noffering an improved trade-off between prompt alignment and quality."}
{"id": "2506.24119", "pdf": "https://arxiv.org/pdf/2506.24119", "abs": "https://arxiv.org/abs/2506.24119", "authors": ["Bo Liu", "Leon Guertler", "Simon Yu", "Zichen Liu", "Penghui Qi", "Daniel Balcells", "Mickel Liu", "Cheston Tan", "Weiyan Shi", "Min Lin", "Wee Sun Lee", "Natasha Jaques"], "title": "SPIRAL: Self-Play on Zero-Sum Games Incentivizes Reasoning via Multi-Agent Multi-Turn Reinforcement Learning", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "Work in Progress", "summary": "Recent advances in reinforcement learning have shown that language models can\ndevelop sophisticated reasoning through training on tasks with verifiable\nrewards, but these approaches depend on human-curated problem-answer pairs and\ndomain-specific reward engineering. We introduce SPIRAL, a self-play framework\nwhere models learn by playing multi-turn, zero-sum games against continuously\nimproving versions of themselves, eliminating the need for human supervision.\nThrough self-play, SPIRAL generates an infinite curriculum of progressively\nchallenging problems as models must constantly adapt to stronger opponents. To\nenable this self-play training at scale, We implement a fully online,\nmulti-turn, multi-agent reinforcement learning system for LLMs and propose\nrole-conditioned advantage estimation (RAE) to stabilize multi-agent training.\nUsing SPIRAL, self-play on zero-sum games produces reasoning capabilities that\ntransfer broadly. Training Qwen3-4B-Base on Kuhn Poker alone achieves 8.6%\nimprovement on math and 8.4% on general reasoning, outperforming SFT on 25,000\nexpert game trajectories. Analysis reveals that this transfer occurs through\nthree cognitive patterns: systematic decomposition, expected value calculation,\nand case-by-case analysis. Multi-game training (TicTacToe, Kuhn Poker, Simple\nNegotiation) further enhances performance as each game develops distinct\nreasoning strengths. Applying SPIRAL to a strong reasoning model\n(DeepSeek-R1-Distill-Qwen-7B) can still lead to 2.0% average improvement. These\nresults demonstrate that zero-sum games naturally develop transferable\nreasoning capabilities, highlighting a promising direction for autonomous\nreasoning development."}
