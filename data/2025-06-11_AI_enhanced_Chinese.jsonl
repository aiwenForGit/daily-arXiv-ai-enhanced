{"id": "2506.08018", "pdf": "https://arxiv.org/pdf/2506.08018", "abs": "https://arxiv.org/abs/2506.08018", "authors": ["Fei Li", "Song Liu", "Weiguo Wu", "Shiqiang Nie", "Jinyu Wang"], "title": "KVmix: Gradient-Based Layer Importance-Aware Mixed-Precision Quantization for KV Cache", "categories": ["cs.LG", "cs.AI", "03B65 ((Primary))", "I.2.7"], "comment": "14 pages, 8 figures, 4 tables", "summary": "The high memory demands of the Key-Value (KV) Cache during the inference of\nLarge Language Models (LLMs) severely restrict their deployment in\nresource-constrained platforms. Quantization can effectively alleviate the\nmemory pressure caused by KV Cache. However, existing methods either rely on\nstatic one-size-fits-all precision allocation or fail to dynamically prioritize\ncritical KV in long-context tasks, forcing memory-accuracy-throughput\ntradeoffs. In this work, we propose a novel mixed-precision quantization method\nfor KV Cache named KVmix. KVmix leverages gradient-based importance analysis to\nevaluate how individual Key and Value projection matrices affect the model\nloss, enabling layer-specific bit-width allocation for mix-precision\nquantization. It dynamically prioritizes higher precision for important layers\nwhile aggressively quantizing less influential ones, achieving a tunable\nbalance between accuracy and efficiency. KVmix also introduces a dynamic\nlong-context optimization strategy that adaptively keeps full-precision KV\npairs for recent pivotal tokens and compresses older ones, achieving\nhigh-quality sequence generation with low memory usage. Additionally, KVmix\nprovides efficient low-bit quantization and CUDA kernels to optimize\ncomputational overhead. On LLMs such as Llama and Mistral, KVmix achieves\nnear-lossless inference performance with extremely low quantization\nconfiguration (Key 2.19bit Value 2.38bit), while delivering a remarkable 4.9x\nmemory compression and a 5.3x speedup in inference throughput.", "AI": {"tldr": "KVmix\u662f\u4e00\u79cd\u65b0\u578b\u6df7\u5408\u7cbe\u5ea6\u91cf\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u4f18\u5316LLM\u63a8\u7406\u4e2d\u7684KV\u7f13\u5b58\uff0c\u901a\u8fc7\u52a8\u6001\u5206\u914d\u7cbe\u5ea6\u548c\u957f\u4e0a\u4e0b\u6587\u4f18\u5316\u7b56\u7565\uff0c\u663e\u8457\u964d\u4f4e\u5185\u5b58\u5360\u7528\u5e76\u63d0\u5347\u63a8\u7406\u901f\u5ea6\u3002", "motivation": "LLM\u63a8\u7406\u4e2d\u7684KV\u7f13\u5b58\u5185\u5b58\u9700\u6c42\u9ad8\uff0c\u9650\u5236\u4e86\u5176\u5728\u8d44\u6e90\u53d7\u9650\u5e73\u53f0\u4e0a\u7684\u90e8\u7f72\u3002\u73b0\u6709\u91cf\u5316\u65b9\u6cd5\u65e0\u6cd5\u52a8\u6001\u5206\u914d\u7cbe\u5ea6\u6216\u4f18\u5316\u957f\u4e0a\u4e0b\u6587\u4efb\u52a1\u3002", "method": "KVmix\u5229\u7528\u68af\u5ea6\u91cd\u8981\u6027\u5206\u6790\uff0c\u52a8\u6001\u5206\u914d\u5c42\u7279\u5b9a\u6bd4\u7279\u5bbd\u5ea6\uff0c\u5e76\u5f15\u5165\u957f\u4e0a\u4e0b\u6587\u4f18\u5316\u7b56\u7565\uff0c\u4f18\u5148\u4fdd\u7559\u5173\u952eKV\u5bf9\u7684\u9ad8\u7cbe\u5ea6\u3002", "result": "\u5728Llama\u548cMistral\u7b49LLM\u4e0a\uff0cKVmix\u5b9e\u73b0\u4e86\u63a5\u8fd1\u65e0\u635f\u7684\u63a8\u7406\u6027\u80fd\uff0c\u5185\u5b58\u538b\u7f294.9\u500d\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u53475.3\u500d\u3002", "conclusion": "KVmix\u901a\u8fc7\u52a8\u6001\u6df7\u5408\u7cbe\u5ea6\u91cf\u5316\u548c\u957f\u4e0a\u4e0b\u6587\u4f18\u5316\uff0c\u6709\u6548\u5e73\u8861\u4e86\u5185\u5b58\u3001\u7cbe\u5ea6\u548c\u6548\u7387\uff0c\u4e3aLLM\u90e8\u7f72\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.08019", "pdf": "https://arxiv.org/pdf/2506.08019", "abs": "https://arxiv.org/abs/2506.08019", "authors": ["Andrew Wells", "Geraldine Henningsen", "Brice Bolane Tchinde Kengne"], "title": "Gridding Forced Displacement using Semi-Supervised Learning", "categories": ["cs.LG", "cs.CV", "cs.CY"], "comment": null, "summary": "We present a semi-supervised approach that disaggregates refugee statistics\nfrom administrative boundaries to 0.5-degree grid cells across 25 Sub-Saharan\nAfrican countries. By integrating UNHCR's ProGres registration data with\nsatellite-derived building footprints from Google Open Buildings and location\ncoordinates from OpenStreetMap Populated Places, our label spreading algorithm\ncreates spatially explicit refugee statistics at high granularity.This\nmethodology achieves 92.9% average accuracy in placing over 10 million refugee\nobservations into appropriate grid cells, enabling the identification of\nlocalized displacement patterns previously obscured in broader regional and\nnational statistics. The resulting high-resolution dataset provides a\nfoundation for a deeper understanding of displacement drivers.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u534a\u76d1\u7763\u65b9\u6cd5\uff0c\u5c06\u96be\u6c11\u7684\u7edf\u8ba1\u6570\u636e\u4ece\u884c\u653f\u8fb9\u754c\u5206\u89e3\u52300.5\u5ea6\u7684\u7f51\u683c\u5355\u5143\u4e2d\uff0c\u8986\u76d625\u4e2a\u6492\u54c8\u62c9\u4ee5\u5357\u975e\u6d32\u56fd\u5bb6\u3002", "motivation": "\u901a\u8fc7\u9ad8\u5206\u8fa8\u7387\u7684\u6570\u636e\u5206\u6790\uff0c\u63ed\u793a\u4ee5\u5f80\u88ab\u533a\u57df\u548c\u56fd\u5bb6\u7edf\u8ba1\u6570\u636e\u63a9\u76d6\u7684\u5c40\u90e8\u6d41\u79bb\u5931\u6240\u6a21\u5f0f\u3002", "method": "\u7ed3\u5408UNHCR\u7684ProGres\u6ce8\u518c\u6570\u636e\u3001Google Open Buildings\u7684\u536b\u661f\u5efa\u7b51\u8db3\u8ff9\u548cOpenStreetMap\u7684\u5730\u70b9\u5750\u6807\uff0c\u4f7f\u7528\u6807\u7b7e\u4f20\u64ad\u7b97\u6cd5\u751f\u6210\u9ad8\u7cbe\u5ea6\u7684\u96be\u6c11\u7edf\u8ba1\u6570\u636e\u3002", "result": "\u65b9\u6cd5\u5e73\u5747\u51c6\u786e\u7387\u8fbe\u523092.9%\uff0c\u6210\u529f\u5c061000\u591a\u4e07\u96be\u6c11\u89c2\u6d4b\u6570\u636e\u5206\u914d\u5230\u5408\u9002\u7684\u7f51\u683c\u5355\u5143\u3002", "conclusion": "\u9ad8\u5206\u8fa8\u7387\u6570\u636e\u96c6\u4e3a\u6df1\u5165\u7406\u89e3\u6d41\u79bb\u5931\u6240\u7684\u9a71\u52a8\u56e0\u7d20\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.08020", "pdf": "https://arxiv.org/pdf/2506.08020", "abs": "https://arxiv.org/abs/2506.08020", "authors": ["Zi-Ying Chen", "Chuan-Xian Ren", "Hong Yan"], "title": "Bi-level Unbalanced Optimal Transport for Partial Domain Adaptation", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Partial domain adaptation (PDA) problem requires aligning cross-domain\nsamples while distinguishing the outlier classes for accurate knowledge\ntransfer. The widely used weighting framework tries to address the outlier\nclasses by introducing the reweighed source domain with a similar label\ndistribution to the target domain. However, the empirical modeling of weights\ncan only characterize the sample-wise relations, which leads to insufficient\nexploration of cluster structures, and the weights could be sensitive to the\ninaccurate prediction and cause confusion on the outlier classes. To tackle\nthese issues, we propose a Bi-level Unbalanced Optimal Transport (BUOT) model\nto simultaneously characterize the sample-wise and class-wise relations in a\nunified transport framework. Specifically, a cooperation mechanism between\nsample-level and class-level transport is introduced, where the sample-level\ntransport provides essential structure information for the class-level\nknowledge transfer, while the class-level transport supplies discriminative\ninformation for the outlier identification. The bi-level transport plan\nprovides guidance for the alignment process. By incorporating the label-aware\ntransport cost, the local transport structure is ensured and a fast computation\nformulation is derived to improve the efficiency. Extensive experiments on\nbenchmark datasets validate the competitiveness of BUOT.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u5c42\u6b21\u4e0d\u5e73\u8861\u6700\u4f18\u4f20\u8f93\uff08BUOT\uff09\u6a21\u578b\uff0c\u7528\u4e8e\u89e3\u51b3\u90e8\u5206\u9886\u57df\u81ea\u9002\u5e94\uff08PDA\uff09\u95ee\u9898\uff0c\u901a\u8fc7\u540c\u65f6\u8868\u5f81\u6837\u672c\u7ea7\u548c\u7c7b\u7ea7\u5173\u7cfb\uff0c\u63d0\u5347\u77e5\u8bc6\u8f6c\u79fb\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u90e8\u5206\u9886\u57df\u81ea\u9002\u5e94\u95ee\u9898\u9700\u8981\u5bf9\u9f50\u8de8\u9886\u57df\u6837\u672c\u5e76\u8bc6\u522b\u5f02\u5e38\u7c7b\uff0c\u73b0\u6709\u52a0\u6743\u6846\u67b6\u4ec5\u80fd\u8868\u5f81\u6837\u672c\u7ea7\u5173\u7cfb\uff0c\u5bf9\u5f02\u5e38\u7c7b\u7684\u8bc6\u522b\u4e0d\u591f\u51c6\u786e\u3002", "method": "\u63d0\u51faBUOT\u6a21\u578b\uff0c\u7ed3\u5408\u6837\u672c\u7ea7\u548c\u7c7b\u7ea7\u4f20\u8f93\uff0c\u901a\u8fc7\u5408\u4f5c\u673a\u5236\u63d0\u4f9b\u7ed3\u6784\u4fe1\u606f\u548c\u5224\u522b\u4fe1\u606f\uff0c\u5e76\u5f15\u5165\u6807\u7b7e\u611f\u77e5\u4f20\u8f93\u6210\u672c\u4ee5\u63d0\u9ad8\u6548\u7387\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86BUOT\u7684\u7ade\u4e89\u529b\u3002", "conclusion": "BUOT\u6a21\u578b\u901a\u8fc7\u53cc\u5c42\u6b21\u4f20\u8f93\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u90e8\u5206\u9886\u57df\u81ea\u9002\u5e94\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u77e5\u8bc6\u8f6c\u79fb\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2506.08021", "pdf": "https://arxiv.org/pdf/2506.08021", "abs": "https://arxiv.org/abs/2506.08021", "authors": ["Weihao Zou", "Weibing Feng", "Pin Wu"], "title": "FlowBERT: Prompt-tuned BERT for variable flow field prediction", "categories": ["cs.LG", "physics.flu-dyn"], "comment": null, "summary": "This study proposes a universal flow field prediction framework based on\nknowledge transfer\n  from large language model (LLM), addressing the high computational costs of\ntraditional\n  computational fluid dynamics (CFD) methods and the limited cross-condition\ntransfer capability\n  of existing deep learning models. The framework innovatively integrates\nProper Orthogonal\n  Decomposition (POD) dimensionality reduction with fine-tuning strategies for\npretrained LLM,\n  where POD facilitates compressed representation of flow field features while\nthe fine-tuned model\n  learns to encode system dynamics in state space. To enhance the model's\nadaptability to flow field\n  data, we specifically designed fluid dynamics-oriented text templates that\nimprove predictive\n  performance through enriched contextual semantic information. Experimental\nresults demonstrate\n  that our framework outperforms conventional Transformer models in few-shot\nlearning scenarios while\n  exhibiting exceptional generalization across various inflow conditions and\nairfoil geometries.\n  Ablation studies reveal the contributions of key components in the FlowBERT\narchitecture. Compared\n  to traditional Navier-Stokes equation solvers requiring hours of computation,\nour approach reduces\n  prediction time to seconds while maintaining over 90% accuracy. The developed\nknowledge transfer\n  paradigm establishes a new direction for rapid fluid dynamics prediction,\nwith potential\n  applications extending to aerodynamic optimization, flow control, and other\nengineering domains.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u77e5\u8bc6\u8fc1\u79fb\u7684\u901a\u7528\u6d41\u573a\u9884\u6d4b\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u8ba1\u7b97\u6d41\u4f53\u52a8\u529b\u5b66\uff08CFD\uff09\u65b9\u6cd5\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u548c\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u8de8\u6761\u4ef6\u8fc1\u79fb\u80fd\u529b\u6709\u9650\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edfCFD\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u800c\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u8de8\u6761\u4ef6\u8fc1\u79fb\u80fd\u529b\u4e0a\u8868\u73b0\u4e0d\u8db3\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u4e14\u9002\u5e94\u6027\u5f3a\u7684\u9884\u6d4b\u6846\u67b6\u3002", "method": "\u6846\u67b6\u521b\u65b0\u6027\u5730\u7ed3\u5408\u4e86Proper Orthogonal Decomposition\uff08POD\uff09\u964d\u7ef4\u6280\u672f\u548c\u9884\u8bad\u7ec3LLM\u7684\u5fae\u8c03\u7b56\u7565\uff0cPOD\u7528\u4e8e\u6d41\u573a\u7279\u5f81\u7684\u538b\u7f29\u8868\u793a\uff0c\u5fae\u8c03\u6a21\u578b\u5219\u5b66\u4e60\u5728\u72b6\u6001\u7a7a\u95f4\u4e2d\u7f16\u7801\u7cfb\u7edf\u52a8\u6001\u3002\u6b64\u5916\uff0c\u8bbe\u8ba1\u4e86\u6d41\u4f53\u52a8\u529b\u5b66\u5bfc\u5411\u7684\u6587\u672c\u6a21\u677f\u4ee5\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u5c11\u6837\u672c\u5b66\u4e60\u573a\u666f\u4e2d\u4f18\u4e8e\u4f20\u7edfTransformer\u6a21\u578b\uff0c\u5e76\u5728\u591a\u79cd\u6d41\u5165\u6761\u4ef6\u548c\u7ffc\u578b\u51e0\u4f55\u4e2d\u8868\u73b0\u51fa\u5353\u8d8a\u7684\u6cdb\u5316\u80fd\u529b\u3002\u4e0e\u4f20\u7edfNavier-Stokes\u65b9\u7a0b\u6c42\u89e3\u5668\u76f8\u6bd4\uff0c\u9884\u6d4b\u65f6\u95f4\u7f29\u77ed\u81f3\u79d2\u7ea7\u4e14\u4fdd\u630190%\u4ee5\u4e0a\u51c6\u786e\u7387\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5feb\u901f\u6d41\u4f53\u52a8\u529b\u5b66\u9884\u6d4b\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\uff0c\u6f5c\u5728\u5e94\u7528\u5305\u62ec\u6c14\u52a8\u4f18\u5316\u3001\u6d41\u52a8\u63a7\u5236\u7b49\u5de5\u7a0b\u9886\u57df\u3002"}}
{"id": "2506.08022", "pdf": "https://arxiv.org/pdf/2506.08022", "abs": "https://arxiv.org/abs/2506.08022", "authors": ["Chenxi Liu", "Tianyi Xiong", "Ruibo Chen", "Yihan Wu", "Junfeng Guo", "Tianyi Zhou", "Heng Huang"], "title": "Modality-Balancing Preference Optimization of Large Multimodal Models by Adversarial Negative Mining", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "The task adaptation and alignment of Large Multimodal Models (LMMs) have been\nsignificantly advanced by instruction tuning and further strengthened by recent\npreference optimization. Yet, most LMMs still suffer from severe modality\nimbalance during reasoning, i.e., outweighing language prior biases over visual\ninputs, which bottlenecks their generalization to downstream tasks and causes\nhallucinations. However, existing preference optimization approaches for LMMs\ndo not focus on restraining the internal biases of their Large Language Model\n(LLM) backbones when curating the training data. Moreover, they heavily rely on\noffline data and lack the capacity to explore diverse responses adaptive to\ndynamic distributional shifts during training. Meanwhile, Group Relative Policy\nOptimization (GRPO), a recent method using online-generated data and verified\nrewards to improve reasoning capabilities, remains largely underexplored in LMM\nalignment. In this paper, we propose a novel preference learning framework,\nModality-Balancing Preference Optimization (MBPO), to address the modality\nimbalance in LMMs. MBPO constructs a more effective offline preference dataset\nby generating hard negatives, i.e., rejected responses misled by LLM biases due\nto limited usage of visual information, through adversarial perturbation of\ninput images. Moreover, MBPO leverages the easy-to-verify nature of close-ended\ntasks to generate online responses with verified rewards. GRPO is then employed\nto train the model with offline-online hybrid data. Extensive experiments\ndemonstrate that MBPO can enhance LMM performance on challenging\nvision-language tasks and effectively reduce hallucinations.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMBPO\u7684\u65b0\u504f\u597d\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u751f\u6210\u786c\u8d1f\u6837\u672c\u548c\u5728\u7ebf\u9a8c\u8bc1\u5956\u52b1\u6570\u636e\uff0c\u7ed3\u5408GRPO\u65b9\u6cd5\uff0c\u89e3\u51b3\u591a\u6a21\u6001\u6a21\u578b\u4e2d\u7684\u6a21\u6001\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u63d0\u5347\u6027\u80fd\u5e76\u51cf\u5c11\u5e7b\u89c9\u3002", "motivation": "\u73b0\u6709\u504f\u597d\u4f18\u5316\u65b9\u6cd5\u672a\u6709\u6548\u6291\u5236LLM\u9aa8\u5e72\u7684\u5185\u90e8\u504f\u89c1\uff0c\u4e14\u4f9d\u8d56\u79bb\u7ebf\u6570\u636e\uff0c\u65e0\u6cd5\u9002\u5e94\u52a8\u6001\u5206\u5e03\u53d8\u5316\uff0c\u5bfc\u81f4\u591a\u6a21\u6001\u6a21\u578b\u5728\u63a8\u7406\u4e2d\u51fa\u73b0\u6a21\u6001\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "method": "MBPO\u901a\u8fc7\u5bf9\u6297\u6027\u6270\u52a8\u751f\u6210\u786c\u8d1f\u6837\u672c\u6784\u5efa\u79bb\u7ebf\u504f\u597d\u6570\u636e\u96c6\uff0c\u5e76\u5229\u7528\u95ed\u7aef\u4efb\u52a1\u751f\u6210\u5728\u7ebf\u9a8c\u8bc1\u5956\u52b1\u6570\u636e\uff0c\u7ed3\u5408GRPO\u65b9\u6cd5\u8bad\u7ec3\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cMBPO\u80fd\u663e\u8457\u63d0\u5347\u591a\u6a21\u6001\u6a21\u578b\u5728\u89c6\u89c9\u8bed\u8a00\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u5e76\u6709\u6548\u51cf\u5c11\u5e7b\u89c9\u3002", "conclusion": "MBPO\u4e3a\u89e3\u51b3\u591a\u6a21\u6001\u6a21\u578b\u4e2d\u7684\u6a21\u6001\u4e0d\u5e73\u8861\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u65b9\u6cd5\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.08027", "pdf": "https://arxiv.org/pdf/2506.08027", "abs": "https://arxiv.org/abs/2506.08027", "authors": ["Asit Mishra", "Dusan Stosic", "Simon Layton"], "title": "Recipes for Pre-training LLMs with MXFP8", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": null, "summary": "Precision scaling - using fewer bits to represent model parameters and\nrelated tensors during pre-training - has emerged as a compelling technique for\nimproving GPU efficiency without sacrificing accuracy. Microscaling (MX)\nformats in NVIDIA's latest Blackwell GPUs represent a major leap in enabling\nthis precision scaling aspect. These formats combine narrow floating-point data\ntypes with per-block scaling factors, offering a fine-grained approach to\nquantizing tensors.\n  Although MX-formats offer the promise of improved numeric stability compared\nto other reduced-precision representations, in practice they must be used\ncarefully in order to successfully converge an LLM on a multi-trillion token\ndataset. In this paper, we show that the rounding mode suggested in OCP\nspecification can lead to divergence when pre-training an LLM. We show an\nimproved rounding mode, which uses round-to-infinity to compute scaling\nfactors, enables successful pre-training in MXFP8 for an 8B model on 15T\ntokens.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u9884\u8bad\u7ec3\u4e2d\u4f7f\u7528\u4f4e\u7cbe\u5ea6\u8868\u793a\uff08\u5982MX\u683c\u5f0f\uff09\u4ee5\u63d0\u9ad8GPU\u6548\u7387\u7684\u65b9\u6cd5\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u820d\u5165\u6a21\u5f0f\u4ee5\u907f\u514d\u6a21\u578b\u53d1\u6563\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u7cbe\u5ea6\u7f29\u653e\uff08\u5982MX\u683c\u5f0f\uff09\u5728\u4e0d\u727a\u7272\u51c6\u786e\u6027\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8GPU\u6548\u7387\uff0c\u540c\u65f6\u89e3\u51b3\u5b9e\u9645\u5e94\u7528\u4e2d\u53ef\u80fd\u51fa\u73b0\u7684\u6570\u503c\u7a33\u5b9a\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u820d\u5165\u6a21\u5f0f\uff08round-to-infinity\uff09\u6765\u8ba1\u7b97\u7f29\u653e\u56e0\u5b50\uff0c\u4ee5\u89e3\u51b3OCP\u89c4\u8303\u4e2d\u5efa\u8bae\u7684\u820d\u5165\u6a21\u5f0f\u5bfc\u81f4\u7684\u6a21\u578b\u53d1\u6563\u95ee\u9898\u3002", "result": "\u5728MXFP8\u683c\u5f0f\u4e0b\uff0c\u4f7f\u7528\u6539\u8fdb\u7684\u820d\u5165\u6a21\u5f0f\u6210\u529f\u9884\u8bad\u7ec3\u4e86\u4e00\u4e2a8B\u53c2\u6570\u7684\u6a21\u578b\uff0c\u6570\u636e\u96c6\u89c4\u6a21\u4e3a15T tokens\u3002", "conclusion": "\u6539\u8fdb\u7684\u820d\u5165\u6a21\u5f0f\u80fd\u591f\u6709\u6548\u89e3\u51b3MX\u683c\u5f0f\u5728\u9884\u8bad\u7ec3\u4e2d\u7684\u6570\u503c\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u4e3a\u4f4e\u7cbe\u5ea6\u9884\u8bad\u7ec3\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.08051", "pdf": "https://arxiv.org/pdf/2506.08051", "abs": "https://arxiv.org/abs/2506.08051", "authors": ["Mahmuda Sultana Mimi", "Md Monzurul Islam", "Anannya Ghosh Tusti", "Shriyank Somvanshi", "Subasish Das"], "title": "ST-GraphNet: A Spatio-Temporal Graph Neural Network for Understanding and Predicting Automated Vehicle Crash Severity", "categories": ["cs.LG"], "comment": null, "summary": "Understanding the spatial and temporal dynamics of automated vehicle (AV)\ncrash severity is critical for advancing urban mobility safety and\ninfrastructure planning. In this work, we introduce ST-GraphNet, a\nspatio-temporal graph neural network framework designed to model and predict AV\ncrash severity by using both fine-grained and region-aggregated spatial graphs.\nUsing a balanced dataset of 2,352 real-world AV-related crash reports from\nTexas (2024), including geospatial coordinates, crash timestamps, SAE\nautomation levels, and narrative descriptions, we construct two complementary\ngraph representations: (1) a fine-grained graph with individual crash events as\nnodes, where edges are defined via spatio-temporal proximity; and (2) a\ncoarse-grained graph where crashes are aggregated into Hexagonal Hierarchical\nSpatial Indexing (H3)-based spatial cells, connected through hexagonal\nadjacency. Each node in the graph is enriched with multimodal data, including\nsemantic, spatial, and temporal attributes, including textual embeddings from\ncrash narratives using a pretrained Sentence-BERT model. We evaluate various\ngraph neural network (GNN) architectures, such as Graph Convolutional Networks\n(GCN), Graph Attention Networks (GAT), and Dynamic Spatio-Temporal GCN\n(DSTGCN), to classify crash severity and predict high-risk regions. Our\nproposed ST-GraphNet, which utilizes a DSTGCN backbone on the coarse-grained H3\ngraph, achieves a test accuracy of 97.74\\%, substantially outperforming the\nbest fine-grained model (64.7\\% test accuracy). These findings highlight the\neffectiveness of spatial aggregation, dynamic message passing, and multi-modal\nfeature integration in capturing the complex spatio-temporal patterns\nunderlying AV crash severity.", "AI": {"tldr": "ST-GraphNet\u662f\u4e00\u4e2a\u65f6\u7a7a\u56fe\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\uff0c\u7528\u4e8e\u5efa\u6a21\u548c\u9884\u6d4b\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\uff08AV\uff09\u78b0\u649e\u4e25\u91cd\u6027\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u548c\u533a\u57df\u805a\u5408\u7684\u7a7a\u95f4\u56fe\u5b9e\u73b0\uff0c\u6d4b\u8bd5\u51c6\u786e\u7387\u8fbe97.74%\u3002", "motivation": "\u7406\u89e3AV\u78b0\u649e\u4e25\u91cd\u6027\u7684\u65f6\u7a7a\u52a8\u6001\u5bf9\u63d0\u5347\u57ce\u5e02\u4ea4\u901a\u5b89\u5168\u548c\u57fa\u7840\u8bbe\u65bd\u89c4\u5212\u81f3\u5173\u91cd\u8981\u3002", "method": "\u4f7f\u7528\u7ec6\u7c92\u5ea6\u548cH3\u7a7a\u95f4\u5355\u5143\u805a\u5408\u7684\u56fe\u8868\u793a\uff0c\u7ed3\u5408\u591a\u6a21\u6001\u6570\u636e\uff08\u5982\u6587\u672c\u5d4c\u5165\uff09\uff0c\u8bc4\u4f30\u591a\u79cdGNN\u67b6\u6784\uff08\u5982GCN\u3001GAT\u3001DSTGCN\uff09\u3002", "result": "ST-GraphNet\u5728\u7c97\u7c92\u5ea6H3\u56fe\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u6d4b\u8bd5\u51c6\u786e\u738797.74%\uff0c\u663e\u8457\u4f18\u4e8e\u7ec6\u7c92\u5ea6\u6a21\u578b\uff0864.7%\uff09\u3002", "conclusion": "\u7a7a\u95f4\u805a\u5408\u3001\u52a8\u6001\u6d88\u606f\u4f20\u9012\u548c\u591a\u6a21\u6001\u7279\u5f81\u6574\u5408\u80fd\u6709\u6548\u6355\u6349AV\u78b0\u649e\u4e25\u91cd\u6027\u7684\u590d\u6742\u65f6\u7a7a\u6a21\u5f0f\u3002"}}
{"id": "2506.08054", "pdf": "https://arxiv.org/pdf/2506.08054", "abs": "https://arxiv.org/abs/2506.08054", "authors": ["Yiming Wang", "Hao Peng", "Senzhang Wang", "Haohua Du", "Chunyang Liu", "Jia Wu", "Guanlin Wu"], "title": "STAMImputer: Spatio-Temporal Attention MoE for Traffic Data Imputation", "categories": ["cs.LG", "cs.AI"], "comment": "10 pages, 5 figures, 3 tables. Extended version of paper accepted at\n  IJCAI 2025", "summary": "Traffic data imputation is fundamentally important to support various\napplications in intelligent transportation systems such as traffic flow\nprediction. However, existing time-to-space sequential methods often fail to\neffectively extract features in block-wise missing data scenarios. Meanwhile,\nthe static graph structure for spatial feature propagation significantly\nconstrains the models flexibility in handling the distribution shift issue for\nthe nonstationary traffic data. To address these issues, this paper proposes a\nSpatioTemporal Attention Mixture of experts network named STAMImputer for\ntraffic data imputation. Specifically, we introduce a Mixture of Experts (MoE)\nframework to capture latent spatio-temporal features and their influence\nweights, effectively imputing block missing. A novel Low-rank guided Sampling\nGraph ATtention (LrSGAT) mechanism is designed to dynamically balance the local\nand global correlations across road networks. The sampled attention vectors are\nutilized to generate dynamic graphs that capture real-time spatial\ncorrelations. Extensive experiments are conducted on four traffic datasets for\nevaluation. The result shows STAMImputer achieves significantly performance\nimprovement compared with existing SOTA approaches. Our codes are available at\nhttps://github.com/RingBDStack/STAMImupter.", "AI": {"tldr": "STAMImputer\u662f\u4e00\u79cd\u7528\u4e8e\u4ea4\u901a\u6570\u636e\u586b\u8865\u7684\u65f6\u7a7a\u6ce8\u610f\u529b\u6df7\u5408\u4e13\u5bb6\u7f51\u7edc\uff0c\u901a\u8fc7\u52a8\u6001\u56fe\u7ed3\u6784\u548c\u4e13\u5bb6\u6846\u67b6\u89e3\u51b3\u5757\u7f3a\u5931\u548c\u975e\u5e73\u7a33\u6570\u636e\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5757\u7f3a\u5931\u6570\u636e\u573a\u666f\u4e0b\u63d0\u53d6\u7279\u5f81\u6548\u679c\u4e0d\u4f73\uff0c\u9759\u6001\u56fe\u7ed3\u6784\u9650\u5236\u4e86\u6a21\u578b\u5bf9\u975e\u5e73\u7a33\u4ea4\u901a\u6570\u636e\u7684\u7075\u6d3b\u6027\u3002", "method": "\u63d0\u51fa\u6df7\u5408\u4e13\u5bb6\u6846\u67b6\uff08MoE\uff09\u6355\u83b7\u65f6\u7a7a\u7279\u5f81\u53ca\u5176\u6743\u91cd\uff0c\u8bbe\u8ba1\u4f4e\u79e9\u5f15\u5bfc\u91c7\u6837\u56fe\u6ce8\u610f\u529b\u673a\u5236\uff08LrSGAT\uff09\u52a8\u6001\u5e73\u8861\u5c40\u90e8\u548c\u5168\u5c40\u76f8\u5173\u6027\u3002", "result": "\u5728\u56db\u4e2a\u4ea4\u901a\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0cSTAMImputer\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "STAMImputer\u6709\u6548\u89e3\u51b3\u4e86\u4ea4\u901a\u6570\u636e\u586b\u8865\u4e2d\u7684\u5757\u7f3a\u5931\u548c\u975e\u5e73\u7a33\u6027\u95ee\u9898\uff0c\u6027\u80fd\u4f18\u8d8a\u3002"}}
{"id": "2506.08060", "pdf": "https://arxiv.org/pdf/2506.08060", "abs": "https://arxiv.org/abs/2506.08060", "authors": ["Asankhaya Sharma"], "title": "Eliciting Fine-Tuned Transformer Capabilities via Inference-Time Techniques", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models have transformed natural language processing, yet\nsupervised fine-tuning (SFT) remains computationally intensive. This paper\nformally proves that capabilities acquired through SFT can be approximated by a\nbase transformer model using inference-time techniques, specifically in-context\nlearning (ICL), without altering model parameters, under idealized assumptions\nincluding unbounded computational resources and access to the fine-tuning\ndataset. We extend these results to practical scenarios with finite context\nlengths and partial dataset access. For text generation tasks with fixed output\nlength $l$, datasets of size $\\mathrm{O}\\left( \\frac{m V}{\\varepsilon^2} \\log\n\\frac{m}{\\delta} \\right)$ or, with bounded context, $\\mathrm{O}\\left( \\frac{l\n\\log V}{\\varepsilon^2} \\log \\frac{1}{\\delta} \\right)$ suffice to approximate\nfine-tuned behavior across $m$ contexts within error $\\varepsilon$, where $V$\nis the vocabulary size and $\\delta$ is the failure probability. For linear\nclassification, datasets of size $\\mathrm{O}\\left( \\frac{d}{\\varepsilon}\n\\right)$ or, with fixed context, $\\mathrm{O}\\left( \\frac{1}{\\varepsilon^2} \\log\n\\frac{1}{\\delta} \\right)$ are sufficient, where $d$ is the input dimension.\nGrounded in the Turing completeness of transformers, these results provide a\ntheoretical foundation for resource-efficient deployment of large language\nmodels, with practical techniques like retrieval-augmented generation bridging\ntheory to real-world applications.", "AI": {"tldr": "\u8bba\u6587\u8bc1\u660e\uff0c\u901a\u8fc7\u63a8\u7406\u65f6\u6280\u672f\uff08\u5982\u4e0a\u4e0b\u6587\u5b66\u4e60\uff09\u53ef\u4ee5\u8fd1\u4f3c\u76d1\u7763\u5fae\u8c03\u7684\u80fd\u529b\uff0c\u65e0\u9700\u4fee\u6539\u6a21\u578b\u53c2\u6570\uff0c\u5e76\u6269\u5c55\u5230\u5b9e\u9645\u573a\u666f\u3002", "motivation": "\u51cf\u5c11\u76d1\u7763\u5fae\u8c03\u7684\u8ba1\u7b97\u5f00\u9500\uff0c\u63a2\u7d22\u5728\u6709\u9650\u8d44\u6e90\u548c\u90e8\u5206\u6570\u636e\u96c6\u8bbf\u95ee\u4e0b\u7684\u9ad8\u6548\u6a21\u578b\u90e8\u7f72\u3002", "method": "\u57fa\u4e8e\u7406\u60f3\u5316\u5047\u8bbe\uff0c\u5229\u7528\u4e0a\u4e0b\u6587\u5b66\u4e60\u6280\u672f\uff0c\u6269\u5c55\u5230\u6709\u9650\u4e0a\u4e0b\u6587\u957f\u5ea6\u548c\u90e8\u5206\u6570\u636e\u96c6\u8bbf\u95ee\u7684\u5b9e\u9645\u573a\u666f\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u6587\u672c\u751f\u6210\u548c\u7ebf\u6027\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u6240\u9700\u6570\u636e\u96c6\u5927\u5c0f\u7684\u7406\u8bba\u754c\u9650\u3002", "conclusion": "\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6548\u90e8\u7f72\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7b49\u6280\u672f\u8fde\u63a5\u7406\u8bba\u4e0e\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2506.08062", "pdf": "https://arxiv.org/pdf/2506.08062", "abs": "https://arxiv.org/abs/2506.08062", "authors": ["Woosung Kim", "Jinho Lee", "Jongmin Lee", "Byung-Jun Lee"], "title": "FairDICE: Fairness-Driven Offline Multi-Objective Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "Multi-objective Reinforcement Learning", "summary": "Multi-objective reinforcement learning (MORL) aims to optimize policies in\nthe presence of conflicting objectives, where linear scalarization is commonly\nused to reduce vector-valued returns into scalar signals. While effective for\ncertain preferences, this approach cannot capture fairness-oriented goals such\nas Nash social welfare or max-min fairness, which require nonlinear and\nnon-additive trade-offs. Although several online algorithms have been proposed\nfor specific fairness objectives, a unified approach for optimizing nonlinear\nwelfare criteria in the offline setting-where learning must proceed from a\nfixed dataset-remains unexplored. In this work, we present FairDICE, the first\noffline MORL framework that directly optimizes nonlinear welfare objective.\nFairDICE leverages distribution correction estimation to jointly account for\nwelfare maximization and distributional regularization, enabling stable and\nsample-efficient learning without requiring explicit preference weights or\nexhaustive weight search. Across multiple offline benchmarks, FairDICE\ndemonstrates strong fairness-aware performance compared to existing baselines.", "AI": {"tldr": "FairDICE\u662f\u9996\u4e2a\u79bb\u7ebf\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u76f4\u63a5\u4f18\u5316\u975e\u7ebf\u6027\u798f\u5229\u76ee\u6807\uff0c\u65e0\u9700\u663e\u5f0f\u504f\u597d\u6743\u91cd\u6216\u7a77\u4e3e\u641c\u7d22\u3002", "motivation": "\u73b0\u6709\u7ebf\u6027\u6807\u91cf\u5316\u65b9\u6cd5\u65e0\u6cd5\u6355\u6349\u516c\u5e73\u5bfc\u5411\u76ee\u6807\uff08\u5982Nash\u793e\u4f1a\u798f\u5229\u6216\u6700\u5927\u6700\u5c0f\u516c\u5e73\uff09\uff0c\u800c\u79bb\u7ebf\u73af\u5883\u4e0b\u975e\u7ebf\u6027\u798f\u5229\u6807\u51c6\u7684\u7edf\u4e00\u4f18\u5316\u65b9\u6cd5\u5c1a\u672a\u63a2\u7d22\u3002", "method": "FairDICE\u5229\u7528\u5206\u5e03\u6821\u6b63\u4f30\u8ba1\uff0c\u8054\u5408\u8003\u8651\u798f\u5229\u6700\u5927\u5316\u548c\u5206\u5e03\u6b63\u5219\u5316\uff0c\u5b9e\u73b0\u7a33\u5b9a\u4e14\u6837\u672c\u9ad8\u6548\u7684\u5b66\u4e60\u3002", "result": "\u5728\u591a\u4e2a\u79bb\u7ebf\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cFairDICE\u8868\u73b0\u51fa\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u7684\u516c\u5e73\u611f\u77e5\u6027\u80fd\u3002", "conclusion": "FairDICE\u4e3a\u79bb\u7ebf\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u975e\u7ebf\u6027\u798f\u5229\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u4e14\u7edf\u4e00\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.08063", "pdf": "https://arxiv.org/pdf/2506.08063", "abs": "https://arxiv.org/abs/2506.08063", "authors": ["Songqiao Hu", "Zeyi Liu", "Xiao He"], "title": "Lite-RVFL: A Lightweight Random Vector Functional-Link Neural Network for Learning Under Concept Drift", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": "6 pages, 4 figures, accepted by the 2025 CAA Symposium on Fault\n  Detection, Supervision and Safety for Technical Processes (SAFEPROCESS 2025)", "summary": "The change in data distribution over time, also known as concept drift, poses\na significant challenge to the reliability of online learning methods. Existing\nmethods typically require model retraining or drift detection, both of which\ndemand high computational costs and are often unsuitable for real-time\napplications. To address these limitations, a lightweight, fast and efficient\nrandom vector functional-link network termed Lite-RVFL is proposed, capable of\nadapting to concept drift without drift detection and retraining. Lite-RVFL\nintroduces a novel objective function that assigns weights exponentially\nincreasing to new samples, thereby emphasizing recent data and enabling timely\nadaptation. Theoretical analysis confirms the feasibility of this objective\nfunction for drift adaptation, and an efficient incremental update rule is\nderived. Experimental results on a real-world safety assessment task validate\nthe efficiency, effectiveness in adapting to drift, and potential to capture\ntemporal patterns of Lite-RVFL. The source code is available at\nhttps://github.com/songqiaohu/Lite-RVFL.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u5feb\u901f\u7684Lite-RVFL\u7f51\u7edc\uff0c\u65e0\u9700\u68c0\u6d4b\u6982\u5ff5\u6f02\u79fb\u6216\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u9002\u5e94\u6570\u636e\u5206\u5e03\u53d8\u5316\u3002", "motivation": "\u89e3\u51b3\u5728\u7ebf\u5b66\u4e60\u65b9\u6cd5\u56e0\u6982\u5ff5\u6f02\u79fb\u5bfc\u81f4\u7684\u53ef\u9760\u6027\u95ee\u9898\uff0c\u907f\u514d\u9ad8\u8ba1\u7b97\u6210\u672c\u7684\u91cd\u8bad\u7ec3\u548c\u6f02\u79fb\u68c0\u6d4b\u3002", "method": "\u5f15\u5165\u6307\u6570\u52a0\u6743\u65b0\u6837\u672c\u7684\u76ee\u6807\u51fd\u6570\uff0c\u5f3a\u8c03\u8fd1\u671f\u6570\u636e\uff0c\u5e76\u63a8\u5bfc\u51fa\u9ad8\u6548\u7684\u589e\u91cf\u66f4\u65b0\u89c4\u5219\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86Lite-RVFL\u5728\u9002\u5e94\u6f02\u79fb\u548c\u6355\u6349\u65f6\u95f4\u6a21\u5f0f\u4e0a\u7684\u9ad8\u6548\u6027\u548c\u6709\u6548\u6027\u3002", "conclusion": "Lite-RVFL\u662f\u4e00\u79cd\u9002\u7528\u4e8e\u5b9e\u65f6\u5e94\u7528\u7684\u9ad8\u6548\u6982\u5ff5\u6f02\u79fb\u9002\u5e94\u65b9\u6cd5\u3002"}}
{"id": "2506.08070", "pdf": "https://arxiv.org/pdf/2506.08070", "abs": "https://arxiv.org/abs/2506.08070", "authors": ["Ziheng Qin", "Hailun Xu", "Wei Chee Yew", "Qi Jia", "Yang Luo", "Kanchan Sarkar", "Danhui Guan", "Kai Wang", "Yang You"], "title": "Info-Coevolution: An Efficient Framework for Data Model Coevolution", "categories": ["cs.LG", "cs.AI"], "comment": "V1", "summary": "Machine learning relies heavily on data, yet the continuous growth of\nreal-world data poses challenges for efficient dataset construction and\ntraining. A fundamental yet unsolved question is: given our current model and\ndata, does a new data (sample/batch) need annotation/learning? Conventional\napproaches retain all available data, leading to non-optimal data and training\nefficiency. Active learning aims to reduce data redundancy by selecting a\nsubset of samples to annotate, while it increases pipeline complexity and\nintroduces bias. In this work, we propose Info-Coevolution, a novel framework\nthat efficiently enables models and data to coevolve through online selective\nannotation with no bias. Leveraging task-specific models (and open-source\nmodels), it selectively annotates and integrates online and web data to improve\ndatasets efficiently. For real-world datasets like ImageNet-1K,\nInfo-Coevolution reduces annotation and training costs by 32\\% without\nperformance loss. It is able to automatically give the saving ratio without\ntuning the ratio. It can further reduce the annotation ratio to 50\\% with\nsemi-supervised learning. We also explore retrieval-based dataset enhancement\nusing unlabeled open-source data. Code is available at\nhttps://github.com/NUS-HPC-AI-Lab/Info-Coevolution/.", "AI": {"tldr": "Info-Coevolution\u662f\u4e00\u79cd\u65b0\u9896\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u7ebf\u9009\u62e9\u6027\u6807\u6ce8\u5b9e\u73b0\u6a21\u578b\u4e0e\u6570\u636e\u7684\u534f\u540c\u8fdb\u5316\uff0c\u51cf\u5c11\u6807\u6ce8\u548c\u8bad\u7ec3\u6210\u672c\uff0c\u540c\u65f6\u907f\u514d\u504f\u5dee\u3002", "motivation": "\u89e3\u51b3\u673a\u5668\u5b66\u4e60\u4e2d\u6570\u636e\u589e\u957f\u5e26\u6765\u7684\u6807\u6ce8\u548c\u8bad\u7ec3\u6548\u7387\u95ee\u9898\uff0c\u907f\u514d\u4f20\u7edf\u65b9\u6cd5\u7684\u6570\u636e\u5197\u4f59\u548c\u4e3b\u52a8\u5b66\u4e60\u7684\u590d\u6742\u6027\u53ca\u504f\u5dee\u3002", "method": "\u5229\u7528\u4efb\u52a1\u7279\u5b9a\u6a21\u578b\u548c\u5f00\u6e90\u6a21\u578b\uff0c\u9009\u62e9\u6027\u6807\u6ce8\u5e76\u6574\u5408\u5728\u7ebf\u548c\u7f51\u7edc\u6570\u636e\uff0c\u4f18\u5316\u6570\u636e\u96c6\u3002", "result": "\u5728ImageNet-1K\u7b49\u6570\u636e\u96c6\u4e0a\uff0c\u6807\u6ce8\u548c\u8bad\u7ec3\u6210\u672c\u51cf\u5c1132%\uff0c\u6027\u80fd\u65e0\u635f\u5931\uff1b\u534a\u76d1\u7763\u5b66\u4e60\u4e0b\u53ef\u8fdb\u4e00\u6b65\u51cf\u5c1150%\u6807\u6ce8\u6bd4\u4f8b\u3002", "conclusion": "Info-Coevolution\u9ad8\u6548\u63d0\u5347\u6570\u636e\u96c6\u8d28\u91cf\uff0c\u964d\u4f4e\u6807\u6ce8\u548c\u8bad\u7ec3\u6210\u672c\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2506.08113", "pdf": "https://arxiv.org/pdf/2506.08113", "abs": "https://arxiv.org/abs/2506.08113", "authors": ["Timoth\u00e9e Hornek Amir Sartipi", "Igor Tchappi", "Gilbert Fridgen"], "title": "Benchmarking Pre-Trained Time Series Models for Electricity Price Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Accurate electricity price forecasting (EPF) is crucial for effective\ndecision-making in power trading on the spot market. While recent advances in\ngenerative artificial intelligence (GenAI) and pre-trained large language\nmodels (LLMs) have inspired the development of numerous time series foundation\nmodels (TSFMs) for time series forecasting, their effectiveness in EPF remains\nuncertain. To address this gap, we benchmark several state-of-the-art\npretrained models--Chronos-Bolt, Chronos-T5, TimesFM, Moirai, Time-MoE, and\nTimeGPT--against established statistical and machine learning (ML) methods for\nEPF. Using 2024 day-ahead auction (DAA) electricity prices from Germany,\nFrance, the Netherlands, Austria, and Belgium, we generate daily forecasts with\na one-day horizon. Chronos-Bolt and Time-MoE emerge as the strongest among the\nTSFMs, performing on par with traditional models. However, the biseasonal MSTL\nmodel, which captures daily and weekly seasonality, stands out for its\nconsistent performance across countries and evaluation metrics, with no TSFM\nstatistically outperforming it.", "AI": {"tldr": "\u8bba\u6587\u6bd4\u8f83\u4e86\u591a\u79cd\u9884\u8bad\u7ec3\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u4e0e\u4f20\u7edf\u65b9\u6cd5\u5728\u7535\u529b\u4ef7\u683c\u9884\u6d4b\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u4f20\u7edf\u65b9\u6cd5\uff08\u5982MSTL\uff09\u4ecd\u5177\u6709\u4f18\u52bf\u3002", "motivation": "\u7535\u529b\u4ef7\u683c\u9884\u6d4b\u5bf9\u7535\u529b\u73b0\u8d27\u5e02\u573a\u51b3\u7b56\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u751f\u6210\u5f0fAI\u548c\u9884\u8bad\u7ec3\u5927\u6a21\u578b\u5728\u7535\u529b\u4ef7\u683c\u9884\u6d4b\u4e2d\u7684\u6548\u679c\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u901a\u8fc7\u5fb7\u56fd\u3001\u6cd5\u56fd\u3001\u8377\u5170\u3001\u5965\u5730\u5229\u548c\u6bd4\u5229\u65f6\u76842024\u5e74\u65e5\u524d\u62cd\u5356\u7535\u529b\u4ef7\u683c\u6570\u636e\uff0c\u5bf9\u6bd4\u4e86\u591a\u79cd\u9884\u8bad\u7ec3\u6a21\u578b\u4e0e\u4f20\u7edf\u7edf\u8ba1\u548c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u7684\u8868\u73b0\u3002", "result": "Chronos-Bolt\u548cTime-MoE\u8868\u73b0\u6700\u4f73\uff0c\u4f46MSTL\u6a21\u578b\u5728\u4e00\u81f4\u6027\u548c\u7edf\u8ba1\u6027\u80fd\u4e0a\u4f18\u4e8e\u6240\u6709\u9884\u8bad\u7ec3\u6a21\u578b\u3002", "conclusion": "\u4f20\u7edf\u65b9\u6cd5\uff08\u5982MSTL\uff09\u5728\u7535\u529b\u4ef7\u683c\u9884\u6d4b\u4e2d\u4ecd\u5177\u6709\u4f18\u52bf\uff0c\u9884\u8bad\u7ec3\u6a21\u578b\u5c1a\u672a\u8d85\u8d8a\u3002"}}
{"id": "2506.08125", "pdf": "https://arxiv.org/pdf/2506.08125", "abs": "https://arxiv.org/abs/2506.08125", "authors": ["Hanbing Liu", "Lang Cao", "Yuanyi Ren", "Mengyu Zhou", "Haoyu Dong", "Xiaojun Ma", "Shi Han", "Dongmei Zhang"], "title": "Bingo: Boosting Efficient Reasoning of LLMs via Dynamic and Significance-based Reinforcement Learning", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Large language models have demonstrated impressive reasoning capabilities,\nyet they often suffer from inefficiencies due to unnecessarily verbose or\nredundant outputs. While many works have explored reinforcement learning (RL)\nto enhance reasoning abilities, most primarily focus on improving accuracy,\nwith limited attention to reasoning efficiency. Some existing approaches\nintroduce direct length-based rewards to encourage brevity, but this often\nleads to noticeable drops in accuracy. In this paper, we propose Bingo, an RL\nframework that advances length-based reward design to boost efficient\nreasoning. Bingo incorporates two key mechanisms: a significance-aware length\nreward, which gradually guides the model to reduce only insignificant tokens,\nand a dynamic length reward, which initially encourages elaborate reasoning for\nhard questions but decays over time to improve overall efficiency. Experiments\nacross multiple reasoning benchmarks show that Bingo improves both accuracy and\nefficiency. It outperforms the vanilla reward and several other length-based\nreward baselines in RL, achieving a favorable trade-off between accuracy and\nefficiency. These results underscore the potential of training LLMs explicitly\nfor efficient reasoning.", "AI": {"tldr": "Bingo\u662f\u4e00\u4e2aRL\u6846\u67b6\uff0c\u901a\u8fc7\u6539\u8fdb\u957f\u5ea6\u5956\u52b1\u8bbe\u8ba1\uff0c\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6548\u63a8\u7406\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u6548\u7387\u65f6\uff0c\u5e38\u56e0\u76f4\u63a5\u7684\u957f\u5ea6\u5956\u52b1\u5bfc\u81f4\u51c6\u786e\u6027\u4e0b\u964d\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u5e73\u8861\u7684\u65b9\u6cd5\u3002", "method": "Bingo\u5f15\u5165\u663e\u8457\u6027\u611f\u77e5\u957f\u5ea6\u5956\u52b1\u548c\u52a8\u6001\u957f\u5ea6\u5956\u52b1\uff0c\u9010\u6b65\u51cf\u5c11\u65e0\u5173\u6807\u8bb0\u5e76\u52a8\u6001\u8c03\u6574\u63a8\u7406\u957f\u5ea6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cBingo\u5728\u591a\u4e2a\u63a8\u7406\u57fa\u51c6\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u51c6\u786e\u6027\u4e0e\u6548\u7387\u7684\u826f\u597d\u5e73\u8861\u3002", "conclusion": "Bingo\u5c55\u793a\u4e86\u901a\u8fc7\u663e\u5f0f\u8bad\u7ec3\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u9ad8\u6548\u63a8\u7406\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.08139", "pdf": "https://arxiv.org/pdf/2506.08139", "abs": "https://arxiv.org/abs/2506.08139", "authors": ["Aviad Susman", "Mayte Su\u00e1rez-Fari\u00f1as", "Joseph T Colonel"], "title": "Nearness of Neighbors Attention for Regression in Supervised Finetuning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "It is common in supervised machine learning to combine the feature extraction\ncapabilities of neural networks with the predictive power of traditional\nalgorithms, such as k-nearest neighbors (k-NN) or support vector machines. This\nprocedure involves performing supervised fine-tuning (SFT) on a\ndomain-appropriate feature extractor, followed by training a traditional\npredictor on the resulting SFT embeddings. When used in this manner,\ntraditional predictors often deliver increased performance over the SFT model\nitself, despite the fine-tuned feature extractor yielding embeddings\nspecifically optimized for prediction by the neural network's final dense\nlayer. This suggests that directly incorporating traditional algorithms into\nSFT as prediction layers may further improve performance. However, many\ntraditional algorithms have not been implemented as neural network layers due\nto their non-differentiable nature and their unique optimization requirements.\nAs a step towards solving this problem, we introduce the Nearness of Neighbors\nAttention (NONA) regression layer. NONA uses the mechanics of neural network\nattention and a novel learned attention-masking scheme to yield a\ndifferentiable proxy of the k-NN regression algorithm. Results on multiple\nunstructured datasets show improved performance over both dense layer\nprediction and k-NN on SFT embeddings for regression.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aNONA\u7684\u53ef\u5fae\u5206k-NN\u56de\u5f52\u5c42\uff0c\u901a\u8fc7\u7ed3\u5408\u795e\u7ecf\u7f51\u7edc\u7684\u6ce8\u610f\u529b\u673a\u5236\u548c\u4f20\u7edf\u7b97\u6cd5\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u63d0\u5347\u4e86\u56de\u5f52\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u7b97\u6cd5\uff08\u5982k-NN\uff09\u5728\u7279\u5f81\u63d0\u53d6\u540e\u8868\u73b0\u4f18\u4e8e\u795e\u7ecf\u7f51\u7edc\u672c\u8eab\uff0c\u4f46\u7531\u4e8e\u5176\u4e0d\u53ef\u5fae\u6027\u548c\u72ec\u7279\u4f18\u5316\u9700\u6c42\uff0c\u96be\u4ee5\u76f4\u63a5\u878d\u5165\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u3002", "method": "\u5f15\u5165NONA\u56de\u5f52\u5c42\uff0c\u5229\u7528\u6ce8\u610f\u529b\u673a\u5236\u548c\u5b66\u4e60\u7684\u6ce8\u610f\u529b\u63a9\u7801\u65b9\u6848\uff0c\u5b9e\u73b0k-NN\u7684\u53ef\u5fae\u5206\u8fd1\u4f3c\u3002", "result": "\u5728\u591a\u4e2a\u975e\u7ed3\u6784\u5316\u6570\u636e\u96c6\u4e0a\uff0cNONA\u5728\u56de\u5f52\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u5bc6\u96c6\u5c42\u9884\u6d4b\u548c\u57fa\u4e8eSFT\u5d4c\u5165\u7684k-NN\u3002", "conclusion": "NONA\u4e3a\u5c06\u4f20\u7edf\u7b97\u6cd5\u878d\u5165\u795e\u7ecf\u7f51\u7edc\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u884c\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002"}}
{"id": "2506.08140", "pdf": "https://arxiv.org/pdf/2506.08140", "abs": "https://arxiv.org/abs/2506.08140", "authors": ["Yifei Li", "Hanane Nour Moussa", "Ziru Chen", "Shijie Chen", "Botao Yu", "Mingyi Xue", "Benjamin Burns", "Tzu-Yao Chiu", "Vishal Dey", "Zitong Lu", "Chen Wei", "Qianheng Zhang", "Tianyu Zhang", "Song Gao", "Xuhui Huang", "Xia Ning", "Nesreen K. Ahmed", "Ali Payani", "Huan Sun"], "title": "AutoSDT: Scaling Data-Driven Discovery Tasks Toward Open Co-Scientists", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Despite long-standing efforts in accelerating scientific discovery with AI,\nbuilding AI co-scientists remains challenging due to limited high-quality data\nfor training and evaluation. To tackle this data scarcity issue, we present\nAutoSDT, an automatic pipeline that collects high-quality coding tasks in\nreal-world data-driven discovery workflows. AutoSDT leverages the coding\ncapabilities and parametric knowledge of LLMs to search for diverse sources,\nselect ecologically valid tasks, and synthesize accurate task instructions and\ncode solutions. Using our pipeline, we construct AutoSDT-5K, a dataset of 5,404\ncoding tasks for data-driven discovery that covers four scientific disciplines\nand 756 unique Python packages. To the best of our knowledge, AutoSDT-5K is the\nonly automatically collected and the largest open dataset for data-driven\nscientific discovery. Expert feedback on a subset of 256 tasks shows the\neffectiveness of AutoSDT: 93% of the collected tasks are ecologically valid,\nand 92.2% of the synthesized programs are functionally correct. Trained on\nAutoSDT-5K, the Qwen2.5-Coder-Instruct LLM series, dubbed AutoSDT-Coder, show\nsubstantial improvement on two challenging data-driven discovery benchmarks,\nScienceAgentBench and DiscoveryBench. Most notably, AutoSDT-Coder-32B reaches\nthe same level of performance as GPT-4o on ScienceAgentBench with a success\nrate of 7.8%, doubling the performance of its base model. On DiscoveryBench, it\nlifts the hypothesis matching score to 8.1, bringing a 17.4% relative\nimprovement and closing the gap between open-weight models and GPT-4o.", "AI": {"tldr": "AutoSDT\u662f\u4e00\u4e2a\u81ea\u52a8\u6784\u5efa\u9ad8\u8d28\u91cf\u79d1\u5b66\u53d1\u73b0\u7f16\u7801\u4efb\u52a1\u7684\u7ba1\u9053\uff0c\u521b\u5efa\u4e86AutoSDT-5K\u6570\u636e\u96c6\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u5728\u79d1\u5b66\u53d1\u73b0\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u89e3\u51b3\u79d1\u5b66\u53d1\u73b0\u4e2d\u9ad8\u8d28\u91cf\u6570\u636e\u7a00\u7f3a\u7684\u95ee\u9898\uff0c\u4ee5\u52a0\u901fAI\u5728\u79d1\u5b66\u9886\u57df\u7684\u5e94\u7528\u3002", "method": "\u5229\u7528LLM\u7684\u7f16\u7801\u80fd\u529b\u548c\u53c2\u6570\u77e5\u8bc6\uff0c\u81ea\u52a8\u6536\u96c6\u3001\u7b5b\u9009\u548c\u5408\u6210\u4efb\u52a1\u4e0e\u4ee3\u7801\u89e3\u51b3\u65b9\u6848\uff0c\u6784\u5efaAutoSDT-5K\u6570\u636e\u96c6\u3002", "result": "AutoSDT-5K\u5305\u542b5,404\u4e2a\u4efb\u52a1\uff0c93%\u7684\u4efb\u52a1\u751f\u6001\u6709\u6548\uff0c92.2%\u7684\u4ee3\u7801\u529f\u80fd\u6b63\u786e\u3002AutoSDT-Coder\u6a21\u578b\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u663e\u8457\u63d0\u5347\u3002", "conclusion": "AutoSDT\u4e3a\u89e3\u51b3\u79d1\u5b66\u53d1\u73b0\u4e2d\u7684\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\uff0c\u5e76\u663e\u8457\u63d0\u5347\u4e86AI\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2506.08143", "pdf": "https://arxiv.org/pdf/2506.08143", "abs": "https://arxiv.org/abs/2506.08143", "authors": ["Francesco Tonin", "Alex Lambert", "Johan A. K. Suykens", "Volkan Cevher"], "title": "Accelerating Spectral Clustering under Fairness Constraints", "categories": ["cs.LG"], "comment": "ICML 2025", "summary": "Fairness of decision-making algorithms is an increasingly important issue. In\nthis paper, we focus on spectral clustering with group fairness constraints,\nwhere every demographic group is represented in each cluster proportionally as\nin the general population. We present a new efficient method for fair spectral\nclustering (Fair SC) by casting the Fair SC problem within the difference of\nconvex functions (DC) framework. To this end, we introduce a novel variable\naugmentation strategy and employ an alternating direction method of multipliers\ntype of algorithm adapted to DC problems. We show that each associated\nsubproblem can be solved efficiently, resulting in higher computational\nefficiency compared to prior work, which required a computationally expensive\neigendecomposition. Numerical experiments demonstrate the effectiveness of our\napproach on both synthetic and real-world benchmarks, showing significant\nspeedups in computation time over prior art, especially as the problem size\ngrows. This work thus represents a considerable step forward towards the\nadoption of fair clustering in real-world applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u516c\u5e73\u8c31\u805a\u7c7b\u65b9\u6cd5\uff08Fair SC\uff09\uff0c\u901a\u8fc7\u5c06\u95ee\u9898\u8f6c\u5316\u4e3a\u51f8\u5dee\u51fd\u6570\uff08DC\uff09\u6846\u67b6\uff0c\u5e76\u5f15\u5165\u65b0\u7684\u53d8\u91cf\u589e\u5f3a\u7b56\u7565\u548cADMM\u7b97\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u51b3\u7b56\u7b97\u6cd5\u7684\u516c\u5e73\u6027\u65e5\u76ca\u91cd\u8981\uff0c\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8c31\u805a\u7c7b\u4e2d\u7684\u7fa4\u4f53\u516c\u5e73\u6027\u95ee\u9898\uff0c\u786e\u4fdd\u6bcf\u4e2a\u805a\u7c7b\u4e2d\u4eba\u53e3\u7fa4\u4f53\u7684\u6bd4\u4f8b\u4e0e\u603b\u4f53\u4e00\u81f4\u3002", "method": "\u5c06\u516c\u5e73\u8c31\u805a\u7c7b\u95ee\u9898\u8f6c\u5316\u4e3aDC\u6846\u67b6\uff0c\u91c7\u7528\u53d8\u91cf\u589e\u5f3a\u7b56\u7565\u548cADMM\u7b97\u6cd5\uff0c\u907f\u514d\u4e86\u6602\u8d35\u7684\u7279\u5f81\u5206\u89e3\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5747\u6709\u6548\uff0c\u8ba1\u7b97\u901f\u5ea6\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u5927\u89c4\u6a21\u95ee\u9898\u4e0a\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u516c\u5e73\u805a\u7c7b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u63a8\u5e7f\u63d0\u4f9b\u4e86\u91cd\u8981\u8fdb\u5c55\u3002"}}
{"id": "2506.08146", "pdf": "https://arxiv.org/pdf/2506.08146", "abs": "https://arxiv.org/abs/2506.08146", "authors": ["Vahidullah Ta\u00e7", "Amirhossein Amiri-Hezaveh", "Manuel K. Rausch", "Grace N. Bechtel", "Francisco Sahli Costabal", "Adrian Buganza Tepole"], "title": "Fully data-driven inverse hyperelasticity with hyper-network neural ODE fields", "categories": ["cs.LG"], "comment": null, "summary": "We propose a new framework for identifying mechanical properties of\nheterogeneous materials without a closed-form constitutive equation. Given a\nfull-field measurement of the displacement field, for instance as obtained from\ndigital image correlation (DIC), a continuous approximation of the strain field\nis obtained by training a neural network that incorporates Fourier features to\neffectively capture sharp gradients in the data. A physics-based data-driven\nmethod built upon ordinary neural differential equations (NODEs) is employed to\ndiscover constitutive equations. The NODE framework can represent arbitrary\nmaterials while satisfying constraints in the theory of constitutive equations\nby default. To account for heterogeneity, a hyper-network is defined, where the\ninput is the material coordinate system, and the output is the NODE-based\nconstitutive equation. The parameters of the hyper-network are optimized by\nminimizing a multi-objective loss function that includes penalty terms for\nviolations of the strong form of the equilibrium equations of elasticity and\nthe associated Neumann boundary conditions. We showcase the framework with\nseveral numerical examples, including heterogeneity arising from variations in\nmaterial parameters, spatial transitions from isotropy to anisotropy, material\nidentification in the presence of noise, and, ultimately, application to\nexperimental data. As the numerical results suggest, the proposed approach is\nrobust and general in identifying the mechanical properties of heterogeneous\nmaterials with very few assumptions, making it a suitable alternative to\nclassical inverse methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u8bc6\u522b\u5f02\u8d28\u6750\u6599\u7684\u529b\u5b66\u6027\u8d28\uff0c\u65e0\u9700\u5c01\u95ed\u5f62\u5f0f\u7684\u672c\u6784\u65b9\u7a0b\u3002\u901a\u8fc7\u7ed3\u5408\u5085\u91cc\u53f6\u7279\u5f81\u7684\u795e\u7ecf\u7f51\u7edc\u548c\u57fa\u4e8e\u7269\u7406\u7684\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u5bf9\u5f02\u8d28\u6750\u6599\u7684\u9c81\u68d2\u8bc6\u522b\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u5c01\u95ed\u5f62\u5f0f\u7684\u672c\u6784\u65b9\u7a0b\uff0c\u9650\u5236\u4e86\u5f02\u8d28\u6750\u6599\u529b\u5b66\u6027\u8d28\u7684\u8bc6\u522b\u3002\u65b0\u6846\u67b6\u65e8\u5728\u514b\u670d\u8fd9\u4e00\u9650\u5236\u3002", "method": "\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u7ed3\u5408\u5085\u91cc\u53f6\u7279\u5f81\u8fd1\u4f3c\u5e94\u53d8\u573a\uff0c\u5e76\u57fa\u4e8eNODE\u6846\u67b6\u53d1\u73b0\u672c\u6784\u65b9\u7a0b\u3002\u901a\u8fc7\u8d85\u7f51\u7edc\u5904\u7406\u5f02\u8d28\u6027\uff0c\u4f18\u5316\u591a\u76ee\u6807\u635f\u5931\u51fd\u6570\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u566a\u58f0\u548c\u5f02\u8d28\u6027\u6761\u4ef6\u4e0b\u5747\u80fd\u6709\u6548\u8bc6\u522b\u6750\u6599\u6027\u8d28\uff0c\u9002\u7528\u4e8e\u5b9e\u9a8c\u6570\u636e\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5f02\u8d28\u6750\u6599\u529b\u5b66\u6027\u8d28\u8bc6\u522b\u63d0\u4f9b\u4e86\u901a\u7528\u4e14\u9c81\u68d2\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4f18\u4e8e\u4f20\u7edf\u9006\u5411\u65b9\u6cd5\u3002"}}
{"id": "2506.08164", "pdf": "https://arxiv.org/pdf/2506.08164", "abs": "https://arxiv.org/abs/2506.08164", "authors": ["Hadi Reisizadeh", "Jinghan Jia", "Zhiqi Bu", "Bhanukiran Vinzamuri", "Anil Ramakrishna", "Kai-Wei Chang", "Volkan Cevher", "Sijia Liu", "Mingyi Hong"], "title": "BLUR: A Bi-Level Optimization Approach for LLM Unlearning", "categories": ["cs.LG"], "comment": null, "summary": "Enabling large language models (LLMs) to unlearn knowledge and capabilities\nacquired during training has proven vital for ensuring compliance with data\nregulations and promoting ethical practices in generative AI. Although there\nare growing interests in developing various unlearning algorithms, it remains\nunclear how to best formulate the unlearning problem. The most popular\nformulation uses a weighted sum of forget and retain loss, but it often leads\nto performance degradation due to the inherent trade-off between forget and\nretain losses. In this work, we argue that it is important to model the\nhierarchical structure of the unlearning problem, where the forget problem\n(which \\textit{unlearns} certain knowledge and/or capabilities) takes priority\nover the retain problem (which preserves model utility). This hierarchical\nstructure naturally leads to a bi-level optimization formulation where the\nlower-level objective focuses on minimizing the forget loss, while the\nupper-level objective aims to maintain the model's utility. Based on this new\nformulation, we propose a novel algorithm, termed Bi-Level UnleaRning\n(\\texttt{BLUR}), which not only possesses strong theoretical guarantees but\nmore importantly, delivers superior performance. In particular, our extensive\nexperiments demonstrate that \\texttt{BLUR} consistently outperforms all the\nstate-of-the-art algorithms across various unlearning tasks, models, and\nmetrics. Codes are available at\nhttps://github.com/OptimAI-Lab/BLURLLMUnlearning.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5c42\u7ed3\u6784\u7684\u9057\u5fd8\u5b66\u4e60\u95ee\u9898\uff0c\u5e76\u57fa\u4e8e\u6b64\u63d0\u51fa\u4e86Bi-Level UnleaRning (BLUR)\u7b97\u6cd5\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u786e\u4fdd\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8bad\u7ec3\u540e\u80fd\u591f\u9057\u5fd8\u7279\u5b9a\u77e5\u8bc6\u6216\u80fd\u529b\uff0c\u4ee5\u7b26\u5408\u6570\u636e\u6cd5\u89c4\u548c\u4f26\u7406\u5b9e\u8df5\u3002", "method": "\u91c7\u7528\u53cc\u5c42\u4f18\u5316\u6846\u67b6\uff0c\u4e0b\u5c42\u76ee\u6807\u6700\u5c0f\u5316\u9057\u5fd8\u635f\u5931\uff0c\u4e0a\u5c42\u76ee\u6807\u4fdd\u6301\u6a21\u578b\u6548\u7528\u3002", "result": "BLUR\u7b97\u6cd5\u5728\u5404\u79cd\u9057\u5fd8\u4efb\u52a1\u3001\u6a21\u578b\u548c\u6307\u6807\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u5206\u5c42\u7ed3\u6784\u548cBLUR\u7b97\u6cd5\u4e3a\u9057\u5fd8\u5b66\u4e60\u95ee\u9898\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.08167", "pdf": "https://arxiv.org/pdf/2506.08167", "abs": "https://arxiv.org/abs/2506.08167", "authors": ["Sunny Gupta", "Nikita Jangid", "Amit Sethi"], "title": "UniVarFL: Uniformity and Variance Regularized Federated Learning for Heterogeneous Data", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.DC", "I.2.6; C.1.4; D.1.3; I.5.1; H.3.4; I.2.10; I.4.0; I.4.1; I.4.2;\n  I.4.6; I.4.7; I.4.8; I.4.9; I.4.10; I.5.1; I.5.2; I.5.4; J.2; I.2.11; I.2.10"], "comment": null, "summary": "Federated Learning (FL) often suffers from severe performance degradation\nwhen faced with non-IID data, largely due to local classifier bias. Traditional\nremedies such as global model regularization or layer freezing either incur\nhigh computational costs or struggle to adapt to feature shifts. In this work,\nwe propose UniVarFL, a novel FL framework that emulates IID-like training\ndynamics directly at the client level, eliminating the need for global model\ndependency. UniVarFL leverages two complementary regularization strategies\nduring local training: Classifier Variance Regularization, which aligns\nclass-wise probability distributions with those expected under IID conditions,\neffectively mitigating local classifier bias; and Hyperspherical Uniformity\nRegularization, which encourages a uniform distribution of feature\nrepresentations across the hypersphere, thereby enhancing the model's ability\nto generalize under diverse data distributions. Extensive experiments on\nmultiple benchmark datasets demonstrate that UniVarFL outperforms existing\nmethods in accuracy, highlighting its potential as a highly scalable and\nefficient solution for real-world FL deployments, especially in\nresource-constrained settings. Code: https://github.com/sunnyinAI/UniVarFL", "AI": {"tldr": "UniVarFL\u662f\u4e00\u79cd\u65b0\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5ba2\u6237\u7aef\u7ea7\u522b\u7684IID\u6a21\u62df\u548c\u4e24\u79cd\u6b63\u5219\u5316\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u975eIID\u6570\u636e\u5bfc\u81f4\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\u3002", "motivation": "\u975eIID\u6570\u636e\u5bfc\u81f4\u8054\u90a6\u5b66\u4e60\u6027\u80fd\u4e0b\u964d\uff0c\u4f20\u7edf\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u6216\u9002\u5e94\u6027\u5dee\u3002", "method": "UniVarFL\u91c7\u7528\u5206\u7c7b\u5668\u65b9\u5dee\u6b63\u5219\u5316\u548c\u8d85\u7403\u9762\u5747\u5300\u6b63\u5219\u5316\uff0c\u6a21\u62dfIID\u8bad\u7ec3\u52a8\u6001\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cUniVarFL\u5728\u51c6\u786e\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "UniVarFL\u662f\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u7684\u5b9e\u9645\u8054\u90a6\u5b66\u4e60\u90e8\u7f72\u3002"}}
{"id": "2506.08169", "pdf": "https://arxiv.org/pdf/2506.08169", "abs": "https://arxiv.org/abs/2506.08169", "authors": ["Jingqiao Tang", "Ryan Bausback", "Feng Bao", "Richard Archibald"], "title": "Federated Learning on Stochastic Neural Networks", "categories": ["cs.LG", "cs.DC"], "comment": "25 pages, 19 figures, Submitted to Journal of Machine Learning for\n  Modeling and Computing", "summary": "Federated learning is a machine learning paradigm that leverages edge\ncomputing on client devices to optimize models while maintaining user privacy\nby ensuring that local data remains on the device. However, since all data is\ncollected by clients, federated learning is susceptible to latent noise in\nlocal datasets. Factors such as limited measurement capabilities or human\nerrors may introduce inaccuracies in client data. To address this challenge, we\npropose the use of a stochastic neural network as the local model within the\nfederated learning framework. Stochastic neural networks not only facilitate\nthe estimation of the true underlying states of the data but also enable the\nquantification of latent noise. We refer to our federated learning approach,\nwhich incorporates stochastic neural networks as local models, as Federated\nstochastic neural networks. We will present numerical experiments demonstrating\nthe performance and effectiveness of our method, particularly in handling\nnon-independent and identically distributed data.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u968f\u673a\u795e\u7ecf\u7f51\u7edc\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\uff08Federated stochastic neural networks\uff09\uff0c\u7528\u4e8e\u5904\u7406\u672c\u5730\u6570\u636e\u4e2d\u7684\u6f5c\u5728\u566a\u58f0\u95ee\u9898\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u4e2d\u672c\u5730\u6570\u636e\u53ef\u80fd\u56e0\u6d4b\u91cf\u80fd\u529b\u6709\u9650\u6216\u4eba\u4e3a\u9519\u8bef\u5f15\u5165\u566a\u58f0\uff0c\u5f71\u54cd\u6a21\u578b\u6027\u80fd\u3002", "method": "\u5728\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u4e2d\u4f7f\u7528\u968f\u673a\u795e\u7ecf\u7f51\u7edc\u4f5c\u4e3a\u672c\u5730\u6a21\u578b\uff0c\u4ee5\u4f30\u8ba1\u6570\u636e\u771f\u5b9e\u72b6\u6001\u5e76\u91cf\u5316\u566a\u58f0\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u5904\u7406\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u65f6\u8868\u73b0\u6709\u6548\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u6570\u636e\u566a\u58f0\u95ee\u9898\u3002"}}
{"id": "2506.08176", "pdf": "https://arxiv.org/pdf/2506.08176", "abs": "https://arxiv.org/abs/2506.08176", "authors": ["Anh V Nguyen", "Diego Klabjan"], "title": "FedGA-Tree: Federated Decision Tree using Genetic Algorithm", "categories": ["cs.LG"], "comment": null, "summary": "In recent years, with rising concerns for data privacy, Federated Learning\nhas gained prominence, as it enables collaborative training without the\naggregation of raw data from participating clients. However, much of the\ncurrent focus has been on parametric gradient-based models, while nonparametric\ncounterparts such as decision tree are relatively understudied. Existing\nmethods for adapting decision trees to Federated Learning generally combine a\ngreedy tree-building algorithm with differential privacy to produce a global\nmodel for all clients. These methods are limited to classification trees and\ncategorical data due to the constraints of differential privacy. In this paper,\nwe explore an alternative approach that utilizes Genetic Algorithm to\nfacilitate the construction of personalized decision trees and accommodate\ncategorical and numerical data, thus allowing for both classification and\nregression trees. Comprehensive experiments demonstrate that our method\nsurpasses decision trees trained solely on local data and a benchmark\nalgorithm.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9057\u4f20\u7b97\u6cd5\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u6784\u5efa\u4e2a\u6027\u5316\u7684\u51b3\u7b56\u6811\uff0c\u652f\u6301\u5206\u7c7b\u548c\u56de\u5f52\u4efb\u52a1\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u8054\u90a6\u5b66\u4e60\u4e3b\u8981\u5173\u6ce8\u57fa\u4e8e\u68af\u5ea6\u7684\u53c2\u6570\u6a21\u578b\uff0c\u800c\u5bf9\u975e\u53c2\u6570\u6a21\u578b\uff08\u5982\u51b3\u7b56\u6811\uff09\u7684\u7814\u7a76\u8f83\u5c11\uff0c\u4e14\u73b0\u6709\u65b9\u6cd5\u53d7\u9650\u4e8e\u5206\u7c7b\u4efb\u52a1\u548c\u5206\u7c7b\u6570\u636e\u3002", "method": "\u5229\u7528\u9057\u4f20\u7b97\u6cd5\u6784\u5efa\u4e2a\u6027\u5316\u7684\u51b3\u7b56\u6811\uff0c\u652f\u6301\u5206\u7c7b\u548c\u6570\u503c\u6570\u636e\uff0c\u9002\u7528\u4e8e\u5206\u7c7b\u548c\u56de\u5f52\u4efb\u52a1\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u4ec5\u57fa\u4e8e\u672c\u5730\u6570\u636e\u8bad\u7ec3\u7684\u51b3\u7b56\u6811\u548c\u57fa\u51c6\u7b97\u6cd5\u3002", "conclusion": "\u9057\u4f20\u7b97\u6cd5\u4e3a\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u51b3\u7b56\u6811\u63d0\u4f9b\u4e86\u4e00\u79cd\u7075\u6d3b\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u652f\u6301\u66f4\u5e7f\u6cdb\u7684\u6570\u636e\u7c7b\u578b\u548c\u4efb\u52a1\u3002"}}
{"id": "2506.08201", "pdf": "https://arxiv.org/pdf/2506.08201", "abs": "https://arxiv.org/abs/2506.08201", "authors": ["Krishna Pillutla", "Jalaj Upadhyay", "Christopher A. Choquette-Choo", "Krishnamurthy Dvijotham", "Arun Ganesh", "Monika Henzinger", "Jonathan Katz", "Ryan McKenna", "H. Brendan McMahan", "Keith Rush", "Thomas Steinke", "Abhradeep Thakurta"], "title": "Correlated Noise Mechanisms for Differentially Private Learning", "categories": ["cs.LG"], "comment": "212 pages", "summary": "This monograph explores the design and analysis of correlated noise\nmechanisms for differential privacy (DP), focusing on their application to\nprivate training of AI and machine learning models via the core primitive of\nestimation of weighted prefix sums. While typical DP mechanisms inject\nindependent noise into each step of a stochastic gradient (SGD) learning\nalgorithm in order to protect the privacy of the training data, a growing body\nof recent research demonstrates that introducing (anti-)correlations in the\nnoise can significantly improve privacy-utility trade-offs by carefully\ncanceling out some of the noise added on earlier steps in subsequent steps.\nSuch correlated noise mechanisms, known variously as matrix mechanisms,\nfactorization mechanisms, and DP-Follow-the-Regularized-Leader (DP-FTRL) when\napplied to learning algorithms, have also been influential in practice, with\nindustrial deployment at a global scale.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5dee\u5206\u9690\u79c1\uff08DP\uff09\u4e2d\u76f8\u5173\u566a\u58f0\u673a\u5236\u7684\u8bbe\u8ba1\u4e0e\u5206\u6790\uff0c\u91cd\u70b9\u7814\u7a76\u5176\u5728AI\u548c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u79c1\u6709\u8bad\u7ec3\u4e2d\u7684\u5e94\u7528\uff0c\u901a\u8fc7\u52a0\u6743\u524d\u7f00\u548c\u4f30\u8ba1\u7684\u6838\u5fc3\u539f\u8bed\u3002", "motivation": "\u4f20\u7edfDP\u673a\u5236\u5728\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff08SGD\uff09\u5b66\u4e60\u7b97\u6cd5\u7684\u6bcf\u4e00\u6b65\u6ce8\u5165\u72ec\u7acb\u566a\u58f0\u4ee5\u4fdd\u62a4\u8bad\u7ec3\u6570\u636e\u7684\u9690\u79c1\uff0c\u4f46\u7814\u7a76\u8868\u660e\u5f15\u5165\uff08\u53cd\uff09\u76f8\u5173\u566a\u58f0\u53ef\u4ee5\u901a\u8fc7\u5728\u540e\u7eed\u6b65\u9aa4\u4e2d\u62b5\u6d88\u90e8\u5206\u566a\u58f0\uff0c\u663e\u8457\u6539\u5584\u9690\u79c1-\u6548\u7528\u6743\u8861\u3002", "method": "\u7814\u7a76\u91c7\u7528\u76f8\u5173\u566a\u58f0\u673a\u5236\uff0c\u5982\u77e9\u9635\u673a\u5236\u3001\u56e0\u5b50\u5206\u89e3\u673a\u5236\u548c\u5e94\u7528\u4e8e\u5b66\u4e60\u7b97\u6cd5\u7684DP-FTRL\uff0c\u901a\u8fc7\u52a0\u6743\u524d\u7f00\u548c\u4f30\u8ba1\u5b9e\u73b0\u79c1\u6709\u8bad\u7ec3\u3002", "result": "\u76f8\u5173\u566a\u58f0\u673a\u5236\u5728\u5b9e\u8df5\u4e2d\u5177\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u5df2\u5728\u5168\u7403\u8303\u56f4\u5185\u5b9e\u73b0\u5de5\u4e1a\u7ea7\u90e8\u7f72\u3002", "conclusion": "\u76f8\u5173\u566a\u58f0\u673a\u5236\u901a\u8fc7\u4f18\u5316\u566a\u58f0\u76f8\u5173\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5dee\u5206\u9690\u79c1\u5728AI\u548c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8bad\u7ec3\u4e2d\u7684\u9690\u79c1-\u6548\u7528\u6743\u8861\u3002"}}
{"id": "2506.08205", "pdf": "https://arxiv.org/pdf/2506.08205", "abs": "https://arxiv.org/abs/2506.08205", "authors": ["Shadab Anwar Shaikh", "Kranthi Balusu", "Ayoub Soulami"], "title": "A Machine Learning Approach to Generate Residual Stress Distributions using Sparse Characterization Data in Friction-Stir Processed Parts", "categories": ["cs.LG", "cs.CE"], "comment": null, "summary": "Residual stresses, which remain within a component after processing, can\ndeteriorate performance. Accurately determining their full-field distributions\nis essential for optimizing the structural integrity and longevity. However,\nthe experimental effort required for full-field characterization is\nimpractical. Given these challenges, this work proposes a machine learning (ML)\nbased Residual Stress Generator (RSG) to infer full-field stresses from limited\nmeasurements. An extensive dataset was initially constructed by performing\nnumerous process simulations with a diverse parameter set. A ML model based on\nU-Net architecture was then trained to learn the underlying structure through\nsystematic hyperparameter tuning. Then, the model's ability to generate\nsimulated stresses was evaluated, and it was ultimately tested on actual\ncharacterization data to validate its effectiveness. The model's prediction of\nsimulated stresses shows that it achieved excellent predictive accuracy and\nexhibited a significant degree of generalization, indicating that it\nsuccessfully learnt the latent structure of residual stress distribution. The\nRSG's performance in predicting experimentally characterized data highlights\nthe feasibility of the proposed approach in providing a comprehensive\nunderstanding of residual stress distributions from limited measurements,\nthereby significantly reducing experimental efforts.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u6b8b\u4f59\u5e94\u529b\u751f\u6210\u5668\uff08RSG\uff09\uff0c\u901a\u8fc7\u6709\u9650\u6d4b\u91cf\u6570\u636e\u63a8\u65ad\u5168\u573a\u5e94\u529b\u5206\u5e03\uff0c\u663e\u8457\u51cf\u5c11\u5b9e\u9a8c\u5de5\u4f5c\u91cf\u3002", "motivation": "\u6b8b\u4f59\u5e94\u529b\u4f1a\u5f71\u54cd\u7ec4\u4ef6\u6027\u80fd\uff0c\u4f46\u5168\u573a\u5e94\u529b\u5206\u5e03\u7684\u5b9e\u9a8c\u8868\u5f81\u5de5\u4f5c\u91cf\u5de8\u5927\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u9ad8\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u5927\u91cf\u5de5\u827a\u6a21\u62df\u6784\u5efa\u6570\u636e\u96c6\uff0c\u91c7\u7528U-Net\u67b6\u6784\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u901a\u8fc7\u8d85\u53c2\u6570\u8c03\u4f18\u4f18\u5316\u6a21\u578b\u3002", "result": "\u6a21\u578b\u5728\u6a21\u62df\u5e94\u529b\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u9ad8\u7cbe\u5ea6\u548c\u5f3a\u6cdb\u5316\u80fd\u529b\uff0c\u5b9e\u9a8c\u6570\u636e\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "RSG\u65b9\u6cd5\u80fd\u591f\u4ece\u6709\u9650\u6d4b\u91cf\u4e2d\u5168\u9762\u7406\u89e3\u6b8b\u4f59\u5e94\u529b\u5206\u5e03\uff0c\u663e\u8457\u964d\u4f4e\u5b9e\u9a8c\u9700\u6c42\u3002"}}
{"id": "2506.08216", "pdf": "https://arxiv.org/pdf/2506.08216", "abs": "https://arxiv.org/abs/2506.08216", "authors": ["Shahaf Bassan", "Guy Amir", "Meirav Zehavi", "Guy Katz"], "title": "What makes an Ensemble (Un) Interpretable?", "categories": ["cs.LG", "cs.CC", "cs.LO"], "comment": "To appear in ICML 2025", "summary": "Ensemble models are widely recognized in the ML community for their limited\ninterpretability. For instance, while a single decision tree is considered\ninterpretable, ensembles of trees (e.g., boosted trees) are often treated as\nblack-boxes. Despite this folklore recognition, there remains a lack of\nrigorous mathematical understanding of what particularly makes an ensemble\n(un)-interpretable, including how fundamental factors like the (1) *number*,\n(2) *size*, and (3) *type* of base models influence its interpretability. In\nthis work, we seek to bridge this gap by applying concepts from computational\ncomplexity theory to study the challenges of generating explanations for\nvarious ensemble configurations. Our analysis uncovers nuanced complexity\npatterns influenced by various factors. For example, we demonstrate that under\nstandard complexity assumptions like P$\\neq$NP, interpreting ensembles remains\nintractable even when base models are of constant size. Surprisingly, the\ncomplexity changes drastically with the number of base models: small ensembles\nof decision trees are efficiently interpretable, whereas interpreting ensembles\nwith even a constant number of linear models remains intractable. We believe\nthat our findings provide a more robust foundation for understanding the\ninterpretability of ensembles, emphasizing the benefits of examining it through\na computational complexity lens.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u96c6\u6210\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u8ba1\u7b97\u590d\u6742\u6027\u7406\u8bba\u5206\u6790\u4e86\u5f71\u54cd\u5176\u53ef\u89e3\u91ca\u6027\u7684\u56e0\u7d20\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u914d\u7f6e\u4e0b\u7684\u590d\u6742\u6027\u6a21\u5f0f\u3002", "motivation": "\u5c3d\u7ba1\u96c6\u6210\u6a21\u578b\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u88ab\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u5176\u53ef\u89e3\u91ca\u6027\u7f3a\u4e4f\u4e25\u683c\u7684\u6570\u5b66\u7406\u89e3\uff0c\u5c24\u5176\u662f\u57fa\u7840\u6a21\u578b\u7684\u6570\u91cf\u3001\u5927\u5c0f\u548c\u7c7b\u578b\u5982\u4f55\u5f71\u54cd\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u5e94\u7528\u8ba1\u7b97\u590d\u6742\u6027\u7406\u8bba\uff0c\u7814\u7a76\u4e0d\u540c\u96c6\u6210\u914d\u7f6e\u4e0b\u751f\u6210\u89e3\u91ca\u7684\u6311\u6218\u3002", "result": "\u5206\u6790\u8868\u660e\uff0c\u5373\u4f7f\u57fa\u7840\u6a21\u578b\u5927\u5c0f\u56fa\u5b9a\uff0c\u89e3\u91ca\u96c6\u6210\u6a21\u578b\u4ecd\u5177\u6709\u8ba1\u7b97\u590d\u6742\u6027\uff1b\u51b3\u7b56\u6811\u7684\u5c0f\u578b\u96c6\u6210\u53ef\u9ad8\u6548\u89e3\u91ca\uff0c\u800c\u7ebf\u6027\u6a21\u578b\u7684\u96c6\u6210\u5373\u4f7f\u6570\u91cf\u5c11\u4e5f\u96be\u4ee5\u89e3\u91ca\u3002", "conclusion": "\u7814\u7a76\u4e3a\u7406\u89e3\u96c6\u6210\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u63d0\u4f9b\u4e86\u66f4\u575a\u5b9e\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5f3a\u8c03\u4e86\u8ba1\u7b97\u590d\u6742\u6027\u89c6\u89d2\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2506.08226", "pdf": "https://arxiv.org/pdf/2506.08226", "abs": "https://arxiv.org/abs/2506.08226", "authors": ["Arthur Feeney", "Kuei-Hsiang Huang", "Aparna Chandramowlishwaran"], "title": "Mondrian: Transformer Operators via Domain Decomposition", "categories": ["cs.LG"], "comment": "26 pages, 7 figures", "summary": "Operator learning enables data-driven modeling of partial differential\nequations (PDEs) by learning mappings between function spaces. However, scaling\ntransformer-based operator models to high-resolution, multiscale domains\nremains a challenge due to the quadratic cost of attention and its coupling to\ndiscretization. We introduce \\textbf{Mondrian}, transformer operators that\ndecompose a domain into non-overlapping subdomains and apply attention over\nsequences of subdomain-restricted functions. Leveraging principles from domain\ndecomposition, Mondrian decouples attention from discretization. Within each\nsubdomain, it replaces standard layers with expressive neural operators, and\nattention across subdomains is computed via softmax-based inner products over\nfunctions. The formulation naturally extends to hierarchical windowed and\nneighborhood attention, supporting both local and global interactions. Mondrian\nachieves strong performance on Allen-Cahn and Navier-Stokes PDEs, demonstrating\nresolution scaling without retraining. These results highlight the promise of\ndomain-decomposed attention for scalable and general-purpose neural operators.", "AI": {"tldr": "Mondrian\u662f\u4e00\u79cd\u57fa\u4e8eTransformer\u7684\u7b97\u5b50\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u57df\u5206\u89e3\u4e3a\u4e0d\u91cd\u53e0\u7684\u5b50\u57df\u5e76\u5e94\u7528\u6ce8\u610f\u529b\u673a\u5236\uff0c\u89e3\u51b3\u4e86\u9ad8\u5206\u8fa8\u7387\u3001\u591a\u5c3a\u5ea6PDE\u5efa\u6a21\u4e2d\u7684\u8ba1\u7b97\u6311\u6218\u3002", "motivation": "\u4f20\u7edfTransformer\u6a21\u578b\u5728\u9ad8\u5206\u8fa8\u7387\u3001\u591a\u5c3a\u5ea6PDE\u5efa\u6a21\u4e2d\u56e0\u6ce8\u610f\u529b\u673a\u5236\u7684\u4e8c\u6b21\u8ba1\u7b97\u6210\u672c\u548c\u4e0e\u79bb\u6563\u5316\u7684\u8026\u5408\u800c\u96be\u4ee5\u6269\u5c55\u3002", "method": "Mondrian\u5c06\u57df\u5206\u89e3\u4e3a\u5b50\u57df\uff0c\u5728\u5b50\u57df\u5185\u4f7f\u7528\u795e\u7ecf\u7b97\u5b50\u66ff\u4ee3\u6807\u51c6\u5c42\uff0c\u5e76\u901a\u8fc7\u57fa\u4e8esoftmax\u7684\u5185\u79ef\u8ba1\u7b97\u5b50\u57df\u95f4\u7684\u6ce8\u610f\u529b\u3002\u652f\u6301\u5206\u5c42\u7a97\u53e3\u548c\u90bb\u57df\u6ce8\u610f\u529b\u3002", "result": "\u5728Allen-Cahn\u548cNavier-Stokes PDE\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u652f\u6301\u5206\u8fa8\u7387\u6269\u5c55\u800c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u3002", "conclusion": "Mondrian\u5c55\u793a\u4e86\u57df\u5206\u89e3\u6ce8\u610f\u529b\u5728\u53ef\u6269\u5c55\u548c\u901a\u7528\u795e\u7ecf\u7b97\u5b50\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.08228", "pdf": "https://arxiv.org/pdf/2506.08228", "abs": "https://arxiv.org/abs/2506.08228", "authors": ["Mustafa Baniodeh", "Kratarth Goel", "Scott Ettinger", "Carlos Fuertes", "Ari Seff", "Tim Shen", "Cole Gulino", "Chenjie Yang", "Ghassen Jerfel", "Dokook Choe", "Rui Wang", "Vinutha Kallem", "Sergio Casas", "Rami Al-Rfou", "Benjamin Sapp", "Dragomir Anguelov"], "title": "Scaling Laws of Motion Forecasting and Planning -- A Technical Report", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "We study the empirical scaling laws of a family of encoder-decoder\nautoregressive transformer models on the task of joint motion forecasting and\nplanning in the autonomous driving domain. Using a 500 thousand hours driving\ndataset, we demonstrate that, similar to language modeling, model performance\nimproves as a power-law function of the total compute budget, and we observe a\nstrong correlation between model training loss and model evaluation metrics.\nMost interestingly, closed-loop metrics also improve with scaling, which has\nimportant implications for the suitability of open-loop metrics for model\ndevelopment and hill climbing. We also study the optimal scaling of the number\nof transformer parameters and the training data size for a training\ncompute-optimal model. We find that as the training compute budget grows,\noptimal scaling requires increasing the model size 1.5x as fast as the dataset\nsize. We also study inference-time compute scaling, where we observe that\nsampling and clustering the output of smaller models makes them competitive\nwith larger models, up to a crossover point beyond which a larger models\nbecomes more inference-compute efficient. Overall, our experimental results\ndemonstrate that optimizing the training and inference-time scaling properties\nof motion forecasting and planning models is a key lever for improving their\nperformance to address a wide variety of driving scenarios. Finally, we briefly\nstudy the utility of training on general logged driving data of other agents to\nimprove the performance of the ego-agent, an important research area to address\nthe scarcity of robotics data for large capacity models training.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u7f16\u7801\u5668-\u89e3\u7801\u5668\u81ea\u56de\u5f52Transformer\u6a21\u578b\u5728\u81ea\u52a8\u9a7e\u9a76\u9886\u57df\u7684\u8fd0\u52a8\u9884\u6d4b\u548c\u89c4\u5212\u4efb\u52a1\u4e2d\uff0c\u6027\u80fd\u968f\u8ba1\u7b97\u9884\u7b97\u5448\u5e42\u5f8b\u589e\u957f\uff0c\u95ed\u73af\u6307\u6807\u4e5f\u968f\u89c4\u6a21\u63d0\u5347\u3002", "motivation": "\u63a2\u7d22\u81ea\u52a8\u9a7e\u9a76\u9886\u57df\u4e2d\u8fd0\u52a8\u9884\u6d4b\u548c\u89c4\u5212\u6a21\u578b\u7684\u6027\u80fd\u4e0e\u8ba1\u7b97\u9884\u7b97\u3001\u6a21\u578b\u89c4\u6a21\u53ca\u6570\u636e\u89c4\u6a21\u7684\u5173\u7cfb\uff0c\u4ee5\u4f18\u5316\u6a21\u578b\u5f00\u53d1\u548c\u8bc4\u4f30\u3002", "method": "\u4f7f\u752850\u4e07\u5c0f\u65f6\u9a7e\u9a76\u6570\u636e\u96c6\uff0c\u7814\u7a76\u6a21\u578b\u6027\u80fd\u4e0e\u8ba1\u7b97\u9884\u7b97\u7684\u5173\u7cfb\uff0c\u5206\u6790\u6a21\u578b\u53c2\u6570\u4e0e\u6570\u636e\u89c4\u6a21\u7684\u4f18\u5316\u6bd4\u4f8b\uff0c\u5e76\u63a2\u8ba8\u63a8\u7406\u65f6\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u6a21\u578b\u6027\u80fd\u968f\u8ba1\u7b97\u9884\u7b97\u5448\u5e42\u5f8b\u589e\u957f\uff0c\u95ed\u73af\u6307\u6807\u63d0\u5347\uff1b\u6a21\u578b\u89c4\u6a21\u9700\u6bd4\u6570\u636e\u89c4\u6a21\u589e\u957f\u5feb1.5\u500d\uff1b\u5c0f\u6a21\u578b\u901a\u8fc7\u91c7\u6837\u548c\u805a\u7c7b\u5728\u63a8\u7406\u65f6\u53ef\u4e0e\u66f4\u5927\u6a21\u578b\u7ade\u4e89\u3002", "conclusion": "\u4f18\u5316\u8bad\u7ec3\u548c\u63a8\u7406\u65f6\u7684\u89c4\u6a21\u7279\u6027\u662f\u63d0\u5347\u8fd0\u52a8\u9884\u6d4b\u548c\u89c4\u5212\u6a21\u578b\u6027\u80fd\u7684\u5173\u952e\uff0c\u540c\u65f6\u5229\u7528\u5176\u4ed6\u8f66\u8f86\u7684\u9a7e\u9a76\u6570\u636e\u53ef\u7f13\u89e3\u673a\u5668\u4eba\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u3002"}}
{"id": "2506.08231", "pdf": "https://arxiv.org/pdf/2506.08231", "abs": "https://arxiv.org/abs/2506.08231", "authors": ["Melissa Estevez", "Nisha Singh", "Lauren Dyson", "Blythe Adamson", "Qianyu Yuan", "Megan W. Hildner", "Erin Fidyk", "Olive Mbah", "Farhad Khan", "Kathi Seidl-Rathkopf", "Aaron B. Cohen"], "title": "Ensuring Reliability of Curated EHR-Derived Data: The Validation of Accuracy for LLM/ML-Extracted Information and Data (VALID) Framework", "categories": ["cs.LG", "cs.AI", "cs.PF"], "comment": "18 pages, 3 tables, 1 figure", "summary": "Large language models (LLMs) are increasingly used to extract clinical data\nfrom electronic health records (EHRs), offering significant improvements in\nscalability and efficiency for real-world data (RWD) curation in oncology.\nHowever, the adoption of LLMs introduces new challenges in ensuring the\nreliability, accuracy, and fairness of extracted data, which are essential for\nresearch, regulatory, and clinical applications. Existing quality assurance\nframeworks for RWD and artificial intelligence do not fully address the unique\nerror modes and complexities associated with LLM-extracted data. In this paper,\nwe propose a comprehensive framework for evaluating the quality of clinical\ndata extracted by LLMs. The framework integrates variable-level performance\nbenchmarking against expert human abstraction, automated verification checks\nfor internal consistency and plausibility, and replication analyses comparing\nLLM-extracted data to human-abstracted datasets or external standards. This\nmultidimensional approach enables the identification of variables most in need\nof improvement, systematic detection of latent errors, and confirmation of\ndataset fitness-for-purpose in real-world research. Additionally, the framework\nsupports bias assessment by stratifying metrics across demographic subgroups.\nBy providing a rigorous and transparent method for assessing LLM-extracted RWD,\nthis framework advances industry standards and supports the trustworthy use of\nAI-powered evidence generation in oncology research and practice.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u63d0\u53d6\u4e34\u5e8a\u6570\u636e\u8d28\u91cf\u7684\u7efc\u5408\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u8d28\u91cf\u4fdd\u8bc1\u6846\u67b6\u672a\u6db5\u76d6\u7684\u72ec\u7279\u6311\u6218\u3002", "motivation": "LLM\u5728\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHR\uff09\u6570\u636e\u63d0\u53d6\u4e2d\u867d\u63d0\u9ad8\u4e86\u6548\u7387\uff0c\u4f46\u5176\u53ef\u9760\u6027\u3001\u51c6\u786e\u6027\u548c\u516c\u5e73\u6027\u4ecd\u9700\u9a8c\u8bc1\uff0c\u5c24\u5176\u662f\u5728\u80bf\u7624\u5b66\u7814\u7a76\u4e2d\u3002", "method": "\u6846\u67b6\u7ed3\u5408\u4e86\u53d8\u91cf\u7ea7\u6027\u80fd\u57fa\u51c6\u6d4b\u8bd5\u3001\u81ea\u52a8\u9a8c\u8bc1\u68c0\u67e5\uff08\u5185\u90e8\u4e00\u81f4\u6027\u548c\u5408\u7406\u6027\uff09\u4ee5\u53ca\u590d\u5236\u5206\u6790\uff08\u4e0e\u4eba\u5de5\u63d0\u53d6\u6570\u636e\u6216\u5916\u90e8\u6807\u51c6\u5bf9\u6bd4\uff09\u3002", "result": "\u8be5\u591a\u7ef4\u65b9\u6cd5\u80fd\u8bc6\u522b\u9700\u6539\u8fdb\u7684\u53d8\u91cf\u3001\u7cfb\u7edf\u6027\u68c0\u6d4b\u6f5c\u5728\u9519\u8bef\uff0c\u5e76\u786e\u8ba4\u6570\u636e\u96c6\u5728\u771f\u5b9e\u4e16\u754c\u7814\u7a76\u4e2d\u7684\u9002\u7528\u6027\uff0c\u540c\u65f6\u652f\u6301\u504f\u5dee\u8bc4\u4f30\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aLLM\u63d0\u53d6\u7684\u771f\u5b9e\u4e16\u754c\u6570\u636e\u63d0\u4f9b\u4e86\u4e25\u683c\u900f\u660e\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u63a8\u52a8\u4e86\u884c\u4e1a\u6807\u51c6\uff0c\u652f\u6301AI\u5728\u80bf\u7624\u5b66\u7814\u7a76\u4e2d\u7684\u53ef\u4fe1\u5e94\u7528\u3002"}}
{"id": "2506.08240", "pdf": "https://arxiv.org/pdf/2506.08240", "abs": "https://arxiv.org/abs/2506.08240", "authors": ["Dongkyu Cho", "Rumi Chunara"], "title": "Dealing with the Evil Twins: Improving Random Augmentation by Addressing Catastrophic Forgetting of Diverse Augmentations", "categories": ["cs.LG"], "comment": "12 pages, 6 figures", "summary": "Data augmentation is a promising tool for enhancing out-of-distribution\ngeneralization, where the key is to produce diverse, challenging variations of\nthe source domain via costly targeted augmentations that maximize its\ngeneralization effect. Conversely, random augmentation is inexpensive but is\ndeemed suboptimal due to its limited effect. In this paper, we revisit random\naugmentation and explore methods to address its shortcomings. We show that the\nstochastic nature of random augmentation can produce a set of colliding\naugmentations that distorts the learned features, similar to catastrophic\nforgetting. We propose a simple solution that improves the generalization\neffect of random augmentation by addressing forgetting, which displays strong\ngeneralization performance across various single source domain generalization\n(sDG) benchmarks.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u968f\u673a\u6570\u636e\u589e\u5f3a\u7684\u4e0d\u8db3\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u65b9\u6cd5\u4ee5\u89e3\u51b3\u5176\u5bfc\u81f4\u7684\u7279\u5f81\u5931\u771f\u95ee\u9898\uff0c\u4ece\u800c\u63d0\u5347\u6cdb\u5316\u6027\u80fd\u3002", "motivation": "\u968f\u673a\u6570\u636e\u589e\u5f3a\u867d\u7136\u6210\u672c\u4f4e\uff0c\u4f46\u56e0\u5176\u5c40\u9650\u6027\u88ab\u8ba4\u4e3a\u6548\u679c\u4e0d\u4f73\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u5176\u5bfc\u81f4\u7684\u7279\u5f81\u5931\u771f\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u65b9\u6cd5\uff0c\u901a\u8fc7\u89e3\u51b3\u968f\u673a\u589e\u5f3a\u4e2d\u7684\u9057\u5fd8\u95ee\u9898\u6765\u6539\u8fdb\u5176\u6cdb\u5316\u6548\u679c\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u5355\u6e90\u57df\u6cdb\u5316\uff08sDG\uff09\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u89e3\u51b3\u968f\u673a\u589e\u5f3a\u7684\u9057\u5fd8\u95ee\u9898\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u5176\u6cdb\u5316\u6548\u679c\uff0c\u6210\u4e3a\u4e00\u79cd\u4f4e\u6210\u672c\u4e14\u9ad8\u6548\u7684\u589e\u5f3a\u65b9\u6cd5\u3002"}}
{"id": "2506.08243", "pdf": "https://arxiv.org/pdf/2506.08243", "abs": "https://arxiv.org/abs/2506.08243", "authors": ["Zhenjiang Mao", "Artem Bisliouk", "Rohith Reddy Nama", "Ivan Ruchkin"], "title": "Temporalizing Confidence: Evaluation of Chain-of-Thought Reasoning with Signal Temporal Logic", "categories": ["cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have shown impressive performance in\nmathematical reasoning tasks when guided by Chain-of-Thought (CoT) prompting.\nHowever, they tend to produce highly confident yet incorrect outputs, which\nposes significant risks in domains like education, where users may lack the\nexpertise to assess reasoning steps. To address this, we propose a structured\nframework that models stepwise confidence as a temporal signal and evaluates it\nusing Signal Temporal Logic (STL). In particular, we define formal STL-based\nconstraints to capture desirable temporal properties and compute robustness\nscores that serve as structured, interpretable confidence estimates. Our\napproach also introduces a set of uncertainty reshaping strategies to enforce\nsmoothness, monotonicity, and causal consistency across the reasoning\ntrajectory. Experiments show that our approach consistently improves\ncalibration metrics and provides more reliable uncertainty estimates than\nconventional confidence aggregation and post-hoc calibration.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4fe1\u53f7\u65f6\u5e8f\u903b\u8f91\uff08STL\uff09\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u548c\u6539\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u9010\u6b65\u7f6e\u4fe1\u5ea6\uff0c\u4ece\u800c\u63d0\u9ad8\u5176\u8f93\u51fa\u7684\u53ef\u9760\u6027\u3002", "motivation": "LLMs\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5bb9\u6613\u4ea7\u751f\u9ad8\u7f6e\u4fe1\u5ea6\u5374\u9519\u8bef\u7684\u8f93\u51fa\uff0c\u8fd9\u5728\u6559\u80b2\u7b49\u9886\u57df\u5b58\u5728\u98ce\u9669\u3002", "method": "\u5229\u7528STL\u5b9a\u4e49\u65f6\u5e8f\u7ea6\u675f\uff0c\u8ba1\u7b97\u9c81\u68d2\u6027\u5206\u6570\u4f5c\u4e3a\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\uff0c\u5e76\u5f15\u5165\u4e0d\u786e\u5b9a\u6027\u91cd\u5851\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u6539\u5584\u4e86\u6821\u51c6\u6307\u6807\uff0c\u63d0\u4f9b\u4e86\u6bd4\u4f20\u7edf\u65b9\u6cd5\u66f4\u53ef\u9760\u7684\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86LLMs\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u7f6e\u4fe1\u5ea6\u53ef\u9760\u6027\u548c\u8f93\u51fa\u8d28\u91cf\u3002"}}
{"id": "2506.08244", "pdf": "https://arxiv.org/pdf/2506.08244", "abs": "https://arxiv.org/abs/2506.08244", "authors": ["Riccardo Ali", "Pietro Li\u00f2", "Jamie Vicary"], "title": "Parameter-free approximate equivariance for tasks with finite group symmetry", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Equivariant neural networks incorporate symmetries through group actions,\nembedding them as an inductive bias to improve performance on a wide variety of\ntasks. However, existing equivariant methods can be computationally intensive,\nwith high parameter counts, and are often tied to a specific architecture. We\npropose a simple zero-parameter approach that imposes approximate equivariance\nfor a finite group in the latent representation, as an additional term in the\nloss function. We conduct experiments which allow the network to learn a group\nrepresentation on the latent space, and show in every case it prefers to learn\nthe regular representation. Fixing this action on the latent space, this yields\na simple method to impose approximate equivariance as an additional loss\npenalty. We benchmark our approach on three datasets and compare it against\nseveral existing equivariant methods, showing that in many cases it achieves\nsimilar or better performance for a fraction of the parameters.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u96f6\u53c2\u6570\u7684\u8fd1\u4f3c\u7b49\u53d8\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u635f\u5931\u51fd\u6570\u4e2d\u6dfb\u52a0\u989d\u5916\u9879\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u6027\u548c\u53c2\u6570\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7b49\u53d8\u65b9\u6cd5\u8ba1\u7b97\u91cf\u5927\u3001\u53c2\u6570\u91cf\u9ad8\u4e14\u67b6\u6784\u53d7\u9650\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u7b80\u5355\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5728\u6f5c\u5728\u8868\u793a\u4e2d\u4e3a\u6709\u9650\u7fa4\u6dfb\u52a0\u8fd1\u4f3c\u7b49\u53d8\u9879\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\u7684\u989d\u5916\u60e9\u7f5a\u9879\uff0c\u5e76\u8ba9\u7f51\u7edc\u5b66\u4e60\u6f5c\u5728\u7a7a\u95f4\u7684\u7fa4\u8868\u793a\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u7f51\u7edc\u503e\u5411\u4e8e\u5b66\u4e60\u6b63\u5219\u8868\u793a\uff0c\u4e14\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u6027\u80fd\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u5f53\u6216\u66f4\u597d\uff0c\u540c\u65f6\u53c2\u6570\u91cf\u5927\u5e45\u51cf\u5c11\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u9ad8\u6548\u7684\u8fd1\u4f3c\u7b49\u53d8\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u4efb\u52a1\u3002"}}
{"id": "2506.08255", "pdf": "https://arxiv.org/pdf/2506.08255", "abs": "https://arxiv.org/abs/2506.08255", "authors": ["Patryk Krukowski", "\u0141ukasz Gorczyca", "Piotr Helm", "Kamil Ksi\u0105\u017cek", "Przemys\u0142aw Spurek"], "title": "SHIELD: Secure Hypernetworks for Incremental Expansion Learning Defense", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Traditional deep neural networks suffer from several limitations, including\ncatastrophic forgetting. When models are adapted to new datasets, they tend to\nquickly forget previously learned knowledge. Another significant issue is the\nlack of robustness to even small perturbations in the input data. In practice,\nwe can often easily perform adversarial attacks and change the network's\npredictions, adding minimal noise to the input. Dedicated architectures and\ntraining procedures can solve each of the above problems separately.\nUnfortunately, currently, no model can simultaneously address both catastrophic\nforgetting and vulnerability to adversarial attacks. We introduce SHIELD\n(Secure Hypernetworks for Incremental Expansion and Learning Defense), a novel\napproach that integrates a hypernetwork-based continual learning approach with\ninterval arithmetic. SHIELD use the hypernetwork to transfer trainable task\nembedding vectors into the weights of a target model dedicated to specific\ndata. This paradigm allows for the dynamic generation of separate networks for\neach subtask, while the hypernetwork aggregates and analyzes information across\nall tasks. The target model takes in the input a data sample with a defined\ninterval range, and by creating a hypercube, produces a prediction for the\ngiven range. Therefore, such target models provide strict guarantees against\nall possible attacks for data samples within the interval range. Our approach\nenhances security without sacrificing network adaptability, addressing the\noverlooked challenge of safety in continual learning.", "AI": {"tldr": "SHIELD\u662f\u4e00\u79cd\u7ed3\u5408\u8d85\u7f51\u7edc\u548c\u533a\u95f4\u7b97\u672f\u7684\u65b0\u65b9\u6cd5\uff0c\u65e8\u5728\u540c\u65f6\u89e3\u51b3\u707e\u96be\u6027\u9057\u5fd8\u548c\u5bf9\u6297\u653b\u51fb\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5b58\u5728\u707e\u96be\u6027\u9057\u5fd8\u548c\u5bf9\u8f93\u5165\u6570\u636e\u6270\u52a8\u7684\u8106\u5f31\u6027\uff0c\u76ee\u524d\u5c1a\u65e0\u6a21\u578b\u80fd\u540c\u65f6\u89e3\u51b3\u8fd9\u4e24\u4e2a\u95ee\u9898\u3002", "method": "SHIELD\u901a\u8fc7\u8d85\u7f51\u7edc\u751f\u6210\u9488\u5bf9\u7279\u5b9a\u4efb\u52a1\u7684\u76ee\u6807\u6a21\u578b\u6743\u91cd\uff0c\u5e76\u7ed3\u5408\u533a\u95f4\u7b97\u672f\u4e3a\u8f93\u5165\u6570\u636e\u63d0\u4f9b\u4e25\u683c\u7684\u5b89\u5168\u4fdd\u8bc1\u3002", "result": "SHIELD\u80fd\u591f\u5728\u6301\u7eed\u5b66\u4e60\u4e2d\u52a8\u6001\u751f\u6210\u4efb\u52a1\u4e13\u7528\u7f51\u7edc\uff0c\u540c\u65f6\u62b5\u5fa1\u5bf9\u6297\u653b\u51fb\u3002", "conclusion": "SHIELD\u5728\u63d0\u5347\u5b89\u5168\u6027\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u7f51\u7edc\u7684\u9002\u5e94\u6027\uff0c\u89e3\u51b3\u4e86\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u5b89\u5168\u6027\u6311\u6218\u3002"}}
{"id": "2506.08266", "pdf": "https://arxiv.org/pdf/2506.08266", "abs": "https://arxiv.org/abs/2506.08266", "authors": ["Yaswanth Chittepu", "Blossom Metevier", "Will Schwarzer", "Austin Hoag", "Scott Niekum", "Philip S. Thomas"], "title": "Reinforcement Learning from Human Feedback with High-Confidence Safety Constraints", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.AP"], "comment": "20 pages, 6 figures, 4 tables, Second Reinforcement Learning\n  Conference (RLC 2025)", "summary": "Existing approaches to language model alignment often treat safety as a\ntradeoff against helpfulness, which can lead to unacceptable responses in\nsensitive domains. To ensure reliable performance in such settings, we propose\nHigh-Confidence Safe Reinforcement Learning from Human Feedback (HC-RLHF), a\nmethod that provides high-confidence safety guarantees while maximizing\nhelpfulness. Similar to previous methods, HC-RLHF explicitly decouples human\npreferences into helpfulness and harmlessness (safety), which are learned by\ntraining a reward model and a cost model, respectively. It then employs a\ntwo-step process to find safe solutions. In the first step, it optimizes the\nreward function under an intentionally pessimistic version of the cost\nconstraint. In the second step, the trained model undergoes a safety test to\nverify whether its performance stays within an upper-confidence bound of the\nactual cost constraint. We provide a theoretical analysis of HC-RLHF, including\nproof that it will not return an unsafe solution with a probability greater\nthan a user-specified threshold. For our empirical analysis, we apply HC-RLHF\nto align three different language models (Qwen2-1.5B, Qwen2.5-3B, and\nLLaMa3.2-3B) with human preferences. Our results demonstrate that HC-RLHF\nproduces safe models with high probability and can improve harmlessness and\nhelpfulness compared to previous methods.", "AI": {"tldr": "HC-RLHF\u662f\u4e00\u79cd\u9ad8\u7f6e\u4fe1\u5ea6\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u89e3\u8026\u4eba\u7c7b\u504f\u597d\u4e3a\u5e2e\u52a9\u6027\u548c\u5b89\u5168\u6027\uff0c\u63d0\u4f9b\u5b89\u5168\u4fdd\u8bc1\u7684\u540c\u65f6\u6700\u5927\u5316\u5e2e\u52a9\u6027\u3002", "motivation": "\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u65b9\u6cd5\u5e38\u5c06\u5b89\u5168\u6027\u4e0e\u5e2e\u52a9\u6027\u5bf9\u7acb\uff0c\u5bfc\u81f4\u654f\u611f\u9886\u57df\u4e0d\u53ef\u63a5\u53d7\u7684\u54cd\u5e94\uff0c\u9700\u6539\u8fdb\u3002", "method": "HC-RLHF\u8bad\u7ec3\u5956\u52b1\u6a21\u578b\u548c\u6210\u672c\u6a21\u578b\uff0c\u5206\u4e24\u6b65\u4f18\u5316\uff1a\u60b2\u89c2\u7ea6\u675f\u4e0b\u4f18\u5316\u5956\u52b1\uff0c\u518d\u901a\u8fc7\u5b89\u5168\u6d4b\u8bd5\u9a8c\u8bc1\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u8868\u660eHC-RLHF\u5728Qwen2\u548cLLaMa3\u6a21\u578b\u4e0a\u663e\u8457\u63d0\u5347\u5b89\u5168\u6027\u548c\u5e2e\u52a9\u6027\u3002", "conclusion": "HC-RLHF\u80fd\u9ad8\u6982\u7387\u751f\u6210\u5b89\u5168\u6a21\u578b\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2506.08267", "pdf": "https://arxiv.org/pdf/2506.08267", "abs": "https://arxiv.org/abs/2506.08267", "authors": ["Mansooreh Montazerin", "Majd Al Aawar", "Antonio Ortega", "Ajitesh Srivastava"], "title": "Sparse Interpretable Deep Learning with LIES Networks for Symbolic Regression", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Symbolic regression (SR) aims to discover closed-form mathematical\nexpressions that accurately describe data, offering interpretability and\nanalytical insight beyond standard black-box models. Existing SR methods often\nrely on population-based search or autoregressive modeling, which struggle with\nscalability and symbolic consistency. We introduce LIES (Logarithm, Identity,\nExponential, Sine), a fixed neural network architecture with interpretable\nprimitive activations that are optimized to model symbolic expressions. We\ndevelop a framework to extract compact formulae from LIES networks by training\nwith an appropriate oversampling strategy and a tailored loss function to\npromote sparsity and to prevent gradient instability. After training, it\napplies additional pruning strategies to further simplify the learned\nexpressions into compact formulae. Our experiments on SR benchmarks show that\nthe LIES framework consistently produces sparse and accurate symbolic formulae\noutperforming all baselines. We also demonstrate the importance of each design\ncomponent through ablation studies.", "AI": {"tldr": "LIES\u6846\u67b6\u901a\u8fc7\u56fa\u5b9a\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u548c\u4f18\u5316\u7b56\u7565\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u7b26\u53f7\u56de\u5f52\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7b26\u53f7\u56de\u5f52\u65b9\u6cd5\u5728\u53ef\u6269\u5c55\u6027\u548c\u7b26\u53f7\u4e00\u81f4\u6027\u4e0a\u5b58\u5728\u4e0d\u8db3\uff0cLIES\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u91c7\u7528LIES\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u7ed3\u5408\u8fc7\u91c7\u6837\u7b56\u7565\u548c\u5b9a\u5236\u635f\u5931\u51fd\u6570\uff0c\u8bad\u7ec3\u540e\u901a\u8fc7\u526a\u679d\u7b80\u5316\u8868\u8fbe\u5f0f\u3002", "result": "\u5b9e\u9a8c\u8868\u660eLIES\u751f\u6210\u7684\u516c\u5f0f\u7a00\u758f\u4e14\u51c6\u786e\uff0c\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "LIES\u6846\u67b6\u901a\u8fc7\u5176\u8bbe\u8ba1\u7ec4\u4ef6\u6709\u6548\u63d0\u5347\u4e86\u7b26\u53f7\u56de\u5f52\u7684\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2506.08270", "pdf": "https://arxiv.org/pdf/2506.08270", "abs": "https://arxiv.org/abs/2506.08270", "authors": ["Zitong Huang", "Mansooreh Montazerin", "Ajitesh Srivastava"], "title": "SWAT-NN: Simultaneous Weights and Architecture Training for Neural Networks in a Latent Space", "categories": ["cs.LG"], "comment": null, "summary": "Designing neural networks typically relies on manual trial and error or a\nneural architecture search (NAS) followed by weight training. The former is\ntime-consuming and labor-intensive, while the latter often discretizes\narchitecture search and weight optimization. In this paper, we propose a\nfundamentally different approach that simultaneously optimizes both the\narchitecture and the weights of a neural network. Our framework first trains a\nuniversal multi-scale autoencoder that embeds both architectural and parametric\ninformation into a continuous latent space, where functionally similar neural\nnetworks are mapped closer together. Given a dataset, we then randomly\ninitialize a point in the embedding space and update it via gradient descent to\nobtain the optimal neural network, jointly optimizing its structure and\nweights. The optimization process incorporates sparsity and compactness\npenalties to promote efficient models. Experiments on synthetic regression\ntasks demonstrate that our method effectively discovers sparse and compact\nneural networks with strong performance.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u540c\u65f6\u4f18\u5316\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u548c\u6743\u91cd\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fde\u7eed\u6f5c\u5728\u7a7a\u95f4\u5d4c\u5165\u67b6\u6784\u548c\u53c2\u6570\u4fe1\u606f\uff0c\u5b9e\u73b0\u9ad8\u6548\u6a21\u578b\u8bbe\u8ba1\u3002", "motivation": "\u4f20\u7edf\u795e\u7ecf\u7f51\u7edc\u8bbe\u8ba1\u4f9d\u8d56\u624b\u52a8\u8bd5\u9519\u6216\u5206\u6b65\u4f18\u5316\uff0c\u6548\u7387\u4f4e\u4e14\u4e0d\u8fde\u7eed\u3002", "method": "\u8bad\u7ec3\u591a\u5c3a\u5ea6\u81ea\u7f16\u7801\u5668\u5d4c\u5165\u67b6\u6784\u548c\u53c2\u6570\u4fe1\u606f\uff0c\u901a\u8fc7\u68af\u5ea6\u4e0b\u964d\u8054\u5408\u4f18\u5316\u7ed3\u6784\u548c\u6743\u91cd\u3002", "result": "\u5728\u5408\u6210\u56de\u5f52\u4efb\u52a1\u4e2d\u6210\u529f\u53d1\u73b0\u7a00\u758f\u4e14\u7d27\u51d1\u7684\u9ad8\u6027\u80fd\u7f51\u7edc\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u795e\u7ecf\u7f51\u7edc\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u8fde\u7eed\u7684\u4f18\u5316\u9014\u5f84\u3002"}}
{"id": "2506.08272", "pdf": "https://arxiv.org/pdf/2506.08272", "abs": "https://arxiv.org/abs/2506.08272", "authors": ["Tarushri N. S."], "title": "Universal Differential Equations for Scientific Machine Learning of Node-Wise Battery Dynamics in Smart Grids", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Universal Differential Equations (UDEs), which blend neural networks with\nphysical differential equations, have emerged as a powerful framework for\nscientific machine learning (SciML), enabling data-efficient, interpretable,\nand physically consistent modeling. In the context of smart grid systems,\nmodeling node-wise battery dynamics remains a challenge due to the\nstochasticity of solar input and variability in household load profiles.\nTraditional approaches often struggle with generalization and fail to capture\nunmodeled residual dynamics. This work proposes a UDE-based approach to learn\nnode-specific battery evolution by embedding a neural residual into a\nphysically inspired battery ODE. Synthetic yet realistic solar generation and\nload demand data are used to simulate battery dynamics over time. The neural\ncomponent learns to model unobserved or stochastic corrections arising from\nheterogeneity in node demand and environmental conditions. Comprehensive\nexperiments reveal that the trained UDE aligns closely with ground truth\nbattery trajectories, exhibits smooth convergence behavior, and maintains\nstability in long-term forecasts. These findings affirm the viability of\nUDE-based SciML approaches for battery modeling in decentralized energy\nnetworks and suggest broader implications for real-time control and\noptimization in renewable-integrated smart grids.", "AI": {"tldr": "UDEs\u7ed3\u5408\u795e\u7ecf\u7f51\u7edc\u4e0e\u7269\u7406\u5fae\u5206\u65b9\u7a0b\uff0c\u7528\u4e8e\u667a\u80fd\u7535\u7f51\u4e2d\u7535\u6c60\u52a8\u6001\u5efa\u6a21\uff0c\u6570\u636e\u9ad8\u6548\u4e14\u7269\u7406\u4e00\u81f4\u3002", "motivation": "\u89e3\u51b3\u667a\u80fd\u7535\u7f51\u4e2d\u7535\u6c60\u52a8\u6001\u5efa\u6a21\u7684\u6311\u6218\uff0c\u5305\u62ec\u592a\u9633\u80fd\u7684\u968f\u673a\u6027\u548c\u5bb6\u5ead\u8d1f\u8f7d\u7684\u53d8\u5f02\u6027\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u672a\u5efa\u6a21\u7684\u6b8b\u5dee\u52a8\u6001\u3002", "method": "\u63d0\u51fa\u57fa\u4e8eUDE\u7684\u65b9\u6cd5\uff0c\u5c06\u795e\u7ecf\u6b8b\u5dee\u5d4c\u5165\u7269\u7406\u542f\u53d1\u7684\u7535\u6c60ODE\u4e2d\uff0c\u5229\u7528\u5408\u6210\u6570\u636e\u6a21\u62df\u7535\u6c60\u52a8\u6001\u3002", "result": "\u8bad\u7ec3\u540e\u7684UDE\u4e0e\u771f\u5b9e\u7535\u6c60\u8f68\u8ff9\u9ad8\u5ea6\u543b\u5408\uff0c\u6536\u655b\u5e73\u6ed1\uff0c\u957f\u671f\u9884\u6d4b\u7a33\u5b9a\u3002", "conclusion": "UDE\u65b9\u6cd5\u9002\u7528\u4e8e\u5206\u6563\u5f0f\u80fd\u6e90\u7f51\u7edc\u4e2d\u7684\u7535\u6c60\u5efa\u6a21\uff0c\u5bf9\u5b9e\u65f6\u63a7\u5236\u548c\u4f18\u5316\u6709\u5e7f\u6cdb\u610f\u4e49\u3002"}}
{"id": "2506.08274", "pdf": "https://arxiv.org/pdf/2506.08274", "abs": "https://arxiv.org/abs/2506.08274", "authors": ["Jo\u00e3o Manoel Herrera Pinheiro", "Suzana Vilas Boas de Oliveira", "Thiago Henrique Segreto Silva", "Pedro Antonio Rabelo Saraiva", "Enzo Ferreira de Souza", "Leonardo Andr\u00e9 Ambrosio", "Marcelo Becker"], "title": "The Impact of Feature Scaling In Machine Learning: Effects on Regression and Classification Tasks", "categories": ["cs.LG", "stat.ML"], "comment": "27 pages", "summary": "This research addresses the critical lack of comprehensive studies on feature\nscaling by systematically evaluating 12 scaling techniques - including several\nless common transformations - across 14 different Machine Learning algorithms\nand 16 datasets for classification and regression tasks. We meticulously\nanalyzed impacts on predictive performance (using metrics such as accuracy,\nMAE, MSE, and $R^2$) and computational costs (training time, inference time,\nand memory usage). Key findings reveal that while ensemble methods (such as\nRandom Forest and gradient boosting models like XGBoost, CatBoost and LightGBM)\ndemonstrate robust performance largely independent of scaling, other widely\nused models such as Logistic Regression, SVMs, TabNet, and MLPs show\nsignificant performance variations highly dependent on the chosen scaler. This\nextensive empirical analysis, with all source code, experimental results, and\nmodel parameters made publicly available to ensure complete transparency and\nreproducibility, offers model-specific crucial guidance to practitioners on the\nneed for an optimal selection of feature scaling techniques.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e8612\u79cd\u7279\u5f81\u7f29\u653e\u6280\u672f\u5bf914\u79cd\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u548c16\u4e2a\u6570\u636e\u96c6\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u96c6\u6210\u65b9\u6cd5\u5bf9\u7f29\u653e\u4e0d\u654f\u611f\uff0c\u800c\u5176\u4ed6\u6a21\u578b\u5982\u903b\u8f91\u56de\u5f52\u3001SVM\u7b49\u6027\u80fd\u663e\u8457\u4f9d\u8d56\u7f29\u653e\u9009\u62e9\u3002", "motivation": "\u89e3\u51b3\u7279\u5f81\u7f29\u653e\u9886\u57df\u7f3a\u4e4f\u5168\u9762\u7814\u7a76\u7684\u95ee\u9898\uff0c\u4e3a\u5b9e\u8df5\u8005\u63d0\u4f9b\u6a21\u578b\u7279\u5b9a\u7684\u7f29\u653e\u6280\u672f\u9009\u62e9\u6307\u5bfc\u3002", "method": "\u4f7f\u752812\u79cd\u7f29\u653e\u6280\u672f\uff0c\u8bc4\u4f3014\u79cd\u7b97\u6cd5\u572816\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u9884\u6d4b\u6027\u80fd\u548c\u8ba1\u7b97\u6210\u672c\u3002", "result": "\u96c6\u6210\u65b9\u6cd5\u5bf9\u7f29\u653e\u4e0d\u654f\u611f\uff0c\u5176\u4ed6\u6a21\u578b\u6027\u80fd\u663e\u8457\u4f9d\u8d56\u7f29\u653e\u9009\u62e9\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u6a21\u578b\u7279\u5b9a\u7684\u7279\u5f81\u7f29\u653e\u9009\u62e9\u6307\u5bfc\uff0c\u5e76\u516c\u5f00\u4e86\u6240\u6709\u4ee3\u7801\u548c\u7ed3\u679c\u4ee5\u786e\u4fdd\u900f\u660e\u6027\u548c\u53ef\u91cd\u590d\u6027\u3002"}}
{"id": "2506.08292", "pdf": "https://arxiv.org/pdf/2506.08292", "abs": "https://arxiv.org/abs/2506.08292", "authors": ["Xie Yi", "Zhanke Zhou", "Chentao Cao", "Qiyu Niu", "Tongliang Liu", "Bo Han"], "title": "From Debate to Equilibrium: Belief-Driven Multi-Agent LLM Reasoning via Bayesian Nash Equilibrium", "categories": ["cs.LG", "cs.CL"], "comment": "Accepted by ICML 2025", "summary": "Multi-agent frameworks can substantially boost the reasoning power of large\nlanguage models (LLMs), but they typically incur heavy computational costs and\nlack convergence guarantees. To overcome these challenges, we recast multi-LLM\ncoordination as an incomplete-information game and seek a Bayesian Nash\nequilibrium (BNE), in which each agent optimally responds to its probabilistic\nbeliefs about the strategies of others. We introduce Efficient Coordination via\nNash Equilibrium (ECON), a hierarchical reinforcement-learning paradigm that\nmarries distributed reasoning with centralized final output. Under ECON, each\nLLM independently selects responses that maximize its expected reward,\nconditioned on its beliefs about co-agents, without requiring costly\ninter-agent exchanges. We mathematically prove that ECON attains a markedly\ntighter regret bound than non-equilibrium multi-agent schemes. Empirically,\nECON outperforms existing multi-LLM approaches by 11.2% on average across six\nbenchmarks spanning complex reasoning and planning tasks. Further experiments\ndemonstrate ECON's ability to flexibly incorporate additional models,\nconfirming its scalability and paving the way toward larger, more powerful\nmulti-LLM ensembles. The code is publicly available at:\nhttps://github.com/tmlr-group/ECON.", "AI": {"tldr": "ECON\u662f\u4e00\u79cd\u57fa\u4e8e\u8d1d\u53f6\u65af\u7eb3\u4ec0\u5747\u8861\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u63d0\u5347LLM\u7684\u63a8\u7406\u80fd\u529b\uff0c\u51cf\u5c11\u8ba1\u7b97\u6210\u672c\u5e76\u4fdd\u8bc1\u6536\u655b\u6027\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u6846\u67b6\u867d\u80fd\u589e\u5f3aLLM\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5b58\u5728\u8ba1\u7b97\u6210\u672c\u9ad8\u548c\u7f3a\u4e4f\u6536\u655b\u4fdd\u8bc1\u7684\u95ee\u9898\u3002", "method": "\u5c06\u591aLLM\u534f\u8c03\u5efa\u6a21\u4e3a\u4e0d\u5b8c\u5168\u4fe1\u606f\u535a\u5f08\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u7eb3\u4ec0\u5747\u8861\u5b9e\u73b0\u5206\u5e03\u5f0f\u63a8\u7406\u4e0e\u96c6\u4e2d\u8f93\u51fa\u7684\u7ed3\u5408\u3002", "result": "ECON\u5728\u516d\u4e2a\u590d\u6742\u63a8\u7406\u548c\u89c4\u5212\u4efb\u52a1\u4e0a\u5e73\u5747\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd511.2%\uff0c\u4e14\u5177\u6709\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "ECON\u4e3a\u66f4\u5f3a\u5927\u3001\u53ef\u6269\u5c55\u7684\u591aLLM\u96c6\u6210\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2506.08295", "pdf": "https://arxiv.org/pdf/2506.08295", "abs": "https://arxiv.org/abs/2506.08295", "authors": ["Zhanke Zhou", "Xiao Feng", "Zhaocheng Zhu", "Jiangchao Yao", "Sanmi Koyejo", "Bo Han"], "title": "From Passive to Active Reasoning: Can Large Language Models Ask the Right Questions under Incomplete Information?", "categories": ["cs.LG", "cs.CL"], "comment": "Accepted by ICML 2025", "summary": "While existing benchmarks probe the reasoning abilities of large language\nmodels (LLMs) across diverse domains, they predominantly assess passive\nreasoning, providing models with all the information needed to reach a\nsolution. By contrast, active reasoning-where an LLM must interact with\nexternal systems to acquire missing evidence or data-has received little\nsystematic attention. To address this shortfall, we present AR-Bench, a novel\nbenchmark designed explicitly to evaluate an LLM's active reasoning skills.\nAR-Bench comprises three task families-detective cases, situation puzzles, and\nguessing numbers-that together simulate real-world, agentic scenarios and\nmeasure performance across commonsense, logical, and symbolic reasoning\nchallenges. Empirical evaluation on AR-Bench demonstrates that contemporary\nLLMs exhibit pronounced difficulties with active reasoning: they frequently\nfail to acquire or leverage the information needed to solve tasks. This gap\nhighlights a stark divergence between their passive and active reasoning\nabilities. Moreover, ablation studies indicate that even advanced strategies,\nsuch as tree-based searching or post-training approaches, yield only modest\ngains and fall short of the levels required for real-world deployment.\nCollectively, these findings highlight the critical need to advance methodology\nfor active reasoning, e.g., incorporating interactive learning, real-time\nfeedback loops, and environment-aware objectives for training. The benchmark is\npublicly available at: https://github.com/tmlr-group/AR-Bench.", "AI": {"tldr": "AR-Bench\u662f\u4e00\u4e2a\u65b0\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u4e3b\u52a8\u63a8\u7406\u80fd\u529b\uff0c\u53d1\u73b0\u5f53\u524d\u6a21\u578b\u5728\u6b64\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u4e3b\u8981\u8bc4\u4f30\u88ab\u52a8\u63a8\u7406\uff0c\u7f3a\u4e4f\u5bf9\u4e3b\u52a8\u63a8\u7406\uff08\u9700\u4e0e\u5916\u90e8\u7cfb\u7edf\u4ea4\u4e92\uff09\u7684\u7cfb\u7edf\u6027\u7814\u7a76\u3002", "method": "\u8bbe\u8ba1\u4e86AR-Bench\uff0c\u5305\u542b\u4e09\u7c7b\u4efb\u52a1\uff08\u4fa6\u63a2\u6848\u4f8b\u3001\u60c5\u5883\u8c1c\u9898\u3001\u731c\u6570\u5b57\uff09\uff0c\u6a21\u62df\u73b0\u5b9e\u573a\u666f\u5e76\u6d4b\u8bd5\u5e38\u8bc6\u3001\u903b\u8f91\u548c\u7b26\u53f7\u63a8\u7406\u80fd\u529b\u3002", "result": "\u5f53\u4ee3LLM\u5728\u4e3b\u52a8\u63a8\u7406\u4e0a\u8868\u73b0\u8f83\u5dee\uff0c\u96be\u4ee5\u83b7\u53d6\u6216\u5229\u7528\u6240\u9700\u4fe1\u606f\uff0c\u4e14\u73b0\u6709\u7b56\u7565\u6539\u8fdb\u6709\u9650\u3002", "conclusion": "\u9700\u53d1\u5c55\u65b0\u65b9\u6cd5\uff08\u5982\u4ea4\u4e92\u5b66\u4e60\u3001\u5b9e\u65f6\u53cd\u9988\uff09\u4ee5\u63d0\u5347\u4e3b\u52a8\u63a8\u7406\u80fd\u529b\uff0cAR-Bench\u5df2\u516c\u5f00\u3002"}}
{"id": "2506.08298", "pdf": "https://arxiv.org/pdf/2506.08298", "abs": "https://arxiv.org/abs/2506.08298", "authors": ["Trung-Kien Nguyen", "Heng Ping", "Shixuan Li", "Peiyu Zhang", "Nikos Kanakaris", "Nicholas Kotov", "Paul Bogdan"], "title": "H$^2$GFM: Towards unifying Homogeneity and Heterogeneity on Text-Attributed Graphs", "categories": ["cs.LG"], "comment": null, "summary": "The growing interests and applications of graph learning in diverse domains\nhave propelled the development of a unified model generalizing well across\ndifferent graphs and tasks, known as the Graph Foundation Model (GFM). Existing\nresearch has leveraged text-attributed graphs (TAGs) to tackle the\nheterogeneity in node features among graphs. However, they primarily focus on\nhomogeneous TAGs (HoTAGs), leaving heterogeneous TAGs (HeTAGs), where multiple\ntypes of nodes/edges reside, underexplored. To enhance the capabilities and\napplications of GFM, we introduce H$^2$GFM, a novel framework designed to\ngeneralize across both HoTAGs and HeTAGs. Our model projects diverse\nmeta-relations among graphs under a unified textual space, and employs a\ncontext encoding to capture spatial and higher-order semantic relationships. To\nachieve robust node representations, we propose a novel context-adaptive graph\ntransformer (CGT), effectively capturing information from both context\nneighbors and their relationships. Furthermore, we employ a mixture of CGT\nexperts to capture the heterogeneity in structural patterns among graph types.\nComprehensive experiments on a wide range of HoTAGs and HeTAGs as well as\nlearning scenarios demonstrate the effectiveness of our model.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aH$^2$GFM\u7684\u65b0\u6846\u67b6\uff0c\u65e8\u5728\u7edf\u4e00\u5904\u7406\u540c\u8d28\u548c\u5f02\u8d28\u6587\u672c\u5c5e\u6027\u56fe\uff08TAGs\uff09\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u7f16\u7801\u548c\u81ea\u9002\u5e94\u56fe\u53d8\u6362\u5668\uff08CGT\uff09\u63d0\u5347\u56fe\u57fa\u7840\u6a21\u578b\uff08GFM\uff09\u7684\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u540c\u8d28\u6587\u672c\u5c5e\u6027\u56fe\uff08HoTAGs\uff09\uff0c\u800c\u5ffd\u7565\u4e86\u5f02\u8d28\u6587\u672c\u5c5e\u6027\u56fe\uff08HeTAGs\uff09\u3002\u4e3a\u4e86\u6269\u5c55GFM\u7684\u5e94\u7528\u8303\u56f4\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u540c\u65f6\u5904\u7406\u8fd9\u4e24\u79cd\u56fe\u7684\u7edf\u4e00\u6a21\u578b\u3002", "method": "H$^2$GFM\u6846\u67b6\u901a\u8fc7\u7edf\u4e00\u6587\u672c\u7a7a\u95f4\u6295\u5f71\u591a\u6837\u5143\u5173\u7cfb\uff0c\u5e76\u5229\u7528\u4e0a\u4e0b\u6587\u7f16\u7801\u6355\u6349\u7a7a\u95f4\u548c\u9ad8\u9636\u8bed\u4e49\u5173\u7cfb\u3002\u63d0\u51fa\u4e0a\u4e0b\u6587\u81ea\u9002\u5e94\u56fe\u53d8\u6362\u5668\uff08CGT\uff09\u548c\u6df7\u5408\u4e13\u5bb6\u673a\u5236\uff0c\u4ee5\u5904\u7406\u56fe\u7c7b\u578b\u7684\u7ed3\u6784\u5f02\u8d28\u6027\u3002", "result": "\u5728\u591a\u79cdHoTAGs\u548cHeTAGs\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6a21\u578b\u7684\u6709\u6548\u6027\u3002", "conclusion": "H$^2$GFM\u4e3a\u56fe\u57fa\u7840\u6a21\u578b\u63d0\u4f9b\u4e86\u66f4\u5e7f\u6cdb\u7684\u9002\u7528\u6027\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u5f02\u8d28\u6587\u672c\u5c5e\u6027\u56fe\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2506.08309", "pdf": "https://arxiv.org/pdf/2506.08309", "abs": "https://arxiv.org/abs/2506.08309", "authors": ["Katherine Tieu", "Dongqi Fu", "Zihao Li", "Ross Maciejewski", "Jingrui He"], "title": "Learnable Spatial-Temporal Positional Encoding for Link Prediction", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by ICML 2025. 28 pages, 1 figures, 22 tables", "summary": "Accurate predictions rely on the expressiveness power of graph deep learning\nframeworks like graph neural networks and graph transformers, where a\npositional encoding mechanism has become much more indispensable in recent\nstate-of-the-art works to record the canonical position information. However,\nthe current positional encoding is limited in three aspects: (1) most\npositional encoding methods use pre-defined, and fixed functions, which are\ninadequate to adapt to the complex attributed graphs; (2) a few pioneering\nworks proposed the learnable positional encoding but are still limited to the\nstructural information, not considering the real-world time-evolving\ntopological and feature information; (3) most positional encoding methods are\nequipped with transformers' attention mechanism to fully leverage their\ncapabilities, where the dense or relational attention is often unaffordable on\nlarge-scale structured data. Hence, we aim to develop Learnable\nSpatial-Temporal Positional Encoding in an effective and efficient manner and\npropose a simple temporal link prediction model named L-STEP. Briefly, for\nL-STEP, we (1) prove the proposed positional learning scheme can preserve the\ngraph property from the spatial-temporal spectral viewpoint, (2) verify that\nMLPs can fully exploit the expressiveness and reach transformers' performance\non that encoding, (3) change different initial positional encoding inputs to\nshow robustness, (4) analyze the theoretical complexity and obtain less\nempirical running time than SOTA, and (5) demonstrate its temporal link\nprediction out-performance on 13 classic datasets and with 10 algorithms in\nboth transductive and inductive settings using 3 different sampling strategies.\nAlso, \\name\\ obtains the leading performance in the newest large-scale TGB\nbenchmark. Our code is available at https://github.com/kthrn22/L-STEP.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u5b66\u4e60\u7684\u65f6\u7a7a\u4f4d\u7f6e\u7f16\u7801\u65b9\u6cd5L-STEP\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u4f4d\u7f6e\u7f16\u7801\u5728\u9002\u5e94\u6027\u3001\u52a8\u6001\u6027\u548c\u6548\u7387\u4e0a\u7684\u4e0d\u8db3\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u73b0\u6709\u4f4d\u7f6e\u7f16\u7801\u65b9\u6cd5\u5728\u9002\u5e94\u590d\u6742\u5c5e\u6027\u56fe\u3001\u52a8\u6001\u62d3\u6251\u548c\u7279\u5f81\u4fe1\u606f\u4ee5\u53ca\u5927\u89c4\u6a21\u6570\u636e\u6548\u7387\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u7075\u6d3b\u548c\u9ad8\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faL-STEP\u6a21\u578b\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u65f6\u7a7a\u4f4d\u7f6e\u7f16\u7801\u65b9\u6848\uff0c\u7ed3\u5408MLPs\u5b9e\u73b0\u9ad8\u6548\u8868\u8fbe\uff0c\u5e76\u572813\u4e2a\u7ecf\u5178\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u5176\u6027\u80fd\u3002", "result": "L-STEP\u5728\u65f6\u7a7a\u94fe\u63a5\u9884\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u7406\u8bba\u590d\u6742\u5ea6\u548c\u5b9e\u9645\u8fd0\u884c\u65f6\u95f4\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5728TGB\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9886\u5148\u3002", "conclusion": "L-STEP\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u7075\u6d3b\u7684\u4f4d\u7f6e\u7f16\u7801\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u52a8\u6001\u56fe\u6570\u636e\uff0c\u5e76\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u5c55\u73b0\u4e86\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2506.08312", "pdf": "https://arxiv.org/pdf/2506.08312", "abs": "https://arxiv.org/abs/2506.08312", "authors": ["Tom\u00e1s Gonz\u00e1lez", "Giulia Fanti", "Aaditya Ramdas"], "title": "Private Evolution Converges", "categories": ["cs.LG", "cs.CR", "cs.DS", "math.PR", "math.ST", "stat.TH", "68P27 (Primary) 68Q32, 68Q87, 60B10 (Secondary)"], "comment": null, "summary": "Private Evolution (PE) is a promising training-free method for differentially\nprivate (DP) synthetic data generation. While it achieves strong performance in\nsome domains (e.g., images and text), its behavior in others (e.g., tabular\ndata) is less consistent. To date, the only theoretical analysis of the\nconvergence of PE depends on unrealistic assumptions about both the algorithm's\nbehavior and the structure of the sensitive dataset. In this work, we develop a\nnew theoretical framework to explain PE's practical behavior and identify\nsufficient conditions for its convergence. For $d$-dimensional sensitive\ndatasets with $n$ data points from a bounded domain, we prove that PE produces\nan $(\\epsilon, \\delta)$-DP synthetic dataset with expected 1-Wasserstein\ndistance of order $\\tilde{O}(d(n\\epsilon)^{-1/d})$ from the original,\nestablishing worst-case convergence of the algorithm as $n \\to \\infty$. Our\nanalysis extends to general Banach spaces as well. We also connect PE to the\nPrivate Signed Measure Mechanism, a method for DP synthetic data generation\nthat has thus far not seen much practical adoption. We demonstrate the\npractical relevance of our theoretical findings in simulations.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.08316", "pdf": "https://arxiv.org/pdf/2506.08316", "abs": "https://arxiv.org/abs/2506.08316", "authors": ["Alan N. Amin", "Nate Gruver", "Andrew Gordon Wilson"], "title": "Why Masking Diffusion Works: Condition on the Jump Schedule for Improved Discrete Diffusion", "categories": ["cs.LG", "stat.ML"], "comment": "Code available at: https://github.com/AlanNawzadAmin/SCUD", "summary": "Discrete diffusion models, like continuous diffusion models, generate\nhigh-quality samples by gradually undoing noise applied to datapoints with a\nMarkov process. Gradual generation in theory comes with many conceptual\nbenefits; for example, inductive biases can be incorporated into the noising\nMarkov process, and access to improved sampling algorithms. In practice,\nhowever, the consistently best performing discrete diffusion model is,\nsurprisingly, masking diffusion, which does not denoise gradually. Here we\nexplain the superior performance of masking diffusion by noting that it makes\nuse of a fundamental difference between continuous and discrete Markov\nprocesses: discrete Markov processes evolve by discontinuous jumps at a fixed\nrate and, unlike other discrete diffusion models, masking diffusion builds in\nthe known distribution of jump times and only learns where to jump to. We show\nthat we can similarly bake in the known distribution of jump times into any\ndiscrete diffusion model. The resulting models - schedule-conditioned discrete\ndiffusion (SCUD) - generalize classical discrete diffusion and masking\ndiffusion. By applying SCUD to models with noising processes that incorporate\ninductive biases on images, text, and protein data, we build models that\noutperform masking.", "AI": {"tldr": "\u79bb\u6563\u6269\u6563\u6a21\u578b\u901a\u5e38\u901a\u8fc7\u9010\u6b65\u53bb\u566a\u751f\u6210\u9ad8\u8d28\u91cf\u6837\u672c\uff0c\u4f46\u5b9e\u8df5\u4e2d\u8868\u73b0\u6700\u597d\u7684\u662f\u63a9\u7801\u6269\u6563\u6a21\u578b\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u63a9\u7801\u6269\u6563\u5229\u7528\u4e86\u79bb\u6563\u9a6c\u5c14\u53ef\u592b\u8fc7\u7a0b\u7684\u8df3\u8dc3\u7279\u6027\uff0c\u901a\u8fc7\u56fa\u5b9a\u8df3\u8dc3\u65f6\u95f4\u5206\u5e03\u63d0\u5347\u6027\u80fd\u3002\u57fa\u4e8e\u6b64\uff0c\u63d0\u51fa\u4e86SCUD\u6a21\u578b\uff0c\u8fdb\u4e00\u6b65\u4f18\u5316\u4e86\u79bb\u6563\u6269\u6563\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u7814\u7a76\u79bb\u6563\u6269\u6563\u6a21\u578b\u6027\u80fd\u5dee\u5f02\u7684\u539f\u56e0\uff0c\u5c24\u5176\u662f\u63a9\u7801\u6269\u6563\u6a21\u578b\u8868\u73b0\u4f18\u5f02\u7684\u539f\u56e0\u3002", "method": "\u63d0\u51faSCUD\u6a21\u578b\uff0c\u5c06\u5df2\u77e5\u8df3\u8dc3\u65f6\u95f4\u5206\u5e03\u878d\u5165\u79bb\u6563\u6269\u6563\u6a21\u578b\uff0c\u5e76\u5728\u56fe\u50cf\u3001\u6587\u672c\u548c\u86cb\u767d\u8d28\u6570\u636e\u4e0a\u9a8c\u8bc1\u5176\u6027\u80fd\u3002", "result": "SCUD\u6a21\u578b\u5728\u591a\u79cd\u6570\u636e\u4e0a\u8868\u73b0\u4f18\u4e8e\u63a9\u7801\u6269\u6563\u6a21\u578b\u3002", "conclusion": "\u901a\u8fc7\u5229\u7528\u79bb\u6563\u9a6c\u5c14\u53ef\u592b\u8fc7\u7a0b\u7684\u8df3\u8dc3\u7279\u6027\uff0cSCUD\u6a21\u578b\u663e\u8457\u63d0\u5347\u4e86\u79bb\u6563\u6269\u6563\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2506.08326", "pdf": "https://arxiv.org/pdf/2506.08326", "abs": "https://arxiv.org/abs/2506.08326", "authors": ["Xingbo Fu", "Zehong Wang", "Zihan Chen", "Jiazheng Li", "Yaochen Zhu", "Zhenyu Lei", "Cong Shen", "Yanfang Ye", "Chuxu Zhang", "Jundong Li"], "title": "Graph Prompting for Graph Learning Models: Recent Advances and Future Directions", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by KDD 2025 Tutorial/Survey Track", "summary": "Graph learning models have demonstrated great prowess in learning expressive\nrepresentations from large-scale graph data in a wide variety of real-world\nscenarios. As a prevalent strategy for training powerful graph learning models,\nthe \"pre-training, adaptation\" scheme first pre-trains graph learning models on\nunlabeled graph data in a self-supervised manner and then adapts them to\nspecific downstream tasks. During the adaptation phase, graph prompting emerges\nas a promising approach that learns trainable prompts while keeping the\npre-trained graph learning models unchanged. In this paper, we present a\nsystematic review of recent advancements in graph prompting. First, we\nintroduce representative graph pre-training methods that serve as the\nfoundation step of graph prompting. Next, we review mainstream techniques in\ngraph prompting and elaborate on how they design learnable prompts for graph\nprompting. Furthermore, we summarize the real-world applications of graph\nprompting from different domains. Finally, we discuss several open challenges\nin existing studies with promising future directions in this field.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7efc\u8ff0\u4e86\u56fe\u63d0\u793a\uff08graph prompting\uff09\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u5305\u62ec\u56fe\u9884\u8bad\u7ec3\u65b9\u6cd5\u3001\u4e3b\u6d41\u56fe\u63d0\u793a\u6280\u672f\u53ca\u5176\u5e94\u7528\uff0c\u5e76\u8ba8\u8bba\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u56fe\u5b66\u4e60\u6a21\u578b\u5728\u591a\u79cd\u73b0\u5b9e\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u800c\u56fe\u63d0\u793a\u4f5c\u4e3a\u4e00\u79cd\u65b0\u5174\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u9884\u8bad\u7ec3\u6a21\u578b\u4e0d\u53d8\u7684\u60c5\u51b5\u4e0b\u901a\u8fc7\u53ef\u5b66\u4e60\u63d0\u793a\u9002\u5e94\u4e0b\u6e38\u4efb\u52a1\uff0c\u5177\u6709\u91cd\u8981\u7814\u7a76\u4ef7\u503c\u3002", "method": "\u4ecb\u7ecd\u4e86\u56fe\u9884\u8bad\u7ec3\u65b9\u6cd5\u4f5c\u4e3a\u57fa\u7840\uff0c\u5e76\u8be6\u7ec6\u9610\u8ff0\u4e86\u4e3b\u6d41\u56fe\u63d0\u793a\u6280\u672f\u5982\u4f55\u8bbe\u8ba1\u53ef\u5b66\u4e60\u63d0\u793a\u3002", "result": "\u603b\u7ed3\u4e86\u56fe\u63d0\u793a\u5728\u4e0d\u540c\u9886\u57df\u7684\u5b9e\u9645\u5e94\u7528\u3002", "conclusion": "\u8ba8\u8bba\u4e86\u73b0\u6709\u7814\u7a76\u7684\u5f00\u653e\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2506.08337", "pdf": "https://arxiv.org/pdf/2506.08337", "abs": "https://arxiv.org/abs/2506.08337", "authors": ["Juhyeok Choi", "Chenglin Fan"], "title": "A Simple Analysis of Discretization Error in Diffusion Models", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Diffusion models, formulated as discretizations of stochastic differential\nequations (SDEs), achieve state-of-the-art generative performance. However,\nexisting analyses of their discretization error often rely on complex\nprobabilistic tools. In this work, we present a simplified theoretical\nframework for analyzing the Euler--Maruyama discretization of\nvariance-preserving SDEs (VP-SDEs) in Denoising Diffusion Probabilistic Models\n(DDPMs), where $ T $ denotes the number of denoising steps in the diffusion\nprocess. Our approach leverages Gr\\\"onwall's inequality to derive a convergence\nrate of $ \\mathcal{O}(1/T^{1/2}) $ under Lipschitz assumptions, significantly\nstreamlining prior proofs. Furthermore, we demonstrate that the Gaussian noise\nin the discretization can be replaced by a discrete random variable (e.g.,\nRademacher or uniform noise) without sacrificing convergence guarantees-an\ninsight with practical implications for efficient sampling. Experiments\nvalidate our theory, showing that (1) the error scales as predicted, (2)\ndiscrete noise achieves comparable sample quality to Gaussian noise, and (3)\nincorrect noise scaling degrades performance. By unifying simplified analysis\nand discrete noise substitution, our work bridges theoretical rigor with\npractical efficiency in diffusion-based generative modeling.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5316\u7684\u7406\u8bba\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u6790DDPM\u4e2dVP-SDE\u7684Euler--Maruyama\u79bb\u6563\u5316\u8bef\u5dee\uff0c\u5e76\u8bc1\u660e\u4e86\u79bb\u6563\u566a\u58f0\u53ef\u4ee5\u66ff\u4ee3\u9ad8\u65af\u566a\u58f0\u800c\u4e0d\u5f71\u54cd\u6536\u655b\u6027\u3002", "motivation": "\u73b0\u6709\u6269\u6563\u6a21\u578b\u7684\u79bb\u6563\u5316\u8bef\u5dee\u5206\u6790\u901a\u5e38\u4f9d\u8d56\u590d\u6742\u7684\u6982\u7387\u5de5\u5177\uff0c\u672c\u6587\u65e8\u5728\u7b80\u5316\u8fd9\u4e00\u5206\u6790\u8fc7\u7a0b\u3002", "method": "\u5229\u7528Gr\u00f6nwall\u4e0d\u7b49\u5f0f\uff0c\u5728Lipschitz\u5047\u8bbe\u4e0b\u63a8\u5bfc\u51fa\u6536\u655b\u901f\u7387\u4e3a$\\mathcal{O}(1/T^{1/2})$\uff0c\u5e76\u9a8c\u8bc1\u79bb\u6563\u566a\u58f0\u7684\u53ef\u884c\u6027\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8bef\u5dee\u6309\u9884\u6d4b\u6bd4\u4f8b\u7f29\u653e\uff0c\u79bb\u6563\u566a\u58f0\u4e0e\u9ad8\u65af\u566a\u58f0\u6548\u679c\u76f8\u5f53\uff0c\u566a\u58f0\u7f29\u653e\u9519\u8bef\u4f1a\u964d\u4f4e\u6027\u80fd\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u7b80\u5316\u5206\u6790\u548c\u79bb\u6563\u566a\u58f0\u66ff\u4ee3\uff0c\u5728\u6269\u6563\u751f\u6210\u6a21\u578b\u4e2d\u5b9e\u73b0\u4e86\u7406\u8bba\u4e25\u8c28\u6027\u4e0e\u5b9e\u9645\u6548\u7387\u7684\u7edf\u4e00\u3002"}}
{"id": "2506.08340", "pdf": "https://arxiv.org/pdf/2506.08340", "abs": "https://arxiv.org/abs/2506.08340", "authors": ["Emo Todorov"], "title": "Dynamical System Optimization", "categories": ["cs.LG"], "comment": null, "summary": "We develop an optimization framework centered around a core idea: once a\n(parametric) policy is specified, control authority is transferred to the\npolicy, resulting in an autonomous dynamical system. Thus we should be able to\noptimize policy parameters without further reference to controls or actions,\nand without directly using the machinery of approximate Dynamic Programming and\nReinforcement Learning. Here we derive simpler algorithms at the autonomous\nsystem level, and show that they compute the same quantities as policy\ngradients and Hessians, natural gradients, proximal methods. Analogs to\napproximate policy iteration and off-policy learning are also available. Since\npolicy parameters and other system parameters are treated uniformly, the same\nalgorithms apply to behavioral cloning, mechanism design, system\nidentification, learning of state estimators. Tuning of generative AI models is\nnot only possible, but is conceptually closer to the present framework than to\nReinforcement Learning.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f18\u5316\u6846\u67b6\uff0c\u5c06\u63a7\u5236\u6743\u8f6c\u79fb\u7ed9\u53c2\u6570\u5316\u7b56\u7565\uff0c\u4ece\u800c\u5728\u81ea\u6cbb\u7cfb\u7edf\u5c42\u9762\u7b80\u5316\u7b97\u6cd5\uff0c\u5e76\u8bc1\u660e\u5176\u4e0e\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u7b49\u6548\u3002", "motivation": "\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u548c\u52a8\u6001\u89c4\u5212\u65b9\u6cd5\u590d\u6742\uff0c\u5e0c\u671b\u901a\u8fc7\u81ea\u6cbb\u7cfb\u7edf\u7684\u89c6\u89d2\u7b80\u5316\u4f18\u5316\u8fc7\u7a0b\u3002", "method": "\u5728\u81ea\u6cbb\u7cfb\u7edf\u5c42\u9762\u8bbe\u8ba1\u7b97\u6cd5\uff0c\u76f4\u63a5\u4f18\u5316\u7b56\u7565\u53c2\u6570\uff0c\u907f\u514d\u4f7f\u7528\u63a7\u5236\u548c\u52a8\u4f5c\u7684\u663e\u5f0f\u53c2\u8003\u3002", "result": "\u65b0\u7b97\u6cd5\u4e0e\u4f20\u7edf\u65b9\u6cd5\uff08\u5982\u7b56\u7565\u68af\u5ea6\u3001\u81ea\u7136\u68af\u5ea6\u7b49\uff09\u8ba1\u7b97\u7ed3\u679c\u4e00\u81f4\uff0c\u5e76\u9002\u7528\u4e8e\u591a\u79cd\u4efb\u52a1\uff08\u5982\u884c\u4e3a\u514b\u9686\u3001\u7cfb\u7edf\u8fa8\u8bc6\u7b49\uff09\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u751f\u6210\u5f0fAI\u6a21\u578b\u8c03\u4f18\u7b49\u4efb\u52a1\u63d0\u4f9b\u4e86\u66f4\u7b80\u6d01\u7684\u4f18\u5316\u89c6\u89d2\u3002"}}
{"id": "2506.08347", "pdf": "https://arxiv.org/pdf/2506.08347", "abs": "https://arxiv.org/abs/2506.08347", "authors": ["Yinan Huang", "Haoteng Ying", "Eli Chien", "Rongzhe Wei", "Pan Li"], "title": "Differentially Private Relational Learning with Entity-level Privacy Guarantees", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "Learning with relational and network-structured data is increasingly vital in\nsensitive domains where protecting the privacy of individual entities is\nparamount. Differential Privacy (DP) offers a principled approach for\nquantifying privacy risks, with DP-SGD emerging as a standard mechanism for\nprivate model training. However, directly applying DP-SGD to relational\nlearning is challenging due to two key factors: (i) entities often participate\nin multiple relations, resulting in high and difficult-to-control sensitivity;\nand (ii) relational learning typically involves multi-stage, potentially\ncoupled (interdependent) sampling procedures that make standard privacy\namplification analyses inapplicable. This work presents a principled framework\nfor relational learning with formal entity-level DP guarantees. We provide a\nrigorous sensitivity analysis and introduce an adaptive gradient clipping\nscheme that modulates clipping thresholds based on entity occurrence frequency.\nWe also extend the privacy amplification results to a tractable subclass of\ncoupled sampling, where the dependence arises only through sample sizes. These\ncontributions lead to a tailored DP-SGD variant for relational data with\nprovable privacy guarantees. Experiments on fine-tuning text encoders over\ntext-attributed network-structured relational data demonstrate the strong\nutility-privacy trade-offs of our approach. Our code is available at\nhttps://github.com/Graph-COM/Node_DP.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u5173\u7cfb\u6570\u636e\u7684\u5dee\u5206\u9690\u79c1\u5b66\u4e60\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u76f4\u63a5\u5e94\u7528DP-SGD\u7684\u6311\u6218\uff0c\u5305\u62ec\u5b9e\u4f53\u53c2\u4e0e\u591a\u5173\u7cfb\u5bfc\u81f4\u7684\u9ad8\u654f\u611f\u6027\u548c\u591a\u9636\u6bb5\u91c7\u6837\u95ee\u9898\u3002", "motivation": "\u5728\u654f\u611f\u9886\u57df\u4e2d\uff0c\u4fdd\u62a4\u4e2a\u4f53\u9690\u79c1\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u76f4\u63a5\u5e94\u7528\u4e8e\u5173\u7cfb\u6570\u636e\u5b66\u4e60\u3002", "method": "\u901a\u8fc7\u4e25\u683c\u7684\u654f\u611f\u6027\u5206\u6790\u548c\u81ea\u9002\u5e94\u68af\u5ea6\u88c1\u526a\u65b9\u6848\uff0c\u6269\u5c55\u4e86\u9690\u79c1\u653e\u5927\u7ed3\u679c\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u4e13\u4e3a\u5173\u7cfb\u6570\u636e\u8bbe\u8ba1\u7684DP-SGD\u53d8\u4f53\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6587\u672c\u5c5e\u6027\u7f51\u7edc\u5173\u7cfb\u6570\u636e\u4e0a\u5b9e\u73b0\u4e86\u826f\u597d\u7684\u9690\u79c1-\u6548\u7528\u6743\u8861\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5173\u7cfb\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u5b9e\u4f53\u7ea7\u5dee\u5206\u9690\u79c1\u4fdd\u8bc1\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2506.08353", "pdf": "https://arxiv.org/pdf/2506.08353", "abs": "https://arxiv.org/abs/2506.08353", "authors": ["Hyunseok Seung", "Jaewoo Lee", "Hyunsuk Ko"], "title": "An Adaptive Method Stabilizing Activations for Enhanced Generalization", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "We introduce AdaAct, a novel optimization algorithm that adjusts learning\nrates according to activation variance. Our method enhances the stability of\nneuron outputs by incorporating neuron-wise adaptivity during the training\nprocess, which subsequently leads to better generalization -- a complementary\napproach to conventional activation regularization methods. Experimental\nresults demonstrate AdaAct's competitive performance across standard image\nclassification benchmarks. We evaluate AdaAct on CIFAR and ImageNet, comparing\nit with other state-of-the-art methods. Importantly, AdaAct effectively bridges\nthe gap between the convergence speed of Adam and the strong generalization\ncapabilities of SGD, all while maintaining competitive execution times. Code is\navailable at https://github.com/hseung88/adaact.", "AI": {"tldr": "AdaAct\u662f\u4e00\u79cd\u65b0\u9896\u7684\u4f18\u5316\u7b97\u6cd5\uff0c\u901a\u8fc7\u6839\u636e\u6fc0\u6d3b\u65b9\u5dee\u8c03\u6574\u5b66\u4e60\u7387\uff0c\u63d0\u5347\u795e\u7ecf\u5143\u8f93\u51fa\u7684\u7a33\u5b9a\u6027\uff0c\u4ece\u800c\u6539\u5584\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u6fc0\u6d3b\u6b63\u5219\u5316\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0cAdaAct\u901a\u8fc7\u795e\u7ecf\u5143\u7ea7\u81ea\u9002\u5e94\u586b\u8865\u4e86\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "AdaAct\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u52a8\u6001\u8c03\u6574\u5b66\u4e60\u7387\uff0c\u7ed3\u5408\u795e\u7ecf\u5143\u7ea7\u81ea\u9002\u5e94\uff0c\u4f18\u5316\u6fc0\u6d3b\u65b9\u5dee\u3002", "result": "\u5728CIFAR\u548cImageNet\u7b49\u6807\u51c6\u56fe\u50cf\u5206\u7c7b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAdaAct\u8868\u73b0\u51fa\u8272\uff0c\u517c\u5177Adam\u7684\u5feb\u901f\u6536\u655b\u548cSGD\u7684\u5f3a\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "AdaAct\u5728\u4fdd\u6301\u9ad8\u6548\u6267\u884c\u7684\u540c\u65f6\uff0c\u6709\u6548\u5e73\u8861\u4e86\u6536\u655b\u901f\u5ea6\u548c\u6cdb\u5316\u6027\u80fd\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2506.08360", "pdf": "https://arxiv.org/pdf/2506.08360", "abs": "https://arxiv.org/abs/2506.08360", "authors": ["Hyunseok Seung", "Jaewoo Lee", "Hyunsuk Ko"], "title": "NysAct: A Scalable Preconditioned Gradient Descent using Nystrom Approximation", "categories": ["cs.LG"], "comment": null, "summary": "Adaptive gradient methods are computationally efficient and converge quickly,\nbut they often suffer from poor generalization. In contrast, second-order\nmethods enhance convergence and generalization but typically incur high\ncomputational and memory costs. In this work, we introduce NysAct, a scalable\nfirst-order gradient preconditioning method that strikes a balance between\nstate-of-the-art first-order and second-order optimization methods. NysAct\nleverages an eigenvalue-shifted Nystrom method to approximate the activation\ncovariance matrix, which is used as a preconditioning matrix, significantly\nreducing time and memory complexities with minimal impact on test accuracy. Our\nexperiments show that NysAct not only achieves improved test accuracy compared\nto both first-order and second-order methods but also demands considerably less\ncomputational resources than existing second-order methods. Code is available\nat https://github.com/hseung88/nysact.", "AI": {"tldr": "NysAct\u662f\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u4e00\u9636\u68af\u5ea6\u9884\u5904\u7406\u65b9\u6cd5\uff0c\u5e73\u8861\u4e86\u4e00\u9636\u548c\u4e8c\u9636\u4f18\u5316\u65b9\u6cd5\u7684\u4f18\u52bf\uff0c\u901a\u8fc7\u7279\u5f81\u503c\u504f\u79fb\u7684Nystrom\u65b9\u6cd5\u8fd1\u4f3c\u6fc0\u6d3b\u534f\u65b9\u5dee\u77e9\u9635\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u65f6\u95f4\u548c\u5185\u5b58\u590d\u6742\u5ea6\u3002", "motivation": "\u81ea\u9002\u5e94\u68af\u5ea6\u65b9\u6cd5\u8ba1\u7b97\u9ad8\u6548\u4f46\u6cdb\u5316\u80fd\u529b\u5dee\uff0c\u4e8c\u9636\u65b9\u6cd5\u6cdb\u5316\u80fd\u529b\u5f3a\u4f46\u8ba1\u7b97\u548c\u5185\u5b58\u6210\u672c\u9ad8\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u5e73\u8861\u4e24\u8005\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u7279\u5f81\u503c\u504f\u79fb\u7684Nystrom\u65b9\u6cd5\u8fd1\u4f3c\u6fc0\u6d3b\u534f\u65b9\u5dee\u77e9\u9635\u4f5c\u4e3a\u9884\u5904\u7406\u77e9\u9635\u3002", "result": "NysAct\u5728\u6d4b\u8bd5\u7cbe\u5ea6\u4e0a\u4f18\u4e8e\u4e00\u9636\u548c\u4e8c\u9636\u65b9\u6cd5\uff0c\u540c\u65f6\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u663e\u8457\u4f4e\u4e8e\u4e8c\u9636\u65b9\u6cd5\u3002", "conclusion": "NysAct\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u6cdb\u5316\u80fd\u529b\u5f3a\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u4efb\u52a1\u3002"}}
{"id": "2506.08365", "pdf": "https://arxiv.org/pdf/2506.08365", "abs": "https://arxiv.org/abs/2506.08365", "authors": ["Cheng Tan", "Zhenxiao Cao", "Zhangyang Gao", "Siyuan Li", "Yufei Huang", "Stan Z. Li"], "title": "AlphaFold Database Debiasing for Robust Inverse Folding", "categories": ["cs.LG", "q-bio.BM"], "comment": "Under review", "summary": "The AlphaFold Protein Structure Database (AFDB) offers unparalleled\nstructural coverage at near-experimental accuracy, positioning it as a valuable\nresource for data-driven protein design. However, its direct use in training\ndeep models that are sensitive to fine-grained atomic geometry, such as inverse\nfolding, exposes a critical limitation. Comparative analysis of structural\nfeature distributions reveals that AFDB structures exhibit distinct statistical\nregularities, reflecting a systematic geometric bias that deviates from the\nconformational diversity found in experimentally determined structures from the\nProtein Data Bank (PDB). While AFDB structures are cleaner and more idealized,\nPDB structures capture the intrinsic variability and physical realism essential\nfor generalization in downstream tasks. To address this discrepancy, we\nintroduce a Debiasing Structure AutoEncoder (DeSAE) that learns to reconstruct\nnative-like conformations from intentionally corrupted backbone geometries. By\ntraining the model to recover plausible structural states, DeSAE implicitly\ncaptures a more robust and natural structural manifold. At inference, applying\nDeSAE to AFDB structures produces debiased structures that significantly\nimprove inverse folding performance across multiple benchmarks. This work\nhighlights the critical impact of subtle systematic biases in predicted\nstructures and presents a principled framework for debiasing, significantly\nboosting the performance of structure-based learning tasks like inverse\nfolding.", "AI": {"tldr": "AlphaFold\u6570\u636e\u5e93\uff08AFDB\uff09\u867d\u63d0\u4f9b\u9ad8\u7cbe\u5ea6\u86cb\u767d\u7ed3\u6784\uff0c\u4f46\u5176\u51e0\u4f55\u504f\u5dee\u9650\u5236\u4e86\u5728\u9006\u5411\u6298\u53e0\u7b49\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002\u4f5c\u8005\u63d0\u51faDeSAE\u6a21\u578b\uff0c\u901a\u8fc7\u53bb\u504f\u65b9\u6cd5\u63d0\u5347\u7ed3\u6784\u8d28\u91cf\uff0c\u663e\u8457\u6539\u5584\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "AFDB\u7684\u7ed3\u6784\u5b58\u5728\u7cfb\u7edf\u6027\u51e0\u4f55\u504f\u5dee\uff0c\u4e0e\u5b9e\u9a8c\u6570\u636e\uff08PDB\uff09\u7684\u6784\u8c61\u591a\u6837\u6027\u4e0d\u7b26\uff0c\u5f71\u54cd\u6a21\u578b\u5728\u7cbe\u7ec6\u539f\u5b50\u51e0\u4f55\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u63d0\u51faDeSAE\uff08\u53bb\u504f\u7ed3\u6784\u81ea\u7f16\u7801\u5668\uff09\uff0c\u901a\u8fc7\u4ece\u6545\u610f\u635f\u574f\u7684\u4e3b\u94fe\u51e0\u4f55\u4e2d\u91cd\u5efa\u81ea\u7136\u6784\u8c61\uff0c\u5b66\u4e60\u66f4\u7a33\u5065\u7684\u7ed3\u6784\u6d41\u5f62\u3002", "result": "DeSAE\u5904\u7406\u540e\u7684AFDB\u7ed3\u6784\u663e\u8457\u63d0\u5347\u4e86\u9006\u5411\u6298\u53e0\u4efb\u52a1\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u6027\u80fd\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u9884\u6d4b\u7ed3\u6784\u4e2d\u7ec6\u5fae\u504f\u5dee\u7684\u5173\u952e\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u53bb\u504f\u6846\u67b6\uff0c\u4e3a\u7ed3\u6784\u5b66\u4e60\u4efb\u52a1\uff08\u5982\u9006\u5411\u6298\u53e0\uff09\u5e26\u6765\u663e\u8457\u6539\u8fdb\u3002"}}
{"id": "2506.08379", "pdf": "https://arxiv.org/pdf/2506.08379", "abs": "https://arxiv.org/abs/2506.08379", "authors": ["Yurun Yuan", "Tengyang Xie"], "title": "Reinforce LLM Reasoning through Multi-Agent Reflection", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "International Conference on Machine Learning (ICML), 2025", "summary": "Leveraging more test-time computation has proven to be an effective way to\nboost the reasoning capabilities of large language models (LLMs). Among various\nmethods, the verify-and-improve paradigm stands out for enabling dynamic\nsolution exploration and feedback incorporation. However, existing approaches\noften suffer from restricted feedback spaces and lack of coordinated training\nof different parties, leading to suboptimal performance. To address this, we\nmodel this multi-turn refinement process as a Markov Decision Process and\nintroduce DPSDP (Direct Policy Search by Dynamic Programming), a reinforcement\nlearning algorithm that trains an actor-critic LLM system to iteratively refine\nanswers via direct preference learning on self-generated data. Theoretically,\nDPSDP can match the performance of any policy within the training distribution.\nEmpirically, we instantiate DPSDP with various base models and show\nimprovements on both in- and out-of-distribution benchmarks. For example, on\nbenchmark MATH 500, majority voting over five refinement steps increases\nfirst-turn accuracy from 58.2% to 63.2% with Ministral-based models. An\nablation study further confirms the benefits of multi-agent collaboration and\nout-of-distribution generalization.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faDPSDP\u7b97\u6cd5\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u4f18\u5316LLM\u7684\u591a\u8f6e\u7b54\u6848\u4fee\u6b63\u8fc7\u7a0b\uff0c\u63d0\u5347\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u53cd\u9988\u7a7a\u95f4\u548c\u534f\u8c03\u8bad\u7ec3\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0d\u4f73\u3002", "method": "\u5c06\u591a\u8f6e\u4fee\u6b63\u5efa\u6a21\u4e3a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u63d0\u51faDPSDP\u7b97\u6cd5\uff0c\u901a\u8fc7\u76f4\u63a5\u504f\u597d\u5b66\u4e60\u8bad\u7ec3actor-critic\u7cfb\u7edf\u3002", "result": "\u5728MATH 500\u57fa\u51c6\u4e0a\uff0c\u4e94\u8f6e\u4fee\u6b63\u5c06\u51c6\u786e\u7387\u4ece58.2%\u63d0\u5347\u81f363.2%\u3002", "conclusion": "DPSDP\u6709\u6548\u63d0\u5347LLM\u7684\u63a8\u7406\u80fd\u529b\uff0c\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u548c\u6cdb\u5316\u80fd\u529b\u5f97\u5230\u9a8c\u8bc1\u3002"}}
{"id": "2506.08383", "pdf": "https://arxiv.org/pdf/2506.08383", "abs": "https://arxiv.org/abs/2506.08383", "authors": ["Jiaqi Chen", "Rongbin Ye"], "title": "Network Threat Detection: Addressing Class Imbalanced Data with Deep Forest", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "With the rapid expansion of Internet of Things (IoT) networks, detecting\nmalicious traffic in real-time has become a critical cybersecurity challenge.\nThis research addresses the detection challenges by presenting a comprehensive\nempirical analysis of machine learning techniques for malware detection using\nthe IoT-23 dataset provided by the Stratosphere Laboratory. We address the\nsignificant class imbalance within the dataset through three resampling\nstrategies. We implement and compare a few machine learning techniques. Our\nfindings demonstrate that the combination of appropriate imbalance treatment\ntechniques with ensemble methods, particularly gcForest, achieves better\ndetection performance compared to traditional approaches. This work contributes\nsignificantly to the development of more intelligent and efficient automated\nthreat detection systems for IoT environments, helping to secure critical\ninfrastructure against sophisticated cyber attacks while optimizing\ncomputational resource usage.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u7269\u8054\u7f51\u6076\u610f\u6d41\u91cf\u5b9e\u65f6\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5904\u7406\u6570\u636e\u96c6\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u7ed3\u5408\u96c6\u6210\u5b66\u4e60\u65b9\u6cd5\uff08\u5982gcForest\uff09\u63d0\u5347\u4e86\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u7269\u8054\u7f51\u7f51\u7edc\u7684\u5feb\u901f\u6269\u5c55\uff0c\u5b9e\u65f6\u68c0\u6d4b\u6076\u610f\u6d41\u91cf\u6210\u4e3a\u5173\u952e\u6311\u6218\uff0c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u4f7f\u7528IoT-23\u6570\u636e\u96c6\uff0c\u91c7\u7528\u4e09\u79cd\u91cd\u91c7\u6837\u7b56\u7565\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\uff0c\u5e76\u6bd4\u8f83\u591a\u79cd\u673a\u5668\u5b66\u4e60\u6280\u672f\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u7ed3\u5408\u4e0d\u5e73\u8861\u5904\u7406\u6280\u672f\u548c\u96c6\u6210\u65b9\u6cd5\uff08\u5982gcForest\uff09\u80fd\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u6027\u80fd\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u7269\u8054\u7f51\u73af\u5883\u4e0b\u7684\u667a\u80fd\u5a01\u80c1\u68c0\u6d4b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\uff0c\u4f18\u5316\u4e86\u8ba1\u7b97\u8d44\u6e90\u4f7f\u7528\u5e76\u589e\u5f3a\u4e86\u5b89\u5168\u6027\u3002"}}
{"id": "2506.08388", "pdf": "https://arxiv.org/pdf/2506.08388", "abs": "https://arxiv.org/abs/2506.08388", "authors": ["Edoardo Cetin", "Tianyu Zhao", "Yujin Tang"], "title": "Reinforcement Learning Teachers of Test Time Scaling", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Preprint", "summary": "Training reasoning language models (LMs) with reinforcement learning (RL) for\none-hot correctness inherently relies on the LM being able to explore and solve\nits task with some chance at initialization. Furthermore, a key use case of\nreasoning LMs is to act as teachers for distilling new students and\ncold-starting future RL iterations rather than being deployed themselves. From\nthese considerations, we introduce a new framework that avoids RL's exploration\nchallenge by training a new class of Reinforcement-Learned Teachers (RLTs)\nfocused on yielding the most effective downstream distillation. RLTs are\nprompted with both the question and solution to each problem, and tasked to\nsimply \"connect-the-dots\" with detailed explanations tailored for their\nstudents. We train RLTs with dense rewards obtained by feeding each explanation\nto the student and testing its understanding of the problem's solution. In\npractice, the raw outputs of a 7B RLT provide higher final performance on\ncompetition and graduate-level tasks than existing distillation and\ncold-starting pipelines that collect and postprocess the reasoning traces of\norders of magnitude larger LMs. Furthermore, RLTs maintain their effectiveness\nwhen training larger students and when applied zero-shot to out-of-distribution\ntasks, unlocking new levels of efficiency and re-usability for the RL reasoning\nframework.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6Reinforcement-Learned Teachers (RLTs)\uff0c\u901a\u8fc7\u8bad\u7ec3\u6559\u5e08\u6a21\u578b\u6765\u4f18\u5316\u4e0b\u6e38\u84b8\u998f\u6548\u679c\uff0c\u907f\u514d\u5f3a\u5316\u5b66\u4e60\u7684\u63a2\u7d22\u6311\u6218\u3002", "motivation": "\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u6a21\u578b\u521d\u59cb\u5316\u7684\u63a2\u7d22\u80fd\u529b\uff0c\u800cRLTs\u4e13\u6ce8\u4e8e\u751f\u6210\u9002\u5408\u5b66\u751f\u6a21\u578b\u5b66\u4e60\u7684\u8be6\u7ec6\u89e3\u91ca\uff0c\u63d0\u5347\u84b8\u998f\u6548\u7387\u3002", "method": "RLTs\u88ab\u8bbe\u8ba1\u4e3a\u5728\u7ed9\u5b9a\u95ee\u9898\u548c\u89e3\u51b3\u65b9\u6848\u7684\u60c5\u51b5\u4e0b\u751f\u6210\u8be6\u7ec6\u89e3\u91ca\uff0c\u5e76\u901a\u8fc7\u5bc6\u96c6\u5956\u52b1\uff08\u5b66\u751f\u6a21\u578b\u5bf9\u89e3\u91ca\u7684\u7406\u89e3\uff09\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c7B\u53c2\u6570\u7684RLT\u5728\u7ade\u8d5b\u548c\u7814\u7a76\u751f\u7ea7\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u84b8\u998f\u65b9\u6cd5\uff0c\u4e14\u80fd\u9002\u5e94\u66f4\u5927\u89c4\u6a21\u5b66\u751f\u6a21\u578b\u548c\u5206\u5e03\u5916\u4efb\u52a1\u3002", "conclusion": "RLTs\u4e3a\u5f3a\u5316\u5b66\u4e60\u63a8\u7406\u6846\u67b6\u63d0\u4f9b\u4e86\u66f4\u9ad8\u7684\u6548\u7387\u548c\u53ef\u91cd\u7528\u6027\u3002"}}
{"id": "2506.08397", "pdf": "https://arxiv.org/pdf/2506.08397", "abs": "https://arxiv.org/abs/2506.08397", "authors": ["Vamshika Sutar", "Amandeep Singh", "Rohitash Chandra"], "title": "Spatiotemporal deep learning models for detection of rapid intensification in cyclones", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Cyclone rapid intensification is the rapid increase in cyclone wind\nintensity, exceeding a threshold of 30 knots, within 24 hours. Rapid\nintensification is considered an extreme event during a cyclone, and its\noccurrence is relatively rare, contributing to a class imbalance in the\ndataset. A diverse array of factors influences the likelihood of a cyclone\nundergoing rapid intensification, further complicating the task for\nconventional machine learning models. In this paper, we evaluate deep learning,\nensemble learning and data augmentation frameworks to detect cyclone rapid\nintensification based on wind intensity and spatial coordinates. We note that\nconventional data augmentation methods cannot be utilised for generating\nspatiotemporal patterns replicating cyclones that undergo rapid\nintensification. Therefore, our framework employs deep learning models to\ngenerate spatial coordinates and wind intensity that replicate cyclones to\naddress the class imbalance problem of rapid intensification. We also use a\ndeep learning model for the classification module within the data augmentation\nframework to differentiate between rapid and non-rapid intensification events\nduring a cyclone. Our results show that data augmentation improves the results\nfor rapid intensification detection in cyclones, and spatial coordinates play a\ncritical role as input features to the given models. This paves the way for\nresearch in synthetic data generation for spatiotemporal data with extreme\nevents.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u548c\u6570\u636e\u589e\u5f3a\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u68c0\u6d4b\u6c14\u65cb\u5feb\u901f\u589e\u5f3a\u73b0\u8c61\uff0c\u89e3\u51b3\u4e86\u6570\u636e\u96c6\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "motivation": "\u6c14\u65cb\u5feb\u901f\u589e\u5f3a\u662f\u4e00\u79cd\u6781\u7aef\u4e14\u7f55\u89c1\u7684\u73b0\u8c61\uff0c\u5bfc\u81f4\u6570\u636e\u96c6\u7c7b\u522b\u4e0d\u5e73\u8861\uff0c\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u96be\u4ee5\u5904\u7406\u3002", "method": "\u91c7\u7528\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u751f\u6210\u7a7a\u95f4\u5750\u6807\u548c\u98ce\u5f3a\u5ea6\u6570\u636e\u4ee5\u6a21\u62df\u6c14\u65cb\uff0c\u5e76\u7ed3\u5408\u6570\u636e\u589e\u5f3a\u6846\u67b6\u8fdb\u884c\u5206\u7c7b\u3002", "result": "\u6570\u636e\u589e\u5f3a\u663e\u8457\u63d0\u5347\u4e86\u5feb\u901f\u589e\u5f3a\u68c0\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u7a7a\u95f4\u5750\u6807\u4f5c\u4e3a\u8f93\u5165\u7279\u5f81\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u65f6\u7a7a\u6570\u636e\u4e2d\u6781\u7aef\u4e8b\u4ef6\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.08409", "pdf": "https://arxiv.org/pdf/2506.08409", "abs": "https://arxiv.org/abs/2506.08409", "authors": ["Fred Xu", "Song Jiang", "Zijie Huang", "Xiao Luo", "Shichang Zhang", "Adrian Chen", "Yizhou Sun"], "title": "FUSE: Measure-Theoretic Compact Fuzzy Set Representation for Taxonomy Expansion", "categories": ["cs.LG"], "comment": null, "summary": "Taxonomy Expansion, which models complex concepts and their relations, can be\nformulated as a set representation learning task. The generalization of set,\nfuzzy set, incorporates uncertainty and measures the information within a\nsemantic concept, making it suitable for concept modeling. Existing works\nusually model sets as vectors or geometric objects such as boxes, which are not\nclosed under set operations. In this work, we propose a sound and efficient\nformulation of set representation learning based on its volume approximation as\na fuzzy set. The resulting embedding framework, Fuzzy Set Embedding (FUSE),\nsatisfies all set operations and compactly approximates the underlying fuzzy\nset, hence preserving information while being efficient to learn, relying on\nminimum neural architecture. We empirically demonstrate the power of FUSE on\nthe task of taxonomy expansion, where FUSE achieves remarkable improvements up\nto 23% compared with existing baselines. Our work marks the first attempt to\nunderstand and efficiently compute the embeddings of fuzzy sets.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u7cca\u96c6\u7684\u96c6\u5408\u8868\u793a\u5b66\u4e60\u65b9\u6cd5FUSE\uff0c\u7528\u4e8e\u89e3\u51b3\u5206\u7c7b\u6269\u5c55\u4efb\u52a1\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5c06\u96c6\u5408\u5efa\u6a21\u4e3a\u5411\u91cf\u6216\u51e0\u4f55\u5bf9\u8c61\uff08\u5982\u76d2\u5b50\uff09\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u5728\u96c6\u5408\u64cd\u4f5c\u4e0b\u4e0d\u5c01\u95ed\uff0c\u4e14\u65e0\u6cd5\u6709\u6548\u5904\u7406\u4e0d\u786e\u5b9a\u6027\u3002\u6a21\u7cca\u96c6\u80fd\u591f\u66f4\u597d\u5730\u5efa\u6a21\u8bed\u4e49\u6982\u5ff5\u4e2d\u7684\u4fe1\u606f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u7cca\u96c6\u4f53\u79ef\u8fd1\u4f3c\u7684\u58f0\u97f3\u9ad8\u6548\u7684\u96c6\u5408\u8868\u793a\u5b66\u4e60\u65b9\u6cd5FUSE\uff0c\u6ee1\u8db3\u6240\u6709\u96c6\u5408\u64cd\u4f5c\uff0c\u5e76\u901a\u8fc7\u6700\u5c0f\u5316\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u5b9e\u73b0\u9ad8\u6548\u5b66\u4e60\u3002", "result": "\u5728\u5206\u7c7b\u6269\u5c55\u4efb\u52a1\u4e2d\uff0cFUSE\u76f8\u6bd4\u73b0\u6709\u57fa\u7ebf\u5b9e\u73b0\u4e86\u9ad8\u8fbe23%\u7684\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "FUSE\u662f\u9996\u6b21\u5c1d\u8bd5\u7406\u89e3\u5e76\u9ad8\u6548\u8ba1\u7b97\u6a21\u7cca\u96c6\u5d4c\u5165\u7684\u5de5\u4f5c\uff0c\u4e3a\u96c6\u5408\u8868\u793a\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.08412", "pdf": "https://arxiv.org/pdf/2506.08412", "abs": "https://arxiv.org/abs/2506.08412", "authors": ["Saraa Ali", "Aleksandr Khizhik", "Stepan Svirin", "Artem Ryzhikov", "Denis Derkach"], "title": "Learning to Hear Broken Motors: Signature-Guided Data Augmentation for Induction-Motor Diagnostics", "categories": ["cs.LG"], "comment": null, "summary": "The application of machine learning (ML) algorithms in the intelligent\ndiagnosis of three-phase engines has the potential to significantly enhance\ndiagnostic performance and accuracy. Traditional methods largely rely on\nsignature analysis, which, despite being a standard practice, can benefit from\nthe integration of advanced ML techniques. In our study, we innovate by\ncombining ML algorithms with a novel unsupervised anomaly generation\nmethodology that takes into account the engine physics model. We propose\nSignature-Guided Data Augmentation (SGDA), an unsupervised framework that\nsynthesizes physically plausible faults directly in the frequency domain of\nhealthy current signals. Guided by Motor Current Signature Analysis, SGDA\ncreates diverse and realistic anomalies without resorting to computationally\nintensive simulations. This hybrid approach leverages the strengths of both\nsupervised ML and unsupervised signature analysis, achieving superior\ndiagnostic accuracy and reliability along with wide industrial application. The\nfindings highlight the potential of our approach to contribute significantly to\nthe field of engine diagnostics, offering a robust and efficient solution for\nreal-world applications.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u4e0e\u65e0\u76d1\u7763\u5f02\u5e38\u751f\u6210\u65b9\u6cd5\u7684\u65b0\u6846\u67b6SGDA\uff0c\u7528\u4e8e\u4e09\u76f8\u7535\u673a\u667a\u80fd\u8bca\u65ad\uff0c\u663e\u8457\u63d0\u5347\u8bca\u65ad\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u7b7e\u540d\u5206\u6790\uff0c\u867d\u4e3a\u6807\u51c6\u5b9e\u8df5\uff0c\u4f46\u7ed3\u5408\u5148\u8fdbML\u6280\u672f\u53ef\u8fdb\u4e00\u6b65\u63d0\u5347\u8bca\u65ad\u6027\u80fd\u3002", "method": "\u63d0\u51faSGDA\u6846\u67b6\uff0c\u7ed3\u5408ML\u7b97\u6cd5\u4e0e\u65e0\u76d1\u7763\u5f02\u5e38\u751f\u6210\u65b9\u6cd5\uff0c\u76f4\u63a5\u5728\u5065\u5eb7\u7535\u6d41\u4fe1\u53f7\u7684\u9891\u57df\u5408\u6210\u7269\u7406\u5408\u7406\u7684\u6545\u969c\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u8bca\u65ad\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5de5\u4e1a\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "SGDA\u6846\u67b6\u4e3a\u7535\u673a\u8bca\u65ad\u9886\u57df\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u7a33\u5065\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2506.08415", "pdf": "https://arxiv.org/pdf/2506.08415", "abs": "https://arxiv.org/abs/2506.08415", "authors": ["Licong Lin", "Jingfeng Wu", "Peter L. Bartlett"], "title": "Improved Scaling Laws in Linear Regression via Data Reuse", "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH"], "comment": null, "summary": "Neural scaling laws suggest that the test error of large language models\ntrained online decreases polynomially as the model size and data size increase.\nHowever, such scaling can be unsustainable when running out of new data. In\nthis work, we show that data reuse can improve existing scaling laws in linear\nregression. Specifically, we derive sharp test error bounds on $M$-dimensional\nlinear models trained by multi-pass stochastic gradient descent (multi-pass\nSGD) on $N$ data with sketched features. Assuming that the data covariance has\na power-law spectrum of degree $a$, and that the true parameter follows a prior\nwith an aligned power-law spectrum of degree $b-a$ (with $a > b > 1$), we show\nthat multi-pass SGD achieves a test error of $\\Theta(M^{1-b} + L^{(1-b)/a})$,\nwhere $L \\lesssim N^{a/b}$ is the number of iterations. In the same setting,\none-pass SGD only attains a test error of $\\Theta(M^{1-b} + N^{(1-b)/a})$ (see\ne.g., Lin et al., 2024). This suggests an improved scaling law via data reuse\n(i.e., choosing $L>N$) in data-constrained regimes. Numerical simulations are\nalso provided to verify our theoretical findings.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u6570\u636e\u91cd\u7528\u5982\u4f55\u5728\u7ebf\u6027\u56de\u5f52\u4e2d\u6539\u8fdb\u73b0\u6709\u7684\u7f29\u653e\u5b9a\u5f8b\uff0c\u901a\u8fc7\u591a\u8f6e\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff08multi-pass SGD\uff09\u5b9e\u73b0\u66f4\u4f4e\u7684\u6d4b\u8bd5\u8bef\u5dee\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u89e3\u51b3\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5728\u6570\u636e\u8017\u5c3d\u65f6\u65e0\u6cd5\u6301\u7eed\u6269\u5c55\u7684\u95ee\u9898\uff0c\u63a2\u7d22\u6570\u636e\u91cd\u7528\u7684\u6f5c\u529b\u3002", "method": "\u91c7\u7528\u591a\u8f6e\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff08multi-pass SGD\uff09\u8bad\u7ec3M\u7ef4\u7ebf\u6027\u6a21\u578b\uff0c\u5047\u8bbe\u6570\u636e\u534f\u65b9\u5dee\u548c\u771f\u5b9e\u53c2\u6570\u5177\u6709\u7279\u5b9a\u7684\u5e42\u5f8b\u8c31\u3002", "result": "\u591a\u8f6eSGD\u5b9e\u73b0\u4e86\u6bd4\u5355\u8f6eSGD\u66f4\u4f4e\u7684\u6d4b\u8bd5\u8bef\u5dee\uff0c\u9a8c\u8bc1\u4e86\u6570\u636e\u91cd\u7528\u5728\u6570\u636e\u53d7\u9650\u573a\u666f\u4e0b\u7684\u4f18\u52bf\u3002", "conclusion": "\u6570\u636e\u91cd\u7528\u53ef\u4ee5\u6539\u8fdb\u73b0\u6709\u7684\u7f29\u653e\u5b9a\u5f8b\uff0c\u5c24\u5176\u662f\u5728\u6570\u636e\u53d7\u9650\u7684\u60c5\u51b5\u4e0b\uff0c\u591a\u8f6eSGD\u6bd4\u5355\u8f6eSGD\u66f4\u6709\u6548\u3002"}}
{"id": "2506.08417", "pdf": "https://arxiv.org/pdf/2506.08417", "abs": "https://arxiv.org/abs/2506.08417", "authors": ["Qingmao Yao", "Zhichao Lei", "Tianyuan Chen", "Ziyue Yuan", "Xuefan Chen", "Jianxiang Liu", "Faguo Wu", "Xiao Zhang"], "title": "Offline RL with Smooth OOD Generalization in Convex Hull and its Neighborhood", "categories": ["cs.LG", "cs.AI"], "comment": "ICLR 2025", "summary": "Offline Reinforcement Learning (RL) struggles with distributional shifts,\nleading to the $Q$-value overestimation for out-of-distribution (OOD) actions.\nExisting methods address this issue by imposing constraints; however, they\noften become overly conservative when evaluating OOD regions, which constrains\nthe $Q$-function generalization. This over-constraint issue results in poor\n$Q$-value estimation and hinders policy improvement. In this paper, we\nintroduce a novel approach to achieve better $Q$-value estimation by enhancing\n$Q$-function generalization in OOD regions within Convex Hull and its\nNeighborhood (CHN). Under the safety generalization guarantees of the CHN, we\npropose the Smooth Bellman Operator (SBO), which updates OOD $Q$-values by\nsmoothing them with neighboring in-sample $Q$-values. We theoretically show\nthat SBO approximates true $Q$-values for both in-sample and OOD actions within\nthe CHN. Our practical algorithm, Smooth Q-function OOD Generalization (SQOG),\nempirically alleviates the over-constraint issue, achieving near-accurate\n$Q$-value estimation. On the D4RL benchmarks, SQOG outperforms existing\nstate-of-the-art methods in both performance and computational efficiency.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5SQOG\uff0c\u901a\u8fc7\u5e73\u6ed1\u8d1d\u5c14\u66fc\u7b97\u5b50\uff08SBO\uff09\u5728\u51f8\u5305\u53ca\u5176\u90bb\u57df\uff08CHN\uff09\u5185\u63d0\u5347Q\u51fd\u6570\u6cdb\u5316\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2dQ\u503c\u9ad8\u4f30\u95ee\u9898\u3002", "motivation": "\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u5206\u5e03\u504f\u79fb\u5bfc\u81f4Q\u503c\u5bf9\u5206\u5e03\u5916\uff08OOD\uff09\u52a8\u4f5c\u7684\u9ad8\u4f30\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u8fc7\u4e8e\u4fdd\u5b88\uff0c\u9650\u5236\u4e86Q\u51fd\u6570\u6cdb\u5316\u3002", "method": "\u63d0\u51fa\u5e73\u6ed1\u8d1d\u5c14\u66fc\u7b97\u5b50\uff08SBO\uff09\uff0c\u5728CHN\u5185\u901a\u8fc7\u5e73\u6ed1OOD Q\u503c\u4e0e\u90bb\u8fd1\u6837\u672cQ\u503c\u66f4\u65b0Q\u503c\uff0c\u63d0\u5347\u6cdb\u5316\u80fd\u529b\u3002", "result": "SQOG\u5728D4RL\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u63a5\u8fd1\u51c6\u786e\u7684Q\u503c\u4f30\u8ba1\u3002", "conclusion": "SQOG\u901a\u8fc7SBO\u6709\u6548\u7f13\u89e3\u4e86Q\u51fd\u6570\u6cdb\u5316\u7684\u8fc7\u7ea6\u675f\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7684\u6027\u80fd\u3002"}}
{"id": "2506.08419", "pdf": "https://arxiv.org/pdf/2506.08419", "abs": "https://arxiv.org/abs/2506.08419", "authors": ["Ruichen Jiang", "Ali Kavis", "Aryan Mokhtari"], "title": "Online Learning-guided Learning Rate Adaptation via Gradient Alignment", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": "24 pages, 5 figures", "summary": "The performance of an optimizer on large-scale deep learning models depends\ncritically on fine-tuning the learning rate, often requiring an extensive grid\nsearch over base learning rates, schedules, and other hyperparameters. In this\npaper, we propose a principled framework called GALA (Gradient Alignment-based\nLearning rate Adaptation), which dynamically adjusts the learning rate by\ntracking the alignment between consecutive gradients and using a local\ncurvature estimate. Guided by the convergence analysis, we formulate the\nproblem of selecting the learning rate as a one-dimensional online learning\nproblem. When paired with an online learning algorithm such as\nFollow-the-Regularized-Leader, our method produces a flexible, adaptive\nlearning rate schedule that tends to increase when consecutive gradients are\naligned and decrease otherwise. We establish a data-adaptive convergence rate\nfor normalized SGD equipped with GALA in the smooth, nonconvex setting.\nEmpirically, common optimizers such as SGD and Adam, when augmented with GALA,\ndemonstrate robust performance across a wide range of initial learning rates\nand perform competitively without the need for tuning.", "AI": {"tldr": "GALA\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u5b66\u4e60\u7387\uff0c\u57fa\u4e8e\u68af\u5ea6\u5bf9\u9f50\u548c\u5c40\u90e8\u66f2\u7387\u4f30\u8ba1\uff0c\u65e0\u9700\u7e41\u7410\u7684\u8d85\u53c2\u6570\u8c03\u4f18\u5373\u53ef\u63d0\u5347\u4f18\u5316\u5668\u6027\u80fd\u3002", "motivation": "\u5927\u89c4\u6a21\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u6027\u80fd\u9ad8\u5ea6\u4f9d\u8d56\u5b66\u4e60\u7387\u7684\u7cbe\u7ec6\u8c03\u4f18\uff0c\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u7f51\u683c\u641c\u7d22\uff0c\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u63d0\u51faGALA\u6846\u67b6\uff0c\u901a\u8fc7\u8ddf\u8e2a\u8fde\u7eed\u68af\u5ea6\u7684\u5bf9\u9f50\u6027\u548c\u5c40\u90e8\u66f2\u7387\u4f30\u8ba1\u52a8\u6001\u8c03\u6574\u5b66\u4e60\u7387\uff0c\u5c06\u5176\u5efa\u6a21\u4e3a\u4e00\u7ef4\u5728\u7ebf\u5b66\u4e60\u95ee\u9898\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660eGALA\u5728\u5e73\u6ed1\u975e\u51f8\u573a\u666f\u4e0b\u5177\u6709\u6570\u636e\u81ea\u9002\u5e94\u6536\u655b\u7387\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u4e0eSGD\u548cAdam\u7ed3\u5408\u65f6\u8868\u73b0\u7a33\u5065\u4e14\u65e0\u9700\u8c03\u4f18\u3002", "conclusion": "GALA\u4e3a\u5b66\u4e60\u7387\u8c03\u6574\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u81ea\u9002\u5e94\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u8d85\u53c2\u6570\u8c03\u4f18\u7684\u9700\u6c42\u3002"}}
{"id": "2506.08426", "pdf": "https://arxiv.org/pdf/2506.08426", "abs": "https://arxiv.org/abs/2506.08426", "authors": ["Zheng Lin", "Zhe Chen", "Xianhao Chen", "Wei Ni", "Yue Gao"], "title": "HASFL: Heterogeneity-aware Split Federated Learning over Edge Computing Systems", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": "16 pages, 11 figures. arXiv admin note: text overlap with\n  arXiv:2403.13101", "summary": "Split federated learning (SFL) has emerged as a promising paradigm to\ndemocratize machine learning (ML) on edge devices by enabling layer-wise model\npartitioning. However, existing SFL approaches suffer significantly from the\nstraggler effect due to the heterogeneous capabilities of edge devices. To\naddress the fundamental challenge, we propose adaptively controlling batch\nsizes (BSs) and model splitting (MS) for edge devices to overcome resource\nheterogeneity. We first derive a tight convergence bound of SFL that quantifies\nthe impact of varied BSs and MS on learning performance. Based on the\nconvergence bound, we propose HASFL, a heterogeneity-aware SFL framework\ncapable of adaptively controlling BS and MS to balance communication-computing\nlatency and training convergence in heterogeneous edge networks. Extensive\nexperiments with various datasets validate the effectiveness of HASFL and\ndemonstrate its superiority over state-of-the-art benchmarks.", "AI": {"tldr": "HASFL\u6846\u67b6\u901a\u8fc7\u81ea\u9002\u5e94\u63a7\u5236\u6279\u5904\u7406\u5927\u5c0f\u548c\u6a21\u578b\u5206\u5272\uff0c\u89e3\u51b3\u4e86\u8fb9\u7f18\u8bbe\u5907\u8d44\u6e90\u5f02\u6784\u6027\u5bfc\u81f4\u7684\u6162\u901f\u8bbe\u5907\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u5206\u5272\u8054\u90a6\u5b66\u4e60\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5206\u5272\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u56e0\u8fb9\u7f18\u8bbe\u5907\u80fd\u529b\u5f02\u6784\u6027\u800c\u663e\u8457\u53d7\u6162\u901f\u8bbe\u5907\u5f71\u54cd\uff0c\u9700\u89e3\u51b3\u8d44\u6e90\u5f02\u6784\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51faHASFL\u6846\u67b6\uff0c\u901a\u8fc7\u6536\u655b\u754c\u5206\u6790\u6279\u5904\u7406\u5927\u5c0f\u548c\u6a21\u578b\u5206\u5272\u7684\u5f71\u54cd\uff0c\u81ea\u9002\u5e94\u8c03\u6574\u4ee5\u5e73\u8861\u901a\u4fe1-\u8ba1\u7b97\u5ef6\u8fdf\u548c\u8bad\u7ec3\u6536\u655b\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1HASFL\u5728\u591a\u79cd\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u6709\u6548\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "HASFL\u901a\u8fc7\u81ea\u9002\u5e94\u63a7\u5236\u7b56\u7565\uff0c\u663e\u8457\u6539\u5584\u4e86\u5f02\u6784\u8fb9\u7f18\u7f51\u7edc\u4e2d\u7684\u5206\u5272\u8054\u90a6\u5b66\u4e60\u6548\u679c\u3002"}}
{"id": "2506.08435", "pdf": "https://arxiv.org/pdf/2506.08435", "abs": "https://arxiv.org/abs/2506.08435", "authors": ["Mingyuan Fan", "Fuyi Wang", "Cen Chen", "Jianying Zhou"], "title": "Boosting Gradient Leakage Attacks: Data Reconstruction in Realistic FL Settings", "categories": ["cs.LG", "cs.CR", "cs.CV"], "comment": "Accepted to Usenix Security 2025", "summary": "Federated learning (FL) enables collaborative model training among multiple\nclients without the need to expose raw data. Its ability to safeguard privacy,\nat the heart of FL, has recently been a hot-button debate topic. To elaborate,\nseveral studies have introduced a type of attacks known as gradient leakage\nattacks (GLAs), which exploit the gradients shared during training to\nreconstruct clients' raw data. On the flip side, some literature, however,\ncontends no substantial privacy risk in practical FL environments due to the\neffectiveness of such GLAs being limited to overly relaxed conditions, such as\nsmall batch sizes and knowledge of clients' data distributions.\n  This paper bridges this critical gap by empirically demonstrating that\nclients' data can still be effectively reconstructed, even within realistic FL\nenvironments. Upon revisiting GLAs, we recognize that their performance\nfailures stem from their inability to handle the gradient matching problem. To\nalleviate the performance bottlenecks identified above, we develop FedLeak,\nwhich introduces two novel techniques, partial gradient matching and gradient\nregularization. Moreover, to evaluate the performance of FedLeak in real-world\nFL environments, we formulate a practical evaluation protocol grounded in a\nthorough review of extensive FL literature and industry practices. Under this\nprotocol, FedLeak can still achieve high-fidelity data reconstruction, thereby\nunderscoring the significant vulnerability in FL systems and the urgent need\nfor more effective defense methods.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u8bc1\u660e\uff0c\u5373\u4f7f\u5728\u73b0\u5b9e\u7684\u8054\u90a6\u5b66\u4e60\u73af\u5883\u4e2d\uff0c\u68af\u5ea6\u6cc4\u6f0f\u653b\u51fb\uff08GLAs\uff09\u4ecd\u80fd\u6709\u6548\u91cd\u6784\u5ba2\u6237\u7aef\u6570\u636e\uff0c\u5e76\u63d0\u51faFedLeak\u65b9\u6cd5\u4ee5\u89e3\u51b3\u6027\u80fd\u74f6\u9888\u3002", "motivation": "\u63a2\u8ba8\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u4e2d\u68af\u5ea6\u6cc4\u6f0f\u653b\u51fb\u7684\u5b9e\u9645\u98ce\u9669\uff0c\u586b\u8865\u73b0\u6709\u7814\u7a76\u4e2d\u5173\u4e8e\u653b\u51fb\u6709\u6548\u6027\u7684\u4e89\u8bae\u3002", "method": "\u63d0\u51faFedLeak\u65b9\u6cd5\uff0c\u5305\u542b\u90e8\u5206\u68af\u5ea6\u5339\u914d\u548c\u68af\u5ea6\u6b63\u5219\u5316\u4e24\u79cd\u65b0\u6280\u672f\uff0c\u5e76\u8bbe\u8ba1\u57fa\u4e8e\u6587\u732e\u548c\u884c\u4e1a\u5b9e\u8df5\u7684\u8bc4\u4ef7\u534f\u8bae\u3002", "result": "FedLeak\u5728\u73b0\u5b9eFL\u73af\u5883\u4e2d\u4ecd\u80fd\u5b9e\u73b0\u9ad8\u4fdd\u771f\u6570\u636e\u91cd\u6784\uff0c\u63ed\u793aFL\u7cfb\u7edf\u7684\u91cd\u5927\u6f0f\u6d1e\u3002", "conclusion": "FL\u7cfb\u7edf\u5b58\u5728\u663e\u8457\u9690\u79c1\u98ce\u9669\uff0c\u4e9f\u9700\u66f4\u6709\u6548\u7684\u9632\u5fa1\u65b9\u6cd5\u3002"}}
{"id": "2506.08438", "pdf": "https://arxiv.org/pdf/2506.08438", "abs": "https://arxiv.org/abs/2506.08438", "authors": ["Yuchen Wu", "Xinyi Zhong", "Zhuoran Yang"], "title": "Learning to Lead: Incentivizing Strategic Agents in the Dark", "categories": ["cs.LG", "cs.GT", "stat.ML"], "comment": "81 pages, 7 figures", "summary": "We study an online learning version of the generalized principal-agent model,\nwhere a principal interacts repeatedly with a strategic agent possessing\nprivate types, private rewards, and taking unobservable actions. The agent is\nnon-myopic, optimizing a discounted sum of future rewards and may strategically\nmisreport types to manipulate the principal's learning. The principal,\nobserving only her own realized rewards and the agent's reported types, aims to\nlearn an optimal coordination mechanism that minimizes strategic regret. We\ndevelop the first provably sample-efficient algorithm for this challenging\nsetting. Our approach features a novel pipeline that combines (i) a delaying\nmechanism to incentivize approximately myopic agent behavior, (ii) an\ninnovative reward angle estimation framework that uses sector tests and a\nmatching procedure to recover type-dependent reward functions, and (iii) a\npessimistic-optimistic LinUCB algorithm that enables the principal to explore\nefficiently while respecting the agent's incentive constraints. We establish a\nnear optimal $\\tilde{O}(\\sqrt{T}) $ regret bound for learning the principal's\noptimal policy, where $\\tilde{O}(\\cdot) $ omits logarithmic factors. Our\nresults open up new avenues for designing robust online learning algorithms for\na wide range of game-theoretic settings involving private types and strategic\nagents.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5e7f\u4e49\u59d4\u6258-\u4ee3\u7406\u6a21\u578b\u7684\u5728\u7ebf\u5b66\u4e60\u7248\u672c\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6837\u672c\u9ad8\u6548\u7684\u7b97\u6cd5\uff0c\u7ed3\u5408\u5ef6\u8fdf\u673a\u5236\u3001\u5956\u52b1\u89d2\u5ea6\u4f30\u8ba1\u6846\u67b6\u548c\u60b2\u89c2-\u4e50\u89c2LinUCB\u7b97\u6cd5\uff0c\u5b9e\u73b0\u4e86\u63a5\u8fd1\u6700\u4f18\u7684\u540e\u6094\u754c\u3002", "motivation": "\u7814\u7a76\u59d4\u6258\u4eba\u4e0e\u5177\u6709\u79c1\u6709\u7c7b\u578b\u548c\u5956\u52b1\u7684\u6218\u7565\u4ee3\u7406\u4eba\u5728\u91cd\u590d\u4ea4\u4e92\u4e2d\u7684\u5b66\u4e60\u95ee\u9898\uff0c\u65e8\u5728\u8bbe\u8ba1\u4e00\u79cd\u9c81\u68d2\u7684\u5728\u7ebf\u5b66\u4e60\u7b97\u6cd5\u4ee5\u6700\u5c0f\u5316\u6218\u7565\u540e\u6094\u3002", "method": "\u91c7\u7528\u5ef6\u8fdf\u673a\u5236\u6fc0\u52b1\u8fd1\u4f3c\u8fd1\u89c6\u4ee3\u7406\u884c\u4e3a\uff0c\u7ed3\u5408\u5956\u52b1\u89d2\u5ea6\u4f30\u8ba1\u6846\u67b6\uff08\u5305\u62ec\u6247\u533a\u6d4b\u8bd5\u548c\u5339\u914d\u7a0b\u5e8f\uff09\u6062\u590d\u7c7b\u578b\u4f9d\u8d56\u7684\u5956\u52b1\u51fd\u6570\uff0c\u5e76\u4f7f\u7528\u60b2\u89c2-\u4e50\u89c2LinUCB\u7b97\u6cd5\u9ad8\u6548\u63a2\u7d22\u3002", "result": "\u63d0\u51fa\u4e86\u9996\u4e2a\u53ef\u8bc1\u660e\u6837\u672c\u9ad8\u6548\u7684\u7b97\u6cd5\uff0c\u5b9e\u73b0\u4e86\u63a5\u8fd1\u6700\u4f18\u7684$\\tilde{O}(\\sqrt{T})$\u540e\u6094\u754c\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u6d89\u53ca\u79c1\u6709\u7c7b\u578b\u548c\u6218\u7565\u4ee3\u7406\u7684\u535a\u5f08\u8bba\u573a\u666f\u8bbe\u8ba1\u9c81\u68d2\u5728\u7ebf\u5b66\u4e60\u7b97\u6cd5\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2506.08441", "pdf": "https://arxiv.org/pdf/2506.08441", "abs": "https://arxiv.org/abs/2506.08441", "authors": ["Anh N. Nhu", "Sanghyun Son", "Ming Lin"], "title": "Time-Aware World Model for Adaptive Prediction and Control", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "comment": "Paper accepted to ICML 2025", "summary": "In this work, we introduce the Time-Aware World Model (TAWM), a model-based\napproach that explicitly incorporates temporal dynamics. By conditioning on the\ntime-step size, {\\Delta}t, and training over a diverse range of {\\Delta}t\nvalues -- rather than sampling at a fixed time-step -- TAWM learns both high-\nand low-frequency task dynamics across diverse control problems. Grounded in\nthe information-theoretic insight that the optimal sampling rate depends on a\nsystem's underlying dynamics, this time-aware formulation improves both\nperformance and data efficiency. Empirical evaluations show that TAWM\nconsistently outperforms conventional models across varying observation rates\nin a variety of control tasks, using the same number of training samples and\niterations. Our code can be found online at:\ngithub.com/anh-nn01/Time-Aware-World-Model.", "AI": {"tldr": "TAWM\u662f\u4e00\u79cd\u57fa\u4e8e\u65f6\u95f4\u611f\u77e5\u7684\u4e16\u754c\u6a21\u578b\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u65f6\u95f4\u6b65\u957f\u6765\u5b66\u4e60\u4efb\u52a1\u7684\u9ad8\u9891\u548c\u4f4e\u9891\u52a8\u6001\uff0c\u63d0\u5347\u6027\u80fd\u548c\u6570\u636e\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u6a21\u578b\u5728\u56fa\u5b9a\u65f6\u95f4\u6b65\u957f\u4e0b\u91c7\u6837\uff0c\u65e0\u6cd5\u9002\u5e94\u4e0d\u540c\u52a8\u6001\u9891\u7387\u7684\u4efb\u52a1\u9700\u6c42\uff0c\u9650\u5236\u4e86\u6027\u80fd\u548c\u6548\u7387\u3002", "method": "TAWM\u901a\u8fc7\u6761\u4ef6\u5316\u65f6\u95f4\u6b65\u957f\u0394t\uff0c\u5e76\u5728\u591a\u6837\u5316\u7684\u0394t\u503c\u4e0a\u8bad\u7ec3\uff0c\u5b66\u4e60\u4efb\u52a1\u7684\u591a\u9891\u52a8\u6001\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cTAWM\u5728\u591a\u79cd\u63a7\u5236\u4efb\u52a1\u4e2d\u4f18\u4e8e\u4f20\u7edf\u6a21\u578b\uff0c\u5c24\u5176\u5728\u89c2\u5bdf\u7387\u53d8\u5316\u65f6\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "TAWM\u7684\u65f6\u95f4\u611f\u77e5\u8bbe\u8ba1\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u548c\u6570\u636e\u6548\u7387\uff0c\u9002\u7528\u4e8e\u52a8\u6001\u591a\u6837\u7684\u4efb\u52a1\u3002"}}
{"id": "2506.08460", "pdf": "https://arxiv.org/pdf/2506.08460", "abs": "https://arxiv.org/abs/2506.08460", "authors": ["Yihong Guo", "Yu Yang", "Pan Xu", "Anqi Liu"], "title": "MOBODY: Model Based Off-Dynamics Offline Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "We study the off-dynamics offline reinforcement learning problem, where the\ngoal is to learn a policy from offline datasets collected from source and\ntarget domains with mismatched transition. Existing off-dynamics offline RL\nmethods typically either filter source transitions that resemble those of the\ntarget domain or apply reward augmentation to source data, both constrained by\nthe limited transitions available from the target domain. As a result, the\nlearned policy is unable to explore target domain beyond the offline datasets.\nWe propose MOBODY, a Model-Based Off-Dynamics offline RL algorithm that\naddresses this limitation by enabling exploration of the target domain via\nlearned dynamics. MOBODY generates new synthetic transitions in the target\ndomain through model rollouts, which are used as data augmentation during\noffline policy learning. Unlike existing model-based methods that learn\ndynamics from a single domain, MOBODY tackles the challenge of mismatched\ndynamics by leveraging both source and target datasets. Directly merging these\ndatasets can bias the learned model toward source dynamics. Instead, MOBODY\nlearns target dynamics by discovering a shared latent representation of states\nand transitions across domains through representation learning. To stabilize\ntraining, MOBODY incorporates a behavior cloning loss that regularizes the\npolicy. Specifically, we introduce a Q-weighted behavior cloning loss that\nregularizes the policy toward actions with high target-domain Q-values, rather\nthan uniformly imitating all actions in the dataset. These Q-values are learned\nfrom an enhanced target dataset composed of offline target data, augmented\nsource data, and rollout data from the learned target dynamics. We evaluate\nMOBODY on MuJoCo benchmarks and show that it significantly outperforms\nstate-of-the-art baselines, with especially pronounced improvements in\nchallenging scenarios.", "AI": {"tldr": "MOBODY\u662f\u4e00\u79cd\u57fa\u4e8e\u6a21\u578b\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u751f\u6210\u76ee\u6807\u57df\u7684\u5408\u6210\u8f6c\u79fb\u6570\u636e\u6765\u89e3\u51b3\u6e90\u57df\u548c\u76ee\u6807\u57df\u52a8\u6001\u4e0d\u5339\u914d\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u53d7\u9650\u4e8e\u76ee\u6807\u57df\u7684\u6709\u9650\u6570\u636e\uff0c\u65e0\u6cd5\u63a2\u7d22\u76ee\u6807\u57df\u3002MOBODY\u65e8\u5728\u901a\u8fc7\u5b66\u4e60\u52a8\u6001\u6a21\u578b\u751f\u6210\u65b0\u6570\u636e\uff0c\u6269\u5c55\u76ee\u6807\u57df\u7684\u63a2\u7d22\u80fd\u529b\u3002", "method": "MOBODY\u5229\u7528\u8868\u793a\u5b66\u4e60\u53d1\u73b0\u8de8\u57df\u7684\u5171\u4eab\u6f5c\u5728\u72b6\u6001\u548c\u8f6c\u79fb\u8868\u793a\uff0c\u5e76\u901a\u8fc7\u6a21\u578b\u751f\u6210\u76ee\u6807\u57df\u6570\u636e\u3002\u7ed3\u5408Q\u52a0\u6743\u884c\u4e3a\u514b\u9686\u635f\u5931\u7a33\u5b9a\u8bad\u7ec3\u3002", "result": "\u5728MuJoCo\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMOBODY\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u590d\u6742\u573a\u666f\u4e2d\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "MOBODY\u901a\u8fc7\u52a8\u6001\u6a21\u578b\u548c\u6570\u636e\u589e\u5f3a\u6709\u6548\u89e3\u51b3\u4e86\u8de8\u57df\u52a8\u6001\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7684\u6027\u80fd\u3002"}}
{"id": "2506.08463", "pdf": "https://arxiv.org/pdf/2506.08463", "abs": "https://arxiv.org/abs/2506.08463", "authors": ["Zhishuai Liu", "Yu Yang", "Ruhan Wang", "Pan Xu", "Dongruo Zhou"], "title": "How to Provably Improve Return Conditioned Supervised Learning?", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "25 pages, 4 figures, 12 tables", "summary": "In sequential decision-making problems, Return-Conditioned Supervised\nLearning (RCSL) has gained increasing recognition for its simplicity and\nstability in modern decision-making tasks. Unlike traditional offline\nreinforcement learning (RL) algorithms, RCSL frames policy learning as a\nsupervised learning problem by taking both the state and return as input. This\napproach eliminates the instability often associated with temporal difference\n(TD) learning in offline RL. However, RCSL has been criticized for lacking the\nstitching property, meaning its performance is inherently limited by the\nquality of the policy used to generate the offline dataset. To address this\nlimitation, we propose a principled and simple framework called Reinforced\nRCSL. The key innovation of our framework is the introduction of a concept we\ncall the in-distribution optimal return-to-go. This mechanism leverages our\npolicy to identify the best achievable in-dataset future return based on the\ncurrent state, avoiding the need for complex return augmentation techniques.\nOur theoretical analysis demonstrates that Reinforced RCSL can consistently\noutperform the standard RCSL approach. Empirical results further validate our\nclaims, showing significant performance improvements across a range of\nbenchmarks.", "AI": {"tldr": "Reinforced RCSL\u901a\u8fc7\u5f15\u5165in-distribution optimal return-to-go\u673a\u5236\uff0c\u89e3\u51b3\u4e86RCSL\u7f3a\u4e4fstitching\u5c5e\u6027\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "RCSL\u56e0\u5176\u7b80\u5355\u6027\u548c\u7a33\u5b9a\u6027\u5728\u51b3\u7b56\u4efb\u52a1\u4e2d\u53d7\u5230\u5173\u6ce8\uff0c\u4f46\u5176\u6027\u80fd\u53d7\u9650\u4e8e\u79bb\u7ebf\u6570\u636e\u96c6\u7684\u8d28\u91cf\uff0c\u7f3a\u4e4fstitching\u5c5e\u6027\u3002", "method": "\u63d0\u51faReinforced RCSL\u6846\u67b6\uff0c\u5f15\u5165in-distribution optimal return-to-go\u673a\u5236\uff0c\u907f\u514d\u590d\u6742\u7684\u56de\u62a5\u589e\u5f3a\u6280\u672f\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cReinforced RCSL\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u6807\u51c6RCSL\u3002", "conclusion": "Reinforced RCSL\u662f\u4e00\u79cd\u7b80\u5355\u4e14\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86RCSL\u7684\u5173\u952e\u9650\u5236\uff0c\u63d0\u5347\u4e86\u51b3\u7b56\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2506.08464", "pdf": "https://arxiv.org/pdf/2506.08464", "abs": "https://arxiv.org/abs/2506.08464", "authors": ["Hyunseok Seung", "Jaewoo Lee", "Hyunsuk Ko"], "title": "MAC: An Efficient Gradient Preconditioning using Mean Activation Approximated Curvature", "categories": ["cs.LG"], "comment": null, "summary": "Second-order optimization methods for training neural networks, such as KFAC,\nexhibit superior convergence by utilizing curvature information of loss\nlandscape. However, it comes at the expense of high computational burden. In\nthis work, we analyze the two components that constitute the layer-wise Fisher\ninformation matrix (FIM) used in KFAC: the Kronecker factors related to\nactivations and pre-activation gradients. Based on empirical observations on\ntheir eigenspectra, we propose efficient approximations for them, resulting in\na computationally efficient optimization method called MAC. To the best of our\nknowledge, MAC is the first algorithm to apply the Kronecker factorization to\nthe FIM of attention layers used in transformers and explicitly integrate\nattention scores into the preconditioning. We also study the convergence\nproperty of MAC on nonlinear neural networks and provide two conditions under\nwhich it converges to global minima. Our extensive evaluations on various\nnetwork architectures and datasets show that the proposed method outperforms\nKFAC and other state-of-the-art methods in terms of accuracy, end-to-end\ntraining time, and memory usage. Code is available at\nhttps://github.com/hseung88/mac.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u4e8c\u9636\u4f18\u5316\u65b9\u6cd5MAC\uff0c\u901a\u8fc7\u8fd1\u4f3cKronecker\u56e0\u5b50\u964d\u4f4e\u8ba1\u7b97\u8d1f\u62c5\uff0c\u5e76\u5728Transformer\u4e2d\u9996\u6b21\u5e94\u7528Kronecker\u5206\u89e3\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bad\u7ec3\u6548\u7387\u548c\u6027\u80fd\u3002", "motivation": "KFAC\u7b49\u4e8c\u9636\u4f18\u5316\u65b9\u6cd5\u867d\u7136\u6536\u655b\u5feb\uff0c\u4f46\u8ba1\u7b97\u8d1f\u62c5\u9ad8\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u5206\u6790Fisher\u4fe1\u606f\u77e9\u9635\u7684Kronecker\u56e0\u5b50\uff0c\u63d0\u51fa\u9ad8\u6548\u8fd1\u4f3c\u65b9\u6cd5\u4ee5\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u5bf9\u6fc0\u6d3b\u548c\u9884\u6fc0\u6d3b\u68af\u5ea6Kronecker\u56e0\u5b50\u7279\u5f81\u8c31\u7684\u89c2\u5bdf\uff0c\u63d0\u51fa\u9ad8\u6548\u8fd1\u4f3c\u65b9\u6cd5\uff0c\u5f00\u53d1\u51faMAC\u7b97\u6cd5\uff0c\u5e76\u9996\u6b21\u5c06\u5176\u5e94\u7528\u4e8eTransformer\u7684\u6ce8\u610f\u529b\u5c42\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cMAC\u5728\u51c6\u786e\u6027\u3001\u8bad\u7ec3\u65f6\u95f4\u548c\u5185\u5b58\u4f7f\u7528\u4e0a\u5747\u4f18\u4e8eKFAC\u53ca\u5176\u4ed6\u5148\u8fdb\u65b9\u6cd5\uff0c\u4e14\u5728\u67d0\u4e9b\u6761\u4ef6\u4e0b\u80fd\u6536\u655b\u5230\u5168\u5c40\u6700\u4f18\u3002", "conclusion": "MAC\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u901a\u7528\u7684\u4e8c\u9636\u4f18\u5316\u65b9\u6cd5\uff0c\u7279\u522b\u9002\u5408Transformer\u7b49\u590d\u6742\u67b6\u6784\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2506.08473", "pdf": "https://arxiv.org/pdf/2506.08473", "abs": "https://arxiv.org/abs/2506.08473", "authors": ["Shuo Yang", "Qihui Zhang", "Yuyang Liu", "Yue Huang", "Xiaojun Jia", "Kunpeng Ning", "Jiayu Yao", "Jigang Wang", "Hailiang Dai", "Yibing Song", "Li Yuan"], "title": "AsFT: Anchoring Safety During LLM Fine-Tuning Within Narrow Safety Basin", "categories": ["cs.LG"], "comment": null, "summary": "Large language models (LLMs) are vulnerable to safety risks during\nfine-tuning, where small amounts of malicious or harmless data can compromise\nsafeguards. In this paper, building on the concept of alignment direction --\ndefined by the weight difference between aligned and unaligned models -- we\nobserve that perturbations along this direction preserve model safety. In\ncontrast, perturbations along directions orthogonal to this alignment are\nstrongly linked to harmful direction perturbations, rapidly degrading safety\nand framing the parameter space as a narrow safety basin. Based on this\ninsight, we propose a methodology for safety fine-tuning called AsFT (Anchoring\nSafety in Fine-Tuning), which integrates a regularization term into the\ntraining objective. This term uses the alignment direction as an anchor to\nsuppress updates in harmful directions, ensuring that fine-tuning is\nconstrained within the narrow safety basin. Extensive experiments on multiple\ndatasets show that AsFT outperforms Safe LoRA, reducing harmful behavior by\n7.60 percent, improving model performance by 3.44 percent, and maintaining\nrobust performance across various experimental settings. Code is available at\nhttps://github.com/PKU-YuanGroup/AsFT", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAsFT\u7684\u5b89\u5168\u5fae\u8c03\u65b9\u6cd5\uff0c\u901a\u8fc7\u6b63\u5219\u5316\u9879\u6291\u5236\u6709\u5bb3\u65b9\u5411\u7684\u66f4\u65b0\uff0c\u663e\u8457\u51cf\u5c11\u6709\u5bb3\u884c\u4e3a\u5e76\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u5bb9\u6613\u53d7\u5230\u5b89\u5168\u98ce\u9669\u7684\u5f71\u54cd\uff0c\u5c11\u91cf\u6076\u610f\u6216\u65e0\u5bb3\u6570\u636e\u53ef\u80fd\u7834\u574f\u5b89\u5168\u4fdd\u62a4\u63aa\u65bd\u3002", "method": "\u57fa\u4e8e\u5bf9\u9f50\u65b9\u5411\u7684\u6982\u5ff5\uff0c\u63d0\u51faAsFT\u65b9\u6cd5\uff0c\u5c06\u6b63\u5219\u5316\u9879\u5f15\u5165\u8bad\u7ec3\u76ee\u6807\uff0c\u4ee5\u5bf9\u9f50\u65b9\u5411\u4e3a\u951a\u70b9\u6291\u5236\u6709\u5bb3\u65b9\u5411\u7684\u66f4\u65b0\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cAsFT\u4f18\u4e8eSafe LoRA\uff0c\u51cf\u5c11\u6709\u5bb3\u884c\u4e3a7.60%\uff0c\u63d0\u5347\u6a21\u578b\u6027\u80fd3.44%\uff0c\u5e76\u5728\u591a\u79cd\u5b9e\u9a8c\u8bbe\u7f6e\u4e2d\u4fdd\u6301\u7a33\u5065\u8868\u73b0\u3002", "conclusion": "AsFT\u901a\u8fc7\u7ea6\u675f\u5fae\u8c03\u5728\u5b89\u5168\u533a\u57df\u5185\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM\u5fae\u8c03\u4e2d\u7684\u5b89\u5168\u95ee\u9898\u3002"}}
{"id": "2506.08475", "pdf": "https://arxiv.org/pdf/2506.08475", "abs": "https://arxiv.org/abs/2506.08475", "authors": ["Xiaolong He", "Yeonjong Shin", "Anthony Gruber", "Sohyeon Jung", "Kookjin Lee", "Youngsoo Choi"], "title": "Thermodynamically Consistent Latent Dynamics Identification for Parametric Systems", "categories": ["cs.LG", "cs.CE", "cs.NA", "math.NA"], "comment": null, "summary": "We propose an efficient thermodynamics-informed latent space dynamics\nidentification (tLaSDI) framework for the reduced-order modeling of parametric\nnonlinear dynamical systems. This framework integrates autoencoders for\ndimensionality reduction with newly developed parametric GENERIC\nformalism-informed neural networks (pGFINNs), which enable efficient learning\nof parametric latent dynamics while preserving key thermodynamic principles\nsuch as free energy conservation and entropy generation across the parameter\nspace. To further enhance model performance, a physics-informed active learning\nstrategy is incorporated, leveraging a greedy, residual-based error indicator\nto adaptively sample informative training data, outperforming uniform sampling\nat equivalent computational cost. Numerical experiments on the Burgers'\nequation and the 1D/1V Vlasov-Poisson equation demonstrate that the proposed\nmethod achieves up to 3,528x speed-up with 1-3% relative errors, and\nsignificant reduction in training (50-90%) and inference (57-61%) cost.\nMoreover, the learned latent space dynamics reveal the underlying thermodynamic\nbehavior of the system, offering valuable insights into the physical-space\ndynamics.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u70ed\u529b\u5b66\u4fe1\u606f\u7684\u6f5c\u5728\u7a7a\u95f4\u52a8\u529b\u5b66\u8bc6\u522b\u6846\u67b6\uff08tLaSDI\uff09\uff0c\u7528\u4e8e\u53c2\u6570\u5316\u975e\u7ebf\u6027\u52a8\u529b\u7cfb\u7edf\u7684\u964d\u9636\u5efa\u6a21\uff0c\u7ed3\u5408\u81ea\u7f16\u7801\u5668\u548c\u53c2\u6570\u5316GENERIC\u5f62\u5f0f\u795e\u7ecf\u7f51\u7edc\uff08pGFINNs\uff09\uff0c\u5728\u4fdd\u6301\u70ed\u529b\u5b66\u539f\u7406\u7684\u540c\u65f6\u9ad8\u6548\u5b66\u4e60\u6f5c\u5728\u52a8\u529b\u5b66\u3002", "motivation": "\u89e3\u51b3\u53c2\u6570\u5316\u975e\u7ebf\u6027\u52a8\u529b\u7cfb\u7edf\u7684\u9ad8\u6548\u5efa\u6a21\u95ee\u9898\uff0c\u540c\u65f6\u786e\u4fdd\u70ed\u529b\u5b66\u539f\u7406\uff08\u5982\u81ea\u7531\u80fd\u5b88\u6052\u548c\u71b5\u751f\u6210\uff09\u5728\u53c2\u6570\u7a7a\u95f4\u4e2d\u5f97\u4ee5\u4fdd\u7559\u3002", "method": "\u7ed3\u5408\u81ea\u7f16\u7801\u5668\u964d\u7ef4\u548cpGFINNs\uff0c\u91c7\u7528\u7269\u7406\u4fe1\u606f\u4e3b\u52a8\u5b66\u4e60\u7b56\u7565\uff0c\u901a\u8fc7\u6b8b\u5dee\u8bef\u5dee\u6307\u6807\u81ea\u9002\u5e94\u91c7\u6837\u8bad\u7ec3\u6570\u636e\u3002", "result": "\u5728Burgers\u65b9\u7a0b\u548c1D/1V Vlasov-Poisson\u65b9\u7a0b\u4e0a\u5b9e\u73b0\u6700\u9ad83,528\u500d\u52a0\u901f\uff0c\u76f8\u5bf9\u8bef\u5dee1-3%\uff0c\u8bad\u7ec3\u548c\u63a8\u7406\u6210\u672c\u663e\u8457\u964d\u4f4e\u3002", "conclusion": "tLaSDI\u6846\u67b6\u4e0d\u4ec5\u9ad8\u6548\u4e14\u51c6\u786e\uff0c\u8fd8\u80fd\u63ed\u793a\u7cfb\u7edf\u7684\u6f5c\u5728\u70ed\u529b\u5b66\u884c\u4e3a\uff0c\u4e3a\u7269\u7406\u7a7a\u95f4\u52a8\u529b\u5b66\u63d0\u4f9b\u65b0\u89c1\u89e3\u3002"}}
{"id": "2506.08505", "pdf": "https://arxiv.org/pdf/2506.08505", "abs": "https://arxiv.org/abs/2506.08505", "authors": ["Shahaf Bassan", "Yizhak Yisrael Elboher", "Tobias Ladner", "Matthias Althoff", "Guy Katz"], "title": "Explaining, Fast and Slow: Abstraction and Refinement of Provable Explanations", "categories": ["cs.LG", "cs.AI", "cs.LO"], "comment": "To appear in ICML 2025", "summary": "Despite significant advancements in post-hoc explainability techniques for\nneural networks, many current methods rely on heuristics and do not provide\nformally provable guarantees over the explanations provided. Recent work has\nshown that it is possible to obtain explanations with formal guarantees by\nidentifying subsets of input features that are sufficient to determine that\npredictions remain unchanged using neural network verification techniques.\nDespite the appeal of these explanations, their computation faces significant\nscalability challenges. In this work, we address this gap by proposing a novel\nabstraction-refinement technique for efficiently computing provably sufficient\nexplanations of neural network predictions. Our method abstracts the original\nlarge neural network by constructing a substantially reduced network, where a\nsufficient explanation of the reduced network is also provably sufficient for\nthe original network, hence significantly speeding up the verification process.\nIf the explanation is in sufficient on the reduced network, we iteratively\nrefine the network size by gradually increasing it until convergence. Our\nexperiments demonstrate that our approach enhances the efficiency of obtaining\nprovably sufficient explanations for neural network predictions while\nadditionally providing a fine-grained interpretation of the network's\npredictions across different abstraction levels.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u62bd\u8c61-\u7ec6\u5316\u6280\u672f\uff0c\u7528\u4e8e\u9ad8\u6548\u8ba1\u7b97\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u7684\u53ef\u8bc1\u660e\u5145\u5206\u89e3\u91ca\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u53ef\u6269\u5c55\u6027\u4e0a\u7684\u6311\u6218\u3002", "motivation": "\u5c3d\u7ba1\u540e\u9a8c\u89e3\u91ca\u6280\u672f\u5728\u795e\u7ecf\u7f51\u7edc\u4e2d\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u8bb8\u591a\u65b9\u6cd5\u4f9d\u8d56\u542f\u53d1\u5f0f\u4e14\u7f3a\u4e4f\u5f62\u5f0f\u5316\u4fdd\u8bc1\u3002\u672c\u7814\u7a76\u65e8\u5728\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u5f62\u5f0f\u5316\u4fdd\u8bc1\u89e3\u91ca\u3002", "method": "\u901a\u8fc7\u6784\u5efa\u4e00\u4e2a\u663e\u8457\u7b80\u5316\u7684\u7f51\u7edc\u6765\u62bd\u8c61\u539f\u59cb\u5927\u578b\u795e\u7ecf\u7f51\u7edc\uff0c\u9010\u6b65\u7ec6\u5316\u7f51\u7edc\u89c4\u6a21\u76f4\u81f3\u6536\u655b\uff0c\u4ee5\u9ad8\u6548\u9a8c\u8bc1\u89e3\u91ca\u7684\u5145\u5206\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u83b7\u53d6\u53ef\u8bc1\u660e\u5145\u5206\u89e3\u91ca\u7684\u6548\u7387\uff0c\u5e76\u63d0\u4f9b\u4e86\u7f51\u7edc\u9884\u6d4b\u7684\u591a\u5c42\u6b21\u7ec6\u7c92\u5ea6\u89e3\u91ca\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u4fdd\u8bc1\u89e3\u91ca\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684\u540c\u65f6\uff0c\u63d0\u5347\u4e86\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u63d0\u4f9b\u4e86\u66f4\u6df1\u5165\u7684\u7406\u89e3\u3002"}}
{"id": "2506.08514", "pdf": "https://arxiv.org/pdf/2506.08514", "abs": "https://arxiv.org/abs/2506.08514", "authors": ["Jacob Piland", "Chris Sweet", "Adam Czakja"], "title": "DiffGradCAM: A Universal Class Activation Map Resistant to Adversarial Training", "categories": ["cs.LG"], "comment": null, "summary": "Class Activation Mapping (CAM) and its gradient-based variants (e.g.,\nGradCAM) have become standard tools for explaining Convolutional Neural Network\n(CNN) predictions. However, these approaches typically focus on individual\nlogits, while for neural networks using softmax, the class membership\nprobability estimates depend \\textit{only} on the \\textit{differences} between\nlogits, not on their absolute values. This disconnect leaves standard CAMs\nvulnerable to adversarial manipulation, such as passive fooling, where a model\nis trained to produce misleading CAMs without affecting decision performance.\nWe introduce \\textbf{Salience-Hoax Activation Maps (SHAMs)}, an\n\\emph{entropy-aware form of passive fooling} that serves as a benchmark for CAM\nrobustness under adversarial conditions. To address the passive fooling\nvulnerability, we then propose \\textbf{DiffGradCAM}, a novel, lightweight, and\ncontrastive approach to class activation mapping that is both non-suceptible to\npassive fooling, but also matches the output of standard CAM methods such as\nGradCAM in the non-adversarial case. Together, SHAM and DiffGradCAM establish a\nnew framework for probing and improving the robustness of saliency-based\nexplanations. We validate both contributions across multi-class tasks with few\nand many classes.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86SHAMs\u548cDiffGradCAM\uff0c\u5206\u522b\u7528\u4e8e\u6d4b\u8bd5\u548c\u6539\u8fdbCAM\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfCAM\u5728\u5bf9\u6297\u6761\u4ef6\u4e0b\u6613\u53d7\u88ab\u52a8\u6b3a\u9a97\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edfCAM\u65b9\u6cd5\u4ec5\u5173\u6ce8\u5355\u4e2alogits\uff0c\u800csoftmax\u8f93\u51fa\u7684\u6982\u7387\u4f30\u8ba1\u4f9d\u8d56\u4e8elogits\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u8fd9\u5bfc\u81f4CAM\u6613\u53d7\u88ab\u52a8\u6b3a\u9a97\u653b\u51fb\u3002", "method": "\u63d0\u51faSHAMs\u4f5c\u4e3a\u5bf9\u6297\u6761\u4ef6\u4e0b\u7684\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u5e76\u8bbe\u8ba1DiffGradCAM\uff0c\u4e00\u79cd\u8f7b\u91cf\u7ea7\u4e14\u5bf9\u6bd4\u6027\u7684CAM\u65b9\u6cd5\uff0c\u4ee5\u62b5\u5fa1\u88ab\u52a8\u6b3a\u9a97\u3002", "result": "SHAMs\u548cDiffGradCAM\u5728\u591a\u7c7b\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\uff0cDiffGradCAM\u5728\u975e\u5bf9\u6297\u60c5\u51b5\u4e0b\u4e0e\u4f20\u7edfCAM\u65b9\u6cd5\u8868\u73b0\u4e00\u81f4\u3002", "conclusion": "SHAMs\u548cDiffGradCAM\u4e3a\u57fa\u4e8e\u663e\u8457\u6027\u7684\u89e3\u91ca\u65b9\u6cd5\u63d0\u4f9b\u4e86\u65b0\u7684\u9c81\u68d2\u6027\u6d4b\u8bd5\u548c\u6539\u8fdb\u6846\u67b6\u3002"}}
{"id": "2506.08516", "pdf": "https://arxiv.org/pdf/2506.08516", "abs": "https://arxiv.org/abs/2506.08516", "authors": ["Mouadh Yagoubi", "David Danan", "Milad Leyli-Abadi", "Ahmed Mazari", "Jean-Patrick Brunet", "Abbas Kabalan", "Fabien Casenave", "Yuxin Ma", "Giovanni Catalani", "Jean Fesquet", "Jacob Helwig", "Xuan Zhang", "Haiyang Yu", "Xavier Bertrand", "Frederic Tost", "Michael Baurheim", "Joseph Morlier", "Shuiwang Ji"], "title": "NeurIPS 2024 ML4CFD Competition: Results and Retrospective Analysis", "categories": ["cs.LG"], "comment": null, "summary": "The integration of machine learning (ML) into the physical sciences is\nreshaping computational paradigms, offering the potential to accelerate\ndemanding simulations such as computational fluid dynamics (CFD). Yet,\npersistent challenges in accuracy, generalization, and physical consistency\nhinder the practical deployment of ML models in scientific domains. To address\nthese limitations and systematically benchmark progress, we organized the\nML4CFD competition, centered on surrogate modeling for aerodynamic simulations\nover two-dimensional airfoils. The competition attracted over 240 teams, who\nwere provided with a curated dataset generated via OpenFOAM and evaluated\nthrough a multi-criteria framework encompassing predictive accuracy, physical\nfidelity, computational efficiency, and out-of-distribution generalization.\nThis retrospective analysis reviews the competition outcomes, highlighting\nseveral approaches that outperformed baselines under our global evaluation\nscore. Notably, the top entry exceeded the performance of the original OpenFOAM\nsolver on aggregate metrics, illustrating the promise of ML-based surrogates to\noutperform traditional solvers under tailored criteria. Drawing from these\nresults, we analyze the key design principles of top submissions, assess the\nrobustness of our evaluation framework, and offer guidance for future\nscientific ML challenges.", "AI": {"tldr": "ML4CFD\u7ade\u8d5b\u901a\u8fc7\u57fa\u51c6\u6d4b\u8bd5\u5c55\u793a\u4e86\u673a\u5668\u5b66\u4e60\u5728\u8ba1\u7b97\u6d41\u4f53\u52a8\u529b\u5b66\u4e2d\u7684\u6f5c\u529b\uff0c\u90e8\u5206\u6a21\u578b\u6027\u80fd\u8d85\u8fc7\u4f20\u7edf\u6c42\u89e3\u5668\u3002", "motivation": "\u89e3\u51b3\u673a\u5668\u5b66\u4e60\u5728\u79d1\u5b66\u9886\u57df\u4e2d\u51c6\u786e\u6027\u3001\u6cdb\u5316\u6027\u548c\u7269\u7406\u4e00\u81f4\u6027\u65b9\u9762\u7684\u6311\u6218\uff0c\u63a8\u52a8\u5176\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u7ec4\u7ec7ML4CFD\u7ade\u8d5b\uff0c\u63d0\u4f9bOpenFOAM\u751f\u6210\u7684\u6570\u636e\u96c6\uff0c\u591a\u6807\u51c6\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u3002", "result": "\u7ade\u8d5b\u4e2d\u90e8\u5206\u6a21\u578b\u5728\u7efc\u5408\u6307\u6807\u4e0a\u8d85\u8fc7OpenFOAM\u6c42\u89e3\u5668\uff0c\u5c55\u793a\u4e86ML\u66ff\u4ee3\u6a21\u578b\u7684\u6f5c\u529b\u3002", "conclusion": "\u603b\u7ed3\u4e86\u7ade\u8d5b\u7ed3\u679c\uff0c\u5206\u6790\u4e86\u4f18\u79c0\u6a21\u578b\u7684\u8bbe\u8ba1\u539f\u5219\uff0c\u4e3a\u672a\u6765\u79d1\u5b66ML\u6311\u6218\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2506.08523", "pdf": "https://arxiv.org/pdf/2506.08523", "abs": "https://arxiv.org/abs/2506.08523", "authors": ["Pedro Jim\u00e9nez-Gonz\u00e1lez", "Miguel C. Soriano", "Lucas Lacasa"], "title": "Leveraging chaos in the training of artificial neural networks", "categories": ["cs.LG", "cond-mat.dis-nn", "nlin.CD", "physics.data-an"], "comment": null, "summary": "Traditional algorithms to optimize artificial neural networks when confronted\nwith a supervised learning task are usually exploitation-type relaxational\ndynamics such as gradient descent (GD). Here, we explore the dynamics of the\nneural network trajectory along training for unconventionally large learning\nrates. We show that for a region of values of the learning rate, the GD\noptimization shifts away from purely exploitation-like algorithm into a regime\nof exploration-exploitation balance, as the neural network is still capable of\nlearning but the trajectory shows sensitive dependence on initial conditions --\nas characterized by positive network maximum Lyapunov exponent --.\nInterestingly, the characteristic training time required to reach an acceptable\naccuracy in the test set reaches a minimum precisely in such learning rate\nregion, further suggesting that one can accelerate the training of artificial\nneural networks by locating at the onset of chaos. Our results -- initially\nillustrated for the MNIST classification task -- qualitatively hold for a range\nof supervised learning tasks, learning architectures and other hyperparameters,\nand showcase the emergent, constructive role of transient chaotic dynamics in\nthe training of artificial neural networks.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u5f02\u5e38\u5927\u5b66\u4e60\u7387\u4e0b\u68af\u5ea6\u4e0b\u964d\uff08GD\uff09\u4f18\u5316\u795e\u7ecf\u7f51\u7edc\u7684\u52a8\u6001\uff0c\u53d1\u73b0\u5b66\u4e60\u7387\u5728\u7279\u5b9a\u8303\u56f4\u5185\u65f6\uff0cGD\u4f1a\u4ece\u7eaf\u5229\u7528\u8f6c\u5411\u63a2\u7d22-\u5229\u7528\u5e73\u8861\uff0c\u4e14\u8bad\u7ec3\u65f6\u95f4\u6700\u77ed\u3002", "motivation": "\u7814\u7a76\u795e\u7ecf\u7f51\u7edc\u5728\u76d1\u7763\u5b66\u4e60\u4efb\u52a1\u4e2d\uff0c\u4f20\u7edf\u4f18\u5316\u7b97\u6cd5\uff08\u5982\u68af\u5ea6\u4e0b\u964d\uff09\u7684\u5c40\u9650\u6027\uff0c\u63a2\u7d22\u5927\u5b66\u4e60\u7387\u4e0b\u7684\u52a8\u6001\u884c\u4e3a\u53ca\u5176\u5bf9\u8bad\u7ec3\u6548\u7387\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u5206\u6790\u795e\u7ecf\u7f51\u7edc\u8f68\u8ff9\u7684\u6700\u5927Lyapunov\u6307\u6570\uff0c\u7814\u7a76\u5b66\u4e60\u7387\u5bf9\u8bad\u7ec3\u52a8\u6001\u7684\u5f71\u54cd\uff0c\u5e76\u5728MNIST\u5206\u7c7b\u4efb\u52a1\u7b49\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u3002", "result": "\u53d1\u73b0\u7279\u5b9a\u5b66\u4e60\u7387\u8303\u56f4\u5185\uff0cGD\u8868\u73b0\u51fa\u63a2\u7d22-\u5229\u7528\u5e73\u8861\uff0c\u4e14\u8bad\u7ec3\u65f6\u95f4\u6700\u77ed\uff0c\u8868\u660e\u6df7\u6c8c\u52a8\u6001\u5bf9\u8bad\u7ec3\u6709\u79ef\u6781\u4f5c\u7528\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5728\u6df7\u6c8c\u8d77\u59cb\u70b9\u9644\u8fd1\u8bbe\u7f6e\u5b66\u4e60\u7387\u53ef\u4ee5\u52a0\u901f\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\uff0c\u4e3a\u4f18\u5316\u7b97\u6cd5\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.08533", "pdf": "https://arxiv.org/pdf/2506.08533", "abs": "https://arxiv.org/abs/2506.08533", "authors": ["Nihal Acharya Adde", "Alexandra Gianzina", "Hanno Gottschalk", "Andreas Ebert"], "title": "Robust Evolutionary Multi-Objective Network Architecture Search for Reinforcement Learning (EMNAS-RL)", "categories": ["cs.LG", "cs.AI", "math.OC"], "comment": "Published at ESANN 2025 Conference", "summary": "This paper introduces Evolutionary Multi-Objective Network Architecture\nSearch (EMNAS) for the first time to optimize neural network architectures in\nlarge-scale Reinforcement Learning (RL) for Autonomous Driving (AD). EMNAS uses\ngenetic algorithms to automate network design, tailored to enhance rewards and\nreduce model size without compromising performance. Additionally,\nparallelization techniques are employed to accelerate the search, and\nteacher-student methodologies are implemented to ensure scalable optimization.\nThis research underscores the potential of transfer learning as a robust\nframework for optimizing performance across iterative learning processes by\neffectively leveraging knowledge from earlier generations to enhance learning\nefficiency and stability in subsequent generations. Experimental results\ndemonstrate that tailored EMNAS outperforms manually designed models, achieving\nhigher rewards with fewer parameters. The findings of these strategies\ncontribute positively to EMNAS for RL in autonomous driving, advancing the\nfield toward better-performing networks suitable for real-world scenarios.", "AI": {"tldr": "EMNAS\u9996\u6b21\u63d0\u51fa\u7528\u4e8e\u81ea\u52a8\u9a7e\u9a76\u5f3a\u5316\u5b66\u4e60\u7684\u591a\u76ee\u6807\u7f51\u7edc\u67b6\u6784\u641c\u7d22\uff0c\u901a\u8fc7\u9057\u4f20\u7b97\u6cd5\u4f18\u5316\u7f51\u7edc\u8bbe\u8ba1\uff0c\u63d0\u5347\u5956\u52b1\u5e76\u51cf\u5c11\u6a21\u578b\u5927\u5c0f\uff0c\u540c\u65f6\u91c7\u7528\u5e76\u884c\u5316\u548c\u5e08\u751f\u65b9\u6cd5\u52a0\u901f\u641c\u7d22\u3002\u5b9e\u9a8c\u8868\u660e\u5176\u4f18\u4e8e\u4eba\u5de5\u8bbe\u8ba1\u6a21\u578b\u3002", "motivation": "\u4f18\u5316\u81ea\u52a8\u9a7e\u9a76\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u63d0\u5347\u6027\u80fd\u5e76\u51cf\u5c11\u6a21\u578b\u590d\u6742\u5ea6\uff0c\u540c\u65f6\u63a2\u7d22\u8fc1\u79fb\u5b66\u4e60\u5728\u8fed\u4ee3\u5b66\u4e60\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u4f7f\u7528\u9057\u4f20\u7b97\u6cd5\u81ea\u52a8\u5316\u7f51\u7edc\u8bbe\u8ba1\uff0c\u7ed3\u5408\u5e76\u884c\u5316\u6280\u672f\u548c\u5e08\u751f\u65b9\u6cd5\u52a0\u901f\u641c\u7d22\u4e0e\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eEMNAS\u5728\u5956\u52b1\u548c\u53c2\u6570\u6548\u7387\u4e0a\u4f18\u4e8e\u4eba\u5de5\u8bbe\u8ba1\u6a21\u578b\u3002", "conclusion": "EMNAS\u4e3a\u81ea\u52a8\u9a7e\u9a76\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u9ad8\u6548\u7f51\u7edc\u67b6\u6784\u4f18\u5316\u65b9\u6cd5\uff0c\u63a8\u52a8\u9886\u57df\u53d1\u5c55\u3002"}}
{"id": "2506.08551", "pdf": "https://arxiv.org/pdf/2506.08551", "abs": "https://arxiv.org/abs/2506.08551", "authors": ["Panlong Wu", "Ting Wang", "Yifei Zhong", "Haoqi Zhang", "Zitong Wang", "Fangxin Wang"], "title": "DeepForm: Reasoning Large Language Model for Communication System Formulation", "categories": ["cs.LG"], "comment": null, "summary": "Communication system formulation is critical for advancing 6G and future\nwireless technologies, yet it remains a complex, expertise-intensive task.\nWhile Large Language Models (LLMs) offer potential, existing general-purpose\nmodels often lack the specialized domain knowledge, nuanced reasoning\ncapabilities, and access to high-quality, domain-specific training data\nrequired for adapting a general LLM into an LLM specially for communication\nsystem formulation. To bridge this gap, we introduce DeepForm, the first\nreasoning LLM specially for automated communication system formulation. We\npropose the world-first large-scale, open-source dataset meticulously curated\nfor this domain called Communication System Formulation Reasoning Corpus\n(CSFRC). Our framework employs a two-stage training strategy: first, Supervised\nFine-Tuning (SFT) with Chain-of-Thought (CoT) data to distill domain knowledge;\nsecond, a novel rule-based Reinforcement Learning (RL) algorithm, C-ReMax based\non ReMax, to cultivate advanced modeling capabilities and elicit sophisticated\nreasoning patterns like self-correction and verification. Extensive experiments\ndemonstrate that our model achieves state-of-the-art performance, significantly\noutperforming larger proprietary LLMs on diverse senerios. We will release\nrelated resources to foster further research in this area after the paper is\naccepted.", "AI": {"tldr": "DeepForm\u662f\u9996\u4e2a\u4e13\u4e3a\u901a\u4fe1\u7cfb\u7edf\u8bbe\u8ba1\u4f18\u5316\u7684\u63a8\u7406\u578b\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u548c\u9ad8\u8d28\u91cf\u6570\u636e\u96c6CSFRC\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7f3a\u4e4f\u901a\u4fe1\u7cfb\u7edf\u8bbe\u8ba1\u6240\u9700\u7684\u4e13\u4e1a\u77e5\u8bc6\u548c\u63a8\u7406\u80fd\u529b\uff0cDeepForm\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\uff1a\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u5f3a\u5316\u5b66\u4e60\uff08C-ReMax\uff09\uff0c\u7ed3\u5408\u9ad8\u8d28\u91cf\u6570\u636e\u96c6CSFRC\u3002", "result": "DeepForm\u5728\u591a\u79cd\u573a\u666f\u4e0b\u8868\u73b0\u4f18\u5f02\uff0c\u663e\u8457\u8d85\u8d8a\u73b0\u6709\u5927\u578b\u4e13\u6709\u6a21\u578b\u3002", "conclusion": "DeepForm\u4e3a\u901a\u4fe1\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u9ad8\u6548\u5de5\u5177\uff0c\u672a\u6765\u5c06\u516c\u5f00\u8d44\u6e90\u4ee5\u63a8\u52a8\u76f8\u5173\u7814\u7a76\u3002"}}
{"id": "2506.08572", "pdf": "https://arxiv.org/pdf/2506.08572", "abs": "https://arxiv.org/abs/2506.08572", "authors": ["Waiss Azizian", "Michael Kirchhof", "Eugene Ndiaye", "Louis Bethune", "Michal Klein", "Pierre Ablin", "Marco Cuturi"], "title": "The Geometries of Truth Are Orthogonal Across Tasks", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated impressive generalization\ncapabilities across various tasks, but their claim to practical relevance is\nstill mired by concerns on their reliability. Recent works have proposed\nexamining the activations produced by an LLM at inference time to assess\nwhether its answer to a question is correct. Some works claim that a \"geometry\nof truth\" can be learned from examples, in the sense that the activations that\ngenerate correct answers can be distinguished from those leading to mistakes\nwith a linear classifier. In this work, we underline a limitation of these\napproaches: we observe that these \"geometries of truth\" are intrinsically\ntask-dependent and fail to transfer across tasks. More precisely, we show that\nlinear classifiers trained across distinct tasks share little similarity and,\nwhen trained with sparsity-enforcing regularizers, have almost disjoint\nsupports. We show that more sophisticated approaches (e.g., using mixtures of\nprobes and tasks) fail to overcome this limitation, likely because activation\nvectors commonly used to classify answers form clearly separated clusters when\nexamined across tasks.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u57fa\u4e8eLLM\u6fc0\u6d3b\u7684\u7ebf\u6027\u5206\u7c7b\u5668\u5728\u4e0d\u540c\u4efb\u52a1\u95f4\u7f3a\u4e4f\u901a\u7528\u6027\uff0c\u65e0\u6cd5\u6709\u6548\u533a\u5206\u6b63\u786e\u4e0e\u9519\u8bef\u7b54\u6848\u3002", "motivation": "\u63a2\u8ba8LLM\u5728\u63a8\u7406\u65f6\u751f\u6210\u7684\u6fc0\u6d3b\u662f\u5426\u80fd\u53ef\u9760\u533a\u5206\u7b54\u6848\u7684\u6b63\u786e\u6027\uff0c\u5e76\u9a8c\u8bc1\u5176\u4efb\u52a1\u95f4\u7684\u901a\u7528\u6027\u3002", "method": "\u901a\u8fc7\u8bad\u7ec3\u7ebf\u6027\u5206\u7c7b\u5668\u5206\u6790\u4e0d\u540c\u4efb\u52a1\u95f4\u7684\u6fc0\u6d3b\u6a21\u5f0f\uff0c\u5e76\u4f7f\u7528\u7a00\u758f\u6b63\u5219\u5316\u7b49\u65b9\u6cd5\u9a8c\u8bc1\u5176\u5c40\u9650\u6027\u3002", "result": "\u7ebf\u6027\u5206\u7c7b\u5668\u5728\u4e0d\u540c\u4efb\u52a1\u95f4\u76f8\u4f3c\u6027\u4f4e\uff0c\u7a00\u758f\u6b63\u5219\u5316\u540e\u652f\u6301\u96c6\u51e0\u4e4e\u4e0d\u91cd\u53e0\uff0c\u590d\u6742\u65b9\u6cd5\u4e5f\u65e0\u6cd5\u89e3\u51b3\u3002", "conclusion": "LLM\u6fc0\u6d3b\u7684\u201c\u771f\u7406\u51e0\u4f55\u201d\u5177\u6709\u4efb\u52a1\u4f9d\u8d56\u6027\uff0c\u96be\u4ee5\u8de8\u4efb\u52a1\u901a\u7528\u3002"}}
{"id": "2506.08574", "pdf": "https://arxiv.org/pdf/2506.08574", "abs": "https://arxiv.org/abs/2506.08574", "authors": ["Alvise Dei Rossi", "Matteo Metaldi", "Michal Bechny", "Irina Filchenko", "Julia van der Meer", "Markus H. Schmidt", "Claudio L. A. Bassetti", "Athina Tzovara", "Francesca D. Faraci", "Luigi Fiorillo"], "title": "SLEEPYLAND: trust begins with fair evaluation of automatic sleep staging models", "categories": ["cs.LG"], "comment": "41 pages, 4 Figures, 7 Tables", "summary": "Despite advances in deep learning for automatic sleep staging, clinical\nadoption remains limited due to challenges in fair model evaluation,\ngeneralization across diverse datasets, model bias, and variability in human\nannotations. We present SLEEPYLAND, an open-source sleep staging evaluation\nframework designed to address these barriers. It includes more than 22'0000\nhours in-domain (ID) sleep recordings, and more than 84'000 hours out-of-domain\n(OOD) sleep recordings, spanning a broad range of ages, sleep-wake disorders,\nand hardware setups. We release pre-trained models based on high-performing SoA\narchitectures and evaluate them under standardized conditions across single-\nand multi-channel EEG/EOG configurations. We introduce SOMNUS, an ensemble\ncombining models across architectures and channel setups via soft voting.\nSOMNUS achieves robust performance across twenty-four different datasets, with\nmacro-F1 scores between 68.7% and 87.2%, outperforming individual models in\n94.9% of cases. Notably, SOMNUS surpasses previous SoA methods, even including\ncases where compared models were trained ID while SOMNUS treated the same data\nas OOD. Using a subset of the BSWR (N=6'633), we quantify model biases linked\nto age, gender, AHI, and PLMI, showing that while ensemble improves robustness,\nno model architecture consistently minimizes bias in performance and clinical\nmarkers estimation. In evaluations on OOD multi-annotated datasets (DOD-H,\nDOD-O), SOMNUS exceeds the best human scorer, i.e., MF1 85.2% vs 80.8% on\nDOD-H, and 80.2% vs 75.9% on DOD-O, better reproducing the scorer consensus\nthan any individual expert (k = 0.89/0.85 and ACS = 0.95/0.94 for healthy/OSA\ncohorts). Finally, we introduce ensemble disagreement metrics - entropy and\ninter-model divergence based - predicting regions of scorer disagreement with\nROC AUCs up to 0.828, offering a data-driven proxy for human uncertainty.", "AI": {"tldr": "SLEEPYLAND\u662f\u4e00\u4e2a\u5f00\u6e90\u7761\u7720\u5206\u671f\u8bc4\u4f30\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u6a21\u578b\u8bc4\u4f30\u4e0d\u516c\u5e73\u3001\u6cdb\u5316\u80fd\u529b\u5dee\u3001\u6a21\u578b\u504f\u89c1\u548c\u4eba\u5de5\u6807\u6ce8\u5dee\u5f02\u7b49\u95ee\u9898\u3002\u901a\u8fc7SOMNUS\u96c6\u6210\u6a21\u578b\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u751a\u81f3\u8d85\u8d8a\u4eba\u7c7b\u4e13\u5bb6\u3002", "motivation": "\u5f53\u524d\u6df1\u5ea6\u5b66\u4e60\u5728\u81ea\u52a8\u7761\u7720\u5206\u671f\u4e2d\u9762\u4e34\u6a21\u578b\u8bc4\u4f30\u4e0d\u516c\u5e73\u3001\u6cdb\u5316\u80fd\u529b\u5dee\u3001\u504f\u89c1\u548c\u4eba\u5de5\u6807\u6ce8\u5dee\u5f02\u7b49\u6311\u6218\uff0c\u9650\u5236\u4e86\u4e34\u5e8a\u5e94\u7528\u3002", "method": "\u63d0\u51faSLEEPYLAND\u6846\u67b6\uff0c\u5305\u542b\u5927\u91cfID\u548cOOD\u7761\u7720\u6570\u636e\uff0c\u5e76\u5f00\u53d1SOMNUS\u96c6\u6210\u6a21\u578b\uff0c\u901a\u8fc7\u8f6f\u6295\u7968\u7ed3\u5408\u591a\u79cd\u67b6\u6784\u548c\u901a\u9053\u914d\u7f6e\u3002", "result": "SOMNUS\u572824\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u7a33\u5065\uff0c\u5b8fF1\u5206\u657068.7%-87.2%\uff0c\u8d85\u8d8a\u5355\u6a21\u578b\u548c\u4eba\u7c7b\u4e13\u5bb6\u3002\u540c\u65f6\u91cf\u5316\u4e86\u6a21\u578b\u504f\u89c1\uff0c\u5e76\u5f15\u5165\u9884\u6d4b\u4eba\u7c7b\u4e0d\u786e\u5b9a\u6027\u7684\u6307\u6807\u3002", "conclusion": "SLEEPYLAND\u548cSOMNUS\u663e\u8457\u63d0\u5347\u4e86\u7761\u7720\u5206\u671f\u7684\u6027\u80fd\u548c\u9c81\u68d2\u6027\uff0c\u4f46\u4ecd\u9700\u89e3\u51b3\u6a21\u578b\u504f\u89c1\u95ee\u9898\u3002"}}
{"id": "2506.08577", "pdf": "https://arxiv.org/pdf/2506.08577", "abs": "https://arxiv.org/abs/2506.08577", "authors": ["Nicholas A. Pearson", "Francesca Cairoli", "Luca Bortolussi", "Davide Russo", "Francesca Zanello"], "title": "Diffusion-based Time Series Forecasting for Sewerage Systems", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted for presentation at the 13th Urban Drainage Modelling\n  Conference, Innsbruck (Austria), September 2025", "summary": "We introduce a novel deep learning approach that harnesses the power of\ngenerative artificial intelligence to enhance the accuracy of contextual\nforecasting in sewerage systems. By developing a diffusion-based model that\nprocesses multivariate time series data, our system excels at capturing complex\ncorrelations across diverse environmental signals, enabling robust predictions\neven during extreme weather events. To strengthen the model's reliability, we\nfurther calibrate its predictions with a conformal inference technique,\ntailored for probabilistic time series data, ensuring that the resulting\nprediction intervals are statistically reliable and cover the true target\nvalues with a desired confidence level. Our empirical tests on real sewerage\nsystem data confirm the model's exceptional capability to deliver reliable\ncontextual predictions, maintaining accuracy even under severe weather\nconditions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u63d0\u5347\u6c61\u6c34\u7cfb\u7edf\u4e0a\u4e0b\u6587\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u901a\u8fc7\u6269\u6563\u6a21\u578b\u5904\u7406\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u5e76\u7ed3\u5408\u4fdd\u5f62\u63a8\u7406\u6280\u672f\u786e\u4fdd\u9884\u6d4b\u533a\u95f4\u7684\u7edf\u8ba1\u53ef\u9760\u6027\u3002", "motivation": "\u63d0\u5347\u6c61\u6c34\u7cfb\u7edf\u5728\u6781\u7aef\u5929\u6c14\u6761\u4ef6\u4e0b\u7684\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u6355\u6349\u590d\u6742\u7684\u73af\u5883\u4fe1\u53f7\u5173\u8054\u3002", "method": "\u5f00\u53d1\u6269\u6563\u6a21\u578b\u5904\u7406\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u7ed3\u5408\u4fdd\u5f62\u63a8\u7406\u6280\u672f\u6821\u51c6\u9884\u6d4b\u533a\u95f4\u3002", "result": "\u5b9e\u8bc1\u6d4b\u8bd5\u663e\u793a\u6a21\u578b\u5728\u6781\u7aef\u5929\u6c14\u4e0b\u4ecd\u80fd\u4fdd\u6301\u9ad8\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6c61\u6c34\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u4e0a\u4e0b\u6587\u9884\u6d4b\u5de5\u5177\uff0c\u5c24\u5176\u5728\u6076\u52a3\u5929\u6c14\u6761\u4ef6\u4e0b\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2506.08600", "pdf": "https://arxiv.org/pdf/2506.08600", "abs": "https://arxiv.org/abs/2506.08600", "authors": ["Hiroshi Kera", "Shun Arakawa", "Yuta Sato"], "title": "CALT: A Library for Computer Algebra with Transformer", "categories": ["cs.LG", "cs.SC", "math.AC"], "comment": "ISSAC 2025 Short Communications", "summary": "Recent advances in artificial intelligence have demonstrated the learnability\nof symbolic computation through end-to-end deep learning. Given a sufficient\nnumber of examples of symbolic expressions before and after the target\ncomputation, Transformer models - highly effective learners of\nsequence-to-sequence functions - can be trained to emulate the computation.\nThis development opens up several intriguing challenges and new research\ndirections, which require active contributions from the symbolic computation\ncommunity. In this work, we introduce Computer Algebra with Transformer (CALT),\na user-friendly Python library designed to help non-experts in deep learning\ntrain models for symbolic computation tasks.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8eTransformer\u7684\u7b26\u53f7\u8ba1\u7b97\u5e93CALT\uff0c\u5e2e\u52a9\u975e\u6df1\u5ea6\u5b66\u4e60\u4e13\u5bb6\u8bad\u7ec3\u7b26\u53f7\u8ba1\u7b97\u6a21\u578b\u3002", "motivation": "\u8fd1\u5e74\u6765AI\u5728\u7b26\u53f7\u8ba1\u7b97\u4e2d\u7684\u53ef\u5b66\u4e60\u6027\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u9700\u8981\u7b26\u53f7\u8ba1\u7b97\u793e\u533a\u7684\u79ef\u6781\u53c2\u4e0e\u3002", "method": "\u5229\u7528Transformer\u6a21\u578b\u8bad\u7ec3\u5e8f\u5217\u5230\u5e8f\u5217\u51fd\u6570\uff0c\u901a\u8fc7\u5927\u91cf\u7b26\u53f7\u8868\u8fbe\u5f0f\u793a\u4f8b\u6a21\u62df\u8ba1\u7b97\u3002", "result": "\u5f00\u53d1\u4e86CALT\u5e93\uff0c\u4e3a\u975e\u4e13\u5bb6\u63d0\u4f9b\u4fbf\u6377\u7684\u7b26\u53f7\u8ba1\u7b97\u6a21\u578b\u8bad\u7ec3\u5de5\u5177\u3002", "conclusion": "CALT\u4e3a\u7b26\u53f7\u8ba1\u7b97\u9886\u57df\u7684\u7814\u7a76\u548c\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2506.08604", "pdf": "https://arxiv.org/pdf/2506.08604", "abs": "https://arxiv.org/abs/2506.08604", "authors": ["Giacomo Baldan", "Qiang Liu", "Alberto Guardone", "Nils Thuerey"], "title": "Flow Matching Meets PDEs: A Unified Framework for Physics-Constrained Generation", "categories": ["cs.LG", "cs.AI", "cs.CE", "cs.NA", "math.NA"], "comment": null, "summary": "Generative machine learning methods, such as diffusion models and flow\nmatching, have shown great potential in modeling complex system behaviors and\nbuilding efficient surrogate models. However, these methods typically learn the\nunderlying physics implicitly from data. We propose Physics-Based Flow Matching\n(PBFM), a novel generative framework that explicitly embeds physical\nconstraints, both PDE residuals and algebraic relations, into the flow matching\nobjective. We also introduce temporal unrolling at training time that improves\nthe accuracy of the final, noise-free sample prediction. Our method jointly\nminimizes the flow matching loss and the physics-based residual loss without\nrequiring hyperparameter tuning of their relative weights. Additionally, we\nanalyze the role of the minimum noise level, $\\sigma_{\\min}$, in the context of\nphysical constraints and evaluate a stochastic sampling strategy that helps to\nreduce physical residuals. Through extensive benchmarks on three representative\nPDE problems, we show that our approach yields up to an $8\\times$ more accurate\nphysical residuals compared to FM, while clearly outperforming existing\nalgorithms in terms of distributional accuracy. PBFM thus provides a principled\nand efficient framework for surrogate modeling, uncertainty quantification, and\naccelerated simulation in physics and engineering applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPBFM\u7684\u65b0\u751f\u6210\u6846\u67b6\uff0c\u663e\u5f0f\u5d4c\u5165\u7269\u7406\u7ea6\u675f\u5230\u6d41\u5339\u914d\u76ee\u6807\u4e2d\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u7269\u7406\u6b8b\u5dee\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u65b9\u6cd5\uff08\u5982\u6269\u6563\u6a21\u578b\u548c\u6d41\u5339\u914d\uff09\u901a\u5e38\u4ece\u6570\u636e\u4e2d\u9690\u5f0f\u5b66\u4e60\u7269\u7406\u89c4\u5f8b\uff0c\u7f3a\u4e4f\u663e\u5f0f\u7269\u7406\u7ea6\u675f\u7684\u5d4c\u5165\u3002", "method": "\u7ed3\u5408\u6d41\u5339\u914d\u635f\u5931\u548c\u57fa\u4e8e\u7269\u7406\u7684\u6b8b\u5dee\u635f\u5931\uff0c\u5f15\u5165\u65f6\u95f4\u5c55\u5f00\u8bad\u7ec3\uff0c\u5e76\u5206\u6790\u6700\u5c0f\u566a\u58f0\u6c34\u5e73\u7684\u4f5c\u7528\u3002", "result": "\u5728\u4e09\u4e2a\u5178\u578bPDE\u95ee\u9898\u4e0a\uff0cPBFM\u7684\u7269\u7406\u6b8b\u5dee\u6bd4FM\u51c6\u786e8\u500d\uff0c\u4e14\u5728\u5206\u5e03\u51c6\u786e\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u7b97\u6cd5\u3002", "conclusion": "PBFM\u4e3a\u7269\u7406\u548c\u5de5\u7a0b\u5e94\u7528\u4e2d\u7684\u4ee3\u7406\u5efa\u6a21\u3001\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u548c\u52a0\u901f\u6a21\u62df\u63d0\u4f9b\u4e86\u9ad8\u6548\u6846\u67b6\u3002"}}
{"id": "2506.08607", "pdf": "https://arxiv.org/pdf/2506.08607", "abs": "https://arxiv.org/abs/2506.08607", "authors": ["Kiran Purohit", "V Venktesh", "Sourangshu Bhattacharya", "Avishek Anand"], "title": "Sample Efficient Demonstration Selection for In-Context Learning", "categories": ["cs.LG"], "comment": "Accepted at ICML 2025 , 24 pages", "summary": "The in-context learning paradigm with LLMs has been instrumental in advancing\na wide range of natural language processing tasks. The selection of few-shot\nexamples (exemplars / demonstration samples) is essential for constructing\neffective prompts under context-length budget constraints. In this paper, we\nformulate the exemplar selection task as a top-m best arms identification\nproblem. A key challenge in this setup is the exponentially large number of\narms that need to be evaluated to identify the m-best arms. We propose CASE\n(Challenger Arm Sampling for Exemplar selection), a novel sample-efficient\nselective exploration strategy that maintains a shortlist of \"challenger\" arms,\nwhich are current candidates for the top-m arms. In each iteration, only one of\nthe arms from this shortlist or the current topm set is pulled, thereby\nreducing sample complexity and, consequently, the number of LLM evaluations.\nFurthermore, we model the scores of exemplar subsets (arms) using a\nparameterized linear scoring function, leading to stochastic linear bandits\nsetting. CASE achieves remarkable efficiency gains of up to 7x speedup in\nruntime while requiring 7x fewer LLM calls (87% reduction) without sacrificing\nperformance compared to state-of-the-art exemplar selection methods. We release\nour code and data at https://github.com/kiranpurohit/CASE", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCASE\u7684\u9ad8\u6548\u793a\u4f8b\u9009\u62e9\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u793a\u4f8b\u9009\u62e9\u5efa\u6a21\u4e3a\u591a\u81c2\u8001\u864e\u673a\u95ee\u9898\uff0c\u663e\u8457\u51cf\u5c11\u4e86LLM\u8bc4\u4f30\u6b21\u6570\u548c\u8fd0\u884c\u65f6\u5f00\u9500\u3002", "motivation": "\u5728\u4e0a\u4e0b\u6587\u5b66\u4e60\u8303\u5f0f\u4e2d\uff0c\u793a\u4f8b\u9009\u62e9\u5bf9\u6784\u5efa\u9ad8\u6548\u63d0\u793a\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u8bc4\u4f30\u5927\u91cf\u793a\u4f8b\u65f6\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u5c06\u793a\u4f8b\u9009\u62e9\u95ee\u9898\u5efa\u6a21\u4e3a\u591a\u81c2\u8001\u864e\u673a\u95ee\u9898\uff0c\u63d0\u51faCASE\u7b56\u7565\uff0c\u901a\u8fc7\u7ef4\u62a4\u2018\u6311\u6218\u8005\u2019\u81c2\u77ed\u5217\u8868\u51cf\u5c11\u6837\u672c\u590d\u6742\u5ea6\u3002", "result": "CASE\u5b9e\u73b0\u4e867\u500d\u8fd0\u884c\u65f6\u52a0\u901f\u548c87%\u7684LLM\u8c03\u7528\u51cf\u5c11\uff0c\u540c\u65f6\u4fdd\u6301\u6027\u80fd\u3002", "conclusion": "CASE\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u6027\u80fd\u4f18\u8d8a\u7684\u793a\u4f8b\u9009\u62e9\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u4e0a\u4e0b\u6587\u5b66\u4e60\u4efb\u52a1\u3002"}}
{"id": "2506.08618", "pdf": "https://arxiv.org/pdf/2506.08618", "abs": "https://arxiv.org/abs/2506.08618", "authors": ["Xianquan Yan", "Hakan Akg\u00fcn", "Kenji Kawaguchi", "N. Duane Loh", "Ching Hua Lee"], "title": "HSG-12M: A Large-Scale Spatial Multigraph Dataset", "categories": ["cs.LG", "cond-mat.mes-hall", "cond-mat.other", "cs.AI", "cs.CV"], "comment": "39 pages, 13 figures, 3 tables. Code & pipeline:\n  [https://github.com/sarinstein-yan/Poly2Graph] Dataset:\n  [https://github.com/sarinstein-yan/HSG-12M] Dataset released under CC BY 4.0", "summary": "Existing graph benchmarks assume non-spatial, simple edges, collapsing\nphysically distinct paths into a single link. We introduce HSG-12M, the first\nlarge-scale dataset of $\\textbf{spatial multigraphs}-$graphs embedded in a\nmetric space where multiple geometrically distinct trajectories between two\nnodes are retained as separate edges. HSG-12M contains 11.6 million static and\n5.1 million dynamic $\\textit{Hamiltonian spectral graphs}$ across 1401\ncharacteristic-polynomial classes, derived from 177 TB of spectral potential\ndata. Each graph encodes the full geometry of a 1-D crystal's energy spectrum\non the complex plane, producing diverse, physics-grounded topologies that\ntranscend conventional node-coordinate datasets. To enable future extensions,\nwe release $\\texttt{Poly2Graph}$: a high-performance, open-source pipeline that\nmaps arbitrary 1-D crystal Hamiltonians to spectral graphs. Benchmarks with\npopular GNNs expose new challenges in learning from multi-edge geometry at\nscale. Beyond its practical utility, we show that spectral graphs serve as\nuniversal topological fingerprints of polynomials, vectors, and matrices,\nforging a new algebra-to-graph link. HSG-12M lays the groundwork for\ngeometry-aware graph learning and new opportunities of data-driven scientific\ndiscovery in condensed matter physics and beyond.", "AI": {"tldr": "HSG-12M\u662f\u9996\u4e2a\u5927\u89c4\u6a21\u7a7a\u95f4\u591a\u56fe\u6570\u636e\u96c6\uff0c\u5305\u542b\u9759\u6001\u548c\u52a8\u6001\u54c8\u5bc6\u987f\u8c31\u56fe\uff0c\u7528\u4e8e\u51e0\u4f55\u611f\u77e5\u56fe\u5b66\u4e60\u3002", "motivation": "\u73b0\u6709\u56fe\u57fa\u51c6\u5047\u8bbe\u8fb9\u662f\u975e\u7a7a\u95f4\u4e14\u7b80\u5355\u7684\uff0c\u5ffd\u7565\u4e86\u7269\u7406\u4e0a\u4e0d\u540c\u7684\u8def\u5f84\u3002HSG-12M\u586b\u8865\u4e86\u8fd9\u4e00\u7a7a\u767d\uff0c\u4fdd\u7559\u4e86\u591a\u6761\u51e0\u4f55\u8def\u5f84\u3002", "method": "\u901a\u8fc7Poly2Graph\u7ba1\u9053\u5c06\u4e00\u7ef4\u6676\u4f53\u7684\u54c8\u5bc6\u987f\u91cf\u6620\u5c04\u4e3a\u8c31\u56fe\uff0c\u751f\u621011.6M\u9759\u6001\u548c5.1M\u52a8\u6001\u56fe\u3002", "result": "HSG-12M\u5c55\u793a\u4e86\u591a\u8fb9\u51e0\u4f55\u5b66\u4e60\u7684\u65b0\u6311\u6218\uff0c\u5e76\u4f5c\u4e3a\u591a\u9879\u5f0f\u3001\u5411\u91cf\u548c\u77e9\u9635\u7684\u901a\u7528\u62d3\u6251\u6307\u7eb9\u3002", "conclusion": "HSG-12M\u4e3a\u51e0\u4f55\u611f\u77e5\u56fe\u5b66\u4e60\u548c\u6570\u636e\u9a71\u52a8\u7684\u79d1\u5b66\u53d1\u73b0\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.08641", "pdf": "https://arxiv.org/pdf/2506.08641", "abs": "https://arxiv.org/abs/2506.08641", "authors": ["Simon Roschmann", "Quentin Bouniot", "Vasilii Feofanov", "Ievgen Redko", "Zeynep Akata"], "title": "Time Series Representations for Classification Lie Hidden in Pretrained Vision Transformers", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Time series classification is a fundamental task in healthcare and industry,\nyet the development of time series foundation models (TSFMs) remains limited by\nthe scarcity of publicly available time series datasets. In this work, we\npropose Time Vision Transformer (TiViT), a framework that converts time series\ninto images to leverage the representational power of frozen Vision\nTransformers (ViTs) pretrained on large-scale image datasets. First, we\ntheoretically motivate our approach by analyzing the 2D patching of ViTs for\ntime series, showing that it can increase the number of label-relevant tokens\nand reduce the sample complexity. Second, we empirically demonstrate that TiViT\nachieves state-of-the-art performance on standard time series classification\nbenchmarks by utilizing the hidden representations of large OpenCLIP models. We\nexplore the structure of TiViT representations and find that intermediate\nlayers with high intrinsic dimension are the most effective for time series\nclassification. Finally, we assess the alignment between TiViT and TSFM\nrepresentation spaces and identify a strong complementarity, with further\nperformance gains achieved by combining their features. Our findings reveal yet\nanother direction for reusing vision representations in a non-visual domain.", "AI": {"tldr": "TiViT\u6846\u67b6\u5c06\u65f6\u95f4\u5e8f\u5217\u8f6c\u6362\u4e3a\u56fe\u50cf\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u7684\u89c6\u89c9Transformer\uff08ViT\uff09\u8fdb\u884c\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\uff0c\u6027\u80fd\u8fbe\u5230SOTA\u3002", "motivation": "\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\uff08TSFMs\uff09\u7684\u53d1\u5c55\u53d7\u9650\u4e8e\u516c\u5f00\u6570\u636e\u96c6\u7684\u7a00\u7f3a\u6027\uff0cTiViT\u65e8\u5728\u901a\u8fc7\u89c6\u89c9\u8868\u793a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5c06\u65f6\u95f4\u5e8f\u5217\u8f6c\u6362\u4e3a\u56fe\u50cf\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u7684ViT\u6a21\u578b\u63d0\u53d6\u7279\u5f81\uff0c\u5206\u6790\u51762D\u5206\u5757\u5bf9\u65f6\u95f4\u5e8f\u5217\u7684\u5f71\u54cd\u3002", "result": "TiViT\u5728\u6807\u51c6\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u57fa\u51c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4e2d\u95f4\u5c42\u9ad8\u7ef4\u7279\u5f81\u6700\u6709\u6548\u3002\u4e0eTSFM\u7279\u5f81\u7ed3\u5408\u53ef\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "TiViT\u5c55\u793a\u4e86\u89c6\u89c9\u8868\u793a\u5728\u975e\u89c6\u89c9\u9886\u57df\u7684\u590d\u7528\u6f5c\u529b\uff0c\u4e3a\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2506.08644", "pdf": "https://arxiv.org/pdf/2506.08644", "abs": "https://arxiv.org/abs/2506.08644", "authors": ["Woosung Kim", "JunHo Seo", "Jongmin Lee", "Byung-Jun Lee"], "title": "Semi-gradient DICE for Offline Constrained Reinforcement Learning", "categories": ["cs.LG"], "comment": "Constrained Offline Reinforcement Learning", "summary": "Stationary Distribution Correction Estimation (DICE) addresses the mismatch\nbetween the stationary distribution induced by a policy and the target\ndistribution required for reliable off-policy evaluation (OPE) and policy\noptimization. DICE-based offline constrained RL particularly benefits from the\nflexibility of DICE, as it simultaneously maximizes return while estimating\ncosts in offline settings. However, we have observed that recent approaches\ndesigned to enhance the offline RL performance of the DICE framework\ninadvertently undermine its ability to perform OPE, making them unsuitable for\nconstrained RL scenarios. In this paper, we identify the root cause of this\nlimitation: their reliance on a semi-gradient optimization, which solves a\nfundamentally different optimization problem and results in failures in cost\nestimation. Building on these insights, we propose a novel method to enable OPE\nand constrained RL through semi-gradient DICE. Our method ensures accurate cost\nestimation and achieves state-of-the-art performance on the offline constrained\nRL benchmark, DSRL.", "AI": {"tldr": "DICE\u6846\u67b6\u7528\u4e8e\u89e3\u51b3\u7b56\u7565\u8bf1\u5bfc\u7684\u5e73\u7a33\u5206\u5e03\u4e0e\u76ee\u6807\u5206\u5e03\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u4f46\u8fd1\u671f\u6539\u8fdb\u65b9\u6cd5\u524a\u5f31\u4e86\u5176\u79bb\u7ebf\u7b56\u7565\u8bc4\u4f30\u80fd\u529b\u3002\u672c\u6587\u63d0\u51fa\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u534a\u68af\u5ea6DICE\u5b9e\u73b0\u51c6\u786e\u6210\u672c\u4f30\u8ba1\u548c\u7ea6\u675fRL\u3002", "motivation": "\u89e3\u51b3DICE\u6846\u67b6\u5728\u79bb\u7ebf\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u4e2d\u56e0\u534a\u68af\u5ea6\u4f18\u5316\u5bfc\u81f4\u7684\u6210\u672c\u4f30\u8ba1\u5931\u8d25\u95ee\u9898\uff0c\u63d0\u5347\u5176\u79bb\u7ebf\u7b56\u7565\u8bc4\u4f30\u548c\u7ea6\u675fRL\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u534a\u68af\u5ea6DICE\u4f18\u5316\uff0c\u786e\u4fdd\u51c6\u786e\u6210\u672c\u4f30\u8ba1\uff0c\u5e76\u5728\u79bb\u7ebf\u7ea6\u675fRL\u57fa\u51c6DSRL\u4e0a\u5b9e\u73b0\u6700\u4f18\u6027\u80fd\u3002", "result": "\u65b0\u65b9\u6cd5\u5728DSRL\u57fa\u51c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u89e3\u51b3\u4e86\u6210\u672c\u4f30\u8ba1\u5931\u8d25\u95ee\u9898\u3002", "conclusion": "\u901a\u8fc7\u534a\u68af\u5ea6DICE\u4f18\u5316\uff0c\u672c\u6587\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u79bb\u7ebf\u7ea6\u675fRL\u4e2d\u7684\u6210\u672c\u4f30\u8ba1\u95ee\u9898\uff0c\u5e76\u63d0\u5347\u4e86\u6027\u80fd\u3002"}}
{"id": "2506.08645", "pdf": "https://arxiv.org/pdf/2506.08645", "abs": "https://arxiv.org/abs/2506.08645", "authors": ["Youqi Wu", "Jingwei Zhang", "Farzan Farnia"], "title": "Fusing Cross-modal and Uni-modal Representations: A Kronecker Product Approach", "categories": ["cs.LG"], "comment": null, "summary": "Cross-modal embeddings, such as CLIP, BLIP and their variants, have achieved\npromising results in aligning representations across modalities. However, these\nembeddings could underperform compared to state-of-the-art single-modality\nembeddings on modality-specific tasks. On the other hand, single-modality\nembeddings excel in their domains but lack cross-modal alignment capabilities.\nIn this work, we focus on the problem of unifying cross-modality and\nsingle-modality embeddings to achieve the performance of modality-expert\nembedding within individual modalities while preserving cross-modal alignment.\nTo this end, we propose RP-KrossFuse, a method that leverages a random\nprojection-based Kronecker product to integrate cross-modal embeddings with\nsingle-modality embeddings. RP-KrossFuse aims to fuse the sample-pairwise\nsimilarity scores of the fused embeddings and operates efficiently in a\nspecified kernel space and supports scalable implementations via random Fourier\nfeatures for shift-invariant kernels such as the Gaussian kernel. We\ndemonstrate the effectiveness of RP-KrossFuse through several numerical\nexperiments, combining CLIP embeddings with uni-modal image and text\nembeddings. Our numerical results indicate that RP-KrossFuse achieves\ncompetitive modality-specific performance while retaining cross-modal\nalignment, bridging the gap between cross-modal and single-modality embeddings.", "AI": {"tldr": "RP-KrossFuse\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u968f\u673a\u6295\u5f71\u548cKronecker\u4e58\u79ef\u878d\u5408\u8de8\u6a21\u6001\u548c\u5355\u6a21\u6001\u5d4c\u5165\u7684\u65b9\u6cd5\uff0c\u65e8\u5728\u5728\u4fdd\u6301\u8de8\u6a21\u6001\u5bf9\u9f50\u7684\u540c\u65f6\u63d0\u5347\u5355\u6a21\u6001\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u8de8\u6a21\u6001\u5d4c\u5165\uff08\u5982CLIP\u3001BLIP\uff09\u5728\u8de8\u6a21\u6001\u5bf9\u9f50\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u5355\u6a21\u6001\u4efb\u52a1\u4e0a\u6027\u80fd\u4e0d\u53ca\u5355\u6a21\u6001\u5d4c\u5165\uff1b\u800c\u5355\u6a21\u6001\u5d4c\u5165\u7f3a\u4e4f\u8de8\u6a21\u6001\u5bf9\u9f50\u80fd\u529b\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u7edf\u4e00\u4e24\u8005\u3002", "method": "RP-KrossFuse\u5229\u7528\u968f\u673a\u6295\u5f71\u7684Kronecker\u4e58\u79ef\u878d\u5408\u8de8\u6a21\u6001\u548c\u5355\u6a21\u6001\u5d4c\u5165\uff0c\u901a\u8fc7\u6837\u672c\u5bf9\u76f8\u4f3c\u6027\u5206\u6570\u5728\u6838\u7a7a\u95f4\u4e2d\u9ad8\u6548\u64cd\u4f5c\uff0c\u5e76\u652f\u6301\u53ef\u6269\u5c55\u5b9e\u73b0\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cRP-KrossFuse\u5728\u7ed3\u5408CLIP\u5d4c\u5165\u4e0e\u5355\u6a21\u6001\u5d4c\u5165\u65f6\uff0c\u65e2\u80fd\u4fdd\u6301\u8de8\u6a21\u6001\u5bf9\u9f50\uff0c\u53c8\u5728\u5355\u6a21\u6001\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "RP-KrossFuse\u6210\u529f\u5f25\u5408\u4e86\u8de8\u6a21\u6001\u548c\u5355\u6a21\u6001\u5d4c\u5165\u4e4b\u95f4\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u5b9e\u73b0\u4e86\u4e24\u8005\u7684\u7edf\u4e00\u3002"}}
{"id": "2506.08652", "pdf": "https://arxiv.org/pdf/2506.08652", "abs": "https://arxiv.org/abs/2506.08652", "authors": ["Mahesh Godavarti"], "title": "JoFormer (Journey-based Transformer): Theory and Empirical Analysis on the Tiny Shakespeare Dataset", "categories": ["cs.LG", "cs.AI", "20-XX, 08A02", "F.4.1; I.2"], "comment": null, "summary": "Transformers have demonstrated remarkable success in sequence modeling, yet\neffectively incorporating positional information remains a challenging and\nactive area of research. In this paper, we introduce JoFormer, a journey-based\nTransformer architecture grounded in a recently proposed non-commutative\nalgebra for composing transformations across positions. JoFormer represents\nrelative positions through learnable directional transforms that are\nsequentially composed along the input, thereby extending and generalizing\nexisting approaches based on relative position representations. We derive the\nJoFormer attention mechanism from first principles and show that it subsumes\nstandard methods such as rotary transformations as special cases. To evaluate\nits effectiveness, we compare JoFormer to the RoFormer baseline on the Tiny\nShakespeare character-level language modeling task. Our results demonstrate\nthat\n  JoFormer consistently achieves lower perplexity and faster convergence,\nhighlighting the advantages of its more expressive, journey-based treatment of\nposition. Notably, the per-token JoFormer is still a primitive, conceptual\nvariant with layer-independent angles, yet it already demonstrates strong\nperformance-underscoring its promise as a proof of concept for more expressive\narchitectures. We conclude by discussing how JoFormer offers a principled\napproach to integrating positional structure into Transformer architectures.\nThe code used in this work is available at\nhttps://github.com/mahesh-godavarti/joformer.", "AI": {"tldr": "JoFormer\u662f\u4e00\u79cd\u57fa\u4e8e\u975e\u4ea4\u6362\u4ee3\u6570\u7684Transformer\u67b6\u6784\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u5b9a\u5411\u53d8\u6362\u8868\u793a\u76f8\u5bf9\u4f4d\u7f6e\uff0c\u4f18\u4e8eRoFormer\uff0c\u5728Tiny Shakespeare\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u89e3\u51b3Transformer\u4e2d\u6709\u6548\u6574\u5408\u4f4d\u7f6e\u4fe1\u606f\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faJoFormer\u67b6\u6784\uff0c\u5229\u7528\u975e\u4ea4\u6362\u4ee3\u6570\u7ec4\u5408\u4f4d\u7f6e\u53d8\u6362\uff0c\u6269\u5c55\u76f8\u5bf9\u4f4d\u7f6e\u8868\u793a\u65b9\u6cd5\u3002", "result": "JoFormer\u5728Tiny Shakespeare\u4efb\u52a1\u4e2d\u5b9e\u73b0\u66f4\u4f4e\u56f0\u60d1\u5ea6\u548c\u66f4\u5feb\u6536\u655b\u3002", "conclusion": "JoFormer\u4e3aTransformer\u4e2d\u4f4d\u7f6e\u7ed3\u6784\u7684\u6574\u5408\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\uff0c\u5c55\u793a\u4e86\u5176\u6f5c\u529b\u3002"}}
{"id": "2506.08655", "pdf": "https://arxiv.org/pdf/2506.08655", "abs": "https://arxiv.org/abs/2506.08655", "authors": ["Kamil Jerabek", "Jan Luxemburk", "Richard Plny", "Josef Koumar", "Jaroslav Pesek", "Karel Hynek"], "title": "When Simple Model Just Works: Is Network Traffic Classification in Crisis?", "categories": ["cs.LG", "cs.NI"], "comment": null, "summary": "Machine learning has been applied to network traffic classification (TC) for\nover two decades. While early efforts used shallow models, the latter 2010s saw\na shift toward complex neural networks, often reporting near-perfect accuracy.\nHowever, it was recently revealed that a simple k-NN baseline using packet\nsequences metadata (sizes, times, and directions) can be on par or even\noutperform more complex methods. In this paper, we investigate this phenomenon\nfurther and evaluate this baseline across 12 datasets and 15 TC tasks, and\ninvestigate why it performs so well. Our analysis shows that most datasets\ncontain over 50% redundant samples (identical packet sequences), which\nfrequently appear in both training and test sets due to common splitting\npractices. This redundancy can lead to overestimated model performance and\nreduce the theoretical maximum accuracy when identical flows have conflicting\nlabels. Given its distinct characteristics, we further argue that standard\nmachine learning practices adapted from domains like NLP or computer vision may\nbe ill-suited for TC. Finally, we propose new directions for task formulation\nand evaluation to address these challenges and help realign the field.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u7b80\u5355\u7684k-NN\u57fa\u7ebf\u65b9\u6cd5\u5728\u7f51\u7edc\u6d41\u91cf\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u539f\u56e0\u662f\u6570\u636e\u96c6\u4e2d\u5b58\u5728\u5927\u91cf\u5197\u4f59\u6837\u672c\uff0c\u5bfc\u81f4\u590d\u6742\u6a21\u578b\u7684\u6027\u80fd\u88ab\u9ad8\u4f30\u3002", "motivation": "\u63a2\u8ba8\u4e3a\u4f55\u7b80\u5355\u7684k-NN\u65b9\u6cd5\u5728\u7f51\u7edc\u6d41\u91cf\u5206\u7c7b\u4e2d\u8868\u73b0\u4f18\u4e8e\u590d\u6742\u795e\u7ecf\u7f51\u7edc\uff0c\u5e76\u63ed\u793a\u6570\u636e\u96c6\u5197\u4f59\u95ee\u9898\u5bf9\u6a21\u578b\u8bc4\u4f30\u7684\u5f71\u54cd\u3002", "method": "\u572812\u4e2a\u6570\u636e\u96c6\u548c15\u4e2a\u5206\u7c7b\u4efb\u52a1\u4e2d\u8bc4\u4f30k-NN\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5206\u6790\u6570\u636e\u5197\u4f59\u53ca\u5176\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u6570\u636e\u96c6\u4e2d\u8d85\u8fc750%\u7684\u6837\u672c\u662f\u5197\u4f59\u7684\uff0c\u5bfc\u81f4\u6a21\u578b\u6027\u80fd\u88ab\u9ad8\u4f30\uff0c\u4e14\u6807\u51c6\u673a\u5668\u5b66\u4e60\u5b9e\u8df5\u53ef\u80fd\u4e0d\u9002\u7528\u4e8e\u6d41\u91cf\u5206\u7c7b\u3002", "conclusion": "\u63d0\u51fa\u65b0\u7684\u4efb\u52a1\u5b9a\u4e49\u548c\u8bc4\u4f30\u65b9\u5411\uff0c\u4ee5\u89e3\u51b3\u6570\u636e\u5197\u4f59\u95ee\u9898\u5e76\u91cd\u65b0\u8c03\u6574\u9886\u57df\u7814\u7a76\u3002"}}
{"id": "2506.08660", "pdf": "https://arxiv.org/pdf/2506.08660", "abs": "https://arxiv.org/abs/2506.08660", "authors": ["Jinkwan Jang", "Hyungjin Park", "Jinmyeong Choi", "Taesup Kim"], "title": "Towards Robust Real-World Multivariate Time Series Forecasting: A Unified Framework for Dependency, Asynchrony, and Missingness", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Real-world time series data are inherently multivariate, often exhibiting\ncomplex inter-channel dependencies. Each channel is typically sampled at its\nown period and is prone to missing values due to various practical and\noperational constraints. These characteristics pose fundamental challenges\nrelated to channel dependency, sampling asynchrony, and missingness, all of\nwhich must be addressed to enable robust and reliable forecasting in practical\nsettings. However, most existing architectures are built on oversimplified\nassumptions, such as identical sampling periods across channels and fully\nobserved inputs at test time, which often do not hold in real-world scenarios.\nTo bridge this gap, we propose ChannelTokenFormer, a Transformer-based\nforecasting model with a flexible architecture designed to explicitly capture\ncross-channel interactions, accommodate channel-wise asynchronous sampling, and\neffectively handle missing values. Extensive experiments on three benchmark\ndatasets modified to reflect practical settings, along with one real-world\nindustrial dataset, demonstrate the superior robustness and accuracy of\nChannelTokenFormer under challenging real-world conditions.", "AI": {"tldr": "ChannelTokenFormer\u662f\u4e00\u79cd\u57fa\u4e8eTransformer\u7684\u9884\u6d4b\u6a21\u578b\uff0c\u65e8\u5728\u89e3\u51b3\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e2d\u7684\u901a\u9053\u4f9d\u8d56\u6027\u3001\u5f02\u6b65\u91c7\u6837\u548c\u7f3a\u5931\u503c\u95ee\u9898\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u901a\u5e38\u662f\u591a\u53d8\u91cf\u7684\uff0c\u5b58\u5728\u590d\u6742\u7684\u901a\u9053\u95f4\u4f9d\u8d56\u5173\u7cfb\u3001\u5f02\u6b65\u91c7\u6837\u548c\u7f3a\u5931\u503c\u95ee\u9898\uff0c\u800c\u73b0\u6709\u6a21\u578b\u901a\u5e38\u57fa\u4e8e\u8fc7\u4e8e\u7b80\u5316\u7684\u5047\u8bbe\uff0c\u65e0\u6cd5\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u63d0\u51faChannelTokenFormer\uff0c\u901a\u8fc7\u7075\u6d3b\u7684\u67b6\u6784\u663e\u5f0f\u6355\u6349\u8de8\u901a\u9053\u4ea4\u4e92\u3001\u9002\u5e94\u901a\u9053\u5f02\u6b65\u91c7\u6837\u5e76\u6709\u6548\u5904\u7406\u7f3a\u5931\u503c\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u548c\u4e00\u4e2a\u771f\u5b9e\u5de5\u4e1a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cChannelTokenFormer\u5728\u590d\u6742\u73b0\u5b9e\u6761\u4ef6\u4e0b\u5177\u6709\u4f18\u8d8a\u7684\u9c81\u68d2\u6027\u548c\u51c6\u786e\u6027\u3002", "conclusion": "ChannelTokenFormer\u4e3a\u89e3\u51b3\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u5b9e\u9645\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.08662", "pdf": "https://arxiv.org/pdf/2506.08662", "abs": "https://arxiv.org/abs/2506.08662", "authors": ["Florian Borzechowski", "Michael Sch\u00e4fer", "Heiko Schwarz", "Jonathan Pfaff", "Detlev Marpe", "Thomas Wiegand"], "title": "Optimizing Learned Image Compression on Scalar and Entropy-Constraint Quantization", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT"], "comment": "Accepted at ICIP2024, the IEEE International Conference on Image\n  Processing", "summary": "The continuous improvements on image compression with variational\nautoencoders have lead to learned codecs competitive with conventional\napproaches in terms of rate-distortion efficiency. Nonetheless, taking the\nquantization into account during the training process remains a problem, since\nit produces zero derivatives almost everywhere and needs to be replaced with a\ndifferentiable approximation which allows end-to-end optimization. Though there\nare different methods for approximating the quantization, none of them model\nthe quantization noise correctly and thus, result in suboptimal networks.\nHence, we propose an additional finetuning training step: After conventional\nend-to-end training, parts of the network are retrained on quantized latents\nobtained at the inference stage. For entropy-constraint quantizers like\nTrellis-Coded Quantization, the impact of the quantizer is particularly\ndifficult to approximate by rounding or adding noise as the quantized latents\nare interdependently chosen through a trellis search based on both the entropy\nmodel and a distortion measure. We show that retraining on correctly quantized\ndata consistently yields additional coding gain for both uniform scalar and\nespecially for entropy-constraint quantization, without increasing inference\ncomplexity. For the Kodak test set, we obtain average savings between 1% and\n2%, and for the TecNick test set up to 2.2% in terms of Bj{\\o}ntegaard-Delta\nbitrate.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u989d\u5916\u7684\u5fae\u8c03\u8bad\u7ec3\u6b65\u9aa4\uff0c\u901a\u8fc7\u5728\u63a8\u7406\u9636\u6bb5\u5bf9\u91cf\u5316\u6f5c\u5728\u8868\u793a\u8fdb\u884c\u91cd\u65b0\u8bad\u7ec3\uff0c\u4ee5\u63d0\u5347\u56fe\u50cf\u538b\u7f29\u7f51\u7edc\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u96be\u4ee5\u6b63\u786e\u5efa\u6a21\u91cf\u5316\u566a\u58f0\uff0c\u5bfc\u81f4\u7f51\u7edc\u6027\u80fd\u4e0d\u4f73\u3002", "method": "\u5728\u4f20\u7edf\u7aef\u5230\u7aef\u8bad\u7ec3\u540e\uff0c\u5bf9\u7f51\u7edc\u7684\u90e8\u5206\u8fdb\u884c\u57fa\u4e8e\u91cf\u5316\u6f5c\u5728\u8868\u793a\u7684\u91cd\u65b0\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5747\u5300\u6807\u91cf\u91cf\u5316\u548c\u71b5\u7ea6\u675f\u91cf\u5316\u4e2d\u5747\u80fd\u5e26\u6765\u989d\u5916\u7684\u7f16\u7801\u589e\u76ca\uff0c\u4e14\u4e0d\u589e\u52a0\u63a8\u7406\u590d\u6742\u5ea6\u3002", "conclusion": "\u901a\u8fc7\u6b63\u786e\u91cf\u5316\u6570\u636e\u7684\u91cd\u65b0\u8bad\u7ec3\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u56fe\u50cf\u538b\u7f29\u7f51\u7edc\u7684\u6027\u80fd\u3002"}}
{"id": "2506.08669", "pdf": "https://arxiv.org/pdf/2506.08669", "abs": "https://arxiv.org/abs/2506.08669", "authors": ["Dongge Han", "Menglin Xia", "Daniel Madrigal Diaz", "Samuel Kessler", "Ankur Mallick", "Xuchao Zhang", "Mirian Del Carmen Hipolito Garcia", "Jin Xu", "Victor R\u00fchle", "Saravan Rajmohan"], "title": "Enhancing Reasoning Capabilities of Small Language Models with Blueprints and Prompt Template Search", "categories": ["cs.LG", "cs.AI"], "comment": "TTODLer-FM Workshop@ICML'25 (Tiny Titans: The next wave of On-Device\n  Learning for Foundational Models)", "summary": "Small language models (SLMs) offer promising and efficient alternatives to\nlarge language models (LLMs). However, SLMs' limited capacity restricts their\nreasoning capabilities and makes them sensitive to prompt variations. To\naddress these challenges, we propose a novel framework that enhances SLM\nreasoning capabilities through LLM generated blueprints. The blueprints provide\nstructured, high-level reasoning guides that help SLMs systematically tackle\nrelated problems. Furthermore, our framework integrates a prompt template\nsearch mechanism to mitigate the SLMs' sensitivity to prompt variations. Our\nframework demonstrates improved SLM performance across various tasks, including\nmath (GSM8K), coding (MBPP), and logic reasoning (BBH). Our approach improves\nthe reasoning capabilities of SLMs without increasing model size or requiring\nadditional training, offering a lightweight and deployment-friendly solution\nfor on-device or resource-constrained environments.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u901a\u8fc7LLM\u751f\u6210\u84dd\u56fe\u589e\u5f3aSLM\u63a8\u7406\u80fd\u529b\u7684\u65b0\u6846\u67b6\uff0c\u540c\u65f6\u51cf\u5c11\u5bf9\u63d0\u793a\u53d8\u5316\u7684\u654f\u611f\u6027\uff0c\u63d0\u5347SLM\u5728\u591a\u79cd\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "SLM\u56e0\u5bb9\u91cf\u6709\u9650\u5bfc\u81f4\u63a8\u7406\u80fd\u529b\u4e0d\u8db3\u4e14\u5bf9\u63d0\u793a\u53d8\u5316\u654f\u611f\uff0c\u9700\u8981\u4e00\u79cd\u8f7b\u91cf\u7ea7\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5229\u7528LLM\u751f\u6210\u7ed3\u6784\u5316\u84dd\u56fe\u6307\u5bfcSLM\u63a8\u7406\uff0c\u5e76\u96c6\u6210\u63d0\u793a\u6a21\u677f\u641c\u7d22\u673a\u5236\u3002", "result": "\u5728\u6570\u5b66\u3001\u7f16\u7a0b\u548c\u903b\u8f91\u63a8\u7406\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u5347SLM\u6027\u80fd\uff0c\u65e0\u9700\u589e\u52a0\u6a21\u578b\u89c4\u6a21\u6216\u989d\u5916\u8bad\u7ec3\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u90e8\u7f72\u53cb\u597d\u7684SLM\u589e\u5f3a\u65b9\u6848\u3002"}}
{"id": "2506.08673", "pdf": "https://arxiv.org/pdf/2506.08673", "abs": "https://arxiv.org/abs/2506.08673", "authors": ["Diptarka Chakraborty", "Kushagra Chatterjee", "Debarati Das", "Tien Long Nguyen", "Romina Nobahari"], "title": "Towards Fair Representation: Clustering and Consensus", "categories": ["cs.LG", "cs.DS"], "comment": "The paper has been accepted at the Conference on Learning Theory\n  (COLT) 2025", "summary": "Consensus clustering, a fundamental task in machine learning and data\nanalysis, aims to aggregate multiple input clusterings of a dataset,\npotentially based on different non-sensitive attributes, into a single\nclustering that best represents the collective structure of the data. In this\nwork, we study this fundamental problem through the lens of fair clustering, as\nintroduced by Chierichetti et al. [NeurIPS'17], which incorporates the\ndisparate impact doctrine to ensure proportional representation of each\nprotected group in the dataset within every cluster. Our objective is to find a\nconsensus clustering that is not only representative but also fair with respect\nto specific protected attributes. To the best of our knowledge, we are the\nfirst to address this problem and provide a constant-factor approximation.\n  As part of our investigation, we examine how to minimally modify an existing\nclustering to enforce fairness -- an essential postprocessing step in many\nclustering applications that require fair representation. We develop an optimal\nalgorithm for datasets with equal group representation and near-linear time\nconstant factor approximation algorithms for more general scenarios with\ndifferent proportions of two group sizes. We complement our approximation\nresult by showing that the problem is NP-hard for two unequal-sized groups.\nGiven the fundamental nature of this problem, we believe our results on Closest\nFair Clustering could have broader implications for other clustering problems,\nparticularly those for which no prior approximation guarantees exist for their\nfair variants.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728\u5171\u8bc6\u805a\u7c7b\u4e2d\u5f15\u5165\u516c\u5e73\u6027\u7ea6\u675f\u7684\u95ee\u9898\uff0c\u9996\u6b21\u63d0\u51fa\u4e86\u4e00\u4e2a\u5e38\u6570\u56e0\u5b50\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u5e76\u63a2\u8ba8\u4e86\u5982\u4f55\u6700\u5c0f\u5316\u4fee\u6539\u73b0\u6709\u805a\u7c7b\u4ee5\u5b9e\u73b0\u516c\u5e73\u6027\u3002", "motivation": "\u5171\u8bc6\u805a\u7c7b\u901a\u5e38\u57fa\u4e8e\u975e\u654f\u611f\u5c5e\u6027\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u516c\u5e73\u6027\u7684\u8003\u8651\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u5f15\u5165\u516c\u5e73\u6027\u7ea6\u675f\uff0c\u786e\u4fdd\u6bcf\u4e2a\u53d7\u4fdd\u62a4\u7ec4\u5728\u805a\u7c7b\u4e2d\u5f97\u5230\u6bd4\u4f8b\u4ee3\u8868\u3002", "method": "\u4f5c\u8005\u5f00\u53d1\u4e86\u4e00\u79cd\u6700\u4f18\u7b97\u6cd5\u7528\u4e8e\u7b49\u6bd4\u4f8b\u7ec4\u8868\u793a\u7684\u6570\u636e\u96c6\uff0c\u5e76\u4e3a\u66f4\u4e00\u822c\u7684\u573a\u666f\u63d0\u4f9b\u4e86\u8fd1\u4f3c\u7ebf\u6027\u65f6\u95f4\u7684\u5e38\u6570\u56e0\u5b50\u8fd1\u4f3c\u7b97\u6cd5\u3002\u540c\u65f6\u8bc1\u660e\u4e86\u95ee\u9898\u5728\u4e24\u7ec4\u4e0d\u7b49\u6bd4\u4f8b\u65f6\u7684NP\u96be\u89e3\u6027\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u5e38\u6570\u56e0\u5b50\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u5e76\u5c55\u793a\u4e86\u5982\u4f55\u9ad8\u6548\u5730\u4fee\u6539\u73b0\u6709\u805a\u7c7b\u4ee5\u5b9e\u73b0\u516c\u5e73\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5171\u8bc6\u805a\u7c7b\u4e2d\u7684\u516c\u5e73\u6027\u95ee\u9898\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u7b97\u6cd5\uff0c\u53ef\u80fd\u5bf9\u5176\u4ed6\u805a\u7c7b\u95ee\u9898\u7684\u516c\u5e73\u6027\u7814\u7a76\u4ea7\u751f\u5e7f\u6cdb\u5f71\u54cd\u3002"}}
{"id": "2506.08681", "pdf": "https://arxiv.org/pdf/2506.08681", "abs": "https://arxiv.org/abs/2506.08681", "authors": ["Phuc Minh Nguyen", "Ngoc-Hieu Nguyen", "Duy H. M. Nguyen", "Anji Liu", "An Mai", "Binh T. Nguyen", "Daniel Sonntag", "Khoa D. Doan"], "title": "Mitigating Reward Over-optimization in Direct Alignment Algorithms with Importance Sampling", "categories": ["cs.LG"], "comment": "First version", "summary": "Direct Alignment Algorithms (DAAs) such as Direct Preference Optimization\n(DPO) have emerged as alternatives to the standard Reinforcement Learning from\nHuman Feedback (RLHF) for aligning large language models (LLMs) with human\nvalues. However, these methods are more susceptible to over-optimization, in\nwhich the model drifts away from the reference policy, leading to degraded\nperformance as training progresses. This paper proposes a novel\nimportance-sampling approach to mitigate the over-optimization problem of\noffline DAAs. This approach, called (IS-DAAs), multiplies the DAA objective\nwith an importance ratio that accounts for the reference policy distribution.\nIS-DAAs additionally avoid the high variance issue associated with importance\nsampling by clipping the importance ratio to a maximum value. Our extensive\nexperiments demonstrate that IS-DAAs can effectively mitigate\nover-optimization, especially under low regularization strength, and achieve\nbetter performance than other methods designed to address this problem. Our\nimplementations are provided publicly at this link.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u91cd\u8981\u6027\u91c7\u6837\u7684\u65b9\u6cd5\uff08IS-DAAs\uff09\uff0c\u7528\u4e8e\u89e3\u51b3\u76f4\u63a5\u5bf9\u9f50\u7b97\u6cd5\uff08DAAs\uff09\u4e2d\u7684\u8fc7\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u5f15\u5165\u91cd\u8981\u6027\u6bd4\u7387\u548c\u526a\u88c1\u6280\u672f\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u76f4\u63a5\u5bf9\u9f50\u7b97\u6cd5\uff08\u5982DPO\uff09\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5bb9\u6613\u51fa\u73b0\u8fc7\u4f18\u5316\u95ee\u9898\uff0c\u5bfc\u81f4\u6a21\u578b\u504f\u79bb\u53c2\u8003\u7b56\u7565\uff0c\u6027\u80fd\u4e0b\u964d\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51faIS-DAAs\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cd\u8981\u6027\u6bd4\u7387\u8c03\u6574\u76ee\u6807\u51fd\u6570\uff0c\u5e76\u526a\u88c1\u91cd\u8981\u6027\u6bd4\u7387\u4ee5\u51cf\u5c11\u65b9\u5dee\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cIS-DAAs\u80fd\u6709\u6548\u7f13\u89e3\u8fc7\u4f18\u5316\u95ee\u9898\uff0c\u5c24\u5176\u5728\u4f4e\u6b63\u5219\u5316\u5f3a\u5ea6\u4e0b\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "conclusion": "IS-DAAs\u662f\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u663e\u8457\u6539\u5584DAAs\u7684\u8fc7\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2506.08698", "pdf": "https://arxiv.org/pdf/2506.08698", "abs": "https://arxiv.org/abs/2506.08698", "authors": ["Boyu Xie", "Tangtang Xie"], "title": "Variational Autoencoder-Based Approach to Latent Feature Analysis on Efficient Representation of Power Load Monitoring Data", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages, 2 figures", "summary": "With the development of smart grids, High-Dimensional and Incomplete (HDI)\nPower Load Monitoring (PLM) data challenges the performance of Power Load\nForecasting (PLF) models. In this paper, we propose a potential\ncharacterization model VAE-LF based on Variational Autoencoder (VAE) for\nefficiently representing and complementing PLM missing data. VAE-LF learns a\nlow-dimensional latent representation of the data using an Encoder-Decoder\nstructure by splitting the HDI PLM data into vectors and feeding them\nsequentially into the VAE-LF model, and generates the complementary data.\nExperiments on the UK-DALE dataset show that VAE-LF outperforms other benchmark\nmodels in both 5% and 10% sparsity test cases, with significantly lower RMSE\nand MAE, and especially outperforms on low sparsity ratio data. The method\nprovides an efficient data-completion solution for electric load management in\nsmart grids.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09\u7684VAE-LF\u6a21\u578b\uff0c\u7528\u4e8e\u9ad8\u6548\u8868\u793a\u548c\u8865\u5168\u9ad8\u7ef4\u4e0d\u5b8c\u6574\u7535\u529b\u8d1f\u8377\u76d1\u6d4b\u6570\u636e\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u5728\u7a00\u758f\u6570\u636e\u4e0b\u8868\u73b0\u4f18\u8d8a\u3002", "motivation": "\u667a\u80fd\u7535\u7f51\u4e2d\u9ad8\u7ef4\u4e0d\u5b8c\u6574\u7535\u529b\u8d1f\u8377\u76d1\u6d4b\u6570\u636e\u5bf9\u8d1f\u8377\u9884\u6d4b\u6a21\u578b\u6027\u80fd\u63d0\u51fa\u6311\u6218\uff0c\u9700\u9ad8\u6548\u6570\u636e\u8865\u5168\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u7f16\u7801\u5668-\u89e3\u7801\u5668\u7ed3\u6784\u7684VAE-LF\u6a21\u578b\uff0c\u5c06\u6570\u636e\u5206\u5411\u91cf\u8f93\u5165\u5e76\u751f\u6210\u8865\u5168\u6570\u636e\u3002", "result": "\u5728UK-DALE\u6570\u636e\u96c6\u4e0a\uff0cVAE-LF\u57285%\u548c10%\u7a00\u758f\u5ea6\u4e0bRMSE\u548cMAE\u663e\u8457\u4f18\u4e8e\u57fa\u51c6\u6a21\u578b\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u4f4e\u7a00\u758f\u5ea6\u6570\u636e\u3002", "conclusion": "VAE-LF\u4e3a\u667a\u80fd\u7535\u7f51\u7535\u529b\u8d1f\u8377\u7ba1\u7406\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u6570\u636e\u8865\u5168\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.08727", "pdf": "https://arxiv.org/pdf/2506.08727", "abs": "https://arxiv.org/abs/2506.08727", "authors": ["Samarth Sikand", "Rohit Mehra", "Priyavanshi Pathania", "Nikhil Bamby", "Vibhu Saujanya Sharma", "Vikrant Kaulgud", "Sanjay Podder", "Adam P. Burden"], "title": "Breaking the ICE: Exploring promises and challenges of benchmarks for Inference Carbon & Energy estimation for LLMs", "categories": ["cs.LG", "cs.AI", "cs.CY", "cs.SE"], "comment": "5 pages. To be published in the proceedings of 9th International\n  Workshop on Green and Sustainable Software (GREENS '25), April 29, 2025,\n  Ottawa, Canada (Co-located with ICSE 2025)", "summary": "While Generative AI stands to be one of the fastest adopted technologies\never, studies have made evident that the usage of Large Language Models (LLMs)\nputs significant burden on energy grids and our environment. It may prove a\nhindrance to the Sustainability goals of any organization. A crucial step in\nany Sustainability strategy is monitoring or estimating the energy consumption\nof various components. While there exist multiple tools for monitoring energy\nconsumption, there is a dearth of tools/frameworks for estimating the\nconsumption or carbon emissions. Current drawbacks of both monitoring and\nestimation tools include high input data points, intrusive nature, high error\nmargin, etc. We posit that leveraging emerging LLM benchmarks and related data\npoints can help overcome aforementioned challenges while balancing accuracy of\nthe emission estimations. To that extent, we discuss the challenges of current\napproaches and present our evolving framework, R-ICE, which estimates prompt\nlevel inference carbon emissions by leveraging existing state-of-the-art(SOTA)\nbenchmark. This direction provides a more practical and non-intrusive way to\nenable emerging use-cases like dynamic LLM routing, carbon accounting, etc. Our\npromising validation results suggest that benchmark-based modelling holds great\npotential for inference emission estimation and warrants further exploration\nfrom the scientific community.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u57fa\u51c6\u7684\u6846\u67b6R-ICE\uff0c\u7528\u4e8e\u4f30\u7b97\u63d0\u793a\u7ea7\u63a8\u7406\u78b3\u6392\u653e\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5de5\u5177\u7684\u9ad8\u6570\u636e\u9700\u6c42\u3001\u4fb5\u5165\u6027\u548c\u8bef\u5dee\u95ee\u9898\u3002", "motivation": "\u751f\u6210\u5f0fAI\u548cLLMs\u7684\u5e7f\u6cdb\u5e94\u7528\u5bf9\u80fd\u6e90\u548c\u73af\u5883\u9020\u6210\u8d1f\u62c5\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u6709\u6548\u7684\u78b3\u6392\u653e\u4f30\u7b97\u5de5\u5177\uff0c\u963b\u788d\u53ef\u6301\u7eed\u53d1\u5c55\u76ee\u6807\u7684\u5b9e\u73b0\u3002", "method": "\u5229\u7528\u73b0\u6709SOTA\u57fa\u51c6\u548c\u76f8\u5173\u6570\u636e\u70b9\uff0c\u5f00\u53d1\u975e\u4fb5\u5165\u6027\u7684\u6846\u67b6R-ICE\uff0c\u4f30\u7b97\u63d0\u793a\u7ea7\u63a8\u7406\u78b3\u6392\u653e\u3002", "result": "\u9a8c\u8bc1\u7ed3\u679c\u8868\u660e\uff0c\u57fa\u4e8e\u57fa\u51c6\u7684\u5efa\u6a21\u5728\u78b3\u6392\u653e\u4f30\u7b97\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u652f\u6301\u52a8\u6001LLM\u8def\u7531\u548c\u78b3\u6838\u7b97\u7b49\u5e94\u7528\u3002", "conclusion": "R-ICE\u6846\u67b6\u4e3a\u78b3\u6392\u653e\u4f30\u7b97\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u975e\u4fb5\u5165\u6027\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u503c\u5f97\u79d1\u5b66\u754c\u8fdb\u4e00\u6b65\u63a2\u7d22\u3002"}}
{"id": "2506.08737", "pdf": "https://arxiv.org/pdf/2506.08737", "abs": "https://arxiv.org/abs/2506.08737", "authors": ["Haozhe Ma", "Guoji Fu", "Zhengding Luo", "Jiele Wu", "Tze-Yun Leong"], "title": "Exploration by Random Reward Perturbation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We introduce Random Reward Perturbation (RRP), a novel exploration strategy\nfor reinforcement learning (RL). Our theoretical analyses demonstrate that\nadding zero-mean noise to environmental rewards effectively enhances policy\ndiversity during training, thereby expanding the range of exploration. RRP is\nfully compatible with the action-perturbation-based exploration strategies,\nsuch as $\\epsilon$-greedy, stochastic policies, and entropy regularization,\nproviding additive improvements to exploration effects. It is general,\nlightweight, and can be integrated into existing RL algorithms with minimal\nimplementation effort and negligible computational overhead. RRP establishes a\ntheoretical connection between reward shaping and noise-driven exploration,\nhighlighting their complementary potential. Experiments show that RRP\nsignificantly boosts the performance of Proximal Policy Optimization and Soft\nActor-Critic, achieving higher sample efficiency and escaping local optima\nacross various tasks, under both sparse and dense reward scenarios.", "AI": {"tldr": "RRP\u662f\u4e00\u79cd\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u63a2\u7d22\u7b56\u7565\uff0c\u901a\u8fc7\u5411\u73af\u5883\u5956\u52b1\u6dfb\u52a0\u96f6\u5747\u503c\u566a\u58f0\u589e\u5f3a\u7b56\u7565\u591a\u6837\u6027\uff0c\u63d0\u5347\u63a2\u7d22\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u63a2\u7d22\u7b56\u7565\uff08\u5982\u52a8\u4f5c\u6270\u52a8\uff09\u53ef\u80fd\u4e0d\u8db3\u4ee5\u5145\u5206\u63a2\u7d22\u73af\u5883\uff0cRRP\u901a\u8fc7\u5956\u52b1\u6270\u52a8\u63d0\u4f9b\u8865\u5145\u3002", "method": "\u5728\u73af\u5883\u5956\u52b1\u4e2d\u6dfb\u52a0\u96f6\u5747\u503c\u566a\u58f0\uff0c\u4e0e\u52a8\u4f5c\u6270\u52a8\u7b56\u7565\u517c\u5bb9\uff0c\u6613\u4e8e\u96c6\u6210\u5230\u73b0\u6709RL\u7b97\u6cd5\u4e2d\u3002", "result": "\u5b9e\u9a8c\u8868\u660eRRP\u663e\u8457\u63d0\u5347\u4e86PPO\u548cSAC\u7684\u6027\u80fd\uff0c\u63d0\u9ad8\u4e86\u6837\u672c\u6548\u7387\u5e76\u907f\u514d\u5c40\u90e8\u6700\u4f18\u3002", "conclusion": "RRP\u901a\u8fc7\u5956\u52b1\u6270\u52a8\u4e0e\u566a\u58f0\u9a71\u52a8\u63a2\u7d22\u7684\u7406\u8bba\u8054\u7cfb\uff0c\u5c55\u793a\u4e86\u5176\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.08740", "pdf": "https://arxiv.org/pdf/2506.08740", "abs": "https://arxiv.org/abs/2506.08740", "authors": ["Sidhika Balachandar", "Shuvom Sadhuka", "Bonnie Berger", "Emma Pierson", "Nikhil Garg"], "title": "Urban Incident Prediction with Graph Neural Networks: Integrating Government Ratings and Crowdsourced Reports", "categories": ["cs.LG"], "comment": null, "summary": "Graph neural networks (GNNs) are widely used in urban spatiotemporal\nforecasting, such as predicting infrastructure problems. In this setting,\ngovernment officials wish to know in which neighborhoods incidents like\npotholes or rodent issues occur. The true state of incidents (e.g., street\nconditions) for each neighborhood is observed via government inspection\nratings. However, these ratings are only conducted for a sparse set of\nneighborhoods and incident types. We also observe the state of incidents via\ncrowdsourced reports, which are more densely observed but may be biased due to\nheterogeneous reporting behavior. First, for such settings, we propose a\nmultiview, multioutput GNN-based model that uses both unbiased rating data and\nbiased reporting data to predict the true latent state of incidents. Second, we\ninvestigate a case study of New York City urban incidents and collect,\nstandardize, and make publicly available a dataset of 9,615,863 crowdsourced\nreports and 1,041,415 government inspection ratings over 3 years and across 139\ntypes of incidents. Finally, we show on both real and semi-synthetic data that\nour model can better predict the latent state compared to models that use only\nreporting data or models that use only rating data, especially when rating data\nis sparse and reports are predictive of ratings. We also quantify demographic\nbiases in crowdsourced reporting, e.g., higher-income neighborhoods report\nproblems at higher rates. Our analysis showcases a widely applicable approach\nfor latent state prediction using heterogeneous, sparse, and biased data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u89c6\u56fe\u3001\u591a\u8f93\u51fa\u7684GNN\u6a21\u578b\uff0c\u7ed3\u5408\u653f\u5e9c\u68c0\u67e5\u8bc4\u5206\u548c\u4f17\u5305\u62a5\u544a\u6570\u636e\u9884\u6d4b\u57ce\u5e02\u4e8b\u4ef6\u7684\u771f\u5b9e\u72b6\u6001\uff0c\u5e76\u5728\u7ebd\u7ea6\u5e02\u6848\u4f8b\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u57ce\u5e02\u65f6\u7a7a\u9884\u6d4b\u4e2d\uff0c\u653f\u5e9c\u68c0\u67e5\u8bc4\u5206\u7a00\u758f\u4e14\u4f17\u5305\u62a5\u544a\u5b58\u5728\u504f\u5dee\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u7ed3\u5408\u4e24\u8005\u9884\u6d4b\u4e8b\u4ef6\u7684\u771f\u5b9e\u72b6\u6001\u3002", "method": "\u63d0\u51fa\u591a\u89c6\u56fe\u3001\u591a\u8f93\u51fa\u7684GNN\u6a21\u578b\uff0c\u6574\u5408\u653f\u5e9c\u8bc4\u5206\u548c\u4f17\u5305\u62a5\u544a\u6570\u636e\u3002", "result": "\u6a21\u578b\u5728\u771f\u5b9e\u548c\u534a\u5408\u6210\u6570\u636e\u4e0a\u4f18\u4e8e\u4ec5\u4f7f\u7528\u5355\u4e00\u6570\u636e\u6e90\u7684\u6a21\u578b\uff0c\u5e76\u91cf\u5316\u4e86\u4f17\u5305\u62a5\u544a\u7684\u7fa4\u4f53\u504f\u5dee\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5229\u7528\u5f02\u6784\u3001\u7a00\u758f\u548c\u504f\u5dee\u6570\u636e\u8fdb\u884c\u6f5c\u5728\u72b6\u6001\u9884\u6d4b\u63d0\u4f9b\u4e86\u5e7f\u6cdb\u9002\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.08764", "pdf": "https://arxiv.org/pdf/2506.08764", "abs": "https://arxiv.org/abs/2506.08764", "authors": ["Benjamin Dadoun", "Soufiane Hayou", "Hanan Salam", "Mohamed El Amine Seddik", "Pierre Youssef"], "title": "On the Stability of the Jacobian Matrix in Deep Neural Networks", "categories": ["cs.LG", "68T07, 60B20"], "comment": "16 pages, 26 figures", "summary": "Deep neural networks are known to suffer from exploding or vanishing\ngradients as depth increases, a phenomenon closely tied to the spectral\nbehavior of the input-output Jacobian. Prior work has identified critical\ninitialization schemes that ensure Jacobian stability, but these analyses are\ntypically restricted to fully connected networks with i.i.d. weights. In this\nwork, we go significantly beyond these limitations: we establish a general\nstability theorem for deep neural networks that accommodates sparsity (such as\nthat introduced by pruning) and non-i.i.d., weakly correlated weights (e.g.\ninduced by training). Our results rely on recent advances in random matrix\ntheory, and provide rigorous guarantees for spectral stability in a much\nbroader class of network models. This extends the theoretical foundation for\ninitialization schemes in modern neural networks with structured and dependent\nrandomness.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9002\u7528\u4e8e\u7a00\u758f\u6027\u548c\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6743\u91cd\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7a33\u5b9a\u6027\u7406\u8bba\uff0c\u6269\u5c55\u4e86\u73b0\u6709\u521d\u59cb\u5316\u65b9\u6848\u7684\u7406\u8bba\u57fa\u7840\u3002", "motivation": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5728\u6df1\u5ea6\u589e\u52a0\u65f6\u5bb9\u6613\u51fa\u73b0\u68af\u5ea6\u7206\u70b8\u6216\u6d88\u5931\u95ee\u9898\uff0c\u73b0\u6709\u7814\u7a76\u591a\u5c40\u9650\u4e8e\u5168\u8fde\u63a5\u7f51\u7edc\u548c\u72ec\u7acb\u540c\u5206\u5e03\u6743\u91cd\uff0c\u65e0\u6cd5\u9002\u5e94\u73b0\u4ee3\u7f51\u7edc\u7684\u7ed3\u6784\u5316\u548c\u76f8\u5173\u6027\u9700\u6c42\u3002", "method": "\u5229\u7528\u968f\u673a\u77e9\u9635\u7406\u8bba\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u5efa\u7acb\u4e86\u4e00\u4e2a\u9002\u7528\u4e8e\u7a00\u758f\u6027\u548c\u5f31\u76f8\u5173\u6743\u91cd\u7684\u7a33\u5b9a\u6027\u5b9a\u7406\u3002", "result": "\u4e3a\u66f4\u5e7f\u6cdb\u7684\u7f51\u7edc\u6a21\u578b\u63d0\u4f9b\u4e86\u8c31\u7a33\u5b9a\u6027\u7684\u4e25\u683c\u4fdd\u8bc1\uff0c\u6269\u5c55\u4e86\u521d\u59cb\u5316\u65b9\u6848\u7684\u7406\u8bba\u9002\u7528\u8303\u56f4\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5177\u6709\u7ed3\u6784\u5316\u548c\u4f9d\u8d56\u6027\u968f\u673a\u6027\u7684\u73b0\u4ee3\u795e\u7ecf\u7f51\u7edc\u63d0\u4f9b\u4e86\u66f4\u575a\u5b9e\u7684\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2506.08837", "pdf": "https://arxiv.org/pdf/2506.08837", "abs": "https://arxiv.org/abs/2506.08837", "authors": ["Luca Beurer-Kellner", "Beat Buesser Ana-Maria Cre\u0163u", "Edoardo Debenedetti", "Daniel Dobos", "Daniel Fabian", "Marc Fischer", "David Froelicher", "Kathrin Grosse", "Daniel Naeff", "Ezinwanne Ozoani", "Andrew Paverd", "Florian Tram\u00e8r", "V\u00e1clav Volhejn"], "title": "Design Patterns for Securing LLM Agents against Prompt Injections", "categories": ["cs.LG"], "comment": null, "summary": "As AI agents powered by Large Language Models (LLMs) become increasingly\nversatile and capable of addressing a broad spectrum of tasks, ensuring their\nsecurity has become a critical challenge. Among the most pressing threats are\nprompt injection attacks, which exploit the agent's resilience on natural\nlanguage inputs -- an especially dangerous threat when agents are granted tool\naccess or handle sensitive information. In this work, we propose a set of\nprincipled design patterns for building AI agents with provable resistance to\nprompt injection. We systematically analyze these patterns, discuss their\ntrade-offs in terms of utility and security, and illustrate their real-world\napplicability through a series of case studies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u5957\u8bbe\u8ba1\u6a21\u5f0f\uff0c\u7528\u4e8e\u6784\u5efa\u5177\u6709\u53ef\u8bc1\u660e\u6297\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u80fd\u529b\u7684AI\u4ee3\u7406\uff0c\u5206\u6790\u4e86\u5176\u6548\u7528\u4e0e\u5b89\u5168\u7684\u6743\u8861\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "motivation": "\u968f\u7740\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684AI\u4ee3\u7406\u80fd\u529b\u589e\u5f3a\uff0c\u5176\u5b89\u5168\u6027\u6210\u4e3a\u5173\u952e\u6311\u6218\uff0c\u5c24\u5176\u662f\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u5bf9\u5de5\u5177\u8bbf\u95ee\u6216\u654f\u611f\u4fe1\u606f\u5904\u7406\u7684\u5a01\u80c1\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u5957\u8bbe\u8ba1\u6a21\u5f0f\uff0c\u7cfb\u7edf\u5206\u6790\u5176\u6548\u7528\u4e0e\u5b89\u5168\u7684\u6743\u8861\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u3002", "result": "\u8bbe\u8ba1\u6a21\u5f0f\u4e3a\u6784\u5efa\u6297\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u7684AI\u4ee3\u7406\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\uff0c\u5e76\u5c55\u793a\u4e86\u5b9e\u9645\u5e94\u7528\u6548\u679c\u3002", "conclusion": "\u672c\u6587\u7684\u8bbe\u8ba1\u6a21\u5f0f\u4e3aAI\u4ee3\u7406\u7684\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u8df5\u6307\u5bfc\uff0c\u5e73\u8861\u4e86\u6548\u7528\u4e0e\u5b89\u5168\u3002"}}
{"id": "2506.08844", "pdf": "https://arxiv.org/pdf/2506.08844", "abs": "https://arxiv.org/abs/2506.08844", "authors": ["Siyi Sun", "David Antony Selby", "Yunchuan Huang", "Sebastian Vollmer", "Seth Flaxman", "Anisoara Calinescu"], "title": "IMAGIC-500: IMputation benchmark on A Generative Imaginary Country (500k samples)", "categories": ["cs.LG", "cs.CE"], "comment": null, "summary": "Missing data imputation in tabular datasets remains a pivotal challenge in\ndata science and machine learning, particularly within socioeconomic research.\nHowever, real-world socioeconomic datasets are typically subject to strict data\nprotection protocols, which often prohibit public sharing, even for synthetic\nderivatives. This severely limits the reproducibility and accessibility of\nbenchmark studies in such settings. Further, there are very few publicly\navailable synthetic datasets. Thus, there is limited availability of benchmarks\nfor systematic evaluation of imputation methods on socioeconomic datasets,\nwhether real or synthetic. In this study, we utilize the World Bank's publicly\navailable synthetic dataset, Synthetic Data for an Imaginary Country, which\nclosely mimics a real World Bank household survey while being fully public,\nenabling broad access for methodological research. With this as a starting\npoint, we derived the IMAGIC-500 dataset: we select a subset of 500k\nindividuals across approximately 100k households with 19 socioeconomic\nfeatures, designed to reflect the hierarchical structure of real-world\nhousehold surveys. This paper introduces a comprehensive missing data\nimputation benchmark on IMAGIC-500 under various missing mechanisms (MCAR, MAR,\nMNAR) and missingness ratios (10\\%, 20\\%, 30\\%, 40\\%, 50\\%). Our evaluation\nconsiders the imputation accuracy for continuous and categorical variables,\ncomputational efficiency, and impact on downstream predictive tasks, such as\nestimating educational attainment at the individual level. The results\nhighlight the strengths and weaknesses of statistical, traditional machine\nlearning, and deep learning imputation techniques, including recent\ndiffusion-based methods. The IMAGIC-500 dataset and benchmark aim to facilitate\nthe development of robust imputation algorithms and foster reproducible social\nscience research.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5229\u7528\u516c\u5f00\u7684\u5408\u6210\u6570\u636e\u96c6IMAGIC-500\uff0c\u8bc4\u4f30\u4e86\u4e0d\u540c\u7f3a\u5931\u6570\u636e\u586b\u8865\u65b9\u6cd5\u5728\u591a\u79cd\u7f3a\u5931\u673a\u5236\u548c\u6bd4\u4f8b\u4e0b\u7684\u8868\u73b0\uff0c\u65e8\u5728\u4fc3\u8fdb\u53ef\u590d\u73b0\u7684\u793e\u4f1a\u79d1\u5b66\u7814\u7a76\u3002", "motivation": "\u73b0\u5b9e\u793e\u4f1a\u7ecf\u6d4e\u6570\u636e\u96c6\u56e0\u9690\u79c1\u4fdd\u62a4\u96be\u4ee5\u516c\u5f00\u5171\u4eab\uff0c\u5bfc\u81f4\u586b\u8865\u65b9\u6cd5\u8bc4\u4f30\u7f3a\u4e4f\u57fa\u51c6\uff0c\u9650\u5236\u4e86\u7814\u7a76\u7684\u53ef\u590d\u73b0\u6027\u548c\u53ef\u8bbf\u95ee\u6027\u3002", "method": "\u4f7f\u7528World Bank\u7684\u5408\u6210\u6570\u636e\u96c6\uff0c\u6784\u5efaIMAGIC-500\uff0c\u8bc4\u4f30\u7edf\u8ba1\u3001\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5728\u591a\u79cd\u7f3a\u5931\u673a\u5236\u4e0b\u7684\u586b\u8865\u6548\u679c\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86\u4e0d\u540c\u586b\u8865\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\uff0c\u5e76\u63d0\u4f9b\u4e86\u5bf9\u4e0b\u6e38\u9884\u6d4b\u4efb\u52a1\u7684\u5f71\u54cd\u5206\u6790\u3002", "conclusion": "IMAGIC-500\u6570\u636e\u96c6\u548c\u57fa\u51c6\u6d4b\u8bd5\u6709\u52a9\u4e8e\u5f00\u53d1\u9c81\u68d2\u7684\u586b\u8865\u7b97\u6cd5\uff0c\u63a8\u52a8\u793e\u4f1a\u79d1\u5b66\u7814\u7a76\u7684\u53ef\u590d\u73b0\u6027\u3002"}}
{"id": "2506.08850", "pdf": "https://arxiv.org/pdf/2506.08850", "abs": "https://arxiv.org/abs/2506.08850", "authors": ["Amin Avan", "Akramul Azim", "Qusay Mahmoud"], "title": "Agile Reinforcement Learning for Real-Time Task Scheduling in Edge Computing", "categories": ["cs.LG"], "comment": null, "summary": "Soft real-time applications are becoming increasingly complex, posing\nsignificant challenges for scheduling offloaded tasks in edge computing\nenvironments while meeting task timing constraints. Moreover, the exponential\ngrowth of the search space, presence of multiple objectives and parameters, and\nhighly dynamic nature of edge computing environments further exacerbate the\ncomplexity of task scheduling. As a result, schedulers based on heuristic and\nmetaheuristic algorithms frequently encounter difficulties in generating\noptimal or near-optimal task schedules due to their constrained ability to\nadapt to the dynamic conditions and complex environmental characteristics of\nedge computing. Accordingly, reinforcement learning algorithms have been\nincorporated into schedulers to address the complexity and dynamic conditions\ninherent in task scheduling in edge computing. However, a significant\nlimitation of reinforcement learning algorithms is the prolonged learning time\nrequired to adapt to new environments and to address medium- and large-scale\nproblems. This challenge arises from the extensive global action space and\nfrequent random exploration of irrelevant actions. Therefore, this study\nproposes Agile Reinforcement learning (aRL), in which the RL-agent performs\ninformed exploration and executes only relevant actions. Consequently, the\npredictability of the RL-agent is enhanced, leading to rapid adaptation and\nconvergence, which positions aRL as a suitable candidate for scheduling the\ntasks of soft real-time applications in edge computing. The experiments\ndemonstrate that the combination of informed exploration and action-masking\nmethods enables aRL to achieve a higher hit-ratio and converge faster than the\nbaseline approaches.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u654f\u6377\u5f3a\u5316\u5b66\u4e60\uff08aRL\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u667a\u80fd\u63a2\u7d22\u548c\u52a8\u4f5c\u5c4f\u853d\u6280\u672f\u4f18\u5316\u8fb9\u7f18\u8ba1\u7b97\u4e2d\u7684\u4efb\u52a1\u8c03\u5ea6\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u9002\u5e94\u6027\u95ee\u9898\u3002", "motivation": "\u8fb9\u7f18\u8ba1\u7b97\u73af\u5883\u4e2d\u4efb\u52a1\u8c03\u5ea6\u7684\u590d\u6742\u6027\u3001\u52a8\u6001\u6027\u548c\u591a\u76ee\u6807\u6027\u5bfc\u81f4\u4f20\u7edf\u542f\u53d1\u5f0f\u7b97\u6cd5\u96be\u4ee5\u751f\u6210\u6700\u4f18\u8c03\u5ea6\u65b9\u6848\uff0c\u800c\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u53c8\u56e0\u5b66\u4e60\u65f6\u95f4\u8fc7\u957f\u800c\u53d7\u9650\u3002", "method": "\u63d0\u51faaRL\u65b9\u6cd5\uff0c\u7ed3\u5408\u667a\u80fd\u63a2\u7d22\u548c\u52a8\u4f5c\u5c4f\u853d\u6280\u672f\uff0c\u51cf\u5c11\u65e0\u5173\u52a8\u4f5c\u7684\u968f\u673a\u63a2\u7d22\uff0c\u63d0\u5347RL-agent\u7684\u9884\u6d4b\u6027\u548c\u9002\u5e94\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0caRL\u5728\u547d\u4e2d\u7387\u548c\u6536\u655b\u901f\u5ea6\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "aRL\u662f\u4e00\u79cd\u9002\u7528\u4e8e\u8fb9\u7f18\u8ba1\u7b97\u4e2d\u8f6f\u5b9e\u65f6\u5e94\u7528\u4efb\u52a1\u8c03\u5ea6\u7684\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2506.08871", "pdf": "https://arxiv.org/pdf/2506.08871", "abs": "https://arxiv.org/abs/2506.08871", "authors": ["Victor M. Tenorio", "Madeline Navarro", "Samuel Rey", "Santiago Segarra", "Antonio G. Marques"], "title": "Adapting to Heterophilic Graph Data with Structure-Guided Neighbor Discovery", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Graph Neural Networks (GNNs) often struggle with heterophilic data, where\nconnected nodes may have dissimilar labels, as they typically assume homophily\nand rely on local message passing. To address this, we propose creating\nalternative graph structures by linking nodes with similar structural\nattributes (e.g., role-based or global), thereby fostering higher label\nhomophily on these new graphs. We theoretically prove that GNN performance can\nbe improved by utilizing graphs with fewer false positive edges (connections\nbetween nodes of different classes) and that considering multiple graph views\nincreases the likelihood of finding such beneficial structures. Building on\nthese insights, we introduce Structure-Guided GNN (SG-GNN), an architecture\nthat processes the original graph alongside the newly created structural\ngraphs, adaptively learning to weigh their contributions. Extensive experiments\non various benchmark datasets, particularly those with heterophilic\ncharacteristics, demonstrate that our SG-GNN achieves state-of-the-art or\nhighly competitive performance, highlighting the efficacy of exploiting\nstructural information to guide GNNs.", "AI": {"tldr": "SG-GNN\u901a\u8fc7\u6784\u5efa\u57fa\u4e8e\u7ed3\u6784\u5c5e\u6027\u7684\u65b0\u56fe\uff0c\u63d0\u5347\u5f02\u8d28\u6027\u6570\u636e\u4e0a\u7684GNN\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3GNN\u5728\u5f02\u8d28\u6027\u6570\u636e\uff08\u8fde\u63a5\u8282\u70b9\u6807\u7b7e\u4e0d\u540c\uff09\u4e0a\u7684\u6027\u80fd\u95ee\u9898\u3002", "method": "\u521b\u5efa\u57fa\u4e8e\u7ed3\u6784\u5c5e\u6027\u7684\u65b0\u56fe\uff0c\u7ed3\u5408\u539f\u59cb\u56fe\u548c\u591a\u89c6\u56fe\u7ed3\u6784\uff0c\u81ea\u9002\u5e94\u5b66\u4e60\u6743\u91cd\u3002", "result": "\u5728\u5f02\u8d28\u6027\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u6216\u63a5\u8fd1\u6700\u4f18\u6027\u80fd\u3002", "conclusion": "\u5229\u7528\u7ed3\u6784\u4fe1\u606f\u6307\u5bfcGNN\u53ef\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2506.08882", "pdf": "https://arxiv.org/pdf/2506.08882", "abs": "https://arxiv.org/abs/2506.08882", "authors": ["Dimitrios Amaxilatis", "Themistoklis Sarantakos", "Ioannis Chatzigiannakis", "Georgios Mylonas"], "title": "Filling in the Blanks: Applying Data Imputation in incomplete Water Metering Data", "categories": ["cs.LG"], "comment": null, "summary": "In this work, we explore the application of recent data imputation techniques\nto enhance monitoring and management of water distribution networks using smart\nwater meters, based on data derived from a real-world IoT water grid monitoring\ndeployment. Despite the detailed data produced by such meters, data gaps due to\ntechnical issues can significantly impact operational decisions and efficiency.\nOur results, by comparing various imputation methods, such as k-Nearest\nNeighbors, MissForest, Transformers, and Recurrent Neural Networks, indicate\nthat effective data imputation can substantially enhance the quality of the\ninsights derived from water consumption data as we study their effect on\naccuracy and reliability of water metering data to provide solutions in\napplications like leak detection and predictive maintenance scheduling.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u6570\u636e\u63d2\u8865\u6280\u672f\u5728\u667a\u80fd\u6c34\u8868\u76d1\u6d4b\u4e2d\u7684\u5e94\u7528\uff0c\u901a\u8fc7\u6bd4\u8f83\u591a\u79cd\u63d2\u8865\u65b9\u6cd5\uff0c\u53d1\u73b0\u5176\u80fd\u663e\u8457\u63d0\u5347\u6c34\u8d28\u6570\u636e\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u667a\u80fd\u6c34\u8868\u6570\u636e\u56e0\u6280\u672f\u95ee\u9898\u5b58\u5728\u7f3a\u5931\uff0c\u5f71\u54cd\u8fd0\u8425\u51b3\u7b56\u548c\u6548\u7387\uff0c\u9700\u901a\u8fc7\u6570\u636e\u63d2\u8865\u63d0\u5347\u6570\u636e\u8d28\u91cf\u3002", "method": "\u6bd4\u8f83\u4e86k-\u6700\u8fd1\u90bb\u3001MissForest\u3001Transformer\u548c\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u7b49\u591a\u79cd\u6570\u636e\u63d2\u8865\u65b9\u6cd5\u3002", "result": "\u6709\u6548\u7684\u6570\u636e\u63d2\u8865\u663e\u8457\u63d0\u5347\u4e86\u6c34\u8d28\u6570\u636e\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\uff0c\u652f\u6301\u6f0f\u635f\u68c0\u6d4b\u548c\u9884\u6d4b\u6027\u7ef4\u62a4\u7b49\u5e94\u7528\u3002", "conclusion": "\u6570\u636e\u63d2\u8865\u6280\u672f\u80fd\u663e\u8457\u6539\u5584\u667a\u80fd\u6c34\u8868\u6570\u636e\u7684\u8d28\u91cf\uff0c\u4e3a\u6c34\u52a1\u7ba1\u7406\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u51b3\u7b56\u652f\u6301\u3002"}}
{"id": "2506.08884", "pdf": "https://arxiv.org/pdf/2506.08884", "abs": "https://arxiv.org/abs/2506.08884", "authors": ["Shiqin Tang", "Shujian Yu"], "title": "InfoDPCCA: Information-Theoretic Dynamic Probabilistic Canonical Correlation Analysis", "categories": ["cs.LG", "cs.IT", "math.IT"], "comment": "accepted by UAI-25, code is available at\n  \\url{https://github.com/marcusstang/InfoDPCCA}", "summary": "Extracting meaningful latent representations from high-dimensional sequential\ndata is a crucial challenge in machine learning, with applications spanning\nnatural science and engineering. We introduce InfoDPCCA, a dynamic\nprobabilistic Canonical Correlation Analysis (CCA) framework designed to model\ntwo interdependent sequences of observations. InfoDPCCA leverages a novel\ninformation-theoretic objective to extract a shared latent representation that\ncaptures the mutual structure between the data streams and balances\nrepresentation compression and predictive sufficiency while also learning\nseparate latent components that encode information specific to each sequence.\nUnlike prior dynamic CCA models, such as DPCCA, our approach explicitly\nenforces the shared latent space to encode only the mutual information between\nthe sequences, improving interpretability and robustness. We further introduce\na two-step training scheme to bridge the gap between information-theoretic\nrepresentation learning and generative modeling, along with a residual\nconnection mechanism to enhance training stability. Through experiments on\nsynthetic and medical fMRI data, we demonstrate that InfoDPCCA excels as a tool\nfor representation learning. Code of InfoDPCCA is available at\nhttps://github.com/marcusstang/InfoDPCCA.", "AI": {"tldr": "InfoDPCCA\u662f\u4e00\u79cd\u52a8\u6001\u6982\u7387CCA\u6846\u67b6\uff0c\u7528\u4e8e\u5efa\u6a21\u4e24\u4e2a\u76f8\u4e92\u4f9d\u8d56\u7684\u89c2\u6d4b\u5e8f\u5217\uff0c\u901a\u8fc7\u4fe1\u606f\u8bba\u76ee\u6807\u63d0\u53d6\u5171\u4eab\u6f5c\u5728\u8868\u793a\uff0c\u5e76\u5b66\u4e60\u5e8f\u5217\u7279\u5b9a\u7684\u6f5c\u5728\u6210\u5206\u3002", "motivation": "\u4ece\u9ad8\u7ef4\u5e8f\u5217\u6570\u636e\u4e2d\u63d0\u53d6\u6709\u610f\u4e49\u7684\u6f5c\u5728\u8868\u793a\u662f\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u5c24\u5176\u5728\u81ea\u7136\u79d1\u5b66\u548c\u5de5\u7a0b\u9886\u57df\u6709\u5e7f\u6cdb\u5e94\u7528\u3002", "method": "InfoDPCCA\u91c7\u7528\u4fe1\u606f\u8bba\u76ee\u6807\u63d0\u53d6\u5171\u4eab\u6f5c\u5728\u8868\u793a\uff0c\u5e76\u901a\u8fc7\u4e24\u6b65\u8bad\u7ec3\u65b9\u6848\u548c\u6b8b\u5dee\u8fde\u63a5\u673a\u5236\u63d0\u5347\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cInfoDPCCA\u5728\u5408\u6210\u548c\u533b\u5b66fMRI\u6570\u636e\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u662f\u4e00\u79cd\u6709\u6548\u7684\u8868\u793a\u5b66\u4e60\u5de5\u5177\u3002", "conclusion": "InfoDPCCA\u901a\u8fc7\u660e\u786e\u7f16\u7801\u5e8f\u5217\u95f4\u7684\u4e92\u4fe1\u606f\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u89e3\u91ca\u6027\u548c\u9c81\u68d2\u6027\uff0c\u4f18\u4e8e\u73b0\u6709\u52a8\u6001CCA\u6a21\u578b\u3002"}}
{"id": "2506.08889", "pdf": "https://arxiv.org/pdf/2506.08889", "abs": "https://arxiv.org/abs/2506.08889", "authors": ["Yizhao Gao", "Shuming Guo", "Shijie Cao", "Yuqing Xia", "Yu Cheng", "Lei Wang", "Lingxiao Ma", "Yutao Sun", "Tianzhu Ye", "Li Dong", "Hayden Kwok-Hay So", "Yu Hua", "Ting Cao", "Fan Yang", "Mao Yang"], "title": "SeerAttention-R: Sparse Attention Adaptation for Long Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We introduce SeerAttention-R, a sparse attention framework specifically\ntailored for the long decoding of reasoning models. Extended from\nSeerAttention, SeerAttention-R retains the design of learning attention\nsparsity through a self-distilled gating mechanism, while removing query\npooling to accommodate auto-regressive decoding. With a lightweight plug-in\ngating, SeerAttention-R is flexible and can be easily integrated into existing\npretrained model without modifying the original parameters. We demonstrate that\nSeerAttention-R, trained on just 0.4B tokens, maintains near-lossless reasoning\naccuracy with 4K token budget in AIME benchmark under large sparse attention\nblock sizes (64/128). Using TileLang, we develop a highly optimized sparse\ndecoding kernel that achieves near-theoretical speedups of up to 9x over\nFlashAttention-3 on H100 GPU at 90% sparsity. Code is available at:\nhttps://github.com/microsoft/SeerAttention.", "AI": {"tldr": "SeerAttention-R\u662f\u4e00\u79cd\u7a00\u758f\u6ce8\u610f\u529b\u6846\u67b6\uff0c\u4e13\u4e3a\u63a8\u7406\u6a21\u578b\u7684\u957f\u89e3\u7801\u8bbe\u8ba1\uff0c\u901a\u8fc7\u81ea\u84b8\u998f\u95e8\u63a7\u673a\u5236\u5b66\u4e60\u6ce8\u610f\u529b\u7a00\u758f\u6027\uff0c\u4fdd\u6301\u9ad8\u63a8\u7406\u7cbe\u5ea6\uff0c\u5e76\u5728H100 GPU\u4e0a\u5b9e\u73b09\u500d\u52a0\u901f\u3002", "motivation": "\u89e3\u51b3\u957f\u89e3\u7801\u63a8\u7406\u6a21\u578b\u4e2d\u6ce8\u610f\u529b\u673a\u5236\u7684\u8ba1\u7b97\u6548\u7387\u548c\u7a00\u758f\u6027\u95ee\u9898\u3002", "method": "\u6269\u5c55SeerAttention\u6846\u67b6\uff0c\u79fb\u9664\u67e5\u8be2\u6c60\u5316\u4ee5\u9002\u5e94\u81ea\u56de\u5f52\u89e3\u7801\uff0c\u5f15\u5165\u8f7b\u91cf\u7ea7\u95e8\u63a7\u673a\u5236\u3002", "result": "\u5728AIME\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4ec5\u75280.4B token\u8bad\u7ec3\uff0c4K token\u9884\u7b97\u4e0b\u4fdd\u6301\u63a5\u8fd1\u65e0\u635f\u7684\u63a8\u7406\u7cbe\u5ea6\uff1b\u5728H100 GPU\u4e0a\u5b9e\u73b09\u500d\u52a0\u901f\u3002", "conclusion": "SeerAttention-R\u662f\u4e00\u79cd\u9ad8\u6548\u3001\u7075\u6d3b\u7684\u7a00\u758f\u6ce8\u610f\u529b\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u957f\u89e3\u7801\u63a8\u7406\u4efb\u52a1\u3002"}}
{"id": "2506.08902", "pdf": "https://arxiv.org/pdf/2506.08902", "abs": "https://arxiv.org/abs/2506.08902", "authors": ["Chongyi Zheng", "Seohong Park", "Sergey Levine", "Benjamin Eysenbach"], "title": "Intention-Conditioned Flow Occupancy Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large-scale pre-training has fundamentally changed how machine learning\nresearch is done today: large foundation models are trained once, and then can\nbe used by anyone in the community (including those without data or compute\nresources to train a model from scratch) to adapt and fine-tune to specific\ntasks. Applying this same framework to reinforcement learning (RL) is appealing\nbecause it offers compelling avenues for addressing core challenges in RL,\nincluding sample efficiency and robustness. However, there remains a\nfundamental challenge to pre-train large models in the context of RL: actions\nhave long-term dependencies, so training a foundation model that reasons across\ntime is important. Recent advances in generative AI have provided new tools for\nmodeling highly complex distributions. In this paper, we build a probabilistic\nmodel to predict which states an agent will visit in the temporally distant\nfuture (i.e., an occupancy measure) using flow matching. As large datasets are\noften constructed by many distinct users performing distinct tasks, we include\nin our model a latent variable capturing the user intention. This intention\nincreases the expressivity of our model, and enables adaptation with\ngeneralized policy improvement. We call our proposed method\nintention-conditioned flow occupancy models (InFOM). Comparing with alternative\nmethods for pre-training, our experiments on $36$ state-based and $4$\nimage-based benchmark tasks demonstrate that the proposed method achieves $1.8\n\\times$ median improvement in returns and increases success rates by $36\\%$.\nWebsite: https://chongyi-zheng.github.io/infom Code:\nhttps://github.com/chongyi-zheng/infom", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6d41\u5339\u914d\u7684\u6982\u7387\u6a21\u578b\uff08InFOM\uff09\uff0c\u7528\u4e8e\u9884\u6d4b\u667a\u80fd\u4f53\u5728\u957f\u671f\u672a\u6765\u53ef\u80fd\u8bbf\u95ee\u7684\u72b6\u6001\uff0c\u5e76\u901a\u8fc7\u6f5c\u5728\u53d8\u91cf\u6355\u6349\u7528\u6237\u610f\u56fe\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5f3a\u5316\u5b66\u4e60\u7684\u9884\u8bad\u7ec3\u6548\u679c\u3002", "motivation": "\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u53d6\u5f97\u4e86\u6210\u529f\uff0c\u4f46\u5728\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u4e2d\u4ecd\u9762\u4e34\u957f\u671f\u4f9d\u8d56\u7684\u6311\u6218\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u5efa\u6a21\u672a\u6765\u72b6\u6001\u5206\u5e03\u548c\u7528\u6237\u610f\u56fe\uff0c\u63d0\u5347RL\u7684\u6837\u672c\u6548\u7387\u548c\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6d41\u5339\u914d\u7684\u6982\u7387\u6a21\u578b\uff08InFOM\uff09\uff0c\u901a\u8fc7\u6f5c\u5728\u53d8\u91cf\u6355\u6349\u7528\u6237\u610f\u56fe\uff0c\u5e76\u5229\u7528\u5e7f\u4e49\u7b56\u7565\u6539\u8fdb\u5b9e\u73b0\u6a21\u578b\u9002\u5e94\u3002", "result": "\u572836\u4e2a\u57fa\u4e8e\u72b6\u6001\u548c4\u4e2a\u57fa\u4e8e\u56fe\u50cf\u7684\u57fa\u51c6\u4efb\u52a1\u4e2d\uff0cInFOM\u7684\u4e2d\u4f4d\u56de\u62a5\u63d0\u5347\u4e861.8\u500d\uff0c\u6210\u529f\u7387\u63d0\u9ad8\u4e8636%\u3002", "conclusion": "InFOM\u901a\u8fc7\u5efa\u6a21\u672a\u6765\u72b6\u6001\u548c\u7528\u6237\u610f\u56fe\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5f3a\u5316\u5b66\u4e60\u7684\u9884\u8bad\u7ec3\u6548\u679c\uff0c\u4e3aRL\u7684\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.08916", "pdf": "https://arxiv.org/pdf/2506.08916", "abs": "https://arxiv.org/abs/2506.08916", "authors": ["Maria-Veronica Ciocanel", "John T. Nardini", "Kevin B. Flores", "Erica M. Rutter", "Suzanne S. Sindi", "Alexandria Volkening"], "title": "Enhancing generalizability of model discovery across parameter space with multi-experiment equation learning (ME-EQL)", "categories": ["cs.LG", "math.DS", "q-bio.QM"], "comment": "31 pages, 10 figures", "summary": "Agent-based modeling (ABM) is a powerful tool for understanding\nself-organizing biological systems, but it is computationally intensive and\noften not analytically tractable. Equation learning (EQL) methods can derive\ncontinuum models from ABM data, but they typically require extensive\nsimulations for each parameter set, raising concerns about generalizability. In\nthis work, we extend EQL to Multi-experiment equation learning (ME-EQL) by\nintroducing two methods: one-at-a-time ME-EQL (OAT ME-EQL), which learns\nindividual models for each parameter set and connects them via interpolation,\nand embedded structure ME-EQL (ES ME-EQL), which builds a unified model library\nacross parameters. We demonstrate these methods using a birth--death mean-field\nmodel and an on-lattice agent-based model of birth, death, and migration with\nspatial structure. Our results show that both methods significantly reduce the\nrelative error in recovering parameters from agent-based simulations, with OAT\nME-EQL offering better generalizability across parameter space. Our findings\nhighlight the potential of equation learning from multiple experiments to\nenhance the generalizability and interpretability of learned models for complex\nbiological systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u5b9e\u9a8c\u65b9\u7a0b\u5b66\u4e60\uff08ME-EQL\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e24\u79cd\u5177\u4f53\u65b9\u6cd5\uff08OAT ME-EQL\u548cES ME-EQL\uff09\u4eceABM\u6570\u636e\u4e2d\u5b66\u4e60\u8fde\u7eed\u6a21\u578b\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u53c2\u6570\u6062\u590d\u8bef\u5dee\uff0c\u5e76\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u901a\u7528\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u57fa\u4e8e\u4ee3\u7406\u7684\u5efa\u6a21\uff08ABM\uff09\u5728\u7406\u89e3\u81ea\u7ec4\u7ec7\u751f\u7269\u7cfb\u7edf\u65b9\u9762\u5177\u6709\u5f3a\u5927\u80fd\u529b\uff0c\u4f46\u5176\u8ba1\u7b97\u5bc6\u96c6\u4e14\u96be\u4ee5\u89e3\u6790\u3002\u73b0\u6709\u7684\u65b9\u7a0b\u5b66\u4e60\uff08EQL\uff09\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u6a21\u62df\uff0c\u901a\u7528\u6027\u53d7\u9650\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u79cdME-EQL\u65b9\u6cd5\uff1aOAT ME-EQL\uff08\u9010\u4e2a\u53c2\u6570\u5b66\u4e60\u5e76\u901a\u8fc7\u63d2\u503c\u8fde\u63a5\uff09\u548cES ME-EQL\uff08\u6784\u5efa\u8de8\u53c2\u6570\u7684\u7edf\u4e00\u6a21\u578b\u5e93\uff09\u3002", "result": "\u4e24\u79cd\u65b9\u6cd5\u5747\u663e\u8457\u964d\u4f4e\u4e86\u4eceABM\u6a21\u62df\u4e2d\u6062\u590d\u53c2\u6570\u7684\u76f8\u5bf9\u8bef\u5dee\uff0c\u5176\u4e2dOAT ME-EQL\u5728\u53c2\u6570\u7a7a\u95f4\u4e2d\u7684\u901a\u7528\u6027\u66f4\u597d\u3002", "conclusion": "\u591a\u5b9e\u9a8c\u65b9\u7a0b\u5b66\u4e60\u80fd\u591f\u63d0\u5347\u590d\u6742\u751f\u7269\u7cfb\u7edf\u5b66\u4e60\u6a21\u578b\u7684\u901a\u7528\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2506.08928", "pdf": "https://arxiv.org/pdf/2506.08928", "abs": "https://arxiv.org/abs/2506.08928", "authors": ["Zhongyuan Liang", "Zachary T. Rewolinski", "Abhineet Agarwal", "Tiffany M. Tang", "Bin Yu"], "title": "Local MDI+: Local Feature Importances for Tree-Based Models", "categories": ["cs.LG", "stat.ME", "stat.ML"], "comment": null, "summary": "Tree-based ensembles such as random forests remain the go-to for tabular data\nover deep learning models due to their prediction performance and computational\nefficiency. These advantages have led to their widespread deployment in\nhigh-stakes domains, where interpretability is essential for ensuring\ntrustworthy predictions. This has motivated the development of popular local\n(i.e. sample-specific) feature importance (LFI) methods such as LIME and\nTreeSHAP. However, these approaches rely on approximations that ignore the\nmodel's internal structure and instead depend on potentially unstable\nperturbations. These issues are addressed in the global setting by MDI+, a\nfeature importance method which exploits an equivalence between decision trees\nand linear models on a transformed node basis. However, the global MDI+ scores\nare not able to explain predictions when faced with heterogeneous individual\ncharacteristics. To address this gap, we propose Local MDI+ (LMDI+), a novel\nextension of the MDI+ framework to the sample specific setting. LMDI+\noutperforms existing baselines LIME and TreeSHAP in identifying\ninstance-specific signal features, averaging a 10% improvement in downstream\ntask performance across twelve real-world benchmark datasets. It further\ndemonstrates greater stability by consistently producing similar instance-level\nfeature importance rankings across multiple random forest fits. Finally, LMDI+\nenables local interpretability use cases, including the identification of\ncloser counterfactuals and the discovery of homogeneous subgroups.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLMDI+\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u73b0\u6709\u5c40\u90e8\u7279\u5f81\u91cd\u8981\u6027\u65b9\u6cd5\uff08\u5982LIME\u548cTreeSHAP\uff09\u5728\u89e3\u91ca\u6811\u6a21\u578b\u9884\u6d4b\u65f6\u7684\u4e0d\u8db3\u3002LMDI+\u901a\u8fc7\u6269\u5c55\u5168\u5c40MDI+\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5b9e\u4f8b\u7279\u5b9a\u7279\u5f81\u8bc6\u522b\u7684\u6027\u80fd\uff0c\u5e76\u5728\u591a\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u6811\u6a21\u578b\uff08\u5982\u968f\u673a\u68ee\u6797\uff09\u5728\u9ad8\u98ce\u9669\u9886\u57df\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5176\u5c40\u90e8\u7279\u5f81\u91cd\u8981\u6027\u65b9\u6cd5\uff08\u5982LIME\u548cTreeSHAP\uff09\u4f9d\u8d56\u8fd1\u4f3c\u548c\u6270\u52a8\uff0c\u5bfc\u81f4\u89e3\u91ca\u4e0d\u7a33\u5b9a\u3002MDI+\u5728\u5168\u5c40\u8bbe\u5b9a\u4e2d\u89e3\u51b3\u4e86\u8fd9\u4e00\u95ee\u9898\uff0c\u4f46\u65e0\u6cd5\u5904\u7406\u4e2a\u4f53\u5f02\u8d28\u6027\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u7a33\u5b9a\u7684\u5c40\u90e8\u89e3\u91ca\u65b9\u6cd5\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86LMDI+\uff0c\u5c06MDI+\u6846\u67b6\u6269\u5c55\u5230\u6837\u672c\u7279\u5b9a\u8bbe\u5b9a\uff0c\u5229\u7528\u51b3\u7b56\u6811\u4e0e\u7ebf\u6027\u6a21\u578b\u5728\u8282\u70b9\u57fa\u4e0a\u7684\u7b49\u4ef7\u6027\uff0c\u751f\u6210\u66f4\u7a33\u5b9a\u7684\u5c40\u90e8\u7279\u5f81\u91cd\u8981\u6027\u3002", "result": "LMDI+\u572812\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5e73\u5747\u63d0\u5347\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd10%\uff0c\u5e76\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u7a33\u5b9a\u6027\uff0c\u80fd\u751f\u6210\u4e00\u81f4\u7684\u5b9e\u4f8b\u7ea7\u7279\u5f81\u91cd\u8981\u6027\u6392\u540d\u3002\u6b64\u5916\uff0cLMDI+\u8fd8\u652f\u6301\u5c40\u90e8\u53ef\u89e3\u91ca\u6027\u7528\u4f8b\uff0c\u5982\u8bc6\u522b\u66f4\u63a5\u8fd1\u7684\u53cd\u4e8b\u5b9e\u548c\u53d1\u73b0\u540c\u8d28\u5b50\u7ec4\u3002", "conclusion": "LMDI+\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u5c40\u90e8\u7279\u5f81\u91cd\u8981\u6027\u65b9\u6cd5\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u4e3a\u6811\u6a21\u578b\u7684\u89e3\u91ca\u63d0\u4f9b\u4e86\u66f4\u7a33\u5b9a\u548c\u51c6\u786e\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.08936", "pdf": "https://arxiv.org/pdf/2506.08936", "abs": "https://arxiv.org/abs/2506.08936", "authors": ["Amina Mollaysa", "Artem Moskale", "Pushpak Pati", "Tommaso Mansi", "Mangal Prakash", "Rui Liao"], "title": "BioLangFusion: Multimodal Fusion of DNA, mRNA, and Protein Language Models", "categories": ["cs.LG"], "comment": "Proceedings of ICML 2025 Workshop on Multi-modal Foundation\n  Proceedings of ICML 2025 Workshop on Multi-modal Foundation Proceedings of\n  ICML 2025 Workshop on Multi-modal Foundation Models and Large Language Models\n  for Life Sciences", "summary": "We present BioLangFusion, a simple approach for integrating pre-trained DNA,\nmRNA, and protein language models into unified molecular representations.\nMotivated by the central dogma of molecular biology (information flow from gene\nto transcript to protein), we align per-modality embeddings at the biologically\nmeaningful codon level (three nucleotides encoding one amino acid) to ensure\ndirect cross-modal correspondence. BioLangFusion studies three standard fusion\ntechniques: (i) codon-level embedding concatenation, (ii) entropy-regularized\nattention pooling inspired by multiple-instance learning, and (iii) cross-modal\nmulti-head attention -- each technique providing a different inductive bias for\ncombining modality-specific signals. These methods require no additional\npre-training or modification of the base models, allowing straightforward\nintegration with existing sequence-based foundation models. Across five\nmolecular property prediction tasks, BioLangFusion outperforms strong unimodal\nbaselines, showing that even simple fusion of pre-trained models can capture\ncomplementary multi-omic information with minimal overhead.", "AI": {"tldr": "BioLangFusion\u901a\u8fc7\u6574\u5408\u9884\u8bad\u7ec3\u7684DNA\u3001mRNA\u548c\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\uff0c\u751f\u6210\u7edf\u4e00\u7684\u5206\u5b50\u8868\u793a\uff0c\u5728\u5206\u5b50\u5c5e\u6027\u9884\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u5355\u6a21\u6001\u57fa\u7ebf\u3002", "motivation": "\u53d7\u5206\u5b50\u751f\u7269\u5b66\u4e2d\u5fc3\u6cd5\u5219\uff08\u4fe1\u606f\u4ece\u57fa\u56e0\u5230\u8f6c\u5f55\u672c\u518d\u5230\u86cb\u767d\u8d28\u7684\u6d41\u52a8\uff09\u542f\u53d1\uff0c\u7814\u7a76\u5982\u4f55\u6574\u5408\u591a\u6a21\u6001\u5206\u5b50\u6570\u636e\u3002", "method": "\u91c7\u7528\u4e09\u79cd\u6807\u51c6\u878d\u5408\u6280\u672f\uff1a\u5bc6\u7801\u5b50\u7ea7\u5d4c\u5165\u62fc\u63a5\u3001\u71b5\u6b63\u5219\u5316\u6ce8\u610f\u529b\u6c60\u5316\u548c\u8de8\u6a21\u6001\u591a\u5934\u6ce8\u610f\u529b\uff0c\u65e0\u9700\u989d\u5916\u9884\u8bad\u7ec3\u3002", "result": "\u5728\u4e94\u4e2a\u5206\u5b50\u5c5e\u6027\u9884\u6d4b\u4efb\u52a1\u4e2d\uff0cBioLangFusion\u4f18\u4e8e\u5355\u6a21\u6001\u57fa\u7ebf\uff0c\u8868\u660e\u7b80\u5355\u878d\u5408\u9884\u8bad\u7ec3\u6a21\u578b\u5373\u53ef\u6355\u83b7\u4e92\u8865\u7684\u591a\u7ec4\u5b66\u4fe1\u606f\u3002", "conclusion": "BioLangFusion\u5c55\u793a\u4e86\u901a\u8fc7\u7b80\u5355\u878d\u5408\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u53ef\u4ee5\u9ad8\u6548\u6574\u5408\u591a\u6a21\u6001\u5206\u5b50\u6570\u636e\uff0c\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2506.08939", "pdf": "https://arxiv.org/pdf/2506.08939", "abs": "https://arxiv.org/abs/2506.08939", "authors": ["Hang Ye", "Gaoxiang Duan", "Haoran Zeng", "Yangxin Zhu", "Lingxue Meng", "Xiaoying Zheng", "Yongxin Zhu"], "title": "KARMA: A Multilevel Decomposition Hybrid Mamba Framework for Multivariate Long-Term Time Series Forecasting", "categories": ["cs.LG"], "comment": "10 pages,3 figures, published to WASA2025", "summary": "Multivariate long-term and efficient time series forecasting is a key\nrequirement for a variety of practical applications, and there are complex\ninterleaving time dynamics in time series data that require decomposition\nmodeling. Traditional time series decomposition methods are single and rely on\nfixed rules, which are insufficient for mining the potential information of the\nseries and adapting to the dynamic characteristics of complex series. On the\nother hand, the Transformer-based models for time series forecasting struggle\nto effectively model long sequences and intricate dynamic relationships due to\ntheir high computational complexity. To overcome these limitations, we\nintroduce KARMA, with an Adaptive Time Channel Decomposition module (ATCD) to\ndynamically extract trend and seasonal components. It further integrates a\nHybrid Frequency-Time Decomposition module (HFTD) to further decompose Series\ninto frequency-domain and time-domain. These components are coupled with\nmulti-scale Mamba-based KarmaBlock to efficiently process global and local\ninformation in a coordinated manner. Experiments on eight real-world datasets\nfrom diverse domains well demonstrated that KARMA significantly outperforms\nmainstream baseline methods in both predictive accuracy and computational\nefficiency. Code and full results are available at this repository:\nhttps://github.com/yedadasd/KARMA", "AI": {"tldr": "KARMA\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u65f6\u95f4\u901a\u9053\u5206\u89e3\u6a21\u5757\uff08ATCD\uff09\u548c\u6df7\u5408\u9891\u7387-\u65f6\u95f4\u5206\u89e3\u6a21\u5757\uff08HFTD\uff09\uff0c\u7ed3\u5408\u591a\u5c3a\u5ea6Mamba-based KarmaBlock\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u53d8\u91cf\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u65f6\u95f4\u5e8f\u5217\u5206\u89e3\u65b9\u6cd5\u5355\u4e00\u4e14\u4f9d\u8d56\u56fa\u5b9a\u89c4\u5219\uff0c\u65e0\u6cd5\u6316\u6398\u6f5c\u5728\u4fe1\u606f\u6216\u9002\u5e94\u590d\u6742\u52a8\u6001\u7279\u6027\uff1bTransformer\u6a21\u578b\u56e0\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u800c\u96be\u4ee5\u6709\u6548\u5efa\u6a21\u957f\u5e8f\u5217\u548c\u590d\u6742\u52a8\u6001\u5173\u7cfb\u3002", "method": "KARMA\u901a\u8fc7ATCD\u52a8\u6001\u63d0\u53d6\u8d8b\u52bf\u548c\u5b63\u8282\u6027\u6210\u5206\uff0cHFTD\u8fdb\u4e00\u6b65\u5206\u89e3\u5e8f\u5217\u4e3a\u9891\u57df\u548c\u65f6\u57df\uff0c\u7ed3\u5408\u591a\u5c3a\u5ea6KarmaBlock\u534f\u8c03\u5904\u7406\u5168\u5c40\u548c\u5c40\u90e8\u4fe1\u606f\u3002", "result": "\u5728\u516b\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cKARMA\u5728\u9884\u6d4b\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u663e\u8457\u4f18\u4e8e\u4e3b\u6d41\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "KARMA\u901a\u8fc7\u52a8\u6001\u5206\u89e3\u548c\u9ad8\u6548\u4fe1\u606f\u5904\u7406\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u548cTransformer\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u591a\u53d8\u91cf\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.08961", "pdf": "https://arxiv.org/pdf/2506.08961", "abs": "https://arxiv.org/abs/2506.08961", "authors": ["Chenxu Wang", "Huaping Liu"], "title": "Towards Robust Deep Reinforcement Learning against Environmental State Perturbation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Adversarial attacks and robustness in Deep Reinforcement Learning (DRL) have\nbeen widely studied in various threat models; however, few consider\nenvironmental state perturbations, which are natural in embodied scenarios. To\nimprove the robustness of DRL agents, we formulate the problem of environmental\nstate perturbation, introducing a preliminary non-targeted attack method as a\ncalibration adversary, and then propose a defense framework, named Boosted\nAdversarial Training (BAT), which first tunes the agents via supervised\nlearning to avoid catastrophic failure and subsequently adversarially trains\nthe agent with reinforcement learning. Extensive experimental results\nsubstantiate the vulnerability of mainstream agents under environmental state\nperturbations and the effectiveness of our proposed attack. The defense results\ndemonstrate that while existing robust reinforcement learning algorithms may\nnot be suitable, our BAT framework can significantly enhance the robustness of\nagents against environmental state perturbations across various situations.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u4e2d\u73af\u5883\u72b6\u6001\u6270\u52a8\u7684\u5bf9\u6297\u653b\u51fb\u4e0e\u9632\u5fa1\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aBAT\u7684\u9632\u5fa1\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7406\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8f83\u5c11\u5173\u6ce8\u73af\u5883\u72b6\u6001\u6270\u52a8\uff0c\u800c\u8fd9\u662f\u5177\u8eab\u573a\u666f\u4e2d\u7684\u81ea\u7136\u73b0\u8c61\uff0c\u56e0\u6b64\u9700\u8981\u63d0\u5347DRL\u4ee3\u7406\u5728\u6b64\u7c7b\u6270\u52a8\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "method": "\u9996\u5148\u63d0\u51fa\u4e00\u79cd\u975e\u76ee\u6807\u653b\u51fb\u65b9\u6cd5\u4f5c\u4e3a\u6821\u51c6\u5bf9\u624b\uff0c\u968f\u540e\u8bbe\u8ba1BAT\u6846\u67b6\uff0c\u901a\u8fc7\u76d1\u7763\u5b66\u4e60\u8c03\u6574\u4ee3\u7406\u4ee5\u907f\u514d\u707e\u96be\u6027\u5931\u8d25\uff0c\u518d\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u5bf9\u6297\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u4e3b\u6d41\u4ee3\u7406\u5728\u73af\u5883\u72b6\u6001\u6270\u52a8\u4e0b\u5b58\u5728\u8106\u5f31\u6027\uff0cBAT\u6846\u67b6\u80fd\u663e\u8457\u63d0\u5347\u4ee3\u7406\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "BAT\u6846\u67b6\u5728\u591a\u79cd\u60c5\u51b5\u4e0b\u6709\u6548\u589e\u5f3a\u4e86\u4ee3\u7406\u5bf9\u73af\u5883\u72b6\u6001\u6270\u52a8\u7684\u9c81\u68d2\u6027\uff0c\u800c\u73b0\u6709\u9c81\u68d2\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u53ef\u80fd\u4e0d\u9002\u7528\u3002"}}
{"id": "2506.08965", "pdf": "https://arxiv.org/pdf/2506.08965", "abs": "https://arxiv.org/abs/2506.08965", "authors": ["Yiyang Zhao", "Huiyu Bai", "Xuejiao Zhao"], "title": "GFRIEND: Generative Few-shot Reward Inference through EfficieNt DPO", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The ability to train high-performing reward models with few-shot data is\ncritical for enhancing the efficiency and scalability of Reinforcement Learning\nfrom Human Feedback (RLHF). We propose a data augmentation and expansion\nframework that enables generative reward models trained on small datasets to\nachieve comparable performance to those trained on large-scale datasets.\nTraditional methods to train a generative reward model, such as Direct\nPreference Optimization (DPO), are constrained by inefficiencies in sample\npairing and limited data diversity. This work introduces preference refinement,\nwhich employs Chain-of-Thought (CoT) sampling to uncover diverse and\nhigh-quality preference relationships. It also incorporates a perplexity-based\nscoring mechanism to assign nuanced preference levels and utilizes Multi-level\nDirect Preference Optimization (M-DPO) to enable the model to capture\nfiner-grained preference differences between samples. Experimental results\ndemonstrate that the proposed method significantly enhances data efficiency and\nmodel performance, enabling reward models trained in a few-shot setting to\nachieve results on par with those trained on large-scale datasets. This study\nunderscores the potential of data-efficient strategies in advancing reward\nmodel optimization, offering a robust solution for low-resource RLHF\napplications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6570\u636e\u589e\u5f3a\u548c\u6269\u5c55\u6846\u67b6\uff0c\u901a\u8fc7\u504f\u597d\u7ec6\u5316\u548c\u591a\u7ea7\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08M-DPO\uff09\uff0c\u4f7f\u5c0f\u6570\u636e\u96c6\u8bad\u7ec3\u7684\u751f\u6210\u5956\u52b1\u6a21\u578b\u8fbe\u5230\u4e0e\u5927\u89c4\u6a21\u6570\u636e\u96c6\u8bad\u7ec3\u76f8\u5f53\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\uff08\u5982\u76f4\u63a5\u504f\u597d\u4f18\u5316DPO\uff09\u5728\u6837\u672c\u914d\u5bf9\u548c\u6570\u636e\u591a\u6837\u6027\u4e0a\u6548\u7387\u4f4e\u4e0b\uff0c\u9650\u5236\u4e86\u751f\u6210\u5956\u52b1\u6a21\u578b\u7684\u6027\u80fd\u3002", "method": "\u5f15\u5165\u504f\u597d\u7ec6\u5316\uff08CoT\u91c7\u6837\uff09\u548c\u56f0\u60d1\u5ea6\u8bc4\u5206\u673a\u5236\uff0c\u7ed3\u5408M-DPO\u6355\u6349\u66f4\u7ec6\u7c92\u5ea6\u7684\u504f\u597d\u5dee\u5f02\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6570\u636e\u6548\u7387\u548c\u6a21\u578b\u6027\u80fd\uff0c\u4f7f\u5c0f\u6837\u672c\u8bad\u7ec3\u7684\u5956\u52b1\u6a21\u578b\u8fbe\u5230\u4e0e\u5927\u89c4\u6a21\u6570\u636e\u96c6\u76f8\u5f53\u7684\u7ed3\u679c\u3002", "conclusion": "\u6570\u636e\u9ad8\u6548\u7b56\u7565\u5728\u5956\u52b1\u6a21\u578b\u4f18\u5316\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4e3a\u4f4e\u8d44\u6e90RLHF\u5e94\u7528\u63d0\u4f9b\u4e86\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.08977", "pdf": "https://arxiv.org/pdf/2506.08977", "abs": "https://arxiv.org/abs/2506.08977", "authors": ["Victoria Hankemeier", "Malte Schilling"], "title": "Tailored Architectures for Time Series Forecasting: Evaluating Deep Learning Models on Gaussian Process-Generated Data", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at IJCNN25, Code: https://github.com/vicky-hnk/time-flex", "summary": "Developments in Deep Learning have significantly improved time series\nforecasting by enabling more accurate modeling of complex temporal dependencies\ninherent in sequential data. The effectiveness of such models is often\ndemonstrated on limited sets of specific real-world data. Although this allows\nfor comparative analysis, it still does not demonstrate how specific data\ncharacteristics align with the architectural strengths of individual models.\nOur research aims at uncovering clear connections between time series\ncharacteristics and particular models. We introduce a novel dataset generated\nusing Gaussian Processes, specifically designed to display distinct, known\ncharacteristics for targeted evaluations of model adaptability to them.\nFurthermore, we present TimeFlex, a new model that incorporates a modular\narchitecture tailored to handle diverse temporal dynamics, including trends and\nperiodic patterns. This model is compared to current state-of-the-art models,\noffering a deeper understanding of how models perform under varied time series\nconditions.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5TimeFlex\uff0c\u901a\u8fc7\u751f\u6210\u5177\u6709\u7279\u5b9a\u7279\u5f81\u7684\u6570\u636e\u96c6\uff0c\u7814\u7a76\u65f6\u95f4\u5e8f\u5217\u7279\u6027\u4e0e\u6a21\u578b\u6027\u80fd\u7684\u5173\u7cfb\u3002", "motivation": "\u63ed\u793a\u65f6\u95f4\u5e8f\u5217\u7279\u6027\u4e0e\u7279\u5b9a\u6a21\u578b\u4e4b\u95f4\u7684\u660e\u786e\u8054\u7cfb\uff0c\u4ee5\u66f4\u597d\u5730\u7406\u89e3\u6a21\u578b\u5bf9\u4e0d\u540c\u65f6\u95f4\u5e8f\u5217\u6761\u4ef6\u7684\u9002\u5e94\u6027\u3002", "method": "\u4f7f\u7528\u9ad8\u65af\u8fc7\u7a0b\u751f\u6210\u5177\u6709\u5df2\u77e5\u7279\u5f81\u7684\u6570\u636e\u96c6\uff0c\u5e76\u5f00\u53d1\u6a21\u5757\u5316\u67b6\u6784\u6a21\u578bTimeFlex\uff0c\u7528\u4e8e\u5904\u7406\u591a\u6837\u5316\u7684\u65f6\u95f4\u52a8\u6001\u3002", "result": "TimeFlex\u5728\u591a\u79cd\u65f6\u95f4\u5e8f\u5217\u6761\u4ef6\u4e0b\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u5148\u8fdb\u6a21\u578b\u3002", "conclusion": "\u7814\u7a76\u4e3a\u65f6\u95f4\u5e8f\u5217\u7279\u6027\u4e0e\u6a21\u578b\u6027\u80fd\u7684\u5173\u7cfb\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\uff0cTimeFlex\u5c55\u793a\u4e86\u66f4\u5f3a\u7684\u9002\u5e94\u6027\u3002"}}
{"id": "2506.08978", "pdf": "https://arxiv.org/pdf/2506.08978", "abs": "https://arxiv.org/abs/2506.08978", "authors": ["Anna Langedijk", "Jaap Jumelet", "Willem Zuidema"], "title": "Propositional Logic for Probing Generalization in Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The extent to which neural networks are able to acquire and represent\nsymbolic rules remains a key topic of research and debate. Much current work\nfocuses on the impressive capabilities of large language models, as well as\ntheir often ill-understood failures on a wide range of reasoning tasks. In this\npaper, in contrast, we investigate the generalization behavior of three key\nneural architectures (Transformers, Graph Convolution Networks and LSTMs) in a\ncontrolled task rooted in propositional logic. The task requires models to\ngenerate satisfying assignments for logical formulas, making it a structured\nand interpretable setting for studying compositionality. We introduce a\nbalanced extension of an existing dataset to eliminate superficial patterns and\nenable testing on unseen operator combinations. Using this dataset, we evaluate\nthe ability of the three architectures to generalize beyond the training\ndistribution. While all models perform well in-distribution, we find that\ngeneralization to unseen patterns, particularly those involving negation,\nremains a significant challenge. Transformers fail to apply negation\ncompositionally, unless structural biases are introduced. Our findings\nhighlight persistent limitations in the ability of standard architectures to\nlearn systematic representations of logical operators, suggesting the need for\nstronger inductive biases to support robust rule-based reasoning.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u4e09\u79cd\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff08Transformer\u3001GCN\u548cLSTM\uff09\u5728\u547d\u9898\u903b\u8f91\u4efb\u52a1\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u53d1\u73b0\u5176\u5bf9\u672a\u89c1\u6a21\u5f0f\uff08\u5c24\u5176\u662f\u5426\u5b9a\u64cd\u4f5c\uff09\u7684\u6cdb\u5316\u4ecd\u5177\u6311\u6218\u6027\u3002", "motivation": "\u63a2\u8ba8\u795e\u7ecf\u7f51\u7edc\u5728\u7b26\u53f7\u89c4\u5219\u8868\u793a\u4e2d\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u903b\u8f91\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u901a\u8fc7\u547d\u9898\u903b\u8f91\u4efb\u52a1\u6d4b\u8bd5\u4e09\u79cd\u67b6\u6784\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4f7f\u7528\u5e73\u8861\u6570\u636e\u96c6\u6d88\u9664\u8868\u9762\u6a21\u5f0f\u3002", "result": "\u6240\u6709\u6a21\u578b\u5728\u8bad\u7ec3\u5206\u5e03\u5185\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5bf9\u5426\u5b9a\u64cd\u4f5c\u7684\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\uff0cTransformer\u9700\u7ed3\u6784\u504f\u7f6e\u624d\u80fd\u7ec4\u5408\u5e94\u7528\u5426\u5b9a\u3002", "conclusion": "\u6807\u51c6\u67b6\u6784\u5728\u903b\u8f91\u64cd\u4f5c\u7684\u7cfb\u7edf\u8868\u793a\u4e0a\u5b58\u5728\u5c40\u9650\uff0c\u9700\u66f4\u5f3a\u5f52\u7eb3\u504f\u7f6e\u4ee5\u652f\u6301\u57fa\u4e8e\u89c4\u5219\u7684\u63a8\u7406\u3002"}}
{"id": "2506.08982", "pdf": "https://arxiv.org/pdf/2506.08982", "abs": "https://arxiv.org/abs/2506.08982", "authors": ["Ivan Rubachev", "Akim Kotelnikov", "Nikolay Kartashev"], "title": "On Finetuning Tabular Foundation Models", "categories": ["cs.LG"], "comment": null, "summary": "Foundation models are an emerging research direction in tabular deep\nlearning. Notably, TabPFNv2 recently claimed superior performance over\ntraditional GBDT-based methods on small-scale datasets using an in-context\nlearning paradigm, which does not adapt model parameters to target datasets.\nHowever, the optimal finetuning approach for adapting tabular foundational\nmodels, and how this adaptation reshapes their internal mechanisms, remains\nunderexplored. While prior works studied finetuning for earlier foundational\nmodels, inconsistent findings and TabPFNv2's unique architecture necessitate\nfresh investigation. To address these questions, we first systematically\nevaluate various finetuning strategies on diverse datasets. Our findings\nestablish full finetuning as the most practical solution for TabPFNv2 in terms\nof time-efficiency and effectiveness. We then investigate how finetuning alters\nTabPFNv2's inner mechanisms, drawing an analogy to retrieval-augmented models.\nWe reveal that the success of finetuning stems from the fact that after\ngradient-based adaptation, the dot products of the query-representations of\ntest objects and the key-representations of in-context training objects more\naccurately reflect their target similarity. This improved similarity allows\nfinetuned TabPFNv2 to better approximate target dependency by appropriately\nweighting relevant in-context samples, improving the retrieval-based prediction\nlogic. From the practical perspective, we managed to finetune TabPFNv2 on\ndatasets with up to 50K objects, observing performance improvements on almost\nall tasks. More precisely, on academic datasets with I.I.D. splits, finetuning\nallows TabPFNv2 to achieve state-of-the-art results, while on datasets with\ngradual temporal shifts and rich feature sets, TabPFNv2 is less stable and\nprior methods remain better.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86TabPFNv2\u6a21\u578b\u5728\u8868\u683c\u6570\u636e\u4e0a\u7684\u5fae\u8c03\u7b56\u7565\u53ca\u5176\u5185\u90e8\u673a\u5236\u53d8\u5316\uff0c\u53d1\u73b0\u5168\u5fae\u8c03\u662f\u6700\u4f18\u65b9\u6cd5\uff0c\u5e76\u63ed\u793a\u4e86\u5176\u6210\u529f\u7684\u539f\u56e0\u5728\u4e8e\u6539\u8fdb\u7684\u76f8\u4f3c\u6027\u5ea6\u91cf\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u4f18\u5316\u8868\u683c\u57fa\u7840\u6a21\u578b\uff08\u5982TabPFNv2\uff09\u7684\u5fae\u8c03\u65b9\u6cd5\uff0c\u5e76\u7406\u89e3\u5fae\u8c03\u5982\u4f55\u6539\u53d8\u5176\u5185\u90e8\u673a\u5236\u3002", "method": "\u7cfb\u7edf\u8bc4\u4f30\u591a\u79cd\u5fae\u8c03\u7b56\u7565\uff0c\u5206\u6790\u5fae\u8c03\u5bf9TabPFNv2\u5185\u90e8\u673a\u5236\u7684\u5f71\u54cd\uff0c\u7c7b\u6bd4\u68c0\u7d22\u589e\u5f3a\u6a21\u578b\u3002", "result": "\u5168\u5fae\u8c03\u5728\u65f6\u95f4\u548c\u6548\u679c\u4e0a\u6700\u4f18\uff1b\u5fae\u8c03\u901a\u8fc7\u6539\u8fdb\u76f8\u4f3c\u6027\u5ea6\u91cf\u63d0\u5347\u6027\u80fd\uff0c\u572850K\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u65f6\u5e8f\u6570\u636e\u548c\u590d\u6742\u7279\u5f81\u4e0a\u4e0d\u7a33\u5b9a\u3002", "conclusion": "\u5168\u5fae\u8c03\u662fTabPFNv2\u7684\u6700\u4f73\u5b9e\u8df5\uff0c\u4f46\u5176\u9002\u7528\u6027\u53d7\u6570\u636e\u96c6\u7279\u6027\u5f71\u54cd\u3002"}}
{"id": "2506.08989", "pdf": "https://arxiv.org/pdf/2506.08989", "abs": "https://arxiv.org/abs/2506.08989", "authors": ["Xiao Liang", "Zhong-Zhi Li", "Yeyun Gong", "Yang Wang", "Hengyuan Zhang", "Yelong Shen", "Ying Nian Wu", "Weizhu Chen"], "title": "SwS: Self-aware Weakness-driven Problem Synthesis in Reinforcement Learning for LLM Reasoning", "categories": ["cs.LG", "cs.CL"], "comment": "Reinforcement Learning; Large Language Models; LLM Reasoning", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has proven effective\nfor training large language models (LLMs) on complex reasoning tasks, such as\nmathematical problem solving. A prerequisite for the scalability of RLVR is a\nhigh-quality problem set with precise and verifiable answers. However, the\nscarcity of well-crafted human-labeled math problems and limited-verification\nanswers in existing distillation-oriented synthetic datasets limit their\neffectiveness in RL. Additionally, most problem synthesis strategies\nindiscriminately expand the problem set without considering the model's\ncapabilities, leading to low efficiency in generating useful questions. To\nmitigate this issue, we introduce a Self-aware Weakness-driven problem\nSynthesis framework (SwS) that systematically identifies model deficiencies and\nleverages them for problem augmentation. Specifically, we define weaknesses as\nquestions that the model consistently fails to learn through its iterative\nsampling during RL training. We then extract the core concepts from these\nfailure cases and synthesize new problems to strengthen the model's weak areas\nin subsequent augmented training, enabling it to focus on and gradually\novercome its weaknesses. Without relying on external knowledge distillation,\nour framework enables robust generalization byempowering the model to\nself-identify and address its weaknesses in RL, yielding average performance\ngains of 10.0% and 7.7% on 7B and 32B models across eight mainstream reasoning\nbenchmarks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u6211\u611f\u77e5\u5f31\u70b9\u9a71\u52a8\u7684\u95ee\u9898\u5408\u6210\u6846\u67b6\uff08SwS\uff09\uff0c\u901a\u8fc7\u8bc6\u522b\u6a21\u578b\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5f31\u70b9\u5e76\u751f\u6210\u9488\u5bf9\u6027\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u95ee\u9898\u96c6\u8d28\u91cf\u4e0d\u8db3\u4e14\u7f3a\u4e4f\u9488\u5bf9\u6027\uff0c\u9650\u5236\u4e86\u5f3a\u5316\u5b66\u4e60\u5728\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u4e2d\u7684\u6548\u679c\u3002", "method": "\u901a\u8fc7\u5206\u6790\u6a21\u578b\u5728\u8bad\u7ec3\u4e2d\u7684\u5931\u8d25\u6848\u4f8b\uff0c\u63d0\u53d6\u6838\u5fc3\u6982\u5ff5\u5e76\u5408\u6210\u65b0\u95ee\u9898\uff0c\u9488\u5bf9\u6027\u5f3a\u5316\u6a21\u578b\u5f31\u70b9\u3002", "result": "\u5728\u591a\u4e2a\u4e3b\u6d41\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c7B\u548c32B\u6a21\u578b\u7684\u5e73\u5747\u6027\u80fd\u5206\u522b\u63d0\u5347\u4e8610.0%\u548c7.7%\u3002", "conclusion": "SwS\u6846\u67b6\u65e0\u9700\u5916\u90e8\u77e5\u8bc6\u84b8\u998f\uff0c\u901a\u8fc7\u81ea\u6211\u8bc6\u522b\u548c\u89e3\u51b3\u5f31\u70b9\uff0c\u5b9e\u73b0\u4e86\u6a21\u578b\u7684\u7a33\u5065\u6cdb\u5316\u3002"}}
{"id": "2506.09007", "pdf": "https://arxiv.org/pdf/2506.09007", "abs": "https://arxiv.org/abs/2506.09007", "authors": ["Sophia Tang", "Yinuo Zhang", "Alexander Tong", "Pranam Chatterjee"], "title": "Branched Schr\u00f6dinger Bridge Matching", "categories": ["cs.LG"], "comment": null, "summary": "Predicting the intermediate trajectories between an initial and target\ndistribution is a central problem in generative modeling. Existing approaches,\nsuch as flow matching and Schr\\\"odinger Bridge Matching, effectively learn\nmappings between two distributions by modeling a single stochastic path.\nHowever, these methods are inherently limited to unimodal transitions and\ncannot capture branched or divergent evolution from a common origin to multiple\ndistinct outcomes. To address this, we introduce Branched Schr\\\"odinger Bridge\nMatching (BranchSBM), a novel framework that learns branched Schr\\\"odinger\nbridges. BranchSBM parameterizes multiple time-dependent velocity fields and\ngrowth processes, enabling the representation of population-level divergence\ninto multiple terminal distributions. We show that BranchSBM is not only more\nexpressive but also essential for tasks involving multi-path surface\nnavigation, modeling cell fate bifurcations from homogeneous progenitor states,\nand simulating diverging cellular responses to perturbations.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5BranchSBM\uff0c\u7528\u4e8e\u89e3\u51b3\u751f\u6210\u6a21\u578b\u4e2d\u591a\u8def\u5f84\u8f68\u8ff9\u9884\u6d4b\u7684\u95ee\u9898\uff0c\u514b\u670d\u4e86\u73b0\u6709\u65b9\u6cd5\u53ea\u80fd\u5904\u7406\u5355\u4e00\u8def\u5f84\u7684\u9650\u5236\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\uff08\u5982\u6d41\u5339\u914d\u548cSchr\\\"odinger Bridge Matching\uff09\u53ea\u80fd\u5efa\u6a21\u5355\u4e00\u8def\u5f84\uff0c\u65e0\u6cd5\u6355\u6349\u4ece\u5171\u540c\u8d77\u6e90\u5230\u591a\u4e2a\u4e0d\u540c\u7ed3\u679c\u7684\u5206\u652f\u6216\u53d1\u6563\u6f14\u5316\u3002", "method": "\u63d0\u51fa\u4e86Branched Schr\\\"odinger Bridge Matching (BranchSBM)\uff0c\u901a\u8fc7\u53c2\u6570\u5316\u591a\u4e2a\u65f6\u95f4\u4f9d\u8d56\u7684\u901f\u5ea6\u573a\u548c\u589e\u957f\u8fc7\u7a0b\uff0c\u5b9e\u73b0\u591a\u7ec8\u7aef\u5206\u5e03\u7684\u5206\u652f\u5efa\u6a21\u3002", "result": "BranchSBM\u5728\u591a\u8def\u5f84\u8868\u9762\u5bfc\u822a\u3001\u7ec6\u80de\u547d\u8fd0\u5206\u53c9\u5efa\u6a21\u548c\u7ec6\u80de\u54cd\u5e94\u6a21\u62df\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u8868\u8fbe\u80fd\u529b\u3002", "conclusion": "BranchSBM\u4e3a\u89e3\u51b3\u591a\u8def\u5f84\u751f\u6210\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u6269\u5c55\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u9002\u7528\u8303\u56f4\u3002"}}
{"id": "2506.09010", "pdf": "https://arxiv.org/pdf/2506.09010", "abs": "https://arxiv.org/abs/2506.09010", "authors": ["Sebastian Schmidt", "Prasanga Dhungel", "Christoffer L\u00f6ffler", "Bj\u00f6rn Nieth", "Stephan G\u00fcnnemann", "Leo Schwinn"], "title": "Effective Data Pruning through Score Extrapolation", "categories": ["cs.LG"], "comment": null, "summary": "Training advanced machine learning models demands massive datasets, resulting\nin prohibitive computational costs. To address this challenge, data pruning\ntechniques identify and remove redundant training samples while preserving\nmodel performance. Yet, existing pruning techniques predominantly require a\nfull initial training pass to identify removable samples, negating any\nefficiency benefits for single training runs. To overcome this limitation, we\nintroduce a novel importance score extrapolation framework that requires\ntraining on only a small subset of data. We present two initial approaches in\nthis framework - k-nearest neighbors and graph neural networks - to accurately\npredict sample importance for the entire dataset using patterns learned from\nthis minimal subset. We demonstrate the effectiveness of our approach for 2\nstate-of-the-art pruning methods (Dynamic Uncertainty and TDDS), 4 different\ndatasets (CIFAR-10, CIFAR-100, Places-365, and ImageNet), and 3 training\nparadigms (supervised, unsupervised, and adversarial). Our results indicate\nthat score extrapolation is a promising direction to scale expensive score\ncalculation methods, such as pruning, data attribution, or other tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u91cd\u8981\u6027\u5206\u6570\u5916\u63a8\u6846\u67b6\uff0c\u4ec5\u9700\u8bad\u7ec3\u4e00\u5c0f\u90e8\u5206\u6570\u636e\u5373\u53ef\u9884\u6d4b\u6574\u4e2a\u6570\u636e\u96c6\u7684\u6837\u672c\u91cd\u8981\u6027\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6570\u636e\u526a\u679d\u6280\u672f\u9700\u5b8c\u6574\u8bad\u7ec3\u7684\u4f4e\u6548\u95ee\u9898\u3002", "motivation": "\u5927\u89c4\u6a21\u6570\u636e\u96c6\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u73b0\u6709\u6570\u636e\u526a\u679d\u6280\u672f\u9700\u5b8c\u6574\u8bad\u7ec3\uff0c\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u5f15\u5165\u91cd\u8981\u6027\u5206\u6570\u5916\u63a8\u6846\u67b6\uff0c\u57fa\u4e8e\u5c0f\u6570\u636e\u5b50\u96c6\u8bad\u7ec3\uff0c\u91c7\u7528k\u8fd1\u90bb\u548c\u56fe\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u6837\u672c\u91cd\u8981\u6027\u3002", "result": "\u5728\u591a\u79cd\u6570\u636e\u96c6\u548c\u8bad\u7ec3\u8303\u5f0f\u4e0b\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u9002\u7528\u4e8e\u52a8\u6001\u4e0d\u786e\u5b9a\u6027\u548cTDDS\u7b49\u526a\u679d\u65b9\u6cd5\u3002", "conclusion": "\u5206\u6570\u5916\u63a8\u662f\u6269\u5c55\u6602\u8d35\u5206\u6570\u8ba1\u7b97\u4efb\u52a1\uff08\u5982\u526a\u679d\u3001\u6570\u636e\u5f52\u56e0\uff09\u7684\u6709\u524d\u666f\u65b9\u5411\u3002"}}
{"id": "2506.09016", "pdf": "https://arxiv.org/pdf/2506.09016", "abs": "https://arxiv.org/abs/2506.09016", "authors": ["Ruiqi Zhang", "Daman Arora", "Song Mei", "Andrea Zanette"], "title": "SPEED-RL: Faster Training of Reasoning Models via Online Curriculum Learning", "categories": ["cs.LG"], "comment": "pre-print", "summary": "Training large language models with reinforcement learning (RL) against\nverifiable rewards significantly enhances their reasoning abilities, yet\nremains computationally expensive due to inefficient uniform prompt sampling.\nWe introduce Selective Prompting with Efficient Estimation of Difficulty\n(SPEED), an adaptive online RL curriculum that selectively chooses training\nexamples of intermediate difficulty to maximize learning efficiency.\nTheoretically, we establish that intermediate-difficulty prompts improve the\ngradient estimator's signal-to-noise ratio, accelerating convergence.\nEmpirically, our efficient implementation leads to 2x to 6x faster training\nwithout degrading accuracy, requires no manual tuning, and integrates\nseamlessly into standard RL algorithms.", "AI": {"tldr": "SPEED\u662f\u4e00\u79cd\u81ea\u9002\u5e94\u5728\u7ebfRL\u8bfe\u7a0b\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u91c7\u6837\u4e2d\u7b49\u96be\u5ea6\u63d0\u793a\u6765\u63d0\u5347\u8bad\u7ec3\u6548\u7387\uff0c\u5b9e\u73b02x\u52306x\u7684\u52a0\u901f\u4e14\u4e0d\u5f71\u54cd\u51c6\u786e\u6027\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4e2d\uff0c\u5747\u5300\u91c7\u6837\u63d0\u793a\u5bfc\u81f4\u8bad\u7ec3\u6548\u7387\u4f4e\u4e0b\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u3002", "method": "\u63d0\u51faSPEED\u65b9\u6cd5\uff0c\u9009\u62e9\u6027\u91c7\u6837\u4e2d\u7b49\u96be\u5ea6\u63d0\u793a\uff0c\u4f18\u5316\u68af\u5ea6\u4f30\u8ba1\u5668\u7684\u4fe1\u566a\u6bd4\uff0c\u52a0\u901f\u6536\u655b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSPEED\u5b9e\u73b02x\u52306x\u7684\u8bad\u7ec3\u52a0\u901f\uff0c\u65e0\u9700\u624b\u52a8\u8c03\u53c2\u4e14\u517c\u5bb9\u6807\u51c6RL\u7b97\u6cd5\u3002", "conclusion": "SPEED\u901a\u8fc7\u81ea\u9002\u5e94\u9009\u62e9\u63d0\u793a\uff0c\u663e\u8457\u63d0\u5347\u8bad\u7ec3\u6548\u7387\uff0c\u4e3a\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578bRL\u8bad\u7ec3\u63d0\u4f9b\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.09018", "pdf": "https://arxiv.org/pdf/2506.09018", "abs": "https://arxiv.org/abs/2506.09018", "authors": ["Marton Havasi", "Brian Karrer", "Itai Gat", "Ricky T. Q. Chen"], "title": "Edit Flows: Flow Matching with Edit Operations", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Autoregressive generative models naturally generate variable-length\nsequences, while non-autoregressive models struggle, often imposing rigid,\ntoken-wise structures. We propose Edit Flows, a non-autoregressive model that\novercomes these limitations by defining a discrete flow over sequences through\nedit operations-insertions, deletions, and substitutions. By modeling these\noperations within a Continuous-time Markov Chain over the sequence space, Edit\nFlows enable flexible, position-relative generation that aligns more closely\nwith the structure of sequence data. Our training method leverages an expanded\nstate space with auxiliary variables, making the learning process efficient and\ntractable. Empirical results show that Edit Flows outperforms both\nautoregressive and mask models on image captioning and significantly\noutperforms the mask construction in text and code generation.", "AI": {"tldr": "Edit Flows\u662f\u4e00\u79cd\u975e\u81ea\u56de\u5f52\u6a21\u578b\uff0c\u901a\u8fc7\u7f16\u8f91\u64cd\u4f5c\uff08\u63d2\u5165\u3001\u5220\u9664\u3001\u66ff\u6362\uff09\u5728\u5e8f\u5217\u7a7a\u95f4\u4e0a\u5b9a\u4e49\u79bb\u6563\u6d41\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u975e\u81ea\u56de\u5f52\u6a21\u578b\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u4f20\u7edf\u975e\u81ea\u56de\u5f52\u6a21\u578b\u5728\u5904\u7406\u53d8\u957f\u5e8f\u5217\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u901a\u5e38\u9700\u8981\u56fa\u5b9a\u7684token\u7ed3\u6784\u3002Edit Flows\u65e8\u5728\u901a\u8fc7\u7075\u6d3b\u7684\u7f16\u8f91\u64cd\u4f5c\u66f4\u8d34\u8fd1\u5e8f\u5217\u6570\u636e\u7684\u7ed3\u6784\u3002", "method": "Edit Flows\u5229\u7528\u8fde\u7eed\u65f6\u95f4\u9a6c\u5c14\u53ef\u592b\u94fe\u5728\u5e8f\u5217\u7a7a\u95f4\u4e0a\u5efa\u6a21\u7f16\u8f91\u64cd\u4f5c\uff0c\u5e76\u901a\u8fc7\u6269\u5c55\u72b6\u6001\u7a7a\u95f4\u548c\u8f85\u52a9\u53d8\u91cf\u5b9e\u73b0\u9ad8\u6548\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cEdit Flows\u5728\u56fe\u50cf\u63cf\u8ff0\u751f\u6210\u4efb\u52a1\u4e0a\u4f18\u4e8e\u81ea\u56de\u5f52\u548c\u63a9\u7801\u6a21\u578b\uff0c\u5728\u6587\u672c\u548c\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u63a9\u7801\u6784\u9020\u65b9\u6cd5\u3002", "conclusion": "Edit Flows\u901a\u8fc7\u7f16\u8f91\u64cd\u4f5c\u5b9e\u73b0\u4e86\u7075\u6d3b\u7684\u975e\u81ea\u56de\u5f52\u751f\u6210\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5e8f\u5217\u751f\u6210\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2506.09026", "pdf": "https://arxiv.org/pdf/2506.09026", "abs": "https://arxiv.org/abs/2506.09026", "authors": ["Amrith Setlur", "Matthew Y. R. Yang", "Charlie Snell", "Jeremy Greer", "Ian Wu", "Virginia Smith", "Max Simchowitz", "Aviral Kumar"], "title": "e3: Learning to Explore Enables Extrapolation of Test-Time Compute for LLMs", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Test-time scaling offers a promising path to improve LLM reasoning by\nutilizing more compute at inference time; however, the true promise of this\nparadigm lies in extrapolation (i.e., improvement in performance on hard\nproblems as LLMs keep \"thinking\" for longer, beyond the maximum token budget\nthey were trained on). Surprisingly, we find that most existing reasoning\nmodels do not extrapolate well. We show that one way to enable extrapolation is\nby training the LLM to perform in-context exploration: training the LLM to\neffectively spend its test time budget by chaining operations (such as\ngeneration, verification, refinement, etc.), or testing multiple hypotheses\nbefore it commits to an answer. To enable in-context exploration, we identify\nthree key ingredients as part of our recipe e3: (1) chaining skills that the\nbase LLM has asymmetric competence in, e.g., chaining verification (easy) with\ngeneration (hard), as a way to implement in-context search; (2) leveraging\n\"negative\" gradients from incorrect traces to amplify exploration during RL,\nresulting in longer search traces that chains additional asymmetries; and (3)\ncoupling task difficulty with training token budget during training via a\nspecifically-designed curriculum to structure in-context exploration. Our\nrecipe e3 produces the best known 1.7B model according to AIME'25 and HMMT'25\nscores, and extrapolates to 2x the training token budget. Our e3-1.7B model not\nonly attains high pass@1 scores, but also improves pass@k over the base model.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3ae3\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bad\u7ec3LLM\u8fdb\u884c\u4e0a\u4e0b\u6587\u63a2\u7d22\uff0c\u4ee5\u63d0\u5347\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u5728\u6d4b\u8bd5\u65f6\u95f4\u9884\u7b97\u8d85\u51fa\u8bad\u7ec3\u8303\u56f4\u65f6\u5b9e\u73b0\u6027\u80fd\u5916\u63a8\u3002", "motivation": "\u73b0\u6709\u63a8\u7406\u6a21\u578b\u5728\u6027\u80fd\u5916\u63a8\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u4e0a\u4e0b\u6587\u63a2\u7d22\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "e3\u65b9\u6cd5\u5305\u62ec\u4e09\u4e2a\u5173\u952e\u6210\u5206\uff1a1) \u94fe\u5f0f\u64cd\u4f5c\uff08\u5982\u751f\u6210\u3001\u9a8c\u8bc1\u3001\u7cbe\u70bc\u7b49\uff09\uff1b2) \u5229\u7528\u9519\u8bef\u8f68\u8ff9\u7684\u201c\u8d1f\u68af\u5ea6\u201d\u589e\u5f3a\u63a2\u7d22\uff1b3) \u901a\u8fc7\u7279\u5b9a\u8bbe\u8ba1\u7684\u8bfe\u7a0b\u5b66\u4e60\u7ed3\u5408\u4efb\u52a1\u96be\u5ea6\u4e0e\u8bad\u7ec3\u9884\u7b97\u3002", "result": "e3-1.7B\u6a21\u578b\u5728AIME'25\u548cHMMT'25\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u5e76\u80fd\u5916\u63a8\u52302\u500d\u7684\u8bad\u7ec3\u9884\u7b97\uff0c\u540c\u65f6\u63d0\u5347\u4e86pass@1\u548cpass@k\u5206\u6570\u3002", "conclusion": "e3\u65b9\u6cd5\u901a\u8fc7\u4e0a\u4e0b\u6587\u63a2\u7d22\u6709\u6548\u63d0\u5347\u4e86LLM\u7684\u63a8\u7406\u80fd\u529b\u548c\u5916\u63a8\u6027\u80fd\u3002"}}
{"id": "2506.09034", "pdf": "https://arxiv.org/pdf/2506.09034", "abs": "https://arxiv.org/abs/2506.09034", "authors": ["Sizhe Dang", "Yangyang Guo", "Yanjun Zhao", "Haishan Ye", "Xiaodong Zheng", "Guang Dai", "Ivor Tsang"], "title": "FZOO: Fast Zeroth-Order Optimizer for Fine-Tuning Large Language Models towards Adam-Scale Speed", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Fine-tuning large language models (LLMs) often faces GPU memory bottlenecks:\nthe backward pass of first-order optimizers like Adam increases memory usage to\nmore than 10 times the inference level (e.g., 633 GB for OPT-30B). Zeroth-order\n(ZO) optimizers avoid this cost by estimating gradients only from forward\npasses, yet existing methods like MeZO usually require many more steps to\nconverge. Can this trade-off between speed and memory in ZO be fundamentally\nimproved? Normalized-SGD demonstrates strong empirical performance with greater\nmemory efficiency than Adam. In light of this, we introduce FZOO, a Fast\nZeroth-Order Optimizer toward Adam-Scale Speed. FZOO reduces the total forward\npasses needed for convergence by employing batched one-sided estimates that\nadapt step sizes based on the standard deviation of batch losses. It also\naccelerates per-batch computation through the use of Rademacher random vector\nperturbations coupled with CUDA's parallel processing. Extensive experiments on\ndiverse models, including RoBERTa-large, OPT (350M-66B), Phi-2, and Llama3,\nacross 11 tasks validate FZOO's effectiveness. On average, FZOO outperforms\nMeZO by 3 percent in accuracy while requiring 3 times fewer forward passes. For\nRoBERTa-large, FZOO achieves average improvements of 5.6 percent in accuracy\nand an 18 times reduction in forward passes compared to MeZO, achieving\nconvergence speeds comparable to Adam. We also provide theoretical analysis\nproving FZOO's formal equivalence to a normalized-SGD update rule and its\nconvergence guarantees. FZOO integrates smoothly into PEFT techniques, enabling\neven larger memory savings. Overall, our results make single-GPU, high-speed,\nfull-parameter fine-tuning practical and point toward future work on\nmemory-efficient pre-training.", "AI": {"tldr": "FZOO\u662f\u4e00\u79cd\u5feb\u901f\u96f6\u9636\u4f18\u5316\u5668\uff0c\u901a\u8fc7\u51cf\u5c11\u6536\u655b\u6240\u9700\u7684\u524d\u5411\u4f20\u9012\u6b21\u6570\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4f18\u5316\u901f\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u5185\u5b58\u9ad8\u6548\u6027\uff0c\u9002\u7528\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5fae\u8c03\u3002", "motivation": "\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u4e2dGPU\u5185\u5b58\u74f6\u9888\u95ee\u9898\uff0c\u540c\u65f6\u63d0\u5347\u96f6\u9636\u4f18\u5316\u5668\u7684\u6536\u655b\u901f\u5ea6\u3002", "method": "\u91c7\u7528\u6279\u91cf\u5355\u8fb9\u4f30\u8ba1\u548c\u57fa\u4e8e\u635f\u5931\u6807\u51c6\u5dee\u7684\u6b65\u957f\u8c03\u6574\uff0c\u7ed3\u5408Rademacher\u968f\u673a\u5411\u91cf\u6270\u52a8\u548cCUDA\u5e76\u884c\u5904\u7406\u3002", "result": "FZOO\u572811\u4e2a\u4efb\u52a1\u4e2d\u5e73\u5747\u6bd4MeZO\u51c6\u786e\u7387\u63d0\u53473%\uff0c\u524d\u5411\u4f20\u9012\u6b21\u6570\u51cf\u5c113\u500d\uff1b\u5728RoBERTa-large\u4e0a\u51c6\u786e\u7387\u63d0\u53475.6%\uff0c\u524d\u5411\u4f20\u9012\u6b21\u6570\u51cf\u5c1118\u500d\u3002", "conclusion": "FZOO\u5b9e\u73b0\u4e86\u5355GPU\u9ad8\u901f\u5168\u53c2\u6570\u5fae\u8c03\uff0c\u4e3a\u5185\u5b58\u9ad8\u6548\u9884\u8bad\u7ec3\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2506.09044", "pdf": "https://arxiv.org/pdf/2506.09044", "abs": "https://arxiv.org/abs/2506.09044", "authors": ["Javier Sanguino", "Thomas Kehrenberg", "Jose A. Lozano", "Novi Quadrianto"], "title": "The Decoupled Risk Landscape in Performative Prediction", "categories": ["cs.LG"], "comment": null, "summary": "Performative Prediction addresses scenarios where deploying a model induces a\ndistribution shift in the input data, such as individuals modifying their\nfeatures and reapplying for a bank loan after rejection. Literature has had a\ntheoretical perspective giving mathematical guarantees for convergence (either\nto the stable or optimal point). We believe that visualization of the loss\nlandscape can complement this theoretical advances with practical insights.\nTherefore, (1) we introduce a simple decoupled risk visualization method\ninspired in the two-step process that performative prediction is. Our approach\nvisualizes the risk landscape with respect to two parameter vectors: model\nparameters and data parameters. We use this method to propose new properties of\nthe interest points, to examine how existing algorithms traverse the risk\nlandscape and perform under more realistic conditions, including strategic\nclassification with non-linear models. (2) Building on this decoupled risk\nvisualization, we introduce a novel setting - extended Performative Prediction\n- which captures scenarios where the distribution reacts to a model different\nfrom the decision-making one, reflecting the reality that agents often lack\nfull access to the deployed model.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u89c6\u5316\u635f\u5931\u666f\u89c2\u7684\u65b9\u6cd5\uff0c\u4ee5\u8865\u5145\u7406\u8bba\u5206\u6790\uff0c\u5e76\u5f15\u5165\u6269\u5c55\u7684Performative Prediction\u8bbe\u7f6e\u3002", "motivation": "\u901a\u8fc7\u53ef\u89c6\u5316\u635f\u5931\u666f\u89c2\uff0c\u4e3aPerformative Prediction\u7684\u7406\u8bba\u7814\u7a76\u63d0\u4f9b\u5b9e\u8df5\u6d1e\u5bdf\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u89e3\u8026\u98ce\u9669\u53ef\u89c6\u5316\u65b9\u6cd5\uff0c\u5206\u6790\u6a21\u578b\u53c2\u6570\u548c\u6570\u636e\u53c2\u6570\u7684\u98ce\u9669\u666f\u89c2\uff0c\u5e76\u5f15\u5165\u6269\u5c55\u7684Performative Prediction\u8bbe\u7f6e\u3002", "result": "\u901a\u8fc7\u53ef\u89c6\u5316\u65b9\u6cd5\u63ed\u793a\u4e86\u5174\u8da3\u70b9\u7684\u65b0\u7279\u6027\uff0c\u5e76\u9a8c\u8bc1\u4e86\u73b0\u6709\u7b97\u6cd5\u5728\u66f4\u73b0\u5b9e\u6761\u4ef6\u4e0b\u7684\u8868\u73b0\u3002", "conclusion": "\u53ef\u89c6\u5316\u65b9\u6cd5\u4e3aPerformative Prediction\u63d0\u4f9b\u4e86\u65b0\u7684\u5b9e\u8df5\u89c6\u89d2\uff0c\u6269\u5c55\u7684\u8bbe\u7f6e\u66f4\u8d34\u8fd1\u73b0\u5b9e\u573a\u666f\u3002"}}
{"id": "2506.09046", "pdf": "https://arxiv.org/pdf/2506.09046", "abs": "https://arxiv.org/abs/2506.09046", "authors": ["Xiaowen Ma", "Chenyang Lin", "Yao Zhang", "Volker Tresp", "Yunpu Ma"], "title": "Agentic Neural Networks: Self-Evolving Multi-Agent Systems via Textual Backpropagation", "categories": ["cs.LG", "cs.AI", "cs.MA"], "comment": null, "summary": "Leveraging multiple Large Language Models(LLMs) has proven effective for\naddressing complex, high-dimensional tasks, but current approaches often rely\non static, manually engineered multi-agent configurations. To overcome these\nconstraints, we present the Agentic Neural Network(ANN), a framework that\nconceptualizes multi-agent collaboration as a layered neural network\narchitecture. In this design, each agent operates as a node, and each layer\nforms a cooperative \"team\" focused on a specific subtask. Agentic Neural\nNetwork follows a two-phase optimization strategy: (1) Forward Phase-Drawing\ninspiration from neural network forward passes, tasks are dynamically\ndecomposed into subtasks, and cooperative agent teams with suitable aggregation\nmethods are constructed layer by layer. (2) Backward Phase-Mirroring\nbackpropagation, we refine both global and local collaboration through\niterative feedback, allowing agents to self-evolve their roles, prompts, and\ncoordination. This neuro-symbolic approach enables ANN to create new or\nspecialized agent teams post-training, delivering notable gains in accuracy and\nadaptability. Across four benchmark datasets, ANN surpasses leading multi-agent\nbaselines under the same configurations, showing consistent performance\nimprovements. Our findings indicate that ANN provides a scalable, data-driven\nframework for multi-agent systems, combining the collaborative capabilities of\nLLMs with the efficiency and flexibility of neural network principles. We plan\nto open-source the entire framework.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAgentic Neural Network\uff08ANN\uff09\u7684\u6846\u67b6\uff0c\u5c06\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u5efa\u6a21\u4e3a\u5206\u5c42\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u901a\u8fc7\u52a8\u6001\u4efb\u52a1\u5206\u89e3\u548c\u8fed\u4ee3\u4f18\u5316\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4f9d\u8d56\u9759\u6001\u914d\u7f6e\uff0c\u9650\u5236\u4e86\u7075\u6d3b\u6027\u548c\u9002\u5e94\u6027\u3002ANN\u65e8\u5728\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u5b9e\u73b0\u52a8\u6001\u534f\u4f5c\u3002", "method": "ANN\u91c7\u7528\u4e24\u9636\u6bb5\u4f18\u5316\u7b56\u7565\uff1a\u524d\u5411\u9636\u6bb5\u52a8\u6001\u5206\u89e3\u4efb\u52a1\u5e76\u6784\u5efa\u534f\u4f5c\u56e2\u961f\uff0c\u540e\u5411\u9636\u6bb5\u901a\u8fc7\u53cd\u9988\u4f18\u5316\u534f\u4f5c\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cANN\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u591a\u667a\u80fd\u4f53\u57fa\u7ebf\uff0c\u663e\u8457\u63d0\u5347\u4e86\u51c6\u786e\u6027\u548c\u9002\u5e94\u6027\u3002", "conclusion": "ANN\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u6570\u636e\u9a71\u52a8\u7684\u6846\u67b6\uff0c\u7ed3\u5408\u4e86LLMs\u7684\u534f\u4f5c\u80fd\u529b\u548c\u795e\u7ecf\u7f51\u7edc\u7684\u6548\u7387\u3002"}}
{"id": "2506.09048", "pdf": "https://arxiv.org/pdf/2506.09048", "abs": "https://arxiv.org/abs/2506.09048", "authors": ["Yuxin Dong", "Jiachen Jiang", "Zhihui Zhu", "Xia Ning"], "title": "Understanding Task Vectors in In-Context Learning: Emergence, Functionality, and Limitations", "categories": ["cs.LG"], "comment": null, "summary": "Task vectors offer a compelling mechanism for accelerating inference in\nin-context learning (ICL) by distilling task-specific information into a\nsingle, reusable representation. Despite their empirical success, the\nunderlying principles governing their emergence and functionality remain\nunclear. This work proposes the Linear Combination Conjecture, positing that\ntask vectors act as single in-context demonstrations formed through linear\ncombinations of the original ones. We provide both theoretical and empirical\nsupport for this conjecture. First, we show that task vectors naturally emerge\nin linear transformers trained on triplet-formatted prompts through loss\nlandscape analysis. Next, we predict the failure of task vectors on\nrepresenting high-rank mappings and confirm this on practical LLMs. Our\nfindings are further validated through saliency analyses and parameter\nvisualization, suggesting an enhancement of task vectors by injecting multiple\nones into few-shot prompts. Together, our results advance the understanding of\ntask vectors and shed light on the mechanisms underlying ICL in\ntransformer-based models.", "AI": {"tldr": "\u4efb\u52a1\u5411\u91cf\u901a\u8fc7\u7ebf\u6027\u7ec4\u5408\u539f\u59cb\u6f14\u793a\u5f62\u6210\uff0c\u7528\u4e8e\u52a0\u901f\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e2d\u7684\u63a8\u7406\uff0c\u4f46\u5176\u539f\u7406\u5c1a\u4e0d\u660e\u786e\u3002\u672c\u6587\u63d0\u51fa\u7ebf\u6027\u7ec4\u5408\u731c\u60f3\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u63a2\u7d22\u4efb\u52a1\u5411\u91cf\u5728\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e2d\u7684\u5f62\u6210\u673a\u5236\u53ca\u5176\u529f\u80fd\u539f\u7406\uff0c\u4ee5\u63d0\u5347\u5176\u5e94\u7528\u6548\u679c\u3002", "method": "\u901a\u8fc7\u635f\u5931\u666f\u89c2\u5206\u6790\u9a8c\u8bc1\u4efb\u52a1\u5411\u91cf\u5728\u7ebf\u6027\u53d8\u6362\u5668\u4e2d\u7684\u81ea\u7136\u6d8c\u73b0\uff0c\u5e76\u9884\u6d4b\u5176\u5728\u8868\u793a\u9ad8\u79e9\u6620\u5c04\u65f6\u7684\u5931\u8d25\u3002", "result": "\u4efb\u52a1\u5411\u91cf\u901a\u8fc7\u7ebf\u6027\u7ec4\u5408\u5f62\u6210\uff0c\u4f46\u5728\u9ad8\u79e9\u6620\u5c04\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u901a\u8fc7\u6ce8\u5165\u591a\u4e2a\u4efb\u52a1\u5411\u91cf\u53ef\u63d0\u5347\u6548\u679c\u3002", "conclusion": "\u4efb\u52a1\u5411\u91cf\u7684\u7ebf\u6027\u7ec4\u5408\u731c\u60f3\u5f97\u5230\u9a8c\u8bc1\uff0c\u4e3a\u7406\u89e3\u5176\u5728\u53d8\u6362\u5668\u6a21\u578b\u4e2d\u7684\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2506.00160", "pdf": "https://arxiv.org/pdf/2506.00160", "abs": "https://arxiv.org/abs/2506.00160", "authors": ["Qihui Fan", "Enfu Nan", "Wenbo Li", "Lei Lu", "Pu Zhao", "Yanzhi Wang"], "title": "Werewolf: A Straightforward Game Framework with TTS for Improved User Engagement", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "The growing popularity of social deduction game systems for both business\napplications and AI research has greatly benefited from the rapid advancements\nin Large Language Models (LLMs), which now demonstrate stronger reasoning and\npersuasion capabilities. Especially with the raise of DeepSeek R1 and V3\nmodels, LLMs should enable a more engaging experience for human players in\nLLM-agent-based social deduction games like Werewolf. Previous works either\nfine-tuning, advanced prompting engineering, or additional experience pool to\nachieve engaging text-format Werewolf game experience. We propose a novel yet\nstraightforward LLM-based Werewolf game system with tuned Text-to-Speech(TTS)\nmodels designed for enhanced compatibility with various LLM models, and\nimproved user engagement. We argue with ever enhancing LLM reasoning, extra\ncomponents will be unnecessary in the case of Werewolf.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u72fc\u4eba\u6740\u6e38\u620f\u7cfb\u7edf\uff0c\u7ed3\u5408\u4f18\u5316\u7684TTS\u6a21\u578b\uff0c\u4ee5\u63d0\u5347\u7528\u6237\u4f53\u9a8c\uff0c\u5e76\u8ba4\u4e3a\u968f\u7740LLM\u63a8\u7406\u80fd\u529b\u7684\u589e\u5f3a\uff0c\u989d\u5916\u7ec4\u4ef6\u5c06\u53d8\u5f97\u591a\u4f59\u3002", "motivation": "\u968f\u7740LLM\u63a8\u7406\u548c\u8bf4\u670d\u80fd\u529b\u7684\u63d0\u5347\uff0c\u7ed3\u5408\u793e\u4ea4\u63a8\u7406\u6e38\u620f\uff08\u5982\u72fc\u4eba\u6740\uff09\u7684\u9700\u6c42\uff0c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u4f18\u5316TTS\u6a21\u578b\u548cLLM\u517c\u5bb9\u6027\uff0c\u63d0\u4f9b\u66f4\u6c89\u6d78\u7684\u6e38\u620f\u4f53\u9a8c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u72fc\u4eba\u6740\u6e38\u620f\u7cfb\u7edf\uff0c\u7ed3\u5408\u4f18\u5316\u7684TTS\u6a21\u578b\uff0c\u51cf\u5c11\u5bf9\u989d\u5916\u7ec4\u4ef6\uff08\u5982\u5fae\u8c03\u6216\u7ecf\u9a8c\u6c60\uff09\u7684\u4f9d\u8d56\u3002", "result": "\u7cfb\u7edf\u901a\u8fc7\u4f18\u5316\u7684TTS\u548cLLM\u517c\u5bb9\u6027\uff0c\u63d0\u5347\u4e86\u7528\u6237\u53c2\u4e0e\u5ea6\u548c\u6e38\u620f\u4f53\u9a8c\u3002", "conclusion": "\u968f\u7740LLM\u63a8\u7406\u80fd\u529b\u7684\u6301\u7eed\u589e\u5f3a\uff0c\u672a\u6765\u5728\u72fc\u4eba\u6740\u7b49\u6e38\u620f\u4e2d\uff0c\u989d\u5916\u7ec4\u4ef6\u53ef\u80fd\u4e0d\u518d\u5fc5\u8981\u3002"}}
{"id": "2506.08023", "pdf": "https://arxiv.org/pdf/2506.08023", "abs": "https://arxiv.org/abs/2506.08023", "authors": ["Qifeng Wu", "Zhengzhe Liu", "Han Zhu", "Yizhou Zhao", "Daisuke Kihara", "Min Xu"], "title": "Aligning Proteins and Language: A Foundation Model for Protein Retrieval", "categories": ["q-bio.BM", "cs.AI", "cs.CE", "cs.CV", "cs.LG"], "comment": "4 pages for body, 3 pages for appendix, 11 figures. Accepted to CVPR\n  2025 Workshop on Multimodal Foundation Models for Biomedicine: Challenges and\n  Opportunities(MMFM-BIOMED)", "summary": "This paper aims to retrieve proteins with similar structures and semantics\nfrom large-scale protein dataset, facilitating the functional interpretation of\nprotein structures derived by structural determination methods like\ncryo-Electron Microscopy (cryo-EM). Motivated by the recent progress of\nvision-language models (VLMs), we propose a CLIP-style framework for aligning\n3D protein structures with functional annotations using contrastive learning.\nFor model training, we propose a large-scale dataset of approximately 200,000\nprotein-caption pairs with rich functional descriptors. We evaluate our model\nin both in-domain and more challenging cross-database retrieval on Protein Data\nBank (PDB) and Electron Microscopy Data Bank (EMDB) dataset, respectively. In\nboth cases, our approach demonstrates promising zero-shot retrieval\nperformance, highlighting the potential of multimodal foundation models for\nstructure-function understanding in protein biology.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eCLIP\u98ce\u683c\u7684\u591a\u6a21\u6001\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u5927\u89c4\u6a21\u86cb\u767d\u8d28\u6570\u636e\u96c6\u4e2d\u68c0\u7d22\u7ed3\u6784\u548c\u8bed\u4e49\u76f8\u4f3c\u7684\u86cb\u767d\u8d28\uff0c\u4ee5\u8f85\u52a9\u529f\u80fd\u6ce8\u91ca\u3002", "motivation": "\u8fd1\u5e74\u6765\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u7684\u8fdb\u5c55\u542f\u53d1\u4e86\u5229\u7528\u5bf9\u6bd4\u5b66\u4e60\u5bf9\u9f503D\u86cb\u767d\u8d28\u7ed3\u6784\u4e0e\u529f\u80fd\u6ce8\u91ca\u7684\u7814\u7a76\u3002", "method": "\u91c7\u7528CLIP\u98ce\u683c\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u8bad\u7ec3\u6a21\u578b\uff0c\u5e76\u4f7f\u7528\u7ea620\u4e07\u86cb\u767d\u8d28-\u63cf\u8ff0\u5bf9\u7684\u6570\u636e\u96c6\u3002", "result": "\u5728PDB\u548cEMDB\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u96f6\u6837\u672c\u68c0\u7d22\u7684\u4f18\u5f02\u6027\u80fd\u3002", "conclusion": "\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u5728\u86cb\u767d\u8d28\u7ed3\u6784-\u529f\u80fd\u7406\u89e3\u4e2d\u5177\u6709\u6f5c\u529b\u3002"}}
{"id": "2506.08026", "pdf": "https://arxiv.org/pdf/2506.08026", "abs": "https://arxiv.org/abs/2506.08026", "authors": ["Xibai Wang"], "title": "TIP-Search: Time-Predictable Inference Scheduling for Market Prediction under Uncertain Load", "categories": ["cs.AI", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "This paper proposes TIP-Search, a time-predictable inference scheduling\nframework for real-time market prediction under uncertain workloads. Motivated\nby the strict latency demands in high-frequency financial systems, TIP-Search\ndynamically selects a deep learning model from a heterogeneous pool, aiming to\nmaximize predictive accuracy while satisfying per-task deadline constraints.\nOur approach profiles latency and generalization performance offline, then\nperforms online task-aware selection without relying on explicit input domain\nlabels. We evaluate TIP-Search on three real-world limit order book datasets\n(FI-2010, Binance BTC/USDT, LOBSTER AAPL) and demonstrate that it outperforms\nstatic baselines with up to 8.5% improvement in accuracy and 100% deadline\nsatisfaction. Our results highlight the effectiveness of TIP-Search in robust\nlow-latency financial inference under uncertainty.", "AI": {"tldr": "TIP-Search\u662f\u4e00\u79cd\u65f6\u95f4\u53ef\u9884\u6d4b\u7684\u63a8\u7406\u8c03\u5ea6\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u4e0d\u786e\u5b9a\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u8fdb\u884c\u5b9e\u65f6\u5e02\u573a\u9884\u6d4b\uff0c\u65e8\u5728\u6ee1\u8db3\u9ad8\u5ef6\u8fdf\u9700\u6c42\u5e76\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u9ad8\u9891\u7387\u91d1\u878d\u7cfb\u7edf\u5bf9\u5ef6\u8fdf\u6709\u4e25\u683c\u8981\u6c42\uff0c\u9700\u8981\u52a8\u6001\u9009\u62e9\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4ee5\u6ee1\u8db3\u4efb\u52a1\u622a\u6b62\u65f6\u95f4\u5e76\u6700\u5927\u5316\u9884\u6d4b\u51c6\u786e\u6027\u3002", "method": "TIP-Search\u901a\u8fc7\u79bb\u7ebf\u5206\u6790\u5ef6\u8fdf\u548c\u6cdb\u5316\u6027\u80fd\uff0c\u5728\u7ebf\u8fdb\u884c\u4efb\u52a1\u611f\u77e5\u9009\u62e9\uff0c\u65e0\u9700\u4f9d\u8d56\u660e\u786e\u7684\u8f93\u5165\u57df\u6807\u7b7e\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u8ba2\u5355\u7c3f\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\uff0cTIP-Search\u6bd4\u9759\u6001\u57fa\u7ebf\u65b9\u6cd5\u51c6\u786e\u7387\u63d0\u9ad88.5%\uff0c\u4e14100%\u6ee1\u8db3\u622a\u6b62\u65f6\u95f4\u3002", "conclusion": "TIP-Search\u5728\u4e0d\u786e\u5b9a\u73af\u5883\u4e0b\u5b9e\u73b0\u4e86\u4f4e\u5ef6\u8fdf\u4e14\u7a33\u5065\u7684\u91d1\u878d\u63a8\u7406\u3002"}}
{"id": "2506.08029", "pdf": "https://arxiv.org/pdf/2506.08029", "abs": "https://arxiv.org/abs/2506.08029", "authors": ["Jiayu Li", "Masood Mortazavi", "Ning Yan", "Yihong Ma", "Reza Zafarani"], "title": "Inverse Design in Distributed Circuits Using Single-Step Reinforcement Learning", "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.SY"], "comment": "A briefer version of this paper was accepted as a Work-in-Progress\n  (WIP) at the Design Automation Conference (DAC) 2024", "summary": "The goal of inverse design in distributed circuits is to generate\nnear-optimal designs that meet a desirable transfer function specification.\nExisting design exploration methods use some combination of strategies\ninvolving artificial grids, differentiable evaluation procedures, and specific\ntemplate topologies. However, real-world design practices often require\nnon-differentiable evaluation procedures, varying topologies, and\nnear-continuous placement spaces. In this paper, we propose DCIDA, a design\nexploration framework that learns a near-optimal design sampling policy for a\ntarget transfer function. DCIDA decides all design factors in a compound\nsingle-step action by sampling from a set of jointly-trained conditional\ndistributions generated by the policy. Utilizing an injective interdependent\n``map\", DCIDA transforms raw sampled design ``actions\" into uniquely equivalent\nphysical representations, enabling the framework to learn the conditional\ndependencies among joint ``raw'' design decisions. Our experiments demonstrate\nDCIDA's Transformer-based policy network achieves significant reductions in\ndesign error compared to state-of-the-art approaches, with significantly better\nfit in cases involving more complex transfer functions.", "AI": {"tldr": "DCIDA\u662f\u4e00\u79cd\u7528\u4e8e\u5206\u5e03\u5f0f\u7535\u8def\u9006\u8bbe\u8ba1\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u5408\u8bad\u7ec3\u7684\u91c7\u6837\u7b56\u7565\u751f\u6210\u8fd1\u6700\u4f18\u8bbe\u8ba1\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8bbe\u8ba1\u8bef\u5dee\u3002", "motivation": "\u73b0\u6709\u8bbe\u8ba1\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u7f51\u683c\u3001\u53ef\u5fae\u5206\u8bc4\u4f30\u548c\u56fa\u5b9a\u62d3\u6251\uff0c\u800c\u5b9e\u9645\u8bbe\u8ba1\u9700\u8981\u975e\u53ef\u5fae\u5206\u8bc4\u4f30\u3001\u53ef\u53d8\u62d3\u6251\u548c\u8fde\u7eed\u7a7a\u95f4\u3002", "method": "DCIDA\u901a\u8fc7\u8054\u5408\u8bad\u7ec3\u7684\u91c7\u6837\u7b56\u7565\u751f\u6210\u8bbe\u8ba1\u51b3\u7b56\uff0c\u5229\u7528\u6ce8\u5165\u5f0f\u6620\u5c04\u5c06\u539f\u59cb\u8bbe\u8ba1\u52a8\u4f5c\u8f6c\u5316\u4e3a\u7269\u7406\u8868\u793a\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cDCIDA\u7684Transformer\u7b56\u7565\u5728\u590d\u6742\u4f20\u9012\u51fd\u6570\u4e0b\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "DCIDA\u4e3a\u5206\u5e03\u5f0f\u7535\u8def\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.08030", "pdf": "https://arxiv.org/pdf/2506.08030", "abs": "https://arxiv.org/abs/2506.08030", "authors": ["Brian Liu", "Rahul Mazumder"], "title": "MOSS: Multi-Objective Optimization for Stable Rule Sets", "categories": ["math.OC", "cs.LG", "stat.ML"], "comment": null, "summary": "We present MOSS, a multi-objective optimization framework for constructing\nstable sets of decision rules. MOSS incorporates three important criteria for\ninterpretability: sparsity, accuracy, and stability, into a single\nmulti-objective optimization framework. Importantly, MOSS allows a practitioner\nto rapidly evaluate the trade-off between accuracy and stability in sparse rule\nsets in order to select an appropriate model. We develop a specialized cutting\nplane algorithm in our framework to rapidly compute the Pareto frontier between\nthese two objectives, and our algorithm scales to problem instances beyond the\ncapabilities of commercial optimization solvers. Our experiments show that MOSS\noutperforms state-of-the-art rule ensembles in terms of both predictive\nperformance and stability.", "AI": {"tldr": "MOSS\u662f\u4e00\u4e2a\u591a\u76ee\u6807\u4f18\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u6784\u5efa\u7a33\u5b9a\u7684\u51b3\u7b56\u89c4\u5219\u96c6\uff0c\u540c\u65f6\u8003\u8651\u7a00\u758f\u6027\u3001\u51c6\u786e\u6027\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u89e3\u51b3\u51b3\u7b56\u89c4\u5219\u96c6\u4e2d\u7a00\u758f\u6027\u3001\u51c6\u786e\u6027\u548c\u7a33\u5b9a\u6027\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\uff0c\u4e3a\u5b9e\u8df5\u8005\u63d0\u4f9b\u5feb\u901f\u8bc4\u4f30\u548c\u9009\u62e9\u6a21\u578b\u7684\u80fd\u529b\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u4e13\u7528\u7684\u5207\u5272\u5e73\u9762\u7b97\u6cd5\uff0c\u7528\u4e8e\u5feb\u901f\u8ba1\u7b97\u7a00\u758f\u89c4\u5219\u96c6\u4e2d\u51c6\u786e\u6027\u548c\u7a33\u5b9a\u6027\u4e4b\u95f4\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\uff0c\u5e76\u6269\u5c55\u5230\u5546\u4e1a\u6c42\u89e3\u5668\u65e0\u6cd5\u5904\u7406\u7684\u95ee\u9898\u89c4\u6a21\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cMOSS\u5728\u9884\u6d4b\u6027\u80fd\u548c\u7a33\u5b9a\u6027\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u89c4\u5219\u96c6\u6210\u65b9\u6cd5\u3002", "conclusion": "MOSS\u901a\u8fc7\u591a\u76ee\u6807\u4f18\u5316\u6846\u67b6\u6709\u6548\u5e73\u8861\u4e86\u7a00\u758f\u6027\u3001\u51c6\u786e\u6027\u548c\u7a33\u5b9a\u6027\uff0c\u4e3a\u51b3\u7b56\u89c4\u5219\u96c6\u7684\u6784\u5efa\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.08033", "pdf": "https://arxiv.org/pdf/2506.08033", "abs": "https://arxiv.org/abs/2506.08033", "authors": ["Axel TahmasebiMoradi", "Vincent Ren", "Benjamin Le-Creurer", "Chetra Mang"], "title": "Feasibility Study of CNNs and MLPs for Radiation Heat Transfer in 2-D Furnaces with Spectrally Participative Gases", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": null, "summary": "Aiming to reduce the computational cost of numerical simulations, a\nconvolutional neural network (CNN) and a multi-layer perceptron (MLP) are\nintroduced to build a surrogate model to approximate radiative heat transfer\nsolutions in a 2-D walled domain with participative gases. The originality of\nthis work lays in the adaptation of the inputs of the problem (gas and wall\nproperties) in order to fit with the CNN architecture, more commonly used for\nimage processing. Two precision datasets have been created with the classical\nsolver, ICARUS2D, that uses the discrete transfer radiation method with the\nstatistical narrow bands model. The performance of the CNN architecture is\ncompared to a more classical MLP architecture in terms of speed and accuracy.\nThanks to Optuna, all results are obtained using the optimized hyper parameters\nnetworks. The results show a significant speedup with industrially acceptable\nrelative errors compared to the classical solver for both architectures.\nAdditionally, the CNN outperforms the MLP in terms of precision and is more\nrobust and stable to changes in hyper-parameters. A performance analysis on the\ndataset size of the samples have also been carried out to gain a deeper\nunderstanding of the model behavior.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528CNN\u548cMLP\u6784\u5efa\u66ff\u4ee3\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u4ee5\u51cf\u5c11\u6570\u503c\u6a21\u62df\u7684\u8ba1\u7b97\u6210\u672c\uff0c\u7528\u4e8e\u8fd1\u4f3c2D\u58c1\u57df\u4e2d\u53c2\u4e0e\u6027\u6c14\u4f53\u7684\u8f90\u5c04\u70ed\u4f20\u9012\u89e3\u3002", "motivation": "\u65e8\u5728\u964d\u4f4e\u6570\u503c\u6a21\u62df\u7684\u8ba1\u7b97\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u5de5\u4e1a\u53ef\u63a5\u53d7\u7684\u7cbe\u5ea6\u3002", "method": "\u901a\u8fc7\u8c03\u6574\u8f93\u5165\u4ee5\u9002\u5e94CNN\u67b6\u6784\uff0c\u521b\u5efa\u4e86\u4e24\u4e2a\u7cbe\u5ea6\u6570\u636e\u96c6\uff0c\u5e76\u4f7f\u7528Optuna\u4f18\u5316\u8d85\u53c2\u6570\uff0c\u6bd4\u8f83\u4e86CNN\u548cMLP\u7684\u6027\u80fd\u3002", "result": "\u7ed3\u679c\u663e\u793aCNN\u548cMLP\u5747\u663e\u8457\u63d0\u901f\u4e14\u8bef\u5dee\u53ef\u63a5\u53d7\uff0cCNN\u5728\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027\u4e0a\u4f18\u4e8eMLP\u3002", "conclusion": "CNN\u5728\u66ff\u4ee3\u6a21\u578b\u4e2d\u8868\u73b0\u66f4\u4f18\uff0c\u9002\u7528\u4e8e\u5de5\u4e1a\u5e94\u7528\u3002"}}
{"id": "2506.08043", "pdf": "https://arxiv.org/pdf/2506.08043", "abs": "https://arxiv.org/abs/2506.08043", "authors": ["Ashkan Shahbazi", "Kyvia Pereira", "Jon S. Heiselman", "Elaheh Akbari", "Annie C. Benson", "Sepehr Seifi", "Xinyuan Liu", "Garrison L. Johnston", "Erwin Terpstra", "Anne Draaisma", "Jan-Jaap Severes", "Jie Ying Wu", "Nabil Simaan", "Michael L. Miga", "Soheil Kolouri"], "title": "Neural-Augmented Kelvinlet: Real-Time Soft Tissue Deformation with Multiple Graspers", "categories": ["cs.GR", "cs.CV", "cs.LG", "cs.RO"], "comment": null, "summary": "Fast and accurate simulation of soft tissue deformation is a critical factor\nfor surgical robotics and medical training. In this paper, we introduce a novel\nphysics-informed neural simulator that approximates soft tissue deformations in\na realistic and real-time manner. Our framework integrates Kelvinlet-based\npriors into neural simulators, making it the first approach to leverage\nKelvinlets for residual learning and regularization in data-driven soft tissue\nmodeling. By incorporating large-scale Finite Element Method (FEM) simulations\nof both linear and nonlinear soft tissue responses, our method improves neural\nnetwork predictions across diverse architectures, enhancing accuracy and\nphysical consistency while maintaining low latency for real-time performance.\nWe demonstrate the effectiveness of our approach by performing accurate\nsurgical maneuvers that simulate the use of standard laparoscopic tissue\ngrasping tools with high fidelity. These results establish Kelvinlet-augmented\nlearning as a powerful and efficient strategy for real-time, physics-aware soft\ntissue simulation in surgical applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7269\u7406\u4fe1\u606f\u7684\u795e\u7ecf\u6a21\u62df\u5668\uff0c\u7528\u4e8e\u5b9e\u65f6\u3001\u9ad8\u7cbe\u5ea6\u6a21\u62df\u8f6f\u7ec4\u7ec7\u53d8\u5f62\uff0c\u7ed3\u5408Kelvinlet\u5148\u9a8c\u548cFEM\u6a21\u62df\uff0c\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u548c\u7269\u7406\u4e00\u81f4\u6027\u3002", "motivation": "\u5feb\u901f\u51c6\u786e\u7684\u8f6f\u7ec4\u7ec7\u53d8\u5f62\u6a21\u62df\u5bf9\u624b\u672f\u673a\u5668\u4eba\u548c\u533b\u5b66\u8bad\u7ec3\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5c06Kelvinlet\u5148\u9a8c\u5f15\u5165\u795e\u7ecf\u6a21\u62df\u5668\uff0c\u7ed3\u5408\u5927\u89c4\u6a21FEM\u6a21\u62df\uff08\u7ebf\u6027\u548c\u975e\u7ebf\u6027\u54cd\u5e94\uff09\uff0c\u7528\u4e8e\u6b8b\u5dee\u5b66\u4e60\u548c\u6b63\u5219\u5316\u3002", "result": "\u65b9\u6cd5\u63d0\u9ad8\u4e86\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u7269\u7406\u4e00\u81f4\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4f4e\u5ef6\u8fdf\uff0c\u9002\u7528\u4e8e\u5b9e\u65f6\u624b\u672f\u6a21\u62df\u3002", "conclusion": "Kelvinlet\u589e\u5f3a\u5b66\u4e60\u662f\u4e00\u79cd\u9ad8\u6548\u7b56\u7565\uff0c\u9002\u7528\u4e8e\u624b\u672f\u5e94\u7528\u4e2d\u5b9e\u65f6\u3001\u7269\u7406\u611f\u77e5\u7684\u8f6f\u7ec4\u7ec7\u6a21\u62df\u3002"}}
{"id": "2506.08047", "pdf": "https://arxiv.org/pdf/2506.08047", "abs": "https://arxiv.org/abs/2506.08047", "authors": ["A. G. R. Sandeepa", "Sanka Mohottala"], "title": "Evaluation of Machine Learning Models in Student Academic Performance Prediction", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": "Paper Accepted for IEEE ICARC Conference (2025). 6 pages, 5 figures", "summary": "This research investigates the use of machine learning methods to forecast\nstudents' academic performance in a school setting. Students' data with\nbehavioral, academic, and demographic details were used in implementations with\nstandard classical machine learning models including multi-layer perceptron\nclassifier (MLPC). MLPC obtained 86.46% maximum accuracy for test set across\nall implementations. Under 10-fold cross validation, MLPC obtained 79.58%\naverage accuracy for test set while for train set, it was 99.65%. MLP's better\nperformance over other machine learning models strongly suggest the potential\nuse of neural networks as data-efficient models. Feature selection approach\nplayed a crucial role in improving the performance and multiple evaluation\napproaches were used in order to compare with existing literature. Explainable\nmachine learning methods were utilized to demystify the black box models and to\nvalidate the feature selection approach.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u9884\u6d4b\u5b66\u751f\u5b66\u4e1a\u8868\u73b0\u7684\u6548\u679c\uff0c\u591a\u5c42\u611f\u77e5\u5668\u5206\u7c7b\u5668\uff08MLPC\uff09\u8868\u73b0\u6700\u4f73\uff0c\u6d4b\u8bd5\u96c6\u51c6\u786e\u7387\u8fbe86.46%\u3002", "motivation": "\u63a2\u7d22\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff08\u5c24\u5176\u662f\u795e\u7ecf\u7f51\u7edc\uff09\u5728\u6559\u80b2\u6570\u636e\u4e2d\u7684\u9ad8\u6548\u6027\u548c\u6570\u636e\u5229\u7528\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u5b66\u751f\u884c\u4e3a\u3001\u5b66\u672f\u548c\u4eba\u53e3\u7edf\u8ba1\u6570\u636e\uff0c\u7ed3\u5408\u591a\u5c42\u611f\u77e5\u5668\u5206\u7c7b\u5668\uff08MLPC\uff09\u548c\u5176\u4ed6\u7ecf\u5178\u6a21\u578b\u8fdb\u884c\u9884\u6d4b\u3002", "result": "MLPC\u5728\u6d4b\u8bd5\u96c6\u4e0a\u6700\u9ad8\u51c6\u786e\u7387\u4e3a86.46%\uff0c10\u6298\u4ea4\u53c9\u9a8c\u8bc1\u5e73\u5747\u51c6\u786e\u7387\u4e3a79.58%\u3002\u7279\u5f81\u9009\u62e9\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "\u795e\u7ecf\u7f51\u7edc\u5728\u9884\u6d4b\u5b66\u751f\u8868\u73b0\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u7279\u5f81\u9009\u62e9\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u5bf9\u6a21\u578b\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2506.08049", "pdf": "https://arxiv.org/pdf/2506.08049", "abs": "https://arxiv.org/abs/2506.08049", "authors": ["Tengfei Lyu", "Weijia Zhang", "Hao Liu"], "title": "Physics-Informed Teleconnection-Aware Transformer for Global Subseasonal-to-Seasonal Forecasting", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "Subseasonal-to-seasonal (S2S) forecasting, which predicts climate conditions\nfrom several weeks to months in advance, presents significant challenges due to\nthe chaotic dynamics of atmospheric systems and complex interactions across\nmultiple scales. Current approaches often fail to explicitly model underlying\nphysical processes and teleconnections that are crucial at S2S timescales. We\nintroduce TelePiT, a novel deep learning architecture that enhances global S2S\nforecasting through integrated multi-scale physics and teleconnection\nawareness. Our approach consists of three key components: (1) Spherical\nHarmonic Embedding, which accurately encodes global atmospheric variables onto\nspherical geometry; (2) Multi-Scale Physics-Informed Neural ODE, which\nexplicitly captures atmospheric physical processes across multiple learnable\nfrequency bands; (3) Teleconnection-Aware Transformer, which models critical\nglobal climate interactions through tactfully injecting teleconnection patterns\ninto the self-attention. Extensive experiments demonstrate that TelePiT\nsignificantly outperforms state-of-the-art data-driven baselines and\noperational numerical weather prediction systems, with remarkable improvements\nfor atmospheric variables including a 57.7% reduction in RMSE for 2-meter\ntemperature compared to previous best models.", "AI": {"tldr": "TelePiT\u662f\u4e00\u79cd\u65b0\u578b\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\uff0c\u901a\u8fc7\u6574\u5408\u591a\u5c3a\u5ea6\u7269\u7406\u548c\u9065\u76f8\u5173\u610f\u8bc6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5168\u7403\u6b21\u5b63\u8282\u5230\u5b63\u8282\uff08S2S\uff09\u9884\u6d4b\u80fd\u529b\u3002", "motivation": "S2S\u9884\u6d4b\u9762\u4e34\u5927\u6c14\u7cfb\u7edf\u6df7\u6c8c\u52a8\u529b\u5b66\u548c\u591a\u5c3a\u5ea6\u590d\u6742\u4ea4\u4e92\u7684\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u660e\u786e\u5efa\u6a21\u5173\u952e\u7269\u7406\u8fc7\u7a0b\u548c\u9065\u76f8\u5173\u3002", "method": "TelePiT\u5305\u542b\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a\u7403\u8c10\u5d4c\u5165\u3001\u591a\u5c3a\u5ea6\u7269\u7406\u4fe1\u606f\u795e\u7ecfODE\u548c\u9065\u76f8\u5173\u611f\u77e5Transformer\u3002", "result": "\u5b9e\u9a8c\u663e\u793aTelePiT\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6570\u636e\u9a71\u52a8\u6a21\u578b\u548c\u6570\u503c\u5929\u6c14\u9884\u62a5\u7cfb\u7edf\uff0c\u59822\u7c73\u6e29\u5ea6RMSE\u964d\u4f4e57.7%\u3002", "conclusion": "TelePiT\u901a\u8fc7\u591a\u5c3a\u5ea6\u7269\u7406\u548c\u9065\u76f8\u5173\u5efa\u6a21\uff0c\u4e3aS2S\u9884\u6d4b\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.08059", "pdf": "https://arxiv.org/pdf/2506.08059", "abs": "https://arxiv.org/abs/2506.08059", "authors": ["Huong Van Le", "Weibin Ren", "Junhong Kim", "Yukyung Yun", "Young Bin Park", "Young Jun Kim", "Bok Kyung Han", "Inho Choi", "Jong IL Park", "Hwi-Yeol Yun", "Jae-Mun Choi"], "title": "CaliciBoost: Performance-Driven Evaluation of Molecular Representations for Caco-2 Permeability Prediction", "categories": ["q-bio.QM", "cs.AI", "cs.LG"], "comment": "49 pages, 11 figures", "summary": "Caco-2 permeability serves as a critical in vitro indicator for predicting\nthe oral absorption of drug candidates during early-stage drug discovery. To\nenhance the accuracy and efficiency of computational predictions, we\nsystematically investigated the impact of eight molecular feature\nrepresentation types including 2D/3D descriptors, structural fingerprints, and\ndeep learning-based embeddings combined with automated machine learning\ntechniques to predict Caco-2 permeability. Using two datasets of differing\nscale and diversity (TDC benchmark and curated OCHEM data), we assessed model\nperformance across representations and identified PaDEL, Mordred, and RDKit\ndescriptors as particularly effective for Caco-2 prediction. Notably, the\nAutoML-based model CaliciBoost achieved the best MAE performance. Furthermore,\nfor both PaDEL and Mordred representations, the incorporation of 3D descriptors\nresulted in a 15.73% reduction in MAE compared to using 2D features alone, as\nconfirmed by feature importance analysis. These findings highlight the\neffectiveness of AutoML approaches in ADMET modeling and offer practical\nguidance for feature selection in data-limited prediction tasks.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u901a\u8fc7\u7ed3\u5408\u591a\u79cd\u5206\u5b50\u7279\u5f81\u8868\u793a\u548c\u81ea\u52a8\u673a\u5668\u5b66\u4e60\u6280\u672f\uff0c\u63d0\u9ad8Caco-2\u6e17\u900f\u6027\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "Caco-2\u6e17\u900f\u6027\u662f\u65e9\u671f\u836f\u7269\u53d1\u73b0\u4e2d\u9884\u6d4b\u53e3\u670d\u5438\u6536\u7684\u5173\u952e\u6307\u6807\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u6709\u5f85\u63d0\u5347\u3002", "method": "\u7cfb\u7edf\u7814\u7a76\u4e86\u516b\u79cd\u5206\u5b50\u7279\u5f81\u8868\u793a\u7c7b\u578b\uff08\u59822D/3D\u63cf\u8ff0\u7b26\u3001\u7ed3\u6784\u6307\u7eb9\u548c\u6df1\u5ea6\u5b66\u4e60\u5d4c\u5165\uff09\u4e0e\u81ea\u52a8\u673a\u5668\u5b66\u4e60\u6280\u672f\u7684\u7ed3\u5408\u6548\u679c\uff0c\u4f7f\u7528\u4e24\u4e2a\u6570\u636e\u96c6\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u3002", "result": "PaDEL\u3001Mordred\u548cRDKit\u63cf\u8ff0\u7b26\u8868\u73b0\u6700\u4f73\uff0cAutoML\u6a21\u578bCaliciBoost\u7684MAE\u6027\u80fd\u6700\u4f18\uff1b3D\u63cf\u8ff0\u7b26\u7684\u52a0\u5165\u4f7fMAE\u964d\u4f4e15.73%\u3002", "conclusion": "\u7814\u7a76\u8bc1\u660e\u4e86AutoML\u5728ADMET\u5efa\u6a21\u4e2d\u7684\u6709\u6548\u6027\uff0c\u5e76\u4e3a\u6570\u636e\u6709\u9650\u7684\u4efb\u52a1\u63d0\u4f9b\u4e86\u7279\u5f81\u9009\u62e9\u7684\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2506.08065", "pdf": "https://arxiv.org/pdf/2506.08065", "abs": "https://arxiv.org/abs/2506.08065", "authors": ["Ye Zhu", "Duo Xu", "Zhiwei Deng", "Jonathon C. Tan", "Olga Russakovsky"], "title": "Dynamic Diffusion Schr\u00f6dinger Bridge in Astrophysical Observational Inversions", "categories": ["astro-ph.IM", "cs.LG"], "comment": "Preprint. Code will be available at\n  https://github.com/L-YeZhu/AstroDSB", "summary": "We study Diffusion Schr\\\"odinger Bridge (DSB) models in the context of\ndynamical astrophysical systems, specifically tackling observational inverse\nprediction tasks within Giant Molecular Clouds (GMCs) for star formation. We\nintroduce the Astro-DSB model, a variant of DSB with the pairwise domain\nassumption tailored for astrophysical dynamics. By investigating its learning\nprocess and prediction performance in both physically simulated data and in\nreal observations (the Taurus B213 data), we present two main takeaways. First,\nfrom the astrophysical perspective, our proposed paired DSB method improves\ninterpretability, learning efficiency, and prediction performance over\nconventional astrostatistical and other machine learning methods. Second, from\nthe generative modeling perspective, probabilistic generative modeling reveals\nimprovements over discriminative pixel-to-pixel modeling in Out-Of-Distribution\n(OOD) testing cases of physical simulations with unseen initial conditions and\ndifferent dominant physical processes. Our study expands research into\ndiffusion models beyond the traditional visual synthesis application and\nprovides evidence of the models' learning abilities beyond pure data\nstatistics, paving a path for future physics-aware generative models which can\nalign dynamics between machine learning and real (astro)physical systems.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u6269\u6563\u859b\u5b9a\u8c14\u6865\uff08DSB\uff09\u6a21\u578b\u5728\u52a8\u6001\u5929\u4f53\u7269\u7406\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\uff0c\u63d0\u51fa\u4e86Astro-DSB\u6a21\u578b\uff0c\u5e76\u5728GMCs\u7684\u89c2\u6d4b\u9006\u9884\u6d4b\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u5176\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u5929\u4f53\u7edf\u8ba1\u548c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728GMCs\u7684\u89c2\u6d4b\u9006\u9884\u6d4b\u4efb\u52a1\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u4e86Astro-DSB\u6a21\u578b\uff0c\u4e00\u79cd\u9488\u5bf9\u5929\u4f53\u7269\u7406\u52a8\u6001\u8bbe\u8ba1\u7684DSB\u53d8\u4f53\uff0c\u5e76\u5728\u6a21\u62df\u6570\u636e\u548c\u771f\u5b9e\u89c2\u6d4b\u6570\u636e\uff08Taurus B213\uff09\u4e2d\u6d4b\u8bd5\u5176\u5b66\u4e60\u548c\u9884\u6d4b\u6027\u80fd\u3002", "result": "Astro-DSB\u5728\u53ef\u89e3\u91ca\u6027\u3001\u5b66\u4e60\u6548\u7387\u548c\u9884\u6d4b\u6027\u80fd\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u4e14\u5728OOD\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u7814\u7a76\u6269\u5c55\u4e86\u6269\u6563\u6a21\u578b\u7684\u5e94\u7528\u8303\u56f4\uff0c\u5c55\u793a\u4e86\u5176\u5728\u7269\u7406\u611f\u77e5\u751f\u6210\u6a21\u578b\u4e2d\u7684\u6f5c\u529b\uff0c\u4e3a\u672a\u6765\u52a8\u6001\u5bf9\u9f50\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2506.08066", "pdf": "https://arxiv.org/pdf/2506.08066", "abs": "https://arxiv.org/abs/2506.08066", "authors": ["Alexander Stepikin", "Evgenia Romanenkova", "Alexey Zaytsev"], "title": "WWAggr: A Window Wasserstein-based Aggregation for Ensemble Change Point Detection", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "Change Point Detection (CPD) aims to identify moments of abrupt distribution\nshifts in data streams. Real-world high-dimensional CPD remains challenging due\nto data pattern complexity and violation of common assumptions. Resorting to\nstandalone deep neural networks, the current state-of-the-art detectors have\nyet to achieve perfect quality. Concurrently, ensembling provides more robust\nsolutions, boosting the performance. In this paper, we investigate ensembles of\ndeep change point detectors and realize that standard prediction aggregation\ntechniques, e.g., averaging, are suboptimal and fail to account for problem\npeculiarities. Alternatively, we introduce WWAggr -- a novel task-specific\nmethod of ensemble aggregation based on the Wasserstein distance. Our procedure\nis versatile, working effectively with various ensembles of deep CPD models.\nMoreover, unlike existing solutions, we practically lift a long-standing\nproblem of the decision threshold selection for CPD.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eWasserstein\u8ddd\u79bb\u7684\u65b0\u578b\u96c6\u6210\u805a\u5408\u65b9\u6cd5WWAggr\uff0c\u7528\u4e8e\u63d0\u5347\u9ad8\u7ef4\u6570\u636e\u6d41\u4e2d\u7684\u53d8\u5316\u70b9\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u53d8\u5316\u70b9\u68c0\u6d4b\u5668\u5728\u590d\u6742\u6570\u636e\u6a21\u5f0f\u548c\u5e38\u89c1\u5047\u8bbe\u5931\u6548\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u4e0d\u4f73\uff0c\u800c\u6807\u51c6\u96c6\u6210\u805a\u5408\u65b9\u6cd5\uff08\u5982\u5e73\u5747\uff09\u672a\u80fd\u5145\u5206\u5229\u7528\u95ee\u9898\u7279\u6027\u3002", "method": "\u5f15\u5165WWAggr\uff0c\u4e00\u79cd\u57fa\u4e8eWasserstein\u8ddd\u79bb\u7684\u4efb\u52a1\u7279\u5b9a\u96c6\u6210\u805a\u5408\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u6df1\u5ea6\u53d8\u5316\u70b9\u68c0\u6d4b\u6a21\u578b\u7684\u96c6\u6210\u3002", "result": "WWAggr\u6709\u6548\u63d0\u5347\u4e86\u53d8\u5316\u70b9\u68c0\u6d4b\u7684\u6027\u80fd\uff0c\u5e76\u89e3\u51b3\u4e86\u51b3\u7b56\u9608\u503c\u9009\u62e9\u7684\u957f\u671f\u95ee\u9898\u3002", "conclusion": "WWAggr\u4e3a\u9ad8\u7ef4\u6570\u636e\u6d41\u4e2d\u7684\u53d8\u5316\u70b9\u68c0\u6d4b\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u9c81\u68d2\u548c\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.08073", "pdf": "https://arxiv.org/pdf/2506.08073", "abs": "https://arxiv.org/abs/2506.08073", "authors": ["Yu Liu", "Utkarsh Pratiush", "Kamyar Barakati", "Hiroshi Funakubo", "Ching-Che Lin", "Jaegyu Kim", "Lane W. Martin", "Sergei V. Kalinin"], "title": "Domain Switching on the Pareto Front: Multi-Objective Deep Kernel Learning in Automated Piezoresponse Force Microscopy", "categories": ["cond-mat.mtrl-sci", "cond-mat.mes-hall", "cs.AI", "cs.LG"], "comment": null, "summary": "Ferroelectric polarization switching underpins the functional performance of\na wide range of materials and devices, yet its dependence on complex local\nmicrostructural features renders systematic exploration by manual or grid-based\nspectroscopic measurements impractical. Here, we introduce a multi-objective\nkernel-learning workflow that infers the microstructural rules governing\nswitching behavior directly from high-resolution imaging data. Applied to\nautomated piezoresponse force microscopy (PFM) experiments, our framework\nefficiently identifies the key relationships between domain-wall configurations\nand local switching kinetics, revealing how specific wall geometries and defect\ndistributions modulate polarization reversal. Post-experiment analysis projects\nabstract reward functions, such as switching ease and domain symmetry, onto\nphysically interpretable descriptors including domain configuration and\nproximity to boundaries. This enables not only high-throughput active learning,\nbut also mechanistic insight into the microstructural control of switching\nphenomena. While demonstrated for ferroelectric domain switching, our approach\nprovides a powerful, generalizable tool for navigating complex,\nnon-differentiable design spaces, from structure-property correlations in\nmolecular discovery to combinatorial optimization across diverse imaging\nmodalities.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u76ee\u6807\u6838\u5b66\u4e60\u5de5\u4f5c\u6d41\uff0c\u7528\u4e8e\u4ece\u9ad8\u5206\u8fa8\u7387\u6210\u50cf\u6570\u636e\u4e2d\u63a8\u65ad\u5fae\u7ed3\u6784\u89c4\u5219\uff0c\u63ed\u793a\u4e86\u94c1\u7535\u6781\u5316\u5f00\u5173\u884c\u4e3a\u7684\u5fae\u89c2\u673a\u5236\u3002", "motivation": "\u94c1\u7535\u6781\u5316\u5f00\u5173\u884c\u4e3a\u5bf9\u6750\u6599\u548c\u8bbe\u5907\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5176\u4f9d\u8d56\u590d\u6742\u7684\u5c40\u90e8\u5fae\u7ed3\u6784\u7279\u5f81\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u7cfb\u7edf\u7814\u7a76\u3002", "method": "\u91c7\u7528\u591a\u76ee\u6807\u6838\u5b66\u4e60\u5de5\u4f5c\u6d41\uff0c\u7ed3\u5408\u81ea\u52a8\u5316\u538b\u7535\u54cd\u5e94\u529b\u663e\u5fae\u955c\uff08PFM\uff09\u5b9e\u9a8c\uff0c\u5206\u6790\u57df\u58c1\u6784\u578b\u4e0e\u5c40\u90e8\u5f00\u5173\u52a8\u529b\u5b66\u7684\u5173\u952e\u5173\u7cfb\u3002", "result": "\u63ed\u793a\u4e86\u7279\u5b9a\u58c1\u51e0\u4f55\u548c\u7f3a\u9677\u5206\u5e03\u5bf9\u6781\u5316\u53cd\u8f6c\u7684\u8c03\u63a7\u4f5c\u7528\uff0c\u5e76\u5c06\u62bd\u8c61\u5956\u52b1\u51fd\u6570\u6620\u5c04\u5230\u7269\u7406\u53ef\u89e3\u91ca\u7684\u63cf\u8ff0\u7b26\u4e0a\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u9002\u7528\u4e8e\u94c1\u7535\u57df\u5f00\u5173\u7814\u7a76\uff0c\u8fd8\u53ef\u63a8\u5e7f\u5230\u5176\u4ed6\u590d\u6742\u975e\u53ef\u5fae\u8bbe\u8ba1\u7a7a\u95f4\u7684\u63a2\u7d22\u3002"}}
{"id": "2506.08121", "pdf": "https://arxiv.org/pdf/2506.08121", "abs": "https://arxiv.org/abs/2506.08121", "authors": ["Qi Feng", "Gu Wang"], "title": "Continuous Policy and Value Iteration for Stochastic Control Problems and Its Convergence", "categories": ["math.OC", "cs.LG", "93E20, 93E35, 60H10"], "comment": "37 pages", "summary": "We introduce a continuous policy-value iteration algorithm where the\napproximations of the value function of a stochastic control problem and the\noptimal control are simultaneously updated through Langevin-type dynamics. This\nframework applies to both the entropy-regularized relaxed control problems and\nthe classical control problems, with infinite horizon. We establish policy\nimprovement and demonstrate convergence to the optimal control under the\nmonotonicity condition of the Hamiltonian. By utilizing Langevin-type\nstochastic differential equations for continuous updates along the policy\niteration direction, our approach enables the use of distribution sampling and\nnon-convex learning techniques in machine learning to optimize the value\nfunction and identify the optimal control simultaneously.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8fde\u7eed\u7b56\u7565-\u503c\u8fed\u4ee3\u7b97\u6cd5\uff0c\u901a\u8fc7Langevin\u52a8\u529b\u5b66\u540c\u65f6\u66f4\u65b0\u968f\u673a\u63a7\u5236\u95ee\u9898\u7684\u503c\u51fd\u6570\u548c\u6700\u4f18\u63a7\u5236\u7684\u8fd1\u4f3c\u89e3\u3002", "motivation": "\u89e3\u51b3\u71b5\u6b63\u5219\u5316\u677e\u5f1b\u63a7\u5236\u95ee\u9898\u548c\u7ecf\u5178\u63a7\u5236\u95ee\u9898\u4e2d\u65e0\u9650\u65f6\u95f4\u8303\u56f4\u4e0b\u7684\u503c\u51fd\u6570\u548c\u6700\u4f18\u63a7\u5236\u540c\u65f6\u4f18\u5316\u95ee\u9898\u3002", "method": "\u5229\u7528Langevin\u578b\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u8fdb\u884c\u8fde\u7eed\u66f4\u65b0\uff0c\u7ed3\u5408\u5206\u5e03\u91c7\u6837\u548c\u975e\u51f8\u5b66\u4e60\u6280\u672f\u3002", "result": "\u5728\u54c8\u5bc6\u987f\u5355\u8c03\u6027\u6761\u4ef6\u4e0b\uff0c\u8bc1\u660e\u4e86\u7b56\u7565\u6539\u8fdb\u548c\u6536\u655b\u5230\u6700\u4f18\u63a7\u5236\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u5206\u5e03\u91c7\u6837\u548c\u975e\u51f8\u5b66\u4e60\u6280\u672f\u63d0\u4f9b\u4e86\u65b0\u7684\u5e94\u7528\u9014\u5f84\u3002"}}
{"id": "2506.08127", "pdf": "https://arxiv.org/pdf/2506.08127", "abs": "https://arxiv.org/abs/2506.08127", "authors": ["Cyrille Kone", "Emilie Kaufmann", "Laura Richert"], "title": "Constrained Pareto Set Identification with Bandit Feedback", "categories": ["stat.ML", "cs.LG"], "comment": "To appear in Proceedings of ICML2025", "summary": "In this paper, we address the problem of identifying the Pareto Set under\nfeasibility constraints in a multivariate bandit setting. Specifically, given a\n$K$-armed bandit with unknown means $\\mu_1, \\dots, \\mu_K \\in \\mathbb{R}^d$, the\ngoal is to identify the set of arms whose mean is not uniformly worse than that\nof another arm (i.e., not smaller for all objectives), while satisfying some\nknown set of linear constraints, expressing, for example, some minimal\nperformance on each objective. Our focus lies in fixed-confidence\nidentification, for which we introduce an algorithm that significantly\noutperforms racing-like algorithms and the intuitive two-stage approach that\nfirst identifies feasible arms and then their Pareto Set. We further prove an\ninformation-theoretic lower bound on the sample complexity of any algorithm for\nconstrained Pareto Set identification, showing that the sample complexity of\nour approach is near-optimal. Our theoretical results are supported by an\nextensive empirical evaluation on a series of benchmarks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u53ef\u884c\u6027\u7ea6\u675f\u4e0b\u8bc6\u522b\u591a\u76ee\u6807\u5e15\u7d2f\u6258\u96c6\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u65b0\u7b97\u6cd5\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u6837\u672c\u590d\u6742\u5ea6\u7684\u8fd1\u4f18\u6027\u3002", "motivation": "\u89e3\u51b3\u5728\u591a\u81c2\u8001\u864e\u673a\u8bbe\u7f6e\u4e2d\uff0c\u5982\u4f55\u5728\u6ee1\u8db3\u7ebf\u6027\u7ea6\u675f\u6761\u4ef6\u4e0b\u8bc6\u522b\u5e15\u7d2f\u6258\u96c6\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u56fa\u5b9a\u7f6e\u4fe1\u5ea6\u8bc6\u522b\u7b97\u6cd5\uff0c\u4f18\u4e8e\u4f20\u7edf\u7684\u4e24\u9636\u6bb5\u65b9\u6cd5\u548c\u7ade\u8d5b\u7c7b\u7b97\u6cd5\u3002", "result": "\u7b97\u6cd5\u5728\u6837\u672c\u590d\u6742\u5ea6\u4e0a\u63a5\u8fd1\u7406\u8bba\u4e0b\u754c\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "conclusion": "\u65b0\u7b97\u6cd5\u5728\u7406\u8bba\u548c\u5b9e\u9a8c\u4e0a\u5747\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.08147", "pdf": "https://arxiv.org/pdf/2506.08147", "abs": "https://arxiv.org/abs/2506.08147", "authors": ["Muhammad Usman", "Muhammad Ahmad", "M. Shahiki Tash", "Irina Gelbukh", "Rolando Quintero Tellez", "Grigori Sidorov"], "title": "Multilingual Hate Speech Detection in Social Media Using Translation-Based Approaches with Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Social media platforms are critical spaces for public discourse, shaping\nopinions and community dynamics, yet their widespread use has amplified harmful\ncontent, particularly hate speech, threatening online safety and inclusivity.\nWhile hate speech detection has been extensively studied in languages like\nEnglish and Spanish, Urdu remains underexplored, especially using\ntranslation-based approaches. To address this gap, we introduce a trilingual\ndataset of 10,193 tweets in English (3,834 samples), Urdu (3,197 samples), and\nSpanish (3,162 samples), collected via keyword filtering, with a balanced\ndistribution of 4,849 Hateful and 5,344 Not-Hateful labels. Our methodology\nleverages attention layers as a precursor to transformer-based models and large\nlanguage models (LLMs), enhancing feature extraction for multilingual hate\nspeech detection. For non-transformer models, we use TF-IDF for feature\nextraction. The dataset is benchmarked using state-of-the-art models, including\nGPT-3.5 Turbo and Qwen 2.5 72B, alongside traditional machine learning models\nlike SVM and other transformers (e.g., BERT, RoBERTa). Three annotators,\nfollowing rigorous guidelines, ensured high dataset quality, achieving a\nFleiss' Kappa of 0.821. Our approach, integrating attention layers with GPT-3.5\nTurbo and Qwen 2.5 72B, achieves strong performance, with macro F1 scores of\n0.87 for English (GPT-3.5 Turbo), 0.85 for Spanish (GPT-3.5 Turbo), 0.81 for\nUrdu (Qwen 2.5 72B), and 0.88 for the joint multilingual model (Qwen 2.5 72B).\nThese results reflect improvements of 8.75% in English (over SVM baseline\n0.80), 8.97% in Spanish (over SVM baseline 0.78), 5.19% in Urdu (over SVM\nbaseline 0.77), and 7.32% in the joint multilingual model (over SVM baseline\n0.82). Our framework offers a robust solution for multilingual hate speech\ndetection, fostering safer digital communities worldwide.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6ce8\u610f\u529b\u5c42\u548cTransformer\u6a21\u578b\u7684\u591a\u8bed\u8a00\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5e76\u5728\u82f1\u8bed\u3001\u897f\u73ed\u7259\u8bed\u548c\u4e4c\u5c14\u90fd\u8bed\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u793e\u4ea4\u5a92\u4f53\u4e0a\u7684\u4ec7\u6068\u8a00\u8bba\u5a01\u80c1\u5728\u7ebf\u5b89\u5168\u548c\u5305\u5bb9\u6027\uff0c\u800c\u4e4c\u5c14\u90fd\u8bed\u7684\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u7814\u7a76\u8f83\u5c11\uff0c\u5c24\u5176\u662f\u57fa\u4e8e\u7ffb\u8bd1\u7684\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u6ce8\u610f\u529b\u5c42\u589e\u5f3aTransformer\u6a21\u578b\uff08\u5982GPT-3.5 Turbo\u548cQwen 2.5 72B\uff09\u7684\u7279\u5f81\u63d0\u53d6\u80fd\u529b\uff0c\u540c\u65f6\u4f7f\u7528TF-IDF\u652f\u6301\u975eTransformer\u6a21\u578b\u3002", "result": "\u5728\u82f1\u8bed\u3001\u897f\u73ed\u7259\u8bed\u548c\u4e4c\u5c14\u90fd\u8bed\u4e0a\u5206\u522b\u5b9e\u73b0\u4e860.87\u30010.85\u548c0.81\u7684\u5b8fF1\u5206\u6570\uff0c\u591a\u8bed\u8a00\u6a21\u578b\u8fbe\u52300.88\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u591a\u8bed\u8a00\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u52a9\u4e8e\u6784\u5efa\u66f4\u5b89\u5168\u7684\u6570\u5b57\u793e\u533a\u3002"}}
{"id": "2506.08153", "pdf": "https://arxiv.org/pdf/2506.08153", "abs": "https://arxiv.org/abs/2506.08153", "authors": ["Renato Cordeiro Ferreira"], "title": "A Metrics-Oriented Architectural Model to Characterize Complexity on Machine Learning-Enabled Systems", "categories": ["cs.SE", "cs.AI", "cs.LG", "D.2.11; D.2.8; I.2.0"], "comment": "4 pages, 3 figures (2 diagrams, 1 table), to be published in CAIN\n  2025", "summary": "How can the complexity of ML-enabled systems be managed effectively? The goal\nof this research is to investigate how complexity affects ML-Enabled Systems\n(MLES). To address this question, this research aims to introduce a\nmetrics-based architectural model to characterize the complexity of MLES. The\ngoal is to support architectural decisions, providing a guideline for the\ninception and growth of these systems. This paper showcases the first step for\ncreating the metrics-based architectural model: an extension of a reference\narchitecture that can describe MLES to collect their metrics.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6307\u6807\u7684\u67b6\u6784\u6a21\u578b\uff0c\u7528\u4e8e\u7ba1\u7406ML\u7cfb\u7edf\u7684\u590d\u6742\u6027\uff0c\u5e76\u6269\u5c55\u4e86\u53c2\u8003\u67b6\u6784\u4ee5\u6536\u96c6\u6307\u6807\u3002", "motivation": "\u63a2\u8ba8\u590d\u6742\u6027\u5982\u4f55\u5f71\u54cdML\u7cfb\u7edf\uff0c\u5e76\u652f\u6301\u67b6\u6784\u51b3\u7b56\u3002", "method": "\u6269\u5c55\u53c2\u8003\u67b6\u6784\u4ee5\u63cf\u8ff0ML\u7cfb\u7edf\u5e76\u6536\u96c6\u6307\u6807\u3002", "result": "\u63d0\u51fa\u4e86\u6784\u5efa\u6307\u6807\u6a21\u578b\u7684\u7b2c\u4e00\u6b65\u3002", "conclusion": "\u4e3aML\u7cfb\u7edf\u7684\u590d\u6742\u6027\u7ba1\u7406\u63d0\u4f9b\u4e86\u521d\u6b65\u6846\u67b6\u3002"}}
{"id": "2506.08192", "pdf": "https://arxiv.org/pdf/2506.08192", "abs": "https://arxiv.org/abs/2506.08192", "authors": ["Jared Claypoole", "Steven Cheung", "Ashish Gehani", "Vinod Yegneswaran", "Ahmad Ridley"], "title": "Interpreting Agent Behaviors in Reinforcement-Learning-Based Cyber-Battle Simulation Platforms", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "We analyze two open source deep reinforcement learning agents submitted to\nthe CAGE Challenge 2 cyber defense challenge, where each competitor submitted\nan agent to defend a simulated network against each of several provided\nrules-based attack agents. We demonstrate that one can gain interpretability of\nagent successes and failures by simplifying the complex state and action spaces\nand by tracking important events, shedding light on the fine-grained behavior\nof both the defense and attack agents in each experimental scenario. By\nanalyzing important events within an evaluation episode, we identify patterns\nin infiltration and clearing events that tell us how well the attacker and\ndefender played their respective roles; for example, defenders were generally\nable to clear infiltrations within one or two timesteps of a host being\nexploited. By examining transitions in the environment's state caused by the\nvarious possible actions, we determine which actions tended to be effective and\nwhich did not, showing that certain important actions are between 40% and 99%\nineffective. We examine how decoy services affect exploit success, concluding\nfor instance that decoys block up to 94% of exploits that would directly grant\nprivileged access to a host. Finally, we discuss the realism of the challenge\nand ways that the CAGE Challenge 4 has addressed some of our concerns.", "AI": {"tldr": "\u5206\u6790\u4e86\u4e24\u4e2a\u5f00\u6e90\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u5728CAGE Challenge 2\u4e2d\u7684\u8868\u73b0\uff0c\u901a\u8fc7\u7b80\u5316\u72b6\u6001\u548c\u52a8\u4f5c\u7a7a\u95f4\u4ee5\u53ca\u8ddf\u8e2a\u5173\u952e\u4e8b\u4ef6\uff0c\u63ed\u793a\u4e86\u9632\u5fa1\u548c\u653b\u51fb\u4ee3\u7406\u7684\u7ec6\u7c92\u5ea6\u884c\u4e3a\u3002", "motivation": "\u7814\u7a76\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u5728\u7f51\u7edc\u5b89\u5168\u9632\u5fa1\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u63d0\u5347\u5176\u884c\u4e3a\u7684\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u7b80\u5316\u590d\u6742\u7684\u72b6\u6001\u548c\u52a8\u4f5c\u7a7a\u95f4\uff0c\u8ddf\u8e2a\u5173\u952e\u4e8b\u4ef6\uff0c\u5206\u6790\u73af\u5883\u72b6\u6001\u8f6c\u6362\u548c\u52a8\u4f5c\u6548\u679c\u3002", "result": "\u9632\u5fa1\u4ee3\u7406\u901a\u5e38\u80fd\u57281-2\u4e2a\u65f6\u95f4\u6b65\u5185\u6e05\u9664\u5165\u4fb5\uff1b\u67d0\u4e9b\u5173\u952e\u52a8\u4f5c\u7684\u65e0\u6548\u6027\u9ad8\u8fbe40%-99%\uff1b\u8bf1\u9975\u670d\u52a1\u80fd\u963b\u6b62\u9ad8\u8fbe94%\u7684\u7279\u6743\u8bbf\u95ee\u653b\u51fb\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u4ee3\u7406\u884c\u4e3a\u7684\u6709\u6548\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u5bf9CAGE Challenge 4\u7684\u6539\u8fdb\u5efa\u8bae\u3002"}}
{"id": "2506.08210", "pdf": "https://arxiv.org/pdf/2506.08210", "abs": "https://arxiv.org/abs/2506.08210", "authors": ["Andrew Z. Wang", "Songwei Ge", "Tero Karras", "Ming-Yu Liu", "Yogesh Balaji"], "title": "A Comprehensive Study of Decoder-Only LLMs for Text-to-Image Generation", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": "CVPR 2025", "summary": "Both text-to-image generation and large language models (LLMs) have made\nsignificant advancements. However, many text-to-image models still employ the\nsomewhat outdated T5 and CLIP as their text encoders. In this work, we\ninvestigate the effectiveness of using modern decoder-only LLMs as text\nencoders for text-to-image diffusion models. We build a standardized training\nand evaluation pipeline that allows us to isolate and evaluate the effect of\ndifferent text embeddings. We train a total of 27 text-to-image models with 12\ndifferent text encoders to analyze the critical aspects of LLMs that could\nimpact text-to-image generation, including the approaches to extract\nembeddings, different LLMs variants, and model sizes. Our experiments reveal\nthat the de facto way of using last-layer embeddings as conditioning leads to\ninferior performance. Instead, we explore embeddings from various layers and\nfind that using layer-normalized averaging across all layers significantly\nimproves alignment with complex prompts. Most LLMs with this conditioning\noutperform the baseline T5 model, showing enhanced performance in advanced\nvisio-linguistic reasoning skills.", "AI": {"tldr": "\u7814\u7a76\u4e86\u4f7f\u7528\u73b0\u4ee3\u4ec5\u89e3\u7801\u5668LLM\u4f5c\u4e3a\u6587\u672c\u7f16\u7801\u5668\u5728\u6587\u672c\u5230\u56fe\u50cf\u6269\u6563\u6a21\u578b\u4e2d\u7684\u6548\u679c\uff0c\u53d1\u73b0\u591a\u5c42\u5f52\u4e00\u5316\u5e73\u5747\u5d4c\u5165\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u63a2\u7d22\u73b0\u4ee3LLM\u4f5c\u4e3a\u6587\u672c\u7f16\u7801\u5668\u662f\u5426\u80fd\u63d0\u5347\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u7684\u6548\u679c\uff0c\u66ff\u4ee3\u8fc7\u65f6\u7684T5\u548cCLIP\u3002", "method": "\u6784\u5efa\u6807\u51c6\u5316\u8bad\u7ec3\u548c\u8bc4\u4f30\u6d41\u7a0b\uff0c\u8bad\u7ec327\u4e2a\u6a21\u578b\uff0c\u5206\u679012\u79cd\u6587\u672c\u7f16\u7801\u5668\u7684\u5d4c\u5165\u63d0\u53d6\u65b9\u5f0f\u3001LLM\u53d8\u4f53\u548c\u6a21\u578b\u5927\u5c0f\u3002", "result": "\u591a\u5c42\u5f52\u4e00\u5316\u5e73\u5747\u5d4c\u5165\u663e\u8457\u63d0\u5347\u590d\u6742\u63d0\u793a\u7684\u5bf9\u9f50\u6548\u679c\uff0c\u591a\u6570LLM\u4f18\u4e8e\u57fa\u7ebfT5\u6a21\u578b\u3002", "conclusion": "\u73b0\u4ee3LLM\u4f5c\u4e3a\u6587\u672c\u7f16\u7801\u5668\u80fd\u63d0\u5347\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u6027\u80fd\uff0c\u5c24\u5176\u662f\u590d\u6742\u89c6\u89c9\u8bed\u8a00\u63a8\u7406\u4efb\u52a1\u3002"}}
{"id": "2506.08263", "pdf": "https://arxiv.org/pdf/2506.08263", "abs": "https://arxiv.org/abs/2506.08263", "authors": ["Pouya Agheli", "Tugce Kobal", "Fran\u00e7ois Durand", "Matthew Andrews"], "title": "Learning-Based Multiuser Scheduling in MIMO-OFDM Systems with Hybrid Beamforming", "categories": ["cs.IT", "cs.LG", "eess.SP", "math.IT"], "comment": "To appear in the proceedings of the European Conference on Networks\n  and Communications (EuCNC) & 6G Summit, 2025", "summary": "We investigate the multiuser scheduling problem in multiple-input\nmultiple-output (MIMO) systems using orthogonal frequency division multiplexing\n(OFDM) and hybrid beamforming in which a base station (BS) communicates with\nmultiple users over millimeter wave (mmWave) channels in the downlink. Improved\nscheduling is critical for enhancing spectral efficiency and the long-term\nperformance of the system from the perspective of proportional fairness (PF)\nmetric in hybrid beamforming systems due to its limited multiplexing gain. Our\nobjective is to maximize PF by properly designing the analog and digital\nprecoders within the hybrid beamforming and selecting the users subject to the\nnumber of radio frequency (RF) chains. Leveraging the characteristics of mmWave\nchannels, we apply a two-timescale protocol. On a long timescale, we assign an\nanalog beam to each user. Scheduling the users and designing the digital\nprecoder are done accordingly on a short timescale. To conduct scheduling, we\npropose combinatorial solutions, such as greedy and sorting algorithms,\nfollowed by a machine learning (ML) approach. Our numerical results highlight\nthe trade-off between the performance and complexity of the proposed\napproaches. Consequently, we show that the choice of approach depends on the\nspecific criteria within a given scenario.", "AI": {"tldr": "\u7814\u7a76\u4e86\u591a\u7528\u6237\u8c03\u5ea6\u95ee\u9898\uff0c\u7ed3\u5408MIMO-OFDM\u548c\u6df7\u5408\u6ce2\u675f\u6210\u5f62\u6280\u672f\uff0c\u4ee5\u6beb\u7c73\u6ce2\u4fe1\u9053\u4e3a\u80cc\u666f\uff0c\u63d0\u51fa\u4e24\u65f6\u95f4\u5c3a\u5ea6\u534f\u8bae\u548c\u591a\u79cd\u8c03\u5ea6\u7b97\u6cd5\u3002", "motivation": "\u63d0\u5347\u9891\u8c31\u6548\u7387\u548c\u957f\u671f\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u6df7\u5408\u6ce2\u675f\u6210\u5f62\u7cfb\u7edf\u4e2d\uff0c\u7531\u4e8e\u590d\u7528\u589e\u76ca\u6709\u9650\uff0c\u8c03\u5ea6\u95ee\u9898\u5c24\u4e3a\u5173\u952e\u3002", "method": "\u91c7\u7528\u4e24\u65f6\u95f4\u5c3a\u5ea6\u534f\u8bae\uff0c\u957f\u5c3a\u5ea6\u5206\u914d\u6a21\u62df\u6ce2\u675f\uff0c\u77ed\u5c3a\u5ea6\u8c03\u5ea6\u7528\u6237\u5e76\u8bbe\u8ba1\u6570\u5b57\u9884\u7f16\u7801\u5668\uff0c\u63d0\u51fa\u8d2a\u5a6a\u3001\u6392\u5e8f\u7b97\u6cd5\u53ca\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u3002", "result": "\u6570\u503c\u7ed3\u679c\u5c55\u793a\u4e86\u6027\u80fd\u4e0e\u590d\u6742\u5ea6\u7684\u6743\u8861\uff0c\u4e0d\u540c\u65b9\u6cd5\u9002\u7528\u4e8e\u4e0d\u540c\u573a\u666f\u3002", "conclusion": "\u65b9\u6cd5\u9009\u62e9\u9700\u6839\u636e\u5177\u4f53\u573a\u666f\u9700\u6c42\uff0c\u6743\u8861\u6027\u80fd\u4e0e\u590d\u6742\u5ea6\u3002"}}
{"id": "2506.08276", "pdf": "https://arxiv.org/pdf/2506.08276", "abs": "https://arxiv.org/abs/2506.08276", "authors": ["Yichuan Wang", "Shu Liu", "Zhifei Li", "Yongji Wu", "Ziming Mao", "Yilong Zhao", "Xiao Yan", "Zhiying Xu", "Yang Zhou", "Ion Stoica", "Sewon Min", "Matei Zaharia", "Joseph E. Gonzalez"], "title": "LEANN: A Low-Storage Vector Index", "categories": ["cs.DB", "cs.LG"], "comment": null, "summary": "Embedding-based search is widely used in applications such as recommendation\nand retrieval-augmented generation (RAG). Recently, there is a growing demand\nto support these capabilities over personal data stored locally on devices.\nHowever, maintaining the necessary data structure associated with the\nembedding-based search is often infeasible due to its high storage overhead.\nFor example, indexing 100 GB of raw data requires 150 to 700 GB of storage,\nmaking local deployment impractical. Reducing this overhead while maintaining\nsearch quality and latency becomes a critical challenge. In this paper, we\npresent LEANN, a storage-efficient approximate nearest neighbor (ANN) search\nindex optimized for resource-constrained personal devices. LEANN combines a\ncompact graph-based structure with an efficient on-the-fly recomputation\nstrategy to enable fast and accurate retrieval with minimal storage overhead.\nOur evaluation shows that LEANN reduces index size to under 5% of the original\nraw data, achieving up to 50 times smaller storage than standard indexes, while\nmaintaining 90% top-3 recall in under 2 seconds on real-world question\nanswering benchmarks.", "AI": {"tldr": "LEANN\u662f\u4e00\u79cd\u9488\u5bf9\u8d44\u6e90\u53d7\u9650\u4e2a\u4eba\u8bbe\u5907\u7684\u5b58\u50a8\u9ad8\u6548\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\u7d22\u5f15\uff0c\u901a\u8fc7\u7d27\u51d1\u7684\u56fe\u7ed3\u6784\u548c\u52a8\u6001\u91cd\u8ba1\u7b97\u7b56\u7565\uff0c\u663e\u8457\u51cf\u5c11\u5b58\u50a8\u5f00\u9500\uff0c\u540c\u65f6\u4fdd\u6301\u641c\u7d22\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u57fa\u4e8e\u5d4c\u5165\u7684\u641c\u7d22\u5728\u672c\u5730\u8bbe\u5907\u4e0a\u7684\u9700\u6c42\u589e\u957f\uff0c\u9ad8\u5b58\u50a8\u5f00\u9500\u6210\u4e3a\u4e3b\u8981\u969c\u788d\uff0c\u9700\u8981\u4e00\u79cd\u89e3\u51b3\u65b9\u6848\u6765\u51cf\u5c11\u5b58\u50a8\u9700\u6c42\u800c\u4e0d\u5f71\u54cd\u641c\u7d22\u8d28\u91cf\u3002", "method": "LEANN\u7ed3\u5408\u7d27\u51d1\u7684\u56fe\u7ed3\u6784\u548c\u52a8\u6001\u91cd\u8ba1\u7b97\u7b56\u7565\uff0c\u4f18\u5316\u5b58\u50a8\u548c\u68c0\u7d22\u6548\u7387\u3002", "result": "LEANN\u5c06\u7d22\u5f15\u5927\u5c0f\u964d\u81f3\u539f\u59cb\u6570\u636e\u76845%\u4ee5\u4e0b\uff0c\u5b58\u50a8\u9700\u6c42\u6bd4\u6807\u51c6\u7d22\u5f15\u5c0f50\u500d\uff0c\u540c\u65f6\u5728\u771f\u5b9e\u95ee\u7b54\u57fa\u51c6\u4e0a\u4fdd\u630190%\u7684top-3\u53ec\u56de\u7387\u548c2\u79d2\u5185\u7684\u5ef6\u8fdf\u3002", "conclusion": "LEANN\u4e3a\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5b58\u50a8\u9700\u6c42\u5e76\u4fdd\u6301\u4e86\u641c\u7d22\u6027\u80fd\u3002"}}
{"id": "2506.08277", "pdf": "https://arxiv.org/pdf/2506.08277", "abs": "https://arxiv.org/abs/2506.08277", "authors": ["Subba Reddy Oota", "Khushbu Pahwa", "Prachi Jindal", "Satya Sai Srinath Namburi", "Maneesh Singh", "Tanmoy Chakraborty", "Bapi S. Raju", "Manish Gupta"], "title": "Instruction-Tuned Video-Audio Models Elucidate Functional Specialization in the Brain", "categories": ["q-bio.NC", "cs.AI", "cs.CL", "cs.CV", "cs.LG"], "comment": "39 pages, 22 figures", "summary": "Recent voxel-wise multimodal brain encoding studies have shown that\nmultimodal large language models (MLLMs) exhibit a higher degree of brain\nalignment compared to unimodal models in both unimodal and multimodal stimulus\nsettings. More recently, instruction-tuned multimodal models have shown to\ngenerate task-specific representations that align strongly with brain activity.\nHowever, prior work evaluating the brain alignment of MLLMs has primarily\nfocused on unimodal settings or relied on non-instruction-tuned multimodal\nmodels for multimodal stimuli. To address this gap, we investigated brain\nalignment, that is, measuring the degree of predictivity of neural activity\nrecorded while participants were watching naturalistic movies (video along with\naudio) with representations derived from MLLMs. We utilized\ninstruction-specific embeddings from six video and two audio instruction-tuned\nMLLMs. Experiments with 13 video task-specific instructions show that\ninstruction-tuned video MLLMs significantly outperform non-instruction-tuned\nmultimodal (by 15%) and unimodal models (by 20%). Our evaluation of MLLMs for\nboth video and audio tasks using language-guided instructions shows clear\ndisentanglement in task-specific representations from MLLMs, leading to precise\ndifferentiation of multimodal functional processing in the brain. We also find\nthat MLLM layers align hierarchically with the brain, with early sensory areas\nshowing strong alignment with early layers, while higher-level visual and\nlanguage regions align more with middle to late layers. These findings provide\nclear evidence for the role of task-specific instructions in improving the\nalignment between brain activity and MLLMs, and open new avenues for mapping\njoint information processing in both the systems. We make the code publicly\navailable [https://github.com/subbareddy248/mllm_videos].", "AI": {"tldr": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5728\u4efb\u52a1\u7279\u5b9a\u6307\u4ee4\u4e0b\u6bd4\u975e\u6307\u4ee4\u8c03\u4f18\u6a21\u578b\u66f4\u663e\u8457\u5730\u9884\u6d4b\u5927\u8111\u6d3b\u52a8\uff0c\u5c24\u5176\u5728\u89c6\u542c\u591a\u6a21\u6001\u523a\u6fc0\u4e2d\u3002", "motivation": "\u586b\u8865\u73b0\u6709\u7814\u7a76\u5728\u8bc4\u4f30MLLMs\u5927\u8111\u5bf9\u9f50\u6027\u65f6\u672a\u5145\u5206\u63a2\u7d22\u6307\u4ee4\u8c03\u4f18\u591a\u6a21\u6001\u6a21\u578b\u7684\u7a7a\u767d\u3002", "method": "\u5229\u752813\u79cd\u89c6\u9891\u4efb\u52a1\u7279\u5b9a\u6307\u4ee4\u7684MLLMs\u5d4c\u5165\uff0c\u6d4b\u91cf\u81ea\u7136\u7535\u5f71\u89c2\u770b\u65f6\u7684\u795e\u7ecf\u6d3b\u52a8\u9884\u6d4b\u6027\u3002", "result": "\u6307\u4ee4\u8c03\u4f18\u89c6\u9891MLLMs\u663e\u8457\u4f18\u4e8e\u975e\u6307\u4ee4\u8c03\u4f18\u591a\u6a21\u6001\uff0815%\uff09\u548c\u5355\u6a21\u6001\u6a21\u578b\uff0820%\uff09\uff0c\u4e14MLLMs\u5c42\u6b21\u4e0e\u5927\u8111\u533a\u57df\u5bf9\u9f50\u3002", "conclusion": "\u4efb\u52a1\u7279\u5b9a\u6307\u4ee4\u663e\u8457\u63d0\u5347MLLMs\u4e0e\u5927\u8111\u6d3b\u52a8\u7684\u5bf9\u9f50\u6027\uff0c\u4e3a\u7814\u7a76\u591a\u6a21\u6001\u4fe1\u606f\u5904\u7406\u63d0\u4f9b\u65b0\u9014\u5f84\u3002"}}
{"id": "2506.08279", "pdf": "https://arxiv.org/pdf/2506.08279", "abs": "https://arxiv.org/abs/2506.08279", "authors": ["Aditi Sundararaman", "Amogh Adishesha", "Andrew Jaegle", "Dan Bigioi", "Hyoung-Kyu Song", "Jon Kyl", "Justin Mao", "Kevin Lan", "Mojtaba Komeili", "ShahRukh Athar", "Sheila Babayan", "Stanislau Beliasau", "William Buchwalter"], "title": "Seeing Voices: Generating A-Roll Video from Audio with Mirage", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Technical report website: mirage.app/research/seeing-voices, product\n  website: mirage.app", "summary": "From professional filmmaking to user-generated content, creators and\nconsumers have long recognized that the power of video depends on the\nharmonious integration of what we hear (the video's audio track) with what we\nsee (the video's image sequence). Current approaches to video generation either\nignore sound to focus on general-purpose but silent image sequence generation\nor address both visual and audio elements but focus on restricted application\ndomains such as re-dubbing. We introduce Mirage, an audio-to-video foundation\nmodel that excels at generating realistic, expressive output imagery from\nscratch given an audio input. When integrated with existing methods for speech\nsynthesis (text-to-speech, or TTS), Mirage results in compelling multimodal\nvideo. When trained on audio-video footage of people talking (A-roll) and\nconditioned on audio containing speech, Mirage generates video of people\ndelivering a believable interpretation of the performance implicit in input\naudio. Our central technical contribution is a unified method for training\nself-attention-based audio-to-video generation models, either from scratch or\ngiven existing weights. This methodology allows Mirage to retain generality as\nan approach to audio-to-video generation while producing outputs of superior\nsubjective quality to methods that incorporate audio-specific architectures or\nloss components specific to people, speech, or details of how images or audio\nare captured. We encourage readers to watch and listen to the results of Mirage\nfor themselves (see paper and comments for links).", "AI": {"tldr": "Mirage\u662f\u4e00\u4e2a\u97f3\u9891\u5230\u89c6\u9891\u7684\u57fa\u7840\u6a21\u578b\uff0c\u80fd\u591f\u6839\u636e\u97f3\u9891\u8f93\u5165\u751f\u6210\u903c\u771f\u3001\u5bcc\u6709\u8868\u73b0\u529b\u7684\u89c6\u9891\u3002\u5b83\u7ed3\u5408\u4e86\u8bed\u97f3\u5408\u6210\u6280\u672f\uff0c\u5b9e\u73b0\u4e86\u591a\u6a21\u6001\u89c6\u9891\u751f\u6210\u3002", "motivation": "\u89c6\u9891\u521b\u4f5c\u4e2d\u97f3\u9891\u4e0e\u89c6\u89c9\u7684\u548c\u8c10\u6574\u5408\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u5ffd\u7565\u97f3\u9891\uff0c\u8981\u4e48\u5c40\u9650\u4e8e\u7279\u5b9a\u9886\u57df\uff08\u5982\u91cd\u65b0\u914d\u97f3\uff09\u3002Mirage\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u63d0\u4f9b\u901a\u7528\u7684\u97f3\u9891\u5230\u89c6\u9891\u751f\u6210\u65b9\u6848\u3002", "method": "Mirage\u91c7\u7528\u57fa\u4e8e\u81ea\u6ce8\u610f\u529b\u7684\u7edf\u4e00\u8bad\u7ec3\u65b9\u6cd5\uff0c\u652f\u6301\u4ece\u96f6\u5f00\u59cb\u8bad\u7ec3\u6216\u57fa\u4e8e\u73b0\u6709\u6743\u91cd\u5fae\u8c03\u3002\u8be5\u65b9\u6cd5\u907f\u514d\u4e86\u9488\u5bf9\u7279\u5b9a\u9886\u57df\uff08\u5982\u8bed\u97f3\u6216\u56fe\u50cf\u6355\u83b7\u7ec6\u8282\uff09\u7684\u67b6\u6784\u6216\u635f\u5931\u51fd\u6570\u3002", "result": "Mirage\u751f\u6210\u7684\u89c6\u9891\u5728\u4e3b\u89c2\u8d28\u91cf\u4e0a\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u80fd\u591f\u6839\u636e\u97f3\u9891\u8f93\u5165\u751f\u6210\u903c\u771f\u7684\u8868\u6f14\u89c6\u9891\u3002", "conclusion": "Mirage\u4e3a\u97f3\u9891\u5230\u89c6\u9891\u751f\u6210\u63d0\u4f9b\u4e86\u901a\u7528\u4e14\u9ad8\u8d28\u91cf\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5c55\u793a\u4e86\u81ea\u6ce8\u610f\u529b\u6a21\u578b\u5728\u591a\u6a21\u6001\u751f\u6210\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.08325", "pdf": "https://arxiv.org/pdf/2506.08325", "abs": "https://arxiv.org/abs/2506.08325", "authors": ["Marcos Matabuena", "Rahul Ghosal", "Pavlo Mozharovskyi", "Oscar Hernan Madrid Padilla", "Jukka-Pekka Onnela"], "title": "Model-Free Kernel Conformal Depth Measures Algorithm for Uncertainty Quantification in Regression Models in Separable Hilbert Spaces", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": "arXiv admin note: substantial text overlap with arXiv:2405.13970", "summary": "Depth measures are powerful tools for defining level sets in emerging,\nnon--standard, and complex random objects such as high-dimensional multivariate\ndata, functional data, and random graphs. Despite their favorable theoretical\nproperties, the integration of depth measures into regression modeling to\nprovide prediction regions remains a largely underexplored area of research. To\naddress this gap, we propose a novel, model-free uncertainty quantification\nalgorithm based on conditional depth measures--specifically, conditional kernel\nmean embeddings and an integrated depth measure. These new algorithms can be\nused to define prediction and tolerance regions when predictors and responses\nare defined in separable Hilbert spaces. The use of kernel mean embeddings\nensures faster convergence rates in prediction region estimation. To enhance\nthe practical utility of the algorithms with finite samples, we also introduce\na conformal prediction variant that provides marginal, non-asymptotic\nguarantees for the derived prediction regions. Additionally, we establish both\nconditional and unconditional consistency results, as well as fast convergence\nrates in certain homoscedastic settings. We evaluate the finite--sample\nperformance of our model in extensive simulation studies involving various\ntypes of functional data and traditional Euclidean scenarios. Finally, we\ndemonstrate the practical relevance of our approach through a digital health\napplication related to physical activity, aiming to provide personalized\nrecommendations", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6761\u4ef6\u6df1\u5ea6\u5ea6\u91cf\u7684\u65b0\u578b\u65e0\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7b97\u6cd5\uff0c\u7528\u4e8e\u5b9a\u4e49\u9884\u6d4b\u533a\u57df\uff0c\u9002\u7528\u4e8e\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u4e2d\u7684\u9884\u6d4b\u53d8\u91cf\u548c\u54cd\u5e94\u53d8\u91cf\u3002", "motivation": "\u6df1\u5ea6\u5ea6\u91cf\u5728\u590d\u6742\u968f\u673a\u5bf9\u8c61\u4e2d\u5b9a\u4e49\u6c34\u5e73\u96c6\u5177\u6709\u4f18\u52bf\uff0c\u4f46\u5c06\u5176\u6574\u5408\u5230\u56de\u5f52\u5efa\u6a21\u4e2d\u4ee5\u63d0\u4f9b\u9884\u6d4b\u533a\u57df\u7684\u7814\u7a76\u8f83\u5c11\u3002", "method": "\u7ed3\u5408\u6761\u4ef6\u6838\u5747\u503c\u5d4c\u5165\u548c\u96c6\u6210\u6df1\u5ea6\u5ea6\u91cf\uff0c\u63d0\u51fa\u7b97\u6cd5\uff0c\u5e76\u5f15\u5165\u4fdd\u5f62\u9884\u6d4b\u53d8\u4f53\u4ee5\u589e\u5f3a\u5b9e\u7528\u6027\u3002", "result": "\u7b97\u6cd5\u5728\u6a21\u62df\u7814\u7a76\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u529f\u80fd\u6570\u636e\u548c\u4f20\u7edf\u6b27\u51e0\u91cc\u5f97\u573a\u666f\uff0c\u5e76\u5728\u6570\u5b57\u5065\u5eb7\u5e94\u7528\u4e2d\u9a8c\u8bc1\u4e86\u5b9e\u7528\u6027\u3002", "conclusion": "\u65b0\u7b97\u6cd5\u4e3a\u590d\u6742\u6570\u636e\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u9884\u6d4b\u533a\u57df\u5b9a\u4e49\u65b9\u6cd5\uff0c\u5177\u6709\u7406\u8bba\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2506.08336", "pdf": "https://arxiv.org/pdf/2506.08336", "abs": "https://arxiv.org/abs/2506.08336", "authors": ["Li Changjiang", "Liang Jiacheng", "Cao Bochuan", "Chen Jinghui", "Wang Ting"], "title": "Your Agent Can Defend Itself against Backdoor Attacks", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "Despite their growing adoption across domains, large language model\n(LLM)-powered agents face significant security risks from backdoor attacks\nduring training and fine-tuning. These compromised agents can subsequently be\nmanipulated to execute malicious operations when presented with specific\ntriggers in their inputs or environments. To address this pressing risk, we\npresent ReAgent, a novel defense against a range of backdoor attacks on\nLLM-based agents. Intuitively, backdoor attacks often result in inconsistencies\namong the user's instruction, the agent's planning, and its execution. Drawing\non this insight, ReAgent employs a two-level approach to detect potential\nbackdoors. At the execution level, ReAgent verifies consistency between the\nagent's thoughts and actions; at the planning level, ReAgent leverages the\nagent's capability to reconstruct the instruction based on its thought\ntrajectory, checking for consistency between the reconstructed instruction and\nthe user's instruction. Extensive evaluation demonstrates ReAgent's\neffectiveness against various backdoor attacks across tasks. For instance,\nReAgent reduces the attack success rate by up to 90\\% in database operation\ntasks, outperforming existing defenses by large margins. This work reveals the\npotential of utilizing compromised agents themselves to mitigate backdoor\nrisks.", "AI": {"tldr": "ReAgent\u662f\u4e00\u79cd\u9488\u5bf9LLM\u4ee3\u7406\u540e\u95e8\u653b\u51fb\u7684\u65b0\u578b\u9632\u5fa1\u65b9\u6cd5\uff0c\u901a\u8fc7\u68c0\u6d4b\u7528\u6237\u6307\u4ee4\u3001\u4ee3\u7406\u8ba1\u5212\u548c\u6267\u884c\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\u6765\u8bc6\u522b\u540e\u95e8\uff0c\u663e\u8457\u964d\u4f4e\u653b\u51fb\u6210\u529f\u7387\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee3\u7406\u5728\u8bad\u7ec3\u548c\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u9762\u4e34\u540e\u95e8\u653b\u51fb\u7684\u5b89\u5168\u98ce\u9669\uff0c\u53ef\u80fd\u5bfc\u81f4\u6076\u610f\u64cd\u4f5c\u3002", "method": "ReAgent\u91c7\u7528\u4e24\u7ea7\u65b9\u6cd5\uff1a\u6267\u884c\u5c42\u9a8c\u8bc1\u4ee3\u7406\u601d\u7ef4\u4e0e\u884c\u52a8\u7684\u4e00\u81f4\u6027\uff1b\u8ba1\u5212\u5c42\u901a\u8fc7\u4ee3\u7406\u91cd\u5efa\u6307\u4ee4\u7684\u80fd\u529b\u68c0\u67e5\u4e00\u81f4\u6027\u3002", "result": "ReAgent\u5728\u591a\u79cd\u4efb\u52a1\u4e2d\u6709\u6548\u9632\u5fa1\u540e\u95e8\u653b\u51fb\uff0c\u4f8b\u5982\u5728\u6570\u636e\u5e93\u64cd\u4f5c\u4efb\u52a1\u4e2d\u5c06\u653b\u51fb\u6210\u529f\u7387\u964d\u4f4e\u9ad8\u8fbe90%\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5229\u7528\u88ab\u653b\u51fb\u4ee3\u7406\u81ea\u8eab\u80fd\u529b\u53ef\u4ee5\u7f13\u89e3\u540e\u95e8\u98ce\u9669\uff0cReAgent\u4e3aLLM\u4ee3\u7406\u5b89\u5168\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.08338", "pdf": "https://arxiv.org/pdf/2506.08338", "abs": "https://arxiv.org/abs/2506.08338", "authors": ["Ryoichi Asashiba", "Reiji Kozuma", "Hirokazu Iwasawa"], "title": "midr: Learning from Black-Box Models by Maximum Interpretation Decomposition", "categories": ["stat.ME", "cs.LG"], "comment": "20 pages, 10 figures", "summary": "The use of appropriate methods of Interpretable Machine Learning (IML) and\neXplainable Artificial Intelligence (XAI) is essential for adopting black-box\npredictive models in fields where model and prediction explainability is\nrequired. As a novel tool for interpreting black-box models, we introduce the R\npackage midr, which implements Maximum Interpretation Decomposition (MID). MID\nis a functional decomposition approach that derives a low-order additive\nrepresentation of a black-box model by minimizing the squared error between the\nmodel's prediction function and this additive representation. midr enables\nlearning from black-box models by constructing a global surrogate model with\nadvanced analytical capabilities. After reviewing related work and the\ntheoretical foundation of MID, we demonstrate the package's usage and discuss\nsome of its key features.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86R\u5305midr\uff0c\u7528\u4e8e\u5b9e\u73b0\u6700\u5927\u89e3\u91ca\u5206\u89e3\uff08MID\uff09\uff0c\u4ee5\u89e3\u91ca\u9ed1\u76d2\u6a21\u578b\u3002", "motivation": "\u5728\u9700\u8981\u6a21\u578b\u548c\u9884\u6d4b\u53ef\u89e3\u91ca\u6027\u7684\u9886\u57df\uff0c\u91c7\u7528\u9002\u5f53\u7684\u53ef\u89e3\u91ca\u673a\u5668\u5b66\u4e60\uff08IML\uff09\u548c\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\uff08XAI\uff09\u65b9\u6cd5\u81f3\u5173\u91cd\u8981\u3002", "method": "MID\u662f\u4e00\u79cd\u529f\u80fd\u5206\u89e3\u65b9\u6cd5\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u9ed1\u76d2\u6a21\u578b\u9884\u6d4b\u51fd\u6570\u4e0e\u4f4e\u9636\u52a0\u6027\u8868\u793a\u4e4b\u95f4\u7684\u5e73\u65b9\u8bef\u5dee\uff0c\u6784\u5efa\u5168\u5c40\u66ff\u4ee3\u6a21\u578b\u3002", "result": "midr\u5305\u80fd\u591f\u901a\u8fc7\u6784\u5efa\u5177\u6709\u9ad8\u7ea7\u5206\u6790\u80fd\u529b\u7684\u5168\u5c40\u66ff\u4ee3\u6a21\u578b\uff0c\u4ece\u9ed1\u76d2\u6a21\u578b\u4e2d\u5b66\u4e60\u3002", "conclusion": "\u8bba\u6587\u5c55\u793a\u4e86midr\u5305\u7684\u7528\u6cd5\uff0c\u5e76\u8ba8\u8bba\u4e86\u5176\u5173\u952e\u7279\u6027\u3002"}}
{"id": "2506.08344", "pdf": "https://arxiv.org/pdf/2506.08344", "abs": "https://arxiv.org/abs/2506.08344", "authors": ["Ne\u015fet \u00dcnver Akmandor", "Sarvesh Prajapati", "Mark Zolotas", "Ta\u015fk\u0131n Pad\u0131r"], "title": "Re4MPC: Reactive Nonlinear MPC for Multi-model Motion Planning via Deep Reinforcement Learning", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.SY", "eess.SY"], "comment": "Accepted to the 2025 IEEE International Conference on Automation\n  Science and Engineering (CASE)", "summary": "Traditional motion planning methods for robots with many degrees-of-freedom,\nsuch as mobile manipulators, are often computationally prohibitive for\nreal-world settings. In this paper, we propose a novel multi-model motion\nplanning pipeline, termed Re4MPC, which computes trajectories using Nonlinear\nModel Predictive Control (NMPC). Re4MPC generates trajectories in a\ncomputationally efficient manner by reactively selecting the model, cost, and\nconstraints of the NMPC problem depending on the complexity of the task and\nrobot state. The policy for this reactive decision-making is learned via a Deep\nReinforcement Learning (DRL) framework. We introduce a mathematical formulation\nto integrate NMPC into this DRL framework. To validate our methodology and\ndesign choices, we evaluate DRL training and test outcomes in a physics-based\nsimulation involving a mobile manipulator. Experimental results demonstrate\nthat Re4MPC is more computationally efficient and achieves higher success rates\nin reaching end-effector goals than the NMPC baseline, which computes\nwhole-body trajectories without our learning mechanism.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRe4MPC\u7684\u65b0\u578b\u591a\u6a21\u578b\u8fd0\u52a8\u89c4\u5212\u7ba1\u9053\uff0c\u7ed3\u5408\u975e\u7ebf\u6027\u6a21\u578b\u9884\u6d4b\u63a7\u5236\uff08NMPC\uff09\u548c\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\u548c\u4efb\u52a1\u6210\u529f\u7387\u3002", "motivation": "\u4f20\u7edf\u7684\u9ad8\u81ea\u7531\u5ea6\u673a\u5668\u4eba\u8fd0\u52a8\u89c4\u5212\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u96be\u4ee5\u5e94\u7528\u4e8e\u5b9e\u9645\u573a\u666f\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7NMPC\u751f\u6210\u8f68\u8ff9\uff0c\u5e76\u5229\u7528DRL\u6846\u67b6\u5b66\u4e60\u53cd\u5e94\u6027\u51b3\u7b56\u7b56\u7565\uff0c\u52a8\u6001\u9009\u62e9\u6a21\u578b\u3001\u6210\u672c\u548c\u7ea6\u675f\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cRe4MPC\u6bd4\u4f20\u7edfNMPC\u57fa\u7ebf\u65b9\u6cd5\u8ba1\u7b97\u6548\u7387\u66f4\u9ad8\uff0c\u4e14\u672b\u7aef\u6267\u884c\u5668\u76ee\u6807\u8fbe\u6210\u7387\u66f4\u9ad8\u3002", "conclusion": "Re4MPC\u4e3a\u9ad8\u81ea\u7531\u5ea6\u673a\u5668\u4eba\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u8fd0\u52a8\u89c4\u5212\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.08362", "pdf": "https://arxiv.org/pdf/2506.08362", "abs": "https://arxiv.org/abs/2506.08362", "authors": ["Lesi Chen", "Chengchang Liu", "Luo Luo", "Jingzhao Zhang"], "title": "Solving Convex-Concave Problems with $\\tilde{\\mathcal{O}}(\u03b5^{-4/7})$ Second-Order Oracle Complexity", "categories": ["math.OC", "cs.LG"], "comment": "COLT 2025", "summary": "Previous algorithms can solve convex-concave minimax problems $\\min_{x \\in\n\\mathcal{X}} \\max_{y \\in \\mathcal{Y}} f(x,y)$ with\n$\\mathcal{O}(\\epsilon^{-2/3})$ second-order oracle calls using Newton-type\nmethods. This result has been speculated to be optimal because the upper bound\nis achieved by a natural generalization of the optimal first-order method. In\nthis work, we show an improved upper bound of\n$\\tilde{\\mathcal{O}}(\\epsilon^{-4/7})$ by generalizing the optimal second-order\nmethod for convex optimization to solve the convex-concave minimax problem. We\nfurther apply a similar technique to lazy Hessian algorithms and show that our\nproposed algorithm can also be seen as a second-order ``Catalyst'' framework\n(Lin et al., JMLR 2018) that could accelerate any globally convergent\nalgorithms for solving minimax problems.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.08381", "pdf": "https://arxiv.org/pdf/2506.08381", "abs": "https://arxiv.org/abs/2506.08381", "authors": ["He Yang", "Fei Ren", "Hai-Sui Yu", "Xueyu Geng", "Pei-Zhi Zhuang"], "title": "TS-PIELM: Time-Stepping Physics-Informed Extreme Learning Machine Facilitates Soil Consolidation Analyses", "categories": ["physics.geo-ph", "cs.LG"], "comment": null, "summary": "Accuracy and efficiency of the conventional physics-informed neural network\n(PINN) need to be improved before it can be a competitive alternative for soil\nconsolidation analyses. This paper aims to overcome these limitations by\nproposing a highly accurate and efficient physics-informed machine learning\n(PIML) approach, termed time-stepping physics-informed extreme learning machine\n(TS-PIELM). In the TS-PIELM framework the consolidation process is divided into\nnumerous time intervals, which helps overcome the limitation of PIELM in\nsolving differential equations with sharp gradients. To accelerate network\ntraining, the solution is approximated by a single-layer feedforward extreme\nlearning machine (ELM), rather than using a fully connected neural network in\nPINN. The input layer weights of the ELM network are generated randomly and\nfixed during the training process. Subsequently, the output layer weights are\ndirectly computed by solving a system of linear equations, which significantly\nenhances the training efficiency compared to the time-consuming gradient\ndescent method in PINN. Finally, the superior performance of TS-PIELM is\ndemonstrated by solving three typical Terzaghi consolidation problems. Compared\nto PINN, results show that the computational efficiency and accuracy of the\nnovel TS-PIELM framework are improved by more than 1000 times and 100 times for\none-dimensional cases, respectively. This paper provides compelling evidence\nthat PIML can be a powerful tool for computational geotechnics.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u7269\u7406\u4fe1\u606f\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff08TS-PIELM\uff09\uff0c\u7528\u4e8e\u6539\u8fdb\u4f20\u7edfPINN\u5728\u571f\u58e4\u56fa\u7ed3\u5206\u6790\u4e2d\u7684\u7cbe\u5ea6\u548c\u6548\u7387\u3002", "motivation": "\u4f20\u7edfPINN\u5728\u571f\u58e4\u56fa\u7ed3\u5206\u6790\u4e2d\u7684\u7cbe\u5ea6\u548c\u6548\u7387\u4e0d\u8db3\uff0c\u9700\u8981\u6539\u8fdb\u4ee5\u6210\u4e3a\u6709\u7ade\u4e89\u529b\u7684\u66ff\u4ee3\u65b9\u6cd5\u3002", "method": "\u63d0\u51faTS-PIELM\u6846\u67b6\uff0c\u5c06\u56fa\u7ed3\u8fc7\u7a0b\u5206\u4e3a\u591a\u4e2a\u65f6\u95f4\u533a\u95f4\uff0c\u4f7f\u7528\u5355\u5c42\u524d\u9988\u6781\u9650\u5b66\u4e60\u673a\uff08ELM\uff09\u8fd1\u4f3c\u89e3\uff0c\u901a\u8fc7\u7ebf\u6027\u65b9\u7a0b\u7ec4\u76f4\u63a5\u8ba1\u7b97\u8f93\u51fa\u5c42\u6743\u91cd\u3002", "result": "TS-PIELM\u7684\u8ba1\u7b97\u6548\u7387\u548c\u7cbe\u5ea6\u5206\u522b\u63d0\u9ad8\u4e861000\u500d\u548c100\u500d\uff08\u4e00\u7ef4\u60c5\u51b5\uff09\u3002", "conclusion": "TS-PIELM\u8bc1\u660e\u4e86\u7269\u7406\u4fe1\u606f\u673a\u5668\u5b66\u4e60\u5728\u8ba1\u7b97\u5ca9\u571f\u5de5\u7a0b\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.08399", "pdf": "https://arxiv.org/pdf/2506.08399", "abs": "https://arxiv.org/abs/2506.08399", "authors": ["Jiachen Ma", "Zhanhui Zhou", "Chao Yang", "Chaochao Lu"], "title": "SafeCoT: Improving VLM Safety with Minimal Reasoning", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Ensuring safe and appropriate responses from vision-language models (VLMs)\nremains a critical challenge, particularly in high-risk or ambiguous scenarios.\nWe introduce SafeCoT, a lightweight, interpretable framework that leverages\nrule-based chain-of-thought (CoT) supervision to improve refusal behavior in\nVLMs. Unlike prior methods that rely on large-scale safety annotations or\ncomplex modeling, SafeCoT uses minimal supervision to help models reason about\nsafety risks and make context-aware refusals. Experiments across multiple\nbenchmarks show that SafeCoT significantly reduces overrefusal and enhances\ngeneralization, even with limited training data. Our approach offers a scalable\nsolution for aligning VLMs with safety-critical objectives.", "AI": {"tldr": "SafeCoT\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u3001\u53ef\u89e3\u91ca\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u89c4\u5219\u9a71\u52a8\u7684\u94fe\u5f0f\u601d\u8003\u76d1\u7763\u6539\u8fdb\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u62d2\u7edd\u884c\u4e3a\u3002", "motivation": "\u89e3\u51b3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u9ad8\u98ce\u9669\u6216\u6a21\u7cca\u573a\u666f\u4e2d\u5b89\u5168\u54cd\u5e94\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u5229\u7528\u89c4\u5219\u9a71\u52a8\u7684\u94fe\u5f0f\u601d\u8003\u76d1\u7763\uff0c\u6700\u5c0f\u5316\u76d1\u7763\u9700\u6c42\uff0c\u5e2e\u52a9\u6a21\u578b\u63a8\u7406\u5b89\u5168\u98ce\u9669\u5e76\u505a\u51fa\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u62d2\u7edd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSafeCoT\u663e\u8457\u51cf\u5c11\u4e86\u8fc7\u5ea6\u62d2\u7edd\u5e76\u63d0\u5347\u4e86\u6cdb\u5316\u80fd\u529b\uff0c\u5373\u4f7f\u5728\u6709\u9650\u8bad\u7ec3\u6570\u636e\u4e0b\u3002", "conclusion": "SafeCoT\u4e3a\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u5bf9\u9f50\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.08400", "pdf": "https://arxiv.org/pdf/2506.08400", "abs": "https://arxiv.org/abs/2506.08400", "authors": ["Luel Hagos Beyene", "Vivek Verma", "Min Ma", "Jesujoba O. Alabi", "Fabian David Schmidt", "Joyce Nakatumba-Nabende", "David Ifeoluwa Adelani"], "title": "mSTEB: Massively Multilingual Evaluation of LLMs on Speech and Text Tasks", "categories": ["cs.CL", "cs.LG", "cs.SD"], "comment": "working paper", "summary": "Large Language models (LLMs) have demonstrated impressive performance on a\nwide range of tasks, including in multimodal settings such as speech. However,\ntheir evaluation is often limited to English and a few high-resource languages.\nFor low-resource languages, there is no standardized evaluation benchmark. In\nthis paper, we address this gap by introducing mSTEB, a new benchmark to\nevaluate the performance of LLMs on a wide range of tasks covering language\nidentification, text classification, question answering, and translation tasks\non both speech and text modalities. We evaluated the performance of leading\nLLMs such as Gemini 2.0 Flash and GPT-4o (Audio) and state-of-the-art open\nmodels such as Qwen 2 Audio and Gemma 3 27B. Our evaluation shows a wide gap in\nperformance between high-resource and low-resource languages, especially for\nlanguages spoken in Africa and Americas/Oceania. Our findings show that more\ninvestment is needed to address their under-representation in LLMs coverage.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86mSTEB\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u591a\u8bed\u8a00\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u91cd\u70b9\u5173\u6ce8\u4f4e\u8d44\u6e90\u8bed\u8a00\u3002", "motivation": "\u5f53\u524dLLMs\u7684\u8bc4\u4f30\u4e3b\u8981\u96c6\u4e2d\u4e8e\u82f1\u8bed\u548c\u9ad8\u8d44\u6e90\u8bed\u8a00\uff0c\u7f3a\u4e4f\u5bf9\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u6807\u51c6\u5316\u8bc4\u4f30\u3002", "method": "\u5f15\u5165mSTEB\u57fa\u51c6\uff0c\u6db5\u76d6\u8bed\u8a00\u8bc6\u522b\u3001\u6587\u672c\u5206\u7c7b\u3001\u95ee\u7b54\u548c\u7ffb\u8bd1\u4efb\u52a1\uff0c\u8bc4\u4f30\u4e86\u5305\u62ecGemini 2.0 Flash\u3001GPT-4o (Audio)\u7b49\u6a21\u578b\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u9ad8\u8d44\u6e90\u4e0e\u4f4e\u8d44\u6e90\u8bed\u8a00\uff08\u5c24\u5176\u662f\u975e\u6d32\u548c\u7f8e\u6d32/\u5927\u6d0b\u6d32\u8bed\u8a00\uff09\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u6027\u80fd\u5dee\u8ddd\u3002", "conclusion": "\u9700\u8981\u66f4\u591a\u6295\u8d44\u4ee5\u89e3\u51b3\u4f4e\u8d44\u6e90\u8bed\u8a00\u5728LLMs\u4e2d\u7684\u4ee3\u8868\u6027\u4e0d\u8db3\u95ee\u9898\u3002"}}
{"id": "2506.08423", "pdf": "https://arxiv.org/pdf/2506.08423", "abs": "https://arxiv.org/abs/2506.08423", "authors": ["Utkarsh Pratiush", "Austin Houston", "Kamyar Barakati", "Aditya Raghavan", "Dasol Yoon", "Harikrishnan KP", "Zhaslan Baraissov", "Desheng Ma", "Samuel S. Welborn", "Mikolaj Jakowski", "Shawn-Patrick Barhorst", "Alexander J. Pattison", "Panayotis Manganaris", "Sita Sirisha Madugula", "Sai Venkata Gayathri Ayyagari", "Vishal Kennedy", "Ralph Bulanadi", "Michelle Wang", "Kieran J. Pang", "Ian Addison-Smith", "Willy Menacho", "Horacio V. Guzman", "Alexander Kiefer", "Nicholas Furth", "Nikola L. Kolev", "Mikhail Petrov", "Viktoriia Liu", "Sergey Ilyev", "Srikar Rairao", "Tommaso Rodani", "Ivan Pinto-Huguet", "Xuli Chen", "Josep Crua\u00f1es", "Marta Torrens", "Jovan Pomar", "Fanzhi Su", "Pawan Vedanti", "Zhiheng Lyu", "Xingzhi Wang", "Lehan Yao", "Amir Taqieddin", "Forrest Laskowski", "Xiangyu Yin", "Yu-Tsun Shao", "Benjamin Fein-Ashley", "Yi Jiang", "Vineet Kumar", "Himanshu Mishra", "Yogesh Paul", "Adib Bazgir", "Rama chandra Praneeth Madugula", "Yuwen Zhang", "Pravan Omprakash", "Jian Huang", "Eric Montufar-Morales", "Vivek Chawla", "Harshit Sethi", "Jie Huang", "Lauri Kurki", "Grace Guinan", "Addison Salvador", "Arman Ter-Petrosyan", "Madeline Van Winkle", "Steven R. Spurgeon", "Ganesh Narasimha", "Zijie Wu", "Richard Liu", "Yongtao Liu", "Boris Slautin", "Andrew R Lupini", "Rama Vasudevan", "Gerd Duscher", "Sergei V. Kalinin"], "title": "Mic-hackathon 2024: Hackathon on Machine Learning for Electron and Scanning Probe Microscopy", "categories": ["cond-mat.mtrl-sci", "cs.LG", "physics.ins-det"], "comment": null, "summary": "Microscopy is a primary source of information on materials structure and\nfunctionality at nanometer and atomic scales. The data generated is often\nwell-structured, enriched with metadata and sample histories, though not always\nconsistent in detail or format. The adoption of Data Management Plans (DMPs) by\nmajor funding agencies promotes preservation and access. However, deriving\ninsights remains difficult due to the lack of standardized code ecosystems,\nbenchmarks, and integration strategies. As a result, data usage is inefficient\nand analysis time is extensive. In addition to post-acquisition analysis, new\nAPIs from major microscope manufacturers enable real-time, ML-based analytics\nfor automated decision-making and ML-agent-controlled microscope operation.\nYet, a gap remains between the ML and microscopy communities, limiting the\nimpact of these methods on physics, materials discovery, and optimization.\nHackathons help bridge this divide by fostering collaboration between ML\nresearchers and microscopy experts. They encourage the development of novel\nsolutions that apply ML to microscopy, while preparing a future workforce for\ninstrumentation, materials science, and applied ML. This hackathon produced\nbenchmark datasets and digital twins of microscopes to support community growth\nand standardized workflows. All related code is available at GitHub:\nhttps://github.com/KalininGroup/Mic-hackathon-2024-codes-publication/tree/1.0.0.1", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u663e\u5fae\u955c\u6570\u636e\u7ba1\u7406\u7684\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u901a\u8fc7\u9ed1\u5ba2\u9a6c\u62c9\u677e\u4fc3\u8fdbML\u4e0e\u663e\u5fae\u955c\u793e\u533a\u5408\u4f5c\u7684\u65b9\u6cd5\uff0c\u5e76\u5f00\u53d1\u4e86\u6807\u51c6\u5316\u5de5\u5177\u548c\u6570\u636e\u96c6\u3002", "motivation": "\u663e\u5fae\u955c\u6570\u636e\u867d\u4e30\u5bcc\u4f46\u683c\u5f0f\u4e0d\u4e00\uff0c\u7f3a\u4e4f\u6807\u51c6\u5316\u5de5\u5177\u548c\u96c6\u6210\u7b56\u7565\uff0c\u5bfc\u81f4\u5206\u6790\u6548\u7387\u4f4e\u4e0b\u3002ML\u4e0e\u663e\u5fae\u955c\u793e\u533a\u7684\u5408\u4f5c\u4e0d\u8db3\u4e5f\u9650\u5236\u4e86\u6280\u672f\u8fdb\u6b65\u3002", "method": "\u901a\u8fc7\u9ed1\u5ba2\u9a6c\u62c9\u677e\u4fc3\u8fdbML\u4e0e\u663e\u5fae\u955c\u4e13\u5bb6\u7684\u534f\u4f5c\uff0c\u5f00\u53d1\u6807\u51c6\u5316\u4ee3\u7801\u751f\u6001\u7cfb\u7edf\u548c\u6570\u5b57\u5b6a\u751f\u663e\u5fae\u955c\uff0c\u4ee5\u652f\u6301\u5b9e\u65f6\u5206\u6790\u548c\u81ea\u52a8\u5316\u51b3\u7b56\u3002", "result": "\u751f\u6210\u4e86\u57fa\u51c6\u6570\u636e\u96c6\u548c\u663e\u5fae\u955c\u6570\u5b57\u5b6a\u751f\uff0c\u63a8\u52a8\u4e86\u793e\u533a\u53d1\u5c55\u548c\u6807\u51c6\u5316\u5de5\u4f5c\u6d41\u7a0b\u3002", "conclusion": "\u9ed1\u5ba2\u9a6c\u62c9\u677e\u662f\u5f25\u5408ML\u4e0e\u663e\u5fae\u955c\u793e\u533a\u5dee\u8ddd\u7684\u6709\u6548\u65b9\u5f0f\uff0c\u4e3a\u672a\u6765\u6280\u672f\u53d1\u5c55\u548c\u4eba\u624d\u57f9\u517b\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.08428", "pdf": "https://arxiv.org/pdf/2506.08428", "abs": "https://arxiv.org/abs/2506.08428", "authors": ["Evan Markou", "Thalaiyasingam Ajanthan", "Stephen Gould"], "title": "Sharper Convergence Rates for Nonconvex Optimisation via Reduction Mappings", "categories": ["math.OC", "cs.LG"], "comment": "37 pages, 5 figures", "summary": "Many high-dimensional optimisation problems exhibit rich geometric structures\nin their set of minimisers, often forming smooth manifolds due to\nover-parametrisation or symmetries. When this structure is known, at least\nlocally, it can be exploited through reduction mappings that reparametrise part\nof the parameter space to lie on the solution manifold. These reductions\nnaturally arise from inner optimisation problems and effectively remove\nredundant directions, yielding a lower-dimensional objective. In this work, we\nintroduce a general framework to understand how such reductions influence the\noptimisation landscape. We show that well-designed reduction mappings improve\ncurvature properties of the objective, leading to better-conditioned problems\nand theoretically faster convergence for gradient-based methods. Our analysis\nunifies a range of scenarios where structural information at optimality is\nleveraged to accelerate convergence, offering a principled explanation for the\nempirical gains observed in such optimisation algorithms.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u6846\u67b6\uff0c\u5229\u7528\u5df2\u77e5\u7684\u4f18\u5316\u95ee\u9898\u89e3\u6d41\u5f62\u7ed3\u6784\uff0c\u901a\u8fc7\u964d\u7ef4\u6620\u5c04\u6539\u5584\u76ee\u6807\u51fd\u6570\u7684\u66f2\u7387\u7279\u6027\uff0c\u4ece\u800c\u52a0\u901f\u68af\u5ea6\u65b9\u6cd5\u7684\u6536\u655b\u3002", "motivation": "\u9ad8\u7ef4\u4f18\u5316\u95ee\u9898\u7684\u89e3\u96c6\u5e38\u5177\u6709\u51e0\u4f55\u7ed3\u6784\uff08\u5982\u6d41\u5f62\uff09\uff0c\u82e5\u80fd\u5229\u7528\u8fd9\u4e9b\u7ed3\u6784\uff0c\u53ef\u63d0\u5347\u4f18\u5316\u6548\u7387\u3002", "method": "\u5f15\u5165\u964d\u7ef4\u6620\u5c04\uff0c\u5c06\u53c2\u6570\u7a7a\u95f4\u91cd\u65b0\u53c2\u6570\u5316\u5230\u89e3\u6d41\u5f62\u4e0a\uff0c\u53bb\u9664\u5197\u4f59\u65b9\u5411\uff0c\u964d\u4f4e\u95ee\u9898\u7ef4\u5ea6\u3002", "result": "\u8bc1\u660e\u8bbe\u8ba1\u826f\u597d\u7684\u964d\u7ef4\u6620\u5c04\u80fd\u6539\u5584\u76ee\u6807\u51fd\u6570\u7684\u66f2\u7387\uff0c\u4f7f\u95ee\u9898\u6761\u4ef6\u66f4\u597d\uff0c\u7406\u8bba\u4e0a\u52a0\u901f\u68af\u5ea6\u65b9\u6cd5\u7684\u6536\u655b\u3002", "conclusion": "\u8be5\u6846\u67b6\u7edf\u4e00\u4e86\u5229\u7528\u7ed3\u6784\u4fe1\u606f\u52a0\u901f\u4f18\u5316\u7684\u573a\u666f\uff0c\u4e3a\u5b9e\u8bc1\u89c2\u5bdf\u5230\u7684\u6027\u80fd\u63d0\u5347\u63d0\u4f9b\u4e86\u7406\u8bba\u89e3\u91ca\u3002"}}
{"id": "2506.08433", "pdf": "https://arxiv.org/pdf/2506.08433", "abs": "https://arxiv.org/abs/2506.08433", "authors": ["Hern\u00e1n Maina", "Nicol\u00e1s Wolovick", "Luciana Benotti"], "title": "Low-resource domain adaptation while minimizing energy and hardware resource consumption", "categories": ["cs.CL", "cs.DC", "cs.LG"], "comment": "A shorter version of this work was accepted as a two-page abstract\n  for presentation at the Widening Natural Language Processing (WiNLP) 2023\n  Workshop. That version was not publicly released, and this is the first\n  public version of the work", "summary": "Training Large Language Models (LLMs) is costly in terms of energy, hardware,\nand annotated data, often resulting in a positionality rooted in predominant\ncultures and values (Santy et al., 2023). Domain adaptation has emerged as a\npromising strategy to better align models with diverse cultural and value\ncontexts (Hershcovich et al., 2022), but its computational cost remains a\nsignificant barrier, particularly for research groups lacking access to\nlarge-scale infrastructure. In this paper, we evaluate how the use of different\nnumerical precisions and data parallelization strategies impacts both training\nspeed (as a proxy to energy and hardware consumption) and model accuracy, with\nthe goal of facilitating domain adaptation in low-resource environments. Our\nfindings are relevant to any setting where energy efficiency, accessibility, or\nlimited hardware availability are key concerns.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u901a\u8fc7\u8c03\u6574\u6570\u503c\u7cbe\u5ea6\u548c\u6570\u636e\u5e76\u884c\u5316\u7b56\u7565\u6765\u964d\u4f4e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8bad\u7ec3\u7684\u6210\u672c\uff0c\u4ee5\u4fc3\u8fdb\u4f4e\u8d44\u6e90\u73af\u5883\u4e0b\u7684\u9886\u57df\u9002\u5e94\u3002", "motivation": "\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6210\u672c\u9ad8\u6602\uff0c\u4e14\u5f80\u5f80\u504f\u5411\u4e3b\u6d41\u6587\u5316\u548c\u4ef7\u503c\u89c2\u3002\u9886\u57df\u9002\u5e94\u867d\u80fd\u6539\u5584\u6a21\u578b\u4e0e\u591a\u6837\u5316\u6587\u5316\u80cc\u666f\u7684\u5951\u5408\u5ea6\uff0c\u4f46\u5176\u8ba1\u7b97\u6210\u672c\u4ecd\u662f\u4e00\u4e2a\u969c\u788d\uff0c\u5c24\u5176\u662f\u5728\u8d44\u6e90\u6709\u9650\u7684\u7814\u7a76\u73af\u5883\u4e2d\u3002", "method": "\u901a\u8fc7\u8bc4\u4f30\u4e0d\u540c\u6570\u503c\u7cbe\u5ea6\u548c\u6570\u636e\u5e76\u884c\u5316\u7b56\u7565\u5bf9\u8bad\u7ec3\u901f\u5ea6\u548c\u6a21\u578b\u51c6\u786e\u6027\u7684\u5f71\u54cd\uff0c\u7814\u7a76\u5982\u4f55\u5728\u4f4e\u8d44\u6e90\u73af\u5883\u4e0b\u5b9e\u73b0\u9ad8\u6548\u7684\u9886\u57df\u9002\u5e94\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u4e3a\u5173\u6ce8\u80fd\u6e90\u6548\u7387\u3001\u53ef\u8bbf\u95ee\u6027\u6216\u786c\u4ef6\u6709\u9650\u7684\u573a\u666f\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002", "conclusion": "\u8c03\u6574\u6570\u503c\u7cbe\u5ea6\u548c\u6570\u636e\u5e76\u884c\u5316\u7b56\u7565\u662f\u964d\u4f4eLLM\u8bad\u7ec3\u6210\u672c\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u6709\u52a9\u4e8e\u5728\u8d44\u6e90\u53d7\u9650\u7684\u73af\u5883\u4e2d\u5b9e\u73b0\u9886\u57df\u9002\u5e94\u3002"}}
{"id": "2506.08436", "pdf": "https://arxiv.org/pdf/2506.08436", "abs": "https://arxiv.org/abs/2506.08436", "authors": ["Jiujun He", "Huazhen Lin"], "title": "Olica: Efficient Structured Pruning of Large Language Models without Retraining", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted to ICML 2025", "summary": "Most existing structured pruning methods for Large Language Models (LLMs)\nrequire substantial computational and data resources for retraining to\nreestablish the corrupted correlations, making them prohibitively expensive. To\naddress this, we propose a pruning framework for LLMs called Orthogonal\ndecomposition and Linear Calibration (Olica), which eliminates the need for\nretraining. A key observation is that the multi-head attention (MHA) layer\ndepends on two types of matrix products. By treating these matrix products as\nunified entities and applying principal component analysis (PCA), we extract\nthe most important information to compress LLMs without sacrificing accuracy or\ndisrupting their original structure. Consequently, retraining becomes\nunnecessary. A fast decomposition method is devised, reducing the complexity of\nPCA by a factor of the square of the number of attention heads. Additionally,\nto mitigate error accumulation problem caused by pruning the feed-forward\nnetwork (FFN) layer, we introduce a linear calibration method to reconstruct\nthe residual errors of pruned layers using low-rank matrices. By leveraging\nsingular value decomposition (SVD) on the solution of the least-squares\nproblem, these matrices are obtained without requiring retraining. Extensive\nexperiments show that the proposed Olica is efficient in terms of data usage,\nGPU memory, and running time, while delivering superior performance across\nmultiple benchmarks.", "AI": {"tldr": "Olica\u662f\u4e00\u79cd\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u526a\u679d\u6846\u67b6\uff0c\u901a\u8fc7\u6b63\u4ea4\u5206\u89e3\u548c\u7ebf\u6027\u6821\u51c6\u538b\u7f29\u6a21\u578b\uff0c\u4fdd\u6301\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u526a\u679d\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u8ba1\u7b97\u548c\u6570\u636e\u8d44\u6e90\u91cd\u65b0\u8bad\u7ec3\uff0c\u6210\u672c\u9ad8\u6602\u3002", "method": "\u5229\u7528PCA\u5904\u7406\u591a\u5934\u6ce8\u610f\u529b\u5c42\u7684\u77e9\u9635\u4e58\u79ef\uff0c\u5e76\u901a\u8fc7SVD\u89e3\u51b3\u6700\u5c0f\u4e8c\u4e58\u95ee\u9898\uff0c\u907f\u514d\u91cd\u65b0\u8bad\u7ec3\u3002", "result": "Olica\u5728\u6570\u636e\u4f7f\u7528\u3001GPU\u5185\u5b58\u548c\u8fd0\u884c\u65f6\u95f4\u4e0a\u9ad8\u6548\uff0c\u4e14\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "Olica\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u7684LLM\u526a\u679d\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.08448", "pdf": "https://arxiv.org/pdf/2506.08448", "abs": "https://arxiv.org/abs/2506.08448", "authors": ["Hyakka Nakada", "Shu Tanaka"], "title": "Systematic and Efficient Construction of Quadratic Unconstrained Binary Optimization Forms for High-order and Dense Interactions", "categories": ["quant-ph", "cs.LG"], "comment": null, "summary": "Quantum Annealing (QA) can efficiently solve combinatorial optimization\nproblems whose objective functions are represented by Quadratic Unconstrained\nBinary Optimization (QUBO) formulations. For broader applicability of QA,\nquadratization methods are used to transform higher-order problems into QUBOs.\nHowever, quadratization methods for complex problems involving Machine Learning\n(ML) remain largely unknown. In these problems, strong nonlinearity and dense\ninteractions prevent conventional methods from being applied. Therefore, we\nmodel target functions by the sum of rectified linear unit bases, which not\nonly have the ability of universal approximation, but also have an equivalent\nquadratic-polynomial representation. In this study, the proof of concept is\nverified both numerically and analytically. In addition, by combining QA with\nthe proposed quadratization, we design a new black-box optimization scheme, in\nwhich ML surrogate regressors are inputted to QA after the quadratization\nprocess.", "AI": {"tldr": "\u91cf\u5b50\u9000\u706b\uff08QA\uff09\u80fd\u9ad8\u6548\u89e3\u51b3\u4e8c\u6b21\u65e0\u7ea6\u675f\u4e8c\u8fdb\u5236\u4f18\u5316\uff08QUBO\uff09\u95ee\u9898\u3002\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u7ebf\u6027\u6574\u6d41\u5355\u5143\uff08ReLU\uff09\u7684\u4e8c\u6b21\u5316\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u590d\u6742\u673a\u5668\u5b66\u4e60\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u548c\u89e3\u6790\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edf\u4e8c\u6b21\u5316\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u5177\u6709\u5f3a\u975e\u7ebf\u6027\u548c\u5bc6\u96c6\u4ea4\u4e92\u7684\u590d\u6742\u673a\u5668\u5b66\u4e60\u95ee\u9898\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u7ebf\u6027\u6574\u6d41\u5355\u5143\uff08ReLU\uff09\u57fa\u51fd\u6570\u5efa\u6a21\u76ee\u6807\u51fd\u6570\uff0c\u5e76\u5c06\u5176\u8f6c\u5316\u4e3a\u7b49\u6548\u7684\u4e8c\u6b21\u591a\u9879\u5f0f\u8868\u793a\u3002", "result": "\u901a\u8fc7\u6570\u503c\u548c\u89e3\u6790\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u7ed3\u5408QA\u548c\u4e8c\u6b21\u5316\u7684\u9ed1\u76d2\u4f18\u5316\u65b9\u6848\u3002", "conclusion": "\u63d0\u51fa\u7684ReLU\u57fa\u4e8c\u6b21\u5316\u65b9\u6cd5\u4e3a\u590d\u6742\u673a\u5668\u5b66\u4e60\u95ee\u9898\u7684\u91cf\u5b50\u9000\u706b\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.08455", "pdf": "https://arxiv.org/pdf/2506.08455", "abs": "https://arxiv.org/abs/2506.08455", "authors": ["Julian Berberich", "Tobias Fellner", "Christian Holm"], "title": "The interplay of robustness and generalization in quantum machine learning", "categories": ["quant-ph", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "While adversarial robustness and generalization have individually received\nsubstantial attention in the recent literature on quantum machine learning,\ntheir interplay is much less explored. In this chapter, we address this\ninterplay for variational quantum models, which were recently proposed as\nfunction approximators in supervised learning. We discuss recent results\nquantifying both robustness and generalization via Lipschitz bounds, which\nexplicitly depend on model parameters. Thus, they give rise to a\nregularization-based training approach for robust and generalizable quantum\nmodels, highlighting the importance of trainable data encoding strategies. The\npractical implications of the theoretical results are demonstrated with an\napplication to time series analysis.", "AI": {"tldr": "\u63a2\u8ba8\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u4e2d\u5bf9\u6297\u9c81\u68d2\u6027\u4e0e\u6cdb\u5316\u6027\u7684\u5173\u7cfb\uff0c\u63d0\u51fa\u57fa\u4e8eLipschitz\u754c\u7684\u6b63\u5219\u5316\u8bad\u7ec3\u65b9\u6cd5\u3002", "motivation": "\u7814\u7a76\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u4e2d\u5bf9\u6297\u9c81\u68d2\u6027\u4e0e\u6cdb\u5316\u6027\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u586b\u8865\u73b0\u6709\u6587\u732e\u7684\u7a7a\u767d\u3002", "method": "\u5229\u7528Lipschitz\u754c\u91cf\u5316\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u6027\uff0c\u63d0\u51fa\u57fa\u4e8e\u6b63\u5219\u5316\u7684\u8bad\u7ec3\u65b9\u6cd5\u3002", "result": "\u7406\u8bba\u7ed3\u679c\u5728\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u4e2d\u5f97\u5230\u9a8c\u8bc1\u3002", "conclusion": "\u53ef\u8bad\u7ec3\u7684\u6570\u636e\u7f16\u7801\u7b56\u7565\u5bf9\u9c81\u68d2\u4e14\u6cdb\u5316\u7684\u91cf\u5b50\u6a21\u578b\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2506.08500", "pdf": "https://arxiv.org/pdf/2506.08500", "abs": "https://arxiv.org/abs/2506.08500", "authors": ["Arie Cattan", "Alon Jacovi", "Ori Ram", "Jonathan Herzig", "Roee Aharoni", "Sasha Goldshtein", "Eran Ofek", "Idan Szpektor", "Avi Caciularu"], "title": "DRAGged into Conflicts: Detecting and Addressing Conflicting Sources in Search-Augmented LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Retrieval Augmented Generation (RAG) is a commonly used approach for\nenhancing large language models (LLMs) with relevant and up-to-date\ninformation. However, the retrieved sources can often contain conflicting\ninformation and it remains unclear how models should address such\ndiscrepancies. In this work, we first propose a novel taxonomy of knowledge\nconflict types in RAG, along with the desired model behavior for each type. We\nthen introduce CONFLICTS, a high-quality benchmark with expert annotations of\nconflict types in a realistic RAG setting. CONFLICTS is the first benchmark\nthat enables tracking progress on how models address a wide range of knowledge\nconflicts. We conduct extensive experiments on this benchmark, showing that\nLLMs often struggle to appropriately resolve conflicts between sources. While\nprompting LLMs to explicitly reason about the potential conflict in the\nretrieved documents significantly improves the quality and appropriateness of\ntheir responses, substantial room for improvement in future research remains.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u77e5\u8bc6\u51b2\u7a81\u5206\u7c7b\u6cd5\uff0c\u5e76\u521b\u5efa\u4e86CONFLICTS\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u4e2d\u5904\u7406\u51b2\u7a81\u4fe1\u606f\u7684\u80fd\u529b\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u6a21\u578b\u5728\u51b2\u7a81\u89e3\u51b3\u4e0a\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\u3002", "motivation": "\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u4e2d\u68c0\u7d22\u5230\u7684\u4fe1\u606f\u53ef\u80fd\u5b58\u5728\u51b2\u7a81\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u7cfb\u7edf\u7684\u65b9\u6cd5\u6765\u8bc4\u4f30\u6a21\u578b\u5982\u4f55\u5904\u7406\u8fd9\u4e9b\u51b2\u7a81\u3002", "method": "\u63d0\u51fa\u77e5\u8bc6\u51b2\u7a81\u7684\u5206\u7c7b\u6cd5\uff0c\u5e76\u6784\u5efaCONFLICTS\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30\u6a21\u578b\u5728\u51b2\u7a81\u89e3\u51b3\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u51b2\u7a81\u4fe1\u606f\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u4f46\u901a\u8fc7\u663e\u5f0f\u63d0\u793a\u6a21\u578b\u601d\u8003\u51b2\u7a81\u53ef\u4ee5\u663e\u8457\u6539\u5584\u7ed3\u679c\u3002", "conclusion": "\u672a\u6765\u7814\u7a76\u9700\u8fdb\u4e00\u6b65\u6539\u8fdb\u6a21\u578b\u5728\u51b2\u7a81\u89e3\u51b3\u4e2d\u7684\u80fd\u529b\uff0cCONFLICTS\u57fa\u51c6\u4e3a\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u4e86\u5de5\u5177\u3002"}}
{"id": "2506.08504", "pdf": "https://arxiv.org/pdf/2506.08504", "abs": "https://arxiv.org/abs/2506.08504", "authors": ["Divyaksh Shukla", "Ritesh Baviskar", "Dwijesh Gohil", "Aniket Tiwari", "Atul Shree", "Ashutosh Modi"], "title": "CoMuMDR: Code-mixed Multi-modal Multi-domain corpus for Discourse paRsing in conversations", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted at ACL Findings 2025 (16 pages: 5 pages main content + 3\n  pages references + 8 pages appendix)", "summary": "Discourse parsing is an important task useful for NLU applications such as\nsummarization, machine comprehension, and emotion recognition. The current\ndiscourse parsing datasets based on conversations consists of written English\ndialogues restricted to a single domain. In this resource paper, we introduce\nCoMuMDR: Code-mixed Multi-modal Multi-domain corpus for Discourse paRsing in\nconversations. The corpus (code-mixed in Hindi and English) has both audio and\ntranscribed text and is annotated with nine discourse relations. We experiment\nwith various SoTA baseline models; the poor performance of SoTA models\nhighlights the challenges of multi-domain code-mixed corpus, pointing towards\nthe need for developing better models for such realistic settings.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86CoMuMDR\u8bed\u6599\u5e93\uff0c\u7528\u4e8e\u591a\u6a21\u6001\u591a\u9886\u57df\u4ee3\u7801\u6df7\u5408\u5bf9\u8bdd\u7684\u7bc7\u7ae0\u89e3\u6790\uff0c\u5e76\u5c55\u793a\u4e86\u73b0\u6709\u6a21\u578b\u5728\u6b64\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u4e0d\u4f73\u3002", "motivation": "\u5f53\u524d\u7bc7\u7ae0\u89e3\u6790\u6570\u636e\u96c6\u5c40\u9650\u4e8e\u5355\u4e00\u9886\u57df\u7684\u82f1\u6587\u5bf9\u8bdd\uff0c\u800c\u5b9e\u9645\u5e94\u7528\u4e2d\u9700\u8981\u591a\u6a21\u6001\u548c\u591a\u9886\u57df\u7684\u6570\u636e\u652f\u6301\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u5370\u5730\u8bed\u548c\u82f1\u8bed\u4ee3\u7801\u6df7\u5408\u3001\u591a\u6a21\u6001\uff08\u97f3\u9891\u548c\u6587\u672c\uff09\u7684\u8bed\u6599\u5e93CoMuMDR\uff0c\u5e76\u6807\u6ce8\u4e86\u4e5d\u79cd\u7bc7\u7ae0\u5173\u7cfb\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u73b0\u6709\u5148\u8fdb\u6a21\u578b\u5728\u6b64\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u51f8\u663e\u4e86\u591a\u9886\u57df\u4ee3\u7801\u6df7\u5408\u6570\u636e\u7684\u6311\u6218\u3002", "conclusion": "\u9700\u8981\u5f00\u53d1\u66f4\u597d\u7684\u6a21\u578b\u4ee5\u9002\u5e94\u73b0\u5b9e\u573a\u666f\u4e2d\u7684\u591a\u6a21\u6001\u548c\u591a\u9886\u57df\u4ee3\u7801\u6df7\u5408\u6570\u636e\u3002"}}
{"id": "2506.08507", "pdf": "https://arxiv.org/pdf/2506.08507", "abs": "https://arxiv.org/abs/2506.08507", "authors": ["Kuo Yang", "Xingjie Yang", "Linhui Yu", "Qing Xu", "Yan Fang", "Xu Wang", "Zhengyang Zhou", "Yang Wang"], "title": "MasHost Builds It All: Autonomous Multi-Agent System Directed by Reinforcement Learning", "categories": ["cs.MA", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Model (LLM)-driven Multi-agent systems (Mas) have recently\nemerged as a powerful paradigm for tackling complex real-world tasks. However,\nexisting Mas construction methods typically rely on manually crafted\ninteraction mechanisms or heuristic rules, introducing human biases and\nconstraining the autonomous ability. Even with recent advances in adaptive Mas\nconstruction, existing systems largely remain within the paradigm of\nsemi-autonomous patterns. In this work, we propose MasHost, a Reinforcement\nLearning (RL)-based framework for autonomous and query-adaptive Mas design. By\nformulating Mas construction as a graph search problem, our proposed MasHost\njointly samples agent roles and their interactions through a unified\nprobabilistic sampling mechanism. Beyond the accuracy and efficiency objectives\npursued in prior works, we introduce component rationality as an additional and\nnovel design principle in Mas. To achieve this multi-objective optimization, we\npropose Hierarchical Relative Policy Optimization (HRPO), a novel RL strategy\nthat collaboratively integrates group-relative advantages and action-wise\nrewards. To our knowledge, our proposed MasHost is the first RL-driven\nframework for autonomous Mas graph construction. Extensive experiments on six\nbenchmarks demonstrate that MasHost consistently outperforms most competitive\nbaselines, validating its effectiveness, efficiency, and structure rationality.", "AI": {"tldr": "MasHost\u662f\u4e00\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08MAS\uff09\u81ea\u4e3b\u8bbe\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u56fe\u641c\u7d22\u548c\u6982\u7387\u91c7\u6837\u673a\u5236\u4f18\u5316\u667a\u80fd\u4f53\u89d2\u8272\u4e0e\u4ea4\u4e92\uff0c\u5f15\u5165\u7ec4\u4ef6\u5408\u7406\u6027\u539f\u5219\uff0c\u5e76\u63d0\u51fa\u5206\u5c42\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff08HRPO\uff09\u4ee5\u5b9e\u73b0\u591a\u76ee\u6807\u4f18\u5316\u3002", "motivation": "\u73b0\u6709MAS\u6784\u5efa\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u8bbe\u8ba1\u6216\u542f\u53d1\u5f0f\u89c4\u5219\uff0c\u9650\u5236\u4e86\u81ea\u4e3b\u80fd\u529b\u5e76\u5f15\u5165\u4eba\u4e3a\u504f\u89c1\uff0c\u4e9f\u9700\u4e00\u79cd\u66f4\u81ea\u4e3b\u3001\u9002\u5e94\u6027\u5f3a\u7684\u6784\u5efa\u65b9\u6cd5\u3002", "method": "\u5c06MAS\u6784\u5efa\u5efa\u6a21\u4e3a\u56fe\u641c\u7d22\u95ee\u9898\uff0c\u901a\u8fc7\u6982\u7387\u91c7\u6837\u673a\u5236\u8054\u5408\u91c7\u6837\u667a\u80fd\u4f53\u89d2\u8272\u4e0e\u4ea4\u4e92\uff0c\u63d0\u51faHRPO\u7b56\u7565\u6574\u5408\u7ec4\u76f8\u5bf9\u4f18\u52bf\u548c\u52a8\u4f5c\u5956\u52b1\u4ee5\u5b9e\u73b0\u591a\u76ee\u6807\u4f18\u5316\u3002", "result": "\u5728\u516d\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMasHost\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3001\u6548\u7387\u548c\u7ed3\u6784\u5408\u7406\u6027\u3002", "conclusion": "MasHost\u662f\u9996\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u81ea\u4e3bMAS\u56fe\u6784\u5efa\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86MAS\u7684\u81ea\u4e3b\u6027\u548c\u9002\u5e94\u6027\u3002"}}
{"id": "2506.08518", "pdf": "https://arxiv.org/pdf/2506.08518", "abs": "https://arxiv.org/abs/2506.08518", "authors": ["Sunny Gupta", "Nikita Jangid", "Shounak Das", "Amit Sethi"], "title": "FEDTAIL: Federated Long-Tailed Domain Generalization with Sharpness-Guided Gradient Matching", "categories": ["cs.AI", "cs.CV", "cs.LG", "I.2.6; C.1.4; D.1.3; I.5.1; H.3.4; I.2.10; I.4.0; I.4.1; I.4.2;\n  I.4.6; I.4.7; I.4.8; I.4.9; I.4.10; I.5.1; I.5.2; I.5.4; J.2; I.2.11; I.2.10"], "comment": "Accepted at ICML 2025 Workshop on Collaborative and Federated Agentic\n  Workflows CFAgentic @ ICML'25", "summary": "Domain Generalization (DG) seeks to train models that perform reliably on\nunseen target domains without access to target data during training. While\nrecent progress in smoothing the loss landscape has improved generalization,\nexisting methods often falter under long-tailed class distributions and\nconflicting optimization objectives. We introduce FedTAIL, a federated domain\ngeneralization framework that explicitly addresses these challenges through\nsharpness-guided, gradient-aligned optimization. Our method incorporates a\ngradient coherence regularizer to mitigate conflicts between classification and\nadversarial objectives, leading to more stable convergence. To combat class\nimbalance, we perform class-wise sharpness minimization and propose a\ncurvature-aware dynamic weighting scheme that adaptively emphasizes\nunderrepresented tail classes. Furthermore, we enhance conditional distribution\nalignment by integrating sharpness-aware perturbations into entropy\nregularization, improving robustness under domain shift. FedTAIL unifies\noptimization harmonization, class-aware regularization, and conditional\nalignment into a scalable, federated-compatible framework. Extensive\nevaluations across standard domain generalization benchmarks demonstrate that\nFedTAIL achieves state-of-the-art performance, particularly in the presence of\ndomain shifts and label imbalance, validating its effectiveness in both\ncentralized and federated settings. Code: https://github.com/sunnyinAI/FedTail", "AI": {"tldr": "FedTAIL\u662f\u4e00\u4e2a\u8054\u90a6\u9886\u57df\u6cdb\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u68af\u5ea6\u5bf9\u9f50\u4f18\u5316\u548c\u7c7b\u611f\u77e5\u6b63\u5219\u5316\uff0c\u89e3\u51b3\u4e86\u957f\u5c3e\u5206\u5e03\u548c\u4f18\u5316\u51b2\u7a81\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u5728\u672a\u89c1\u76ee\u6807\u57df\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u957f\u5c3e\u7c7b\u5206\u5e03\u548c\u51b2\u7a81\u4f18\u5316\u76ee\u6807\u4e0b\u8868\u73b0\u4e0d\u4f73\uff0cFedTAIL\u65e8\u5728\u901a\u8fc7\u68af\u5ea6\u5bf9\u9f50\u548c\u7c7b\u611f\u77e5\u6b63\u5219\u5316\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u5f15\u5165\u68af\u5ea6\u4e00\u81f4\u6027\u6b63\u5219\u5316\u51cf\u5c11\u5206\u7c7b\u4e0e\u5bf9\u6297\u76ee\u6807\u7684\u51b2\u7a81\uff0c\u63d0\u51fa\u7c7b\u611f\u77e5\u52a8\u6001\u52a0\u6743\u65b9\u6848\u4ee5\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\uff0c\u5e76\u901a\u8fc7\u9510\u5ea6\u611f\u77e5\u6270\u52a8\u589e\u5f3a\u6761\u4ef6\u5206\u5e03\u5bf9\u9f50\u3002", "result": "\u5728\u6807\u51c6\u9886\u57df\u6cdb\u5316\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cFedTAIL\u8868\u73b0\u51fa\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5c24\u5176\u5728\u57df\u504f\u79fb\u548c\u6807\u7b7e\u4e0d\u5e73\u8861\u60c5\u51b5\u4e0b\u3002", "conclusion": "FedTAIL\u901a\u8fc7\u4f18\u5316\u534f\u8c03\u3001\u7c7b\u611f\u77e5\u6b63\u5219\u5316\u548c\u6761\u4ef6\u5bf9\u9f50\uff0c\u5728\u96c6\u4e2d\u5f0f\u548c\u8054\u90a6\u5f0f\u8bbe\u7f6e\u4e2d\u5747\u6709\u6548\u63d0\u5347\u4e86\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2506.08528", "pdf": "https://arxiv.org/pdf/2506.08528", "abs": "https://arxiv.org/abs/2506.08528", "authors": ["Yu Guan", "Zhiyu Yin", "Haoyu Chen", "Sheng Cheng", "Chaojie Yang", "Tianyin Xu", "Yang Zhang", "Hanyu Zhao", "Yong Li", "Dennis Cai", "Ennan Zhai"], "title": "PerfTracker: Online Performance Troubleshooting for Large-scale Model Training in Production", "categories": ["cs.DC", "cs.LG", "cs.OS"], "comment": null, "summary": "Troubleshooting performance problems of large model training (LMT) is\nimmensely challenging, due to unprecedented scales of modern GPU clusters, the\ncomplexity of software-hardware interactions, and the data intensity of the\ntraining process. Existing troubleshooting approaches designed for traditional\ndistributed systems or datacenter networks fall short and can hardly apply to\nreal-world training systems. In this paper, we present PerfTracker, the first\nonline troubleshooting system utilizing fine-grained profiling, to diagnose\nperformance issues of large-scale model training in production. PerfTracker can\ndiagnose performance issues rooted in both hardware (e.g., GPUs and their\ninterconnects) and software (e.g., Python functions and GPU operations). It\nscales to LMT on modern GPU clusters. PerfTracker effectively summarizes\nruntime behavior patterns of fine-grained LMT functions via online profiling,\nand leverages differential observability to localize the root cause with\nminimal production impact. PerfTracker has been deployed as a production\nservice for large-scale GPU clusters of O(10, 000) GPUs (product homepage\nhttps://help.aliyun.com/zh/pai/user-guide/perftracker-online-performance-analysis-diagnostic-tool).\nIt has been used to diagnose a variety of difficult performance issues.", "AI": {"tldr": "PerfTracker\u662f\u4e00\u79cd\u5728\u7ebf\u6545\u969c\u6392\u9664\u7cfb\u7edf\uff0c\u7528\u4e8e\u8bca\u65ad\u5927\u89c4\u6a21\u6a21\u578b\u8bad\u7ec3\u4e2d\u7684\u6027\u80fd\u95ee\u9898\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u5206\u6790\u548c\u5dee\u5206\u53ef\u89c2\u6d4b\u6027\u5b9a\u4f4d\u95ee\u9898\u6839\u6e90\u3002", "motivation": "\u73b0\u4ee3GPU\u96c6\u7fa4\u89c4\u6a21\u5e9e\u5927\uff0c\u8f6f\u786c\u4ef6\u4ea4\u4e92\u590d\u6742\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u5927\u89c4\u6a21\u6a21\u578b\u8bad\u7ec3\u7684\u6027\u80fd\u95ee\u9898\u3002", "method": "PerfTracker\u5229\u7528\u7ec6\u7c92\u5ea6\u5728\u7ebf\u5206\u6790\uff0c\u603b\u7ed3\u8fd0\u884c\u65f6\u884c\u4e3a\u6a21\u5f0f\uff0c\u5e76\u901a\u8fc7\u5dee\u5206\u53ef\u89c2\u6d4b\u6027\u5b9a\u4f4d\u95ee\u9898\u6839\u6e90\u3002", "result": "PerfTracker\u5df2\u90e8\u7f72\u5728\u5305\u542b\u4e0a\u4e07GPU\u7684\u751f\u4ea7\u96c6\u7fa4\u4e2d\uff0c\u6210\u529f\u8bca\u65ad\u591a\u79cd\u590d\u6742\u6027\u80fd\u95ee\u9898\u3002", "conclusion": "PerfTracker\u4e3a\u5927\u89c4\u6a21\u6a21\u578b\u8bad\u7ec3\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u6027\u80fd\u95ee\u9898\u8bca\u65ad\u5de5\u5177\u3002"}}
{"id": "2506.08535", "pdf": "https://arxiv.org/pdf/2506.08535", "abs": "https://arxiv.org/abs/2506.08535", "authors": ["Ronald Katende"], "title": "Structured Variational $D$-Decomposition for Accurate and Stable Low-Rank Approximation", "categories": ["math.NA", "cs.LG", "cs.NA"], "comment": null, "summary": "We introduce the $D$-decomposition, a non-orthogonal matrix factorization of\nthe form $A \\approx P D Q$, where $P \\in \\mathbb{R}^{n \\times k}$, $D \\in\n\\mathbb{R}^{k \\times k}$, and $Q \\in \\mathbb{R}^{k \\times n}$. The\ndecomposition is defined variationally by minimizing a regularized Frobenius\nloss, allowing control over rank, sparsity, and conditioning. Unlike algebraic\nfactorizations such as LU or SVD, it is computed by alternating minimization.\nWe establish existence and perturbation stability of the solution and show that\neach update has complexity $\\mathcal{O}(n^2k)$. Benchmarks against truncated\nSVD, CUR, and nonnegative matrix factorization show improved reconstruction\naccuracy on MovieLens, MNIST, Olivetti Faces, and gene expression matrices,\nparticularly under sparsity and noise.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u975e\u6b63\u4ea4\u77e9\u9635\u5206\u89e3\u65b9\u6cd5$D$-decomposition\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u6b63\u5219\u5316Frobenius\u635f\u5931\u5b9e\u73b0\uff0c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u5982SVD\u3002", "motivation": "\u4f20\u7edf\u77e9\u9635\u5206\u89e3\u65b9\u6cd5\uff08\u5982LU\u6216SVD\uff09\u5728\u63a7\u5236\u79e9\u3001\u7a00\u758f\u6027\u548c\u6761\u4ef6\u6570\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u7075\u6d3b\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u53d8\u5206\u65b9\u6cd5\u5b9a\u4e49\u5206\u89e3$A \\approx P D Q$\uff0c\u901a\u8fc7\u4ea4\u66ff\u6700\u5c0f\u5316\u8ba1\u7b97\uff0c\u63a7\u5236\u79e9\u3001\u7a00\u758f\u6027\u548c\u6761\u4ef6\u6570\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c$D$-decomposition\u5728MovieLens\u7b49\u6570\u636e\u96c6\u4e0a\u91cd\u5efa\u7cbe\u5ea6\u4f18\u4e8e\u622a\u65adSVD\u3001CUR\u548c\u975e\u8d1f\u77e9\u9635\u5206\u89e3\u3002", "conclusion": "$D$-decomposition\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u7075\u6d3b\u7684\u77e9\u9635\u5206\u89e3\u65b9\u6cd5\uff0c\u7279\u522b\u9002\u7528\u4e8e\u7a00\u758f\u548c\u566a\u58f0\u6570\u636e\u3002"}}
{"id": "2506.08548", "pdf": "https://arxiv.org/pdf/2506.08548", "abs": "https://arxiv.org/abs/2506.08548", "authors": ["Moria Mayala", "Erwan Scornet", "Charles Tillier", "Olivier Wintenberger"], "title": "Asymptotic Normality of Infinite Centered Random Forests -Application to Imbalanced Classification", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Many classification tasks involve imbalanced data, in which a class is\nlargely underrepresented. Several techniques consists in creating a rebalanced\ndataset on which a classifier is trained. In this paper, we study theoretically\nsuch a procedure, when the classifier is a Centered Random Forests (CRF). We\nestablish a Central Limit Theorem (CLT) on the infinite CRF with explicit rates\nand exact constant. We then prove that the CRF trained on the rebalanced\ndataset exhibits a bias, which can be removed with appropriate techniques.\nBased on an importance sampling (IS) approach, the resulting debiased\nestimator, called IS-ICRF, satisfies a CLT centered at the prediction function\nvalue. For high imbalance settings, we prove that the IS-ICRF estimator enjoys\na variance reduction compared to the ICRF trained on the original data.\nTherefore, our theoretical analysis highlights the benefits of training random\nforests on a rebalanced dataset (followed by a debiasing procedure) compared to\nusing the original data. Our theoretical results, especially the variance rates\nand the variance reduction, appear to be valid for Breiman's random forests in\nour experiments.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u7c7b\u522b\u4e0d\u5e73\u8861\u6570\u636e\u4e0a\u8bad\u7ec3Centered Random Forests (CRF)\u7684\u7406\u8bba\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u53bb\u504f\u4f30\u8ba1\u5668IS-ICRF\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u9884\u6d4b\u51fd\u6570\u503c\u4e0a\u7684\u4e2d\u5fc3\u6781\u9650\u5b9a\u7406\uff0c\u5e76\u5728\u9ad8\u4e0d\u5e73\u8861\u8bbe\u7f6e\u4e0b\u5c55\u793a\u4e86\u65b9\u5dee\u964d\u4f4e\u7684\u4f18\u52bf\u3002", "motivation": "\u7c7b\u522b\u4e0d\u5e73\u8861\u6570\u636e\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u5e38\u89c1\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u53ef\u80fd\u5bfc\u81f4\u5206\u7c7b\u5668\u504f\u5dee\u3002\u672c\u6587\u65e8\u5728\u4ece\u7406\u8bba\u4e0a\u5206\u6790\u901a\u8fc7\u91cd\u5e73\u8861\u6570\u636e\u96c6\u8bad\u7ec3CRF\u7684\u6548\u679c\u53ca\u5176\u6539\u8fdb\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u91cd\u8981\u6027\u91c7\u6837(IS)\u7684\u53bb\u504f\u4f30\u8ba1\u5668IS-ICRF\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u5728\u65e0\u9650CRF\u4e0a\u7684\u4e2d\u5fc3\u6781\u9650\u5b9a\u7406(CLT)\u3002", "result": "IS-ICRF\u5728\u9ad8\u4e0d\u5e73\u8861\u8bbe\u7f6e\u4e0b\u8868\u73b0\u51fa\u65b9\u5dee\u964d\u4f4e\u7684\u4f18\u52bf\uff0c\u4e14\u7406\u8bba\u7ed3\u679c\u5728\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u901a\u8fc7\u91cd\u5e73\u8861\u6570\u636e\u96c6\u8bad\u7ec3\u968f\u673a\u68ee\u6797\u5e76\u7ed3\u5408\u53bb\u504f\u6280\u672f\uff0c\u4f18\u4e8e\u76f4\u63a5\u4f7f\u7528\u539f\u59cb\u6570\u636e\u3002"}}
{"id": "2506.08558", "pdf": "https://arxiv.org/pdf/2506.08558", "abs": "https://arxiv.org/abs/2506.08558", "authors": ["William de Vazelhes", "Xiao-Tong Yuan", "Bin Gu"], "title": "Optimization over Sparse Support-Preserving Sets: Two-Step Projection with Global Optimality Guarantees", "categories": ["math.OC", "cs.LG"], "comment": "Accepted for publication at ICML 2025", "summary": "In sparse optimization, enforcing hard constraints using the $\\ell_0$\npseudo-norm offers advantages like controlled sparsity compared to convex\nrelaxations. However, many real-world applications demand not only sparsity\nconstraints but also some extra constraints. While prior algorithms have been\ndeveloped to address this complex scenario with mixed combinatorial and convex\nconstraints, they typically require the closed form projection onto the mixed\nconstraints which might not exist, and/or only provide local guarantees of\nconvergence which is different from the global guarantees commonly sought in\nsparse optimization. To fill this gap, in this paper, we study the problem of\nsparse optimization with extra \\qw{\\textit{support-preserving}} constraints\ncommonly encountered in the literature. We present a new variant of iterative\nhard-thresholding algorithm equipped with a two-step consecutive projection\noperator customized for these mixed constraints, serving as a simple\nalternative to the Euclidean projection onto the mixed constraint. By\nintroducing a novel trade-off between sparsity relaxation and sub-optimality,\nwe provide global guarantees in objective value for the output of our\nalgorithm, in the deterministic, stochastic, and zeroth-order settings, under\nthe conventional restricted strong-convexity/smoothness assumptions. As a\nfundamental contribution in proof techniques, we develop a novel extension of\nthe classic three-point lemma to the considered two-step non-convex projection\noperator, which allows us to analyze the convergence in objective value in an\nelegant way that has not been possible with existing techniques. In the\nzeroth-order case, such technique also improves upon the state-of-the-art\nresult from de Vazelhes et. al. (2022), even in the case without additional\nconstraints, by allowing us to remove a non-vanishing system error present in\ntheir work.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8fed\u4ee3\u786c\u9608\u503c\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u7a00\u758f\u4f18\u5316\u95ee\u9898\u4e2d\u7684\u989d\u5916\u652f\u6301\u4fdd\u6301\u7ea6\u675f\uff0c\u63d0\u4f9b\u4e86\u5168\u5c40\u6536\u655b\u6027\u4fdd\u8bc1\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u6df7\u5408\u7ec4\u5408\u548c\u51f8\u7ea6\u675f\u65f6\u901a\u5e38\u9700\u8981\u95ed\u5f0f\u6295\u5f71\u6216\u4ec5\u63d0\u4f9b\u5c40\u90e8\u6536\u655b\u4fdd\u8bc1\uff0c\u800c\u5b9e\u9645\u5e94\u7528\u9700\u8981\u5168\u5c40\u4fdd\u8bc1\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5e26\u6709\u4e24\u6b65\u8fde\u7eed\u6295\u5f71\u7b97\u5b50\u7684\u8fed\u4ee3\u786c\u9608\u503c\u7b97\u6cd5\uff0c\u9002\u7528\u4e8e\u6df7\u5408\u7ea6\u675f\uff0c\u5e76\u901a\u8fc7\u7a00\u758f\u6027\u4e0e\u6b21\u4f18\u6027\u7684\u6743\u8861\u63d0\u4f9b\u5168\u5c40\u4fdd\u8bc1\u3002", "result": "\u5728\u786e\u5b9a\u6027\u3001\u968f\u673a\u548c\u96f6\u9636\u8bbe\u7f6e\u4e0b\uff0c\u7b97\u6cd5\u5728\u53d7\u9650\u5f3a\u51f8/\u5e73\u6ed1\u5047\u8bbe\u4e0b\u63d0\u4f9b\u4e86\u5168\u5c40\u76ee\u6807\u503c\u4fdd\u8bc1\u3002", "conclusion": "\u8bba\u6587\u901a\u8fc7\u521b\u65b0\u7684\u4e24\u6b65\u975e\u51f8\u6295\u5f71\u7b97\u5b50\u5206\u6790\u6280\u672f\uff0c\u586b\u8865\u4e86\u7a00\u758f\u4f18\u5316\u4e2d\u5168\u5c40\u6536\u655b\u6027\u4fdd\u8bc1\u7684\u7a7a\u767d\uff0c\u5e76\u5728\u96f6\u9636\u60c5\u51b5\u4e0b\u6539\u8fdb\u4e86\u73b0\u6709\u7ed3\u679c\u3002"}}
{"id": "2506.08570", "pdf": "https://arxiv.org/pdf/2506.08570", "abs": "https://arxiv.org/abs/2506.08570", "authors": ["Or Tal", "Felix Kreuk", "Yossi Adi"], "title": "Auto-Regressive vs Flow-Matching: a Comparative Study of Modeling Paradigms for Text-to-Music Generation", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "comment": null, "summary": "Recent progress in text-to-music generation has enabled models to synthesize\nhigh-quality musical segments, full compositions, and even respond to\nfine-grained control signals, e.g. chord progressions. State-of-the-art (SOTA)\nsystems differ significantly across many dimensions, such as training datasets,\nmodeling paradigms, and architectural choices. This diversity complicates\nefforts to evaluate models fairly and pinpoint which design choices most\ninfluence performance. While factors like data and architecture are important,\nin this study we focus exclusively on the modeling paradigm. We conduct a\nsystematic empirical analysis to isolate its effects, offering insights into\nassociated trade-offs and emergent behaviors that can guide future\ntext-to-music generation systems. Specifically, we compare the two arguably\nmost common modeling paradigms: Auto-Regressive decoding and Conditional\nFlow-Matching. We conduct a controlled comparison by training all models from\nscratch using identical datasets, training configurations, and similar backbone\narchitectures. Performance is evaluated across multiple axes, including\ngeneration quality, robustness to inference configurations, scalability,\nadherence to both textual and temporally aligned conditioning, and editing\ncapabilities in the form of audio inpainting. This comparative study sheds\nlight on distinct strengths and limitations of each paradigm, providing\nactionable insights that can inform future architectural and training decisions\nin the evolving landscape of text-to-music generation. Audio sampled examples\nare available at: https://huggingface.co/spaces/ortal1602/ARvsFM", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u5bf9\u6bd4\u81ea\u56de\u5f52\u89e3\u7801\u548c\u6761\u4ef6\u6d41\u5339\u914d\u4e24\u79cd\u5efa\u6a21\u8303\u5f0f\uff0c\u7cfb\u7edf\u5206\u6790\u4e86\u5b83\u4eec\u5728\u6587\u672c\u5230\u97f3\u4e50\u751f\u6210\u4e2d\u7684\u8868\u73b0\uff0c\u4e3a\u672a\u6765\u8bbe\u8ba1\u63d0\u4f9b\u6307\u5bfc\u3002", "motivation": "\u5f53\u524d\u6587\u672c\u5230\u97f3\u4e50\u751f\u6210\u6a21\u578b\u5728\u8bad\u7ec3\u6570\u636e\u3001\u5efa\u6a21\u8303\u5f0f\u548c\u67b6\u6784\u9009\u62e9\u4e0a\u5dee\u5f02\u663e\u8457\uff0c\u5bfc\u81f4\u516c\u5e73\u8bc4\u4f30\u548c\u6027\u80fd\u5f71\u54cd\u56e0\u7d20\u5206\u6790\u56f0\u96be\uff0c\u672c\u6587\u4e13\u6ce8\u4e8e\u5efa\u6a21\u8303\u5f0f\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u76f8\u540c\u6570\u636e\u96c6\u3001\u8bad\u7ec3\u914d\u7f6e\u548c\u7c7b\u4f3c\u9aa8\u5e72\u67b6\u6784\uff0c\u5bf9\u6bd4\u81ea\u56de\u5f52\u89e3\u7801\u548c\u6761\u4ef6\u6d41\u5339\u914d\u4e24\u79cd\u8303\u5f0f\uff0c\u8bc4\u4f30\u751f\u6210\u8d28\u91cf\u3001\u63a8\u7406\u9c81\u68d2\u6027\u3001\u53ef\u6269\u5c55\u6027\u7b49\u3002", "result": "\u63ed\u793a\u4e86\u4e24\u79cd\u8303\u5f0f\u7684\u4f18\u7f3a\u70b9\uff0c\u4e3a\u672a\u6765\u6587\u672c\u5230\u97f3\u4e50\u751f\u6210\u7cfb\u7edf\u7684\u8bbe\u8ba1\u548c\u8bad\u7ec3\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5efa\u6a21\u8303\u5f0f\u7684\u9009\u62e9\u63d0\u4f9b\u4e86\u4f9d\u636e\uff0c\u6709\u52a9\u4e8e\u4f18\u5316\u6587\u672c\u5230\u97f3\u4e50\u751f\u6210\u7cfb\u7edf\u7684\u6027\u80fd\u3002"}}
{"id": "2506.08591", "pdf": "https://arxiv.org/pdf/2506.08591", "abs": "https://arxiv.org/abs/2506.08591", "authors": ["Chengchao Shen", "Hourun Zhu", "Gongfan Fang", "Jianxin Wang", "Xinchao Wang"], "title": "Diversity-Guided MLP Reduction for Efficient Large Vision Transformers", "categories": ["cs.CV", "cs.LG", "cs.MM"], "comment": null, "summary": "Transformer models achieve excellent scaling property, where the performance\nis improved with the increment of model capacity. However, large-scale model\nparameters lead to an unaffordable cost of computing and memory. We analyze\npopular transformer architectures and find that multilayer perceptron (MLP)\nmodules take up the majority of model parameters. To this end, we focus on the\nrecoverability of the compressed models and propose a Diversity-Guided MLP\nReduction (DGMR) method to significantly reduce the parameters of large vision\ntransformers with only negligible performance degradation. Specifically, we\nconduct a Gram-Schmidt weight pruning strategy to eliminate redundant neurons\nof MLP hidden layer, while preserving weight diversity for better performance\nrecover during distillation. Compared to the model trained from scratch, our\npruned model only requires 0.06\\% data of LAION-2B (for the training of large\nvision transformers) without labels (ImageNet-1K) to recover the original\nperformance. Experimental results on several state-of-the-art large vision\ntransformers demonstrate that our method achieves a more than 57.0\\% parameter\nand FLOPs reduction in a near lossless manner. Notably, for EVA-CLIP-E (4.4B),\nour method accomplishes a 71.5\\% parameter and FLOPs reduction without\nperformance degradation. The source code and trained weights are available at\nhttps://github.com/visresearch/DGMR.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6837\u6027\u5f15\u5bfc\u7684MLP\u538b\u7f29\u65b9\u6cd5\uff08DGMR\uff09\uff0c\u663e\u8457\u51cf\u5c11\u5927\u578b\u89c6\u89c9Transformer\u7684\u53c2\u6570\uff0c\u540c\u65f6\u6027\u80fd\u635f\u5931\u6781\u5c0f\u3002", "motivation": "\u5927\u578bTransformer\u6a21\u578b\u53c2\u6570\u8fc7\u591a\u5bfc\u81f4\u8ba1\u7b97\u548c\u5185\u5b58\u6210\u672c\u9ad8\u6602\uff0c\u7814\u7a76\u53d1\u73b0MLP\u6a21\u5757\u5360\u7528\u4e86\u5927\u90e8\u5206\u53c2\u6570\u3002", "method": "\u91c7\u7528Gram-Schmidt\u6743\u91cd\u526a\u679d\u7b56\u7565\u6d88\u9664MLP\u9690\u85cf\u5c42\u7684\u5197\u4f59\u795e\u7ecf\u5143\uff0c\u540c\u65f6\u4fdd\u7559\u6743\u91cd\u591a\u6837\u6027\u4ee5\u63d0\u5347\u84b8\u998f\u6027\u80fd\u3002", "result": "\u5728\u591a\u4e2a\u5148\u8fdb\u7684\u5927\u578b\u89c6\u89c9Transformer\u4e0a\uff0c\u65b9\u6cd5\u5b9e\u73b0\u4e86\u8d85\u8fc757%\u7684\u53c2\u6570\u548cFLOPs\u51cf\u5c11\uff0c\u4e14\u6027\u80fd\u51e0\u4e4e\u65e0\u635f\u3002", "conclusion": "DGMR\u65b9\u6cd5\u9ad8\u6548\u538b\u7f29\u6a21\u578b\uff0c\u663e\u8457\u964d\u4f4e\u6210\u672c\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u89c6\u89c9Transformer\u3002"}}
{"id": "2506.08592", "pdf": "https://arxiv.org/pdf/2506.08592", "abs": "https://arxiv.org/abs/2506.08592", "authors": ["Liyan Xu", "Zhenlin Su", "Mo Yu", "Jiangnan Li", "Fandong Meng", "Jie Zhou"], "title": "Dense Retrievers Can Fail on Simple Queries: Revealing The Granularity Dilemma of Embeddings", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "This work focuses on an observed limitation of text encoders: embeddings may\nnot be able to recognize fine-grained entities or events within the semantics,\nresulting in failed dense retrieval on even simple cases. To examine such\nbehaviors, we first introduce a new evaluation dataset in Chinese, named\nCapRetrieval, whose passages are image captions, and queries are phrases\ninquiring entities or events in various forms. Zero-shot evaluation suggests\nthat encoders may fail on these fine-grained matching, regardless of training\nsources or model sizes. Aiming for enhancement, we proceed to finetune encoders\nwith our proposed data generation strategies, which obtains the best\nperformance on CapRetrieval. Within this process, we further identify an issue\nof granularity dilemma, a challenge for embeddings to express fine-grained\nsalience while aligning with overall semantics. Our dataset, code and models in\nthis work are publicly released at https://github.com/lxucs/CapRetrieval.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u6587\u672c\u7f16\u7801\u5668\u5728\u8bc6\u522b\u7ec6\u7c92\u5ea6\u5b9e\u4f53\u6216\u4e8b\u4ef6\u65f6\u7684\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u4e2d\u6587\u8bc4\u4f30\u6570\u636e\u96c6CapRetrieval\uff0c\u5e76\u901a\u8fc7\u5fae\u8c03\u7f16\u7801\u5668\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u53d1\u73b0\u6587\u672c\u7f16\u7801\u5668\u5728\u7ec6\u7c92\u5ea6\u8bed\u4e49\u5339\u914d\u4e2d\u7684\u4e0d\u8db3\uff0c\u5c24\u5176\u662f\u5bf9\u5b9e\u4f53\u6216\u4e8b\u4ef6\u7684\u8bc6\u522b\u80fd\u529b\u8f83\u5f31\uff0c\u5f71\u54cd\u4e86\u5bc6\u96c6\u68c0\u7d22\u7684\u6548\u679c\u3002", "method": "\u5f15\u5165CapRetrieval\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u7f16\u7801\u5668\u7684\u96f6\u6837\u672c\u8868\u73b0\uff0c\u5e76\u901a\u8fc7\u6570\u636e\u751f\u6210\u7b56\u7565\u5fae\u8c03\u7f16\u7801\u5668\u4ee5\u63d0\u5347\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u7f16\u7801\u5668\u5728\u7ec6\u7c92\u5ea6\u5339\u914d\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u4f46\u901a\u8fc7\u5fae\u8c03\u540e\u6027\u80fd\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u63d0\u51fa\u4e86\u7c92\u5ea6\u56f0\u5883\u95ee\u9898\uff0c\u5e76\u516c\u5f00\u4e86\u6570\u636e\u96c6\u3001\u4ee3\u7801\u548c\u6a21\u578b\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u8d44\u6e90\u3002"}}
{"id": "2506.08594", "pdf": "https://arxiv.org/pdf/2506.08594", "abs": "https://arxiv.org/abs/2506.08594", "authors": ["Yixuan Ma", "Chang Liu", "Weikang Li", "Shun-Yao Zhang", "L. -M. Duan", "Yukai Wu", "Dong-Ling Deng"], "title": "Solving excited states for long-range interacting trapped ions with neural networks", "categories": ["quant-ph", "cond-mat.dis-nn", "cs.AI", "cs.LG"], "comment": null, "summary": "The computation of excited states in strongly interacting quantum many-body\nsystems is of fundamental importance. Yet, it is notoriously challenging due to\nthe exponential scaling of the Hilbert space dimension with the system size.\nHere, we introduce a neural network-based algorithm that can simultaneously\noutput multiple low-lying excited states of a quantum many-body spin system in\nan accurate and efficient fashion. This algorithm, dubbed the neural quantum\nexcited-state (NQES) algorithm, requires no explicit orthogonalization of the\nstates and is generally applicable to higher dimensions. We demonstrate,\nthrough concrete examples including the Haldane-Shastry model with all-to-all\ninteractions, that the NQES algorithm is capable of efficiently computing\nmultiple excited states and their related observable expectations. In addition,\nwe apply the NQES algorithm to two classes of long-range interacting\ntrapped-ion systems in a two-dimensional Wigner crystal. For non-decaying\nall-to-all interactions with alternating signs, our computed low-lying excited\nstates bear spatial correlation patterns similar to those of the ground states,\nwhich closely match recent experimental observations that the\nquasi-adiabatically prepared state accurately reproduces analytical\nground-state correlations. For a system of up to 300 ions with power-law\ndecaying antiferromagnetic interactions, we successfully uncover its gap\nscaling and correlation features. Our results establish a scalable and\nefficient algorithm for computing excited states of interacting quantum\nmany-body systems, which holds potential applications ranging from benchmarking\nquantum devices to photoisomerization.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u7b97\u6cd5\uff08NQES\uff09\uff0c\u7528\u4e8e\u9ad8\u6548\u8ba1\u7b97\u5f3a\u76f8\u4e92\u4f5c\u7528\u91cf\u5b50\u591a\u4f53\u7cfb\u7edf\u7684\u4f4e\u6fc0\u53d1\u6001\uff0c\u65e0\u9700\u663e\u5f0f\u6b63\u4ea4\u5316\uff0c\u9002\u7528\u4e8e\u9ad8\u7ef4\u7cfb\u7edf\u3002", "motivation": "\u5f3a\u76f8\u4e92\u4f5c\u7528\u91cf\u5b50\u591a\u4f53\u7cfb\u7edf\u7684\u6fc0\u53d1\u6001\u8ba1\u7b97\u5177\u6709\u57fa\u7840\u91cd\u8981\u6027\uff0c\u4f46\u7531\u4e8e\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u7ef4\u5ea6\u7684\u6307\u6570\u589e\u957f\uff0c\u4f20\u7edf\u65b9\u6cd5\u9762\u4e34\u5de8\u5927\u6311\u6218\u3002", "method": "\u63d0\u51faNQES\u7b97\u6cd5\uff0c\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u540c\u65f6\u8f93\u51fa\u591a\u4e2a\u4f4e\u6fc0\u53d1\u6001\uff0c\u9002\u7528\u4e8e\u9ad8\u7ef4\u7cfb\u7edf\uff0c\u5e76\u5728Haldane-Shastry\u6a21\u578b\u548c\u4e8c\u7ef4Wigner\u6676\u4f53\u4e2d\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "result": "NQES\u7b97\u6cd5\u6210\u529f\u8ba1\u7b97\u4e86\u591a\u4e2a\u6fc0\u53d1\u6001\u53ca\u5176\u89c2\u6d4b\u503c\uff0c\u63ed\u793a\u4e86\u957f\u7a0b\u76f8\u4e92\u4f5c\u7528\u7cfb\u7edf\u7684\u80fd\u9699\u6807\u5ea6\u548c\u5173\u8054\u7279\u5f81\uff0c\u4e0e\u5b9e\u9a8c\u7ed3\u679c\u4e00\u81f4\u3002", "conclusion": "NQES\u7b97\u6cd5\u4e3a\u91cf\u5b50\u591a\u4f53\u7cfb\u7edf\u7684\u6fc0\u53d1\u6001\u8ba1\u7b97\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684\u65b9\u6cd5\uff0c\u5177\u6709\u4ece\u91cf\u5b50\u8bbe\u5907\u57fa\u51c6\u6d4b\u8bd5\u5230\u5149\u5f02\u6784\u5316\u7b49\u6f5c\u5728\u5e94\u7528\u3002"}}
{"id": "2506.08616", "pdf": "https://arxiv.org/pdf/2506.08616", "abs": "https://arxiv.org/abs/2506.08616", "authors": ["Julien Fageot", "Peva Blanchard", "Gilles Bareilles", "L\u00ea-Nguy\u00ean Hoang"], "title": "Generalizing while preserving monotonicity in comparison-based preference learning models", "categories": ["math.ST", "cs.LG", "stat.TH"], "comment": null, "summary": "If you tell a learning model that you prefer an alternative $a$ over another\nalternative $b$, then you probably expect the model to be monotone, that is,\nthe valuation of $a$ increases, and that of $b$ decreases. Yet, perhaps\nsurprisingly, many widely deployed comparison-based preference learning models,\nincluding large language models, fail to have this guarantee. Until now, the\nonly comparison-based preference learning algorithms that were proved to be\nmonotone are the Generalized Bradley-Terry models. Yet, these models are unable\nto generalize to uncompared data. In this paper, we advance the understanding\nof the set of models with generalization ability that are monotone. Namely, we\npropose a new class of Linear Generalized Bradley-Terry models with Diffusion\nPriors, and identify sufficient conditions on alternatives' embeddings that\nguarantee monotonicity. Our experiments show that this monotonicity is far from\nbeing a general guarantee, and that our new class of generalizing models\nimproves accuracy, especially when the dataset is limited.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7ebf\u6027\u5e7f\u4e49Bradley-Terry\u6a21\u578b\uff0c\u786e\u4fdd\u504f\u597d\u5b66\u4e60\u7684\u5355\u8c03\u6027\uff0c\u5e76\u5728\u6570\u636e\u6709\u9650\u65f6\u63d0\u9ad8\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u504f\u597d\u5b66\u4e60\u6a21\u578b\uff08\u5982\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff09\u7f3a\u4e4f\u5355\u8c03\u6027\u4fdd\u8bc1\uff0c\u800c\u5e7f\u4e49Bradley-Terry\u6a21\u578b\u867d\u5355\u8c03\u4f46\u65e0\u6cd5\u6cdb\u5316\u5230\u672a\u6bd4\u8f83\u6570\u636e\u3002", "method": "\u63d0\u51fa\u7ebf\u6027\u5e7f\u4e49Bradley-Terry\u6a21\u578b\u4e0e\u6269\u6563\u5148\u9a8c\uff0c\u5e76\u8bc6\u522b\u5d4c\u5165\u6761\u4ef6\u7684\u5145\u5206\u6027\u4ee5\u4fdd\u8bc1\u5355\u8c03\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5355\u8c03\u6027\u5e76\u975e\u666e\u904d\u4fdd\u8bc1\uff0c\u65b0\u6a21\u578b\u5728\u6709\u9650\u6570\u636e\u96c6\u4e0b\u663e\u8457\u63d0\u9ad8\u51c6\u786e\u6027\u3002", "conclusion": "\u65b0\u6a21\u578b\u5728\u4fdd\u8bc1\u5355\u8c03\u6027\u7684\u540c\u65f6\u5177\u5907\u6cdb\u5316\u80fd\u529b\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u6570\u636e\u53d7\u9650\u573a\u666f\u3002"}}
{"id": "2506.08646", "pdf": "https://arxiv.org/pdf/2506.08646", "abs": "https://arxiv.org/abs/2506.08646", "authors": ["Mingyu Zheng", "Zhifan Feng", "Jia Wang", "Lanrui Wang", "Zheng Lin", "Yang Hao", "Weiping Wang"], "title": "TableDreamer: Progressive and Weakness-guided Data Synthesis from Scratch for Table Instruction Tuning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "27 pages, 19 figures, Findings of ACL 2025", "summary": "Despite the commendable progress of recent LLM-based data synthesis methods,\nthey face two limitations in generating table instruction tuning data. First,\nthey can not thoroughly explore the vast input space of table understanding\ntasks, leading to limited data diversity. Second, they ignore the weaknesses in\ntable understanding ability of the target LLM and blindly pursue the increase\nof data quantity, resulting in suboptimal data efficiency. In this paper, we\nintroduce a progressive and weakness-guided data synthesis framework tailored\nfor table instruction tuning, named TableDreamer, to mitigate the above issues.\nSpecifically, we first synthesize diverse tables and related instructions as\nseed data, and then perform an iterative exploration of the input space under\nthe guidance of the newly identified weakness data, which eventually serve as\nthe final training data for fine-tuning the target LLM. Extensive experiments\non 10 tabular benchmarks demonstrate the effectiveness of the proposed\nframework, which boosts the average accuracy of Llama3.1-8B-instruct by 11.62%\n(49.07% to 60.69%) with 27K GPT-4o synthetic data and outperforms\nstate-of-the-art data synthesis baselines which use more training data. The\ncode and data is available at https://github.com/SpursGoZmy/TableDreamer", "AI": {"tldr": "TableDreamer\u662f\u4e00\u4e2a\u6e10\u8fdb\u5f0f\u3001\u5f31\u70b9\u5f15\u5bfc\u7684\u6570\u636e\u5408\u6210\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u73b0\u6709LLM\u65b9\u6cd5\u5728\u751f\u6210\u8868\u683c\u6307\u4ee4\u8c03\u4f18\u6570\u636e\u65f6\u7684\u591a\u6837\u6027\u548c\u6548\u7387\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u5145\u5206\u63a2\u7d22\u8868\u683c\u7406\u89e3\u4efb\u52a1\u7684\u8f93\u5165\u7a7a\u95f4\uff0c\u4e14\u5ffd\u89c6\u76ee\u6807LLM\u7684\u5f31\u70b9\uff0c\u5bfc\u81f4\u6570\u636e\u591a\u6837\u6027\u548c\u6548\u7387\u4e0d\u8db3\u3002", "method": "\u901a\u8fc7\u5408\u6210\u591a\u6837\u5316\u7684\u79cd\u5b50\u6570\u636e\uff0c\u5e76\u5728\u5f31\u70b9\u6570\u636e\u7684\u5f15\u5bfc\u4e0b\u8fed\u4ee3\u63a2\u7d22\u8f93\u5165\u7a7a\u95f4\uff0c\u751f\u6210\u6700\u7ec8\u8bad\u7ec3\u6570\u636e\u3002", "result": "\u572810\u4e2a\u8868\u683c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cTableDreamer\u5c06Llama3.1-8B-instruct\u7684\u5e73\u5747\u51c6\u786e\u7387\u63d0\u9ad8\u4e8611.62%\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "TableDreamer\u901a\u8fc7\u5f31\u70b9\u5f15\u5bfc\u548c\u6e10\u8fdb\u5f0f\u5408\u6210\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8868\u683c\u6307\u4ee4\u8c03\u4f18\u7684\u6548\u679c\u3002"}}
{"id": "2506.08654", "pdf": "https://arxiv.org/pdf/2506.08654", "abs": "https://arxiv.org/abs/2506.08654", "authors": ["Ciro Benito Raggio", "Paolo Zaffino", "Maria Francesca Spadea"], "title": "A Privacy-Preserving Federated Learning Framework for Generalizable CBCT to Synthetic CT Translation in Head and Neck", "categories": ["physics.med-ph", "cs.LG"], "comment": null, "summary": "Shortened Abstract\n  Cone-beam computed tomography (CBCT) has become a widely adopted modality for\nimage-guided radiotherapy (IGRT). However, CBCT suffers from increased noise,\nlimited soft-tissue contrast, and artifacts, resulting in unreliable Hounsfield\nunit values and hindering direct dose calculation. Synthetic CT (sCT)\ngeneration from CBCT addresses these issues, especially using deep learning\n(DL) methods. Existing approaches are limited by institutional heterogeneity,\nscanner-dependent variations, and data privacy regulations that prevent\nmulti-center data sharing.\n  To overcome these challenges, we propose a cross-silo horizontal federated\nlearning (FL) approach for CBCT-to-sCT synthesis in the head and neck region,\nextending our FedSynthCT framework. A conditional generative adversarial\nnetwork was collaboratively trained on data from three European medical centers\nin the public SynthRAD2025 challenge dataset.\n  The federated model demonstrated effective generalization across centers,\nwith mean absolute error (MAE) ranging from $64.38\\pm13.63$ to $85.90\\pm7.10$\nHU, structural similarity index (SSIM) from $0.882\\pm0.022$ to $0.922\\pm0.039$,\nand peak signal-to-noise ratio (PSNR) from $32.86\\pm0.94$ to $34.91\\pm1.04$ dB.\nNotably, on an external validation dataset of 60 patients, comparable\nperformance was achieved (MAE: $75.22\\pm11.81$ HU, SSIM: $0.904\\pm0.034$, PSNR:\n$33.52\\pm2.06$ dB) without additional training, confirming robust\ngeneralization despite protocol, scanner differences and registration errors.\n  These findings demonstrate the technical feasibility of FL for CBCT-to-sCT\nsynthesis while preserving data privacy and offer a collaborative solution for\ndeveloping generalizable models across institutions without centralized data\nsharing or site-specific fine-tuning.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a2a\u5411\u8054\u90a6\u5b66\u4e60\u7684\u8de8\u673a\u6784CBCT\u5230sCT\u5408\u6210\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u6570\u636e\u9690\u79c1\u548c\u591a\u4e2d\u5fc3\u6570\u636e\u5171\u4eab\u7684\u9650\u5236\uff0c\u5e76\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "CBCT\u5728\u56fe\u50cf\u5f15\u5bfc\u653e\u7597\u4e2d\u5b58\u5728\u566a\u58f0\u3001\u8f6f\u7ec4\u7ec7\u5bf9\u6bd4\u5ea6\u4f4e\u548c\u4f2a\u5f71\u7b49\u95ee\u9898\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u53d7\u9650\u4e8e\u673a\u6784\u5f02\u8d28\u6027\u3001\u626b\u63cf\u4eea\u5dee\u5f02\u548c\u6570\u636e\u9690\u79c1\u6cd5\u89c4\u3002", "method": "\u91c7\u7528\u6a2a\u5411\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\uff0c\u7ed3\u5408\u6761\u4ef6\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff0c\u5229\u7528\u4e09\u4e2a\u6b27\u6d32\u533b\u7597\u4e2d\u5fc3\u7684\u6570\u636e\u8fdb\u884c\u534f\u4f5c\u8bad\u7ec3\u3002", "result": "\u8054\u90a6\u6a21\u578b\u5728\u591a\u4e2d\u5fc3\u6570\u636e\u4e0a\u8868\u73b0\u51fa\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff0cMAE\u3001SSIM\u548cPSNR\u7b49\u6307\u6807\u5747\u8fbe\u5230\u8f83\u9ad8\u6c34\u5e73\uff0c\u4e14\u5916\u90e8\u9a8c\u8bc1\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u7a33\u5b9a\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6280\u672f\u53ef\u884c\uff0c\u4fdd\u62a4\u4e86\u6570\u636e\u9690\u79c1\uff0c\u4e3a\u8de8\u673a\u6784\u5f00\u53d1\u901a\u7528\u6a21\u578b\u63d0\u4f9b\u4e86\u534f\u4f5c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.08670", "pdf": "https://arxiv.org/pdf/2506.08670", "abs": "https://arxiv.org/abs/2506.08670", "authors": ["Renjie Xu", "Chong Wu", "Maolin Che", "Zhuoheng Ran", "Yimin Wei", "Hong Yan"], "title": "sparseGeoHOPCA: A Geometric Solution to Sparse Higher-Order PCA Without Covariance Estimation", "categories": ["math.NA", "cs.LG", "cs.NA", "math.OC"], "comment": null, "summary": "We propose sparseGeoHOPCA, a novel framework for sparse higher-order\nprincipal component analysis (SHOPCA) that introduces a geometric perspective\nto high-dimensional tensor decomposition. By unfolding the input tensor along\neach mode and reformulating the resulting subproblems as structured binary\nlinear optimization problems, our method transforms the original nonconvex\nsparse objective into a tractable geometric form. This eliminates the need for\nexplicit covariance estimation and iterative deflation, enabling significant\ngains in both computational efficiency and interpretability, particularly in\nhigh-dimensional and unbalanced data scenarios. We theoretically establish the\nequivalence between the geometric subproblems and the original SHOPCA\nformulation, and derive worst-case approximation error bounds based on\nclassical PCA residuals, providing data-dependent performance guarantees. The\nproposed algorithm achieves a total computational complexity of\n$O\\left(\\sum_{n=1}^{N} (k_n^3 + J_n k_n^2)\\right)$, which scales linearly with\ntensor size. Extensive experiments demonstrate that sparseGeoHOPCA accurately\nrecovers sparse supports in synthetic settings, preserves classification\nperformance under 10$\\times$ compression, and achieves high-quality image\nreconstruction on ImageNet, highlighting its robustness and versatility.", "AI": {"tldr": "\u7a00\u758fGeoHOPCA\u662f\u4e00\u79cd\u65b0\u7684\u7a00\u758f\u9ad8\u9636\u4e3b\u6210\u5206\u5206\u6790\u65b9\u6cd5\uff0c\u901a\u8fc7\u51e0\u4f55\u89c6\u89d2\u4f18\u5316\u9ad8\u7ef4\u5f20\u91cf\u5206\u89e3\uff0c\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u4f20\u7edf\u7a00\u758f\u9ad8\u9636\u4e3b\u6210\u5206\u5206\u6790\uff08SHOPCA\uff09\u5728\u9ad8\u7ef4\u548c\u4e0d\u5e73\u8861\u6570\u636e\u573a\u666f\u4e2d\u6548\u7387\u4f4e\u4e14\u96be\u4ee5\u89e3\u91ca\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "\u5c06\u8f93\u5165\u5f20\u91cf\u6cbf\u6bcf\u4e2a\u6a21\u5f0f\u5c55\u5f00\uff0c\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u4e8c\u5143\u7ebf\u6027\u4f18\u5316\u95ee\u9898\uff0c\u907f\u514d\u663e\u5f0f\u534f\u65b9\u5dee\u4f30\u8ba1\u548c\u8fed\u4ee3\u653e\u6c14\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u51e0\u4f55\u5b50\u95ee\u9898\u4e0e\u539fSHOPCA\u7b49\u4ef7\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u7ebf\u6027\u589e\u957f\uff0c\u5b9e\u9a8c\u663e\u793a\u5728\u5408\u6210\u6570\u636e\u3001\u5206\u7c7b\u548c\u56fe\u50cf\u91cd\u5efa\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u7a00\u758fGeoHOPCA\u5728\u9ad8\u6548\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u9c81\u68d2\u6027\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u9ad8\u7ef4\u6570\u636e\u3002"}}
{"id": "2506.08712", "pdf": "https://arxiv.org/pdf/2506.08712", "abs": "https://arxiv.org/abs/2506.08712", "authors": ["Hee Suk Yoon", "Eunseop Yoon", "Mark A. Hasegawa-Johnson", "Sungwoong Kim", "Chang D. Yoo"], "title": "ConfPO: Exploiting Policy Model Confidence for Critical Token Selection in Large Language Model Preference Optimization", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "ICML 2025", "summary": "We introduce ConfPO, a method for preference learning in Large Language\nModels (LLMs) that identifies and optimizes preference-critical tokens based\nsolely on the training policy's confidence, without requiring any auxiliary\nmodels or compute. Unlike prior Direct Alignment Algorithms (DAAs) such as\nDirect Preference Optimization (DPO), which uniformly adjust all token\nprobabilities regardless of their relevance to preference, ConfPO focuses\noptimization on the most impactful tokens. This targeted approach improves\nalignment quality while mitigating overoptimization (i.e., reward hacking) by\nusing the KL divergence budget more efficiently. In contrast to recent\ntoken-level methods that rely on credit-assignment models or AI annotators,\nraising concerns about scalability and reliability, ConfPO is simple,\nlightweight, and model-free. Experimental results on challenging alignment\nbenchmarks, including AlpacaEval 2 and Arena-Hard, demonstrate that ConfPO\nconsistently outperforms uniform DAAs across various LLMs, delivering better\nalignment with zero additional computational overhead.", "AI": {"tldr": "ConfPO\u662f\u4e00\u79cd\u7528\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u504f\u597d\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f18\u5316\u504f\u597d\u5173\u952e\u4ee4\u724c\uff0c\u4ec5\u4f9d\u8d56\u8bad\u7ec3\u7b56\u7565\u7684\u7f6e\u4fe1\u5ea6\uff0c\u65e0\u9700\u989d\u5916\u6a21\u578b\u6216\u8ba1\u7b97\u8d44\u6e90\u3002", "motivation": "\u73b0\u6709\u76f4\u63a5\u5bf9\u9f50\u7b97\u6cd5\uff08\u5982DPO\uff09\u5bf9\u6240\u6709\u4ee4\u724c\u6982\u7387\u8fdb\u884c\u7edf\u4e00\u8c03\u6574\uff0c\u800cConfPO\u4e13\u6ce8\u4e8e\u5bf9\u504f\u597d\u6700\u5173\u952e\u7684\u4ee4\u724c\u8fdb\u884c\u4f18\u5316\uff0c\u4ee5\u63d0\u9ad8\u5bf9\u9f50\u8d28\u91cf\u5e76\u51cf\u5c11\u8fc7\u4f18\u5316\u95ee\u9898\u3002", "method": "ConfPO\u57fa\u4e8e\u8bad\u7ec3\u7b56\u7565\u7684\u7f6e\u4fe1\u5ea6\u8bc6\u522b\u504f\u597d\u5173\u952e\u4ee4\u724c\uff0c\u5e76\u4ec5\u5bf9\u8fd9\u4e9b\u4ee4\u724c\u8fdb\u884c\u4f18\u5316\uff0c\u907f\u514d\u4e86\u989d\u5916\u6a21\u578b\u6216\u8ba1\u7b97\u8d44\u6e90\u7684\u9700\u6c42\u3002", "result": "\u5728AlpacaEval 2\u548cArena-Hard\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cConfPO\u8868\u73b0\u4f18\u4e8e\u7edf\u4e00\u8c03\u6574\u7684DAAs\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u5bf9\u9f50\u6548\u679c\u4e14\u65e0\u989d\u5916\u8ba1\u7b97\u5f00\u9500\u3002", "conclusion": "ConfPO\u662f\u4e00\u79cd\u7b80\u5355\u3001\u8f7b\u91cf\u4e14\u65e0\u9700\u6a21\u578b\u7684\u504f\u597d\u5b66\u4e60\u65b9\u6cd5\uff0c\u80fd\u591f\u9ad8\u6548\u63d0\u5347LLM\u7684\u5bf9\u9f50\u8d28\u91cf\u3002"}}
{"id": "2506.08725", "pdf": "https://arxiv.org/pdf/2506.08725", "abs": "https://arxiv.org/abs/2506.08725", "authors": ["Hyeon Jeon", "Jeongin Park", "Sungbok Shin", "Jinwook Seo"], "title": "Stop Misusing t-SNE and UMAP for Visual Analytics", "categories": ["cs.HC", "cs.LG"], "comment": "9 pages", "summary": "Misuses of t-SNE and UMAP in visual analytics have become increasingly\ncommon. For example, although t-SNE and UMAP projections often do not\nfaithfully reflect true distances between clusters, practitioners frequently\nuse them to investigate inter-cluster relationships. In this paper, we bring\nthis issue to the surface and comprehensively investigate why such misuse\noccurs and how to prevent it. We conduct a literature review of 114 papers to\nverify the prevalence of the misuse and analyze the reasonings behind it. We\nthen execute an interview study to uncover practitioners' implicit motivations\nfor using these techniques -- rationales often undisclosed in the literature.\nOur findings indicate that misuse of t-SNE and UMAP primarily stems from\nlimited discourse on their appropriate use in visual analytics. We conclude by\nproposing future directions and concrete action items to promote more\nreasonable use of DR.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86t-SNE\u548cUMAP\u5728\u53ef\u89c6\u5316\u5206\u6790\u4e2d\u7684\u8bef\u7528\u73b0\u8c61\uff0c\u5206\u6790\u4e86\u539f\u56e0\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u65b9\u5411\u3002", "motivation": "\u63ed\u793at-SNE\u548cUMAP\u5728\u53ef\u89c6\u5316\u5206\u6790\u4e2d\u7684\u5e38\u89c1\u8bef\u7528\uff0c\u63a2\u7a76\u5176\u80cc\u540e\u7684\u539f\u56e0\u53ca\u5982\u4f55\u907f\u514d\u3002", "method": "\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\uff08114\u7bc7\u8bba\u6587\uff09\u548c\u8bbf\u8c08\u7814\u7a76\uff0c\u9a8c\u8bc1\u8bef\u7528\u73b0\u8c61\u5e76\u5206\u6790\u539f\u56e0\u3002", "result": "\u8bef\u7528\u4e3b\u8981\u6e90\u4e8e\u5bf9t-SNE\u548cUMAP\u5728\u53ef\u89c6\u5316\u5206\u6790\u4e2d\u9002\u7528\u6027\u7684\u8ba8\u8bba\u4e0d\u8db3\u3002", "conclusion": "\u63d0\u51fa\u672a\u6765\u65b9\u5411\u548c\u5177\u4f53\u63aa\u65bd\uff0c\u4ee5\u4fc3\u8fdb\u964d\u7ef4\u6280\u672f\u7684\u5408\u7406\u4f7f\u7528\u3002"}}
{"id": "2506.08734", "pdf": "https://arxiv.org/pdf/2506.08734", "abs": "https://arxiv.org/abs/2506.08734", "authors": ["Nelvin Tan", "Yu-Ching Shih", "Dong Yang", "Amol Salunkhe"], "title": "Flexible and Efficient Drift Detection without Labels", "categories": ["stat.ML", "cs.LG", "stat.AP"], "comment": "9 pages, 4 figures", "summary": "Machine learning models are being increasingly used to automate decisions in\nalmost every domain, and ensuring the performance of these models is crucial\nfor ensuring high quality machine learning enabled services. Ensuring concept\ndrift is detected early is thus of the highest importance. A lot of research on\nconcept drift has focused on the supervised case that assumes the true labels\nof supervised tasks are available immediately after making predictions.\nControlling for false positives while monitoring the performance of predictive\nmodels used to make inference from extremely large datasets periodically, where\nthe true labels are not instantly available, becomes extremely challenging. We\npropose a flexible and efficient concept drift detection algorithm that uses\nclassical statistical process control in a label-less setting to accurately\ndetect concept drifts. We shown empirically that under computational\nconstraints, our approach has better statistical power than previous known\nmethods. Furthermore, we introduce a new drift detection framework to model the\nscenario of detecting drift (without labels) given prior detections, and show\nour how our drift detection algorithm can be incorporated effectively into this\nframework. We demonstrate promising performance via numerical simulations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u6807\u7b7e\u7684\u7075\u6d3b\u9ad8\u6548\u7684\u6982\u5ff5\u6f02\u79fb\u68c0\u6d4b\u7b97\u6cd5\uff0c\u57fa\u4e8e\u7ecf\u5178\u7edf\u8ba1\u8fc7\u7a0b\u63a7\u5236\uff0c\u5728\u8ba1\u7b97\u53d7\u9650\u60c5\u51b5\u4e0b\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u786e\u4fdd\u673a\u5668\u5b66\u4e60\u6a21\u578b\u6027\u80fd\u5bf9\u9ad8\u8d28\u91cf\u670d\u52a1\u81f3\u5173\u91cd\u8981\uff0c\u800c\u6982\u5ff5\u6f02\u79fb\u7684\u65e9\u671f\u68c0\u6d4b\u662f\u5173\u952e\u3002\u73b0\u6709\u7814\u7a76\u591a\u57fa\u4e8e\u76d1\u7763\u4efb\u52a1\uff0c\u4f46\u771f\u5b9e\u6807\u7b7e\u5ef6\u8fdf\u7684\u573a\u666f\u4e0b\u68c0\u6d4b\u6311\u6218\u5de8\u5927\u3002", "method": "\u4f7f\u7528\u7ecf\u5178\u7edf\u8ba1\u8fc7\u7a0b\u63a7\u5236\u5728\u65e0\u6807\u7b7e\u8bbe\u7f6e\u4e0b\u68c0\u6d4b\u6982\u5ff5\u6f02\u79fb\uff0c\u5e76\u5f15\u5165\u65b0\u6846\u67b6\u4ee5\u7ed3\u5408\u5148\u9a8c\u68c0\u6d4b\u7ed3\u679c\u3002", "result": "\u5728\u8ba1\u7b97\u53d7\u9650\u60c5\u51b5\u4e0b\uff0c\u7b97\u6cd5\u7edf\u8ba1\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u6570\u503c\u6a21\u62df\u663e\u793a\u826f\u597d\u6548\u679c\u3002", "conclusion": "\u63d0\u51fa\u7684\u7b97\u6cd5\u548c\u6846\u67b6\u5728\u65e0\u6807\u7b7e\u573a\u666f\u4e0b\u9ad8\u6548\u68c0\u6d4b\u6982\u5ff5\u6f02\u79fb\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.08743", "pdf": "https://arxiv.org/pdf/2506.08743", "abs": "https://arxiv.org/abs/2506.08743", "authors": ["Michael F\u00e4rber", "David Lamprecht", "Yuni Susanti"], "title": "Bridging RDF Knowledge Graphs with Graph Neural Networks for Semantically-Rich Recommender Systems", "categories": ["cs.IR", "cs.AI", "cs.DB", "cs.LG"], "comment": "Accepted at DASFAA 2025", "summary": "Graph Neural Networks (GNNs) have substantially advanced the field of\nrecommender systems. However, despite the creation of more than a thousand\nknowledge graphs (KGs) under the W3C standard RDF, their rich semantic\ninformation has not yet been fully leveraged in GNN-based recommender systems.\nTo address this gap, we propose a comprehensive integration of RDF KGs with\nGNNs that utilizes both the topological information from RDF object properties\nand the content information from RDF datatype properties. Our main focus is an\nin-depth evaluation of various GNNs, analyzing how different semantic feature\ninitializations and types of graph structure heterogeneity influence their\nperformance in recommendation tasks. Through experiments across multiple\nrecommendation scenarios involving multi-million-node RDF graphs, we\ndemonstrate that harnessing the semantic richness of RDF KGs significantly\nimproves recommender systems and lays the groundwork for GNN-based recommender\nsystems for the Linked Open Data cloud. The code and data are available on our\nGitHub repository: https://github.com/davidlamprecht/rdf-gnn-recommendation", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06RDF\u77e5\u8bc6\u56fe\u4e0e\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\u5168\u9762\u96c6\u6210\u7684\u65b9\u6cd5\uff0c\u4ee5\u63d0\u5347\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u5df2\u6709\u5927\u91cfRDF\u6807\u51c6\u7684\u77e5\u8bc6\u56fe\uff0c\u4f46\u5176\u4e30\u5bcc\u7684\u8bed\u4e49\u4fe1\u606f\u5c1a\u672a\u5728\u57fa\u4e8eGNN\u7684\u63a8\u8350\u7cfb\u7edf\u4e2d\u5f97\u5230\u5145\u5206\u5229\u7528\u3002", "method": "\u901a\u8fc7\u7ed3\u5408RDF\u77e5\u8bc6\u56fe\u7684\u62d3\u6251\u4fe1\u606f\u548c\u5185\u5bb9\u4fe1\u606f\uff0c\u8bc4\u4f30\u4e0d\u540cGNN\u5728\u63a8\u8350\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5229\u7528RDF\u77e5\u8bc6\u56fe\u7684\u8bed\u4e49\u4fe1\u606f\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u57fa\u4e8eGNN\u7684\u63a8\u8350\u7cfb\u7edf\u5728\u5f00\u653e\u6570\u636e\u4e91\u4e2d\u7684\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.08746", "pdf": "https://arxiv.org/pdf/2506.08746", "abs": "https://arxiv.org/abs/2506.08746", "authors": ["Muhammad Anwar", "Mishca de Costa", "Issam Hammad", "Daniel Lau"], "title": "Towards Secure and Private Language Models for Nuclear Power Plants", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "This paper introduces a domain-specific Large Language Model for nuclear\napplications, built from the publicly accessible Essential CANDU textbook.\nDrawing on a compact Transformer-based architecture, the model is trained on a\nsingle GPU to protect the sensitive data inherent in nuclear operations.\nDespite relying on a relatively small dataset, it shows encouraging signs of\ncapturing specialized nuclear vocabulary, though the generated text sometimes\nlacks syntactic coherence. By focusing exclusively on nuclear content, this\napproach demonstrates the feasibility of in-house LLM solutions that align with\nrigorous cybersecurity and data confidentiality standards. Early successes in\ntext generation underscore the model's utility for specialized tasks, while\nalso revealing the need for richer corpora, more sophisticated preprocessing,\nand instruction fine-tuning to enhance domain accuracy. Future directions\ninclude extending the dataset to cover diverse nuclear subtopics, refining\ntokenization to reduce noise, and systematically evaluating the model's\nreadiness for real-world applications in nuclear domain.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u9488\u5bf9\u6838\u5e94\u7528\u9886\u57df\u7684\u7279\u5b9a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u57fa\u4e8e\u516c\u5f00\u7684Essential CANDU\u6559\u6750\u6784\u5efa\uff0c\u91c7\u7528\u7d27\u51d1\u7684Transformer\u67b6\u6784\uff0c\u5728\u5355GPU\u4e0a\u8bad\u7ec3\u4ee5\u4fdd\u62a4\u6838\u64cd\u4f5c\u4e2d\u7684\u654f\u611f\u6570\u636e\u3002\u5c3d\u7ba1\u6570\u636e\u96c6\u8f83\u5c0f\uff0c\u6a21\u578b\u80fd\u6355\u6349\u4e13\u4e1a\u6838\u8bcd\u6c47\uff0c\u4f46\u751f\u6210\u6587\u672c\u6709\u65f6\u7f3a\u4e4f\u8bed\u6cd5\u8fde\u8d2f\u6027\u3002", "motivation": "\u5f00\u53d1\u4e00\u79cd\u7b26\u5408\u4e25\u683c\u7f51\u7edc\u5b89\u5168\u548c\u6570\u636e\u4fdd\u5bc6\u6807\u51c6\u7684\u5185\u90e8LLM\u89e3\u51b3\u65b9\u6848\uff0c\u4e13\u6ce8\u4e8e\u6838\u9886\u57df\u5185\u5bb9\u3002", "method": "\u57fa\u4e8eTransformer\u67b6\u6784\uff0c\u4f7f\u7528\u5355GPU\u8bad\u7ec3\uff0c\u6570\u636e\u6765\u6e90\u4e8eEssential CANDU\u6559\u6750\u3002", "result": "\u6a21\u578b\u80fd\u6355\u6349\u4e13\u4e1a\u6838\u8bcd\u6c47\uff0c\u4f46\u751f\u6210\u6587\u672c\u6709\u65f6\u7f3a\u4e4f\u8bed\u6cd5\u8fde\u8d2f\u6027\uff0c\u521d\u6b65\u5c55\u793a\u4e86\u5728\u4e13\u4e1a\u4efb\u52a1\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "\u672a\u6765\u9700\u6269\u5c55\u6570\u636e\u96c6\u3001\u4f18\u5316\u9884\u5904\u7406\u548c\u6307\u4ee4\u5fae\u8c03\uff0c\u4ee5\u63d0\u5347\u9886\u57df\u51c6\u786e\u6027\uff0c\u5e76\u8bc4\u4f30\u6a21\u578b\u5728\u6838\u9886\u57df\u5b9e\u9645\u5e94\u7528\u7684\u51c6\u5907\u5ea6\u3002"}}
{"id": "2506.08749", "pdf": "https://arxiv.org/pdf/2506.08749", "abs": "https://arxiv.org/abs/2506.08749", "authors": ["Viktoria Patapovich", "Mo Kordzanganeh", "Alexey Melnikov"], "title": "Superposed Parameterised Quantum Circuits", "categories": ["quant-ph", "cs.ET", "cs.LG", "cs.NE"], "comment": "20 pages, 6 figures, 3 tables", "summary": "Quantum machine learning has shown promise for high-dimensional data\nanalysis, yet many existing approaches rely on linear unitary operations and\nshared trainable parameters across outputs. These constraints limit\nexpressivity and scalability relative to the multi-layered, non-linear\narchitectures of classical deep networks. We introduce superposed parameterised\nquantum circuits to overcome these limitations. By combining flip-flop quantum\nrandom-access memory with repeat-until-success protocols, a superposed\nparameterised quantum circuit embeds an exponential number of parameterised\nsub-models in a single circuit and induces polynomial activation functions\nthrough amplitude transformations and post-selection. We provide an analytic\ndescription of the architecture, showing how multiple parameter sets are\ntrained in parallel while non-linear amplitude transformations broaden\nrepresentational power beyond conventional quantum kernels. Numerical\nexperiments underscore these advantages: on a 1D step-function regression a\ntwo-qubit superposed parameterised quantum circuit cuts the mean-squared error\nby three orders of magnitude versus a parameter-matched variational baseline;\non a 2D star-shaped two-dimensional classification task, introducing a\nquadratic activation lifts accuracy to 81.4% and reduces run-to-run variance\nthree-fold. These results position superposed parameterised quantum circuits as\na hardware-efficient route toward deeper, more versatile parameterised quantum\ncircuits capable of learning complex decision boundaries.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53e0\u52a0\u53c2\u6570\u5316\u91cf\u5b50\u7535\u8def\uff0c\u901a\u8fc7\u7ed3\u5408\u91cf\u5b50\u968f\u673a\u5b58\u50a8\u548c\u91cd\u590d\u76f4\u5230\u6210\u529f\u534f\u8bae\uff0c\u5b9e\u73b0\u4e86\u6307\u6570\u7ea7\u53c2\u6570\u5316\u5b50\u6a21\u578b\u7684\u5d4c\u5165\u548c\u591a\u9879\u5f0f\u6fc0\u6d3b\u51fd\u6570\uff0c\u663e\u8457\u63d0\u5347\u4e86\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u7684\u8868\u8fbe\u80fd\u529b\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u73b0\u6709\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u53d7\u9650\u4e8e\u7ebf\u6027\u9149\u64cd\u4f5c\u548c\u5171\u4eab\u53ef\u8bad\u7ec3\u53c2\u6570\uff0c\u8868\u8fbe\u80fd\u529b\u548c\u53ef\u6269\u5c55\u6027\u4e0d\u8db3\uff0c\u65e0\u6cd5\u4e0e\u7ecf\u5178\u6df1\u5ea6\u7f51\u7edc\u7684\u591a\u5c42\u975e\u7ebf\u6027\u67b6\u6784\u76f8\u6bd4\u3002", "method": "\u7ed3\u5408\u7ffb\u8f6c\u91cf\u5b50\u968f\u673a\u5b58\u50a8\u548c\u91cd\u590d\u76f4\u5230\u6210\u529f\u534f\u8bae\uff0c\u8bbe\u8ba1\u53e0\u52a0\u53c2\u6570\u5316\u91cf\u5b50\u7535\u8def\uff0c\u5d4c\u5165\u6307\u6570\u7ea7\u53c2\u6570\u5316\u5b50\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u632f\u5e45\u53d8\u6362\u548c\u540e\u9009\u62e9\u5b9e\u73b0\u591a\u9879\u5f0f\u6fc0\u6d3b\u51fd\u6570\u3002", "result": "\u57281D\u9636\u8dc3\u51fd\u6570\u56de\u5f52\u4efb\u52a1\u4e2d\uff0c\u8bef\u5dee\u964d\u4f4e\u4e86\u4e09\u4e2a\u6570\u91cf\u7ea7\uff1b\u57282D\u661f\u5f62\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u51c6\u786e\u7387\u63d0\u5347\u81f381.4%\uff0c\u65b9\u5dee\u964d\u4f4e\u4e09\u500d\u3002", "conclusion": "\u53e0\u52a0\u53c2\u6570\u5316\u91cf\u5b50\u7535\u8def\u4e3a\u786c\u4ef6\u9ad8\u6548\u7684\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\uff0c\u80fd\u591f\u5b66\u4e60\u590d\u6742\u51b3\u7b56\u8fb9\u754c\u3002"}}
{"id": "2506.08757", "pdf": "https://arxiv.org/pdf/2506.08757", "abs": "https://arxiv.org/abs/2506.08757", "authors": ["Mishca de Costa", "Muhammad Anwar", "Dave Mercier", "Mark Randall", "Issam Hammad"], "title": "Enhancing Accuracy and Maintainability in Nuclear Plant Data Retrieval: A Function-Calling LLM Approach Over NL-to-SQL", "categories": ["cs.CL", "cs.LG"], "comment": "44th Annual CNS Conference and the 49th Annual CNS/CNA Student\n  Conference, Westin Harbour Castle Hotel, Toronto, ON, Canada, June 8-11, 2025", "summary": "Retrieving operational data from nuclear power plants requires exceptional\naccuracy and transparency due to the criticality of the decisions it supports.\nTraditionally, natural language to SQL (NL-to-SQL) approaches have been\nexplored for querying such data. While NL-to-SQL promises ease of use, it poses\nsignificant risks: end-users cannot easily validate generated SQL queries, and\nlegacy nuclear plant databases -- often complex and poorly structured --\ncomplicate query generation due to decades of incremental modifications. These\nchallenges increase the likelihood of inaccuracies and reduce trust in the\napproach. In this work, we propose an alternative paradigm: leveraging\nfunction-calling large language models (LLMs) to address these challenges.\nInstead of directly generating SQL queries, we define a set of pre-approved,\npurpose-specific functions representing common use cases. Queries are processed\nby invoking these functions, which encapsulate validated SQL logic. This hybrid\napproach mitigates the risks associated with direct NL-to-SQL translations by\nensuring that SQL queries are reviewed and optimized by experts before\ndeployment. While this strategy introduces the upfront cost of developing and\nmaintaining the function library, we demonstrate how NL-to-SQL tools can assist\nin the initial generation of function code, allowing experts to focus on\nvalidation rather than creation. Our study includes a performance comparison\nbetween direct NL-to-SQL generation and the proposed function-based approach,\nhighlighting improvements in accuracy and maintainability. This work\nunderscores the importance of balancing user accessibility with operational\nsafety and provides a novel, actionable framework for robust data retrieval in\ncritical systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u51fd\u6570\u8c03\u7528\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u66ff\u4ee3\u4f20\u7edf\u81ea\u7136\u8bed\u8a00\u8f6cSQL\uff08NL-to-SQL\uff09\u7684\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u6838\u7535\u7ad9\u6570\u636e\u68c0\u7d22\u7684\u51c6\u786e\u6027\u548c\u5b89\u5168\u6027\u3002", "motivation": "\u4f20\u7edfNL-to-SQL\u65b9\u6cd5\u5728\u6838\u7535\u7ad9\u7b49\u5173\u952e\u7cfb\u7edf\u4e2d\u5b58\u5728\u9a8c\u8bc1\u56f0\u96be\u548c\u51c6\u786e\u6027\u98ce\u9669\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u5b89\u5168\u53ef\u9760\u7684\u6570\u636e\u68c0\u7d22\u65b9\u5f0f\u3002", "method": "\u901a\u8fc7\u9884\u5b9a\u4e49\u4e00\u7ec4\u7ecf\u8fc7\u5ba1\u6838\u7684\u4e13\u7528\u51fd\u6570\uff0c\u5c01\u88c5\u5df2\u9a8c\u8bc1\u7684SQL\u903b\u8f91\uff0c\u907f\u514d\u76f4\u63a5\u751f\u6210SQL\u67e5\u8be2\uff0c\u540c\u65f6\u5229\u7528NL-to-SQL\u5de5\u5177\u8f85\u52a9\u751f\u6210\u51fd\u6570\u4ee3\u7801\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u57fa\u4e8e\u51fd\u6570\u7684\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u53ef\u7ef4\u62a4\u6027\u4e0a\u4f18\u4e8e\u76f4\u63a5NL-to-SQL\u751f\u6210\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5e73\u8861\u7528\u6237\u6613\u7528\u6027\u4e0e\u64cd\u4f5c\u5b89\u5168\u6027\u7684\u65b0\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u5173\u952e\u7cfb\u7edf\u7684\u6570\u636e\u68c0\u7d22\u3002"}}
{"id": "2506.08762", "pdf": "https://arxiv.org/pdf/2506.08762", "abs": "https://arxiv.org/abs/2506.08762", "authors": ["Issa Sugiura", "Takashi Ishida", "Taro Makino", "Chieko Tazuke", "Takanori Nakagawa", "Kosuke Nakago", "David Ha"], "title": "EDINET-Bench: Evaluating LLMs on Complex Financial Tasks using Japanese Financial Statements", "categories": ["q-fin.ST", "cs.CE", "cs.CL", "cs.LG"], "comment": null, "summary": "Financial analysis presents complex challenges that could leverage large\nlanguage model (LLM) capabilities. However, the scarcity of challenging\nfinancial datasets, particularly for Japanese financial data, impedes academic\ninnovation in financial analytics. As LLMs advance, this lack of accessible\nresearch resources increasingly hinders their development and evaluation in\nthis specialized domain. To address this gap, we introduce EDINET-Bench, an\nopen-source Japanese financial benchmark designed to evaluate the performance\nof LLMs on challenging financial tasks including accounting fraud detection,\nearnings forecasting, and industry prediction. EDINET-Bench is constructed by\ndownloading annual reports from the past 10 years from Japan's Electronic\nDisclosure for Investors' NETwork (EDINET) and automatically assigning labels\ncorresponding to each evaluation task. Our experiments reveal that even\nstate-of-the-art LLMs struggle, performing only slightly better than logistic\nregression in binary classification for fraud detection and earnings\nforecasting. These results highlight significant challenges in applying LLMs to\nreal-world financial applications and underscore the need for domain-specific\nadaptation. Our dataset, benchmark construction code, and evaluation code is\npublicly available to facilitate future research in finance with LLMs.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86EDINET-Bench\uff0c\u4e00\u4e2a\u5f00\u6e90\u65e5\u672c\u91d1\u878d\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u91d1\u878d\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5f53\u524dLLM\u5728\u91d1\u878d\u9886\u57df\u7684\u5e94\u7528\u4ecd\u9762\u4e34\u6311\u6218\u3002", "motivation": "\u65e5\u672c\u91d1\u878d\u6570\u636e\u7684\u7a00\u7f3a\u6027\u963b\u788d\u4e86\u91d1\u878d\u5206\u6790\u9886\u57df\u7684\u5b66\u672f\u521b\u65b0\uff0c\u5c24\u5176\u662fLLM\u5728\u91d1\u878d\u9886\u57df\u7684\u5e94\u7528\u548c\u53d1\u5c55\u3002", "method": "\u901a\u8fc7\u4ece\u65e5\u672cEDINET\u7cfb\u7edf\u4e0b\u8f7d\u8fc7\u53bb10\u5e74\u7684\u5e74\u62a5\uff0c\u81ea\u52a8\u6807\u6ce8\u4efb\u52a1\u6807\u7b7e\uff0c\u6784\u5efaEDINET-Bench\u6570\u636e\u96c6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5373\u4f7f\u662f\u5148\u8fdb\u7684LLM\u5728\u6b3a\u8bc8\u68c0\u6d4b\u548c\u76c8\u5229\u9884\u6d4b\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u4ec5\u7565\u4f18\u4e8e\u903b\u8f91\u56de\u5f52\u3002", "conclusion": "LLM\u5728\u91d1\u878d\u9886\u57df\u7684\u5b9e\u9645\u5e94\u7528\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u9886\u57df\u7279\u5b9a\u7684\u9002\u5e94\uff0cEDINET-Bench\u7684\u5f00\u6e90\u5c06\u4fc3\u8fdb\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2506.08771", "pdf": "https://arxiv.org/pdf/2506.08771", "abs": "https://arxiv.org/abs/2506.08771", "authors": ["Yuni Susanti", "Michael F\u00e4rber"], "title": "Paths to Causality: Finding Informative Subgraphs Within Knowledge Graphs for Knowledge-Based Causal Discovery", "categories": ["cs.AI", "cs.CL", "cs.IR", "cs.LG"], "comment": "Accepted at KDD 2025 (full research paper)", "summary": "Inferring causal relationships between variable pairs is crucial for\nunderstanding multivariate interactions in complex systems. Knowledge-based\ncausal discovery -- which involves inferring causal relationships by reasoning\nover the metadata of variables (e.g., names or textual context) -- offers a\ncompelling alternative to traditional methods that rely on observational data.\nHowever, existing methods using Large Language Models (LLMs) often produce\nunstable and inconsistent results, compromising their reliability for causal\ninference. To address this, we introduce a novel approach that integrates\nKnowledge Graphs (KGs) with LLMs to enhance knowledge-based causal discovery.\nOur approach identifies informative metapath-based subgraphs within KGs and\nfurther refines the selection of these subgraphs using Learning-to-Rank-based\nmodels. The top-ranked subgraphs are then incorporated into zero-shot prompts,\nimproving the effectiveness of LLMs in inferring the causal relationship.\nExtensive experiments on biomedical and open-domain datasets demonstrate that\nour method outperforms most baselines by up to 44.4 points in F1 scores,\nevaluated across diverse LLMs and KGs. Our code and datasets are available on\nGitHub: https://github.com/susantiyuni/path-to-causality", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u77e5\u8bc6\u56fe\u8c31\uff08KGs\uff09\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u63d0\u5347\u57fa\u4e8e\u77e5\u8bc6\u7684\u56e0\u679c\u53d1\u73b0\uff0c\u89e3\u51b3\u4e86\u73b0\u6709LLM\u65b9\u6cd5\u7684\u4e0d\u7a33\u5b9a\u6027\u548c\u4e0d\u4e00\u81f4\u6027\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u89c2\u6d4b\u6570\u636e\u7684\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u800c\u57fa\u4e8e\u77e5\u8bc6\u7684\u56e0\u679c\u53d1\u73b0\uff08\u5229\u7528\u53d8\u91cf\u5143\u6570\u636e\uff09\u662f\u4e00\u79cd\u6709\u6f5c\u529b\u7684\u66ff\u4ee3\u65b9\u6848\u3002\u7136\u800c\uff0c\u73b0\u6709LLM\u65b9\u6cd5\u7684\u7ed3\u679c\u4e0d\u7a33\u5b9a\u4e14\u4e0d\u4e00\u81f4\uff0c\u5f71\u54cd\u4e86\u53ef\u9760\u6027\u3002", "method": "\u901a\u8fc7\u77e5\u8bc6\u56fe\u8c31\u8bc6\u522b\u4fe1\u606f\u4e30\u5bcc\u7684\u5143\u8def\u5f84\u5b50\u56fe\uff0c\u5e76\u5229\u7528\u5b66\u4e60\u6392\u5e8f\u6a21\u578b\u4f18\u5316\u5b50\u56fe\u9009\u62e9\uff0c\u5c06\u6392\u540d\u9760\u524d\u7684\u5b50\u56fe\u878d\u5165\u96f6\u6837\u672c\u63d0\u793a\u4e2d\uff0c\u63d0\u5347LLM\u7684\u56e0\u679c\u63a8\u7406\u80fd\u529b\u3002", "result": "\u5728\u751f\u7269\u533b\u5b66\u548c\u5f00\u653e\u9886\u57df\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728F1\u5206\u6570\u4e0a\u6bd4\u5927\u591a\u6570\u57fa\u7ebf\u65b9\u6cd5\u9ad8\u51fa44.4\u5206\uff0c\u4e14\u9002\u7528\u4e8e\u591a\u79cdLLM\u548cKG\u3002", "conclusion": "\u7ed3\u5408KGs\u548cLLMs\u7684\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u57fa\u4e8e\u77e5\u8bc6\u7684\u56e0\u679c\u53d1\u73b0\u7684\u6027\u80fd\u548c\u53ef\u9760\u6027\uff0c\u4e3a\u590d\u6742\u7cfb\u7edf\u4e2d\u7684\u56e0\u679c\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.08780", "pdf": "https://arxiv.org/pdf/2506.08780", "abs": "https://arxiv.org/abs/2506.08780", "authors": ["Isaac Corley", "Lakshay Sharma", "Ruth Crasto"], "title": "Landsat-Bench: Datasets and Benchmarks for Landsat Foundation Models", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "The Landsat program offers over 50 years of globally consistent Earth\nimagery. However, the lack of benchmarks for this data constrains progress\ntowards Landsat-based Geospatial Foundation Models (GFM). In this paper, we\nintroduce Landsat-Bench, a suite of three benchmarks with Landsat imagery that\nadapt from existing remote sensing datasets -- EuroSAT-L, BigEarthNet-L, and\nLC100-L. We establish baseline and standardized evaluation methods across both\ncommon architectures and Landsat foundation models pretrained on the SSL4EO-L\ndataset. Notably, we provide evidence that SSL4EO-L pretrained GFMs extract\nbetter representations for downstream tasks in comparison to ImageNet,\nincluding performance gains of +4% OA and +5.1% mAP on EuroSAT-L and\nBigEarthNet-L.", "AI": {"tldr": "Landsat-Bench\u662f\u4e00\u5957\u57fa\u4e8eLandsat\u5f71\u50cf\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542bEuroSAT-L\u3001BigEarthNet-L\u548cLC100-L\uff0c\u7528\u4e8e\u8bc4\u4f30\u5730\u7406\u7a7a\u95f4\u57fa\u7840\u6a21\u578b\uff08GFM\uff09\u7684\u6027\u80fd\u3002", "motivation": "Landsat\u6570\u636e\u7f3a\u4e4f\u6807\u51c6\u5316\u57fa\u51c6\uff0c\u9650\u5236\u4e86\u57fa\u4e8eLandsat\u7684\u5730\u7406\u7a7a\u95f4\u57fa\u7840\u6a21\u578b\u7684\u53d1\u5c55\u3002", "method": "\u901a\u8fc7Landsat-Bench\u7684\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4f7f\u7528SSL4EO-L\u9884\u8bad\u7ec3\u7684GFM\u4e0e\u5e38\u89c1\u67b6\u6784\u8fdb\u884c\u5bf9\u6bd4\u8bc4\u4f30\u3002", "result": "SSL4EO-L\u9884\u8bad\u7ec3\u7684GFM\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8eImageNet\uff0c\u6027\u80fd\u63d0\u5347\u5206\u522b\u4e3a+4% OA\u548c+5.1% mAP\u3002", "conclusion": "Landsat-Bench\u4e3aLandsat\u6570\u636e\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5e76\u9a8c\u8bc1\u4e86SSL4EO-L\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2506.08783", "pdf": "https://arxiv.org/pdf/2506.08783", "abs": "https://arxiv.org/abs/2506.08783", "authors": ["Lukas Kammerer", "Deaglan J. Bartlett", "Gabriel Kronberger", "Harry Desmond", "Pedro G. Ferreira"], "title": "syren-baryon: Analytic emulators for the impact of baryons on the matter power spectrum", "categories": ["astro-ph.CO", "astro-ph.GA", "astro-ph.IM", "cs.LG", "cs.NE"], "comment": "14 pages, 6 figures. Submitted to A&A", "summary": "Baryonic physics has a considerable impact on the distribution of matter in\nour Universe on scales probed by current and future cosmological surveys,\nacting as a key systematic in such analyses. We seek simple symbolic\nparametrisations for the impact of baryonic physics on the matter power\nspectrum for a range of physically motivated models, as a function of\nwavenumber, redshift, cosmology, and parameters controlling the baryonic\nfeedback. We use symbolic regression to construct analytic approximations for\nthe ratio of the matter power spectrum in the presence of baryons to that\nwithout such effects. We obtain separate functions of each of four distinct\nsub-grid prescriptions of baryonic physics from the CAMELS suite of\nhydrodynamical simulations (Astrid, IllustrisTNG, SIMBA and Swift-EAGLE) as\nwell as for a baryonification algorithm. We also provide functions which\ndescribe the uncertainty on these predictions, due to both the stochastic\nnature of baryonic physics and the errors on our fits. The error on our\napproximations to the hydrodynamical simulations is comparable to the sample\nvariance estimated through varying initial conditions, and our baryonification\nexpression has a root mean squared error of better than one percent, although\nthis increases on small scales. These errors are comparable to those of\nprevious numerical emulators for these models. Our expressions are enforced to\nhave the physically correct behaviour on large scales and at high redshift. Due\nto their analytic form, we are able to directly interpret the impact of varying\ncosmology and feedback parameters, and we can identify parameters which have\nlittle to no effect. Each function is based on a different implementation of\nbaryonic physics, and can therefore be used to discriminate between these\nmodels when applied to real data. We provide publicly available code for all\nsymbolic approximations found.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u7b26\u53f7\u56de\u5f52\u65b9\u6cd5\uff0c\u6784\u5efa\u4e86\u63cf\u8ff0\u91cd\u5b50\u7269\u7406\u5bf9\u7269\u8d28\u529f\u7387\u8c31\u5f71\u54cd\u7684\u89e3\u6790\u8fd1\u4f3c\u51fd\u6570\uff0c\u5e76\u63d0\u4f9b\u4e86\u8bef\u5dee\u4f30\u8ba1\u3002\u8fd9\u4e9b\u51fd\u6570\u53ef\u7528\u4e8e\u533a\u5206\u4e0d\u540c\u91cd\u5b50\u7269\u7406\u6a21\u578b\u3002", "motivation": "\u91cd\u5b50\u7269\u7406\u5bf9\u5b87\u5b99\u7269\u8d28\u5206\u5e03\u6709\u663e\u8457\u5f71\u54cd\uff0c\u662f\u5f53\u524d\u548c\u672a\u6765\u5b87\u5b99\u5b66\u8c03\u67e5\u4e2d\u7684\u5173\u952e\u7cfb\u7edf\u8bef\u5dee\u6765\u6e90\u3002\u7814\u7a76\u65e8\u5728\u627e\u5230\u7b80\u5355\u7b26\u53f7\u53c2\u6570\u5316\u65b9\u6cd5\uff0c\u91cf\u5316\u91cd\u5b50\u7269\u7406\u5bf9\u7269\u8d28\u529f\u7387\u8c31\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u7b26\u53f7\u56de\u5f52\u65b9\u6cd5\uff0c\u57fa\u4e8eCAMELS\u6d41\u4f53\u52a8\u529b\u5b66\u6a21\u62df\u6570\u636e\uff08\u5305\u62ecAstrid\u3001IllustrisTNG\u3001SIMBA\u548cSwift-EAGLE\uff09\u4ee5\u53ca\u91cd\u5b50\u5316\u7b97\u6cd5\uff0c\u6784\u5efa\u89e3\u6790\u8fd1\u4f3c\u51fd\u6570\u3002", "result": "\u5f97\u5230\u7684\u8fd1\u4f3c\u51fd\u6570\u8bef\u5dee\u4e0e\u6837\u672c\u65b9\u5dee\u76f8\u5f53\uff0c\u91cd\u5b50\u5316\u8868\u8fbe\u5f0f\u7684\u5747\u65b9\u6839\u8bef\u5dee\u4f4e\u4e8e1%\u3002\u51fd\u6570\u5177\u6709\u7269\u7406\u6b63\u786e\u7684\u5927\u5c3a\u5ea6\u548c\u9ad8\u7ea2\u79fb\u884c\u4e3a\u3002", "conclusion": "\u89e3\u6790\u5f62\u5f0f\u7684\u51fd\u6570\u53ef\u76f4\u63a5\u89e3\u91ca\u5b87\u5b99\u5b66\u548c\u53cd\u9988\u53c2\u6570\u7684\u5f71\u54cd\uff0c\u5e76\u533a\u5206\u4e0d\u540c\u91cd\u5b50\u7269\u7406\u6a21\u578b\u3002\u6240\u6709\u7b26\u53f7\u8fd1\u4f3c\u4ee3\u7801\u5df2\u516c\u5f00\u3002"}}
{"id": "2506.08860", "pdf": "https://arxiv.org/pdf/2506.08860", "abs": "https://arxiv.org/abs/2506.08860", "authors": ["Samah Kansab", "Francis Bordeleau", "Ali Tizghadam"], "title": "On The Impact of Merge Request Deviations on Code Review Practices", "categories": ["cs.SE", "cs.AI", "cs.LG"], "comment": null, "summary": "Code review is a key practice in software engineering, ensuring quality and\ncollaboration. However, industrial Merge Request (MR) workflows often deviate\nfrom standardized review processes, with many MRs serving non-review purposes\n(e.g., drafts, rebases, or dependency updates). We term these cases deviations\nand hypothesize that ignoring them biases analytics and undermines ML models\nfor review analysis.\n  We identify seven deviation categories, occurring in 37.02% of MRs, and\npropose a few-shot learning detection method (91% accuracy). By excluding\ndeviations, ML models predicting review completion time improve performance in\n53.33% of cases (up to 2.25x) and exhibit significant shifts in feature\nimportance (47% overall, 60% top-*k*).\n  Our contributions include: (1) a taxonomy of MR deviations, (2) an AI-driven\ndetection approach, and (3) empirical evidence of their impact on ML-based\nreview analytics. This work aids practitioners in optimizing review efforts and\nensuring reliable insights.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u4ee3\u7801\u5ba1\u67e5\u4e2d\u7684\u504f\u5dee\u73b0\u8c61\uff0c\u63d0\u51fa\u4e86\u5206\u7c7b\u548c\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5e76\u8bc1\u660e\u6392\u9664\u504f\u5dee\u80fd\u63d0\u5347\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u5de5\u4e1a\u4e2d\u7684\u5408\u5e76\u8bf7\u6c42\uff08MR\uff09\u6d41\u7a0b\u5e38\u504f\u79bb\u6807\u51c6\u5ba1\u67e5\u6d41\u7a0b\uff0c\u8bb8\u591aMR\u7528\u4e8e\u975e\u5ba1\u67e5\u76ee\u7684\uff0c\u5ffd\u7565\u8fd9\u4e9b\u504f\u5dee\u4f1a\u5f71\u54cd\u5206\u6790\u548c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u51c6\u786e\u6027\u3002", "method": "\u8bc6\u522b\u4e86\u4e03\u7c7b\u504f\u5dee\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5c11\u6837\u672c\u5b66\u4e60\u68c0\u6d4b\u65b9\u6cd5\uff08\u51c6\u786e\u738791%\uff09\uff0c\u5e76\u9a8c\u8bc1\u4e86\u6392\u9664\u504f\u5dee\u5bf9\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u6539\u8fdb\u6548\u679c\u3002", "result": "\u504f\u5dee\u51fa\u73b0\u572837.02%\u7684MR\u4e2d\uff0c\u6392\u9664\u540e\u673a\u5668\u5b66\u4e60\u6a21\u578b\u572853.33%\u7684\u60c5\u51b5\u4e0b\u6027\u80fd\u63d0\u5347\uff08\u6700\u9ad82.25\u500d\uff09\uff0c\u7279\u5f81\u91cd\u8981\u6027\u663e\u8457\u53d8\u5316\uff08\u6574\u4f5347%\uff0ctop-k 60%\uff09\u3002", "conclusion": "\u7814\u7a76\u8d21\u732e\u5305\u62ec\u504f\u5dee\u5206\u7c7b\u3001AI\u68c0\u6d4b\u65b9\u6cd5\u53ca\u5bf9\u673a\u5668\u5b66\u4e60\u5206\u6790\u5f71\u54cd\u7684\u5b9e\u8bc1\uff0c\u5e2e\u52a9\u4f18\u5316\u5ba1\u67e5\u6d41\u7a0b\u548c\u786e\u4fdd\u53ef\u9760\u5206\u6790\u3002"}}
{"id": "2506.08862", "pdf": "https://arxiv.org/pdf/2506.08862", "abs": "https://arxiv.org/abs/2506.08862", "authors": ["Zike Wu", "Qi Yan", "Xuanyu Yi", "Lele Wang", "Renjie Liao"], "title": "StreamSplat: Towards Online Dynamic 3D Reconstruction from Uncalibrated Video Streams", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Real-time reconstruction of dynamic 3D scenes from uncalibrated video streams\nis crucial for numerous real-world applications. However, existing methods\nstruggle to jointly address three key challenges: 1) processing uncalibrated\ninputs in real time, 2) accurately modeling dynamic scene evolution, and 3)\nmaintaining long-term stability and computational efficiency. To this end, we\nintroduce StreamSplat, the first fully feed-forward framework that transforms\nuncalibrated video streams of arbitrary length into dynamic 3D Gaussian\nSplatting (3DGS) representations in an online manner, capable of recovering\nscene dynamics from temporally local observations. We propose two key technical\ninnovations: a probabilistic sampling mechanism in the static encoder for 3DGS\nposition prediction, and a bidirectional deformation field in the dynamic\ndecoder that enables robust and efficient dynamic modeling. Extensive\nexperiments on static and dynamic benchmarks demonstrate that StreamSplat\nconsistently outperforms prior works in both reconstruction quality and dynamic\nscene modeling, while uniquely supporting online reconstruction of arbitrarily\nlong video streams. Code and models are available at\nhttps://github.com/nickwzk/StreamSplat.", "AI": {"tldr": "StreamSplat\u662f\u4e00\u4e2a\u5b9e\u65f6\u4ece\u65e0\u6807\u5b9a\u89c6\u9891\u6d41\u91cd\u5efa\u52a8\u60013D\u573a\u666f\u7684\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u5b9e\u65f6\u5904\u7406\u3001\u52a8\u6001\u5efa\u6a21\u548c\u957f\u671f\u7a33\u5b9a\u6027\u7684\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u5904\u7406\u65e0\u6807\u5b9a\u8f93\u5165\u3001\u52a8\u6001\u573a\u666f\u5efa\u6a21\u548c\u957f\u671f\u7a33\u5b9a\u6027\uff0cStreamSplat\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u9759\u6001\u7f16\u7801\u5668\u4e2d\u7684\u6982\u7387\u91c7\u6837\u673a\u5236\u548c\u52a8\u6001\u89e3\u7801\u5668\u4e2d\u7684\u53cc\u5411\u53d8\u5f62\u573a\uff0c\u7528\u4e8e\u5b9e\u65f6\u52a8\u60013D\u9ad8\u65af\u6cfc\u6e85\u8868\u793a\u3002", "result": "\u5728\u9759\u6001\u548c\u52a8\u6001\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u652f\u6301\u4efb\u610f\u957f\u5ea6\u89c6\u9891\u6d41\u7684\u5728\u7ebf\u91cd\u5efa\u3002", "conclusion": "StreamSplat\u5728\u91cd\u5efa\u8d28\u91cf\u548c\u52a8\u6001\u573a\u666f\u5efa\u6a21\u65b9\u9762\u5177\u6709\u4f18\u52bf\uff0c\u4e14\u652f\u6301\u5b9e\u65f6\u5904\u7406\u3002"}}
{"id": "2506.08885", "pdf": "https://arxiv.org/pdf/2506.08885", "abs": "https://arxiv.org/abs/2506.08885", "authors": ["Danush Khanna", "Krishna Kumar", "Basab Ghosh", "Vinija Jain", "Vasu Sharma", "Aman Chadha", "Amitava Das"], "title": "AdversariaL attacK sAfety aLIgnment(ALKALI): Safeguarding LLMs through GRACE: Geometric Representation-Aware Contrastive Enhancement- Introducing Adversarial Vulnerability Quality Index (AVQI)", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Adversarial threats against LLMs are escalating faster than current defenses\ncan adapt. We expose a critical geometric blind spot in alignment: adversarial\nprompts exploit latent camouflage, embedding perilously close to the safe\nrepresentation manifold while encoding unsafe intent thereby evading surface\nlevel defenses like Direct Preference Optimization (DPO), which remain blind to\nthe latent geometry. We introduce ALKALI, the first rigorously curated\nadversarial benchmark and the most comprehensive to date spanning 9,000 prompts\nacross three macro categories, six subtypes, and fifteen attack families.\nEvaluation of 21 leading LLMs reveals alarmingly high Attack Success Rates\n(ASRs) across both open and closed source models, exposing an underlying\nvulnerability we term latent camouflage, a structural blind spot where\nadversarial completions mimic the latent geometry of safe ones. To mitigate\nthis vulnerability, we introduce GRACE - Geometric Representation Aware\nContrastive Enhancement, an alignment framework coupling preference learning\nwith latent space regularization. GRACE enforces two constraints: latent\nseparation between safe and adversarial completions, and adversarial cohesion\namong unsafe and jailbreak behaviors. These operate over layerwise pooled\nembeddings guided by a learned attention profile, reshaping internal geometry\nwithout modifying the base model, and achieve up to 39% ASR reduction.\nMoreover, we introduce AVQI, a geometry aware metric that quantifies latent\nalignment failure via cluster separation and compactness. AVQI reveals when\nunsafe completions mimic the geometry of safe ones, offering a principled lens\ninto how models internally encode safety. We make the code publicly available\nat https://anonymous.4open.science/r/alkali-B416/README.md.", "AI": {"tldr": "\u8bba\u6587\u63ed\u793a\u4e86LLM\u5bf9\u9f50\u4e2d\u7684\u51e0\u4f55\u76f2\u70b9\uff0c\u63d0\u51faALKALI\u57fa\u51c6\u548cGRACE\u6846\u67b6\u4ee5\u5e94\u5bf9\u6f5c\u5728\u4f2a\u88c5\u653b\u51fb\uff0c\u663e\u8457\u964d\u4f4e\u653b\u51fb\u6210\u529f\u7387\u3002", "motivation": "\u5f53\u524dLLM\u9632\u5fa1\u65e0\u6cd5\u5feb\u901f\u5e94\u5bf9\u5bf9\u6297\u6027\u5a01\u80c1\uff0c\u5c24\u5176\u662f\u6f5c\u5728\u4f2a\u88c5\u653b\u51fb\uff0c\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u548c\u5de5\u5177\u6765\u63d0\u5347\u5b89\u5168\u6027\u3002", "method": "\u63d0\u51faALKALI\u57fa\u51c6\uff08\u5305\u542b9000\u4e2a\u5bf9\u6297\u63d0\u793a\uff09\u548cGRACE\u6846\u67b6\uff08\u7ed3\u5408\u504f\u597d\u5b66\u4e60\u548c\u6f5c\u5728\u7a7a\u95f4\u6b63\u5219\u5316\uff09\uff0c\u5e76\u5f15\u5165AVQI\u5ea6\u91cf\u6f5c\u5728\u5bf9\u9f50\u5931\u8d25\u3002", "result": "\u8bc4\u4f3021\u4e2aLLM\u663e\u793a\u9ad8\u653b\u51fb\u6210\u529f\u7387\uff0cGRACE\u6846\u67b6\u53ef\u964d\u4f4e39%\u7684\u653b\u51fb\u6210\u529f\u7387\u3002", "conclusion": "GRACE\u548cAVQI\u4e3aLLM\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\uff0c\u63ed\u793a\u4e86\u6f5c\u5728\u4f2a\u88c5\u653b\u51fb\u7684\u6f0f\u6d1e\u3002"}}
{"id": "2506.08893", "pdf": "https://arxiv.org/pdf/2506.08893", "abs": "https://arxiv.org/abs/2506.08893", "authors": ["Kai Zhou", "Youbiao He", "Chong Zhong", "Yifu Wu"], "title": "Real-Time Cascade Mitigation in Power Systems Using Influence Graph Improved by Reinforcement Learning", "categories": ["physics.soc-ph", "cs.LG", "physics.data-an"], "comment": null, "summary": "Despite high reliability, modern power systems with growing renewable\npenetration face an increasing risk of cascading outages. Real-time cascade\nmitigation requires fast, complex operational decisions under uncertainty. In\nthis work, we extend the influence graph into a Markov decision process model\n(MDP) for real-time mitigation of cascading outages in power transmission\nsystems, accounting for uncertainties in generation, load, and initial\ncontingencies. The MDP includes a do-nothing action to allow for conservative\ndecision-making and is solved using reinforcement learning. We present a policy\ngradient learning algorithm initialized with a policy corresponding to the\nunmitigated case and designed to handle invalid actions. The proposed learning\nmethod converges faster than the conventional algorithm. Through careful reward\ndesign, we learn a policy that takes conservative actions without deteriorating\nsystem conditions. The model is validated on the IEEE 14-bus and IEEE 118-bus\nsystems. The results show that proactive line disconnections can effectively\nreduce cascading risk, and certain lines consistently emerge as critical in\nmitigating cascade propagation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08MDP\uff09\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5b9e\u65f6\u7f13\u89e3\u7535\u529b\u4f20\u8f93\u7cfb\u7edf\u4e2d\u7684\u7ea7\u8054\u505c\u7535\u98ce\u9669\uff0c\u8003\u8651\u4e86\u53d1\u7535\u3001\u8d1f\u8377\u548c\u521d\u59cb\u6545\u969c\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "motivation": "\u73b0\u4ee3\u7535\u529b\u7cfb\u7edf\u5c3d\u7ba1\u53ef\u9760\u6027\u9ad8\uff0c\u4f46\u968f\u7740\u53ef\u518d\u751f\u80fd\u6e90\u6e17\u900f\u7387\u7684\u589e\u52a0\uff0c\u7ea7\u8054\u505c\u7535\u98ce\u9669\u4e0a\u5347\uff0c\u9700\u8981\u5feb\u901f\u4e14\u590d\u6742\u7684\u5b9e\u65f6\u51b3\u7b56\u3002", "method": "\u5c06\u5f71\u54cd\u56fe\u6269\u5c55\u4e3aMDP\u6a21\u578b\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\uff08\u5c24\u5176\u662f\u7b56\u7565\u68af\u5ea6\u7b97\u6cd5\uff09\u8fdb\u884c\u6c42\u89e3\uff0c\u8bbe\u8ba1\u4e86\u4fdd\u5b88\u51b3\u7b56\u673a\u5236\u548c\u5956\u52b1\u51fd\u6570\u3002", "result": "\u5728IEEE 14\u603b\u7ebf\u548c118\u603b\u7ebf\u7cfb\u7edf\u4e0a\u7684\u9a8c\u8bc1\u8868\u660e\uff0c\u4e3b\u52a8\u65ad\u5f00\u67d0\u4e9b\u7ebf\u8def\u53ef\u6709\u6548\u964d\u4f4e\u7ea7\u8054\u98ce\u9669\uff0c\u5e76\u8bc6\u522b\u51fa\u5173\u952e\u7ebf\u8def\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u5feb\u901f\u6536\u655b\u4e14\u4fdd\u5b88\u51b3\u7b56\uff0c\u4e3a\u7535\u529b\u7cfb\u7edf\u7ea7\u8054\u505c\u7535\u7684\u5b9e\u65f6\u7f13\u89e3\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2506.08911", "pdf": "https://arxiv.org/pdf/2506.08911", "abs": "https://arxiv.org/abs/2506.08911", "authors": ["Petar Jaku\u0161", "Hrvoje D\u017eapo"], "title": "Implementing Keyword Spotting on the MCUX947 Microcontroller with Integrated NPU", "categories": ["cs.HC", "cs.LG", "cs.SD"], "comment": "4 pages", "summary": "This paper presents a keyword spotting (KWS) system implemented on the NXP\nMCXN947 microcontroller with an integrated Neural Processing Unit (NPU),\nenabling real-time voice interaction on resource-constrained devices. The\nsystem combines MFCC feature extraction with a CNN classifier, optimized using\nQuantization Aware Training to reduce model size with minimal accuracy drop.\nExperimental results demonstrate a 59x speedup in inference time when\nleveraging the NPU compared to CPU-only execution, achieving 97.06% accuracy\nwith a model size of 30.58 KB, demonstrating the feasibility of efficient,\nlow-power voice interfaces on embedded platforms.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u5728NXP MCXN947\u5fae\u63a7\u5236\u5668\u4e0a\u5b9e\u73b0\u7684\u5173\u952e\u8bcd\u68c0\u6d4b\u7cfb\u7edf\uff0c\u5229\u7528\u96c6\u6210\u7684\u795e\u7ecf\u5904\u7406\u5355\u5143\uff08NPU\uff09\u5b9e\u73b0\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u7684\u5b9e\u65f6\u8bed\u97f3\u4ea4\u4e92\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u5728\u8d44\u6e90\u53d7\u9650\u7684\u5d4c\u5165\u5f0f\u8bbe\u5907\u4e0a\u5b9e\u73b0\u9ad8\u6548\u7684\u5b9e\u65f6\u8bed\u97f3\u4ea4\u4e92\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u8ba1\u7b97\u80fd\u529b\u548c\u529f\u8017\u4e0a\u7684\u9650\u5236\u3002", "method": "\u7ed3\u5408MFCC\u7279\u5f81\u63d0\u53d6\u548cCNN\u5206\u7c7b\u5668\uff0c\u5e76\u901a\u8fc7\u91cf\u5316\u611f\u77e5\u8bad\u7ec3\u4f18\u5316\u6a21\u578b\u4ee5\u51cf\u5c11\u6a21\u578b\u5927\u5c0f\uff0c\u540c\u65f6\u4fdd\u6301\u8f83\u9ad8\u51c6\u786e\u7387\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5229\u7528NPU\u76f8\u6bd4\u4ec5\u7528CPU\u5b9e\u73b0\u4e8659\u500d\u7684\u63a8\u7406\u901f\u5ea6\u63d0\u5347\uff0c\u6a21\u578b\u5927\u5c0f\u4e3a30.58 KB\uff0c\u51c6\u786e\u7387\u8fbe\u523097.06%\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u8bc1\u660e\u4e86\u5728\u5d4c\u5165\u5f0f\u5e73\u53f0\u4e0a\u5b9e\u73b0\u9ad8\u6548\u3001\u4f4e\u529f\u8017\u8bed\u97f3\u63a5\u53e3\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2506.08920", "pdf": "https://arxiv.org/pdf/2506.08920", "abs": "https://arxiv.org/abs/2506.08920", "authors": ["Zeyu Leo Liu", "Greg Durrett", "Eunsol Choi"], "title": "PropMEND: Hypernetworks for Knowledge Propagation in LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Under review", "summary": "Knowledge editing techniques for large language models (LLMs) can inject\nknowledge that is later reproducible verbatim, but they fall short on\npropagating that knowledge: models cannot answer questions that require\nreasoning with the injected knowledge. We present a hypernetwork-based approach\nfor knowledge propagation, named PropMEND, where we meta-learn how to modify\ngradients of a language modeling loss to encourage injected information to\npropagate. Our approach extends the meta-objective of MEND [29] so that\ngradient updates on knowledge are transformed to enable answering multi-hop\nquestions involving that knowledge. We show improved performance on the\nRippleEdit dataset, showing almost 2x accuracy on challenging multi-hop\nquestions whose answers are not explicitly stated in the injected fact. We\nfurther introduce a new dataset, Controlled RippleEdit, to evaluate the\ngeneralization of our hypernetwork, testing knowledge propagation along\nrelations and entities unseen during hypernetwork training. PropMEND still\noutperforms existing approaches in unseen entity-relation pairs, yet the\nperformance gap decreases substantially, suggesting future work in propagating\nknowledge to a wide range of relations.", "AI": {"tldr": "PropMEND\u662f\u4e00\u79cd\u57fa\u4e8e\u8d85\u7f51\u7edc\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5143\u5b66\u4e60\u4fee\u6539\u8bed\u8a00\u6a21\u578b\u635f\u5931\u7684\u68af\u5ea6\uff0c\u4ee5\u4fc3\u8fdb\u6ce8\u5165\u77e5\u8bc6\u7684\u4f20\u64ad\uff0c\u4ece\u800c\u89e3\u51b3\u591a\u8df3\u63a8\u7406\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u77e5\u8bc6\u7f16\u8f91\u6280\u672f\u65e0\u6cd5\u652f\u6301\u57fa\u4e8e\u6ce8\u5165\u77e5\u8bc6\u7684\u63a8\u7406\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u4fc3\u8fdb\u77e5\u8bc6\u4f20\u64ad\u3002", "method": "\u901a\u8fc7\u6269\u5c55MEND\u7684\u5143\u76ee\u6807\uff0c\u4fee\u6539\u68af\u5ea6\u66f4\u65b0\u4ee5\u652f\u6301\u591a\u8df3\u95ee\u9898\u56de\u7b54\u3002", "result": "\u5728RippleEdit\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u591a\u8df3\u95ee\u9898\u51c6\u786e\u7387\u63d0\u5347\u8fd12\u500d\uff1b\u5728\u672a\u89c1\u5b9e\u4f53\u5173\u7cfb\u5bf9\u4e0a\u4e5f\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "PropMEND\u5728\u77e5\u8bc6\u4f20\u64ad\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u672a\u89c1\u5173\u7cfb\u4e0a\u7684\u6027\u80fd\u4e0b\u964d\u8868\u660e\u672a\u6765\u9700\u8fdb\u4e00\u6b65\u4f18\u5316\u3002"}}
{"id": "2506.08935", "pdf": "https://arxiv.org/pdf/2506.08935", "abs": "https://arxiv.org/abs/2506.08935", "authors": ["Andrew Shin"], "title": "Can A Gamer Train A Mathematical Reasoning Model?", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "While large language models (LLMs) have achieved remarkable performance in\nvarious tasks including mathematical reasoning, their development typically\ndemands prohibitive computational resources. Recent advancements have reduced\ncosts for training capable models, yet even these approaches rely on high-end\nhardware clusters. In this paper, we demonstrate that a single average gaming\nGPU can train a solid mathematical reasoning model, by integrating\nreinforcement learning and memory optimization techniques. Specifically, we\ntrain a 1.5B parameter mathematical reasoning model on RTX 3080 Ti of 16GB\nmemory that achieves comparable or better performance on mathematical reasoning\nbenchmarks than models several times larger, in resource-constrained\nenvironments. Our results challenge the paradigm that state-of-the-art\nmathematical reasoning necessitates massive infrastructure, democratizing\naccess to high-performance AI research.\nhttps://github.com/shinandrew/YouronMath.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u5355\u5f20\u666e\u901a\u6e38\u620fGPU\u4e0a\u8bad\u7ec3\u9ad8\u6027\u80fd\u6570\u5b66\u63a8\u7406\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u548c\u5185\u5b58\u4f18\u5316\u6280\u672f\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u6570\u5b66\u63a8\u7406\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5176\u8bad\u7ec3\u901a\u5e38\u9700\u8981\u6602\u8d35\u7684\u8ba1\u7b97\u8d44\u6e90\u3002\u672c\u6587\u65e8\u5728\u8bc1\u660e\uff0c\u901a\u8fc7\u4f18\u5316\u6280\u672f\uff0c\u53ef\u4ee5\u5728\u8d44\u6e90\u6709\u9650\u7684\u73af\u5883\u4e2d\u9ad8\u6548\u8bad\u7ec3\u6a21\u578b\u3002", "method": "\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u548c\u5185\u5b58\u4f18\u5316\u6280\u672f\uff0c\u5728\u5355\u5f20RTX 3080 Ti\uff0816GB\u5185\u5b58\uff09\u4e0a\u8bad\u7ec3\u4e86\u4e00\u4e2a1.5B\u53c2\u6570\u7684\u6570\u5b66\u63a8\u7406\u6a21\u578b\u3002", "result": "\u8be5\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u6216\u63a5\u8fd1\u66f4\u5927\u89c4\u6a21\u7684\u6a21\u578b\uff0c\u4e14\u8d44\u6e90\u9700\u6c42\u5927\u5e45\u964d\u4f4e\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u9ad8\u6027\u80fd\u6570\u5b66\u63a8\u7406\u6a21\u578b\u65e0\u9700\u4f9d\u8d56\u5927\u89c4\u6a21\u57fa\u7840\u8bbe\u65bd\uff0c\u4e3aAI\u7814\u7a76\u7684\u666e\u53ca\u63d0\u4f9b\u4e86\u53ef\u80fd\u3002"}}
{"id": "2506.08954", "pdf": "https://arxiv.org/pdf/2506.08954", "abs": "https://arxiv.org/abs/2506.08954", "authors": ["Ruben Weitzman", "Peter M\u00f8rch Groth", "Lood Van Niekerk", "Aoi Otani", "Yarin Gal", "Debora Marks", "Pascal Notin"], "title": "Protriever: End-to-End Differentiable Protein Homology Search for Fitness Prediction", "categories": ["q-bio.QM", "cs.LG"], "comment": "Accepted at ICML 2025", "summary": "Retrieving homologous protein sequences is essential for a broad range of\nprotein modeling tasks such as fitness prediction, protein design, structure\nmodeling, and protein-protein interactions. Traditional workflows have relied\non a two-step process: first retrieving homologs via Multiple Sequence\nAlignments (MSA), then training models on one or more of these alignments.\nHowever, MSA-based retrieval is computationally expensive, struggles with\nhighly divergent sequences or complex insertions & deletions patterns, and\noperates independently of the downstream modeling objective. We introduce\nProtriever, an end-to-end differentiable framework that learns to retrieve\nrelevant homologs while simultaneously training for the target task. When\napplied to protein fitness prediction, Protriever achieves state-of-the-art\nperformance compared to sequence-based models that rely on MSA-based homolog\nretrieval, while being two orders of magnitude faster through efficient vector\nsearch. Protriever is both architecture- and task-agnostic, and can flexibly\nadapt to different retrieval strategies and protein databases at inference time\n-- offering a scalable alternative to alignment-centric approaches.", "AI": {"tldr": "Protriever\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u53ef\u5fae\u5206\u6846\u67b6\uff0c\u901a\u8fc7\u5b66\u4e60\u68c0\u7d22\u76f8\u5173\u540c\u6e90\u86cb\u767d\u5e8f\u5217\u5e76\u540c\u65f6\u4e3a\u76ee\u6807\u4efb\u52a1\u8bad\u7ec3\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfMSA\u65b9\u6cd5\u7684\u8ba1\u7b97\u6210\u672c\u9ad8\u548c\u5c40\u9650\u6027\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u7684\u57fa\u4e8eMSA\u7684\u540c\u6e90\u86cb\u767d\u5e8f\u5217\u68c0\u7d22\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u5bf9\u9ad8\u5ea6\u5206\u6b67\u5e8f\u5217\u6216\u590d\u6742\u63d2\u5165/\u5220\u9664\u6a21\u5f0f\u6548\u679c\u4e0d\u4f73\uff0c\u4e14\u4e0e\u4e0b\u6e38\u5efa\u6a21\u76ee\u6807\u65e0\u5173\u3002", "method": "Protriever\u6846\u67b6\u901a\u8fc7\u7aef\u5230\u7aef\u53ef\u5fae\u5206\u5b66\u4e60\uff0c\u540c\u65f6\u68c0\u7d22\u540c\u6e90\u5e8f\u5217\u5e76\u8bad\u7ec3\u76ee\u6807\u4efb\u52a1\uff0c\u652f\u6301\u9ad8\u6548\u5411\u91cf\u641c\u7d22\u3002", "result": "\u5728\u86cb\u767d\u8d28\u9002\u5e94\u6027\u9884\u6d4b\u4efb\u52a1\u4e2d\uff0cProtriever\u6027\u80fd\u4f18\u4e8e\u57fa\u4e8eMSA\u7684\u5e8f\u5217\u6a21\u578b\uff0c\u4e14\u901f\u5ea6\u5feb\u4e24\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "Protriever\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u4e0d\u540c\u68c0\u7d22\u7b56\u7565\u548c\u86cb\u767d\u8d28\u6570\u636e\u5e93\uff0c\u5177\u6709\u67b6\u6784\u548c\u4efb\u52a1\u65e0\u5173\u7684\u7075\u6d3b\u6027\u3002"}}
{"id": "2506.08955", "pdf": "https://arxiv.org/pdf/2506.08955", "abs": "https://arxiv.org/abs/2506.08955", "authors": ["Chunming He", "Kai Li", "Yachao Zhang", "Ziyun Yang", "Youwei Pang", "Longxiang Tang", "Chengyu Fang", "Yulun Zhang", "Linghe Kong", "Xiu Li", "Sina Farsiu"], "title": "Segment Concealed Objects with Incomplete Supervision", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "IEEE TPAMI", "summary": "Incompletely-Supervised Concealed Object Segmentation (ISCOS) involves\nsegmenting objects that seamlessly blend into their surrounding environments,\nutilizing incompletely annotated data, such as weak and semi-annotations, for\nmodel training. This task remains highly challenging due to (1) the limited\nsupervision provided by the incompletely annotated training data, and (2) the\ndifficulty of distinguishing concealed objects from the background, which\narises from the intrinsic similarities in concealed scenarios. In this paper,\nwe introduce the first unified method for ISCOS to address these challenges. To\ntackle the issue of incomplete supervision, we propose a unified mean-teacher\nframework, SEE, that leverages the vision foundation model, ``\\emph{Segment\nAnything Model (SAM)}'', to generate pseudo-labels using coarse masks produced\nby the teacher model as prompts. To mitigate the effect of low-quality\nsegmentation masks, we introduce a series of strategies for pseudo-label\ngeneration, storage, and supervision. These strategies aim to produce\ninformative pseudo-labels, store the best pseudo-labels generated, and select\nthe most reliable components to guide the student model, thereby ensuring\nrobust network training. Additionally, to tackle the issue of intrinsic\nsimilarity, we design a hybrid-granularity feature grouping module that groups\nfeatures at different granularities and aggregates these results. By clustering\nsimilar features, this module promotes segmentation coherence, facilitating\nmore complete segmentation for both single-object and multiple-object images.\nWe validate the effectiveness of our approach across multiple ISCOS tasks, and\nexperimental results demonstrate that our method achieves state-of-the-art\nperformance. Furthermore, SEE can serve as a plug-and-play solution, enhancing\nthe performance of existing models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u65b9\u6cd5\uff08SEE\uff09\u7528\u4e8e\u4e0d\u5b8c\u5168\u76d1\u7763\u7684\u9690\u853d\u7269\u4f53\u5206\u5272\uff08ISCOS\uff09\uff0c\u901a\u8fc7\u5229\u7528SAM\u751f\u6210\u4f2a\u6807\u7b7e\u548c\u6df7\u5408\u7c92\u5ea6\u7279\u5f81\u5206\u7ec4\u6a21\u5757\uff0c\u89e3\u51b3\u4e86\u4e0d\u5b8c\u5168\u76d1\u7763\u548c\u9690\u853d\u7269\u4f53\u4e0e\u80cc\u666f\u76f8\u4f3c\u6027\u7684\u6311\u6218\u3002", "motivation": "\u9690\u853d\u7269\u4f53\u5206\u5272\u4efb\u52a1\u56e0\u4e0d\u5b8c\u5168\u6807\u6ce8\u6570\u636e\u548c\u7269\u4f53\u4e0e\u80cc\u666f\u7684\u76f8\u4f3c\u6027\u800c\u6781\u5177\u6311\u6218\u6027\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u7edf\u4e00\u65b9\u6cd5\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51faSEE\u6846\u67b6\uff0c\u5229\u7528SAM\u751f\u6210\u4f2a\u6807\u7b7e\uff0c\u5e76\u901a\u8fc7\u4f2a\u6807\u7b7e\u751f\u6210\u3001\u5b58\u50a8\u548c\u76d1\u7763\u7b56\u7565\u4f18\u5316\u8bad\u7ec3\u3002\u540c\u65f6\u8bbe\u8ba1\u6df7\u5408\u7c92\u5ea6\u7279\u5f81\u5206\u7ec4\u6a21\u5757\u63d0\u5347\u5206\u5272\u4e00\u81f4\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSEE\u5728\u591a\u4e2aISCOS\u4efb\u52a1\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5e76\u53ef\u4f5c\u4e3a\u5373\u63d2\u5373\u7528\u65b9\u6848\u63d0\u5347\u73b0\u6709\u6a21\u578b\u3002", "conclusion": "SEE\u901a\u8fc7\u4f2a\u6807\u7b7e\u548c\u7279\u5f81\u5206\u7ec4\u6a21\u5757\u6709\u6548\u89e3\u51b3\u4e86ISCOS\u7684\u6311\u6218\uff0c\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\u3002"}}
{"id": "2506.08956", "pdf": "https://arxiv.org/pdf/2506.08956", "abs": "https://arxiv.org/abs/2506.08956", "authors": ["DaeEun Yoon", "Semin Kim", "SangWook Yoo", "Jongha Lee"], "title": "Data Augmentation For Small Object using Fast AutoAugment", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted and published in the USB Proceedings of the 20th\n  International Conference on Modeling Decisions for Artificial Intelligence\n  (MDAI 2023), Ume{\\aa}, Sweden, June 19--22, 2023, ISBN 978-91-527-7293-5,\n  pp.\\ 12--21", "summary": "In recent years, there has been tremendous progress in object detection\nperformance. However, despite these advances, the detection performance for\nsmall objects is significantly inferior to that of large objects. Detecting\nsmall objects is one of the most challenging and important problems in computer\nvision. To improve the detection performance for small objects, we propose an\noptimal data augmentation method using Fast AutoAugment. Through our proposed\nmethod, we can quickly find optimal augmentation policies that can overcome\ndegradation when detecting small objects, and we achieve a 20% performance\nimprovement on the DOTA dataset.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eFast AutoAugment\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5c0f\u76ee\u6807\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u76ee\u6807\u68c0\u6d4b\u6574\u4f53\u6027\u80fd\u63d0\u5347\uff0c\u4f46\u5c0f\u76ee\u6807\u68c0\u6d4b\u6548\u679c\u4ecd\u8f83\u5dee\uff0c\u4e9f\u9700\u6539\u8fdb\u3002", "method": "\u4f7f\u7528Fast AutoAugment\u5feb\u901f\u627e\u5230\u6700\u4f18\u6570\u636e\u589e\u5f3a\u7b56\u7565\uff0c\u4ee5\u514b\u670d\u5c0f\u76ee\u6807\u68c0\u6d4b\u7684\u9000\u5316\u95ee\u9898\u3002", "result": "\u5728DOTA\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e8620%\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u5c0f\u76ee\u6807\u68c0\u6d4b\u6027\u80fd\u4e0d\u8db3\u7684\u95ee\u9898\u3002"}}
{"id": "2506.08957", "pdf": "https://arxiv.org/pdf/2506.08957", "abs": "https://arxiv.org/abs/2506.08957", "authors": ["Yash Ranjan", "Rahul Sengupta", "Anand Rangarajan", "Sanjay Ranka"], "title": "IntTrajSim: Trajectory Prediction for Simulating Multi-Vehicle driving at Signalized Intersections", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Traffic simulators are widely used to study the operational efficiency of\nroad infrastructure, but their rule-based approach limits their ability to\nmimic real-world driving behavior. Traffic intersections are critical\ncomponents of the road infrastructure, both in terms of safety risk (nearly 28%\nof fatal crashes and 58% of nonfatal crashes happen at intersections) as well\nas the operational efficiency of a road corridor. This raises an important\nquestion: can we create a data-driven simulator that can mimic the macro- and\nmicro-statistics of the driving behavior at a traffic intersection? Deep\nGenerative Modeling-based trajectory prediction models provide a good starting\npoint to model the complex dynamics of vehicles at an intersection. But they\nare not tested in a \"live\" micro-simulation scenario and are not evaluated on\ntraffic engineering-related metrics. In this study, we propose traffic\nengineering-related metrics to evaluate generative trajectory prediction models\nand provide a simulation-in-the-loop pipeline to do so. We also provide a\nmulti-headed self-attention-based trajectory prediction model that incorporates\nthe signal information, which outperforms our previous models on the evaluation\nmetrics.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6570\u636e\u9a71\u52a8\u7684\u4ea4\u901a\u6a21\u62df\u5668\uff0c\u901a\u8fc7\u751f\u6210\u8f68\u8ff9\u9884\u6d4b\u6a21\u578b\u6a21\u62df\u4ea4\u53c9\u8def\u53e3\u7684\u9a7e\u9a76\u884c\u4e3a\uff0c\u5e76\u5f15\u5165\u4ea4\u901a\u5de5\u7a0b\u76f8\u5173\u6307\u6807\u8fdb\u884c\u8bc4\u4f30\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u89c4\u5219\u7684\u4ea4\u901a\u6a21\u62df\u5668\u96be\u4ee5\u771f\u5b9e\u6a21\u62df\u9a7e\u9a76\u884c\u4e3a\uff0c\u800c\u4ea4\u53c9\u8def\u53e3\u5728\u5b89\u5168\u548c\u6548\u7387\u4e0a\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u6b64\u9700\u8981\u6570\u636e\u9a71\u52a8\u7684\u6a21\u62df\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u5934\u81ea\u6ce8\u610f\u529b\u8f68\u8ff9\u9884\u6d4b\u6a21\u578b\uff0c\u7ed3\u5408\u4fe1\u53f7\u4fe1\u606f\uff0c\u5e76\u901a\u8fc7\u6a21\u62df\u95ed\u73af\u6d41\u7a0b\u8bc4\u4f30\u6a21\u578b\u3002", "result": "\u65b0\u6a21\u578b\u5728\u4ea4\u901a\u5de5\u7a0b\u76f8\u5173\u6307\u6807\u4e0a\u4f18\u4e8e\u5148\u524d\u6a21\u578b\u3002", "conclusion": "\u6570\u636e\u9a71\u52a8\u7684\u6a21\u62df\u65b9\u6cd5\u4e3a\u4ea4\u901a\u4ea4\u53c9\u8def\u53e3\u7684\u884c\u4e3a\u6a21\u62df\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.08966", "pdf": "https://arxiv.org/pdf/2506.08966", "abs": "https://arxiv.org/abs/2506.08966", "authors": ["Marek Kadl\u010d\u00edk", "Michal \u0160tef\u00e1nik", "Timothee Mickus", "Michal Spiegel", "Josef Kucha\u0159"], "title": "Pre-trained Language Models Learn Remarkably Accurate Representations of Numbers", "categories": ["cs.CL", "cs.LG", "cs.NE"], "comment": null, "summary": "Pretrained language models (LMs) are prone to arithmetic errors. Existing\nwork showed limited success in probing numeric values from models'\nrepresentations, indicating that these errors can be attributed to the inherent\nunreliability of distributionally learned embeddings in representing exact\nquantities. However, we observe that previous probing methods are inadequate\nfor the emergent structure of learned number embeddings with sinusoidal\npatterns.\n  In response, we propose a novel probing technique that decodes numeric values\nfrom input embeddings with near-perfect accuracy across a range of open-source\nLMs. This proves that after the sole pre-training, LMs represent numbers with\nremarkable precision. Finally, we find that the embeddings' preciseness judged\nby our probe's accuracy explains a large portion of LM's errors in elementary\narithmetic, and show that aligning the embeddings with the pattern discovered\nby our probe can mitigate these errors.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u63a2\u6d4b\u6280\u672f\uff0c\u80fd\u591f\u4ece\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u5d4c\u5165\u4e2d\u9ad8\u7cbe\u5ea6\u89e3\u7801\u6570\u503c\uff0c\u8bc1\u660e\u6a21\u578b\u5728\u9884\u8bad\u7ec3\u540e\u80fd\u7cbe\u786e\u8868\u793a\u6570\u5b57\uff0c\u5e76\u53d1\u73b0\u8fd9\u79cd\u7cbe\u786e\u6027\u4e0e\u7b97\u672f\u9519\u8bef\u76f8\u5173\u3002", "motivation": "\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u5728\u7b97\u672f\u8fd0\u7b97\u4e2d\u5bb9\u6613\u51fa\u9519\uff0c\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u6709\u6548\u63a2\u6d4b\u6570\u503c\u5d4c\u5165\u7684\u7ed3\u6784\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u51c6\u786e\u7684\u63a2\u6d4b\u6280\u672f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u63a2\u6d4b\u6280\u672f\uff0c\u80fd\u591f\u4ece\u8f93\u5165\u5d4c\u5165\u4e2d\u89e3\u7801\u6570\u503c\uff0c\u5e76\u9a8c\u8bc1\u5176\u51c6\u786e\u6027\u3002", "result": "\u65b0\u63a2\u6d4b\u6280\u672f\u80fd\u8fd1\u4e4e\u5b8c\u7f8e\u5730\u89e3\u7801\u6570\u503c\uff0c\u8bc1\u660e\u9884\u8bad\u7ec3\u540e\u7684\u8bed\u8a00\u6a21\u578b\u80fd\u7cbe\u786e\u8868\u793a\u6570\u5b57\uff1b\u5d4c\u5165\u7684\u7cbe\u786e\u6027\u4e0e\u7b97\u672f\u9519\u8bef\u76f8\u5173\u3002", "conclusion": "\u901a\u8fc7\u8c03\u6574\u5d4c\u5165\u7ed3\u6784\u4e0e\u63a2\u6d4b\u53d1\u73b0\u7684\u6a21\u5f0f\u5bf9\u9f50\uff0c\u53ef\u4ee5\u51cf\u8f7b\u6a21\u578b\u7684\u7b97\u672f\u9519\u8bef\u3002"}}
{"id": "2506.08990", "pdf": "https://arxiv.org/pdf/2506.08990", "abs": "https://arxiv.org/abs/2506.08990", "authors": ["Chenyu Lian", "Hong-Yu Zhou", "Dongyun Liang", "Jing Qin", "Liansheng Wang"], "title": "Efficient Medical Vision-Language Alignment Through Adapting Masked Vision Models", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "TMI 2025", "summary": "Medical vision-language alignment through cross-modal contrastive learning\nshows promising performance in image-text matching tasks, such as retrieval and\nzero-shot classification. However, conventional cross-modal contrastive\nlearning (CLIP-based) methods suffer from suboptimal visual representation\ncapabilities, which also limits their effectiveness in vision-language\nalignment. In contrast, although the models pretrained via multimodal masked\nmodeling struggle with direct cross-modal matching, they excel in visual\nrepresentation. To address this contradiction, we propose ALTA (ALign Through\nAdapting), an efficient medical vision-language alignment method that utilizes\nonly about 8% of the trainable parameters and less than 1/5 of the\ncomputational consumption required for masked record modeling. ALTA achieves\nsuperior performance in vision-language matching tasks like retrieval and\nzero-shot classification by adapting the pretrained vision model from masked\nrecord modeling. Additionally, we integrate temporal-multiview radiograph\ninputs to enhance the information consistency between radiographs and their\ncorresponding descriptions in reports, further improving the vision-language\nalignment. Experimental evaluations show that ALTA outperforms the\nbest-performing counterpart by over 4% absolute points in text-to-image\naccuracy and approximately 6% absolute points in image-to-text retrieval\naccuracy. The adaptation of vision-language models during efficient alignment\nalso promotes better vision and language understanding. Code is publicly\navailable at https://github.com/DopamineLcy/ALTA.", "AI": {"tldr": "ALTA\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u533b\u5b66\u89c6\u89c9-\u8bed\u8a00\u5bf9\u9f50\u65b9\u6cd5\uff0c\u901a\u8fc7\u9002\u5e94\u9884\u8bad\u7ec3\u7684\u89c6\u89c9\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u68c0\u7d22\u548c\u96f6\u6837\u672c\u5206\u7c7b\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u7684\u8de8\u6a21\u6001\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\u5728\u89c6\u89c9\u8868\u793a\u80fd\u529b\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u800c\u591a\u6a21\u6001\u63a9\u7801\u5efa\u6a21\u65b9\u6cd5\u867d\u7136\u89c6\u89c9\u8868\u793a\u80fd\u529b\u5f3a\uff0c\u4f46\u5728\u8de8\u6a21\u6001\u5339\u914d\u4e0a\u8868\u73b0\u4e0d\u8db3\u3002ALTA\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u77db\u76fe\u3002", "method": "ALTA\u901a\u8fc7\u9002\u5e94\u9884\u8bad\u7ec3\u7684\u89c6\u89c9\u6a21\u578b\uff08\u6765\u81ea\u63a9\u7801\u8bb0\u5f55\u5efa\u6a21\uff09\uff0c\u4ec5\u9700\u7ea68%\u7684\u53ef\u8bad\u7ec3\u53c2\u6570\u548c\u4e0d\u52301/5\u7684\u8ba1\u7b97\u6d88\u8017\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u89c6\u89c9-\u8bed\u8a00\u5bf9\u9f50\u3002\u540c\u65f6\uff0c\u6574\u5408\u4e86\u65f6\u95f4\u591a\u89c6\u89d2\u653e\u5c04\u56fe\u50cf\u8f93\u5165\u4ee5\u589e\u5f3a\u4fe1\u606f\u4e00\u81f4\u6027\u3002", "result": "ALTA\u5728\u6587\u672c\u5230\u56fe\u50cf\u548c\u56fe\u50cf\u5230\u6587\u672c\u68c0\u7d22\u4efb\u52a1\u4e2d\u5206\u522b\u6bd4\u6700\u4f73\u5bf9\u6bd4\u65b9\u6cd5\u9ad8\u51fa4%\u548c6%\u7684\u7edd\u5bf9\u51c6\u786e\u7387\u3002", "conclusion": "ALTA\u4e0d\u4ec5\u63d0\u5347\u4e86\u89c6\u89c9-\u8bed\u8a00\u5bf9\u9f50\u4efb\u52a1\u7684\u6027\u80fd\uff0c\u8fd8\u4fc3\u8fdb\u4e86\u89c6\u89c9\u548c\u8bed\u8a00\u7406\u89e3\u7684\u63d0\u5347\u3002"}}
{"id": "2506.09024", "pdf": "https://arxiv.org/pdf/2506.09024", "abs": "https://arxiv.org/abs/2506.09024", "authors": ["Felix Wagner", "Pramit Saha", "Harry Anthony", "J. Alison Noble", "Konstantinos Kamnitsas"], "title": "DIsoN: Decentralized Isolation Networks for Out-of-Distribution Detection in Medical Imaging", "categories": ["cs.CV", "cs.LG", "I.2.11; I.4.9; I.4.9; J.3; I.2.0"], "comment": null, "summary": "Safe deployment of machine learning (ML) models in safety-critical domains\nsuch as medical imaging requires detecting inputs with characteristics not seen\nduring training, known as out-of-distribution (OOD) detection, to prevent\nunreliable predictions. Effective OOD detection after deployment could benefit\nfrom access to the training data, enabling direct comparison between test\nsamples and the training data distribution to identify differences.\nState-of-the-art OOD detection methods, however, either discard training data\nafter deployment or assume that test samples and training data are centrally\nstored together, an assumption that rarely holds in real-world settings. This\nis because shipping training data with the deployed model is usually impossible\ndue to the size of training databases, as well as proprietary or privacy\nconstraints. We introduce the Isolation Network, an OOD detection framework\nthat quantifies the difficulty of separating a target test sample from the\ntraining data by solving a binary classification task. We then propose\nDecentralized Isolation Networks (DIsoN), which enables the comparison of\ntraining and test data when data-sharing is impossible, by exchanging only\nmodel parameters between the remote computational nodes of training and\ndeployment. We further extend DIsoN with class-conditioning, comparing a target\nsample solely with training data of its predicted class. We evaluate DIsoN on\nfour medical imaging datasets (dermatology, chest X-ray, breast ultrasound,\nhistopathology) across 12 OOD detection tasks. DIsoN performs favorably against\nexisting methods while respecting data-privacy. This decentralized OOD\ndetection framework opens the way for a new type of service that ML developers\ncould provide along with their models: providing remote, secure utilization of\ntheir training data for OOD detection services. Code will be available upon\nacceptance at: *****", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDIsoN\u7684\u53bb\u4e2d\u5fc3\u5316OOD\u68c0\u6d4b\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u8bad\u7ec3\u6570\u636e\u5171\u4eab\u53d7\u9650\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u4ea4\u6362\u6a21\u578b\u53c2\u6570\u5b9e\u73b0\u8bad\u7ec3\u4e0e\u6d4b\u8bd5\u6570\u636e\u7684\u6bd4\u8f83\uff0c\u5e76\u5728\u533b\u5b66\u5f71\u50cf\u6570\u636e\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5728\u5b89\u5168\u5173\u952e\u9886\u57df\uff08\u5982\u533b\u5b66\u5f71\u50cf\uff09\u90e8\u7f72ML\u6a21\u578b\u65f6\uff0c\u9700\u8981\u68c0\u6d4b\u8bad\u7ec3\u6570\u636e\u4e2d\u672a\u89c1\u7684\u8f93\u5165\uff08OOD\uff09\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u4e22\u5f03\u8bad\u7ec3\u6570\u636e\uff0c\u8981\u4e48\u5047\u8bbe\u6570\u636e\u96c6\u4e2d\u5b58\u50a8\uff0c\u8fd9\u5728\u73b0\u5b9e\u4e2d\u96be\u4ee5\u5b9e\u73b0\u3002", "method": "\u63d0\u51fa\u4e86Isolation Network\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u51b3\u4e8c\u5206\u7c7b\u4efb\u52a1\u91cf\u5316\u6d4b\u8bd5\u6837\u672c\u4e0e\u8bad\u7ec3\u6570\u636e\u7684\u5206\u79bb\u96be\u5ea6\uff1b\u8fdb\u4e00\u6b65\u63d0\u51faDIsoN\uff0c\u652f\u6301\u5728\u65e0\u6cd5\u5171\u4eab\u6570\u636e\u65f6\u901a\u8fc7\u4ea4\u6362\u6a21\u578b\u53c2\u6570\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u5728\u56db\u4e2a\u533b\u5b66\u5f71\u50cf\u6570\u636e\u96c6\u4e0a\u768412\u4e2aOOD\u68c0\u6d4b\u4efb\u52a1\u4e2d\uff0cDIsoN\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u3002", "conclusion": "DIsoN\u4e3aML\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u670d\u52a1\u6a21\u5f0f\uff0c\u5373\u8fdc\u7a0b\u5b89\u5168\u5229\u7528\u8bad\u7ec3\u6570\u636e\u8fdb\u884cOOD\u68c0\u6d4b\uff0c\u89e3\u51b3\u4e86\u6570\u636e\u5171\u4eab\u7684\u9650\u5236\u3002"}}
{"id": "2506.09027", "pdf": "https://arxiv.org/pdf/2506.09027", "abs": "https://arxiv.org/abs/2506.09027", "authors": ["Runqian Wang", "Kaiming He"], "title": "Diffuse and Disperse: Image Generation with Representation Regularization", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "The development of diffusion-based generative models over the past decade has\nlargely proceeded independently of progress in representation learning. These\ndiffusion models typically rely on regression-based objectives and generally\nlack explicit regularization. In this work, we propose \\textit{Dispersive\nLoss}, a simple plug-and-play regularizer that effectively improves\ndiffusion-based generative models. Our loss function encourages internal\nrepresentations to disperse in the hidden space, analogous to contrastive\nself-supervised learning, with the key distinction that it requires no positive\nsample pairs and therefore does not interfere with the sampling process used\nfor regression. Compared to the recent method of representation alignment\n(REPA), our approach is self-contained and minimalist, requiring no\npre-training, no additional parameters, and no external data. We evaluate\nDispersive Loss on the ImageNet dataset across a range of models and report\nconsistent improvements over widely used and strong baselines. We hope our work\nwill help bridge the gap between generative modeling and representation\nlearning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDispersive Loss\u7684\u7b80\u5355\u6b63\u5219\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u6539\u8fdb\u57fa\u4e8e\u6269\u6563\u7684\u751f\u6210\u6a21\u578b\uff0c\u65e0\u9700\u989d\u5916\u6570\u636e\u6216\u53c2\u6570\u3002", "motivation": "\u6269\u6563\u751f\u6210\u6a21\u578b\u901a\u5e38\u7f3a\u4e4f\u663e\u5f0f\u6b63\u5219\u5316\uff0c\u4e14\u4e0e\u8868\u793a\u5b66\u4e60\u8fdb\u5c55\u72ec\u7acb\u53d1\u5c55\u3002\u672c\u6587\u65e8\u5728\u5f25\u5408\u751f\u6210\u6a21\u578b\u4e0e\u8868\u793a\u5b66\u4e60\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u63d0\u51faDispersive Loss\uff0c\u4e00\u79cd\u9f13\u52b1\u9690\u7a7a\u95f4\u8868\u793a\u5206\u6563\u7684\u6b63\u5219\u5316\u65b9\u6cd5\uff0c\u65e0\u9700\u6b63\u6837\u672c\u5bf9\uff0c\u4e0d\u5f71\u54cd\u56de\u5f52\u91c7\u6837\u8fc7\u7a0b\u3002", "result": "\u5728ImageNet\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cDispersive Loss\u5728\u591a\u79cd\u6a21\u578b\u4e2d\u5747\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "conclusion": "Dispersive Loss\u662f\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u6b63\u5219\u5316\u65b9\u6cd5\uff0c\u6709\u671b\u4fc3\u8fdb\u751f\u6210\u6a21\u578b\u4e0e\u8868\u793a\u5b66\u4e60\u7684\u7ed3\u5408\u3002"}}
{"id": "2506.09033", "pdf": "https://arxiv.org/pdf/2506.09033", "abs": "https://arxiv.org/abs/2506.09033", "authors": ["Haozhen Zhang", "Tao Feng", "Jiaxuan You"], "title": "Router-R1: Teaching LLMs Multi-Round Routing and Aggregation via Reinforcement Learning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Code is available at https://github.com/ulab-uiuc/Router-R1", "summary": "The rapid emergence of diverse large language models (LLMs) has spurred the\ndevelopment of LLM routers that assign user queries to the most suitable model.\nHowever, existing LLM routers typically perform a single-round, one-to-one\nmapping (\\textit{i.e.}, assigning each query to a single model in isolation),\nwhich limits their capability to tackle complex tasks that demand the\ncomplementary strengths of multiple LLMs. In this paper, we present\n\\textbf{Router-R1}, a reinforcement learning (RL)-based framework that\nformulates multi-LLM routing and aggregation as a sequential decision process.\nRouter-R1 instantiates the router itself as a capable LLM, leveraging its\nreasoning ability to interleave \"think\" actions (internal deliberation) with\n\"route\" actions (dynamic model invocation), and integrates each response into\nits evolving context. To guide learning, we employ a lightweight rule-based\nreward comprising format rewards, final outcome rewards, and a novel cost\nreward for performance and cost trade-off optimization, opening a pathway\ntoward optimizing performance-cost tradeoffs via RL. Router-R1 also conditions\nonly on simple model descriptors such as pricing, latency, and example\nperformance, enabling strong generalization to unseen model selection.\nExperiments on seven general and multi-hop QA benchmarks show that Router-R1\noutperforms over several strong baselines, achieving superior performance while\nmaintaining robust generalization and cost management.Code is available at\nhttps://github.com/ulab-uiuc/Router-R1.", "AI": {"tldr": "Router-R1\u662f\u4e00\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8def\u7531\u548c\u805a\u5408\u591a\u4e2aLLM\u7684\u80fd\u529b\uff0c\u4f18\u5316\u590d\u6742\u4efb\u52a1\u7684\u6027\u80fd\u4e0e\u6210\u672c\u6743\u8861\u3002", "motivation": "\u73b0\u6709LLM\u8def\u7531\u5668\u901a\u5e38\u91c7\u7528\u5355\u8f6e\u4e00\u5bf9\u4e00\u6620\u5c04\uff0c\u65e0\u6cd5\u5145\u5206\u5229\u7528\u591a\u4e2aLLM\u7684\u4e92\u8865\u4f18\u52bf\uff0c\u9650\u5236\u4e86\u5904\u7406\u590d\u6742\u4efb\u52a1\u7684\u80fd\u529b\u3002", "method": "Router-R1\u5c06\u591aLLM\u8def\u7531\u548c\u805a\u5408\u5efa\u6a21\u4e3a\u5e8f\u5217\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5229\u7528LLM\u7684\u63a8\u7406\u80fd\u529b\u4ea4\u66ff\u6267\u884c\u5185\u90e8\u601d\u8003\u548c\u52a8\u6001\u6a21\u578b\u8c03\u7528\uff0c\u5e76\u901a\u8fc7\u8f7b\u91cf\u7ea7\u89c4\u5219\u5956\u52b1\u6307\u5bfc\u5b66\u4e60\u3002", "result": "\u5728\u4e03\u4e2a\u901a\u7528\u548c\u591a\u8df3QA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRouter-R1\u4f18\u4e8e\u591a\u4e2a\u57fa\u7ebf\uff0c\u8868\u73b0\u51fa\u5353\u8d8a\u7684\u6027\u80fd\u3001\u6cdb\u5316\u80fd\u529b\u548c\u6210\u672c\u7ba1\u7406\u3002", "conclusion": "Router-R1\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5b9e\u73b0\u4e86\u591aLLM\u7684\u52a8\u6001\u8def\u7531\u4e0e\u805a\u5408\uff0c\u4e3a\u6027\u80fd\u4e0e\u6210\u672c\u6743\u8861\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2506.08018", "pdf": "https://arxiv.org/pdf/2506.08018", "abs": "https://arxiv.org/abs/2506.08018", "authors": ["Fei Li", "Song Liu", "Weiguo Wu", "Shiqiang Nie", "Jinyu Wang"], "title": "KVmix: Gradient-Based Layer Importance-Aware Mixed-Precision Quantization for KV Cache", "categories": ["cs.LG", "cs.AI", "03B65 ((Primary))", "I.2.7"], "comment": "14 pages, 8 figures, 4 tables", "summary": "The high memory demands of the Key-Value (KV) Cache during the inference of\nLarge Language Models (LLMs) severely restrict their deployment in\nresource-constrained platforms. Quantization can effectively alleviate the\nmemory pressure caused by KV Cache. However, existing methods either rely on\nstatic one-size-fits-all precision allocation or fail to dynamically prioritize\ncritical KV in long-context tasks, forcing memory-accuracy-throughput\ntradeoffs. In this work, we propose a novel mixed-precision quantization method\nfor KV Cache named KVmix. KVmix leverages gradient-based importance analysis to\nevaluate how individual Key and Value projection matrices affect the model\nloss, enabling layer-specific bit-width allocation for mix-precision\nquantization. It dynamically prioritizes higher precision for important layers\nwhile aggressively quantizing less influential ones, achieving a tunable\nbalance between accuracy and efficiency. KVmix also introduces a dynamic\nlong-context optimization strategy that adaptively keeps full-precision KV\npairs for recent pivotal tokens and compresses older ones, achieving\nhigh-quality sequence generation with low memory usage. Additionally, KVmix\nprovides efficient low-bit quantization and CUDA kernels to optimize\ncomputational overhead. On LLMs such as Llama and Mistral, KVmix achieves\nnear-lossless inference performance with extremely low quantization\nconfiguration (Key 2.19bit Value 2.38bit), while delivering a remarkable 4.9x\nmemory compression and a 5.3x speedup in inference throughput.", "AI": {"tldr": "KVmix\u662f\u4e00\u79cd\u65b0\u578b\u7684\u6df7\u5408\u7cbe\u5ea6\u91cf\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u4f18\u5316LLMs\u63a8\u7406\u4e2d\u7684KV Cache\u5185\u5b58\u95ee\u9898\uff0c\u901a\u8fc7\u52a8\u6001\u5206\u914d\u7cbe\u5ea6\u548c\u957f\u4e0a\u4e0b\u6587\u4f18\u5316\u7b56\u7565\uff0c\u5b9e\u73b0\u9ad8\u6548\u4f4e\u5185\u5b58\u63a8\u7406\u3002", "motivation": "\u89e3\u51b3LLMs\u63a8\u7406\u4e2dKV Cache\u7684\u9ad8\u5185\u5b58\u9700\u6c42\u95ee\u9898\uff0c\u907f\u514d\u73b0\u6709\u65b9\u6cd5\u5728\u7cbe\u5ea6\u5206\u914d\u548c\u957f\u4e0a\u4e0b\u6587\u4efb\u52a1\u4e2d\u7684\u4e0d\u8db3\u3002", "method": "\u57fa\u4e8e\u68af\u5ea6\u91cd\u8981\u6027\u5206\u6790\u7684\u6df7\u5408\u7cbe\u5ea6\u91cf\u5316\u65b9\u6cd5\uff0c\u52a8\u6001\u5206\u914d\u5c42\u95f4\u7cbe\u5ea6\uff0c\u4f18\u5316\u957f\u4e0a\u4e0b\u6587\u4efb\u52a1\u4e2d\u7684KV\u5bf9\u5b58\u50a8\u3002", "result": "\u5728Llama\u548cMistral\u7b49LLMs\u4e0a\uff0cKVmix\u5b9e\u73b0\u4e86\u63a5\u8fd1\u65e0\u635f\u7684\u63a8\u7406\u6027\u80fd\uff0c\u5185\u5b58\u538b\u7f294.9\u500d\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u53475.3\u500d\u3002", "conclusion": "KVmix\u901a\u8fc7\u52a8\u6001\u6df7\u5408\u7cbe\u5ea6\u91cf\u5316\u548c\u957f\u4e0a\u4e0b\u6587\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86LLMs\u5728\u8d44\u6e90\u53d7\u9650\u5e73\u53f0\u4e0a\u7684\u90e8\u7f72\u6548\u7387\u3002"}}
{"id": "2506.08019", "pdf": "https://arxiv.org/pdf/2506.08019", "abs": "https://arxiv.org/abs/2506.08019", "authors": ["Andrew Wells", "Geraldine Henningsen", "Brice Bolane Tchinde Kengne"], "title": "Gridding Forced Displacement using Semi-Supervised Learning", "categories": ["cs.LG", "cs.CV", "cs.CY"], "comment": null, "summary": "We present a semi-supervised approach that disaggregates refugee statistics\nfrom administrative boundaries to 0.5-degree grid cells across 25 Sub-Saharan\nAfrican countries. By integrating UNHCR's ProGres registration data with\nsatellite-derived building footprints from Google Open Buildings and location\ncoordinates from OpenStreetMap Populated Places, our label spreading algorithm\ncreates spatially explicit refugee statistics at high granularity.This\nmethodology achieves 92.9% average accuracy in placing over 10 million refugee\nobservations into appropriate grid cells, enabling the identification of\nlocalized displacement patterns previously obscured in broader regional and\nnational statistics. The resulting high-resolution dataset provides a\nfoundation for a deeper understanding of displacement drivers.", "AI": {"tldr": "\u534a\u76d1\u7763\u65b9\u6cd5\u5c06\u96be\u6c11\u7edf\u8ba1\u6570\u636e\u4ece\u884c\u653f\u8fb9\u754c\u5206\u89e3\u52300.5\u5ea6\u7f51\u683c\u5355\u5143\uff0c\u7ed3\u5408\u591a\u79cd\u6570\u636e\u6e90\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u5b9a\u4f4d\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u533a\u57df\u548c\u56fd\u5bb6\u7edf\u8ba1\u6570\u636e\u4e2d\u96be\u6c11\u5206\u5e03\u6a21\u5f0f\u4e0d\u6e05\u6670\u7684\u95ee\u9898\u3002", "method": "\u6574\u5408UNHCR\u6ce8\u518c\u6570\u636e\u3001\u536b\u661f\u5efa\u7b51\u8db3\u8ff9\u548cOpenStreetMap\u5750\u6807\uff0c\u91c7\u7528\u6807\u7b7e\u4f20\u64ad\u7b97\u6cd5\u751f\u6210\u9ad8\u7cbe\u5ea6\u96be\u6c11\u5206\u5e03\u3002", "result": "\u5e73\u5747\u51c6\u786e\u738792.9%\uff0c\u5b9a\u4f4d1000\u591a\u4e07\u96be\u6c11\u6570\u636e\uff0c\u63ed\u793a\u5c40\u90e8\u4f4d\u79fb\u6a21\u5f0f\u3002", "conclusion": "\u9ad8\u5206\u8fa8\u7387\u6570\u636e\u96c6\u4e3a\u6df1\u5165\u7814\u7a76\u96be\u6c11\u4f4d\u79fb\u9a71\u52a8\u56e0\u7d20\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.08020", "pdf": "https://arxiv.org/pdf/2506.08020", "abs": "https://arxiv.org/abs/2506.08020", "authors": ["Zi-Ying Chen", "Chuan-Xian Ren", "Hong Yan"], "title": "Bi-level Unbalanced Optimal Transport for Partial Domain Adaptation", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Partial domain adaptation (PDA) problem requires aligning cross-domain\nsamples while distinguishing the outlier classes for accurate knowledge\ntransfer. The widely used weighting framework tries to address the outlier\nclasses by introducing the reweighed source domain with a similar label\ndistribution to the target domain. However, the empirical modeling of weights\ncan only characterize the sample-wise relations, which leads to insufficient\nexploration of cluster structures, and the weights could be sensitive to the\ninaccurate prediction and cause confusion on the outlier classes. To tackle\nthese issues, we propose a Bi-level Unbalanced Optimal Transport (BUOT) model\nto simultaneously characterize the sample-wise and class-wise relations in a\nunified transport framework. Specifically, a cooperation mechanism between\nsample-level and class-level transport is introduced, where the sample-level\ntransport provides essential structure information for the class-level\nknowledge transfer, while the class-level transport supplies discriminative\ninformation for the outlier identification. The bi-level transport plan\nprovides guidance for the alignment process. By incorporating the label-aware\ntransport cost, the local transport structure is ensured and a fast computation\nformulation is derived to improve the efficiency. Extensive experiments on\nbenchmark datasets validate the competitiveness of BUOT.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u5c42\u6b21\u4e0d\u5e73\u8861\u6700\u4f18\u4f20\u8f93\uff08BUOT\uff09\u6a21\u578b\uff0c\u7528\u4e8e\u89e3\u51b3\u90e8\u5206\u57df\u81ea\u9002\u5e94\uff08PDA\uff09\u95ee\u9898\uff0c\u901a\u8fc7\u540c\u65f6\u8868\u5f81\u6837\u672c\u7ea7\u548c\u7c7b\u7ea7\u5173\u7cfb\uff0c\u63d0\u5347\u77e5\u8bc6\u8f6c\u79fb\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u90e8\u5206\u57df\u81ea\u9002\u5e94\u95ee\u9898\u9700\u8981\u5bf9\u9f50\u8de8\u57df\u6837\u672c\u5e76\u533a\u5206\u5f02\u5e38\u7c7b\uff0c\u4f46\u73b0\u6709\u52a0\u6743\u6846\u67b6\u4ec5\u80fd\u8868\u5f81\u6837\u672c\u7ea7\u5173\u7cfb\uff0c\u5bf9\u5f02\u5e38\u7c7b\u7684\u8bc6\u522b\u4e0d\u591f\u51c6\u786e\u3002", "method": "\u63d0\u51faBUOT\u6a21\u578b\uff0c\u901a\u8fc7\u6837\u672c\u7ea7\u548c\u7c7b\u7ea7\u4f20\u8f93\u7684\u5408\u4f5c\u673a\u5236\uff0c\u7ed3\u5408\u6807\u7b7e\u611f\u77e5\u4f20\u8f93\u6210\u672c\uff0c\u4f18\u5316\u5bf9\u9f50\u8fc7\u7a0b\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86BUOT\u7684\u7ade\u4e89\u529b\u3002", "conclusion": "BUOT\u6a21\u578b\u901a\u8fc7\u53cc\u5c42\u6b21\u4f20\u8f93\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u90e8\u5206\u57df\u81ea\u9002\u5e94\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u5f02\u5e38\u7c7b\u7684\u8bc6\u522b\u548c\u77e5\u8bc6\u8f6c\u79fb\u6548\u679c\u3002"}}
{"id": "2506.08021", "pdf": "https://arxiv.org/pdf/2506.08021", "abs": "https://arxiv.org/abs/2506.08021", "authors": ["Weihao Zou", "Weibing Feng", "Pin Wu"], "title": "FlowBERT: Prompt-tuned BERT for variable flow field prediction", "categories": ["cs.LG", "physics.flu-dyn"], "comment": null, "summary": "This study proposes a universal flow field prediction framework based on\nknowledge transfer\n  from large language model (LLM), addressing the high computational costs of\ntraditional\n  computational fluid dynamics (CFD) methods and the limited cross-condition\ntransfer capability\n  of existing deep learning models. The framework innovatively integrates\nProper Orthogonal\n  Decomposition (POD) dimensionality reduction with fine-tuning strategies for\npretrained LLM,\n  where POD facilitates compressed representation of flow field features while\nthe fine-tuned model\n  learns to encode system dynamics in state space. To enhance the model's\nadaptability to flow field\n  data, we specifically designed fluid dynamics-oriented text templates that\nimprove predictive\n  performance through enriched contextual semantic information. Experimental\nresults demonstrate\n  that our framework outperforms conventional Transformer models in few-shot\nlearning scenarios while\n  exhibiting exceptional generalization across various inflow conditions and\nairfoil geometries.\n  Ablation studies reveal the contributions of key components in the FlowBERT\narchitecture. Compared\n  to traditional Navier-Stokes equation solvers requiring hours of computation,\nour approach reduces\n  prediction time to seconds while maintaining over 90% accuracy. The developed\nknowledge transfer\n  paradigm establishes a new direction for rapid fluid dynamics prediction,\nwith potential\n  applications extending to aerodynamic optimization, flow control, and other\nengineering domains.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u77e5\u8bc6\u8fc1\u79fb\u7684\u901a\u7528\u6d41\u573a\u9884\u6d4b\u6846\u67b6\uff0c\u89e3\u51b3\u4f20\u7edfCFD\u65b9\u6cd5\u9ad8\u8ba1\u7b97\u6210\u672c\u548c\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u8de8\u6761\u4ef6\u8fc1\u79fb\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edfCFD\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u8de8\u6761\u4ef6\u8fc1\u79fb\u80fd\u529b\u4e0a\u6709\u9650\uff0c\u4e9f\u9700\u4e00\u79cd\u9ad8\u6548\u4e14\u901a\u7528\u7684\u6d41\u573a\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408POD\u964d\u7ef4\u4e0e\u9884\u8bad\u7ec3LLM\u5fae\u8c03\u7b56\u7565\uff0c\u8bbe\u8ba1\u6d41\u4f53\u52a8\u529b\u5b66\u5bfc\u5411\u7684\u6587\u672c\u6a21\u677f\uff0c\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u3002", "result": "\u5728\u5c11\u6837\u672c\u5b66\u4e60\u573a\u666f\u4e2d\u4f18\u4e8e\u4f20\u7edfTransformer\u6a21\u578b\uff0c\u8de8\u6d41\u5165\u6761\u4ef6\u548c\u7ffc\u578b\u51e0\u4f55\u8868\u73b0\u51fa\u8272\uff0c\u9884\u6d4b\u65f6\u95f4\u4ece\u5c0f\u65f6\u7ea7\u964d\u81f3\u79d2\u7ea7\uff0c\u7cbe\u5ea6\u8d8590%\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5feb\u901f\u6d41\u4f53\u52a8\u529b\u5b66\u9884\u6d4b\u5f00\u8f9f\u65b0\u65b9\u5411\uff0c\u6f5c\u5728\u5e94\u7528\u5305\u62ec\u6c14\u52a8\u4f18\u5316\u3001\u6d41\u52a8\u63a7\u5236\u7b49\u5de5\u7a0b\u9886\u57df\u3002"}}
{"id": "2506.08022", "pdf": "https://arxiv.org/pdf/2506.08022", "abs": "https://arxiv.org/abs/2506.08022", "authors": ["Chenxi Liu", "Tianyi Xiong", "Ruibo Chen", "Yihan Wu", "Junfeng Guo", "Tianyi Zhou", "Heng Huang"], "title": "Modality-Balancing Preference Optimization of Large Multimodal Models by Adversarial Negative Mining", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "The task adaptation and alignment of Large Multimodal Models (LMMs) have been\nsignificantly advanced by instruction tuning and further strengthened by recent\npreference optimization. Yet, most LMMs still suffer from severe modality\nimbalance during reasoning, i.e., outweighing language prior biases over visual\ninputs, which bottlenecks their generalization to downstream tasks and causes\nhallucinations. However, existing preference optimization approaches for LMMs\ndo not focus on restraining the internal biases of their Large Language Model\n(LLM) backbones when curating the training data. Moreover, they heavily rely on\noffline data and lack the capacity to explore diverse responses adaptive to\ndynamic distributional shifts during training. Meanwhile, Group Relative Policy\nOptimization (GRPO), a recent method using online-generated data and verified\nrewards to improve reasoning capabilities, remains largely underexplored in LMM\nalignment. In this paper, we propose a novel preference learning framework,\nModality-Balancing Preference Optimization (MBPO), to address the modality\nimbalance in LMMs. MBPO constructs a more effective offline preference dataset\nby generating hard negatives, i.e., rejected responses misled by LLM biases due\nto limited usage of visual information, through adversarial perturbation of\ninput images. Moreover, MBPO leverages the easy-to-verify nature of close-ended\ntasks to generate online responses with verified rewards. GRPO is then employed\nto train the model with offline-online hybrid data. Extensive experiments\ndemonstrate that MBPO can enhance LMM performance on challenging\nvision-language tasks and effectively reduce hallucinations.", "AI": {"tldr": "MBPO\u662f\u4e00\u79cd\u65b0\u7684\u504f\u597d\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u751f\u6210\u786c\u8d1f\u6837\u672c\u548c\u5728\u7ebf\u9a8c\u8bc1\u5956\u52b1\uff0c\u89e3\u51b3\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\uff08LMMs\uff09\u4e2d\u7684\u6a21\u6001\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u63d0\u5347\u6027\u80fd\u5e76\u51cf\u5c11\u5e7b\u89c9\u3002", "motivation": "\u73b0\u6709LMMs\u5728\u63a8\u7406\u4e2d\u5b58\u5728\u6a21\u6001\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u504f\u5411\u8bed\u8a00\u5148\u9a8c\u800c\u5ffd\u89c6\u89c6\u89c9\u8f93\u5165\uff0c\u5bfc\u81f4\u4e0b\u6e38\u4efb\u52a1\u6cdb\u5316\u80fd\u529b\u5dee\u548c\u5e7b\u89c9\u73b0\u8c61\u3002\u73b0\u6709\u504f\u597d\u4f18\u5316\u65b9\u6cd5\u672a\u6709\u6548\u6291\u5236LLM\u5185\u90e8\u504f\u89c1\uff0c\u4e14\u4f9d\u8d56\u79bb\u7ebf\u6570\u636e\u3002", "method": "MBPO\u901a\u8fc7\u5bf9\u6297\u6027\u6270\u52a8\u751f\u6210\u786c\u8d1f\u6837\u672c\u6784\u5efa\u79bb\u7ebf\u504f\u597d\u6570\u636e\u96c6\uff0c\u5e76\u5229\u7528\u5c01\u95ed\u5f0f\u4efb\u52a1\u751f\u6210\u5728\u7ebf\u9a8c\u8bc1\u5956\u52b1\u6570\u636e\uff0c\u7ed3\u5408GRPO\u65b9\u6cd5\u8bad\u7ec3\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u8868\u660eMBPO\u80fd\u663e\u8457\u63d0\u5347LMMs\u5728\u89c6\u89c9\u8bed\u8a00\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u5e76\u6709\u6548\u51cf\u5c11\u5e7b\u89c9\u3002", "conclusion": "MBPO\u901a\u8fc7\u5e73\u8861\u6a21\u6001\u504f\u597d\u548c\u52a8\u6001\u6570\u636e\u4f18\u5316\uff0c\u4e3aLMMs\u7684\u6a21\u6001\u5bf9\u9f50\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.08027", "pdf": "https://arxiv.org/pdf/2506.08027", "abs": "https://arxiv.org/abs/2506.08027", "authors": ["Asit Mishra", "Dusan Stosic", "Simon Layton"], "title": "Recipes for Pre-training LLMs with MXFP8", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": null, "summary": "Precision scaling - using fewer bits to represent model parameters and\nrelated tensors during pre-training - has emerged as a compelling technique for\nimproving GPU efficiency without sacrificing accuracy. Microscaling (MX)\nformats in NVIDIA's latest Blackwell GPUs represent a major leap in enabling\nthis precision scaling aspect. These formats combine narrow floating-point data\ntypes with per-block scaling factors, offering a fine-grained approach to\nquantizing tensors.\n  Although MX-formats offer the promise of improved numeric stability compared\nto other reduced-precision representations, in practice they must be used\ncarefully in order to successfully converge an LLM on a multi-trillion token\ndataset. In this paper, we show that the rounding mode suggested in OCP\nspecification can lead to divergence when pre-training an LLM. We show an\nimproved rounding mode, which uses round-to-infinity to compute scaling\nfactors, enables successful pre-training in MXFP8 for an 8B model on 15T\ntokens.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u9884\u8bad\u7ec3\u4e2d\u4f7f\u7528MXFP8\u683c\u5f0f\u7684\u7cbe\u5ea6\u7f29\u653e\u6280\u672f\uff0c\u901a\u8fc7\u6539\u8fdb\u820d\u5165\u6a21\u5f0f\u89e3\u51b3\u4e86LLM\u9884\u8bad\u7ec3\u4e2d\u7684\u53d1\u6563\u95ee\u9898\u3002", "motivation": "\u7814\u7a76MX\u683c\u5f0f\u5728LLM\u9884\u8bad\u7ec3\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u95ee\u9898\uff0c\u7279\u522b\u662f\u820d\u5165\u6a21\u5f0f\u5bf9\u6a21\u578b\u6536\u655b\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u820d\u5165\u6a21\u5f0f\uff08round-to-infinity\uff09\uff0c\u7528\u4e8e\u8ba1\u7b97MXFP8\u683c\u5f0f\u7684\u7f29\u653e\u56e0\u5b50\u3002", "result": "\u6210\u529f\u572815T tokens\u4e0a\u9884\u8bad\u7ec3\u4e86\u4e00\u4e2a8B\u6a21\u578b\uff0c\u8bc1\u660e\u4e86\u6539\u8fdb\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6539\u8fdb\u7684\u820d\u5165\u6a21\u5f0f\u89e3\u51b3\u4e86MXFP8\u683c\u5f0f\u5728LLM\u9884\u8bad\u7ec3\u4e2d\u7684\u53d1\u6563\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u7cbe\u5ea6\u7f29\u653e\u6280\u672f\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2506.08051", "pdf": "https://arxiv.org/pdf/2506.08051", "abs": "https://arxiv.org/abs/2506.08051", "authors": ["Mahmuda Sultana Mimi", "Md Monzurul Islam", "Anannya Ghosh Tusti", "Shriyank Somvanshi", "Subasish Das"], "title": "ST-GraphNet: A Spatio-Temporal Graph Neural Network for Understanding and Predicting Automated Vehicle Crash Severity", "categories": ["cs.LG"], "comment": null, "summary": "Understanding the spatial and temporal dynamics of automated vehicle (AV)\ncrash severity is critical for advancing urban mobility safety and\ninfrastructure planning. In this work, we introduce ST-GraphNet, a\nspatio-temporal graph neural network framework designed to model and predict AV\ncrash severity by using both fine-grained and region-aggregated spatial graphs.\nUsing a balanced dataset of 2,352 real-world AV-related crash reports from\nTexas (2024), including geospatial coordinates, crash timestamps, SAE\nautomation levels, and narrative descriptions, we construct two complementary\ngraph representations: (1) a fine-grained graph with individual crash events as\nnodes, where edges are defined via spatio-temporal proximity; and (2) a\ncoarse-grained graph where crashes are aggregated into Hexagonal Hierarchical\nSpatial Indexing (H3)-based spatial cells, connected through hexagonal\nadjacency. Each node in the graph is enriched with multimodal data, including\nsemantic, spatial, and temporal attributes, including textual embeddings from\ncrash narratives using a pretrained Sentence-BERT model. We evaluate various\ngraph neural network (GNN) architectures, such as Graph Convolutional Networks\n(GCN), Graph Attention Networks (GAT), and Dynamic Spatio-Temporal GCN\n(DSTGCN), to classify crash severity and predict high-risk regions. Our\nproposed ST-GraphNet, which utilizes a DSTGCN backbone on the coarse-grained H3\ngraph, achieves a test accuracy of 97.74\\%, substantially outperforming the\nbest fine-grained model (64.7\\% test accuracy). These findings highlight the\neffectiveness of spatial aggregation, dynamic message passing, and multi-modal\nfeature integration in capturing the complex spatio-temporal patterns\nunderlying AV crash severity.", "AI": {"tldr": "ST-GraphNet\u662f\u4e00\u79cd\u65f6\u7a7a\u56fe\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\uff0c\u7528\u4e8e\u5efa\u6a21\u548c\u9884\u6d4b\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\uff08AV\uff09\u78b0\u649e\u4e25\u91cd\u6027\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u548c\u533a\u57df\u805a\u5408\u7684\u7a7a\u95f4\u56fe\u5b9e\u73b0\u3002", "motivation": "\u7406\u89e3\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u78b0\u649e\u4e25\u91cd\u6027\u7684\u65f6\u7a7a\u52a8\u6001\u5bf9\u63d0\u5347\u57ce\u5e02\u4ea4\u901a\u5b89\u5168\u548c\u57fa\u7840\u8bbe\u65bd\u89c4\u5212\u81f3\u5173\u91cd\u8981\u3002", "method": "\u6784\u5efa\u4e24\u79cd\u4e92\u8865\u7684\u56fe\u8868\u793a\uff1a\u7ec6\u7c92\u5ea6\u56fe\u548c\u7c97\u7c92\u5ea6\u56fe\uff0c\u7ed3\u5408\u591a\u6a21\u6001\u6570\u636e\uff08\u5982\u8bed\u4e49\u3001\u7a7a\u95f4\u548c\u65f6\u95f4\u5c5e\u6027\uff09\uff0c\u5e76\u8bc4\u4f30\u591a\u79cd\u56fe\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u3002", "result": "ST-GraphNet\u5728\u7c97\u7c92\u5ea6H3\u56fe\u4e0a\u4f7f\u7528DSTGCN\u67b6\u6784\uff0c\u6d4b\u8bd5\u51c6\u786e\u7387\u8fbe97.74%\uff0c\u663e\u8457\u4f18\u4e8e\u7ec6\u7c92\u5ea6\u6a21\u578b\uff0864.7%\uff09\u3002", "conclusion": "\u7a7a\u95f4\u805a\u5408\u3001\u52a8\u6001\u6d88\u606f\u4f20\u9012\u548c\u591a\u6a21\u6001\u7279\u5f81\u6574\u5408\u80fd\u6709\u6548\u6355\u6349AV\u78b0\u649e\u4e25\u91cd\u6027\u7684\u590d\u6742\u65f6\u7a7a\u6a21\u5f0f\u3002"}}
{"id": "2506.08054", "pdf": "https://arxiv.org/pdf/2506.08054", "abs": "https://arxiv.org/abs/2506.08054", "authors": ["Yiming Wang", "Hao Peng", "Senzhang Wang", "Haohua Du", "Chunyang Liu", "Jia Wu", "Guanlin Wu"], "title": "STAMImputer: Spatio-Temporal Attention MoE for Traffic Data Imputation", "categories": ["cs.LG", "cs.AI"], "comment": "10 pages, 5 figures, 3 tables. Extended version of paper accepted at\n  IJCAI 2025", "summary": "Traffic data imputation is fundamentally important to support various\napplications in intelligent transportation systems such as traffic flow\nprediction. However, existing time-to-space sequential methods often fail to\neffectively extract features in block-wise missing data scenarios. Meanwhile,\nthe static graph structure for spatial feature propagation significantly\nconstrains the models flexibility in handling the distribution shift issue for\nthe nonstationary traffic data. To address these issues, this paper proposes a\nSpatioTemporal Attention Mixture of experts network named STAMImputer for\ntraffic data imputation. Specifically, we introduce a Mixture of Experts (MoE)\nframework to capture latent spatio-temporal features and their influence\nweights, effectively imputing block missing. A novel Low-rank guided Sampling\nGraph ATtention (LrSGAT) mechanism is designed to dynamically balance the local\nand global correlations across road networks. The sampled attention vectors are\nutilized to generate dynamic graphs that capture real-time spatial\ncorrelations. Extensive experiments are conducted on four traffic datasets for\nevaluation. The result shows STAMImputer achieves significantly performance\nimprovement compared with existing SOTA approaches. Our codes are available at\nhttps://github.com/RingBDStack/STAMImupter.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSTAMImputer\u7684\u65f6\u7a7a\u6ce8\u610f\u529b\u6df7\u5408\u4e13\u5bb6\u7f51\u7edc\uff0c\u7528\u4e8e\u4ea4\u901a\u6570\u636e\u586b\u8865\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u5757\u72b6\u7f3a\u5931\u6570\u636e\u573a\u666f\u548c\u9759\u6001\u56fe\u7ed3\u6784\u9650\u5236\u4e0b\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5757\u72b6\u7f3a\u5931\u6570\u636e\u573a\u666f\u4e2d\u63d0\u53d6\u7279\u5f81\u6548\u679c\u4e0d\u4f73\uff0c\u4e14\u9759\u6001\u56fe\u7ed3\u6784\u9650\u5236\u4e86\u6a21\u578b\u5bf9\u975e\u5e73\u7a33\u4ea4\u901a\u6570\u636e\u7684\u9002\u5e94\u6027\u3002", "method": "\u91c7\u7528\u6df7\u5408\u4e13\u5bb6\uff08MoE\uff09\u6846\u67b6\u6355\u6349\u65f6\u7a7a\u7279\u5f81\u53ca\u5176\u6743\u91cd\uff0c\u5e76\u8bbe\u8ba1\u4f4e\u79e9\u5f15\u5bfc\u91c7\u6837\u56fe\u6ce8\u610f\u529b\u673a\u5236\uff08LrSGAT\uff09\u52a8\u6001\u5e73\u8861\u8def\u7f51\u5c40\u90e8\u4e0e\u5168\u5c40\u76f8\u5173\u6027\u3002", "result": "\u5728\u56db\u4e2a\u4ea4\u901a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSTAMImputer\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "STAMImputer\u901a\u8fc7\u52a8\u6001\u56fe\u7ed3\u6784\u548cMoE\u6846\u67b6\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4ea4\u901a\u6570\u636e\u586b\u8865\u4e2d\u7684\u5173\u952e\u95ee\u9898\u3002"}}
{"id": "2506.08060", "pdf": "https://arxiv.org/pdf/2506.08060", "abs": "https://arxiv.org/abs/2506.08060", "authors": ["Asankhaya Sharma"], "title": "Eliciting Fine-Tuned Transformer Capabilities via Inference-Time Techniques", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models have transformed natural language processing, yet\nsupervised fine-tuning (SFT) remains computationally intensive. This paper\nformally proves that capabilities acquired through SFT can be approximated by a\nbase transformer model using inference-time techniques, specifically in-context\nlearning (ICL), without altering model parameters, under idealized assumptions\nincluding unbounded computational resources and access to the fine-tuning\ndataset. We extend these results to practical scenarios with finite context\nlengths and partial dataset access. For text generation tasks with fixed output\nlength $l$, datasets of size $\\mathrm{O}\\left( \\frac{m V}{\\varepsilon^2} \\log\n\\frac{m}{\\delta} \\right)$ or, with bounded context, $\\mathrm{O}\\left( \\frac{l\n\\log V}{\\varepsilon^2} \\log \\frac{1}{\\delta} \\right)$ suffice to approximate\nfine-tuned behavior across $m$ contexts within error $\\varepsilon$, where $V$\nis the vocabulary size and $\\delta$ is the failure probability. For linear\nclassification, datasets of size $\\mathrm{O}\\left( \\frac{d}{\\varepsilon}\n\\right)$ or, with fixed context, $\\mathrm{O}\\left( \\frac{1}{\\varepsilon^2} \\log\n\\frac{1}{\\delta} \\right)$ are sufficient, where $d$ is the input dimension.\nGrounded in the Turing completeness of transformers, these results provide a\ntheoretical foundation for resource-efficient deployment of large language\nmodels, with practical techniques like retrieval-augmented generation bridging\ntheory to real-world applications.", "AI": {"tldr": "\u8bba\u6587\u8bc1\u660e\uff0c\u901a\u8fc7\u63a8\u7406\u65f6\u6280\u672f\uff08\u5982\u4e0a\u4e0b\u6587\u5b66\u4e60\uff09\u53ef\u4ee5\u8fd1\u4f3c\u76d1\u7763\u5fae\u8c03\u7684\u80fd\u529b\uff0c\u65e0\u9700\u4fee\u6539\u6a21\u578b\u53c2\u6570\uff0c\u5e76\u5728\u7406\u60f3\u5316\u5047\u8bbe\u4e0b\u6269\u5c55\u5230\u5b9e\u9645\u573a\u666f\u3002", "motivation": "\u51cf\u5c11\u76d1\u7763\u5fae\u8c03\u7684\u8ba1\u7b97\u6210\u672c\uff0c\u63a2\u7d22\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8d44\u6e90\u6709\u9650\u60c5\u51b5\u4e0b\u7684\u9ad8\u6548\u90e8\u7f72\u3002", "method": "\u5229\u7528\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\u6280\u672f\uff0c\u5728\u63a8\u7406\u65f6\u8fd1\u4f3c\u76d1\u7763\u5fae\u8c03\u7684\u80fd\u529b\uff0c\u5206\u6790\u4e0d\u540c\u4efb\u52a1\u6240\u9700\u7684\u6570\u636e\u96c6\u89c4\u6a21\u3002", "result": "\u5728\u6587\u672c\u751f\u6210\u548c\u7ebf\u6027\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u786e\u5b9a\u4e86\u8fd1\u4f3c\u5fae\u8c03\u884c\u4e3a\u6240\u9700\u7684\u6570\u636e\u96c6\u89c4\u6a21\uff0c\u5e76\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u3002", "conclusion": "\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6548\u90e8\u7f72\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5b9e\u9645\u6280\u672f\u5982\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u53ef\u8fde\u63a5\u7406\u8bba\u4e0e\u5e94\u7528\u3002"}}
{"id": "2506.08062", "pdf": "https://arxiv.org/pdf/2506.08062", "abs": "https://arxiv.org/abs/2506.08062", "authors": ["Woosung Kim", "Jinho Lee", "Jongmin Lee", "Byung-Jun Lee"], "title": "FairDICE: Fairness-Driven Offline Multi-Objective Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "Multi-objective Reinforcement Learning", "summary": "Multi-objective reinforcement learning (MORL) aims to optimize policies in\nthe presence of conflicting objectives, where linear scalarization is commonly\nused to reduce vector-valued returns into scalar signals. While effective for\ncertain preferences, this approach cannot capture fairness-oriented goals such\nas Nash social welfare or max-min fairness, which require nonlinear and\nnon-additive trade-offs. Although several online algorithms have been proposed\nfor specific fairness objectives, a unified approach for optimizing nonlinear\nwelfare criteria in the offline setting-where learning must proceed from a\nfixed dataset-remains unexplored. In this work, we present FairDICE, the first\noffline MORL framework that directly optimizes nonlinear welfare objective.\nFairDICE leverages distribution correction estimation to jointly account for\nwelfare maximization and distributional regularization, enabling stable and\nsample-efficient learning without requiring explicit preference weights or\nexhaustive weight search. Across multiple offline benchmarks, FairDICE\ndemonstrates strong fairness-aware performance compared to existing baselines.", "AI": {"tldr": "FairDICE\u662f\u9996\u4e2a\u79bb\u7ebf\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u76f4\u63a5\u4f18\u5316\u975e\u7ebf\u6027\u798f\u5229\u76ee\u6807\uff0c\u65e0\u9700\u663e\u5f0f\u504f\u597d\u6743\u91cd\u6216\u7a77\u4e3e\u641c\u7d22\u3002", "motivation": "\u73b0\u6709\u7ebf\u6027\u6807\u91cf\u5316\u65b9\u6cd5\u65e0\u6cd5\u6355\u6349\u516c\u5e73\u5bfc\u5411\u76ee\u6807\uff08\u5982Nash\u793e\u4f1a\u798f\u5229\u6216\u6700\u5927\u6700\u5c0f\u516c\u5e73\uff09\uff0c\u79bb\u7ebf\u73af\u5883\u4e0b\u975e\u7ebf\u6027\u798f\u5229\u6807\u51c6\u7684\u7edf\u4e00\u4f18\u5316\u65b9\u6cd5\u5c1a\u672a\u63a2\u7d22\u3002", "method": "FairDICE\u5229\u7528\u5206\u5e03\u6821\u6b63\u4f30\u8ba1\u8054\u5408\u8003\u8651\u798f\u5229\u6700\u5927\u5316\u548c\u5206\u5e03\u6b63\u5219\u5316\uff0c\u5b9e\u73b0\u7a33\u5b9a\u4e14\u6837\u672c\u9ad8\u6548\u7684\u5b66\u4e60\u3002", "result": "\u5728\u591a\u4e2a\u79bb\u7ebf\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cFairDICE\u8868\u73b0\u51fa\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u7684\u516c\u5e73\u611f\u77e5\u6027\u80fd\u3002", "conclusion": "FairDICE\u4e3a\u79bb\u7ebfMORL\u4e2d\u975e\u7ebf\u6027\u798f\u5229\u76ee\u6807\u7684\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.08063", "pdf": "https://arxiv.org/pdf/2506.08063", "abs": "https://arxiv.org/abs/2506.08063", "authors": ["Songqiao Hu", "Zeyi Liu", "Xiao He"], "title": "Lite-RVFL: A Lightweight Random Vector Functional-Link Neural Network for Learning Under Concept Drift", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": "6 pages, 4 figures, accepted by the 2025 CAA Symposium on Fault\n  Detection, Supervision and Safety for Technical Processes (SAFEPROCESS 2025)", "summary": "The change in data distribution over time, also known as concept drift, poses\na significant challenge to the reliability of online learning methods. Existing\nmethods typically require model retraining or drift detection, both of which\ndemand high computational costs and are often unsuitable for real-time\napplications. To address these limitations, a lightweight, fast and efficient\nrandom vector functional-link network termed Lite-RVFL is proposed, capable of\nadapting to concept drift without drift detection and retraining. Lite-RVFL\nintroduces a novel objective function that assigns weights exponentially\nincreasing to new samples, thereby emphasizing recent data and enabling timely\nadaptation. Theoretical analysis confirms the feasibility of this objective\nfunction for drift adaptation, and an efficient incremental update rule is\nderived. Experimental results on a real-world safety assessment task validate\nthe efficiency, effectiveness in adapting to drift, and potential to capture\ntemporal patterns of Lite-RVFL. The source code is available at\nhttps://github.com/songqiaohu/Lite-RVFL.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u5feb\u901f\u9ad8\u6548\u7684\u968f\u673a\u5411\u91cf\u529f\u80fd\u94fe\u63a5\u7f51\u7edcLite-RVFL\uff0c\u65e0\u9700\u68c0\u6d4b\u6982\u5ff5\u6f02\u79fb\u6216\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u9002\u5e94\u6570\u636e\u5206\u5e03\u53d8\u5316\u3002", "motivation": "\u5728\u7ebf\u5b66\u4e60\u65b9\u6cd5\u5728\u6570\u636e\u5206\u5e03\u968f\u65f6\u95f4\u53d8\u5316\uff08\u6982\u5ff5\u6f02\u79fb\uff09\u65f6\u53ef\u9760\u6027\u4e0b\u964d\uff0c\u73b0\u6709\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u4e0d\u9002\u5408\u5b9e\u65f6\u5e94\u7528\u3002", "method": "Lite-RVFL\u901a\u8fc7\u6307\u6570\u52a0\u6743\u65b0\u6837\u672c\u7684\u76ee\u6807\u51fd\u6570\uff0c\u5f3a\u8c03\u8fd1\u671f\u6570\u636e\u5e76\u5b9e\u73b0\u5feb\u901f\u9002\u5e94\uff0c\u540c\u65f6\u63a8\u5bfc\u4e86\u9ad8\u6548\u7684\u589e\u91cf\u66f4\u65b0\u89c4\u5219\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86Lite-RVFL\u5728\u9002\u5e94\u6982\u5ff5\u6f02\u79fb\u548c\u6355\u6349\u65f6\u95f4\u6a21\u5f0f\u4e0a\u7684\u9ad8\u6548\u6027\u548c\u6709\u6548\u6027\u3002", "conclusion": "Lite-RVFL\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u5feb\u901f\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u5b9e\u65f6\u5e94\u7528\u4e2d\u7684\u6982\u5ff5\u6f02\u79fb\u95ee\u9898\u3002"}}
{"id": "2506.08070", "pdf": "https://arxiv.org/pdf/2506.08070", "abs": "https://arxiv.org/abs/2506.08070", "authors": ["Ziheng Qin", "Hailun Xu", "Wei Chee Yew", "Qi Jia", "Yang Luo", "Kanchan Sarkar", "Danhui Guan", "Kai Wang", "Yang You"], "title": "Info-Coevolution: An Efficient Framework for Data Model Coevolution", "categories": ["cs.LG", "cs.AI"], "comment": "V1", "summary": "Machine learning relies heavily on data, yet the continuous growth of\nreal-world data poses challenges for efficient dataset construction and\ntraining. A fundamental yet unsolved question is: given our current model and\ndata, does a new data (sample/batch) need annotation/learning? Conventional\napproaches retain all available data, leading to non-optimal data and training\nefficiency. Active learning aims to reduce data redundancy by selecting a\nsubset of samples to annotate, while it increases pipeline complexity and\nintroduces bias. In this work, we propose Info-Coevolution, a novel framework\nthat efficiently enables models and data to coevolve through online selective\nannotation with no bias. Leveraging task-specific models (and open-source\nmodels), it selectively annotates and integrates online and web data to improve\ndatasets efficiently. For real-world datasets like ImageNet-1K,\nInfo-Coevolution reduces annotation and training costs by 32\\% without\nperformance loss. It is able to automatically give the saving ratio without\ntuning the ratio. It can further reduce the annotation ratio to 50\\% with\nsemi-supervised learning. We also explore retrieval-based dataset enhancement\nusing unlabeled open-source data. Code is available at\nhttps://github.com/NUS-HPC-AI-Lab/Info-Coevolution/.", "AI": {"tldr": "Info-Coevolution\u662f\u4e00\u79cd\u65b0\u9896\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u7ebf\u9009\u62e9\u6027\u6807\u6ce8\u5b9e\u73b0\u6a21\u578b\u4e0e\u6570\u636e\u7684\u534f\u540c\u8fdb\u5316\uff0c\u663e\u8457\u964d\u4f4e\u6807\u6ce8\u548c\u8bad\u7ec3\u6210\u672c\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u6570\u636e\u7684\u6301\u7eed\u589e\u957f\u5bfc\u81f4\u6570\u636e\u96c6\u6784\u5efa\u548c\u8bad\u7ec3\u6548\u7387\u4f4e\u4e0b\uff0c\u4f20\u7edf\u65b9\u6cd5\u65e0\u6cd5\u9ad8\u6548\u9009\u62e9\u9700\u8981\u6807\u6ce8\u7684\u65b0\u6570\u636e\u3002", "method": "\u5229\u7528\u4efb\u52a1\u7279\u5b9a\u6a21\u578b\u548c\u5f00\u6e90\u6a21\u578b\uff0c\u9009\u62e9\u6027\u6807\u6ce8\u5e76\u6574\u5408\u5728\u7ebf\u548c\u7f51\u7edc\u6570\u636e\uff0c\u5b9e\u73b0\u9ad8\u6548\u6570\u636e\u96c6\u6539\u8fdb\u3002", "result": "\u5728ImageNet-1K\u7b49\u6570\u636e\u96c6\u4e0a\uff0c\u6807\u6ce8\u548c\u8bad\u7ec3\u6210\u672c\u964d\u4f4e32%\uff0c\u4e14\u65e0\u9700\u8c03\u53c2\u5373\u53ef\u81ea\u52a8\u786e\u5b9a\u8282\u7701\u6bd4\u4f8b\u3002\u7ed3\u5408\u534a\u76d1\u7763\u5b66\u4e60\uff0c\u6807\u6ce8\u6bd4\u4f8b\u53ef\u8fdb\u4e00\u6b65\u964d\u81f350%\u3002", "conclusion": "Info-Coevolution\u901a\u8fc7\u65e0\u504f\u89c1\u7684\u5728\u7ebf\u9009\u62e9\u6027\u6807\u6ce8\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6570\u636e\u6548\u7387\u548c\u8bad\u7ec3\u6548\u679c\u3002"}}
{"id": "2506.08113", "pdf": "https://arxiv.org/pdf/2506.08113", "abs": "https://arxiv.org/abs/2506.08113", "authors": ["Timoth\u00e9e Hornek Amir Sartipi", "Igor Tchappi", "Gilbert Fridgen"], "title": "Benchmarking Pre-Trained Time Series Models for Electricity Price Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Accurate electricity price forecasting (EPF) is crucial for effective\ndecision-making in power trading on the spot market. While recent advances in\ngenerative artificial intelligence (GenAI) and pre-trained large language\nmodels (LLMs) have inspired the development of numerous time series foundation\nmodels (TSFMs) for time series forecasting, their effectiveness in EPF remains\nuncertain. To address this gap, we benchmark several state-of-the-art\npretrained models--Chronos-Bolt, Chronos-T5, TimesFM, Moirai, Time-MoE, and\nTimeGPT--against established statistical and machine learning (ML) methods for\nEPF. Using 2024 day-ahead auction (DAA) electricity prices from Germany,\nFrance, the Netherlands, Austria, and Belgium, we generate daily forecasts with\na one-day horizon. Chronos-Bolt and Time-MoE emerge as the strongest among the\nTSFMs, performing on par with traditional models. However, the biseasonal MSTL\nmodel, which captures daily and weekly seasonality, stands out for its\nconsistent performance across countries and evaluation metrics, with no TSFM\nstatistically outperforming it.", "AI": {"tldr": "\u8bba\u6587\u6bd4\u8f83\u4e86\u591a\u79cd\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\uff08TSFMs\uff09\u4e0e\u4f20\u7edf\u7edf\u8ba1\u548c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u7535\u529b\u4ef7\u683c\u9884\u6d4b\uff08EPF\uff09\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0TSFMs\u4e0e\u4f20\u7edf\u65b9\u6cd5\u8868\u73b0\u76f8\u5f53\uff0c\u4f46\u53cc\u5b63\u8282\u6027MSTL\u6a21\u578b\u5728\u4e00\u81f4\u6027\u548c\u6027\u80fd\u4e0a\u66f4\u4f18\u3002", "motivation": "\u7535\u529b\u4ef7\u683c\u9884\u6d4b\u5bf9\u7535\u529b\u73b0\u8d27\u5e02\u573a\u4ea4\u6613\u51b3\u7b56\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u548c\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u5728EPF\u4e2d\u7684\u6548\u679c\u5c1a\u4e0d\u660e\u786e\uff0c\u56e0\u6b64\u9700\u8981\u8bc4\u4f30\u5176\u6027\u80fd\u3002", "method": "\u4f7f\u7528\u5fb7\u56fd\u3001\u6cd5\u56fd\u3001\u8377\u5170\u3001\u5965\u5730\u5229\u548c\u6bd4\u5229\u65f6\u76842024\u5e74\u65e5\u524d\u62cd\u5356\u7535\u529b\u4ef7\u683c\u6570\u636e\uff0c\u6bd4\u8f83\u4e86\u591a\u79cdTSFMs\uff08\u5982Chronos-Bolt\u3001Time-MoE\u7b49\uff09\u4e0e\u4f20\u7edf\u65b9\u6cd5\uff08\u5982MSTL\u6a21\u578b\uff09\u7684\u9884\u6d4b\u6548\u679c\u3002", "result": "Chronos-Bolt\u548cTime-MoE\u5728TSFMs\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u5f53\uff0c\u4f46\u53cc\u5b63\u8282\u6027MSTL\u6a21\u578b\u5728\u4e00\u81f4\u6027\u548c\u6027\u80fd\u4e0a\u66f4\u4f18\u3002", "conclusion": "TSFMs\u5728EPF\u4e2d\u8868\u73b0\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u5f53\uff0c\u4f46MSTL\u6a21\u578b\u56e0\u5176\u6355\u83b7\u5b63\u8282\u6027\u7684\u80fd\u529b\u800c\u6210\u4e3a\u66f4\u53ef\u9760\u7684\u9009\u62e9\u3002"}}
{"id": "2506.08125", "pdf": "https://arxiv.org/pdf/2506.08125", "abs": "https://arxiv.org/abs/2506.08125", "authors": ["Hanbing Liu", "Lang Cao", "Yuanyi Ren", "Mengyu Zhou", "Haoyu Dong", "Xiaojun Ma", "Shi Han", "Dongmei Zhang"], "title": "Bingo: Boosting Efficient Reasoning of LLMs via Dynamic and Significance-based Reinforcement Learning", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Large language models have demonstrated impressive reasoning capabilities,\nyet they often suffer from inefficiencies due to unnecessarily verbose or\nredundant outputs. While many works have explored reinforcement learning (RL)\nto enhance reasoning abilities, most primarily focus on improving accuracy,\nwith limited attention to reasoning efficiency. Some existing approaches\nintroduce direct length-based rewards to encourage brevity, but this often\nleads to noticeable drops in accuracy. In this paper, we propose Bingo, an RL\nframework that advances length-based reward design to boost efficient\nreasoning. Bingo incorporates two key mechanisms: a significance-aware length\nreward, which gradually guides the model to reduce only insignificant tokens,\nand a dynamic length reward, which initially encourages elaborate reasoning for\nhard questions but decays over time to improve overall efficiency. Experiments\nacross multiple reasoning benchmarks show that Bingo improves both accuracy and\nefficiency. It outperforms the vanilla reward and several other length-based\nreward baselines in RL, achieving a favorable trade-off between accuracy and\nefficiency. These results underscore the potential of training LLMs explicitly\nfor efficient reasoning.", "AI": {"tldr": "Bingo\u662f\u4e00\u4e2aRL\u6846\u67b6\uff0c\u901a\u8fc7\u6539\u8fdb\u957f\u5ea6\u5956\u52b1\u8bbe\u8ba1\uff0c\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6548\u63a8\u7406\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u63d0\u5347\u63a8\u7406\u6548\u7387\u65f6\u5f80\u5f80\u727a\u7272\u51c6\u786e\u6027\uff0cBingo\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "Bingo\u5f15\u5165\u4e24\u79cd\u673a\u5236\uff1a\u663e\u8457\u6027\u611f\u77e5\u957f\u5ea6\u5956\u52b1\u548c\u52a8\u6001\u957f\u5ea6\u5956\u52b1\uff0c\u9010\u6b65\u51cf\u5c11\u5197\u4f59\u8f93\u51fa\u5e76\u4f18\u5316\u6548\u7387\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cBingo\u5728\u591a\u4e2a\u63a8\u7406\u57fa\u51c6\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u51c6\u786e\u6027\u4e0e\u6548\u7387\u7684\u5e73\u8861\u3002", "conclusion": "Bingo\u8bc1\u660e\u4e86\u663e\u5f0f\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u4ee5\u5b9e\u73b0\u9ad8\u6548\u63a8\u7406\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.08139", "pdf": "https://arxiv.org/pdf/2506.08139", "abs": "https://arxiv.org/abs/2506.08139", "authors": ["Aviad Susman", "Mayte Su\u00e1rez-Fari\u00f1as", "Joseph T Colonel"], "title": "Nearness of Neighbors Attention for Regression in Supervised Finetuning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "It is common in supervised machine learning to combine the feature extraction\ncapabilities of neural networks with the predictive power of traditional\nalgorithms, such as k-nearest neighbors (k-NN) or support vector machines. This\nprocedure involves performing supervised fine-tuning (SFT) on a\ndomain-appropriate feature extractor, followed by training a traditional\npredictor on the resulting SFT embeddings. When used in this manner,\ntraditional predictors often deliver increased performance over the SFT model\nitself, despite the fine-tuned feature extractor yielding embeddings\nspecifically optimized for prediction by the neural network's final dense\nlayer. This suggests that directly incorporating traditional algorithms into\nSFT as prediction layers may further improve performance. However, many\ntraditional algorithms have not been implemented as neural network layers due\nto their non-differentiable nature and their unique optimization requirements.\nAs a step towards solving this problem, we introduce the Nearness of Neighbors\nAttention (NONA) regression layer. NONA uses the mechanics of neural network\nattention and a novel learned attention-masking scheme to yield a\ndifferentiable proxy of the k-NN regression algorithm. Results on multiple\nunstructured datasets show improved performance over both dense layer\nprediction and k-NN on SFT embeddings for regression.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aNONA\u7684\u53ef\u5fae\u5206k-NN\u56de\u5f52\u5c42\uff0c\u901a\u8fc7\u7ed3\u5408\u795e\u7ecf\u7f51\u7edc\u6ce8\u610f\u529b\u548c\u5b66\u4e60\u63a9\u7801\u673a\u5236\uff0c\u63d0\u5347\u4e86\u56de\u5f52\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u7b97\u6cd5\uff08\u5982k-NN\uff09\u5728\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u540e\u7684\u7279\u5f81\u63d0\u53d6\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u7531\u4e8e\u4e0d\u53ef\u5fae\u5206\u6027\u96be\u4ee5\u76f4\u63a5\u878d\u5165\u795e\u7ecf\u7f51\u7edc\u3002", "method": "\u63d0\u51faNONA\u5c42\uff0c\u5229\u7528\u6ce8\u610f\u529b\u673a\u5236\u548c\u63a9\u7801\u65b9\u6848\u6a21\u62dfk-NN\u56de\u5f52\uff0c\u4f7f\u5176\u53ef\u5fae\u5206\u5e76\u9002\u7528\u4e8e\u795e\u7ecf\u7f51\u7edc\u3002", "result": "\u5728\u591a\u4e2a\u975e\u7ed3\u6784\u5316\u6570\u636e\u96c6\u4e0a\uff0cNONA\u7684\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u7684\u5bc6\u96c6\u5c42\u9884\u6d4b\u548ck-NN\u65b9\u6cd5\u3002", "conclusion": "NONA\u4e3a\u5c06\u4f20\u7edf\u7b97\u6cd5\u878d\u5165\u795e\u7ecf\u7f51\u7edc\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u884c\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u56de\u5f52\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2506.08140", "pdf": "https://arxiv.org/pdf/2506.08140", "abs": "https://arxiv.org/abs/2506.08140", "authors": ["Yifei Li", "Hanane Nour Moussa", "Ziru Chen", "Shijie Chen", "Botao Yu", "Mingyi Xue", "Benjamin Burns", "Tzu-Yao Chiu", "Vishal Dey", "Zitong Lu", "Chen Wei", "Qianheng Zhang", "Tianyu Zhang", "Song Gao", "Xuhui Huang", "Xia Ning", "Nesreen K. Ahmed", "Ali Payani", "Huan Sun"], "title": "AutoSDT: Scaling Data-Driven Discovery Tasks Toward Open Co-Scientists", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Despite long-standing efforts in accelerating scientific discovery with AI,\nbuilding AI co-scientists remains challenging due to limited high-quality data\nfor training and evaluation. To tackle this data scarcity issue, we present\nAutoSDT, an automatic pipeline that collects high-quality coding tasks in\nreal-world data-driven discovery workflows. AutoSDT leverages the coding\ncapabilities and parametric knowledge of LLMs to search for diverse sources,\nselect ecologically valid tasks, and synthesize accurate task instructions and\ncode solutions. Using our pipeline, we construct AutoSDT-5K, a dataset of 5,404\ncoding tasks for data-driven discovery that covers four scientific disciplines\nand 756 unique Python packages. To the best of our knowledge, AutoSDT-5K is the\nonly automatically collected and the largest open dataset for data-driven\nscientific discovery. Expert feedback on a subset of 256 tasks shows the\neffectiveness of AutoSDT: 93% of the collected tasks are ecologically valid,\nand 92.2% of the synthesized programs are functionally correct. Trained on\nAutoSDT-5K, the Qwen2.5-Coder-Instruct LLM series, dubbed AutoSDT-Coder, show\nsubstantial improvement on two challenging data-driven discovery benchmarks,\nScienceAgentBench and DiscoveryBench. Most notably, AutoSDT-Coder-32B reaches\nthe same level of performance as GPT-4o on ScienceAgentBench with a success\nrate of 7.8%, doubling the performance of its base model. On DiscoveryBench, it\nlifts the hypothesis matching score to 8.1, bringing a 17.4% relative\nimprovement and closing the gap between open-weight models and GPT-4o.", "AI": {"tldr": "AutoSDT\u662f\u4e00\u4e2a\u81ea\u52a8\u6536\u96c6\u9ad8\u8d28\u91cf\u7f16\u7801\u4efb\u52a1\u7684\u7ba1\u9053\uff0c\u7528\u4e8e\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u6784\u5efa\u4e86AutoSDT-5K\u6570\u636e\u96c6\uff0c\u5e76\u8bad\u7ec3\u4e86AutoSDT-Coder\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6570\u636e\u9a71\u52a8\u79d1\u5b66\u53d1\u73b0\u7684\u6027\u80fd\u3002", "motivation": "\u52a0\u901f\u79d1\u5b66\u53d1\u73b0\u9700\u8981\u9ad8\u8d28\u91cf\u7684AI\u8f85\u52a9\u5de5\u5177\uff0c\u4f46\u73b0\u6709\u6570\u636e\u7a00\u7f3a\u4e14\u8d28\u91cf\u4e0d\u8db3\uff0c\u963b\u788d\u4e86AI\u6a21\u578b\u7684\u8bad\u7ec3\u4e0e\u8bc4\u4f30\u3002", "method": "\u5229\u7528LLM\u7684\u7f16\u7801\u80fd\u529b\u548c\u53c2\u6570\u77e5\u8bc6\uff0c\u81ea\u52a8\u641c\u7d22\u591a\u6837\u6765\u6e90\u3001\u9009\u62e9\u751f\u6001\u6709\u6548\u4efb\u52a1\uff0c\u5e76\u5408\u6210\u4efb\u52a1\u6307\u4ee4\u548c\u4ee3\u7801\u89e3\u51b3\u65b9\u6848\uff0c\u6784\u5efaAutoSDT-5K\u6570\u636e\u96c6\u3002", "result": "AutoSDT-5K\u6570\u636e\u96c6\u5305\u542b5,404\u4e2a\u4efb\u52a1\uff0c\u4e13\u5bb6\u8bc4\u4f30\u663e\u793a93%\u7684\u4efb\u52a1\u751f\u6001\u6709\u6548\uff0c92.2%\u7684\u4ee3\u7801\u529f\u80fd\u6b63\u786e\u3002AutoSDT-Coder\u6a21\u578b\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u63a5\u8fd1GPT-4o\u6c34\u5e73\u3002", "conclusion": "AutoSDT\u89e3\u51b3\u4e86\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86AI\u5728\u79d1\u5b66\u53d1\u73b0\u4e2d\u7684\u6027\u80fd\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u548c\u6a21\u578b\u3002"}}
{"id": "2506.08143", "pdf": "https://arxiv.org/pdf/2506.08143", "abs": "https://arxiv.org/abs/2506.08143", "authors": ["Francesco Tonin", "Alex Lambert", "Johan A. K. Suykens", "Volkan Cevher"], "title": "Accelerating Spectral Clustering under Fairness Constraints", "categories": ["cs.LG"], "comment": "ICML 2025", "summary": "Fairness of decision-making algorithms is an increasingly important issue. In\nthis paper, we focus on spectral clustering with group fairness constraints,\nwhere every demographic group is represented in each cluster proportionally as\nin the general population. We present a new efficient method for fair spectral\nclustering (Fair SC) by casting the Fair SC problem within the difference of\nconvex functions (DC) framework. To this end, we introduce a novel variable\naugmentation strategy and employ an alternating direction method of multipliers\ntype of algorithm adapted to DC problems. We show that each associated\nsubproblem can be solved efficiently, resulting in higher computational\nefficiency compared to prior work, which required a computationally expensive\neigendecomposition. Numerical experiments demonstrate the effectiveness of our\napproach on both synthetic and real-world benchmarks, showing significant\nspeedups in computation time over prior art, especially as the problem size\ngrows. This work thus represents a considerable step forward towards the\nadoption of fair clustering in real-world applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u516c\u5e73\u8c31\u805a\u7c7b\u65b9\u6cd5\uff08Fair SC\uff09\uff0c\u901a\u8fc7\u5c06\u95ee\u9898\u8f6c\u5316\u4e3a\u51f8\u5dee\u51fd\u6570\uff08DC\uff09\u6846\u67b6\uff0c\u5e76\u5f15\u5165\u53d8\u91cf\u589e\u5f3a\u7b56\u7565\u548cADMM\u7b97\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u89e3\u51b3\u51b3\u7b56\u7b97\u6cd5\u4e2d\u7684\u516c\u5e73\u6027\u95ee\u9898\uff0c\u786e\u4fdd\u6bcf\u4e2a\u805a\u7c7b\u4e2d\u4eba\u53e3\u7edf\u8ba1\u7fa4\u4f53\u7684\u6bd4\u4f8b\u4e0e\u603b\u4f53\u4e00\u81f4\u3002", "method": "\u5c06\u516c\u5e73\u8c31\u805a\u7c7b\u95ee\u9898\u8f6c\u5316\u4e3aDC\u6846\u67b6\uff0c\u91c7\u7528\u53d8\u91cf\u589e\u5f3a\u7b56\u7565\u548cADMM\u7b97\u6cd5\uff0c\u907f\u514d\u6602\u8d35\u7684\u7279\u5f81\u5206\u89e3\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u8ba1\u7b97\u65f6\u95f4\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u516c\u5e73\u805a\u7c7b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u63a8\u5e7f\u63d0\u4f9b\u4e86\u91cd\u8981\u8fdb\u5c55\u3002"}}
{"id": "2506.08146", "pdf": "https://arxiv.org/pdf/2506.08146", "abs": "https://arxiv.org/abs/2506.08146", "authors": ["Vahidullah Ta\u00e7", "Amirhossein Amiri-Hezaveh", "Manuel K. Rausch", "Grace N. Bechtel", "Francisco Sahli Costabal", "Adrian Buganza Tepole"], "title": "Fully data-driven inverse hyperelasticity with hyper-network neural ODE fields", "categories": ["cs.LG"], "comment": null, "summary": "We propose a new framework for identifying mechanical properties of\nheterogeneous materials without a closed-form constitutive equation. Given a\nfull-field measurement of the displacement field, for instance as obtained from\ndigital image correlation (DIC), a continuous approximation of the strain field\nis obtained by training a neural network that incorporates Fourier features to\neffectively capture sharp gradients in the data. A physics-based data-driven\nmethod built upon ordinary neural differential equations (NODEs) is employed to\ndiscover constitutive equations. The NODE framework can represent arbitrary\nmaterials while satisfying constraints in the theory of constitutive equations\nby default. To account for heterogeneity, a hyper-network is defined, where the\ninput is the material coordinate system, and the output is the NODE-based\nconstitutive equation. The parameters of the hyper-network are optimized by\nminimizing a multi-objective loss function that includes penalty terms for\nviolations of the strong form of the equilibrium equations of elasticity and\nthe associated Neumann boundary conditions. We showcase the framework with\nseveral numerical examples, including heterogeneity arising from variations in\nmaterial parameters, spatial transitions from isotropy to anisotropy, material\nidentification in the presence of noise, and, ultimately, application to\nexperimental data. As the numerical results suggest, the proposed approach is\nrobust and general in identifying the mechanical properties of heterogeneous\nmaterials with very few assumptions, making it a suitable alternative to\nclassical inverse methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u548c\u7269\u7406\u9a71\u52a8\u7684\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u8bc6\u522b\u5f02\u8d28\u6750\u6599\u7684\u529b\u5b66\u7279\u6027\uff0c\u65e0\u9700\u5c01\u95ed\u5f62\u5f0f\u7684\u672c\u6784\u65b9\u7a0b\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u5c01\u95ed\u5f62\u5f0f\u7684\u672c\u6784\u65b9\u7a0b\uff0c\u9650\u5236\u4e86\u5f02\u8d28\u6750\u6599\u529b\u5b66\u7279\u6027\u7684\u8bc6\u522b\u3002\u65b0\u6846\u67b6\u65e8\u5728\u514b\u670d\u8fd9\u4e00\u9650\u5236\u3002", "method": "\u7ed3\u5408\u5085\u91cc\u53f6\u7279\u5f81\u7684\u795e\u7ecf\u7f51\u7edc\u8fd1\u4f3c\u5e94\u53d8\u573a\uff0c\u5229\u7528NODE\u6846\u67b6\u53d1\u73b0\u672c\u6784\u65b9\u7a0b\uff0c\u5e76\u901a\u8fc7\u8d85\u7f51\u7edc\u5904\u7406\u5f02\u8d28\u6027\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u8bc6\u522b\u5f02\u8d28\u6750\u6599\u529b\u5b66\u7279\u6027\u65f6\u5177\u6709\u9c81\u68d2\u6027\u548c\u901a\u7528\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u8bc6\u522b\u5f02\u8d28\u6750\u6599\u529b\u5b66\u7279\u6027\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u5b9e\u9a8c\u6570\u636e\u3002"}}
{"id": "2506.08164", "pdf": "https://arxiv.org/pdf/2506.08164", "abs": "https://arxiv.org/abs/2506.08164", "authors": ["Hadi Reisizadeh", "Jinghan Jia", "Zhiqi Bu", "Bhanukiran Vinzamuri", "Anil Ramakrishna", "Kai-Wei Chang", "Volkan Cevher", "Sijia Liu", "Mingyi Hong"], "title": "BLUR: A Bi-Level Optimization Approach for LLM Unlearning", "categories": ["cs.LG"], "comment": null, "summary": "Enabling large language models (LLMs) to unlearn knowledge and capabilities\nacquired during training has proven vital for ensuring compliance with data\nregulations and promoting ethical practices in generative AI. Although there\nare growing interests in developing various unlearning algorithms, it remains\nunclear how to best formulate the unlearning problem. The most popular\nformulation uses a weighted sum of forget and retain loss, but it often leads\nto performance degradation due to the inherent trade-off between forget and\nretain losses. In this work, we argue that it is important to model the\nhierarchical structure of the unlearning problem, where the forget problem\n(which \\textit{unlearns} certain knowledge and/or capabilities) takes priority\nover the retain problem (which preserves model utility). This hierarchical\nstructure naturally leads to a bi-level optimization formulation where the\nlower-level objective focuses on minimizing the forget loss, while the\nupper-level objective aims to maintain the model's utility. Based on this new\nformulation, we propose a novel algorithm, termed Bi-Level UnleaRning\n(\\texttt{BLUR}), which not only possesses strong theoretical guarantees but\nmore importantly, delivers superior performance. In particular, our extensive\nexperiments demonstrate that \\texttt{BLUR} consistently outperforms all the\nstate-of-the-art algorithms across various unlearning tasks, models, and\nmetrics. Codes are available at\nhttps://github.com/OptimAI-Lab/BLURLLMUnlearning.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9057\u5fd8\u5b66\u4e60\u95ee\u9898\u5206\u5c42\u5efa\u6a21\u65b9\u6cd5\uff0c\u5e76\u8bbe\u8ba1\u4e86Bi-Level UnleaRning (BLUR)\u7b97\u6cd5\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u786e\u4fdd\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u5728\u8bad\u7ec3\u540e\u80fd\u591f\u9057\u5fd8\u7279\u5b9a\u77e5\u8bc6\u6216\u80fd\u529b\uff0c\u4ee5\u7b26\u5408\u6570\u636e\u6cd5\u89c4\u548c\u4f26\u7406\u8981\u6c42\u3002", "method": "\u91c7\u7528\u53cc\u5c42\u4f18\u5316\u6846\u67b6\uff0c\u4e0b\u5c42\u6700\u5c0f\u5316\u9057\u5fd8\u635f\u5931\uff0c\u4e0a\u5c42\u4fdd\u6301\u6a21\u578b\u6548\u7528\uff0c\u63d0\u51faBLUR\u7b97\u6cd5\u3002", "result": "BLUR\u5728\u591a\u79cd\u4efb\u52a1\u3001\u6a21\u578b\u548c\u6307\u6807\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u5206\u5c42\u5efa\u6a21\u548cBLUR\u7b97\u6cd5\u4e3aLLM\u9057\u5fd8\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.08167", "pdf": "https://arxiv.org/pdf/2506.08167", "abs": "https://arxiv.org/abs/2506.08167", "authors": ["Sunny Gupta", "Nikita Jangid", "Amit Sethi"], "title": "UniVarFL: Uniformity and Variance Regularized Federated Learning for Heterogeneous Data", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.DC", "I.2.6; C.1.4; D.1.3; I.5.1; H.3.4; I.2.10; I.4.0; I.4.1; I.4.2;\n  I.4.6; I.4.7; I.4.8; I.4.9; I.4.10; I.5.1; I.5.2; I.5.4; J.2; I.2.11; I.2.10"], "comment": null, "summary": "Federated Learning (FL) often suffers from severe performance degradation\nwhen faced with non-IID data, largely due to local classifier bias. Traditional\nremedies such as global model regularization or layer freezing either incur\nhigh computational costs or struggle to adapt to feature shifts. In this work,\nwe propose UniVarFL, a novel FL framework that emulates IID-like training\ndynamics directly at the client level, eliminating the need for global model\ndependency. UniVarFL leverages two complementary regularization strategies\nduring local training: Classifier Variance Regularization, which aligns\nclass-wise probability distributions with those expected under IID conditions,\neffectively mitigating local classifier bias; and Hyperspherical Uniformity\nRegularization, which encourages a uniform distribution of feature\nrepresentations across the hypersphere, thereby enhancing the model's ability\nto generalize under diverse data distributions. Extensive experiments on\nmultiple benchmark datasets demonstrate that UniVarFL outperforms existing\nmethods in accuracy, highlighting its potential as a highly scalable and\nefficient solution for real-world FL deployments, especially in\nresource-constrained settings. Code: https://github.com/sunnyinAI/UniVarFL", "AI": {"tldr": "UniVarFL\u662f\u4e00\u79cd\u65b0\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u79cd\u6b63\u5219\u5316\u7b56\u7565\u89e3\u51b3\u975eIID\u6570\u636e\u4e0b\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u5728\u975eIID\u6570\u636e\u4e0b\u56e0\u5c40\u90e8\u5206\u7c7b\u5668\u504f\u5dee\u5bfc\u81f4\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\u3002", "method": "\u63d0\u51faUniVarFL\u6846\u67b6\uff0c\u7ed3\u5408\u5206\u7c7b\u5668\u65b9\u5dee\u6b63\u5219\u5316\u548c\u8d85\u7403\u9762\u5747\u5300\u6027\u6b63\u5219\u5316\uff0c\u6a21\u62dfIID\u8bad\u7ec3\u52a8\u6001\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cUniVarFL\u5728\u51c6\u786e\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "UniVarFL\u662f\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u7684\u5b9e\u9645\u8054\u90a6\u5b66\u4e60\u90e8\u7f72\u3002"}}
{"id": "2506.08169", "pdf": "https://arxiv.org/pdf/2506.08169", "abs": "https://arxiv.org/abs/2506.08169", "authors": ["Jingqiao Tang", "Ryan Bausback", "Feng Bao", "Richard Archibald"], "title": "Federated Learning on Stochastic Neural Networks", "categories": ["cs.LG", "cs.DC"], "comment": "25 pages, 19 figures, Submitted to Journal of Machine Learning for\n  Modeling and Computing", "summary": "Federated learning is a machine learning paradigm that leverages edge\ncomputing on client devices to optimize models while maintaining user privacy\nby ensuring that local data remains on the device. However, since all data is\ncollected by clients, federated learning is susceptible to latent noise in\nlocal datasets. Factors such as limited measurement capabilities or human\nerrors may introduce inaccuracies in client data. To address this challenge, we\npropose the use of a stochastic neural network as the local model within the\nfederated learning framework. Stochastic neural networks not only facilitate\nthe estimation of the true underlying states of the data but also enable the\nquantification of latent noise. We refer to our federated learning approach,\nwhich incorporates stochastic neural networks as local models, as Federated\nstochastic neural networks. We will present numerical experiments demonstrating\nthe performance and effectiveness of our method, particularly in handling\nnon-independent and identically distributed data.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u968f\u673a\u795e\u7ecf\u7f51\u7edc\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u5904\u7406\u672c\u5730\u6570\u636e\u4e2d\u7684\u6f5c\u5728\u566a\u58f0\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u4e2d\u672c\u5730\u6570\u636e\u53ef\u80fd\u56e0\u6d4b\u91cf\u80fd\u529b\u6709\u9650\u6216\u4eba\u4e3a\u9519\u8bef\u5f15\u5165\u566a\u58f0\uff0c\u5f71\u54cd\u6a21\u578b\u6027\u80fd\u3002", "method": "\u5728\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u4e2d\u4f7f\u7528\u968f\u673a\u795e\u7ecf\u7f51\u7edc\u4f5c\u4e3a\u672c\u5730\u6a21\u578b\uff0c\u4f30\u8ba1\u6570\u636e\u771f\u5b9e\u72b6\u6001\u5e76\u91cf\u5316\u566a\u58f0\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u5904\u7406\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u65f6\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u8054\u90a6\u968f\u673a\u795e\u7ecf\u7f51\u7edc\u80fd\u6709\u6548\u89e3\u51b3\u672c\u5730\u6570\u636e\u566a\u58f0\u95ee\u9898\uff0c\u63d0\u5347\u6a21\u578b\u9c81\u68d2\u6027\u3002"}}
{"id": "2506.08176", "pdf": "https://arxiv.org/pdf/2506.08176", "abs": "https://arxiv.org/abs/2506.08176", "authors": ["Anh V Nguyen", "Diego Klabjan"], "title": "FedGA-Tree: Federated Decision Tree using Genetic Algorithm", "categories": ["cs.LG"], "comment": null, "summary": "In recent years, with rising concerns for data privacy, Federated Learning\nhas gained prominence, as it enables collaborative training without the\naggregation of raw data from participating clients. However, much of the\ncurrent focus has been on parametric gradient-based models, while nonparametric\ncounterparts such as decision tree are relatively understudied. Existing\nmethods for adapting decision trees to Federated Learning generally combine a\ngreedy tree-building algorithm with differential privacy to produce a global\nmodel for all clients. These methods are limited to classification trees and\ncategorical data due to the constraints of differential privacy. In this paper,\nwe explore an alternative approach that utilizes Genetic Algorithm to\nfacilitate the construction of personalized decision trees and accommodate\ncategorical and numerical data, thus allowing for both classification and\nregression trees. Comprehensive experiments demonstrate that our method\nsurpasses decision trees trained solely on local data and a benchmark\nalgorithm.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9057\u4f20\u7b97\u6cd5\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u6784\u5efa\u4e2a\u6027\u5316\u7684\u51b3\u7b56\u6811\uff0c\u652f\u6301\u5206\u7c7b\u548c\u56de\u5f52\u4efb\u52a1\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u8054\u90a6\u5b66\u4e60\u4e3b\u8981\u5173\u6ce8\u57fa\u4e8e\u68af\u5ea6\u7684\u53c2\u6570\u6a21\u578b\uff0c\u975e\u53c2\u6570\u6a21\u578b\uff08\u5982\u51b3\u7b56\u6811\uff09\u7814\u7a76\u8f83\u5c11\uff0c\u4e14\u73b0\u6709\u65b9\u6cd5\u53d7\u9650\u4e8e\u5dee\u5206\u9690\u79c1\uff0c\u4ec5\u9002\u7528\u4e8e\u5206\u7c7b\u4efb\u52a1\u548c\u5206\u7c7b\u6570\u636e\u3002", "method": "\u5229\u7528\u9057\u4f20\u7b97\u6cd5\u6784\u5efa\u4e2a\u6027\u5316\u7684\u51b3\u7b56\u6811\uff0c\u652f\u6301\u5206\u7c7b\u548c\u6570\u503c\u6570\u636e\uff0c\u9002\u7528\u4e8e\u5206\u7c7b\u548c\u56de\u5f52\u4efb\u52a1\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u4ec5\u57fa\u4e8e\u672c\u5730\u6570\u636e\u8bad\u7ec3\u7684\u51b3\u7b56\u6811\u548c\u57fa\u51c6\u7b97\u6cd5\u3002", "conclusion": "\u9057\u4f20\u7b97\u6cd5\u4e3a\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u51b3\u7b56\u6811\u63d0\u4f9b\u4e86\u4e00\u79cd\u7075\u6d3b\u4e14\u9ad8\u6548\u7684\u65b9\u6cd5\uff0c\u6269\u5c55\u4e86\u5176\u5e94\u7528\u8303\u56f4\u3002"}}
{"id": "2506.08201", "pdf": "https://arxiv.org/pdf/2506.08201", "abs": "https://arxiv.org/abs/2506.08201", "authors": ["Krishna Pillutla", "Jalaj Upadhyay", "Christopher A. Choquette-Choo", "Krishnamurthy Dvijotham", "Arun Ganesh", "Monika Henzinger", "Jonathan Katz", "Ryan McKenna", "H. Brendan McMahan", "Keith Rush", "Thomas Steinke", "Abhradeep Thakurta"], "title": "Correlated Noise Mechanisms for Differentially Private Learning", "categories": ["cs.LG"], "comment": "212 pages", "summary": "This monograph explores the design and analysis of correlated noise\nmechanisms for differential privacy (DP), focusing on their application to\nprivate training of AI and machine learning models via the core primitive of\nestimation of weighted prefix sums. While typical DP mechanisms inject\nindependent noise into each step of a stochastic gradient (SGD) learning\nalgorithm in order to protect the privacy of the training data, a growing body\nof recent research demonstrates that introducing (anti-)correlations in the\nnoise can significantly improve privacy-utility trade-offs by carefully\ncanceling out some of the noise added on earlier steps in subsequent steps.\nSuch correlated noise mechanisms, known variously as matrix mechanisms,\nfactorization mechanisms, and DP-Follow-the-Regularized-Leader (DP-FTRL) when\napplied to learning algorithms, have also been influential in practice, with\nindustrial deployment at a global scale.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u76f8\u5173\u566a\u58f0\u673a\u5236\u5728\u5dee\u5206\u9690\u79c1\uff08DP\uff09\u4e2d\u7684\u8bbe\u8ba1\u4e0e\u5206\u6790\uff0c\u91cd\u70b9\u7814\u7a76\u4e86\u5176\u5728AI\u548c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u79c1\u6709\u8bad\u7ec3\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u4f20\u7edfDP\u673a\u5236\u5728\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff08SGD\uff09\u7684\u6bcf\u4e00\u6b65\u6ce8\u5165\u72ec\u7acb\u566a\u58f0\u4ee5\u4fdd\u62a4\u8bad\u7ec3\u6570\u636e\u7684\u9690\u79c1\uff0c\u4f46\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u5f15\u5165\uff08\u53cd\uff09\u76f8\u5173\u566a\u58f0\u53ef\u4ee5\u663e\u8457\u6539\u5584\u9690\u79c1\u4e0e\u6548\u7528\u7684\u6743\u8861\u3002", "method": "\u7814\u7a76\u91c7\u7528\u52a0\u6743\u524d\u7f00\u548c\u4f30\u8ba1\u4f5c\u4e3a\u6838\u5fc3\u65b9\u6cd5\uff0c\u63a2\u8ba8\u4e86\u77e9\u9635\u673a\u5236\u3001\u56e0\u5b50\u5206\u89e3\u673a\u5236\u548cDP-FTRL\u7b49\u566a\u58f0\u673a\u5236\u3002", "result": "\u76f8\u5173\u566a\u58f0\u673a\u5236\u5728\u5b9e\u8df5\u4e2d\u5177\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u5df2\u5728\u5168\u7403\u8303\u56f4\u5185\u5b9e\u73b0\u5de5\u4e1a\u7ea7\u90e8\u7f72\u3002", "conclusion": "\u76f8\u5173\u566a\u58f0\u673a\u5236\u80fd\u591f\u901a\u8fc7\u566a\u58f0\u62b5\u6d88\u4f18\u5316\u9690\u79c1-\u6548\u7528\u6743\u8861\uff0c\u4e3aDP\u5728AI\u8bad\u7ec3\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.08205", "pdf": "https://arxiv.org/pdf/2506.08205", "abs": "https://arxiv.org/abs/2506.08205", "authors": ["Shadab Anwar Shaikh", "Kranthi Balusu", "Ayoub Soulami"], "title": "A Machine Learning Approach to Generate Residual Stress Distributions using Sparse Characterization Data in Friction-Stir Processed Parts", "categories": ["cs.LG", "cs.CE"], "comment": null, "summary": "Residual stresses, which remain within a component after processing, can\ndeteriorate performance. Accurately determining their full-field distributions\nis essential for optimizing the structural integrity and longevity. However,\nthe experimental effort required for full-field characterization is\nimpractical. Given these challenges, this work proposes a machine learning (ML)\nbased Residual Stress Generator (RSG) to infer full-field stresses from limited\nmeasurements. An extensive dataset was initially constructed by performing\nnumerous process simulations with a diverse parameter set. A ML model based on\nU-Net architecture was then trained to learn the underlying structure through\nsystematic hyperparameter tuning. Then, the model's ability to generate\nsimulated stresses was evaluated, and it was ultimately tested on actual\ncharacterization data to validate its effectiveness. The model's prediction of\nsimulated stresses shows that it achieved excellent predictive accuracy and\nexhibited a significant degree of generalization, indicating that it\nsuccessfully learnt the latent structure of residual stress distribution. The\nRSG's performance in predicting experimentally characterized data highlights\nthe feasibility of the proposed approach in providing a comprehensive\nunderstanding of residual stress distributions from limited measurements,\nthereby significantly reducing experimental efforts.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u6b8b\u4f59\u5e94\u529b\u751f\u6210\u5668\uff08RSG\uff09\uff0c\u7528\u4e8e\u4ece\u6709\u9650\u6d4b\u91cf\u6570\u636e\u63a8\u65ad\u5168\u573a\u5e94\u529b\u5206\u5e03\uff0c\u663e\u8457\u51cf\u5c11\u5b9e\u9a8c\u5de5\u4f5c\u91cf\u3002", "motivation": "\u6b8b\u4f59\u5e94\u529b\u4f1a\u5f71\u54cd\u7ec4\u4ef6\u6027\u80fd\uff0c\u4f46\u5168\u573a\u5e94\u529b\u5206\u5e03\u7684\u5b9e\u9a8c\u8868\u5f81\u4e0d\u5207\u5b9e\u9645\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u9ad8\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u5927\u91cf\u5de5\u827a\u6a21\u62df\u6784\u5efa\u6570\u636e\u96c6\uff0c\u4f7f\u7528U-Net\u67b6\u6784\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u548c\u8d85\u53c2\u6570\u8c03\u4f18\u3002", "result": "\u6a21\u578b\u5728\u6a21\u62df\u5e94\u529b\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u9ad8\u7cbe\u5ea6\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u5b9e\u9a8c\u6570\u636e\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "RSG\u65b9\u6cd5\u53ef\u884c\uff0c\u80fd\u4ece\u6709\u9650\u6d4b\u91cf\u4e2d\u5168\u9762\u7406\u89e3\u6b8b\u4f59\u5e94\u529b\u5206\u5e03\uff0c\u663e\u8457\u964d\u4f4e\u5b9e\u9a8c\u6210\u672c\u3002"}}
{"id": "2506.08216", "pdf": "https://arxiv.org/pdf/2506.08216", "abs": "https://arxiv.org/abs/2506.08216", "authors": ["Shahaf Bassan", "Guy Amir", "Meirav Zehavi", "Guy Katz"], "title": "What makes an Ensemble (Un) Interpretable?", "categories": ["cs.LG", "cs.CC", "cs.LO"], "comment": "To appear in ICML 2025", "summary": "Ensemble models are widely recognized in the ML community for their limited\ninterpretability. For instance, while a single decision tree is considered\ninterpretable, ensembles of trees (e.g., boosted trees) are often treated as\nblack-boxes. Despite this folklore recognition, there remains a lack of\nrigorous mathematical understanding of what particularly makes an ensemble\n(un)-interpretable, including how fundamental factors like the (1) *number*,\n(2) *size*, and (3) *type* of base models influence its interpretability. In\nthis work, we seek to bridge this gap by applying concepts from computational\ncomplexity theory to study the challenges of generating explanations for\nvarious ensemble configurations. Our analysis uncovers nuanced complexity\npatterns influenced by various factors. For example, we demonstrate that under\nstandard complexity assumptions like P$\\neq$NP, interpreting ensembles remains\nintractable even when base models are of constant size. Surprisingly, the\ncomplexity changes drastically with the number of base models: small ensembles\nof decision trees are efficiently interpretable, whereas interpreting ensembles\nwith even a constant number of linear models remains intractable. We believe\nthat our findings provide a more robust foundation for understanding the\ninterpretability of ensembles, emphasizing the benefits of examining it through\na computational complexity lens.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u96c6\u6210\u6a21\u578b\u7684\u89e3\u91ca\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u8ba1\u7b97\u590d\u6742\u6027\u7406\u8bba\u5206\u6790\u4e86\u5f71\u54cd\u89e3\u91ca\u6027\u7684\u56e0\u7d20\uff0c\u53d1\u73b0\u4e0d\u540c\u914d\u7f6e\u7684\u96c6\u6210\u6a21\u578b\u5728\u89e3\u91ca\u6027\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002", "motivation": "\u96c6\u6210\u6a21\u578b\uff08\u5982\u63d0\u5347\u6811\uff09\u901a\u5e38\u88ab\u89c6\u4e3a\u9ed1\u7bb1\uff0c\u7f3a\u4e4f\u5bf9\u5176\u89e3\u91ca\u6027\u4e3a\u4f55\u53d7\u9650\u7684\u4e25\u683c\u6570\u5b66\u7406\u89e3\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u5e94\u7528\u8ba1\u7b97\u590d\u6742\u6027\u7406\u8bba\uff0c\u7814\u7a76\u4e0d\u540c\u56e0\u7d20\uff08\u5982\u57fa\u7840\u6a21\u578b\u7684\u6570\u91cf\u3001\u5927\u5c0f\u548c\u7c7b\u578b\uff09\u5bf9\u96c6\u6210\u6a21\u578b\u89e3\u91ca\u6027\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5373\u4f7f\u57fa\u7840\u6a21\u578b\u5927\u5c0f\u56fa\u5b9a\uff0c\u89e3\u91ca\u96c6\u6210\u6a21\u578b\u4ecd\u5177\u6709\u8ba1\u7b97\u96be\u5ea6\uff1b\u800c\u57fa\u7840\u6a21\u578b\u6570\u91cf\u5bf9\u89e3\u91ca\u6027\u5f71\u54cd\u663e\u8457\u3002", "conclusion": "\u901a\u8fc7\u8ba1\u7b97\u590d\u6742\u6027\u89c6\u89d2\uff0c\u4e3a\u7406\u89e3\u96c6\u6210\u6a21\u578b\u7684\u89e3\u91ca\u6027\u63d0\u4f9b\u4e86\u66f4\u575a\u5b9e\u7684\u57fa\u7840\uff0c\u5f3a\u8c03\u4e86\u8fd9\u4e00\u65b9\u6cd5\u7684\u4f18\u52bf\u3002"}}
{"id": "2506.08226", "pdf": "https://arxiv.org/pdf/2506.08226", "abs": "https://arxiv.org/abs/2506.08226", "authors": ["Arthur Feeney", "Kuei-Hsiang Huang", "Aparna Chandramowlishwaran"], "title": "Mondrian: Transformer Operators via Domain Decomposition", "categories": ["cs.LG"], "comment": "26 pages, 7 figures", "summary": "Operator learning enables data-driven modeling of partial differential\nequations (PDEs) by learning mappings between function spaces. However, scaling\ntransformer-based operator models to high-resolution, multiscale domains\nremains a challenge due to the quadratic cost of attention and its coupling to\ndiscretization. We introduce \\textbf{Mondrian}, transformer operators that\ndecompose a domain into non-overlapping subdomains and apply attention over\nsequences of subdomain-restricted functions. Leveraging principles from domain\ndecomposition, Mondrian decouples attention from discretization. Within each\nsubdomain, it replaces standard layers with expressive neural operators, and\nattention across subdomains is computed via softmax-based inner products over\nfunctions. The formulation naturally extends to hierarchical windowed and\nneighborhood attention, supporting both local and global interactions. Mondrian\nachieves strong performance on Allen-Cahn and Navier-Stokes PDEs, demonstrating\nresolution scaling without retraining. These results highlight the promise of\ndomain-decomposed attention for scalable and general-purpose neural operators.", "AI": {"tldr": "Mondrian\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u57df\u5206\u89e3\u7684Transformer\u7b97\u5b50\uff0c\u901a\u8fc7\u5c06\u57df\u5212\u5206\u4e3a\u975e\u91cd\u53e0\u5b50\u57df\u5e76\u5e94\u7528\u6ce8\u610f\u529b\u673a\u5236\uff0c\u89e3\u51b3\u4e86\u9ad8\u5206\u8fa8\u7387\u591a\u5c3a\u5ea6PDE\u5efa\u6a21\u4e2d\u7684\u8ba1\u7b97\u6210\u672c\u95ee\u9898\u3002", "motivation": "\u4f20\u7edfTransformer\u5728\u5efa\u6a21\u9ad8\u5206\u8fa8\u7387\u591a\u5c3a\u5ea6PDE\u65f6\uff0c\u7531\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684\u4e8c\u6b21\u8ba1\u7b97\u6210\u672c\u548c\u4e0e\u79bb\u6563\u5316\u7684\u8026\u5408\uff0c\u96be\u4ee5\u6269\u5c55\u3002Mondrian\u65e8\u5728\u901a\u8fc7\u57df\u5206\u89e3\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "Mondrian\u5c06\u57df\u5206\u89e3\u4e3a\u5b50\u57df\uff0c\u5728\u6bcf\u4e2a\u5b50\u57df\u5185\u4f7f\u7528\u795e\u7ecf\u7b97\u5b50\u66ff\u4ee3\u6807\u51c6\u5c42\uff0c\u5e76\u901a\u8fc7\u57fa\u4e8esoftmax\u7684\u5185\u79ef\u8ba1\u7b97\u5b50\u57df\u95f4\u7684\u6ce8\u610f\u529b\u3002\u652f\u6301\u5206\u5c42\u7a97\u53e3\u548c\u90bb\u57df\u6ce8\u610f\u529b\u3002", "result": "\u5728Allen-Cahn\u548cNavier-Stokes PDE\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5c55\u793a\u4e86\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u7684\u5206\u8fa8\u7387\u6269\u5c55\u80fd\u529b\u3002", "conclusion": "\u57df\u5206\u89e3\u6ce8\u610f\u529b\u673a\u5236\u4e3a\u53ef\u6269\u5c55\u548c\u901a\u7528\u7684\u795e\u7ecf\u7b97\u5b50\u63d0\u4f9b\u4e86\u6f5c\u529b\u3002"}}
{"id": "2506.08228", "pdf": "https://arxiv.org/pdf/2506.08228", "abs": "https://arxiv.org/abs/2506.08228", "authors": ["Mustafa Baniodeh", "Kratarth Goel", "Scott Ettinger", "Carlos Fuertes", "Ari Seff", "Tim Shen", "Cole Gulino", "Chenjie Yang", "Ghassen Jerfel", "Dokook Choe", "Rui Wang", "Vinutha Kallem", "Sergio Casas", "Rami Al-Rfou", "Benjamin Sapp", "Dragomir Anguelov"], "title": "Scaling Laws of Motion Forecasting and Planning -- A Technical Report", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "We study the empirical scaling laws of a family of encoder-decoder\nautoregressive transformer models on the task of joint motion forecasting and\nplanning in the autonomous driving domain. Using a 500 thousand hours driving\ndataset, we demonstrate that, similar to language modeling, model performance\nimproves as a power-law function of the total compute budget, and we observe a\nstrong correlation between model training loss and model evaluation metrics.\nMost interestingly, closed-loop metrics also improve with scaling, which has\nimportant implications for the suitability of open-loop metrics for model\ndevelopment and hill climbing. We also study the optimal scaling of the number\nof transformer parameters and the training data size for a training\ncompute-optimal model. We find that as the training compute budget grows,\noptimal scaling requires increasing the model size 1.5x as fast as the dataset\nsize. We also study inference-time compute scaling, where we observe that\nsampling and clustering the output of smaller models makes them competitive\nwith larger models, up to a crossover point beyond which a larger models\nbecomes more inference-compute efficient. Overall, our experimental results\ndemonstrate that optimizing the training and inference-time scaling properties\nof motion forecasting and planning models is a key lever for improving their\nperformance to address a wide variety of driving scenarios. Finally, we briefly\nstudy the utility of training on general logged driving data of other agents to\nimprove the performance of the ego-agent, an important research area to address\nthe scarcity of robotics data for large capacity models training.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u81ea\u52a8\u9a7e\u9a76\u9886\u57df\u4e2d\u7f16\u7801\u5668-\u89e3\u7801\u5668\u81ea\u56de\u5f52Transformer\u6a21\u578b\u7684\u7f29\u653e\u89c4\u5f8b\uff0c\u53d1\u73b0\u6a21\u578b\u6027\u80fd\u968f\u8ba1\u7b97\u9884\u7b97\u5448\u5e42\u5f8b\u63d0\u5347\uff0c\u5e76\u63a2\u8ba8\u4e86\u8bad\u7ec3\u4e0e\u63a8\u7406\u65f6\u7684\u6700\u4f18\u7f29\u653e\u7b56\u7565\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u63a2\u7d22\u5728\u81ea\u52a8\u9a7e\u9a76\u4efb\u52a1\u4e2d\uff0c\u5982\u4f55\u901a\u8fc7\u7f29\u653e\u6a21\u578b\u548c\u6570\u636e\u96c6\u89c4\u6a21\u6765\u4f18\u5316\u6027\u80fd\uff0c\u5e76\u9a8c\u8bc1\u95ed\u73af\u6307\u6807\u4e0e\u5f00\u73af\u6307\u6807\u7684\u76f8\u5173\u6027\u3002", "method": "\u4f7f\u752850\u4e07\u5c0f\u65f6\u9a7e\u9a76\u6570\u636e\u96c6\uff0c\u5206\u6790\u6a21\u578b\u6027\u80fd\u4e0e\u8ba1\u7b97\u9884\u7b97\u7684\u5173\u7cfb\uff0c\u7814\u7a76\u6a21\u578b\u53c2\u6570\u4e0e\u6570\u636e\u91cf\u7684\u6700\u4f18\u7f29\u653e\u6bd4\u4f8b\uff0c\u5e76\u63a2\u8ba8\u63a8\u7406\u65f6\u7684\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u6a21\u578b\u6027\u80fd\u968f\u8ba1\u7b97\u9884\u7b97\u5e42\u5f8b\u63d0\u5347\uff0c\u8bad\u7ec3\u65f6\u6a21\u578b\u89c4\u6a21\u9700\u4ee5\u6570\u636e\u91cf1.5\u500d\u7684\u901f\u5ea6\u589e\u957f\uff1b\u63a8\u7406\u65f6\u5c0f\u6a21\u578b\u901a\u8fc7\u91c7\u6837\u548c\u805a\u7c7b\u53ef\u5ab2\u7f8e\u5927\u6a21\u578b\uff0c\u76f4\u5230\u4ea4\u53c9\u70b9\u540e\u5927\u6a21\u578b\u66f4\u9ad8\u6548\u3002", "conclusion": "\u4f18\u5316\u8bad\u7ec3\u548c\u63a8\u7406\u7684\u7f29\u653e\u7b56\u7565\u662f\u63d0\u5347\u81ea\u52a8\u9a7e\u9a76\u6a21\u578b\u6027\u80fd\u7684\u5173\u952e\uff0c\u540c\u65f6\u5229\u7528\u5176\u4ed6\u8f66\u8f86\u7684\u65e5\u5fd7\u6570\u636e\u53ef\u7f13\u89e3\u673a\u5668\u4eba\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u3002"}}
{"id": "2506.08231", "pdf": "https://arxiv.org/pdf/2506.08231", "abs": "https://arxiv.org/abs/2506.08231", "authors": ["Melissa Estevez", "Nisha Singh", "Lauren Dyson", "Blythe Adamson", "Qianyu Yuan", "Megan W. Hildner", "Erin Fidyk", "Olive Mbah", "Farhad Khan", "Kathi Seidl-Rathkopf", "Aaron B. Cohen"], "title": "Ensuring Reliability of Curated EHR-Derived Data: The Validation of Accuracy for LLM/ML-Extracted Information and Data (VALID) Framework", "categories": ["cs.LG", "cs.AI", "cs.PF"], "comment": "18 pages, 3 tables, 1 figure", "summary": "Large language models (LLMs) are increasingly used to extract clinical data\nfrom electronic health records (EHRs), offering significant improvements in\nscalability and efficiency for real-world data (RWD) curation in oncology.\nHowever, the adoption of LLMs introduces new challenges in ensuring the\nreliability, accuracy, and fairness of extracted data, which are essential for\nresearch, regulatory, and clinical applications. Existing quality assurance\nframeworks for RWD and artificial intelligence do not fully address the unique\nerror modes and complexities associated with LLM-extracted data. In this paper,\nwe propose a comprehensive framework for evaluating the quality of clinical\ndata extracted by LLMs. The framework integrates variable-level performance\nbenchmarking against expert human abstraction, automated verification checks\nfor internal consistency and plausibility, and replication analyses comparing\nLLM-extracted data to human-abstracted datasets or external standards. This\nmultidimensional approach enables the identification of variables most in need\nof improvement, systematic detection of latent errors, and confirmation of\ndataset fitness-for-purpose in real-world research. Additionally, the framework\nsupports bias assessment by stratifying metrics across demographic subgroups.\nBy providing a rigorous and transparent method for assessing LLM-extracted RWD,\nthis framework advances industry standards and supports the trustworthy use of\nAI-powered evidence generation in oncology research and practice.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e00\u4e2a\u8bc4\u4f30LLM\u63d0\u53d6\u4e34\u5e8a\u6570\u636e\u8d28\u91cf\u7684\u7efc\u5408\u6846\u67b6\uff0c\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u672a\u8986\u76d6\u7684\u72ec\u7279\u95ee\u9898\u548c\u590d\u6742\u6027\u3002", "motivation": "LLM\u5728\u4e34\u5e8a\u6570\u636e\u63d0\u53d6\u4e2d\u7684\u5e94\u7528\u867d\u9ad8\u6548\u4f46\u5b58\u5728\u53ef\u9760\u6027\u3001\u51c6\u786e\u6027\u548c\u516c\u5e73\u6027\u6311\u6218\uff0c\u73b0\u6709\u8d28\u91cf\u4fdd\u8bc1\u6846\u67b6\u672a\u80fd\u5b8c\u5168\u89e3\u51b3\u3002", "method": "\u6846\u67b6\u6574\u5408\u53d8\u91cf\u7ea7\u6027\u80fd\u57fa\u51c6\u6d4b\u8bd5\u3001\u81ea\u52a8\u9a8c\u8bc1\u68c0\u67e5\uff08\u5185\u90e8\u4e00\u81f4\u6027\u548c\u5408\u7406\u6027\uff09\u4ee5\u53ca\u590d\u5236\u5206\u6790\uff08\u5bf9\u6bd4\u4eba\u5de5\u63d0\u53d6\u6570\u636e\u6216\u5916\u90e8\u6807\u51c6\uff09\u3002", "result": "\u591a\u7ef4\u65b9\u6cd5\u80fd\u8bc6\u522b\u9700\u6539\u8fdb\u7684\u53d8\u91cf\u3001\u7cfb\u7edf\u6027\u68c0\u6d4b\u6f5c\u5728\u9519\u8bef\uff0c\u5e76\u786e\u8ba4\u6570\u636e\u96c6\u5728\u771f\u5b9e\u7814\u7a76\u4e2d\u7684\u9002\u7528\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aLLM\u63d0\u53d6\u7684RWD\u63d0\u4f9b\u4e25\u683c\u900f\u660e\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u63a8\u52a8\u884c\u4e1a\u6807\u51c6\u5e76\u652f\u6301AI\u5728\u80bf\u7624\u5b66\u7814\u7a76\u4e2d\u7684\u53ef\u4fe1\u5e94\u7528\u3002"}}
{"id": "2506.08240", "pdf": "https://arxiv.org/pdf/2506.08240", "abs": "https://arxiv.org/abs/2506.08240", "authors": ["Dongkyu Cho", "Rumi Chunara"], "title": "Dealing with the Evil Twins: Improving Random Augmentation by Addressing Catastrophic Forgetting of Diverse Augmentations", "categories": ["cs.LG"], "comment": "12 pages, 6 figures", "summary": "Data augmentation is a promising tool for enhancing out-of-distribution\ngeneralization, where the key is to produce diverse, challenging variations of\nthe source domain via costly targeted augmentations that maximize its\ngeneralization effect. Conversely, random augmentation is inexpensive but is\ndeemed suboptimal due to its limited effect. In this paper, we revisit random\naugmentation and explore methods to address its shortcomings. We show that the\nstochastic nature of random augmentation can produce a set of colliding\naugmentations that distorts the learned features, similar to catastrophic\nforgetting. We propose a simple solution that improves the generalization\neffect of random augmentation by addressing forgetting, which displays strong\ngeneralization performance across various single source domain generalization\n(sDG) benchmarks.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u968f\u673a\u6570\u636e\u589e\u5f3a\u7684\u4e0d\u8db3\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u65b9\u6cd5\u6765\u89e3\u51b3\u5176\u5bfc\u81f4\u7684\u7279\u5f81\u626d\u66f2\u95ee\u9898\uff0c\u4ece\u800c\u63d0\u5347\u6cdb\u5316\u6027\u80fd\u3002", "motivation": "\u968f\u673a\u6570\u636e\u589e\u5f3a\u6210\u672c\u4f4e\u4f46\u6548\u679c\u6709\u9650\uff0c\u800c\u76ee\u6807\u589e\u5f3a\u6210\u672c\u9ad8\u4f46\u6548\u679c\u597d\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u968f\u673a\u589e\u5f3a\u7684\u4e0d\u8db3\u3002", "method": "\u901a\u8fc7\u5206\u6790\u968f\u673a\u589e\u5f3a\u7684\u968f\u673a\u6027\u5bfc\u81f4\u7279\u5f81\u626d\u66f2\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u89e3\u51b3\u9057\u5fd8\u6548\u5e94\u7684\u7b80\u5355\u65b9\u6cd5\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u5355\u6e90\u57df\u6cdb\u5316\uff08sDG\uff09\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u6027\u80fd\u3002", "conclusion": "\u6539\u8fdb\u540e\u7684\u968f\u673a\u589e\u5f3a\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u5347\u6cdb\u5316\u6548\u679c\uff0c\u4e14\u6210\u672c\u4f4e\u5ec9\u3002"}}
{"id": "2506.08243", "pdf": "https://arxiv.org/pdf/2506.08243", "abs": "https://arxiv.org/abs/2506.08243", "authors": ["Zhenjiang Mao", "Artem Bisliouk", "Rohith Reddy Nama", "Ivan Ruchkin"], "title": "Temporalizing Confidence: Evaluation of Chain-of-Thought Reasoning with Signal Temporal Logic", "categories": ["cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have shown impressive performance in\nmathematical reasoning tasks when guided by Chain-of-Thought (CoT) prompting.\nHowever, they tend to produce highly confident yet incorrect outputs, which\nposes significant risks in domains like education, where users may lack the\nexpertise to assess reasoning steps. To address this, we propose a structured\nframework that models stepwise confidence as a temporal signal and evaluates it\nusing Signal Temporal Logic (STL). In particular, we define formal STL-based\nconstraints to capture desirable temporal properties and compute robustness\nscores that serve as structured, interpretable confidence estimates. Our\napproach also introduces a set of uncertainty reshaping strategies to enforce\nsmoothness, monotonicity, and causal consistency across the reasoning\ntrajectory. Experiments show that our approach consistently improves\ncalibration metrics and provides more reliable uncertainty estimates than\nconventional confidence aggregation and post-hoc calibration.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4fe1\u53f7\u65f6\u5e8f\u903b\u8f91\uff08STL\uff09\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u9010\u6b65\u7f6e\u4fe1\u5ea6\uff0c\u5e76\u901a\u8fc7\u4e0d\u786e\u5b9a\u6027\u91cd\u5851\u7b56\u7565\u63d0\u5347\u5176\u53ef\u9760\u6027\u3002", "motivation": "LLMs\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5bb9\u6613\u4ea7\u751f\u9ad8\u7f6e\u4fe1\u5ea6\u5374\u9519\u8bef\u7684\u8f93\u51fa\uff0c\u8fd9\u5728\u6559\u80b2\u7b49\u9886\u57df\u5b58\u5728\u98ce\u9669\u3002", "method": "\u5229\u7528STL\u5b9a\u4e49\u65f6\u95f4\u7ea6\u675f\uff0c\u8ba1\u7b97\u9c81\u68d2\u6027\u5206\u6570\u4f5c\u4e3a\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\uff0c\u5e76\u5f15\u5165\u4e0d\u786e\u5b9a\u6027\u91cd\u5851\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u6539\u5584\u4e86\u6821\u51c6\u6307\u6807\uff0c\u63d0\u4f9b\u4e86\u6bd4\u4f20\u7edf\u65b9\u6cd5\u66f4\u53ef\u9760\u7684\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86LLMs\u5728\u6570\u5b66\u63a8\u7406\u4e2d\u7684\u7f6e\u4fe1\u5ea6\u53ef\u9760\u6027\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2506.08244", "pdf": "https://arxiv.org/pdf/2506.08244", "abs": "https://arxiv.org/abs/2506.08244", "authors": ["Riccardo Ali", "Pietro Li\u00f2", "Jamie Vicary"], "title": "Parameter-free approximate equivariance for tasks with finite group symmetry", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Equivariant neural networks incorporate symmetries through group actions,\nembedding them as an inductive bias to improve performance on a wide variety of\ntasks. However, existing equivariant methods can be computationally intensive,\nwith high parameter counts, and are often tied to a specific architecture. We\npropose a simple zero-parameter approach that imposes approximate equivariance\nfor a finite group in the latent representation, as an additional term in the\nloss function. We conduct experiments which allow the network to learn a group\nrepresentation on the latent space, and show in every case it prefers to learn\nthe regular representation. Fixing this action on the latent space, this yields\na simple method to impose approximate equivariance as an additional loss\npenalty. We benchmark our approach on three datasets and compare it against\nseveral existing equivariant methods, showing that in many cases it achieves\nsimilar or better performance for a fraction of the parameters.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u96f6\u53c2\u6570\u7684\u8fd1\u4f3c\u7b49\u53d8\u6027\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u635f\u5931\u51fd\u6570\u4e2d\u6dfb\u52a0\u989d\u5916\u9879\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u4e14\u53c2\u6570\u66f4\u5c11\u3002", "motivation": "\u73b0\u6709\u7b49\u53d8\u6027\u65b9\u6cd5\u8ba1\u7b97\u590d\u6742\u3001\u53c2\u6570\u591a\u4e14\u67b6\u6784\u53d7\u9650\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u5728\u6f5c\u5728\u8868\u793a\u4e2d\u4e3a\u6709\u9650\u7fa4\u6dfb\u52a0\u8fd1\u4f3c\u7b49\u53d8\u6027\u635f\u5931\u9879\uff0c\u7f51\u7edc\u5b66\u4e60\u6f5c\u5728\u7a7a\u95f4\u7684\u7fa4\u8868\u793a\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u7f51\u7edc\u503e\u5411\u4e8e\u5b66\u4e60\u6b63\u5219\u8868\u793a\uff0c\u6027\u80fd\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u5f53\u6216\u66f4\u597d\uff0c\u53c2\u6570\u66f4\u5c11\u3002", "conclusion": "\u63d0\u51fa\u7684\u96f6\u53c2\u6570\u65b9\u6cd5\u7b80\u5355\u6709\u6548\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u4efb\u52a1\uff0c\u6027\u80fd\u4f18\u8d8a\u3002"}}
{"id": "2506.08255", "pdf": "https://arxiv.org/pdf/2506.08255", "abs": "https://arxiv.org/abs/2506.08255", "authors": ["Patryk Krukowski", "\u0141ukasz Gorczyca", "Piotr Helm", "Kamil Ksi\u0105\u017cek", "Przemys\u0142aw Spurek"], "title": "SHIELD: Secure Hypernetworks for Incremental Expansion Learning Defense", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Traditional deep neural networks suffer from several limitations, including\ncatastrophic forgetting. When models are adapted to new datasets, they tend to\nquickly forget previously learned knowledge. Another significant issue is the\nlack of robustness to even small perturbations in the input data. In practice,\nwe can often easily perform adversarial attacks and change the network's\npredictions, adding minimal noise to the input. Dedicated architectures and\ntraining procedures can solve each of the above problems separately.\nUnfortunately, currently, no model can simultaneously address both catastrophic\nforgetting and vulnerability to adversarial attacks. We introduce SHIELD\n(Secure Hypernetworks for Incremental Expansion and Learning Defense), a novel\napproach that integrates a hypernetwork-based continual learning approach with\ninterval arithmetic. SHIELD use the hypernetwork to transfer trainable task\nembedding vectors into the weights of a target model dedicated to specific\ndata. This paradigm allows for the dynamic generation of separate networks for\neach subtask, while the hypernetwork aggregates and analyzes information across\nall tasks. The target model takes in the input a data sample with a defined\ninterval range, and by creating a hypercube, produces a prediction for the\ngiven range. Therefore, such target models provide strict guarantees against\nall possible attacks for data samples within the interval range. Our approach\nenhances security without sacrificing network adaptability, addressing the\noverlooked challenge of safety in continual learning.", "AI": {"tldr": "SHIELD\u7ed3\u5408\u8d85\u7f51\u7edc\u548c\u533a\u95f4\u7b97\u672f\uff0c\u89e3\u51b3\u4e86\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u707e\u96be\u6027\u9057\u5fd8\u548c\u5bf9\u6297\u653b\u51fb\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5b58\u5728\u707e\u96be\u6027\u9057\u5fd8\u548c\u5bf9\u6297\u653b\u51fb\u8106\u5f31\u6027\u95ee\u9898\uff0c\u76ee\u524d\u6ca1\u6709\u6a21\u578b\u80fd\u540c\u65f6\u89e3\u51b3\u8fd9\u4e24\u4e2a\u95ee\u9898\u3002", "method": "SHIELD\u901a\u8fc7\u8d85\u7f51\u7edc\u751f\u6210\u4efb\u52a1\u5d4c\u5165\u5411\u91cf\uff0c\u52a8\u6001\u4e3a\u76ee\u6807\u6a21\u578b\u5206\u914d\u6743\u91cd\uff0c\u5e76\u7ed3\u5408\u533a\u95f4\u7b97\u672f\u63d0\u4f9b\u4e25\u683c\u7684\u5b89\u5168\u4fdd\u8bc1\u3002", "result": "SHIELD\u80fd\u5728\u6301\u7eed\u5b66\u4e60\u4e2d\u52a8\u6001\u751f\u6210\u5b50\u4efb\u52a1\u7f51\u7edc\uff0c\u540c\u65f6\u62b5\u5fa1\u5bf9\u6297\u653b\u51fb\uff0c\u589e\u5f3a\u5b89\u5168\u6027\u3002", "conclusion": "SHIELD\u5728\u4fdd\u6301\u7f51\u7edc\u9002\u5e94\u6027\u7684\u540c\u65f6\u89e3\u51b3\u4e86\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u5b89\u5168\u95ee\u9898\u3002"}}
{"id": "2506.08266", "pdf": "https://arxiv.org/pdf/2506.08266", "abs": "https://arxiv.org/abs/2506.08266", "authors": ["Yaswanth Chittepu", "Blossom Metevier", "Will Schwarzer", "Austin Hoag", "Scott Niekum", "Philip S. Thomas"], "title": "Reinforcement Learning from Human Feedback with High-Confidence Safety Constraints", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.AP"], "comment": "20 pages, 6 figures, 4 tables, Second Reinforcement Learning\n  Conference (RLC 2025)", "summary": "Existing approaches to language model alignment often treat safety as a\ntradeoff against helpfulness, which can lead to unacceptable responses in\nsensitive domains. To ensure reliable performance in such settings, we propose\nHigh-Confidence Safe Reinforcement Learning from Human Feedback (HC-RLHF), a\nmethod that provides high-confidence safety guarantees while maximizing\nhelpfulness. Similar to previous methods, HC-RLHF explicitly decouples human\npreferences into helpfulness and harmlessness (safety), which are learned by\ntraining a reward model and a cost model, respectively. It then employs a\ntwo-step process to find safe solutions. In the first step, it optimizes the\nreward function under an intentionally pessimistic version of the cost\nconstraint. In the second step, the trained model undergoes a safety test to\nverify whether its performance stays within an upper-confidence bound of the\nactual cost constraint. We provide a theoretical analysis of HC-RLHF, including\nproof that it will not return an unsafe solution with a probability greater\nthan a user-specified threshold. For our empirical analysis, we apply HC-RLHF\nto align three different language models (Qwen2-1.5B, Qwen2.5-3B, and\nLLaMa3.2-3B) with human preferences. Our results demonstrate that HC-RLHF\nproduces safe models with high probability and can improve harmlessness and\nhelpfulness compared to previous methods.", "AI": {"tldr": "HC-RLHF\u662f\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u9ad8\u7f6e\u4fe1\u5ea6\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u786e\u4fdd\u8bed\u8a00\u6a21\u578b\u5728\u654f\u611f\u9886\u57df\u7684\u5b89\u5168\u6027\uff0c\u540c\u65f6\u6700\u5927\u5316\u5b9e\u7528\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5e38\u5c06\u5b89\u5168\u6027\u4e0e\u5b9e\u7528\u6027\u89c6\u4e3a\u6743\u8861\uff0c\u5bfc\u81f4\u654f\u611f\u9886\u57df\u51fa\u73b0\u4e0d\u53ef\u63a5\u53d7\u7684\u54cd\u5e94\u3002HC-RLHF\u65e8\u5728\u63d0\u4f9b\u9ad8\u7f6e\u4fe1\u5ea6\u5b89\u5168\u4fdd\u8bc1\u3002", "method": "HC-RLHF\u5c06\u4eba\u7c7b\u504f\u597d\u5206\u89e3\u4e3a\u5b9e\u7528\u6027\u548c\u5b89\u5168\u6027\uff0c\u5206\u522b\u8bad\u7ec3\u5956\u52b1\u6a21\u578b\u548c\u6210\u672c\u6a21\u578b\u3002\u901a\u8fc7\u4e24\u6b65\u4f18\u5316\u8fc7\u7a0b\uff08\u60b2\u89c2\u7ea6\u675f\u4f18\u5316\u548c\u5b89\u5168\u6d4b\u8bd5\uff09\u786e\u4fdd\u5b89\u5168\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cHC-RLHF\u80fd\u4ee5\u9ad8\u6982\u7387\u751f\u6210\u5b89\u5168\u6a21\u578b\uff0c\u5e76\u5728\u65e0\u5bb3\u6027\u548c\u5b9e\u7528\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "HC-RLHF\u4e3a\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u9760\u7684\u5b89\u5168\u89e3\u51b3\u65b9\u6848\uff0c\u517c\u5177\u7406\u8bba\u4fdd\u969c\u548c\u5b9e\u9645\u6548\u679c\u3002"}}
{"id": "2506.08267", "pdf": "https://arxiv.org/pdf/2506.08267", "abs": "https://arxiv.org/abs/2506.08267", "authors": ["Mansooreh Montazerin", "Majd Al Aawar", "Antonio Ortega", "Ajitesh Srivastava"], "title": "Sparse Interpretable Deep Learning with LIES Networks for Symbolic Regression", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Symbolic regression (SR) aims to discover closed-form mathematical\nexpressions that accurately describe data, offering interpretability and\nanalytical insight beyond standard black-box models. Existing SR methods often\nrely on population-based search or autoregressive modeling, which struggle with\nscalability and symbolic consistency. We introduce LIES (Logarithm, Identity,\nExponential, Sine), a fixed neural network architecture with interpretable\nprimitive activations that are optimized to model symbolic expressions. We\ndevelop a framework to extract compact formulae from LIES networks by training\nwith an appropriate oversampling strategy and a tailored loss function to\npromote sparsity and to prevent gradient instability. After training, it\napplies additional pruning strategies to further simplify the learned\nexpressions into compact formulae. Our experiments on SR benchmarks show that\nthe LIES framework consistently produces sparse and accurate symbolic formulae\noutperforming all baselines. We also demonstrate the importance of each design\ncomponent through ablation studies.", "AI": {"tldr": "LIES\u6846\u67b6\u901a\u8fc7\u56fa\u5b9a\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u548c\u4f18\u5316\u7b56\u7565\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u7b26\u53f7\u56de\u5f52\uff0c\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7b26\u53f7\u56de\u5f52\u65b9\u6cd5\u5728\u53ef\u6269\u5c55\u6027\u548c\u7b26\u53f7\u4e00\u81f4\u6027\u4e0a\u5b58\u5728\u4e0d\u8db3\uff0cLIES\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u91c7\u7528LIES\u67b6\u6784\uff0c\u7ed3\u5408\u8fc7\u91c7\u6837\u7b56\u7565\u548c\u5b9a\u5236\u635f\u5931\u51fd\u6570\uff0c\u4f18\u5316\u7a00\u758f\u6027\u548c\u68af\u5ea6\u7a33\u5b9a\u6027\uff0c\u8bad\u7ec3\u540e\u8fdb\u4e00\u6b65\u526a\u679d\u7b80\u5316\u8868\u8fbe\u5f0f\u3002", "result": "\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLIES\u751f\u6210\u7684\u7b26\u53f7\u516c\u5f0f\u7a00\u758f\u4e14\u51c6\u786e\uff0c\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "LIES\u6846\u67b6\u901a\u8fc7\u5176\u8bbe\u8ba1\u7ec4\u4ef6\u663e\u8457\u63d0\u5347\u4e86\u7b26\u53f7\u56de\u5f52\u7684\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2506.08270", "pdf": "https://arxiv.org/pdf/2506.08270", "abs": "https://arxiv.org/abs/2506.08270", "authors": ["Zitong Huang", "Mansooreh Montazerin", "Ajitesh Srivastava"], "title": "SWAT-NN: Simultaneous Weights and Architecture Training for Neural Networks in a Latent Space", "categories": ["cs.LG"], "comment": null, "summary": "Designing neural networks typically relies on manual trial and error or a\nneural architecture search (NAS) followed by weight training. The former is\ntime-consuming and labor-intensive, while the latter often discretizes\narchitecture search and weight optimization. In this paper, we propose a\nfundamentally different approach that simultaneously optimizes both the\narchitecture and the weights of a neural network. Our framework first trains a\nuniversal multi-scale autoencoder that embeds both architectural and parametric\ninformation into a continuous latent space, where functionally similar neural\nnetworks are mapped closer together. Given a dataset, we then randomly\ninitialize a point in the embedding space and update it via gradient descent to\nobtain the optimal neural network, jointly optimizing its structure and\nweights. The optimization process incorporates sparsity and compactness\npenalties to promote efficient models. Experiments on synthetic regression\ntasks demonstrate that our method effectively discovers sparse and compact\nneural networks with strong performance.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u540c\u65f6\u4f18\u5316\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u548c\u6743\u91cd\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fde\u7eed\u6f5c\u5728\u7a7a\u95f4\u5d4c\u5165\u548c\u68af\u5ea6\u4e0b\u964d\u8054\u5408\u4f18\u5316\u3002", "motivation": "\u4f20\u7edf\u8bbe\u8ba1\u795e\u7ecf\u7f51\u7edc\u7684\u65b9\u6cd5\uff08\u624b\u52a8\u8bd5\u9519\u6216NAS\uff09\u6548\u7387\u4f4e\u4e14\u5206\u79bb\u4e86\u7ed3\u6784\u641c\u7d22\u548c\u6743\u91cd\u4f18\u5316\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u4e14\u8054\u5408\u4f18\u5316\u7684\u65b9\u6cd5\u3002", "method": "\u8bad\u7ec3\u4e00\u4e2a\u591a\u5c3a\u5ea6\u81ea\u7f16\u7801\u5668\uff0c\u5c06\u7ed3\u6784\u548c\u53c2\u6570\u4fe1\u606f\u5d4c\u5165\u8fde\u7eed\u6f5c\u5728\u7a7a\u95f4\uff0c\u901a\u8fc7\u68af\u5ea6\u4e0b\u964d\u8054\u5408\u4f18\u5316\u7ed3\u6784\u548c\u6743\u91cd\uff0c\u5e76\u52a0\u5165\u7a00\u758f\u6027\u548c\u7d27\u51d1\u6027\u60e9\u7f5a\u3002", "result": "\u5728\u5408\u6210\u56de\u5f52\u4efb\u52a1\u4e2d\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u53d1\u73b0\u6027\u80fd\u4f18\u8d8a\u7684\u7a00\u758f\u7d27\u51d1\u795e\u7ecf\u7f51\u7edc\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u795e\u7ecf\u7f51\u7edc\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u8054\u5408\u4f18\u5316\u7684\u65b0\u601d\u8def\u3002"}}
{"id": "2506.08272", "pdf": "https://arxiv.org/pdf/2506.08272", "abs": "https://arxiv.org/abs/2506.08272", "authors": ["Tarushri N. S."], "title": "Universal Differential Equations for Scientific Machine Learning of Node-Wise Battery Dynamics in Smart Grids", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Universal Differential Equations (UDEs), which blend neural networks with\nphysical differential equations, have emerged as a powerful framework for\nscientific machine learning (SciML), enabling data-efficient, interpretable,\nand physically consistent modeling. In the context of smart grid systems,\nmodeling node-wise battery dynamics remains a challenge due to the\nstochasticity of solar input and variability in household load profiles.\nTraditional approaches often struggle with generalization and fail to capture\nunmodeled residual dynamics. This work proposes a UDE-based approach to learn\nnode-specific battery evolution by embedding a neural residual into a\nphysically inspired battery ODE. Synthetic yet realistic solar generation and\nload demand data are used to simulate battery dynamics over time. The neural\ncomponent learns to model unobserved or stochastic corrections arising from\nheterogeneity in node demand and environmental conditions. Comprehensive\nexperiments reveal that the trained UDE aligns closely with ground truth\nbattery trajectories, exhibits smooth convergence behavior, and maintains\nstability in long-term forecasts. These findings affirm the viability of\nUDE-based SciML approaches for battery modeling in decentralized energy\nnetworks and suggest broader implications for real-time control and\noptimization in renewable-integrated smart grids.", "AI": {"tldr": "UDEs\u7ed3\u5408\u795e\u7ecf\u7f51\u7edc\u4e0e\u7269\u7406\u5fae\u5206\u65b9\u7a0b\uff0c\u7528\u4e8e\u667a\u80fd\u7535\u7f51\u4e2d\u7535\u6c60\u52a8\u6001\u5efa\u6a21\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u667a\u80fd\u7535\u7f51\u4e2d\u7535\u6c60\u52a8\u6001\u5efa\u6a21\u56e0\u592a\u9633\u80fd\u8f93\u5165\u968f\u673a\u6027\u548c\u8d1f\u8f7d\u53d8\u5316\u800c\u590d\u6742\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u672a\u5efa\u6a21\u52a8\u6001\u3002", "method": "\u63d0\u51fa\u57fa\u4e8eUDE\u7684\u65b9\u6cd5\uff0c\u5c06\u795e\u7ecf\u7f51\u7edc\u6b8b\u5dee\u5d4c\u5165\u7269\u7406\u7535\u6c60ODE\u4e2d\uff0c\u5b66\u4e60\u8282\u70b9\u7279\u5f02\u6027\u7535\u6c60\u6f14\u5316\u3002", "result": "\u5b9e\u9a8c\u8868\u660eUDE\u6a21\u578b\u4e0e\u771f\u5b9e\u7535\u6c60\u8f68\u8ff9\u9ad8\u5ea6\u543b\u5408\uff0c\u6536\u655b\u5e73\u6ed1\u4e14\u957f\u671f\u9884\u6d4b\u7a33\u5b9a\u3002", "conclusion": "UDE\u65b9\u6cd5\u9002\u7528\u4e8e\u5206\u6563\u5f0f\u80fd\u6e90\u7f51\u7edc\u7535\u6c60\u5efa\u6a21\uff0c\u5bf9\u5b9e\u65f6\u63a7\u5236\u548c\u4f18\u5316\u5177\u6709\u5e7f\u6cdb\u610f\u4e49\u3002"}}
{"id": "2506.08274", "pdf": "https://arxiv.org/pdf/2506.08274", "abs": "https://arxiv.org/abs/2506.08274", "authors": ["Jo\u00e3o Manoel Herrera Pinheiro", "Suzana Vilas Boas de Oliveira", "Thiago Henrique Segreto Silva", "Pedro Antonio Rabelo Saraiva", "Enzo Ferreira de Souza", "Leonardo Andr\u00e9 Ambrosio", "Marcelo Becker"], "title": "The Impact of Feature Scaling In Machine Learning: Effects on Regression and Classification Tasks", "categories": ["cs.LG", "stat.ML"], "comment": "27 pages", "summary": "This research addresses the critical lack of comprehensive studies on feature\nscaling by systematically evaluating 12 scaling techniques - including several\nless common transformations - across 14 different Machine Learning algorithms\nand 16 datasets for classification and regression tasks. We meticulously\nanalyzed impacts on predictive performance (using metrics such as accuracy,\nMAE, MSE, and $R^2$) and computational costs (training time, inference time,\nand memory usage). Key findings reveal that while ensemble methods (such as\nRandom Forest and gradient boosting models like XGBoost, CatBoost and LightGBM)\ndemonstrate robust performance largely independent of scaling, other widely\nused models such as Logistic Regression, SVMs, TabNet, and MLPs show\nsignificant performance variations highly dependent on the chosen scaler. This\nextensive empirical analysis, with all source code, experimental results, and\nmodel parameters made publicly available to ensure complete transparency and\nreproducibility, offers model-specific crucial guidance to practitioners on the\nneed for an optimal selection of feature scaling techniques.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e8612\u79cd\u7279\u5f81\u7f29\u653e\u6280\u672f\u5bf914\u79cd\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u548c16\u4e2a\u6570\u636e\u96c6\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u96c6\u6210\u65b9\u6cd5\u5bf9\u7f29\u653e\u4e0d\u654f\u611f\uff0c\u800c\u5176\u4ed6\u6a21\u578b\uff08\u5982\u903b\u8f91\u56de\u5f52\u3001SVM\u7b49\uff09\u6027\u80fd\u663e\u8457\u4f9d\u8d56\u7f29\u653e\u9009\u62e9\u3002", "motivation": "\u89e3\u51b3\u7279\u5f81\u7f29\u653e\u9886\u57df\u7f3a\u4e4f\u5168\u9762\u7814\u7a76\u7684\u95ee\u9898\uff0c\u4e3a\u5b9e\u8df5\u8005\u63d0\u4f9b\u6a21\u578b\u7279\u5b9a\u7684\u7f29\u653e\u6280\u672f\u9009\u62e9\u6307\u5bfc\u3002", "method": "\u4f7f\u752812\u79cd\u7f29\u653e\u6280\u672f\uff0c\u8bc4\u4f3014\u79cd\u7b97\u6cd5\u572816\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u9884\u6d4b\u6027\u80fd\u548c\u8ba1\u7b97\u6210\u672c\u3002", "result": "\u96c6\u6210\u65b9\u6cd5\uff08\u5982\u968f\u673a\u68ee\u6797\u3001XGBoost\u7b49\uff09\u5bf9\u7f29\u653e\u4e0d\u654f\u611f\uff0c\u800c\u903b\u8f91\u56de\u5f52\u3001SVM\u7b49\u6a21\u578b\u6027\u80fd\u663e\u8457\u4f9d\u8d56\u7f29\u653e\u9009\u62e9\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u6a21\u578b\u7279\u5b9a\u7684\u7f29\u653e\u6280\u672f\u9009\u62e9\u6307\u5357\uff0c\u5e76\u516c\u5f00\u4e86\u6240\u6709\u4ee3\u7801\u548c\u7ed3\u679c\u4ee5\u786e\u4fdd\u900f\u660e\u6027\u548c\u53ef\u590d\u73b0\u6027\u3002"}}
{"id": "2506.08292", "pdf": "https://arxiv.org/pdf/2506.08292", "abs": "https://arxiv.org/abs/2506.08292", "authors": ["Xie Yi", "Zhanke Zhou", "Chentao Cao", "Qiyu Niu", "Tongliang Liu", "Bo Han"], "title": "From Debate to Equilibrium: Belief-Driven Multi-Agent LLM Reasoning via Bayesian Nash Equilibrium", "categories": ["cs.LG", "cs.CL"], "comment": "Accepted by ICML 2025", "summary": "Multi-agent frameworks can substantially boost the reasoning power of large\nlanguage models (LLMs), but they typically incur heavy computational costs and\nlack convergence guarantees. To overcome these challenges, we recast multi-LLM\ncoordination as an incomplete-information game and seek a Bayesian Nash\nequilibrium (BNE), in which each agent optimally responds to its probabilistic\nbeliefs about the strategies of others. We introduce Efficient Coordination via\nNash Equilibrium (ECON), a hierarchical reinforcement-learning paradigm that\nmarries distributed reasoning with centralized final output. Under ECON, each\nLLM independently selects responses that maximize its expected reward,\nconditioned on its beliefs about co-agents, without requiring costly\ninter-agent exchanges. We mathematically prove that ECON attains a markedly\ntighter regret bound than non-equilibrium multi-agent schemes. Empirically,\nECON outperforms existing multi-LLM approaches by 11.2% on average across six\nbenchmarks spanning complex reasoning and planning tasks. Further experiments\ndemonstrate ECON's ability to flexibly incorporate additional models,\nconfirming its scalability and paving the way toward larger, more powerful\nmulti-LLM ensembles. The code is publicly available at:\nhttps://github.com/tmlr-group/ECON.", "AI": {"tldr": "ECON\u662f\u4e00\u79cd\u57fa\u4e8e\u8d1d\u53f6\u65af\u7eb3\u4ec0\u5747\u8861\u7684\u591a\u667a\u80fd\u4f53\u534f\u8c03\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u63d0\u5347LLM\u63a8\u7406\u80fd\u529b\uff0c\u51cf\u5c11\u8ba1\u7b97\u6210\u672c\u5e76\u4fdd\u8bc1\u6536\u655b\u6027\u3002", "motivation": "\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u6846\u67b6\u4e2d\u8ba1\u7b97\u6210\u672c\u9ad8\u548c\u7f3a\u4e4f\u6536\u655b\u4fdd\u8bc1\u7684\u95ee\u9898\u3002", "method": "\u5c06\u591aLLM\u534f\u8c03\u5efa\u6a21\u4e3a\u4e0d\u5b8c\u5168\u4fe1\u606f\u535a\u5f08\uff0c\u91c7\u7528\u8d1d\u53f6\u65af\u7eb3\u4ec0\u5747\u8861\uff0c\u7ed3\u5408\u5206\u5e03\u5f0f\u63a8\u7406\u4e0e\u96c6\u4e2d\u8f93\u51fa\u3002", "result": "ECON\u5728\u516d\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5e73\u5747\u6027\u80fd\u63d0\u534711.2%\uff0c\u5e76\u5177\u6709\u7075\u6d3b\u6269\u5c55\u6027\u3002", "conclusion": "ECON\u4e3a\u66f4\u5f3a\u5927\u3001\u53ef\u6269\u5c55\u7684\u591aLLM\u96c6\u6210\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.08295", "pdf": "https://arxiv.org/pdf/2506.08295", "abs": "https://arxiv.org/abs/2506.08295", "authors": ["Zhanke Zhou", "Xiao Feng", "Zhaocheng Zhu", "Jiangchao Yao", "Sanmi Koyejo", "Bo Han"], "title": "From Passive to Active Reasoning: Can Large Language Models Ask the Right Questions under Incomplete Information?", "categories": ["cs.LG", "cs.CL"], "comment": "Accepted by ICML 2025", "summary": "While existing benchmarks probe the reasoning abilities of large language\nmodels (LLMs) across diverse domains, they predominantly assess passive\nreasoning, providing models with all the information needed to reach a\nsolution. By contrast, active reasoning-where an LLM must interact with\nexternal systems to acquire missing evidence or data-has received little\nsystematic attention. To address this shortfall, we present AR-Bench, a novel\nbenchmark designed explicitly to evaluate an LLM's active reasoning skills.\nAR-Bench comprises three task families-detective cases, situation puzzles, and\nguessing numbers-that together simulate real-world, agentic scenarios and\nmeasure performance across commonsense, logical, and symbolic reasoning\nchallenges. Empirical evaluation on AR-Bench demonstrates that contemporary\nLLMs exhibit pronounced difficulties with active reasoning: they frequently\nfail to acquire or leverage the information needed to solve tasks. This gap\nhighlights a stark divergence between their passive and active reasoning\nabilities. Moreover, ablation studies indicate that even advanced strategies,\nsuch as tree-based searching or post-training approaches, yield only modest\ngains and fall short of the levels required for real-world deployment.\nCollectively, these findings highlight the critical need to advance methodology\nfor active reasoning, e.g., incorporating interactive learning, real-time\nfeedback loops, and environment-aware objectives for training. The benchmark is\npublicly available at: https://github.com/tmlr-group/AR-Bench.", "AI": {"tldr": "AR-Bench\u662f\u4e00\u4e2a\u65b0\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u4e3b\u52a8\u63a8\u7406\u80fd\u529b\uff0c\u53d1\u73b0\u5f53\u524d\u6a21\u578b\u5728\u4e3b\u52a8\u63a8\u7406\u65b9\u9762\u8868\u73b0\u8f83\u5dee\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u4e3b\u8981\u8bc4\u4f30\u88ab\u52a8\u63a8\u7406\uff0c\u800c\u4e3b\u52a8\u63a8\u7406\uff08\u9700\u8981\u4e0e\u5916\u90e8\u7cfb\u7edf\u4ea4\u4e92\u83b7\u53d6\u4fe1\u606f\uff09\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7814\u7a76\u3002", "method": "\u8bbe\u8ba1\u4e86AR-Bench\uff0c\u5305\u542b\u4e09\u7c7b\u4efb\u52a1\uff08\u4fa6\u63a2\u6848\u4f8b\u3001\u60c5\u5883\u8c1c\u9898\u548c\u731c\u6570\u5b57\uff09\uff0c\u6a21\u62df\u771f\u5b9e\u573a\u666f\u5e76\u6d4b\u8bd5\u5e38\u8bc6\u3001\u903b\u8f91\u548c\u7b26\u53f7\u63a8\u7406\u80fd\u529b\u3002", "result": "\u5f53\u524dLLM\u5728\u4e3b\u52a8\u63a8\u7406\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u96be\u4ee5\u83b7\u53d6\u6216\u5229\u7528\u6240\u9700\u4fe1\u606f\uff0c\u4e14\u6539\u8fdb\u7b56\u7565\u6548\u679c\u6709\u9650\u3002", "conclusion": "\u9700\u53d1\u5c55\u4e3b\u52a8\u63a8\u7406\u65b9\u6cd5\uff0c\u5982\u4ea4\u4e92\u5f0f\u5b66\u4e60\u3001\u5b9e\u65f6\u53cd\u9988\u548c\u73af\u5883\u611f\u77e5\u76ee\u6807\u8bad\u7ec3\u3002"}}
{"id": "2506.08298", "pdf": "https://arxiv.org/pdf/2506.08298", "abs": "https://arxiv.org/abs/2506.08298", "authors": ["Trung-Kien Nguyen", "Heng Ping", "Shixuan Li", "Peiyu Zhang", "Nikos Kanakaris", "Nicholas Kotov", "Paul Bogdan"], "title": "H$^2$GFM: Towards unifying Homogeneity and Heterogeneity on Text-Attributed Graphs", "categories": ["cs.LG"], "comment": null, "summary": "The growing interests and applications of graph learning in diverse domains\nhave propelled the development of a unified model generalizing well across\ndifferent graphs and tasks, known as the Graph Foundation Model (GFM). Existing\nresearch has leveraged text-attributed graphs (TAGs) to tackle the\nheterogeneity in node features among graphs. However, they primarily focus on\nhomogeneous TAGs (HoTAGs), leaving heterogeneous TAGs (HeTAGs), where multiple\ntypes of nodes/edges reside, underexplored. To enhance the capabilities and\napplications of GFM, we introduce H$^2$GFM, a novel framework designed to\ngeneralize across both HoTAGs and HeTAGs. Our model projects diverse\nmeta-relations among graphs under a unified textual space, and employs a\ncontext encoding to capture spatial and higher-order semantic relationships. To\nachieve robust node representations, we propose a novel context-adaptive graph\ntransformer (CGT), effectively capturing information from both context\nneighbors and their relationships. Furthermore, we employ a mixture of CGT\nexperts to capture the heterogeneity in structural patterns among graph types.\nComprehensive experiments on a wide range of HoTAGs and HeTAGs as well as\nlearning scenarios demonstrate the effectiveness of our model.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aH$^2$GFM\u7684\u65b0\u6846\u67b6\uff0c\u65e8\u5728\u7edf\u4e00\u5904\u7406\u540c\u8d28\u548c\u5f02\u8d28\u6587\u672c\u5c5e\u6027\u56fe\uff08TAGs\uff09\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u7f16\u7801\u548c\u81ea\u9002\u5e94\u56fe\u53d8\u6362\u5668\uff08CGT\uff09\u63d0\u5347\u56fe\u57fa\u7840\u6a21\u578b\uff08GFM\uff09\u7684\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u540c\u8d28\u6587\u672c\u5c5e\u6027\u56fe\uff08HoTAGs\uff09\uff0c\u800c\u5ffd\u7565\u4e86\u5f02\u8d28\u6587\u672c\u5c5e\u6027\u56fe\uff08HeTAGs\uff09\uff0c\u9650\u5236\u4e86\u56fe\u57fa\u7840\u6a21\u578b\u7684\u5e94\u7528\u8303\u56f4\u3002", "method": "H$^2$GFM\u901a\u8fc7\u7edf\u4e00\u7684\u6587\u672c\u7a7a\u95f4\u6295\u5f71\u591a\u6837\u5316\u7684\u5143\u5173\u7cfb\uff0c\u5e76\u5229\u7528\u4e0a\u4e0b\u6587\u7f16\u7801\u6355\u6349\u7a7a\u95f4\u548c\u9ad8\u9636\u8bed\u4e49\u5173\u7cfb\u3002\u91c7\u7528\u4e0a\u4e0b\u6587\u81ea\u9002\u5e94\u56fe\u53d8\u6362\u5668\uff08CGT\uff09\u548c\u4e13\u5bb6\u6df7\u5408\u6a21\u578b\u5904\u7406\u5f02\u8d28\u6027\u3002", "result": "\u5728\u5e7f\u6cdb\u7684HoTAGs\u548cHeTAGs\u6570\u636e\u96c6\u53ca\u5b66\u4e60\u573a\u666f\u4e2d\uff0c\u6a21\u578b\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "H$^2$GFM\u6709\u6548\u6269\u5c55\u4e86GFM\u7684\u80fd\u529b\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u56fe\u7c7b\u578b\u548c\u4efb\u52a1\u3002"}}
{"id": "2506.08309", "pdf": "https://arxiv.org/pdf/2506.08309", "abs": "https://arxiv.org/abs/2506.08309", "authors": ["Katherine Tieu", "Dongqi Fu", "Zihao Li", "Ross Maciejewski", "Jingrui He"], "title": "Learnable Spatial-Temporal Positional Encoding for Link Prediction", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by ICML 2025. 28 pages, 1 figures, 22 tables", "summary": "Accurate predictions rely on the expressiveness power of graph deep learning\nframeworks like graph neural networks and graph transformers, where a\npositional encoding mechanism has become much more indispensable in recent\nstate-of-the-art works to record the canonical position information. However,\nthe current positional encoding is limited in three aspects: (1) most\npositional encoding methods use pre-defined, and fixed functions, which are\ninadequate to adapt to the complex attributed graphs; (2) a few pioneering\nworks proposed the learnable positional encoding but are still limited to the\nstructural information, not considering the real-world time-evolving\ntopological and feature information; (3) most positional encoding methods are\nequipped with transformers' attention mechanism to fully leverage their\ncapabilities, where the dense or relational attention is often unaffordable on\nlarge-scale structured data. Hence, we aim to develop Learnable\nSpatial-Temporal Positional Encoding in an effective and efficient manner and\npropose a simple temporal link prediction model named L-STEP. Briefly, for\nL-STEP, we (1) prove the proposed positional learning scheme can preserve the\ngraph property from the spatial-temporal spectral viewpoint, (2) verify that\nMLPs can fully exploit the expressiveness and reach transformers' performance\non that encoding, (3) change different initial positional encoding inputs to\nshow robustness, (4) analyze the theoretical complexity and obtain less\nempirical running time than SOTA, and (5) demonstrate its temporal link\nprediction out-performance on 13 classic datasets and with 10 algorithms in\nboth transductive and inductive settings using 3 different sampling strategies.\nAlso, \\name\\ obtains the leading performance in the newest large-scale TGB\nbenchmark. Our code is available at https://github.com/kthrn22/L-STEP.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u5b66\u4e60\u7684\u65f6\u7a7a\u4f4d\u7f6e\u7f16\u7801\u65b9\u6cd5L-STEP\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u4f4d\u7f6e\u7f16\u7801\u5728\u9002\u5e94\u6027\u3001\u52a8\u6001\u6027\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u7684\u4e0d\u8db3\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u73b0\u6709\u56fe\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u4f4d\u7f6e\u7f16\u7801\u65b9\u6cd5\u5b58\u5728\u9002\u5e94\u6027\u5dee\u3001\u65e0\u6cd5\u5904\u7406\u52a8\u6001\u56fe\u4fe1\u606f\u4ee5\u53ca\u8ba1\u7b97\u6548\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u4e9f\u9700\u6539\u8fdb\u3002", "method": "\u63d0\u51faL-STEP\u6a21\u578b\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u65f6\u7a7a\u4f4d\u7f6e\u7f16\u7801\u65b9\u6848\uff0c\u7ed3\u5408MLP\u5b9e\u73b0\u9ad8\u6548\u8868\u8fbe\uff0c\u5e76\u5728\u4e0d\u540c\u521d\u59cb\u7f16\u7801\u8f93\u5165\u4e0b\u9a8c\u8bc1\u5176\u9c81\u68d2\u6027\u3002", "result": "L-STEP\u572813\u4e2a\u7ecf\u5178\u6570\u636e\u96c6\u548c10\u79cd\u7b97\u6cd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8ba1\u7b97\u6548\u7387\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5728TGB\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9886\u5148\u3002", "conclusion": "L-STEP\u662f\u4e00\u79cd\u9ad8\u6548\u3001\u9002\u5e94\u6027\u5f3a\u7684\u65f6\u7a7a\u4f4d\u7f6e\u7f16\u7801\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u56fe\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2506.08312", "pdf": "https://arxiv.org/pdf/2506.08312", "abs": "https://arxiv.org/abs/2506.08312", "authors": ["Tom\u00e1s Gonz\u00e1lez", "Giulia Fanti", "Aaditya Ramdas"], "title": "Private Evolution Converges", "categories": ["cs.LG", "cs.CR", "cs.DS", "math.PR", "math.ST", "stat.TH", "68P27 (Primary) 68Q32, 68Q87, 60B10 (Secondary)"], "comment": null, "summary": "Private Evolution (PE) is a promising training-free method for differentially\nprivate (DP) synthetic data generation. While it achieves strong performance in\nsome domains (e.g., images and text), its behavior in others (e.g., tabular\ndata) is less consistent. To date, the only theoretical analysis of the\nconvergence of PE depends on unrealistic assumptions about both the algorithm's\nbehavior and the structure of the sensitive dataset. In this work, we develop a\nnew theoretical framework to explain PE's practical behavior and identify\nsufficient conditions for its convergence. For $d$-dimensional sensitive\ndatasets with $n$ data points from a bounded domain, we prove that PE produces\nan $(\\epsilon, \\delta)$-DP synthetic dataset with expected 1-Wasserstein\ndistance of order $\\tilde{O}(d(n\\epsilon)^{-1/d})$ from the original,\nestablishing worst-case convergence of the algorithm as $n \\to \\infty$. Our\nanalysis extends to general Banach spaces as well. We also connect PE to the\nPrivate Signed Measure Mechanism, a method for DP synthetic data generation\nthat has thus far not seen much practical adoption. We demonstrate the\npractical relevance of our theoretical findings in simulations.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7406\u8bba\u6846\u67b6\u6765\u89e3\u91caPrivate Evolution (PE)\u7684\u5b9e\u9645\u884c\u4e3a\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u5728\u751f\u6210\u5dee\u5206\u9690\u79c1\u5408\u6210\u6570\u636e\u65f6\u7684\u6536\u655b\u6027\u3002", "motivation": "PE\u5728\u67d0\u4e9b\u9886\u57df\uff08\u5982\u56fe\u50cf\u548c\u6587\u672c\uff09\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u5176\u4ed6\u9886\u57df\uff08\u5982\u8868\u683c\u6570\u636e\uff09\u8868\u73b0\u4e0d\u4e00\u81f4\u3002\u73b0\u6709\u7406\u8bba\u5206\u6790\u4f9d\u8d56\u4e8e\u4e0d\u73b0\u5b9e\u7684\u5047\u8bbe\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u51c6\u786e\u7684\u7406\u8bba\u89e3\u91ca\u3002", "method": "\u4f5c\u8005\u5f00\u53d1\u4e86\u4e00\u4e2a\u65b0\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5206\u6790\u4e86PE\u5728d\u7ef4\u6570\u636e\u96c6\u4e0a\u7684\u6536\u655b\u6027\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u751f\u6210(\u03b5, \u03b4)-DP\u5408\u6210\u6570\u636e\u7684\u80fd\u529b\u3002", "result": "\u8bc1\u660e\u4e86PE\u5728n\u2192\u221e\u65f6\u7684\u6700\u574f\u60c5\u51b5\u6536\u655b\u6027\uff0c\u5e76\u6269\u5c55\u5230\u4e00\u822cBanach\u7a7a\u95f4\u3002\u540c\u65f6\u5c06PE\u4e0ePrivate Signed Measure Mechanism\u8054\u7cfb\u8d77\u6765\u3002", "conclusion": "\u7406\u8bba\u5206\u6790\u901a\u8fc7\u6a21\u62df\u9a8c\u8bc1\u4e86\u5176\u5b9e\u9645\u610f\u4e49\uff0c\u4e3aPE\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u575a\u5b9e\u7684\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2506.08316", "pdf": "https://arxiv.org/pdf/2506.08316", "abs": "https://arxiv.org/abs/2506.08316", "authors": ["Alan N. Amin", "Nate Gruver", "Andrew Gordon Wilson"], "title": "Why Masking Diffusion Works: Condition on the Jump Schedule for Improved Discrete Diffusion", "categories": ["cs.LG", "stat.ML"], "comment": "Code available at: https://github.com/AlanNawzadAmin/SCUD", "summary": "Discrete diffusion models, like continuous diffusion models, generate\nhigh-quality samples by gradually undoing noise applied to datapoints with a\nMarkov process. Gradual generation in theory comes with many conceptual\nbenefits; for example, inductive biases can be incorporated into the noising\nMarkov process, and access to improved sampling algorithms. In practice,\nhowever, the consistently best performing discrete diffusion model is,\nsurprisingly, masking diffusion, which does not denoise gradually. Here we\nexplain the superior performance of masking diffusion by noting that it makes\nuse of a fundamental difference between continuous and discrete Markov\nprocesses: discrete Markov processes evolve by discontinuous jumps at a fixed\nrate and, unlike other discrete diffusion models, masking diffusion builds in\nthe known distribution of jump times and only learns where to jump to. We show\nthat we can similarly bake in the known distribution of jump times into any\ndiscrete diffusion model. The resulting models - schedule-conditioned discrete\ndiffusion (SCUD) - generalize classical discrete diffusion and masking\ndiffusion. By applying SCUD to models with noising processes that incorporate\ninductive biases on images, text, and protein data, we build models that\noutperform masking.", "AI": {"tldr": "\u79bb\u6563\u6269\u6563\u6a21\u578b\u901a\u8fc7\u9010\u6b65\u53bb\u566a\u751f\u6210\u9ad8\u8d28\u91cf\u6837\u672c\uff0c\u4f46\u5b9e\u8df5\u4e2d\u8868\u73b0\u6700\u4f73\u7684\u662f\u63a9\u7801\u6269\u6563\u6a21\u578b\u3002\u7814\u7a76\u53d1\u73b0\u63a9\u7801\u6269\u6563\u5229\u7528\u4e86\u79bb\u6563\u9a6c\u5c14\u53ef\u592b\u8fc7\u7a0b\u7684\u8df3\u8dc3\u7279\u6027\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5SCUD\uff0c\u80fd\u8d85\u8d8a\u63a9\u7801\u6269\u6563\u7684\u6027\u80fd\u3002", "motivation": "\u63a2\u7d22\u79bb\u6563\u6269\u6563\u6a21\u578b\u6027\u80fd\u5dee\u5f02\u7684\u539f\u56e0\uff0c\u5e76\u63d0\u51fa\u6539\u8fdb\u65b9\u6cd5\u3002", "method": "\u63d0\u51faSCUD\u65b9\u6cd5\uff0c\u5c06\u8df3\u8dc3\u65f6\u95f4\u5206\u5e03\u878d\u5165\u79bb\u6563\u6269\u6563\u6a21\u578b\uff0c\u7ed3\u5408\u5f52\u7eb3\u504f\u7f6e\u5e94\u7528\u4e8e\u56fe\u50cf\u3001\u6587\u672c\u548c\u86cb\u767d\u8d28\u6570\u636e\u3002", "result": "SCUD\u6a21\u578b\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u4e8e\u63a9\u7801\u6269\u6563\u3002", "conclusion": "SCUD\u65b9\u6cd5\u901a\u8fc7\u5229\u7528\u79bb\u6563\u9a6c\u5c14\u53ef\u592b\u8fc7\u7a0b\u7684\u7279\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u79bb\u6563\u6269\u6563\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2506.08326", "pdf": "https://arxiv.org/pdf/2506.08326", "abs": "https://arxiv.org/abs/2506.08326", "authors": ["Xingbo Fu", "Zehong Wang", "Zihan Chen", "Jiazheng Li", "Yaochen Zhu", "Zhenyu Lei", "Cong Shen", "Yanfang Ye", "Chuxu Zhang", "Jundong Li"], "title": "Graph Prompting for Graph Learning Models: Recent Advances and Future Directions", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by KDD 2025 Tutorial/Survey Track", "summary": "Graph learning models have demonstrated great prowess in learning expressive\nrepresentations from large-scale graph data in a wide variety of real-world\nscenarios. As a prevalent strategy for training powerful graph learning models,\nthe \"pre-training, adaptation\" scheme first pre-trains graph learning models on\nunlabeled graph data in a self-supervised manner and then adapts them to\nspecific downstream tasks. During the adaptation phase, graph prompting emerges\nas a promising approach that learns trainable prompts while keeping the\npre-trained graph learning models unchanged. In this paper, we present a\nsystematic review of recent advancements in graph prompting. First, we\nintroduce representative graph pre-training methods that serve as the\nfoundation step of graph prompting. Next, we review mainstream techniques in\ngraph prompting and elaborate on how they design learnable prompts for graph\nprompting. Furthermore, we summarize the real-world applications of graph\nprompting from different domains. Finally, we discuss several open challenges\nin existing studies with promising future directions in this field.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7efc\u8ff0\u4e86\u56fe\u63d0\u793a\u5b66\u4e60\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u5305\u62ec\u56fe\u9884\u8bad\u7ec3\u65b9\u6cd5\u3001\u4e3b\u6d41\u56fe\u63d0\u793a\u6280\u672f\u53ca\u5176\u5e94\u7528\uff0c\u5e76\u8ba8\u8bba\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u56fe\u5b66\u4e60\u6a21\u578b\u5728\u5927\u89c4\u6a21\u56fe\u6570\u636e\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5982\u4f55\u901a\u8fc7\u56fe\u63d0\u793a\u6280\u672f\u9ad8\u6548\u9002\u5e94\u4e0b\u6e38\u4efb\u52a1\u4ecd\u662f\u4e00\u4e2a\u5173\u952e\u95ee\u9898\u3002", "method": "\u4ecb\u7ecd\u4e86\u56fe\u9884\u8bad\u7ec3\u65b9\u6cd5\u4f5c\u4e3a\u57fa\u7840\uff0c\u5e76\u8be6\u7ec6\u9610\u8ff0\u4e86\u56fe\u63d0\u793a\u6280\u672f\u4e2d\u53ef\u5b66\u4e60\u63d0\u793a\u7684\u8bbe\u8ba1\u65b9\u6cd5\u3002", "result": "\u603b\u7ed3\u4e86\u56fe\u63d0\u793a\u6280\u672f\u5728\u4e0d\u540c\u9886\u57df\u7684\u5b9e\u9645\u5e94\u7528\u3002", "conclusion": "\u8ba8\u8bba\u4e86\u73b0\u6709\u7814\u7a76\u7684\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2506.08337", "pdf": "https://arxiv.org/pdf/2506.08337", "abs": "https://arxiv.org/abs/2506.08337", "authors": ["Juhyeok Choi", "Chenglin Fan"], "title": "A Simple Analysis of Discretization Error in Diffusion Models", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Diffusion models, formulated as discretizations of stochastic differential\nequations (SDEs), achieve state-of-the-art generative performance. However,\nexisting analyses of their discretization error often rely on complex\nprobabilistic tools. In this work, we present a simplified theoretical\nframework for analyzing the Euler--Maruyama discretization of\nvariance-preserving SDEs (VP-SDEs) in Denoising Diffusion Probabilistic Models\n(DDPMs), where $ T $ denotes the number of denoising steps in the diffusion\nprocess. Our approach leverages Gr\\\"onwall's inequality to derive a convergence\nrate of $ \\mathcal{O}(1/T^{1/2}) $ under Lipschitz assumptions, significantly\nstreamlining prior proofs. Furthermore, we demonstrate that the Gaussian noise\nin the discretization can be replaced by a discrete random variable (e.g.,\nRademacher or uniform noise) without sacrificing convergence guarantees-an\ninsight with practical implications for efficient sampling. Experiments\nvalidate our theory, showing that (1) the error scales as predicted, (2)\ndiscrete noise achieves comparable sample quality to Gaussian noise, and (3)\nincorrect noise scaling degrades performance. By unifying simplified analysis\nand discrete noise substitution, our work bridges theoretical rigor with\npractical efficiency in diffusion-based generative modeling.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5316\u7684\u7406\u8bba\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u6790DDPM\u4e2dVP-SDE\u7684Euler-Maruyama\u79bb\u6563\u5316\u8bef\u5dee\uff0c\u5e76\u8bc1\u660e\u4e86\u5728Lipschitz\u5047\u8bbe\u4e0b\u6536\u655b\u901f\u7387\u4e3a$\\mathcal{O}(1/T^{1/2})$\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8868\u660e\u79bb\u6563\u566a\u58f0\u53ef\u66ff\u4ee3\u9ad8\u65af\u566a\u58f0\u800c\u4e0d\u5f71\u54cd\u6536\u655b\u6027\u3002", "motivation": "\u73b0\u6709\u6269\u6563\u6a21\u578b\u7684\u79bb\u6563\u5316\u8bef\u5dee\u5206\u6790\u5e38\u4f9d\u8d56\u590d\u6742\u6982\u7387\u5de5\u5177\uff0c\u672c\u6587\u65e8\u5728\u7b80\u5316\u5206\u6790\u6846\u67b6\u5e76\u63a2\u7d22\u79bb\u6563\u566a\u58f0\u7684\u5b9e\u7528\u6027\u3002", "method": "\u5229\u7528Gr\u00f6nwall\u4e0d\u7b49\u5f0f\u63a8\u5bfc\u6536\u655b\u901f\u7387\uff0c\u5e76\u5b9e\u9a8c\u9a8c\u8bc1\u79bb\u6563\u566a\u58f0\uff08\u5982Rademacher\u6216\u5747\u5300\u566a\u58f0\uff09\u7684\u6709\u6548\u6027\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8bef\u5dee\u6309\u9884\u6d4b\u6bd4\u4f8b\u7f29\u653e\uff0c\u79bb\u6563\u566a\u58f0\u4e0e\u9ad8\u65af\u566a\u58f0\u6837\u672c\u8d28\u91cf\u76f8\u5f53\uff0c\u566a\u58f0\u7f29\u653e\u4e0d\u5f53\u4f1a\u964d\u4f4e\u6027\u80fd\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u7b80\u5316\u5206\u6790\u548c\u79bb\u6563\u566a\u58f0\u66ff\u4ee3\uff0c\u5728\u6269\u6563\u751f\u6210\u6a21\u578b\u4e2d\u5b9e\u73b0\u4e86\u7406\u8bba\u4e25\u8c28\u6027\u4e0e\u5b9e\u9645\u6548\u7387\u7684\u7edf\u4e00\u3002"}}
{"id": "2506.08340", "pdf": "https://arxiv.org/pdf/2506.08340", "abs": "https://arxiv.org/abs/2506.08340", "authors": ["Emo Todorov"], "title": "Dynamical System Optimization", "categories": ["cs.LG"], "comment": null, "summary": "We develop an optimization framework centered around a core idea: once a\n(parametric) policy is specified, control authority is transferred to the\npolicy, resulting in an autonomous dynamical system. Thus we should be able to\noptimize policy parameters without further reference to controls or actions,\nand without directly using the machinery of approximate Dynamic Programming and\nReinforcement Learning. Here we derive simpler algorithms at the autonomous\nsystem level, and show that they compute the same quantities as policy\ngradients and Hessians, natural gradients, proximal methods. Analogs to\napproximate policy iteration and off-policy learning are also available. Since\npolicy parameters and other system parameters are treated uniformly, the same\nalgorithms apply to behavioral cloning, mechanism design, system\nidentification, learning of state estimators. Tuning of generative AI models is\nnot only possible, but is conceptually closer to the present framework than to\nReinforcement Learning.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u63a7\u5236\u6743\u8f6c\u79fb\u7ed9\u7b56\u7565\uff0c\u4ece\u800c\u5728\u81ea\u6cbb\u52a8\u6001\u7cfb\u7edf\u5c42\u9762\u7b80\u5316\u7b97\u6cd5\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u52a8\u6001\u89c4\u5212\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u590d\u6742\u6027\u3002", "motivation": "\u4f20\u7edf\u52a8\u6001\u89c4\u5212\u548c\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u590d\u6742\u4e14\u8ba1\u7b97\u91cf\u5927\uff0c\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u76f4\u63a5\u5728\u7b56\u7565\u53c2\u6570\u5c42\u9762\u4f18\u5316\uff0c\u7b80\u5316\u7b97\u6cd5\u5e76\u7edf\u4e00\u5904\u7406\u591a\u79cd\u95ee\u9898\u3002", "method": "\u5c06\u63a7\u5236\u6743\u8f6c\u79fb\u7ed9\u7b56\u7565\uff0c\u5f62\u6210\u81ea\u6cbb\u52a8\u6001\u7cfb\u7edf\uff0c\u5e76\u5728\u7cfb\u7edf\u5c42\u9762\u8bbe\u8ba1\u4f18\u5316\u7b97\u6cd5\uff0c\u907f\u514d\u76f4\u63a5\u4f7f\u7528\u52a8\u6001\u89c4\u5212\u548c\u5f3a\u5316\u5b66\u4e60\u5de5\u5177\u3002", "result": "\u63d0\u51fa\u7684\u7b97\u6cd5\u80fd\u591f\u8ba1\u7b97\u4e0e\u7b56\u7565\u68af\u5ea6\u3001Hessian\u77e9\u9635\u3001\u81ea\u7136\u68af\u5ea6\u7b49\u76f8\u540c\u7684\u91cf\uff0c\u5e76\u9002\u7528\u4e8e\u884c\u4e3a\u514b\u9686\u3001\u673a\u5236\u8bbe\u8ba1\u3001\u7cfb\u7edf\u8fa8\u8bc6\u7b49\u95ee\u9898\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e0d\u4ec5\u7b80\u5316\u4e86\u4f18\u5316\u8fc7\u7a0b\uff0c\u8fd8\u7edf\u4e00\u4e86\u7b56\u7565\u53c2\u6570\u548c\u5176\u4ed6\u7cfb\u7edf\u53c2\u6570\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u751f\u6210\u5f0fAI\u6a21\u578b\u7684\u8c03\u4f18\u3002"}}
{"id": "2506.08347", "pdf": "https://arxiv.org/pdf/2506.08347", "abs": "https://arxiv.org/abs/2506.08347", "authors": ["Yinan Huang", "Haoteng Ying", "Eli Chien", "Rongzhe Wei", "Pan Li"], "title": "Differentially Private Relational Learning with Entity-level Privacy Guarantees", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "Learning with relational and network-structured data is increasingly vital in\nsensitive domains where protecting the privacy of individual entities is\nparamount. Differential Privacy (DP) offers a principled approach for\nquantifying privacy risks, with DP-SGD emerging as a standard mechanism for\nprivate model training. However, directly applying DP-SGD to relational\nlearning is challenging due to two key factors: (i) entities often participate\nin multiple relations, resulting in high and difficult-to-control sensitivity;\nand (ii) relational learning typically involves multi-stage, potentially\ncoupled (interdependent) sampling procedures that make standard privacy\namplification analyses inapplicable. This work presents a principled framework\nfor relational learning with formal entity-level DP guarantees. We provide a\nrigorous sensitivity analysis and introduce an adaptive gradient clipping\nscheme that modulates clipping thresholds based on entity occurrence frequency.\nWe also extend the privacy amplification results to a tractable subclass of\ncoupled sampling, where the dependence arises only through sample sizes. These\ncontributions lead to a tailored DP-SGD variant for relational data with\nprovable privacy guarantees. Experiments on fine-tuning text encoders over\ntext-attributed network-structured relational data demonstrate the strong\nutility-privacy trade-offs of our approach. Our code is available at\nhttps://github.com/Graph-COM/Node_DP.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u5173\u7cfb\u6570\u636e\u7684\u5dee\u5206\u9690\u79c1\u5b66\u4e60\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfDP-SGD\u5728\u5173\u7cfb\u5b66\u4e60\u4e2d\u9762\u4e34\u7684\u654f\u611f\u6027\u548c\u9690\u79c1\u653e\u5927\u95ee\u9898\u3002", "motivation": "\u5728\u654f\u611f\u9886\u57df\u4e2d\u4fdd\u62a4\u4e2a\u4f53\u9690\u79c1\u7684\u9700\u6c42\u65e5\u76ca\u589e\u957f\uff0c\u4f46\u76f4\u63a5\u5e94\u7528DP-SGD\u4e8e\u5173\u7cfb\u5b66\u4e60\u5b58\u5728\u6311\u6218\uff0c\u5982\u9ad8\u654f\u611f\u6027\u548c\u591a\u9636\u6bb5\u91c7\u6837\u3002", "method": "\u901a\u8fc7\u4e25\u683c\u7684\u654f\u611f\u6027\u5206\u6790\u548c\u81ea\u9002\u5e94\u68af\u5ea6\u88c1\u526a\u65b9\u6848\uff0c\u6269\u5c55\u9690\u79c1\u653e\u5927\u7ed3\u679c\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u4e13\u4e3a\u5173\u7cfb\u6570\u636e\u8bbe\u8ba1\u7684DP-SGD\u53d8\u4f53\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6587\u672c\u5c5e\u6027\u7f51\u7edc\u6570\u636e\u4e0a\u5b9e\u73b0\u4e86\u826f\u597d\u7684\u9690\u79c1-\u6548\u7528\u5e73\u8861\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5173\u7cfb\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u5b9e\u4f53\u7ea7\u5dee\u5206\u9690\u79c1\u4fdd\u8bc1\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.08353", "pdf": "https://arxiv.org/pdf/2506.08353", "abs": "https://arxiv.org/abs/2506.08353", "authors": ["Hyunseok Seung", "Jaewoo Lee", "Hyunsuk Ko"], "title": "An Adaptive Method Stabilizing Activations for Enhanced Generalization", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "We introduce AdaAct, a novel optimization algorithm that adjusts learning\nrates according to activation variance. Our method enhances the stability of\nneuron outputs by incorporating neuron-wise adaptivity during the training\nprocess, which subsequently leads to better generalization -- a complementary\napproach to conventional activation regularization methods. Experimental\nresults demonstrate AdaAct's competitive performance across standard image\nclassification benchmarks. We evaluate AdaAct on CIFAR and ImageNet, comparing\nit with other state-of-the-art methods. Importantly, AdaAct effectively bridges\nthe gap between the convergence speed of Adam and the strong generalization\ncapabilities of SGD, all while maintaining competitive execution times. Code is\navailable at https://github.com/hseung88/adaact.", "AI": {"tldr": "AdaAct\u662f\u4e00\u79cd\u65b0\u9896\u7684\u4f18\u5316\u7b97\u6cd5\uff0c\u901a\u8fc7\u6839\u636e\u6fc0\u6d3b\u65b9\u5dee\u8c03\u6574\u5b66\u4e60\u7387\uff0c\u63d0\u5347\u795e\u7ecf\u5143\u8f93\u51fa\u7684\u7a33\u5b9a\u6027\uff0c\u4ece\u800c\u6539\u5584\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u6fc0\u6d3b\u6b63\u5219\u5316\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0cAdaAct\u65e8\u5728\u901a\u8fc7\u795e\u7ecf\u5143\u7ea7\u522b\u7684\u81ea\u9002\u5e94\u4f18\u5316\u5f25\u8865\u8fd9\u4e00\u4e0d\u8db3\u3002", "method": "AdaAct\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u5b66\u4e60\u7387\u4ee5\u9002\u5e94\u6fc0\u6d3b\u65b9\u5dee\uff0c\u7ed3\u5408Adam\u7684\u5feb\u901f\u6536\u655b\u548cSGD\u7684\u5f3a\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u5728CIFAR\u548cImageNet\u7b49\u6807\u51c6\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0cAdaAct\u8868\u73b0\u51fa\u4e0e\u73b0\u6709\u65b9\u6cd5\u7ade\u4e89\u7684\u6027\u80fd\u3002", "conclusion": "AdaAct\u6210\u529f\u5e73\u8861\u4e86\u6536\u655b\u901f\u5ea6\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u6548\u6267\u884c\u65f6\u95f4\u3002"}}
{"id": "2506.08360", "pdf": "https://arxiv.org/pdf/2506.08360", "abs": "https://arxiv.org/abs/2506.08360", "authors": ["Hyunseok Seung", "Jaewoo Lee", "Hyunsuk Ko"], "title": "NysAct: A Scalable Preconditioned Gradient Descent using Nystrom Approximation", "categories": ["cs.LG"], "comment": null, "summary": "Adaptive gradient methods are computationally efficient and converge quickly,\nbut they often suffer from poor generalization. In contrast, second-order\nmethods enhance convergence and generalization but typically incur high\ncomputational and memory costs. In this work, we introduce NysAct, a scalable\nfirst-order gradient preconditioning method that strikes a balance between\nstate-of-the-art first-order and second-order optimization methods. NysAct\nleverages an eigenvalue-shifted Nystrom method to approximate the activation\ncovariance matrix, which is used as a preconditioning matrix, significantly\nreducing time and memory complexities with minimal impact on test accuracy. Our\nexperiments show that NysAct not only achieves improved test accuracy compared\nto both first-order and second-order methods but also demands considerably less\ncomputational resources than existing second-order methods. Code is available\nat https://github.com/hseung88/nysact.", "AI": {"tldr": "NysAct\u662f\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u4e00\u9636\u68af\u5ea6\u9884\u5904\u7406\u65b9\u6cd5\uff0c\u5e73\u8861\u4e86\u4e00\u9636\u548c\u4e8c\u9636\u4f18\u5316\u65b9\u6cd5\u7684\u4f18\u52bf\uff0c\u901a\u8fc7\u8fd1\u4f3c\u6fc0\u6d3b\u534f\u65b9\u5dee\u77e9\u9635\u964d\u4f4e\u8ba1\u7b97\u548c\u5185\u5b58\u6210\u672c\uff0c\u540c\u65f6\u63d0\u9ad8\u6d4b\u8bd5\u7cbe\u5ea6\u3002", "motivation": "\u81ea\u9002\u5e94\u68af\u5ea6\u65b9\u6cd5\u8ba1\u7b97\u9ad8\u6548\u4f46\u6cdb\u5316\u80fd\u529b\u5dee\uff0c\u4e8c\u9636\u65b9\u6cd5\u6cdb\u5316\u80fd\u529b\u5f3a\u4f46\u8ba1\u7b97\u548c\u5185\u5b58\u6210\u672c\u9ad8\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u5e73\u8861\u4e24\u8005\u7684\u65b9\u6cd5\u3002", "method": "NysAct\u5229\u7528\u7279\u5f81\u503c\u504f\u79fb\u7684Nystrom\u65b9\u6cd5\u8fd1\u4f3c\u6fc0\u6d3b\u534f\u65b9\u5dee\u77e9\u9635\u4f5c\u4e3a\u9884\u5904\u7406\u77e9\u9635\uff0c\u663e\u8457\u964d\u4f4e\u65f6\u95f4\u548c\u5185\u5b58\u590d\u6742\u5ea6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cNysAct\u5728\u6d4b\u8bd5\u7cbe\u5ea6\u4e0a\u4f18\u4e8e\u4e00\u9636\u548c\u4e8c\u9636\u65b9\u6cd5\uff0c\u540c\u65f6\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u663e\u8457\u4f4e\u4e8e\u4e8c\u9636\u65b9\u6cd5\u3002", "conclusion": "NysAct\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u6cdb\u5316\u80fd\u529b\u5f3a\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u6df1\u5ea6\u5b66\u4e60\u4efb\u52a1\u3002"}}
{"id": "2506.08365", "pdf": "https://arxiv.org/pdf/2506.08365", "abs": "https://arxiv.org/abs/2506.08365", "authors": ["Cheng Tan", "Zhenxiao Cao", "Zhangyang Gao", "Siyuan Li", "Yufei Huang", "Stan Z. Li"], "title": "AlphaFold Database Debiasing for Robust Inverse Folding", "categories": ["cs.LG", "q-bio.BM"], "comment": "Under review", "summary": "The AlphaFold Protein Structure Database (AFDB) offers unparalleled\nstructural coverage at near-experimental accuracy, positioning it as a valuable\nresource for data-driven protein design. However, its direct use in training\ndeep models that are sensitive to fine-grained atomic geometry, such as inverse\nfolding, exposes a critical limitation. Comparative analysis of structural\nfeature distributions reveals that AFDB structures exhibit distinct statistical\nregularities, reflecting a systematic geometric bias that deviates from the\nconformational diversity found in experimentally determined structures from the\nProtein Data Bank (PDB). While AFDB structures are cleaner and more idealized,\nPDB structures capture the intrinsic variability and physical realism essential\nfor generalization in downstream tasks. To address this discrepancy, we\nintroduce a Debiasing Structure AutoEncoder (DeSAE) that learns to reconstruct\nnative-like conformations from intentionally corrupted backbone geometries. By\ntraining the model to recover plausible structural states, DeSAE implicitly\ncaptures a more robust and natural structural manifold. At inference, applying\nDeSAE to AFDB structures produces debiased structures that significantly\nimprove inverse folding performance across multiple benchmarks. This work\nhighlights the critical impact of subtle systematic biases in predicted\nstructures and presents a principled framework for debiasing, significantly\nboosting the performance of structure-based learning tasks like inverse\nfolding.", "AI": {"tldr": "AlphaFold\u6570\u636e\u5e93\uff08AFDB\uff09\u7684\u7ed3\u6784\u6570\u636e\u867d\u7136\u8986\u76d6\u5e7f\u4e14\u7cbe\u5ea6\u9ad8\uff0c\u4f46\u5728\u8bad\u7ec3\u5bf9\u539f\u5b50\u51e0\u4f55\u654f\u611f\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff08\u5982\u9006\u6298\u53e0\uff09\u65f6\u5b58\u5728\u7cfb\u7edf\u6027\u51e0\u4f55\u504f\u5dee\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u7814\u7a76\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u53bb\u504f\u7ed3\u6784\u81ea\u7f16\u7801\u5668\uff08DeSAE\uff09\uff0c\u901a\u8fc7\u91cd\u6784\u81ea\u7136\u6784\u8c61\u6765\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "AFDB\u7684\u7ed3\u6784\u6570\u636e\u867d\u7136\u9ad8\u8d28\u91cf\uff0c\u4f46\u5176\u51e0\u4f55\u504f\u5dee\u9650\u5236\u4e86\u5728\u9006\u6298\u53e0\u7b49\u4efb\u52a1\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u3002\u5b9e\u9a8c\u7ed3\u6784\uff08PDB\uff09\u66f4\u5177\u591a\u6837\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6d88\u9664AFDB\u7684\u504f\u5dee\u3002", "method": "\u63d0\u51faDeSAE\uff0c\u901a\u8fc7\u4ece\u6545\u610f\u635f\u574f\u7684\u4e3b\u94fe\u51e0\u4f55\u4e2d\u91cd\u6784\u81ea\u7136\u6784\u8c61\uff0c\u5b66\u4e60\u66f4\u7a33\u5065\u7684\u7ed3\u6784\u6d41\u5f62\u3002", "result": "DeSAE\u663e\u8457\u63d0\u5347\u4e86\u9006\u6298\u53e0\u4efb\u52a1\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u6027\u80fd\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u9884\u6d4b\u7ed3\u6784\u4e2d\u7684\u7cfb\u7edf\u6027\u504f\u5dee\u5bf9\u4efb\u52a1\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u6709\u6548\u7684\u53bb\u504f\u6846\u67b6\uff0c\u63d0\u5347\u4e86\u7ed3\u6784\u5b66\u4e60\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2506.08379", "pdf": "https://arxiv.org/pdf/2506.08379", "abs": "https://arxiv.org/abs/2506.08379", "authors": ["Yurun Yuan", "Tengyang Xie"], "title": "Reinforce LLM Reasoning through Multi-Agent Reflection", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "International Conference on Machine Learning (ICML), 2025", "summary": "Leveraging more test-time computation has proven to be an effective way to\nboost the reasoning capabilities of large language models (LLMs). Among various\nmethods, the verify-and-improve paradigm stands out for enabling dynamic\nsolution exploration and feedback incorporation. However, existing approaches\noften suffer from restricted feedback spaces and lack of coordinated training\nof different parties, leading to suboptimal performance. To address this, we\nmodel this multi-turn refinement process as a Markov Decision Process and\nintroduce DPSDP (Direct Policy Search by Dynamic Programming), a reinforcement\nlearning algorithm that trains an actor-critic LLM system to iteratively refine\nanswers via direct preference learning on self-generated data. Theoretically,\nDPSDP can match the performance of any policy within the training distribution.\nEmpirically, we instantiate DPSDP with various base models and show\nimprovements on both in- and out-of-distribution benchmarks. For example, on\nbenchmark MATH 500, majority voting over five refinement steps increases\nfirst-turn accuracy from 58.2% to 63.2% with Ministral-based models. An\nablation study further confirms the benefits of multi-agent collaboration and\nout-of-distribution generalization.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faDPSDP\u7b97\u6cd5\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3LLM\u7cfb\u7edf\u8fed\u4ee3\u4f18\u5316\u7b54\u6848\uff0c\u63d0\u5347\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u53cd\u9988\u7a7a\u95f4\u548c\u534f\u540c\u8bad\u7ec3\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9650\u5236\u4e86\u6027\u80fd\u63d0\u5347\u3002", "method": "\u5c06\u591a\u8f6e\u4f18\u5316\u5efa\u6a21\u4e3a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5f15\u5165DPSDP\u7b97\u6cd5\uff0c\u901a\u8fc7\u76f4\u63a5\u504f\u597d\u5b66\u4e60\u8bad\u7ec3actor-critic LLM\u7cfb\u7edf\u3002", "result": "\u5728MATH 500\u57fa\u51c6\u4e0a\uff0c\u4e94\u8f6e\u4f18\u5316\u5c06\u51c6\u786e\u7387\u4ece58.2%\u63d0\u5347\u81f363.2%\uff0c\u9a8c\u8bc1\u4e86\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "DPSDP\u7b97\u6cd5\u6709\u6548\u63d0\u5347\u4e86LLM\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5c24\u5176\u5728\u591a\u8f6e\u4f18\u5316\u548c\u6cdb\u5316\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2506.08383", "pdf": "https://arxiv.org/pdf/2506.08383", "abs": "https://arxiv.org/abs/2506.08383", "authors": ["Jiaqi Chen", "Rongbin Ye"], "title": "Network Threat Detection: Addressing Class Imbalanced Data with Deep Forest", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "With the rapid expansion of Internet of Things (IoT) networks, detecting\nmalicious traffic in real-time has become a critical cybersecurity challenge.\nThis research addresses the detection challenges by presenting a comprehensive\nempirical analysis of machine learning techniques for malware detection using\nthe IoT-23 dataset provided by the Stratosphere Laboratory. We address the\nsignificant class imbalance within the dataset through three resampling\nstrategies. We implement and compare a few machine learning techniques. Our\nfindings demonstrate that the combination of appropriate imbalance treatment\ntechniques with ensemble methods, particularly gcForest, achieves better\ndetection performance compared to traditional approaches. This work contributes\nsignificantly to the development of more intelligent and efficient automated\nthreat detection systems for IoT environments, helping to secure critical\ninfrastructure against sophisticated cyber attacks while optimizing\ncomputational resource usage.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u6076\u610f\u6d41\u91cf\u68c0\u6d4b\u65b9\u6cd5\uff0c\u9488\u5bf9IoT\u7f51\u7edc\u4e2d\u7684\u7c7b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u901a\u8fc7\u91cd\u91c7\u6837\u7b56\u7565\u548c\u96c6\u6210\u65b9\u6cd5\uff08\u5982gcForest\uff09\u63d0\u5347\u4e86\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u968f\u7740IoT\u7f51\u7edc\u7684\u5feb\u901f\u6269\u5c55\uff0c\u5b9e\u65f6\u68c0\u6d4b\u6076\u610f\u6d41\u91cf\u6210\u4e3a\u5173\u952e\u6311\u6218\uff0c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u4f7f\u7528IoT-23\u6570\u636e\u96c6\uff0c\u91c7\u7528\u4e09\u79cd\u91cd\u91c7\u6837\u7b56\u7565\u5904\u7406\u7c7b\u4e0d\u5e73\u8861\uff0c\u5e76\u6bd4\u8f83\u591a\u79cd\u673a\u5668\u5b66\u4e60\u6280\u672f\u3002", "result": "\u7ed3\u5408\u91cd\u91c7\u6837\u548c\u96c6\u6210\u65b9\u6cd5\uff08\u5982gcForest\uff09\u7684\u68c0\u6d4b\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3aIoT\u73af\u5883\u63d0\u4f9b\u4e86\u66f4\u667a\u80fd\u3001\u9ad8\u6548\u7684\u81ea\u52a8\u5316\u5a01\u80c1\u68c0\u6d4b\u7cfb\u7edf\uff0c\u6709\u52a9\u4e8e\u4fdd\u62a4\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u5e76\u4f18\u5316\u8ba1\u7b97\u8d44\u6e90\u3002"}}
{"id": "2506.08388", "pdf": "https://arxiv.org/pdf/2506.08388", "abs": "https://arxiv.org/abs/2506.08388", "authors": ["Edoardo Cetin", "Tianyu Zhao", "Yujin Tang"], "title": "Reinforcement Learning Teachers of Test Time Scaling", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Preprint", "summary": "Training reasoning language models (LMs) with reinforcement learning (RL) for\none-hot correctness inherently relies on the LM being able to explore and solve\nits task with some chance at initialization. Furthermore, a key use case of\nreasoning LMs is to act as teachers for distilling new students and\ncold-starting future RL iterations rather than being deployed themselves. From\nthese considerations, we introduce a new framework that avoids RL's exploration\nchallenge by training a new class of Reinforcement-Learned Teachers (RLTs)\nfocused on yielding the most effective downstream distillation. RLTs are\nprompted with both the question and solution to each problem, and tasked to\nsimply \"connect-the-dots\" with detailed explanations tailored for their\nstudents. We train RLTs with dense rewards obtained by feeding each explanation\nto the student and testing its understanding of the problem's solution. In\npractice, the raw outputs of a 7B RLT provide higher final performance on\ncompetition and graduate-level tasks than existing distillation and\ncold-starting pipelines that collect and postprocess the reasoning traces of\norders of magnitude larger LMs. Furthermore, RLTs maintain their effectiveness\nwhen training larger students and when applied zero-shot to out-of-distribution\ntasks, unlocking new levels of efficiency and re-usability for the RL reasoning\nframework.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6Reinforcement-Learned Teachers (RLTs)\uff0c\u901a\u8fc7\u907f\u514d\u5f3a\u5316\u5b66\u4e60\u7684\u63a2\u7d22\u6311\u6218\uff0c\u4e13\u6ce8\u4e8e\u751f\u6210\u6700\u6709\u6548\u7684\u4e0b\u6e38\u84b8\u998f\u7ed3\u679c\u3002RLTs\u901a\u8fc7\u63d0\u4f9b\u8be6\u7ec6\u89e3\u91ca\u6765\u8bad\u7ec3\u5b66\u751f\u6a21\u578b\uff0c\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u63a8\u7406\u8bed\u8a00\u6a21\u578b\u4f9d\u8d56\u4e8e\u521d\u59cb\u63a2\u7d22\u80fd\u529b\uff0c\u4e14\u6a21\u578b\u4e3b\u8981\u7528\u4e8e\u84b8\u998f\u65b0\u5b66\u751f\u800c\u975e\u76f4\u63a5\u90e8\u7f72\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u6846\u67b6\u6765\u4f18\u5316\u84b8\u998f\u6548\u679c\u3002", "method": "\u5f15\u5165RLTs\u6846\u67b6\uff0cRLTs\u88ab\u63d0\u793a\u95ee\u9898\u548c\u89e3\u51b3\u65b9\u6848\uff0c\u4efb\u52a1\u662f\u751f\u6210\u8be6\u7ec6\u89e3\u91ca\u4ee5\u8bad\u7ec3\u5b66\u751f\u6a21\u578b\u3002\u8bad\u7ec3\u65f6\u4f7f\u7528\u5bc6\u96c6\u5956\u52b1\uff0c\u901a\u8fc7\u5b66\u751f\u6a21\u578b\u5bf9\u89e3\u91ca\u7684\u7406\u89e3\u6765\u8bc4\u4f30\u6548\u679c\u3002", "result": "7B\u89c4\u6a21\u7684RLT\u5728\u7ade\u8d5b\u548c\u7814\u7a76\u751f\u7ea7\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u84b8\u998f\u65b9\u6cd5\uff0c\u4e14\u80fd\u6709\u6548\u8bad\u7ec3\u66f4\u5927\u7684\u5b66\u751f\u6a21\u578b\u548c\u96f6\u6837\u672c\u9002\u5e94\u65b0\u4efb\u52a1\u3002", "conclusion": "RLTs\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u5f3a\u5316\u5b66\u4e60\u63a8\u7406\u7684\u6548\u7387\u548c\u591a\u7528\u9014\u6027\uff0c\u4e3a\u6a21\u578b\u84b8\u998f\u548c\u51b7\u542f\u52a8\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.08397", "pdf": "https://arxiv.org/pdf/2506.08397", "abs": "https://arxiv.org/abs/2506.08397", "authors": ["Vamshika Sutar", "Amandeep Singh", "Rohitash Chandra"], "title": "Spatiotemporal deep learning models for detection of rapid intensification in cyclones", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Cyclone rapid intensification is the rapid increase in cyclone wind\nintensity, exceeding a threshold of 30 knots, within 24 hours. Rapid\nintensification is considered an extreme event during a cyclone, and its\noccurrence is relatively rare, contributing to a class imbalance in the\ndataset. A diverse array of factors influences the likelihood of a cyclone\nundergoing rapid intensification, further complicating the task for\nconventional machine learning models. In this paper, we evaluate deep learning,\nensemble learning and data augmentation frameworks to detect cyclone rapid\nintensification based on wind intensity and spatial coordinates. We note that\nconventional data augmentation methods cannot be utilised for generating\nspatiotemporal patterns replicating cyclones that undergo rapid\nintensification. Therefore, our framework employs deep learning models to\ngenerate spatial coordinates and wind intensity that replicate cyclones to\naddress the class imbalance problem of rapid intensification. We also use a\ndeep learning model for the classification module within the data augmentation\nframework to differentiate between rapid and non-rapid intensification events\nduring a cyclone. Our results show that data augmentation improves the results\nfor rapid intensification detection in cyclones, and spatial coordinates play a\ncritical role as input features to the given models. This paves the way for\nresearch in synthetic data generation for spatiotemporal data with extreme\nevents.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u548c\u6570\u636e\u589e\u5f3a\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u68c0\u6d4b\u6c14\u65cb\u5feb\u901f\u589e\u5f3a\u4e8b\u4ef6\uff0c\u89e3\u51b3\u4e86\u6570\u636e\u96c6\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "motivation": "\u6c14\u65cb\u5feb\u901f\u589e\u5f3a\u662f\u4e00\u79cd\u6781\u7aef\u4e14\u7f55\u89c1\u7684\u4e8b\u4ef6\uff0c\u5bfc\u81f4\u6570\u636e\u96c6\u7c7b\u522b\u4e0d\u5e73\u8861\uff0c\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u96be\u4ee5\u5904\u7406\u3002", "method": "\u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u751f\u6210\u7a7a\u95f4\u5750\u6807\u548c\u98ce\u901f\u6570\u636e\u4ee5\u590d\u5236\u6c14\u65cb\uff0c\u5e76\u7ed3\u5408\u6570\u636e\u589e\u5f3a\u6846\u67b6\u8fdb\u884c\u5206\u7c7b\u3002", "result": "\u6570\u636e\u589e\u5f3a\u63d0\u9ad8\u4e86\u5feb\u901f\u589e\u5f3a\u4e8b\u4ef6\u7684\u68c0\u6d4b\u6548\u679c\uff0c\u7a7a\u95f4\u5750\u6807\u4f5c\u4e3a\u8f93\u5165\u7279\u5f81\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u65f6\u7a7a\u6570\u636e\u4e2d\u6781\u7aef\u4e8b\u4ef6\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.08409", "pdf": "https://arxiv.org/pdf/2506.08409", "abs": "https://arxiv.org/abs/2506.08409", "authors": ["Fred Xu", "Song Jiang", "Zijie Huang", "Xiao Luo", "Shichang Zhang", "Adrian Chen", "Yizhou Sun"], "title": "FUSE: Measure-Theoretic Compact Fuzzy Set Representation for Taxonomy Expansion", "categories": ["cs.LG"], "comment": null, "summary": "Taxonomy Expansion, which models complex concepts and their relations, can be\nformulated as a set representation learning task. The generalization of set,\nfuzzy set, incorporates uncertainty and measures the information within a\nsemantic concept, making it suitable for concept modeling. Existing works\nusually model sets as vectors or geometric objects such as boxes, which are not\nclosed under set operations. In this work, we propose a sound and efficient\nformulation of set representation learning based on its volume approximation as\na fuzzy set. The resulting embedding framework, Fuzzy Set Embedding (FUSE),\nsatisfies all set operations and compactly approximates the underlying fuzzy\nset, hence preserving information while being efficient to learn, relying on\nminimum neural architecture. We empirically demonstrate the power of FUSE on\nthe task of taxonomy expansion, where FUSE achieves remarkable improvements up\nto 23% compared with existing baselines. Our work marks the first attempt to\nunderstand and efficiently compute the embeddings of fuzzy sets.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u7cca\u96c6\u7684\u96c6\u5408\u8868\u793a\u5b66\u4e60\u65b9\u6cd5FUSE\uff0c\u7528\u4e8e\u5206\u7c7b\u6269\u5c55\u4efb\u52a1\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u5347\u663e\u8457\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5c06\u96c6\u5408\u5efa\u6a21\u4e3a\u5411\u91cf\u6216\u51e0\u4f55\u5bf9\u8c61\uff08\u5982\u76d2\u5b50\uff09\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u5728\u96c6\u5408\u64cd\u4f5c\u4e0b\u4e0d\u5c01\u95ed\uff0c\u4e14\u65e0\u6cd5\u6709\u6548\u5904\u7406\u4e0d\u786e\u5b9a\u6027\u3002\u6a21\u7cca\u96c6\u80fd\u66f4\u597d\u5730\u5efa\u6a21\u8bed\u4e49\u6982\u5ff5\u53ca\u5176\u5173\u7cfb\u3002", "method": "\u63d0\u51faFUSE\u6846\u67b6\uff0c\u901a\u8fc7\u4f53\u79ef\u8fd1\u4f3c\u6a21\u7cca\u96c6\u6765\u8868\u793a\u96c6\u5408\uff0c\u6ee1\u8db3\u6240\u6709\u96c6\u5408\u64cd\u4f5c\uff0c\u4e14\u5b66\u4e60\u6548\u7387\u9ad8\uff0c\u4ec5\u9700\u6700\u5c0f\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u3002", "result": "\u5728\u5206\u7c7b\u6269\u5c55\u4efb\u52a1\u4e2d\uff0cFUSE\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u63d0\u5347\u9ad8\u8fbe23%\u3002", "conclusion": "FUSE\u662f\u9996\u4e2a\u5c1d\u8bd5\u7406\u89e3\u5e76\u9ad8\u6548\u8ba1\u7b97\u6a21\u7cca\u96c6\u5d4c\u5165\u7684\u5de5\u4f5c\uff0c\u4e3a\u96c6\u5408\u8868\u793a\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.08412", "pdf": "https://arxiv.org/pdf/2506.08412", "abs": "https://arxiv.org/abs/2506.08412", "authors": ["Saraa Ali", "Aleksandr Khizhik", "Stepan Svirin", "Artem Ryzhikov", "Denis Derkach"], "title": "Learning to Hear Broken Motors: Signature-Guided Data Augmentation for Induction-Motor Diagnostics", "categories": ["cs.LG"], "comment": null, "summary": "The application of machine learning (ML) algorithms in the intelligent\ndiagnosis of three-phase engines has the potential to significantly enhance\ndiagnostic performance and accuracy. Traditional methods largely rely on\nsignature analysis, which, despite being a standard practice, can benefit from\nthe integration of advanced ML techniques. In our study, we innovate by\ncombining ML algorithms with a novel unsupervised anomaly generation\nmethodology that takes into account the engine physics model. We propose\nSignature-Guided Data Augmentation (SGDA), an unsupervised framework that\nsynthesizes physically plausible faults directly in the frequency domain of\nhealthy current signals. Guided by Motor Current Signature Analysis, SGDA\ncreates diverse and realistic anomalies without resorting to computationally\nintensive simulations. This hybrid approach leverages the strengths of both\nsupervised ML and unsupervised signature analysis, achieving superior\ndiagnostic accuracy and reliability along with wide industrial application. The\nfindings highlight the potential of our approach to contribute significantly to\nthe field of engine diagnostics, offering a robust and efficient solution for\nreal-world applications.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u4e0e\u65e0\u76d1\u7763\u5f02\u5e38\u751f\u6210\u65b9\u6cd5\u7684\u65b0\u6846\u67b6SGDA\uff0c\u7528\u4e8e\u4e09\u76f8\u7535\u673a\u7684\u667a\u80fd\u8bca\u65ad\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bca\u65ad\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u8bca\u65ad\u65b9\u6cd5\u4f9d\u8d56\u7b7e\u540d\u5206\u6790\uff0c\u867d\u4e3a\u6807\u51c6\u5b9e\u8df5\uff0c\u4f46\u7ed3\u5408\u5148\u8fdbML\u6280\u672f\u53ef\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u3002", "method": "\u63d0\u51faSGDA\u6846\u67b6\uff0c\u901a\u8fc7\u65e0\u76d1\u7763\u65b9\u5f0f\u5728\u5065\u5eb7\u7535\u6d41\u4fe1\u53f7\u7684\u9891\u57df\u4e2d\u5408\u6210\u7269\u7406\u5408\u7406\u7684\u6545\u969c\uff0c\u7ed3\u5408\u76d1\u7763ML\u548c\u65e0\u76d1\u7763\u7b7e\u540d\u5206\u6790\u3002", "result": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u8bca\u65ad\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5de5\u4e1a\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "SGDA\u4e3a\u7535\u673a\u8bca\u65ad\u9886\u57df\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u7a33\u5065\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u91cd\u8981\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2506.08415", "pdf": "https://arxiv.org/pdf/2506.08415", "abs": "https://arxiv.org/abs/2506.08415", "authors": ["Licong Lin", "Jingfeng Wu", "Peter L. Bartlett"], "title": "Improved Scaling Laws in Linear Regression via Data Reuse", "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH"], "comment": null, "summary": "Neural scaling laws suggest that the test error of large language models\ntrained online decreases polynomially as the model size and data size increase.\nHowever, such scaling can be unsustainable when running out of new data. In\nthis work, we show that data reuse can improve existing scaling laws in linear\nregression. Specifically, we derive sharp test error bounds on $M$-dimensional\nlinear models trained by multi-pass stochastic gradient descent (multi-pass\nSGD) on $N$ data with sketched features. Assuming that the data covariance has\na power-law spectrum of degree $a$, and that the true parameter follows a prior\nwith an aligned power-law spectrum of degree $b-a$ (with $a > b > 1$), we show\nthat multi-pass SGD achieves a test error of $\\Theta(M^{1-b} + L^{(1-b)/a})$,\nwhere $L \\lesssim N^{a/b}$ is the number of iterations. In the same setting,\none-pass SGD only attains a test error of $\\Theta(M^{1-b} + N^{(1-b)/a})$ (see\ne.g., Lin et al., 2024). This suggests an improved scaling law via data reuse\n(i.e., choosing $L>N$) in data-constrained regimes. Numerical simulations are\nalso provided to verify our theoretical findings.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u6570\u636e\u91cd\u7528\u5982\u4f55\u6539\u8fdb\u7ebf\u6027\u56de\u5f52\u4e2d\u7684\u7f29\u653e\u5b9a\u5f8b\uff0c\u901a\u8fc7\u591a\u8f6e\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff08SGD\uff09\u5728\u6570\u636e\u53d7\u9650\u60c5\u51b5\u4e0b\u5b9e\u73b0\u66f4\u4f18\u7684\u6d4b\u8bd5\u8bef\u5dee\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u4e2d\u6570\u636e\u4e0d\u8db3\u65f6\uff0c\u5982\u4f55\u901a\u8fc7\u6570\u636e\u91cd\u7528\u4f18\u5316\u73b0\u6709\u7f29\u653e\u5b9a\u5f8b\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u5728\u591a\u8f6eSGD\u4e2d\u91cd\u7528\u6570\u636e\uff0c\u5e76\u5047\u8bbe\u6570\u636e\u534f\u65b9\u5dee\u548c\u771f\u5b9e\u53c2\u6570\u9075\u5faa\u7279\u5b9a\u7684\u5e42\u5f8b\u8c31\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u591a\u8f6eSGD\u5728\u6570\u636e\u53d7\u9650\u60c5\u51b5\u4e0b\u4f18\u4e8e\u5355\u8f6eSGD\uff0c\u6d4b\u8bd5\u8bef\u5dee\u66f4\u4f4e\u3002", "conclusion": "\u7ed3\u8bba\u652f\u6301\u6570\u636e\u91cd\u7528\u53ef\u4ee5\u6539\u8fdb\u7f29\u653e\u5b9a\u5f8b\uff0c\u5c24\u5176\u5728\u6570\u636e\u53d7\u9650\u65f6\u6548\u679c\u663e\u8457\u3002"}}
{"id": "2506.08417", "pdf": "https://arxiv.org/pdf/2506.08417", "abs": "https://arxiv.org/abs/2506.08417", "authors": ["Qingmao Yao", "Zhichao Lei", "Tianyuan Chen", "Ziyue Yuan", "Xuefan Chen", "Jianxiang Liu", "Faguo Wu", "Xiao Zhang"], "title": "Offline RL with Smooth OOD Generalization in Convex Hull and its Neighborhood", "categories": ["cs.LG", "cs.AI"], "comment": "ICLR 2025", "summary": "Offline Reinforcement Learning (RL) struggles with distributional shifts,\nleading to the $Q$-value overestimation for out-of-distribution (OOD) actions.\nExisting methods address this issue by imposing constraints; however, they\noften become overly conservative when evaluating OOD regions, which constrains\nthe $Q$-function generalization. This over-constraint issue results in poor\n$Q$-value estimation and hinders policy improvement. In this paper, we\nintroduce a novel approach to achieve better $Q$-value estimation by enhancing\n$Q$-function generalization in OOD regions within Convex Hull and its\nNeighborhood (CHN). Under the safety generalization guarantees of the CHN, we\npropose the Smooth Bellman Operator (SBO), which updates OOD $Q$-values by\nsmoothing them with neighboring in-sample $Q$-values. We theoretically show\nthat SBO approximates true $Q$-values for both in-sample and OOD actions within\nthe CHN. Our practical algorithm, Smooth Q-function OOD Generalization (SQOG),\nempirically alleviates the over-constraint issue, achieving near-accurate\n$Q$-value estimation. On the D4RL benchmarks, SQOG outperforms existing\nstate-of-the-art methods in both performance and computational efficiency.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5SQOG\uff0c\u901a\u8fc7\u5e73\u6ed1\u8d1d\u5c14\u66fc\u7b97\u5b50\uff08SBO\uff09\u5728\u51f8\u5305\u53ca\u5176\u90bb\u57df\uff08CHN\uff09\u5185\u589e\u5f3aQ\u51fd\u6570\u6cdb\u5316\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2dQ\u503c\u9ad8\u4f30\u95ee\u9898\uff0c\u5e76\u5728D4RL\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u5206\u5e03\u504f\u79fb\u5bfc\u81f4\u5bf9\u5206\u5e03\u5916\uff08OOD\uff09\u52a8\u4f5c\u7684Q\u503c\u9ad8\u4f30\uff0c\u73b0\u6709\u65b9\u6cd5\u56e0\u8fc7\u5ea6\u7ea6\u675f\u9650\u5236\u4e86Q\u51fd\u6570\u6cdb\u5316\uff0c\u5f71\u54cd\u4e86\u7b56\u7565\u6539\u8fdb\u3002", "method": "\u63d0\u51fa\u5e73\u6ed1\u8d1d\u5c14\u66fc\u7b97\u5b50\uff08SBO\uff09\uff0c\u901a\u8fc7\u5c06OOD Q\u503c\u4e0e\u90bb\u8fd1\u6837\u672c\u5185Q\u503c\u5e73\u6ed1\u66f4\u65b0\uff0c\u589e\u5f3aCHN\u5185\u7684Q\u51fd\u6570\u6cdb\u5316\u3002\u7406\u8bba\u8bc1\u660eSBO\u80fd\u8fd1\u4f3c\u771f\u5b9eQ\u503c\u3002", "result": "SQOG\u7b97\u6cd5\u5728D4RL\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u63a5\u8fd1\u51c6\u786e\u7684Q\u503c\u4f30\u8ba1\uff0c\u4e14\u5728\u8ba1\u7b97\u6548\u7387\u4e0a\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "SQOG\u901a\u8fc7SBO\u89e3\u51b3\u4e86\u8fc7\u5ea6\u7ea6\u675f\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7684Q\u503c\u4f30\u8ba1\u548c\u7b56\u7565\u6027\u80fd\u3002"}}
{"id": "2506.08419", "pdf": "https://arxiv.org/pdf/2506.08419", "abs": "https://arxiv.org/abs/2506.08419", "authors": ["Ruichen Jiang", "Ali Kavis", "Aryan Mokhtari"], "title": "Online Learning-guided Learning Rate Adaptation via Gradient Alignment", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": "24 pages, 5 figures", "summary": "The performance of an optimizer on large-scale deep learning models depends\ncritically on fine-tuning the learning rate, often requiring an extensive grid\nsearch over base learning rates, schedules, and other hyperparameters. In this\npaper, we propose a principled framework called GALA (Gradient Alignment-based\nLearning rate Adaptation), which dynamically adjusts the learning rate by\ntracking the alignment between consecutive gradients and using a local\ncurvature estimate. Guided by the convergence analysis, we formulate the\nproblem of selecting the learning rate as a one-dimensional online learning\nproblem. When paired with an online learning algorithm such as\nFollow-the-Regularized-Leader, our method produces a flexible, adaptive\nlearning rate schedule that tends to increase when consecutive gradients are\naligned and decrease otherwise. We establish a data-adaptive convergence rate\nfor normalized SGD equipped with GALA in the smooth, nonconvex setting.\nEmpirically, common optimizers such as SGD and Adam, when augmented with GALA,\ndemonstrate robust performance across a wide range of initial learning rates\nand perform competitively without the need for tuning.", "AI": {"tldr": "GALA\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u5b66\u4e60\u7387\uff0c\u57fa\u4e8e\u68af\u5ea6\u5bf9\u9f50\u548c\u5c40\u90e8\u66f2\u7387\u4f30\u8ba1\uff0c\u65e0\u9700\u7e41\u7410\u7684\u8d85\u53c2\u6570\u8c03\u4f18\uff0c\u63d0\u5347\u4f18\u5316\u5668\u5728\u5927\u89c4\u6a21\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e2d\u7684\u6027\u80fd\u3002", "motivation": "\u5927\u89c4\u6a21\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e2d\uff0c\u5b66\u4e60\u7387\u7684\u7cbe\u7ec6\u8c03\u4f18\u5bf9\u4f18\u5316\u5668\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u7f51\u683c\u641c\u7d22\uff0c\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u63d0\u51faGALA\u6846\u67b6\uff0c\u901a\u8fc7\u8ddf\u8e2a\u8fde\u7eed\u68af\u5ea6\u7684\u5bf9\u9f50\u6027\u548c\u5c40\u90e8\u66f2\u7387\u4f30\u8ba1\uff0c\u52a8\u6001\u8c03\u6574\u5b66\u4e60\u7387\uff0c\u5e76\u5c06\u5176\u5efa\u6a21\u4e3a\u4e00\u7ef4\u5728\u7ebf\u5b66\u4e60\u95ee\u9898\u3002", "result": "GALA\u5728\u5e73\u6ed1\u975e\u51f8\u8bbe\u7f6e\u4e0b\u4e3a\u5f52\u4e00\u5316SGD\u63d0\u4f9b\u4e86\u6570\u636e\u81ea\u9002\u5e94\u6536\u655b\u7387\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u4e0eSGD\u548cAdam\u7ed3\u5408\u65f6\u8868\u73b0\u7a33\u5065\u4e14\u65e0\u9700\u8c03\u4f18\u3002", "conclusion": "GALA\u4e3a\u5b66\u4e60\u7387\u52a8\u6001\u8c03\u6574\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u81ea\u9002\u5e94\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u8d85\u53c2\u6570\u8c03\u4f18\u7684\u9700\u6c42\u3002"}}
{"id": "2506.08426", "pdf": "https://arxiv.org/pdf/2506.08426", "abs": "https://arxiv.org/abs/2506.08426", "authors": ["Zheng Lin", "Zhe Chen", "Xianhao Chen", "Wei Ni", "Yue Gao"], "title": "HASFL: Heterogeneity-aware Split Federated Learning over Edge Computing Systems", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": "16 pages, 11 figures. arXiv admin note: text overlap with\n  arXiv:2403.13101", "summary": "Split federated learning (SFL) has emerged as a promising paradigm to\ndemocratize machine learning (ML) on edge devices by enabling layer-wise model\npartitioning. However, existing SFL approaches suffer significantly from the\nstraggler effect due to the heterogeneous capabilities of edge devices. To\naddress the fundamental challenge, we propose adaptively controlling batch\nsizes (BSs) and model splitting (MS) for edge devices to overcome resource\nheterogeneity. We first derive a tight convergence bound of SFL that quantifies\nthe impact of varied BSs and MS on learning performance. Based on the\nconvergence bound, we propose HASFL, a heterogeneity-aware SFL framework\ncapable of adaptively controlling BS and MS to balance communication-computing\nlatency and training convergence in heterogeneous edge networks. Extensive\nexperiments with various datasets validate the effectiveness of HASFL and\ndemonstrate its superiority over state-of-the-art benchmarks.", "AI": {"tldr": "HASFL\u6846\u67b6\u901a\u8fc7\u81ea\u9002\u5e94\u63a7\u5236\u6279\u6b21\u5927\u5c0f\u548c\u6a21\u578b\u5206\u5272\uff0c\u89e3\u51b3\u4e86\u5f02\u6784\u8fb9\u7f18\u8bbe\u5907\u5728\u5206\u5272\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u6027\u80fd\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u5206\u5272\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u56e0\u8fb9\u7f18\u8bbe\u5907\u80fd\u529b\u5f02\u6784\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff0c\u4e9f\u9700\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faHASFL\u6846\u67b6\uff0c\u901a\u8fc7\u7406\u8bba\u63a8\u5bfc\u6536\u655b\u8fb9\u754c\uff0c\u81ea\u9002\u5e94\u8c03\u6574\u6279\u6b21\u5927\u5c0f\u548c\u6a21\u578b\u5206\u5272\u4ee5\u4f18\u5316\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1HASFL\u5728\u591a\u79cd\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "HASFL\u6709\u6548\u5e73\u8861\u4e86\u901a\u4fe1\u8ba1\u7b97\u5ef6\u8fdf\u4e0e\u8bad\u7ec3\u6536\u655b\uff0c\u9002\u7528\u4e8e\u5f02\u6784\u8fb9\u7f18\u7f51\u7edc\u3002"}}
{"id": "2506.08435", "pdf": "https://arxiv.org/pdf/2506.08435", "abs": "https://arxiv.org/abs/2506.08435", "authors": ["Mingyuan Fan", "Fuyi Wang", "Cen Chen", "Jianying Zhou"], "title": "Boosting Gradient Leakage Attacks: Data Reconstruction in Realistic FL Settings", "categories": ["cs.LG", "cs.CR", "cs.CV"], "comment": "Accepted to Usenix Security 2025", "summary": "Federated learning (FL) enables collaborative model training among multiple\nclients without the need to expose raw data. Its ability to safeguard privacy,\nat the heart of FL, has recently been a hot-button debate topic. To elaborate,\nseveral studies have introduced a type of attacks known as gradient leakage\nattacks (GLAs), which exploit the gradients shared during training to\nreconstruct clients' raw data. On the flip side, some literature, however,\ncontends no substantial privacy risk in practical FL environments due to the\neffectiveness of such GLAs being limited to overly relaxed conditions, such as\nsmall batch sizes and knowledge of clients' data distributions.\n  This paper bridges this critical gap by empirically demonstrating that\nclients' data can still be effectively reconstructed, even within realistic FL\nenvironments. Upon revisiting GLAs, we recognize that their performance\nfailures stem from their inability to handle the gradient matching problem. To\nalleviate the performance bottlenecks identified above, we develop FedLeak,\nwhich introduces two novel techniques, partial gradient matching and gradient\nregularization. Moreover, to evaluate the performance of FedLeak in real-world\nFL environments, we formulate a practical evaluation protocol grounded in a\nthorough review of extensive FL literature and industry practices. Under this\nprotocol, FedLeak can still achieve high-fidelity data reconstruction, thereby\nunderscoring the significant vulnerability in FL systems and the urgent need\nfor more effective defense methods.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u8bc1\u660e\uff0c\u5373\u4f7f\u5728\u73b0\u5b9e\u7684\u8054\u90a6\u5b66\u4e60\u73af\u5883\u4e2d\uff0c\u68af\u5ea6\u6cc4\u6f0f\u653b\u51fb\uff08GLAs\uff09\u4ecd\u80fd\u6709\u6548\u91cd\u6784\u5ba2\u6237\u7aef\u6570\u636e\uff0c\u5e76\u63d0\u51faFedLeak\u65b9\u6cd5\u89e3\u51b3\u6027\u80fd\u74f6\u9888\u3002", "motivation": "\u63a2\u8ba8\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u4e2d\u68af\u5ea6\u6cc4\u6f0f\u653b\u51fb\u7684\u5b9e\u9645\u98ce\u9669\uff0c\u586b\u8865\u73b0\u6709\u7814\u7a76\u4e2d\u5173\u4e8e\u653b\u51fb\u6709\u6548\u6027\u7684\u5173\u952e\u7a7a\u767d\u3002", "method": "\u63d0\u51faFedLeak\u65b9\u6cd5\uff0c\u5305\u542b\u90e8\u5206\u68af\u5ea6\u5339\u914d\u548c\u68af\u5ea6\u6b63\u5219\u5316\u4e24\u79cd\u65b0\u6280\u672f\uff0c\u5e76\u8bbe\u8ba1\u5b9e\u9645\u8bc4\u4f30\u534f\u8bae\u3002", "result": "FedLeak\u5728\u73b0\u5b9eFL\u73af\u5883\u4e2d\u4ecd\u80fd\u5b9e\u73b0\u9ad8\u4fdd\u771f\u6570\u636e\u91cd\u6784\uff0c\u63ed\u793aFL\u7cfb\u7edf\u7684\u91cd\u5927\u6f0f\u6d1e\u3002", "conclusion": "FL\u7cfb\u7edf\u5b58\u5728\u663e\u8457\u9690\u79c1\u98ce\u9669\uff0c\u4e9f\u9700\u66f4\u6709\u6548\u7684\u9632\u5fa1\u65b9\u6cd5\u3002"}}
{"id": "2506.08438", "pdf": "https://arxiv.org/pdf/2506.08438", "abs": "https://arxiv.org/abs/2506.08438", "authors": ["Yuchen Wu", "Xinyi Zhong", "Zhuoran Yang"], "title": "Learning to Lead: Incentivizing Strategic Agents in the Dark", "categories": ["cs.LG", "cs.GT", "stat.ML"], "comment": "81 pages, 7 figures", "summary": "We study an online learning version of the generalized principal-agent model,\nwhere a principal interacts repeatedly with a strategic agent possessing\nprivate types, private rewards, and taking unobservable actions. The agent is\nnon-myopic, optimizing a discounted sum of future rewards and may strategically\nmisreport types to manipulate the principal's learning. The principal,\nobserving only her own realized rewards and the agent's reported types, aims to\nlearn an optimal coordination mechanism that minimizes strategic regret. We\ndevelop the first provably sample-efficient algorithm for this challenging\nsetting. Our approach features a novel pipeline that combines (i) a delaying\nmechanism to incentivize approximately myopic agent behavior, (ii) an\ninnovative reward angle estimation framework that uses sector tests and a\nmatching procedure to recover type-dependent reward functions, and (iii) a\npessimistic-optimistic LinUCB algorithm that enables the principal to explore\nefficiently while respecting the agent's incentive constraints. We establish a\nnear optimal $\\tilde{O}(\\sqrt{T}) $ regret bound for learning the principal's\noptimal policy, where $\\tilde{O}(\\cdot) $ omits logarithmic factors. Our\nresults open up new avenues for designing robust online learning algorithms for\na wide range of game-theoretic settings involving private types and strategic\nagents.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.08441", "pdf": "https://arxiv.org/pdf/2506.08441", "abs": "https://arxiv.org/abs/2506.08441", "authors": ["Anh N. Nhu", "Sanghyun Son", "Ming Lin"], "title": "Time-Aware World Model for Adaptive Prediction and Control", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "comment": "Paper accepted to ICML 2025", "summary": "In this work, we introduce the Time-Aware World Model (TAWM), a model-based\napproach that explicitly incorporates temporal dynamics. By conditioning on the\ntime-step size, {\\Delta}t, and training over a diverse range of {\\Delta}t\nvalues -- rather than sampling at a fixed time-step -- TAWM learns both high-\nand low-frequency task dynamics across diverse control problems. Grounded in\nthe information-theoretic insight that the optimal sampling rate depends on a\nsystem's underlying dynamics, this time-aware formulation improves both\nperformance and data efficiency. Empirical evaluations show that TAWM\nconsistently outperforms conventional models across varying observation rates\nin a variety of control tasks, using the same number of training samples and\niterations. Our code can be found online at:\ngithub.com/anh-nn01/Time-Aware-World-Model.", "AI": {"tldr": "TAWM\u662f\u4e00\u79cd\u57fa\u4e8e\u65f6\u95f4\u611f\u77e5\u7684\u4e16\u754c\u6a21\u578b\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u65f6\u95f4\u6b65\u957f\u63d0\u5347\u4efb\u52a1\u52a8\u6001\u5b66\u4e60\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u6a21\u578b\u56fa\u5b9a\u65f6\u95f4\u6b65\u957f\u9650\u5236\u4e86\u52a8\u6001\u5b66\u4e60\u7684\u7075\u6d3b\u6027\uff0cTAWM\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "TAWM\u901a\u8fc7\u6761\u4ef6\u5316\u65f6\u95f4\u6b65\u957f\u0394\ud835\udc61\uff0c\u5e76\u5728\u591a\u6837\u5316\u7684\u0394\ud835\udc61\u503c\u4e0a\u8bad\u7ec3\uff0c\u5b66\u4e60\u9ad8\u4f4e\u9891\u4efb\u52a1\u52a8\u6001\u3002", "result": "TAWM\u5728\u591a\u79cd\u63a7\u5236\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u6a21\u578b\uff0c\u4e14\u6570\u636e\u6548\u7387\u66f4\u9ad8\u3002", "conclusion": "\u65f6\u95f4\u611f\u77e5\u7684\u5efa\u6a21\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u548c\u6570\u636e\u6548\u7387\u3002"}}
{"id": "2506.08460", "pdf": "https://arxiv.org/pdf/2506.08460", "abs": "https://arxiv.org/abs/2506.08460", "authors": ["Yihong Guo", "Yu Yang", "Pan Xu", "Anqi Liu"], "title": "MOBODY: Model Based Off-Dynamics Offline Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "We study the off-dynamics offline reinforcement learning problem, where the\ngoal is to learn a policy from offline datasets collected from source and\ntarget domains with mismatched transition. Existing off-dynamics offline RL\nmethods typically either filter source transitions that resemble those of the\ntarget domain or apply reward augmentation to source data, both constrained by\nthe limited transitions available from the target domain. As a result, the\nlearned policy is unable to explore target domain beyond the offline datasets.\nWe propose MOBODY, a Model-Based Off-Dynamics offline RL algorithm that\naddresses this limitation by enabling exploration of the target domain via\nlearned dynamics. MOBODY generates new synthetic transitions in the target\ndomain through model rollouts, which are used as data augmentation during\noffline policy learning. Unlike existing model-based methods that learn\ndynamics from a single domain, MOBODY tackles the challenge of mismatched\ndynamics by leveraging both source and target datasets. Directly merging these\ndatasets can bias the learned model toward source dynamics. Instead, MOBODY\nlearns target dynamics by discovering a shared latent representation of states\nand transitions across domains through representation learning. To stabilize\ntraining, MOBODY incorporates a behavior cloning loss that regularizes the\npolicy. Specifically, we introduce a Q-weighted behavior cloning loss that\nregularizes the policy toward actions with high target-domain Q-values, rather\nthan uniformly imitating all actions in the dataset. These Q-values are learned\nfrom an enhanced target dataset composed of offline target data, augmented\nsource data, and rollout data from the learned target dynamics. We evaluate\nMOBODY on MuJoCo benchmarks and show that it significantly outperforms\nstate-of-the-art baselines, with especially pronounced improvements in\nchallenging scenarios.", "AI": {"tldr": "MOBODY\u662f\u4e00\u79cd\u57fa\u4e8e\u6a21\u578b\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u751f\u6210\u76ee\u6807\u57df\u7684\u65b0\u5408\u6210\u6570\u636e\u6765\u89e3\u51b3\u6e90\u57df\u548c\u76ee\u6807\u57df\u52a8\u6001\u4e0d\u5339\u914d\u7684\u95ee\u9898\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u6e90\u57df\u548c\u76ee\u6807\u57df\u52a8\u6001\u4e0d\u5339\u914d\u65f6\u8868\u73b0\u53d7\u9650\uff0c\u65e0\u6cd5\u63a2\u7d22\u76ee\u6807\u57df\u8d85\u51fa\u79bb\u7ebf\u6570\u636e\u96c6\u7684\u8303\u56f4\u3002", "method": "MOBODY\u901a\u8fc7\u5b66\u4e60\u5171\u4eab\u6f5c\u5728\u8868\u793a\u751f\u6210\u76ee\u6807\u57df\u5408\u6210\u6570\u636e\uff0c\u5e76\u7ed3\u5408Q\u52a0\u6743\u884c\u4e3a\u514b\u9686\u635f\u5931\u7a33\u5b9a\u8bad\u7ec3\u3002", "result": "\u5728MuJoCo\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMOBODY\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u590d\u6742\u573a\u666f\u4e2d\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "MOBODY\u901a\u8fc7\u6a21\u578b\u751f\u6210\u548c\u6f5c\u5728\u8868\u793a\u5b66\u4e60\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u52a8\u6001\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7684\u6027\u80fd\u3002"}}
{"id": "2506.08463", "pdf": "https://arxiv.org/pdf/2506.08463", "abs": "https://arxiv.org/abs/2506.08463", "authors": ["Zhishuai Liu", "Yu Yang", "Ruhan Wang", "Pan Xu", "Dongruo Zhou"], "title": "How to Provably Improve Return Conditioned Supervised Learning?", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "25 pages, 4 figures, 12 tables", "summary": "In sequential decision-making problems, Return-Conditioned Supervised\nLearning (RCSL) has gained increasing recognition for its simplicity and\nstability in modern decision-making tasks. Unlike traditional offline\nreinforcement learning (RL) algorithms, RCSL frames policy learning as a\nsupervised learning problem by taking both the state and return as input. This\napproach eliminates the instability often associated with temporal difference\n(TD) learning in offline RL. However, RCSL has been criticized for lacking the\nstitching property, meaning its performance is inherently limited by the\nquality of the policy used to generate the offline dataset. To address this\nlimitation, we propose a principled and simple framework called Reinforced\nRCSL. The key innovation of our framework is the introduction of a concept we\ncall the in-distribution optimal return-to-go. This mechanism leverages our\npolicy to identify the best achievable in-dataset future return based on the\ncurrent state, avoiding the need for complex return augmentation techniques.\nOur theoretical analysis demonstrates that Reinforced RCSL can consistently\noutperform the standard RCSL approach. Empirical results further validate our\nclaims, showing significant performance improvements across a range of\nbenchmarks.", "AI": {"tldr": "Reinforced RCSL\u901a\u8fc7\u5f15\u5165in-distribution optimal return-to-go\u673a\u5236\uff0c\u89e3\u51b3\u4e86RCSL\u7f3a\u4e4fstitching\u80fd\u529b\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "RCSL\u867d\u7136\u7b80\u5355\u7a33\u5b9a\uff0c\u4f46\u53d7\u9650\u4e8e\u79bb\u7ebf\u6570\u636e\u96c6\u8d28\u91cf\uff0c\u7f3a\u4e4fstitching\u80fd\u529b\u3002", "method": "\u63d0\u51faReinforced RCSL\u6846\u67b6\uff0c\u5229\u7528in-distribution optimal return-to-go\u673a\u5236\u4f18\u5316\u7b56\u7565\u3002", "result": "\u7406\u8bba\u548c\u5b9e\u9a8c\u5747\u8868\u660e\uff0cReinforced RCSL\u4f18\u4e8e\u6807\u51c6RCSL\u3002", "conclusion": "Reinforced RCSL\u662f\u4e00\u79cd\u6709\u6548\u4e14\u7b80\u5355\u7684\u6539\u8fdb\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u987a\u5e8f\u51b3\u7b56\u95ee\u9898\u3002"}}
{"id": "2506.08464", "pdf": "https://arxiv.org/pdf/2506.08464", "abs": "https://arxiv.org/abs/2506.08464", "authors": ["Hyunseok Seung", "Jaewoo Lee", "Hyunsuk Ko"], "title": "MAC: An Efficient Gradient Preconditioning using Mean Activation Approximated Curvature", "categories": ["cs.LG"], "comment": null, "summary": "Second-order optimization methods for training neural networks, such as KFAC,\nexhibit superior convergence by utilizing curvature information of loss\nlandscape. However, it comes at the expense of high computational burden. In\nthis work, we analyze the two components that constitute the layer-wise Fisher\ninformation matrix (FIM) used in KFAC: the Kronecker factors related to\nactivations and pre-activation gradients. Based on empirical observations on\ntheir eigenspectra, we propose efficient approximations for them, resulting in\na computationally efficient optimization method called MAC. To the best of our\nknowledge, MAC is the first algorithm to apply the Kronecker factorization to\nthe FIM of attention layers used in transformers and explicitly integrate\nattention scores into the preconditioning. We also study the convergence\nproperty of MAC on nonlinear neural networks and provide two conditions under\nwhich it converges to global minima. Our extensive evaluations on various\nnetwork architectures and datasets show that the proposed method outperforms\nKFAC and other state-of-the-art methods in terms of accuracy, end-to-end\ntraining time, and memory usage. Code is available at\nhttps://github.com/hseung88/mac.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMAC\u7684\u9ad8\u6548\u4e8c\u9636\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fd1\u4f3cKronecker\u56e0\u5b50\u964d\u4f4e\u8ba1\u7b97\u8d1f\u62c5\uff0c\u4f18\u4e8eKFAC\u548c\u5176\u4ed6\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4e8c\u9636\u4f18\u5316\u65b9\u6cd5\uff08\u5982KFAC\uff09\u5229\u7528\u635f\u5931\u66f2\u9762\u7684\u66f2\u7387\u4fe1\u606f\u63d0\u5347\u6536\u655b\u6027\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\u3002", "method": "\u5206\u6790Kronecker\u56e0\u5b50\uff08\u6fc0\u6d3b\u548c\u9884\u6fc0\u6d3b\u68af\u5ea6\uff09\uff0c\u63d0\u51fa\u9ad8\u6548\u8fd1\u4f3c\u65b9\u6cd5\uff0c\u5e94\u7528\u4e8e\u6ce8\u610f\u529b\u5c42\u7684FIM\u3002", "result": "MAC\u5728\u51c6\u786e\u6027\u3001\u8bad\u7ec3\u65f6\u95f4\u548c\u5185\u5b58\u4f7f\u7528\u4e0a\u4f18\u4e8eKFAC\u548c\u5176\u4ed6\u65b9\u6cd5\u3002", "conclusion": "MAC\u662f\u9996\u4e2a\u5c06Kronecker\u5206\u89e3\u5e94\u7528\u4e8eTransformer\u6ce8\u610f\u529b\u5c42\u7684\u65b9\u6cd5\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2506.08473", "pdf": "https://arxiv.org/pdf/2506.08473", "abs": "https://arxiv.org/abs/2506.08473", "authors": ["Shuo Yang", "Qihui Zhang", "Yuyang Liu", "Yue Huang", "Xiaojun Jia", "Kunpeng Ning", "Jiayu Yao", "Jigang Wang", "Hailiang Dai", "Yibing Song", "Li Yuan"], "title": "AsFT: Anchoring Safety During LLM Fine-Tuning Within Narrow Safety Basin", "categories": ["cs.LG"], "comment": null, "summary": "Large language models (LLMs) are vulnerable to safety risks during\nfine-tuning, where small amounts of malicious or harmless data can compromise\nsafeguards. In this paper, building on the concept of alignment direction --\ndefined by the weight difference between aligned and unaligned models -- we\nobserve that perturbations along this direction preserve model safety. In\ncontrast, perturbations along directions orthogonal to this alignment are\nstrongly linked to harmful direction perturbations, rapidly degrading safety\nand framing the parameter space as a narrow safety basin. Based on this\ninsight, we propose a methodology for safety fine-tuning called AsFT (Anchoring\nSafety in Fine-Tuning), which integrates a regularization term into the\ntraining objective. This term uses the alignment direction as an anchor to\nsuppress updates in harmful directions, ensuring that fine-tuning is\nconstrained within the narrow safety basin. Extensive experiments on multiple\ndatasets show that AsFT outperforms Safe LoRA, reducing harmful behavior by\n7.60 percent, improving model performance by 3.44 percent, and maintaining\nrobust performance across various experimental settings. Code is available at\nhttps://github.com/PKU-YuanGroup/AsFT", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAsFT\u7684\u5b89\u5168\u5fae\u8c03\u65b9\u6cd5\uff0c\u901a\u8fc7\u6b63\u5219\u5316\u9879\u6291\u5236\u6709\u5bb3\u65b9\u5411\u7684\u66f4\u65b0\uff0c\u663e\u8457\u51cf\u5c11\u6709\u5bb3\u884c\u4e3a\u5e76\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u5bb9\u6613\u53d7\u5230\u5b89\u5168\u98ce\u9669\u7684\u5f71\u54cd\uff0c\u5c11\u91cf\u6076\u610f\u6216\u65e0\u5bb3\u6570\u636e\u53ef\u80fd\u7834\u574f\u6a21\u578b\u7684\u5b89\u5168\u6027\u3002", "method": "\u57fa\u4e8e\u5bf9\u9f50\u65b9\u5411\u7684\u6982\u5ff5\uff0c\u63d0\u51faAsFT\u65b9\u6cd5\uff0c\u901a\u8fc7\u6b63\u5219\u5316\u9879\u7ea6\u675f\u5fae\u8c03\u8fc7\u7a0b\uff0c\u786e\u4fdd\u5176\u5728\u5b89\u5168\u8303\u56f4\u5185\u8fdb\u884c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cAsFT\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u4f18\u4e8eSafe LoRA\uff0c\u51cf\u5c11\u6709\u5bb3\u884c\u4e3a7.60%\uff0c\u63d0\u5347\u6027\u80fd3.44%\u3002", "conclusion": "AsFT\u901a\u8fc7\u951a\u5b9a\u5bf9\u9f50\u65b9\u5411\uff0c\u6709\u6548\u7ea6\u675f\u5fae\u8c03\u8fc7\u7a0b\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u7684\u5b89\u5168\u6027\u548c\u6027\u80fd\u3002"}}
{"id": "2506.08475", "pdf": "https://arxiv.org/pdf/2506.08475", "abs": "https://arxiv.org/abs/2506.08475", "authors": ["Xiaolong He", "Yeonjong Shin", "Anthony Gruber", "Sohyeon Jung", "Kookjin Lee", "Youngsoo Choi"], "title": "Thermodynamically Consistent Latent Dynamics Identification for Parametric Systems", "categories": ["cs.LG", "cs.CE", "cs.NA", "math.NA"], "comment": null, "summary": "We propose an efficient thermodynamics-informed latent space dynamics\nidentification (tLaSDI) framework for the reduced-order modeling of parametric\nnonlinear dynamical systems. This framework integrates autoencoders for\ndimensionality reduction with newly developed parametric GENERIC\nformalism-informed neural networks (pGFINNs), which enable efficient learning\nof parametric latent dynamics while preserving key thermodynamic principles\nsuch as free energy conservation and entropy generation across the parameter\nspace. To further enhance model performance, a physics-informed active learning\nstrategy is incorporated, leveraging a greedy, residual-based error indicator\nto adaptively sample informative training data, outperforming uniform sampling\nat equivalent computational cost. Numerical experiments on the Burgers'\nequation and the 1D/1V Vlasov-Poisson equation demonstrate that the proposed\nmethod achieves up to 3,528x speed-up with 1-3% relative errors, and\nsignificant reduction in training (50-90%) and inference (57-61%) cost.\nMoreover, the learned latent space dynamics reveal the underlying thermodynamic\nbehavior of the system, offering valuable insights into the physical-space\ndynamics.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u70ed\u529b\u5b66\u539f\u7406\u7684\u6f5c\u5728\u7a7a\u95f4\u52a8\u529b\u5b66\u8bc6\u522b\u6846\u67b6\uff08tLaSDI\uff09\uff0c\u7528\u4e8e\u53c2\u6570\u975e\u7ebf\u6027\u52a8\u529b\u7cfb\u7edf\u7684\u964d\u9636\u5efa\u6a21\uff0c\u7ed3\u5408\u81ea\u7f16\u7801\u5668\u548c\u53c2\u6570\u5316GENERIC\u795e\u7ecf\u7f51\u7edc\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u5b66\u4e60\u548c\u7269\u7406\u4e00\u81f4\u6027\u3002", "motivation": "\u89e3\u51b3\u53c2\u6570\u975e\u7ebf\u6027\u52a8\u529b\u7cfb\u7edf\u7684\u9ad8\u6548\u5efa\u6a21\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u70ed\u529b\u5b66\u539f\u7406\uff08\u5982\u81ea\u7531\u80fd\u5b88\u6052\u548c\u71b5\u751f\u6210\uff09\u3002", "method": "\u7ed3\u5408\u81ea\u7f16\u7801\u5668\u964d\u7ef4\u548c\u53c2\u6570\u5316GENERIC\u795e\u7ecf\u7f51\u7edc\uff08pGFINNs\uff09\uff0c\u5e76\u91c7\u7528\u57fa\u4e8e\u6b8b\u5dee\u7684\u4e3b\u52a8\u5b66\u4e60\u7b56\u7565\u4f18\u5316\u8bad\u7ec3\u6570\u636e\u91c7\u6837\u3002", "result": "\u5728Burgers\u65b9\u7a0b\u548c1D/1V Vlasov-Poisson\u65b9\u7a0b\u4e0a\u5b9e\u73b0\u4e86\u6700\u9ad83,528\u500d\u52a0\u901f\uff0c\u76f8\u5bf9\u8bef\u5dee1-3%\uff0c\u8bad\u7ec3\u548c\u63a8\u7406\u6210\u672c\u663e\u8457\u964d\u4f4e\u3002", "conclusion": "tLaSDI\u6846\u67b6\u4e0d\u4ec5\u9ad8\u6548\u4e14\u7269\u7406\u4e00\u81f4\uff0c\u8fd8\u80fd\u63ed\u793a\u7cfb\u7edf\u7684\u70ed\u529b\u5b66\u884c\u4e3a\uff0c\u4e3a\u7269\u7406\u7a7a\u95f4\u52a8\u529b\u5b66\u63d0\u4f9b\u65b0\u89c1\u89e3\u3002"}}
{"id": "2506.08505", "pdf": "https://arxiv.org/pdf/2506.08505", "abs": "https://arxiv.org/abs/2506.08505", "authors": ["Shahaf Bassan", "Yizhak Yisrael Elboher", "Tobias Ladner", "Matthias Althoff", "Guy Katz"], "title": "Explaining, Fast and Slow: Abstraction and Refinement of Provable Explanations", "categories": ["cs.LG", "cs.AI", "cs.LO"], "comment": "To appear in ICML 2025", "summary": "Despite significant advancements in post-hoc explainability techniques for\nneural networks, many current methods rely on heuristics and do not provide\nformally provable guarantees over the explanations provided. Recent work has\nshown that it is possible to obtain explanations with formal guarantees by\nidentifying subsets of input features that are sufficient to determine that\npredictions remain unchanged using neural network verification techniques.\nDespite the appeal of these explanations, their computation faces significant\nscalability challenges. In this work, we address this gap by proposing a novel\nabstraction-refinement technique for efficiently computing provably sufficient\nexplanations of neural network predictions. Our method abstracts the original\nlarge neural network by constructing a substantially reduced network, where a\nsufficient explanation of the reduced network is also provably sufficient for\nthe original network, hence significantly speeding up the verification process.\nIf the explanation is in sufficient on the reduced network, we iteratively\nrefine the network size by gradually increasing it until convergence. Our\nexperiments demonstrate that our approach enhances the efficiency of obtaining\nprovably sufficient explanations for neural network predictions while\nadditionally providing a fine-grained interpretation of the network's\npredictions across different abstraction levels.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u62bd\u8c61-\u7cbe\u5316\u6280\u672f\uff0c\u7528\u4e8e\u9ad8\u6548\u8ba1\u7b97\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u7684\u53ef\u8bc1\u660e\u5145\u5206\u89e3\u91ca\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u53ef\u6269\u5c55\u6027\u4e0a\u7684\u6311\u6218\u3002", "motivation": "\u5c3d\u7ba1\u4e8b\u540e\u89e3\u91ca\u6280\u672f\u6709\u6240\u8fdb\u5c55\uff0c\u4f46\u8bb8\u591a\u65b9\u6cd5\u4f9d\u8d56\u542f\u53d1\u5f0f\u4e14\u7f3a\u4e4f\u5f62\u5f0f\u5316\u4fdd\u8bc1\u3002\u73b0\u6709\u53ef\u8bc1\u660e\u89e3\u91ca\u65b9\u6cd5\u8ba1\u7b97\u6548\u7387\u4f4e\uff0c\u96be\u4ee5\u6269\u5c55\u3002", "method": "\u901a\u8fc7\u6784\u5efa\u4e00\u4e2a\u663e\u8457\u7b80\u5316\u7684\u7f51\u7edc\u62bd\u8c61\u539f\u59cb\u5927\u7f51\u7edc\uff0c\u5728\u7b80\u5316\u7f51\u7edc\u4e0a\u8ba1\u7b97\u5145\u5206\u89e3\u91ca\uff0c\u82e5\u4e0d\u8db3\u5219\u9010\u6b65\u7cbe\u5316\u7f51\u7edc\u76f4\u81f3\u6536\u655b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u83b7\u53d6\u53ef\u8bc1\u660e\u5145\u5206\u89e3\u91ca\u7684\u6548\u7387\uff0c\u5e76\u63d0\u4f9b\u4e86\u7f51\u7edc\u9884\u6d4b\u5728\u4e0d\u540c\u62bd\u8c61\u5c42\u6b21\u4e0a\u7684\u7ec6\u7c92\u5ea6\u89e3\u91ca\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u53ef\u8bc1\u660e\u7684\u89e3\u91ca\u6846\u67b6\uff0c\u540c\u65f6\u652f\u6301\u591a\u5c42\u6b21\u7684\u89e3\u91ca\u5206\u6790\u3002"}}
{"id": "2506.08514", "pdf": "https://arxiv.org/pdf/2506.08514", "abs": "https://arxiv.org/abs/2506.08514", "authors": ["Jacob Piland", "Chris Sweet", "Adam Czakja"], "title": "DiffGradCAM: A Universal Class Activation Map Resistant to Adversarial Training", "categories": ["cs.LG"], "comment": null, "summary": "Class Activation Mapping (CAM) and its gradient-based variants (e.g.,\nGradCAM) have become standard tools for explaining Convolutional Neural Network\n(CNN) predictions. However, these approaches typically focus on individual\nlogits, while for neural networks using softmax, the class membership\nprobability estimates depend \\textit{only} on the \\textit{differences} between\nlogits, not on their absolute values. This disconnect leaves standard CAMs\nvulnerable to adversarial manipulation, such as passive fooling, where a model\nis trained to produce misleading CAMs without affecting decision performance.\nWe introduce \\textbf{Salience-Hoax Activation Maps (SHAMs)}, an\n\\emph{entropy-aware form of passive fooling} that serves as a benchmark for CAM\nrobustness under adversarial conditions. To address the passive fooling\nvulnerability, we then propose \\textbf{DiffGradCAM}, a novel, lightweight, and\ncontrastive approach to class activation mapping that is both non-suceptible to\npassive fooling, but also matches the output of standard CAM methods such as\nGradCAM in the non-adversarial case. Together, SHAM and DiffGradCAM establish a\nnew framework for probing and improving the robustness of saliency-based\nexplanations. We validate both contributions across multi-class tasks with few\nand many classes.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86SHAM\u548cDiffGradCAM\uff0c\u7528\u4e8e\u8bc4\u4f30\u548c\u6539\u8fdbCAM\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\uff0c\u89e3\u51b3\u4e86CAM\u5728\u5bf9\u6297\u6761\u4ef6\u4e0b\u7684\u8106\u5f31\u6027\u95ee\u9898\u3002", "motivation": "CAM\u53ca\u5176\u53d8\u4f53\uff08\u5982GradCAM\uff09\u5728\u89e3\u91caCNN\u9884\u6d4b\u65f6\u5b58\u5728\u5bf9\u5355\u4e2alogits\u7684\u4f9d\u8d56\uff0c\u800csoftmax\u8f93\u51fa\u7684\u6982\u7387\u4ec5\u4f9d\u8d56\u4e8elogits\u7684\u5dee\u5f02\u3002\u8fd9\u79cd\u4e0d\u4e00\u81f4\u6027\u4f7fCAM\u5bb9\u6613\u53d7\u5230\u88ab\u52a8\u6b3a\u9a97\u653b\u51fb\u3002", "method": "\u63d0\u51fa\u4e86SHAM\u4f5c\u4e3a\u5bf9\u6297\u6761\u4ef6\u4e0b\u7684\u57fa\u51c6\u6d4b\u8bd5\u5de5\u5177\uff0c\u5e76\u5f00\u53d1\u4e86DiffGradCAM\uff0c\u4e00\u79cd\u8f7b\u91cf\u7ea7\u4e14\u5bf9\u6bd4\u6027\u7684CAM\u65b9\u6cd5\uff0c\u80fd\u591f\u62b5\u6297\u88ab\u52a8\u6b3a\u9a97\u3002", "result": "SHAM\u548cDiffGradCAM\u5728\u591a\u5206\u7c7b\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\uff0cDiffGradCAM\u5728\u975e\u5bf9\u6297\u60c5\u51b5\u4e0b\u4e0e\u6807\u51c6CAM\u65b9\u6cd5\u8868\u73b0\u4e00\u81f4\u3002", "conclusion": "SHAM\u548cDiffGradCAM\u4e3a\u57fa\u4e8e\u663e\u8457\u6027\u7684\u89e3\u91ca\u65b9\u6cd5\u63d0\u4f9b\u4e86\u65b0\u7684\u9c81\u68d2\u6027\u8bc4\u4f30\u548c\u6539\u8fdb\u6846\u67b6\u3002"}}
{"id": "2506.08516", "pdf": "https://arxiv.org/pdf/2506.08516", "abs": "https://arxiv.org/abs/2506.08516", "authors": ["Mouadh Yagoubi", "David Danan", "Milad Leyli-Abadi", "Ahmed Mazari", "Jean-Patrick Brunet", "Abbas Kabalan", "Fabien Casenave", "Yuxin Ma", "Giovanni Catalani", "Jean Fesquet", "Jacob Helwig", "Xuan Zhang", "Haiyang Yu", "Xavier Bertrand", "Frederic Tost", "Michael Baurheim", "Joseph Morlier", "Shuiwang Ji"], "title": "NeurIPS 2024 ML4CFD Competition: Results and Retrospective Analysis", "categories": ["cs.LG"], "comment": null, "summary": "The integration of machine learning (ML) into the physical sciences is\nreshaping computational paradigms, offering the potential to accelerate\ndemanding simulations such as computational fluid dynamics (CFD). Yet,\npersistent challenges in accuracy, generalization, and physical consistency\nhinder the practical deployment of ML models in scientific domains. To address\nthese limitations and systematically benchmark progress, we organized the\nML4CFD competition, centered on surrogate modeling for aerodynamic simulations\nover two-dimensional airfoils. The competition attracted over 240 teams, who\nwere provided with a curated dataset generated via OpenFOAM and evaluated\nthrough a multi-criteria framework encompassing predictive accuracy, physical\nfidelity, computational efficiency, and out-of-distribution generalization.\nThis retrospective analysis reviews the competition outcomes, highlighting\nseveral approaches that outperformed baselines under our global evaluation\nscore. Notably, the top entry exceeded the performance of the original OpenFOAM\nsolver on aggregate metrics, illustrating the promise of ML-based surrogates to\noutperform traditional solvers under tailored criteria. Drawing from these\nresults, we analyze the key design principles of top submissions, assess the\nrobustness of our evaluation framework, and offer guidance for future\nscientific ML challenges.", "AI": {"tldr": "ML4CFD\u7ade\u8d5b\u901a\u8fc7\u8bc4\u4f30\u673a\u5668\u5b66\u4e60\u5728CFD\u4e2d\u7684\u8868\u73b0\uff0c\u5c55\u793a\u4e86ML\u6a21\u578b\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u8d85\u8d8a\u4f20\u7edf\u6c42\u89e3\u5668\u7684\u6f5c\u529b\u3002", "motivation": "\u89e3\u51b3\u673a\u5668\u5b66\u4e60\u5728\u7269\u7406\u79d1\u5b66\u4e2d\u5e94\u7528\u7684\u51c6\u786e\u6027\u3001\u6cdb\u5316\u6027\u548c\u7269\u7406\u4e00\u81f4\u6027\u6311\u6218\u3002", "method": "\u7ec4\u7ec7ML4CFD\u7ade\u8d5b\uff0c\u63d0\u4f9bOpenFOAM\u751f\u6210\u7684\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u9884\u6d4b\u51c6\u786e\u6027\u3001\u7269\u7406\u4fdd\u771f\u5ea6\u7b49\u591a\u9879\u6807\u51c6\u3002", "result": "\u9876\u7ea7\u53c2\u8d5b\u4f5c\u54c1\u5728\u7efc\u5408\u6307\u6807\u4e0a\u8d85\u8d8aOpenFOAM\u6c42\u89e3\u5668\u3002", "conclusion": "ML\u6a21\u578b\u5728\u79d1\u5b66\u8ba1\u7b97\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u672a\u6765\u9700\u4f18\u5316\u8bc4\u4f30\u6846\u67b6\u548c\u8bbe\u8ba1\u539f\u5219\u3002"}}
{"id": "2506.08523", "pdf": "https://arxiv.org/pdf/2506.08523", "abs": "https://arxiv.org/abs/2506.08523", "authors": ["Pedro Jim\u00e9nez-Gonz\u00e1lez", "Miguel C. Soriano", "Lucas Lacasa"], "title": "Leveraging chaos in the training of artificial neural networks", "categories": ["cs.LG", "cond-mat.dis-nn", "nlin.CD", "physics.data-an"], "comment": null, "summary": "Traditional algorithms to optimize artificial neural networks when confronted\nwith a supervised learning task are usually exploitation-type relaxational\ndynamics such as gradient descent (GD). Here, we explore the dynamics of the\nneural network trajectory along training for unconventionally large learning\nrates. We show that for a region of values of the learning rate, the GD\noptimization shifts away from purely exploitation-like algorithm into a regime\nof exploration-exploitation balance, as the neural network is still capable of\nlearning but the trajectory shows sensitive dependence on initial conditions --\nas characterized by positive network maximum Lyapunov exponent --.\nInterestingly, the characteristic training time required to reach an acceptable\naccuracy in the test set reaches a minimum precisely in such learning rate\nregion, further suggesting that one can accelerate the training of artificial\nneural networks by locating at the onset of chaos. Our results -- initially\nillustrated for the MNIST classification task -- qualitatively hold for a range\nof supervised learning tasks, learning architectures and other hyperparameters,\nand showcase the emergent, constructive role of transient chaotic dynamics in\nthe training of artificial neural networks.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5728\u5f02\u5e38\u5927\u5b66\u4e60\u7387\u4e0b\u68af\u5ea6\u4e0b\u964d\uff08GD\uff09\u4f18\u5316\u795e\u7ecf\u7f51\u7edc\u7684\u52a8\u6001\u884c\u4e3a\uff0c\u53d1\u73b0\u5b66\u4e60\u7387\u5728\u7279\u5b9a\u8303\u56f4\u5185\u65f6\uff0cGD\u4f1a\u4ece\u7eaf\u5229\u7528\u578b\u8f6c\u53d8\u4e3a\u63a2\u7d22-\u5229\u7528\u5e73\u8861\u578b\uff0c\u4e14\u8bad\u7ec3\u65f6\u95f4\u6700\u77ed\u3002", "motivation": "\u63a2\u7d22\u795e\u7ecf\u7f51\u7edc\u5728\u975e\u4f20\u7edf\u5927\u5b66\u4e60\u7387\u4e0b\u7684\u8bad\u7ec3\u52a8\u6001\uff0c\u63ed\u793a\u6df7\u6c8c\u52a8\u529b\u5b66\u5728\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\u7684\u79ef\u6781\u4f5c\u7528\u3002", "method": "\u901a\u8fc7\u5206\u6790\u795e\u7ecf\u7f51\u7edc\u8f68\u8ff9\u7684\u6700\u5927Lyapunov\u6307\u6570\uff0c\u7814\u7a76GD\u5728\u4e0d\u540c\u5b66\u4e60\u7387\u4e0b\u7684\u884c\u4e3a\uff0c\u5e76\u5728MNIST\u5206\u7c7b\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u3002", "result": "\u5728\u5b66\u4e60\u7387\u7279\u5b9a\u8303\u56f4\u5185\uff0cGD\u8868\u73b0\u51fa\u63a2\u7d22-\u5229\u7528\u5e73\u8861\uff0c\u8bad\u7ec3\u65f6\u95f4\u6700\u77ed\uff0c\u4e14\u7ed3\u679c\u9002\u7528\u4e8e\u591a\u79cd\u5b66\u4e60\u4efb\u52a1\u548c\u67b6\u6784\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u6df7\u6c8c\u52a8\u529b\u5b66\u5728\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\u5177\u6709\u5efa\u8bbe\u6027\u4f5c\u7528\uff0c\u53ef\u901a\u8fc7\u8c03\u6574\u5b66\u4e60\u7387\u4f18\u5316\u8bad\u7ec3\u6548\u7387\u3002"}}
{"id": "2506.08533", "pdf": "https://arxiv.org/pdf/2506.08533", "abs": "https://arxiv.org/abs/2506.08533", "authors": ["Nihal Acharya Adde", "Alexandra Gianzina", "Hanno Gottschalk", "Andreas Ebert"], "title": "Robust Evolutionary Multi-Objective Network Architecture Search for Reinforcement Learning (EMNAS-RL)", "categories": ["cs.LG", "cs.AI", "math.OC"], "comment": "Published at ESANN 2025 Conference", "summary": "This paper introduces Evolutionary Multi-Objective Network Architecture\nSearch (EMNAS) for the first time to optimize neural network architectures in\nlarge-scale Reinforcement Learning (RL) for Autonomous Driving (AD). EMNAS uses\ngenetic algorithms to automate network design, tailored to enhance rewards and\nreduce model size without compromising performance. Additionally,\nparallelization techniques are employed to accelerate the search, and\nteacher-student methodologies are implemented to ensure scalable optimization.\nThis research underscores the potential of transfer learning as a robust\nframework for optimizing performance across iterative learning processes by\neffectively leveraging knowledge from earlier generations to enhance learning\nefficiency and stability in subsequent generations. Experimental results\ndemonstrate that tailored EMNAS outperforms manually designed models, achieving\nhigher rewards with fewer parameters. The findings of these strategies\ncontribute positively to EMNAS for RL in autonomous driving, advancing the\nfield toward better-performing networks suitable for real-world scenarios.", "AI": {"tldr": "EMNAS\u9996\u6b21\u63d0\u51fa\u7528\u4e8e\u5927\u89c4\u6a21\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u4f18\u5316\uff0c\u901a\u8fc7\u9057\u4f20\u7b97\u6cd5\u81ea\u52a8\u8bbe\u8ba1\u7f51\u7edc\uff0c\u63d0\u5347\u5956\u52b1\u5e76\u51cf\u5c11\u6a21\u578b\u5927\u5c0f\uff0c\u540c\u65f6\u91c7\u7528\u5e76\u884c\u5316\u548c\u5e08\u751f\u65b9\u6cd5\u52a0\u901f\u641c\u7d22\u4e0e\u4f18\u5316\u3002\u5b9e\u9a8c\u8868\u660e\u5176\u4f18\u4e8e\u4eba\u5de5\u8bbe\u8ba1\u6a21\u578b\u3002", "motivation": "\u4f18\u5316\u81ea\u52a8\u9a7e\u9a76\u4e2d\u7684\u5f3a\u5316\u5b66\u4e60\u7f51\u7edc\u67b6\u6784\uff0c\u63d0\u5347\u6027\u80fd\u5e76\u51cf\u5c11\u6a21\u578b\u590d\u6742\u5ea6\uff0c\u540c\u65f6\u63a2\u7d22\u8fc1\u79fb\u5b66\u4e60\u5728\u8fed\u4ee3\u5b66\u4e60\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u4f7f\u7528\u9057\u4f20\u7b97\u6cd5\u81ea\u52a8\u5316\u7f51\u7edc\u8bbe\u8ba1\uff0c\u7ed3\u5408\u5e76\u884c\u5316\u6280\u672f\u548c\u5e08\u751f\u65b9\u6cd5\u52a0\u901f\u641c\u7d22\u4e0e\u4f18\u5316\u3002", "result": "EMNAS\u5728\u5956\u52b1\u548c\u53c2\u6570\u6548\u7387\u4e0a\u4f18\u4e8e\u4eba\u5de5\u8bbe\u8ba1\u6a21\u578b\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u81ea\u52a8\u9a7e\u9a76\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "EMNAS\u4e3a\u81ea\u52a8\u9a7e\u9a76\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u9ad8\u6548\u7f51\u7edc\u8bbe\u8ba1\u6846\u67b6\uff0c\u63a8\u52a8\u9886\u57df\u5411\u66f4\u4f18\u6027\u80fd\u53d1\u5c55\u3002"}}
{"id": "2506.08551", "pdf": "https://arxiv.org/pdf/2506.08551", "abs": "https://arxiv.org/abs/2506.08551", "authors": ["Panlong Wu", "Ting Wang", "Yifei Zhong", "Haoqi Zhang", "Zitong Wang", "Fangxin Wang"], "title": "DeepForm: Reasoning Large Language Model for Communication System Formulation", "categories": ["cs.LG"], "comment": null, "summary": "Communication system formulation is critical for advancing 6G and future\nwireless technologies, yet it remains a complex, expertise-intensive task.\nWhile Large Language Models (LLMs) offer potential, existing general-purpose\nmodels often lack the specialized domain knowledge, nuanced reasoning\ncapabilities, and access to high-quality, domain-specific training data\nrequired for adapting a general LLM into an LLM specially for communication\nsystem formulation. To bridge this gap, we introduce DeepForm, the first\nreasoning LLM specially for automated communication system formulation. We\npropose the world-first large-scale, open-source dataset meticulously curated\nfor this domain called Communication System Formulation Reasoning Corpus\n(CSFRC). Our framework employs a two-stage training strategy: first, Supervised\nFine-Tuning (SFT) with Chain-of-Thought (CoT) data to distill domain knowledge;\nsecond, a novel rule-based Reinforcement Learning (RL) algorithm, C-ReMax based\non ReMax, to cultivate advanced modeling capabilities and elicit sophisticated\nreasoning patterns like self-correction and verification. Extensive experiments\ndemonstrate that our model achieves state-of-the-art performance, significantly\noutperforming larger proprietary LLMs on diverse senerios. We will release\nrelated resources to foster further research in this area after the paper is\naccepted.", "AI": {"tldr": "DeepForm\u662f\u4e00\u4e2a\u4e13\u4e3a\u901a\u4fe1\u7cfb\u7edf\u8bbe\u8ba1\u4f18\u5316\u7684\u63a8\u7406\u578b\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u548c\u9ad8\u8d28\u91cf\u6570\u636e\u96c6CSFRC\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u901a\u7528\u6a21\u578b\u3002", "motivation": "\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5728\u901a\u4fe1\u7cfb\u7edf\u8bbe\u8ba1\u9886\u57df\u7f3a\u4e4f\u4e13\u4e1a\u77e5\u8bc6\u548c\u9ad8\u8d28\u91cf\u6570\u636e\uff0cDeepForm\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\uff1a\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u7ed3\u5408\u94fe\u5f0f\u601d\u7ef4\uff08CoT\uff09\u6570\u636e\uff0c\u4ee5\u53ca\u57fa\u4e8eReMax\u7684\u89c4\u5219\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5C-ReMax\u3002", "result": "\u5b9e\u9a8c\u8868\u660eDeepForm\u5728\u591a\u6837\u5316\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u8d85\u8d8a\u73b0\u6709\u5927\u578b\u4e13\u6709\u6a21\u578b\u3002", "conclusion": "DeepForm\u4e3a\u901a\u4fe1\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u76f8\u5173\u8d44\u6e90\u5c06\u5f00\u6e90\u4ee5\u63a8\u52a8\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2506.08572", "pdf": "https://arxiv.org/pdf/2506.08572", "abs": "https://arxiv.org/abs/2506.08572", "authors": ["Waiss Azizian", "Michael Kirchhof", "Eugene Ndiaye", "Louis Bethune", "Michal Klein", "Pierre Ablin", "Marco Cuturi"], "title": "The Geometries of Truth Are Orthogonal Across Tasks", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated impressive generalization\ncapabilities across various tasks, but their claim to practical relevance is\nstill mired by concerns on their reliability. Recent works have proposed\nexamining the activations produced by an LLM at inference time to assess\nwhether its answer to a question is correct. Some works claim that a \"geometry\nof truth\" can be learned from examples, in the sense that the activations that\ngenerate correct answers can be distinguished from those leading to mistakes\nwith a linear classifier. In this work, we underline a limitation of these\napproaches: we observe that these \"geometries of truth\" are intrinsically\ntask-dependent and fail to transfer across tasks. More precisely, we show that\nlinear classifiers trained across distinct tasks share little similarity and,\nwhen trained with sparsity-enforcing regularizers, have almost disjoint\nsupports. We show that more sophisticated approaches (e.g., using mixtures of\nprobes and tasks) fail to overcome this limitation, likely because activation\nvectors commonly used to classify answers form clearly separated clusters when\nexamined across tasks.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u5c3d\u7ba1LLMs\u7684\u6fc0\u6d3b\u6a21\u5f0f\u53ef\u7528\u4e8e\u533a\u5206\u7b54\u6848\u6b63\u786e\u6027\uff0c\u4f46\u8fd9\u79cd\u201c\u771f\u7406\u51e0\u4f55\u201d\u5177\u6709\u4efb\u52a1\u4f9d\u8d56\u6027\uff0c\u65e0\u6cd5\u8de8\u4efb\u52a1\u8fc1\u79fb\u3002", "motivation": "\u63a2\u8ba8LLMs\u6fc0\u6d3b\u6a21\u5f0f\u5728\u8bc4\u4f30\u7b54\u6848\u6b63\u786e\u6027\u65f6\u7684\u5c40\u9650\u6027\uff0c\u5c24\u5176\u662f\u8de8\u4efb\u52a1\u7684\u53ef\u8fc1\u79fb\u6027\u3002", "method": "\u901a\u8fc7\u7ebf\u6027\u5206\u7c7b\u5668\u5206\u6790\u4e0d\u540c\u4efb\u52a1\u4e2dLLMs\u7684\u6fc0\u6d3b\u6a21\u5f0f\uff0c\u5e76\u5c1d\u8bd5\u4f7f\u7528\u7a00\u758f\u6b63\u5219\u5316\u548c\u590d\u6742\u65b9\u6cd5\uff08\u5982\u6df7\u5408\u63a2\u9488\uff09\u6539\u8fdb\u3002", "result": "\u53d1\u73b0\u4e0d\u540c\u4efb\u52a1\u7684\u7ebf\u6027\u5206\u7c7b\u5668\u76f8\u4f3c\u6027\u4f4e\uff0c\u6fc0\u6d3b\u5411\u91cf\u5728\u8de8\u4efb\u52a1\u65f6\u5f62\u6210\u660e\u663e\u5206\u79bb\u7684\u7c07\u3002", "conclusion": "LLMs\u7684\u201c\u771f\u7406\u51e0\u4f55\u201d\u5177\u6709\u4efb\u52a1\u4f9d\u8d56\u6027\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5b9e\u73b0\u8de8\u4efb\u52a1\u8fc1\u79fb\u3002"}}
{"id": "2506.08574", "pdf": "https://arxiv.org/pdf/2506.08574", "abs": "https://arxiv.org/abs/2506.08574", "authors": ["Alvise Dei Rossi", "Matteo Metaldi", "Michal Bechny", "Irina Filchenko", "Julia van der Meer", "Markus H. Schmidt", "Claudio L. A. Bassetti", "Athina Tzovara", "Francesca D. Faraci", "Luigi Fiorillo"], "title": "SLEEPYLAND: trust begins with fair evaluation of automatic sleep staging models", "categories": ["cs.LG"], "comment": "41 pages, 4 Figures, 7 Tables", "summary": "Despite advances in deep learning for automatic sleep staging, clinical\nadoption remains limited due to challenges in fair model evaluation,\ngeneralization across diverse datasets, model bias, and variability in human\nannotations. We present SLEEPYLAND, an open-source sleep staging evaluation\nframework designed to address these barriers. It includes more than 22'0000\nhours in-domain (ID) sleep recordings, and more than 84'000 hours out-of-domain\n(OOD) sleep recordings, spanning a broad range of ages, sleep-wake disorders,\nand hardware setups. We release pre-trained models based on high-performing SoA\narchitectures and evaluate them under standardized conditions across single-\nand multi-channel EEG/EOG configurations. We introduce SOMNUS, an ensemble\ncombining models across architectures and channel setups via soft voting.\nSOMNUS achieves robust performance across twenty-four different datasets, with\nmacro-F1 scores between 68.7% and 87.2%, outperforming individual models in\n94.9% of cases. Notably, SOMNUS surpasses previous SoA methods, even including\ncases where compared models were trained ID while SOMNUS treated the same data\nas OOD. Using a subset of the BSWR (N=6'633), we quantify model biases linked\nto age, gender, AHI, and PLMI, showing that while ensemble improves robustness,\nno model architecture consistently minimizes bias in performance and clinical\nmarkers estimation. In evaluations on OOD multi-annotated datasets (DOD-H,\nDOD-O), SOMNUS exceeds the best human scorer, i.e., MF1 85.2% vs 80.8% on\nDOD-H, and 80.2% vs 75.9% on DOD-O, better reproducing the scorer consensus\nthan any individual expert (k = 0.89/0.85 and ACS = 0.95/0.94 for healthy/OSA\ncohorts). Finally, we introduce ensemble disagreement metrics - entropy and\ninter-model divergence based - predicting regions of scorer disagreement with\nROC AUCs up to 0.828, offering a data-driven proxy for human uncertainty.", "AI": {"tldr": "SLEEPYLAND\u662f\u4e00\u4e2a\u5f00\u6e90\u7761\u7720\u5206\u671f\u8bc4\u4f30\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u6a21\u578b\u8bc4\u4f30\u3001\u6cdb\u5316\u3001\u504f\u89c1\u548c\u6807\u6ce8\u53d8\u5f02\u6027\u95ee\u9898\uff0c\u5305\u542b\u5927\u91cfID\u548cOOD\u6570\u636e\uff0c\u5e76\u63d0\u51fa\u4e86SOMNUS\u96c6\u6210\u6a21\u578b\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4e34\u5e8a\u91c7\u7528\u6df1\u5ea6\u5b66\u4e60\u8fdb\u884c\u81ea\u52a8\u7761\u7720\u5206\u671f\u7684\u8fdb\u5c55\u53d7\u9650\uff0c\u4e3b\u8981\u7531\u4e8e\u6a21\u578b\u8bc4\u4f30\u4e0d\u516c\u5e73\u3001\u6cdb\u5316\u80fd\u529b\u5dee\u3001\u6a21\u578b\u504f\u89c1\u548c\u6807\u6ce8\u53d8\u5f02\u6027\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51faSLEEPYLAND\u6846\u67b6\uff0c\u5305\u542b\u5927\u91cfID\u548cOOD\u6570\u636e\uff0c\u5e76\u5f00\u53d1SOMNUS\u96c6\u6210\u6a21\u578b\uff0c\u901a\u8fc7\u8f6f\u6295\u7968\u7ed3\u5408\u4e0d\u540c\u67b6\u6784\u548c\u901a\u9053\u914d\u7f6e\u7684\u6a21\u578b\u3002", "result": "SOMNUS\u572824\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u7a33\u5065\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u548c\u4eba\u7c7b\u8bc4\u5206\u8005\uff0c\u540c\u65f6\u91cf\u5316\u4e86\u6a21\u578b\u504f\u89c1\u5e76\u63d0\u51fa\u4e86\u9884\u6d4b\u6807\u6ce8\u5206\u6b67\u7684\u6307\u6807\u3002", "conclusion": "SLEEPYLAND\u548cSOMNUS\u663e\u8457\u63d0\u5347\u4e86\u7761\u7720\u5206\u671f\u7684\u6027\u80fd\u548c\u9c81\u68d2\u6027\uff0c\u4f46\u4ecd\u9700\u8fdb\u4e00\u6b65\u51cf\u5c11\u6a21\u578b\u504f\u89c1\u3002"}}
{"id": "2506.08577", "pdf": "https://arxiv.org/pdf/2506.08577", "abs": "https://arxiv.org/abs/2506.08577", "authors": ["Nicholas A. Pearson", "Francesca Cairoli", "Luca Bortolussi", "Davide Russo", "Francesca Zanello"], "title": "Diffusion-based Time Series Forecasting for Sewerage Systems", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted for presentation at the 13th Urban Drainage Modelling\n  Conference, Innsbruck (Austria), September 2025", "summary": "We introduce a novel deep learning approach that harnesses the power of\ngenerative artificial intelligence to enhance the accuracy of contextual\nforecasting in sewerage systems. By developing a diffusion-based model that\nprocesses multivariate time series data, our system excels at capturing complex\ncorrelations across diverse environmental signals, enabling robust predictions\neven during extreme weather events. To strengthen the model's reliability, we\nfurther calibrate its predictions with a conformal inference technique,\ntailored for probabilistic time series data, ensuring that the resulting\nprediction intervals are statistically reliable and cover the true target\nvalues with a desired confidence level. Our empirical tests on real sewerage\nsystem data confirm the model's exceptional capability to deliver reliable\ncontextual predictions, maintaining accuracy even under severe weather\nconditions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u7528\u4e8e\u63d0\u5347\u6c61\u6c34\u7cfb\u7edf\u4e0a\u4e0b\u6587\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u5e76\u901a\u8fc7\u6269\u6563\u6a21\u578b\u548c\u4fdd\u5f62\u63a8\u7406\u6280\u672f\u786e\u4fdd\u9884\u6d4b\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u63d0\u5347\u6c61\u6c34\u7cfb\u7edf\u5728\u6781\u7aef\u5929\u6c14\u6761\u4ef6\u4e0b\u7684\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u6355\u6349\u590d\u6742\u73af\u5883\u4fe1\u53f7\u95f4\u7684\u5173\u8054\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u7684\u6a21\u578b\u5904\u7406\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u5e76\u7ed3\u5408\u4fdd\u5f62\u63a8\u7406\u6280\u672f\u6821\u51c6\u9884\u6d4b\u533a\u95f4\u3002", "result": "\u6a21\u578b\u5728\u771f\u5b9e\u6c61\u6c34\u7cfb\u7edf\u6570\u636e\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5373\u4f7f\u5728\u6781\u7aef\u5929\u6c14\u4e0b\u4e5f\u80fd\u4fdd\u6301\u9ad8\u51c6\u786e\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6c61\u6c34\u7cfb\u7edf\u7684\u4e0a\u4e0b\u6587\u9884\u6d4b\u63d0\u4f9b\u4e86\u53ef\u9760\u4e14\u7edf\u8ba1\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.08600", "pdf": "https://arxiv.org/pdf/2506.08600", "abs": "https://arxiv.org/abs/2506.08600", "authors": ["Hiroshi Kera", "Shun Arakawa", "Yuta Sato"], "title": "CALT: A Library for Computer Algebra with Transformer", "categories": ["cs.LG", "cs.SC", "math.AC"], "comment": "ISSAC 2025 Short Communications", "summary": "Recent advances in artificial intelligence have demonstrated the learnability\nof symbolic computation through end-to-end deep learning. Given a sufficient\nnumber of examples of symbolic expressions before and after the target\ncomputation, Transformer models - highly effective learners of\nsequence-to-sequence functions - can be trained to emulate the computation.\nThis development opens up several intriguing challenges and new research\ndirections, which require active contributions from the symbolic computation\ncommunity. In this work, we introduce Computer Algebra with Transformer (CALT),\na user-friendly Python library designed to help non-experts in deep learning\ntrain models for symbolic computation tasks.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86CALT\uff0c\u4e00\u4e2a\u7528\u6237\u53cb\u597d\u7684Python\u5e93\uff0c\u5e2e\u52a9\u975e\u6df1\u5ea6\u5b66\u4e60\u4e13\u5bb6\u8bad\u7ec3\u6a21\u578b\u8fdb\u884c\u7b26\u53f7\u8ba1\u7b97\u4efb\u52a1\u3002", "motivation": "\u8fd1\u5e74\u6765AI\u7684\u8fdb\u6b65\u8868\u660e\u7b26\u53f7\u8ba1\u7b97\u53ef\u4ee5\u901a\u8fc7\u7aef\u5230\u7aef\u6df1\u5ea6\u5b66\u4e60\u5b66\u4e60\uff0c\u4f46\u9700\u8981\u7b26\u53f7\u8ba1\u7b97\u793e\u533a\u7684\u79ef\u6781\u53c2\u4e0e\u3002", "method": "\u4f7f\u7528Transformer\u6a21\u578b\u8bad\u7ec3\uff0c\u901a\u8fc7\u5927\u91cf\u7b26\u53f7\u8868\u8fbe\u5f0f\u7684\u793a\u4f8b\u6a21\u62df\u8ba1\u7b97\u3002", "result": "\u5f00\u53d1\u4e86CALT\u5e93\uff0c\u4e3a\u975e\u4e13\u5bb6\u63d0\u4f9b\u4fbf\u6377\u7684\u5de5\u5177\u3002", "conclusion": "CALT\u4e3a\u7b26\u53f7\u8ba1\u7b97\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411\u548c\u5b9e\u8df5\u5de5\u5177\u3002"}}
{"id": "2506.08604", "pdf": "https://arxiv.org/pdf/2506.08604", "abs": "https://arxiv.org/abs/2506.08604", "authors": ["Giacomo Baldan", "Qiang Liu", "Alberto Guardone", "Nils Thuerey"], "title": "Flow Matching Meets PDEs: A Unified Framework for Physics-Constrained Generation", "categories": ["cs.LG", "cs.AI", "cs.CE", "cs.NA", "math.NA"], "comment": null, "summary": "Generative machine learning methods, such as diffusion models and flow\nmatching, have shown great potential in modeling complex system behaviors and\nbuilding efficient surrogate models. However, these methods typically learn the\nunderlying physics implicitly from data. We propose Physics-Based Flow Matching\n(PBFM), a novel generative framework that explicitly embeds physical\nconstraints, both PDE residuals and algebraic relations, into the flow matching\nobjective. We also introduce temporal unrolling at training time that improves\nthe accuracy of the final, noise-free sample prediction. Our method jointly\nminimizes the flow matching loss and the physics-based residual loss without\nrequiring hyperparameter tuning of their relative weights. Additionally, we\nanalyze the role of the minimum noise level, $\\sigma_{\\min}$, in the context of\nphysical constraints and evaluate a stochastic sampling strategy that helps to\nreduce physical residuals. Through extensive benchmarks on three representative\nPDE problems, we show that our approach yields up to an $8\\times$ more accurate\nphysical residuals compared to FM, while clearly outperforming existing\nalgorithms in terms of distributional accuracy. PBFM thus provides a principled\nand efficient framework for surrogate modeling, uncertainty quantification, and\naccelerated simulation in physics and engineering applications.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPBFM\u7684\u65b0\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u663e\u5f0f\u5d4c\u5165\u7269\u7406\u7ea6\u675f\uff08PDE\u6b8b\u5dee\u548c\u4ee3\u6570\u5173\u7cfb\uff09\u5230\u6d41\u5339\u914d\u76ee\u6807\u4e2d\uff0c\u63d0\u9ad8\u4e86\u7269\u7406\u6a21\u62df\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u4f20\u7edf\u751f\u6210\u65b9\u6cd5\uff08\u5982\u6269\u6563\u6a21\u578b\u548c\u6d41\u5339\u914d\uff09\u901a\u5e38\u4ece\u6570\u636e\u4e2d\u9690\u5f0f\u5b66\u4e60\u7269\u7406\u89c4\u5f8b\uff0c\u7f3a\u4e4f\u663e\u5f0f\u7269\u7406\u7ea6\u675f\uff0c\u9650\u5236\u4e86\u5176\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "method": "PBFM\u7ed3\u5408\u6d41\u5339\u914d\u635f\u5931\u548c\u57fa\u4e8e\u7269\u7406\u7684\u6b8b\u5dee\u635f\u5931\uff0c\u65e0\u9700\u8c03\u6574\u8d85\u53c2\u6570\u6743\u91cd\uff0c\u5e76\u5f15\u5165\u65f6\u95f4\u5c55\u5f00\u8bad\u7ec3\u4ee5\u63d0\u9ad8\u9884\u6d4b\u7cbe\u5ea6\u3002", "result": "\u5728\u4e09\u4e2a\u4ee3\u8868\u6027PDE\u95ee\u9898\u4e0a\uff0cPBFM\u7684\u7269\u7406\u6b8b\u5dee\u6bd4\u4f20\u7edf\u65b9\u6cd5\u51c6\u786e8\u500d\uff0c\u4e14\u5728\u5206\u5e03\u51c6\u786e\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u7b97\u6cd5\u3002", "conclusion": "PBFM\u4e3a\u7269\u7406\u548c\u5de5\u7a0b\u5e94\u7528\u4e2d\u7684\u4ee3\u7406\u5efa\u6a21\u3001\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u548c\u52a0\u901f\u6a21\u62df\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u7406\u8bba\u4e25\u8c28\u7684\u6846\u67b6\u3002"}}
{"id": "2506.08607", "pdf": "https://arxiv.org/pdf/2506.08607", "abs": "https://arxiv.org/abs/2506.08607", "authors": ["Kiran Purohit", "V Venktesh", "Sourangshu Bhattacharya", "Avishek Anand"], "title": "Sample Efficient Demonstration Selection for In-Context Learning", "categories": ["cs.LG"], "comment": "Accepted at ICML 2025 , 24 pages", "summary": "The in-context learning paradigm with LLMs has been instrumental in advancing\na wide range of natural language processing tasks. The selection of few-shot\nexamples (exemplars / demonstration samples) is essential for constructing\neffective prompts under context-length budget constraints. In this paper, we\nformulate the exemplar selection task as a top-m best arms identification\nproblem. A key challenge in this setup is the exponentially large number of\narms that need to be evaluated to identify the m-best arms. We propose CASE\n(Challenger Arm Sampling for Exemplar selection), a novel sample-efficient\nselective exploration strategy that maintains a shortlist of \"challenger\" arms,\nwhich are current candidates for the top-m arms. In each iteration, only one of\nthe arms from this shortlist or the current topm set is pulled, thereby\nreducing sample complexity and, consequently, the number of LLM evaluations.\nFurthermore, we model the scores of exemplar subsets (arms) using a\nparameterized linear scoring function, leading to stochastic linear bandits\nsetting. CASE achieves remarkable efficiency gains of up to 7x speedup in\nruntime while requiring 7x fewer LLM calls (87% reduction) without sacrificing\nperformance compared to state-of-the-art exemplar selection methods. We release\nour code and data at https://github.com/kiranpurohit/CASE", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCASE\u7684\u9ad8\u6548\u6837\u672c\u9009\u62e9\u7b56\u7565\uff0c\u7528\u4e8e\u5728\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e2d\u9009\u62e9\u6700\u4f18\u7684few-shot\u793a\u4f8b\uff0c\u663e\u8457\u51cf\u5c11\u4e86LLM\u8bc4\u4f30\u6b21\u6570\u548c\u8fd0\u884c\u65f6\u95f4\u3002", "motivation": "\u5728\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e2d\uff0cfew-shot\u793a\u4f8b\u7684\u9009\u62e9\u5bf9\u6784\u5efa\u9ad8\u6548\u63d0\u793a\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u6837\u672c\u590d\u6742\u6027\u548c\u8ba1\u7b97\u6210\u672c\u4e0a\u5b58\u5728\u6311\u6218\u3002", "method": "\u5c06\u793a\u4f8b\u9009\u62e9\u95ee\u9898\u5efa\u6a21\u4e3atop-m\u6700\u4f73\u81c2\u8bc6\u522b\u95ee\u9898\uff0c\u63d0\u51faCASE\u7b56\u7565\uff0c\u901a\u8fc7\u7ef4\u62a4\u201c\u6311\u6218\u8005\u201d\u81c2\u77ed\u5217\u8868\u548c\u7ebf\u6027\u8bc4\u5206\u51fd\u6570\uff0c\u51cf\u5c11\u6837\u672c\u590d\u6742\u6027\u548cLLM\u8c03\u7528\u6b21\u6570\u3002", "result": "CASE\u5b9e\u73b0\u4e86\u9ad8\u8fbe7\u500d\u7684\u8fd0\u884c\u65f6\u95f4\u52a0\u901f\u548c87%\u7684LLM\u8c03\u7528\u51cf\u5c11\uff0c\u540c\u65f6\u4fdd\u6301\u6027\u80fd\u3002", "conclusion": "CASE\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u6027\u80fd\u4f18\u8d8a\u7684\u793a\u4f8b\u9009\u62e9\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u4e0a\u4e0b\u6587\u5b66\u4e60\u4efb\u52a1\u3002"}}
{"id": "2506.08618", "pdf": "https://arxiv.org/pdf/2506.08618", "abs": "https://arxiv.org/abs/2506.08618", "authors": ["Xianquan Yan", "Hakan Akg\u00fcn", "Kenji Kawaguchi", "N. Duane Loh", "Ching Hua Lee"], "title": "HSG-12M: A Large-Scale Spatial Multigraph Dataset", "categories": ["cs.LG", "cond-mat.mes-hall", "cond-mat.other", "cs.AI", "cs.CV"], "comment": "39 pages, 13 figures, 3 tables. Code & pipeline:\n  [https://github.com/sarinstein-yan/Poly2Graph] Dataset:\n  [https://github.com/sarinstein-yan/HSG-12M] Dataset released under CC BY 4.0", "summary": "Existing graph benchmarks assume non-spatial, simple edges, collapsing\nphysically distinct paths into a single link. We introduce HSG-12M, the first\nlarge-scale dataset of $\\textbf{spatial multigraphs}-$graphs embedded in a\nmetric space where multiple geometrically distinct trajectories between two\nnodes are retained as separate edges. HSG-12M contains 11.6 million static and\n5.1 million dynamic $\\textit{Hamiltonian spectral graphs}$ across 1401\ncharacteristic-polynomial classes, derived from 177 TB of spectral potential\ndata. Each graph encodes the full geometry of a 1-D crystal's energy spectrum\non the complex plane, producing diverse, physics-grounded topologies that\ntranscend conventional node-coordinate datasets. To enable future extensions,\nwe release $\\texttt{Poly2Graph}$: a high-performance, open-source pipeline that\nmaps arbitrary 1-D crystal Hamiltonians to spectral graphs. Benchmarks with\npopular GNNs expose new challenges in learning from multi-edge geometry at\nscale. Beyond its practical utility, we show that spectral graphs serve as\nuniversal topological fingerprints of polynomials, vectors, and matrices,\nforging a new algebra-to-graph link. HSG-12M lays the groundwork for\ngeometry-aware graph learning and new opportunities of data-driven scientific\ndiscovery in condensed matter physics and beyond.", "AI": {"tldr": "HSG-12M\u662f\u9996\u4e2a\u5927\u89c4\u6a21\u7a7a\u95f4\u591a\u91cd\u56fe\u6570\u636e\u96c6\uff0c\u5305\u542b\u9759\u6001\u548c\u52a8\u6001\u7684\u54c8\u5bc6\u987f\u8c31\u56fe\uff0c\u7528\u4e8e\u51e0\u4f55\u611f\u77e5\u56fe\u5b66\u4e60\u3002", "motivation": "\u73b0\u6709\u56fe\u57fa\u51c6\u5047\u8bbe\u8fb9\u662f\u975e\u7a7a\u95f4\u4e14\u7b80\u5355\u7684\uff0c\u5ffd\u7565\u4e86\u7269\u7406\u4e0a\u4e0d\u540c\u7684\u8def\u5f84\u3002HSG-12M\u586b\u8865\u4e86\u8fd9\u4e00\u7a7a\u767d\uff0c\u4fdd\u7559\u4e86\u591a\u6761\u51e0\u4f55\u8def\u5f84\u3002", "method": "\u901a\u8fc7Poly2Graph\u7ba1\u9053\uff0c\u5c06\u4e00\u7ef4\u6676\u4f53\u54c8\u5bc6\u987f\u91cf\u6620\u5c04\u4e3a\u8c31\u56fe\uff0c\u751f\u6210\u591a\u6837\u5316\u7684\u7269\u7406\u57fa\u7840\u62d3\u6251\u7ed3\u6784\u3002", "result": "HSG-12M\u5305\u542b1160\u4e07\u9759\u6001\u548c510\u4e07\u52a8\u6001\u8c31\u56fe\uff0c\u8986\u76d61401\u4e2a\u7279\u5f81\u591a\u9879\u5f0f\u7c7b\u3002GNN\u57fa\u51c6\u6d4b\u8bd5\u63ed\u793a\u4e86\u591a\u8fb9\u51e0\u4f55\u5b66\u4e60\u7684\u65b0\u6311\u6218\u3002", "conclusion": "HSG-12M\u4e3a\u51e0\u4f55\u611f\u77e5\u56fe\u5b66\u4e60\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5e76\u5f00\u8f9f\u4e86\u6570\u636e\u9a71\u52a8\u79d1\u5b66\u53d1\u73b0\u7684\u65b0\u673a\u4f1a\u3002"}}
{"id": "2506.08641", "pdf": "https://arxiv.org/pdf/2506.08641", "abs": "https://arxiv.org/abs/2506.08641", "authors": ["Simon Roschmann", "Quentin Bouniot", "Vasilii Feofanov", "Ievgen Redko", "Zeynep Akata"], "title": "Time Series Representations for Classification Lie Hidden in Pretrained Vision Transformers", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Time series classification is a fundamental task in healthcare and industry,\nyet the development of time series foundation models (TSFMs) remains limited by\nthe scarcity of publicly available time series datasets. In this work, we\npropose Time Vision Transformer (TiViT), a framework that converts time series\ninto images to leverage the representational power of frozen Vision\nTransformers (ViTs) pretrained on large-scale image datasets. First, we\ntheoretically motivate our approach by analyzing the 2D patching of ViTs for\ntime series, showing that it can increase the number of label-relevant tokens\nand reduce the sample complexity. Second, we empirically demonstrate that TiViT\nachieves state-of-the-art performance on standard time series classification\nbenchmarks by utilizing the hidden representations of large OpenCLIP models. We\nexplore the structure of TiViT representations and find that intermediate\nlayers with high intrinsic dimension are the most effective for time series\nclassification. Finally, we assess the alignment between TiViT and TSFM\nrepresentation spaces and identify a strong complementarity, with further\nperformance gains achieved by combining their features. Our findings reveal yet\nanother direction for reusing vision representations in a non-visual domain.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u65f6\u95f4\u5e8f\u5217\u8f6c\u6362\u4e3a\u56fe\u50cf\u4ee5\u5229\u7528\u9884\u8bad\u7ec3\u89c6\u89c9Transformer\uff08ViT\uff09\u7684\u6846\u67b6TiViT\uff0c\u5728\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u4efb\u52a1\u4e2d\u53d6\u5f97\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u5728\u533b\u7597\u548c\u5de5\u4e1a\u4e2d\u5f88\u91cd\u8981\uff0c\u4f46\u516c\u5f00\u6570\u636e\u96c6\u7a00\u7f3a\u9650\u5236\u4e86\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\uff08TSFM\uff09\u7684\u53d1\u5c55\u3002", "method": "\u5c06\u65f6\u95f4\u5e8f\u5217\u8f6c\u6362\u4e3a\u56fe\u50cf\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u7684ViT\u6a21\u578b\uff08\u5982OpenCLIP\uff09\u63d0\u53d6\u9690\u85cf\u8868\u793a\uff0c\u5206\u6790\u51762D\u5206\u5757\u5bf9\u65f6\u95f4\u5e8f\u5217\u7684\u5f71\u54cd\u3002", "result": "TiViT\u5728\u6807\u51c6\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u57fa\u51c6\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u53d1\u73b0\u9ad8\u5185\u5728\u7ef4\u5ea6\u7684\u4e2d\u95f4\u5c42\u6700\u6709\u6548\u3002", "conclusion": "TiViT\u5c55\u793a\u4e86\u89c6\u89c9\u8868\u793a\u5728\u975e\u89c6\u89c9\u9886\u57df\u7684\u590d\u7528\u6f5c\u529b\uff0c\u4e0eTSFM\u8868\u793a\u7a7a\u95f4\u4e92\u8865\uff0c\u7ed3\u5408\u540e\u53ef\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2506.08644", "pdf": "https://arxiv.org/pdf/2506.08644", "abs": "https://arxiv.org/abs/2506.08644", "authors": ["Woosung Kim", "JunHo Seo", "Jongmin Lee", "Byung-Jun Lee"], "title": "Semi-gradient DICE for Offline Constrained Reinforcement Learning", "categories": ["cs.LG"], "comment": "Constrained Offline Reinforcement Learning", "summary": "Stationary Distribution Correction Estimation (DICE) addresses the mismatch\nbetween the stationary distribution induced by a policy and the target\ndistribution required for reliable off-policy evaluation (OPE) and policy\noptimization. DICE-based offline constrained RL particularly benefits from the\nflexibility of DICE, as it simultaneously maximizes return while estimating\ncosts in offline settings. However, we have observed that recent approaches\ndesigned to enhance the offline RL performance of the DICE framework\ninadvertently undermine its ability to perform OPE, making them unsuitable for\nconstrained RL scenarios. In this paper, we identify the root cause of this\nlimitation: their reliance on a semi-gradient optimization, which solves a\nfundamentally different optimization problem and results in failures in cost\nestimation. Building on these insights, we propose a novel method to enable OPE\nand constrained RL through semi-gradient DICE. Our method ensures accurate cost\nestimation and achieves state-of-the-art performance on the offline constrained\nRL benchmark, DSRL.", "AI": {"tldr": "DICE\u65b9\u6cd5\u7528\u4e8e\u89e3\u51b3\u7b56\u7565\u8bf1\u5bfc\u7684\u7a33\u6001\u5206\u5e03\u4e0e\u76ee\u6807\u5206\u5e03\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u4f46\u73b0\u6709\u6539\u8fdb\u65b9\u6cd5\u524a\u5f31\u4e86\u5176\u79bb\u7ebf\u7b56\u7565\u8bc4\u4f30\uff08OPE\uff09\u80fd\u529b\u3002\u672c\u6587\u63d0\u51fa\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u534a\u68af\u5ea6DICE\u5b9e\u73b0OPE\u548c\u7ea6\u675fRL\u3002", "motivation": "\u89e3\u51b3DICE\u6846\u67b6\u5728\u79bb\u7ebfRL\u4e2d\u56e0\u534a\u68af\u5ea6\u4f18\u5316\u5bfc\u81f4\u7684OPE\u80fd\u529b\u4e0b\u964d\u95ee\u9898\uff0c\u63d0\u5347\u7ea6\u675fRL\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u534a\u68af\u5ea6DICE\u4f18\u5316\uff0c\u786e\u4fdd\u51c6\u786e\u7684\u6210\u672c\u4f30\u8ba1\u3002", "result": "\u5728\u79bb\u7ebf\u7ea6\u675fRL\u57fa\u51c6DSRL\u4e0a\u8fbe\u5230\u6700\u4f18\u6027\u80fd\u3002", "conclusion": "\u65b0\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u534a\u68af\u5ea6DICE\u7684\u5c40\u9650\u6027\uff0c\u540c\u65f6\u63d0\u5347\u4e86OPE\u548c\u7ea6\u675fRL\u7684\u6548\u679c\u3002"}}
{"id": "2506.08645", "pdf": "https://arxiv.org/pdf/2506.08645", "abs": "https://arxiv.org/abs/2506.08645", "authors": ["Youqi Wu", "Jingwei Zhang", "Farzan Farnia"], "title": "Fusing Cross-modal and Uni-modal Representations: A Kronecker Product Approach", "categories": ["cs.LG"], "comment": null, "summary": "Cross-modal embeddings, such as CLIP, BLIP and their variants, have achieved\npromising results in aligning representations across modalities. However, these\nembeddings could underperform compared to state-of-the-art single-modality\nembeddings on modality-specific tasks. On the other hand, single-modality\nembeddings excel in their domains but lack cross-modal alignment capabilities.\nIn this work, we focus on the problem of unifying cross-modality and\nsingle-modality embeddings to achieve the performance of modality-expert\nembedding within individual modalities while preserving cross-modal alignment.\nTo this end, we propose RP-KrossFuse, a method that leverages a random\nprojection-based Kronecker product to integrate cross-modal embeddings with\nsingle-modality embeddings. RP-KrossFuse aims to fuse the sample-pairwise\nsimilarity scores of the fused embeddings and operates efficiently in a\nspecified kernel space and supports scalable implementations via random Fourier\nfeatures for shift-invariant kernels such as the Gaussian kernel. We\ndemonstrate the effectiveness of RP-KrossFuse through several numerical\nexperiments, combining CLIP embeddings with uni-modal image and text\nembeddings. Our numerical results indicate that RP-KrossFuse achieves\ncompetitive modality-specific performance while retaining cross-modal\nalignment, bridging the gap between cross-modal and single-modality embeddings.", "AI": {"tldr": "RP-KrossFuse\u65b9\u6cd5\u901a\u8fc7\u968f\u673a\u6295\u5f71\u548cKronecker\u79ef\u6574\u5408\u8de8\u6a21\u6001\u548c\u5355\u6a21\u6001\u5d4c\u5165\uff0c\u5728\u4fdd\u6301\u8de8\u6a21\u6001\u5bf9\u9f50\u7684\u540c\u65f6\u63d0\u5347\u5355\u6a21\u6001\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u8de8\u6a21\u6001\u5d4c\u5165\u5728\u5355\u6a21\u6001\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u800c\u5355\u6a21\u6001\u5d4c\u5165\u7f3a\u4e4f\u8de8\u6a21\u6001\u5bf9\u9f50\u80fd\u529b\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faRP-KrossFuse\u65b9\u6cd5\uff0c\u5229\u7528\u968f\u673a\u6295\u5f71\u548cKronecker\u79ef\u878d\u5408\u8de8\u6a21\u6001\u548c\u5355\u6a21\u6001\u5d4c\u5165\u7684\u76f8\u4f3c\u6027\u5f97\u5206\uff0c\u652f\u6301\u9ad8\u6548\u5b9e\u73b0\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cRP-KrossFuse\u5728\u5355\u6a21\u6001\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u540c\u65f6\u4fdd\u6301\u8de8\u6a21\u6001\u5bf9\u9f50\u80fd\u529b\u3002", "conclusion": "RP-KrossFuse\u6210\u529f\u5f25\u5408\u4e86\u8de8\u6a21\u6001\u548c\u5355\u6a21\u6001\u5d4c\u5165\u4e4b\u95f4\u7684\u6027\u80fd\u5dee\u8ddd\u3002"}}
{"id": "2506.08652", "pdf": "https://arxiv.org/pdf/2506.08652", "abs": "https://arxiv.org/abs/2506.08652", "authors": ["Mahesh Godavarti"], "title": "JoFormer (Journey-based Transformer): Theory and Empirical Analysis on the Tiny Shakespeare Dataset", "categories": ["cs.LG", "cs.AI", "20-XX, 08A02", "F.4.1; I.2"], "comment": null, "summary": "Transformers have demonstrated remarkable success in sequence modeling, yet\neffectively incorporating positional information remains a challenging and\nactive area of research. In this paper, we introduce JoFormer, a journey-based\nTransformer architecture grounded in a recently proposed non-commutative\nalgebra for composing transformations across positions. JoFormer represents\nrelative positions through learnable directional transforms that are\nsequentially composed along the input, thereby extending and generalizing\nexisting approaches based on relative position representations. We derive the\nJoFormer attention mechanism from first principles and show that it subsumes\nstandard methods such as rotary transformations as special cases. To evaluate\nits effectiveness, we compare JoFormer to the RoFormer baseline on the Tiny\nShakespeare character-level language modeling task. Our results demonstrate\nthat\n  JoFormer consistently achieves lower perplexity and faster convergence,\nhighlighting the advantages of its more expressive, journey-based treatment of\nposition. Notably, the per-token JoFormer is still a primitive, conceptual\nvariant with layer-independent angles, yet it already demonstrates strong\nperformance-underscoring its promise as a proof of concept for more expressive\narchitectures. We conclude by discussing how JoFormer offers a principled\napproach to integrating positional structure into Transformer architectures.\nThe code used in this work is available at\nhttps://github.com/mahesh-godavarti/joformer.", "AI": {"tldr": "JoFormer\u662f\u4e00\u79cd\u57fa\u4e8e\u975e\u4ea4\u6362\u4ee3\u6570\u7684Transformer\u67b6\u6784\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u5b9a\u5411\u53d8\u6362\u8868\u793a\u76f8\u5bf9\u4f4d\u7f6e\uff0c\u5728\u8bed\u8a00\u5efa\u6a21\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8eRoFormer\uff0c\u5177\u6709\u66f4\u4f4e\u7684\u56f0\u60d1\u5ea6\u548c\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u3002", "motivation": "\u5c3d\u7ba1Transformer\u5728\u5e8f\u5217\u5efa\u6a21\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5982\u4f55\u6709\u6548\u878d\u5165\u4f4d\u7f6e\u4fe1\u606f\u4ecd\u662f\u4e00\u4e2a\u6311\u6218\u3002JoFormer\u65e8\u5728\u901a\u8fc7\u975e\u4ea4\u6362\u4ee3\u6570\u63d0\u4f9b\u4e00\u79cd\u66f4\u7075\u6d3b\u7684\u4f4d\u7f6e\u8868\u793a\u65b9\u6cd5\u3002", "method": "JoFormer\u91c7\u7528\u57fa\u4e8e\u65c5\u7a0b\u7684\u67b6\u6784\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u5b9a\u5411\u53d8\u6362\u5e8f\u5217\u5316\u7ec4\u5408\u6765\u8868\u793a\u76f8\u5bf9\u4f4d\u7f6e\uff0c\u5e76\u63a8\u5bfc\u51fa\u65b0\u7684\u6ce8\u610f\u529b\u673a\u5236\u3002", "result": "\u5728Tiny Shakespeare\u4efb\u52a1\u4e2d\uff0cJoFormer\u6bd4RoFormer\u8868\u73b0\u66f4\u597d\uff0c\u56f0\u60d1\u5ea6\u66f4\u4f4e\u4e14\u6536\u655b\u66f4\u5feb\u3002", "conclusion": "JoFormer\u4e3aTransformer\u67b6\u6784\u63d0\u4f9b\u4e86\u4e00\u79cd\u57fa\u4e8e\u539f\u5219\u7684\u4f4d\u7f6e\u4fe1\u606f\u96c6\u6210\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u5176\u4f5c\u4e3a\u66f4\u590d\u6742\u67b6\u6784\u539f\u578b\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.08655", "pdf": "https://arxiv.org/pdf/2506.08655", "abs": "https://arxiv.org/abs/2506.08655", "authors": ["Kamil Jerabek", "Jan Luxemburk", "Richard Plny", "Josef Koumar", "Jaroslav Pesek", "Karel Hynek"], "title": "When Simple Model Just Works: Is Network Traffic Classification in Crisis?", "categories": ["cs.LG", "cs.NI"], "comment": null, "summary": "Machine learning has been applied to network traffic classification (TC) for\nover two decades. While early efforts used shallow models, the latter 2010s saw\na shift toward complex neural networks, often reporting near-perfect accuracy.\nHowever, it was recently revealed that a simple k-NN baseline using packet\nsequences metadata (sizes, times, and directions) can be on par or even\noutperform more complex methods. In this paper, we investigate this phenomenon\nfurther and evaluate this baseline across 12 datasets and 15 TC tasks, and\ninvestigate why it performs so well. Our analysis shows that most datasets\ncontain over 50% redundant samples (identical packet sequences), which\nfrequently appear in both training and test sets due to common splitting\npractices. This redundancy can lead to overestimated model performance and\nreduce the theoretical maximum accuracy when identical flows have conflicting\nlabels. Given its distinct characteristics, we further argue that standard\nmachine learning practices adapted from domains like NLP or computer vision may\nbe ill-suited for TC. Finally, we propose new directions for task formulation\nand evaluation to address these challenges and help realign the field.", "AI": {"tldr": "\u8bba\u6587\u53d1\u73b0\u7b80\u5355\u7684k-NN\u57fa\u7ebf\u65b9\u6cd5\u5728\u7f51\u7edc\u6d41\u91cf\u5206\u7c7b\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u539f\u56e0\u662f\u6570\u636e\u96c6\u4e2d\u5b58\u5728\u5927\u91cf\u5197\u4f59\u6837\u672c\uff0c\u5bfc\u81f4\u590d\u6742\u6a21\u578b\u6027\u80fd\u88ab\u9ad8\u4f30\u3002", "motivation": "\u7814\u7a76\u4e3a\u4f55\u7b80\u5355\u7684k-NN\u65b9\u6cd5\u5728\u7f51\u7edc\u6d41\u91cf\u5206\u7c7b\u4e2d\u80fd\u4e0e\u590d\u6742\u795e\u7ecf\u7f51\u7edc\u5ab2\u7f8e\u751a\u81f3\u66f4\u4f18\u3002", "method": "\u8bc4\u4f30k-NN\u57fa\u7ebf\u572812\u4e2a\u6570\u636e\u96c6\u548c15\u4e2a\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5206\u6790\u6570\u636e\u5197\u4f59\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u6570\u636e\u96c6\u4e2d\u8d85\u8fc750%\u7684\u5197\u4f59\u6837\u672c\u5bfc\u81f4\u6a21\u578b\u6027\u80fd\u88ab\u9ad8\u4f30\uff0c\u4e14\u6807\u51c6\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u53ef\u80fd\u4e0d\u9002\u7528\u4e8e\u6d41\u91cf\u5206\u7c7b\u3002", "conclusion": "\u63d0\u51fa\u65b0\u7684\u4efb\u52a1\u8bbe\u8ba1\u548c\u8bc4\u4f30\u65b9\u5411\uff0c\u4ee5\u89e3\u51b3\u6570\u636e\u5197\u4f59\u95ee\u9898\u5e76\u63a8\u52a8\u9886\u57df\u53d1\u5c55\u3002"}}
{"id": "2506.08660", "pdf": "https://arxiv.org/pdf/2506.08660", "abs": "https://arxiv.org/abs/2506.08660", "authors": ["Jinkwan Jang", "Hyungjin Park", "Jinmyeong Choi", "Taesup Kim"], "title": "Towards Robust Real-World Multivariate Time Series Forecasting: A Unified Framework for Dependency, Asynchrony, and Missingness", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Real-world time series data are inherently multivariate, often exhibiting\ncomplex inter-channel dependencies. Each channel is typically sampled at its\nown period and is prone to missing values due to various practical and\noperational constraints. These characteristics pose fundamental challenges\nrelated to channel dependency, sampling asynchrony, and missingness, all of\nwhich must be addressed to enable robust and reliable forecasting in practical\nsettings. However, most existing architectures are built on oversimplified\nassumptions, such as identical sampling periods across channels and fully\nobserved inputs at test time, which often do not hold in real-world scenarios.\nTo bridge this gap, we propose ChannelTokenFormer, a Transformer-based\nforecasting model with a flexible architecture designed to explicitly capture\ncross-channel interactions, accommodate channel-wise asynchronous sampling, and\neffectively handle missing values. Extensive experiments on three benchmark\ndatasets modified to reflect practical settings, along with one real-world\nindustrial dataset, demonstrate the superior robustness and accuracy of\nChannelTokenFormer under challenging real-world conditions.", "AI": {"tldr": "ChannelTokenFormer\u662f\u4e00\u79cd\u57fa\u4e8eTransformer\u7684\u9884\u6d4b\u6a21\u578b\uff0c\u65e8\u5728\u89e3\u51b3\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e2d\u7684\u901a\u9053\u4f9d\u8d56\u6027\u3001\u5f02\u6b65\u91c7\u6837\u548c\u7f3a\u5931\u503c\u95ee\u9898\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u901a\u5e38\u662f\u591a\u53d8\u91cf\u7684\uff0c\u4e14\u5b58\u5728\u590d\u6742\u7684\u901a\u9053\u95f4\u4f9d\u8d56\u5173\u7cfb\u3001\u5f02\u6b65\u91c7\u6837\u548c\u7f3a\u5931\u503c\u95ee\u9898\uff0c\u800c\u73b0\u6709\u6a21\u578b\u901a\u5e38\u57fa\u4e8e\u8fc7\u4e8e\u7b80\u5316\u7684\u5047\u8bbe\uff0c\u65e0\u6cd5\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u63d0\u51faChannelTokenFormer\uff0c\u901a\u8fc7\u7075\u6d3b\u7684\u67b6\u6784\u663e\u5f0f\u6355\u6349\u8de8\u901a\u9053\u4ea4\u4e92\uff0c\u9002\u5e94\u901a\u9053\u5f02\u6b65\u91c7\u6837\uff0c\u5e76\u6709\u6548\u5904\u7406\u7f3a\u5931\u503c\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u548c\u4e00\u4e2a\u771f\u5b9e\u5de5\u4e1a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cChannelTokenFormer\u5728\u590d\u6742\u73b0\u5b9e\u6761\u4ef6\u4e0b\u5177\u6709\u4f18\u8d8a\u7684\u9c81\u68d2\u6027\u548c\u51c6\u786e\u6027\u3002", "conclusion": "ChannelTokenFormer\u4e3a\u89e3\u51b3\u73b0\u5b9e\u4e16\u754c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u5173\u952e\u6311\u6218\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2506.08662", "pdf": "https://arxiv.org/pdf/2506.08662", "abs": "https://arxiv.org/abs/2506.08662", "authors": ["Florian Borzechowski", "Michael Sch\u00e4fer", "Heiko Schwarz", "Jonathan Pfaff", "Detlev Marpe", "Thomas Wiegand"], "title": "Optimizing Learned Image Compression on Scalar and Entropy-Constraint Quantization", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT"], "comment": "Accepted at ICIP2024, the IEEE International Conference on Image\n  Processing", "summary": "The continuous improvements on image compression with variational\nautoencoders have lead to learned codecs competitive with conventional\napproaches in terms of rate-distortion efficiency. Nonetheless, taking the\nquantization into account during the training process remains a problem, since\nit produces zero derivatives almost everywhere and needs to be replaced with a\ndifferentiable approximation which allows end-to-end optimization. Though there\nare different methods for approximating the quantization, none of them model\nthe quantization noise correctly and thus, result in suboptimal networks.\nHence, we propose an additional finetuning training step: After conventional\nend-to-end training, parts of the network are retrained on quantized latents\nobtained at the inference stage. For entropy-constraint quantizers like\nTrellis-Coded Quantization, the impact of the quantizer is particularly\ndifficult to approximate by rounding or adding noise as the quantized latents\nare interdependently chosen through a trellis search based on both the entropy\nmodel and a distortion measure. We show that retraining on correctly quantized\ndata consistently yields additional coding gain for both uniform scalar and\nespecially for entropy-constraint quantization, without increasing inference\ncomplexity. For the Kodak test set, we obtain average savings between 1% and\n2%, and for the TecNick test set up to 2.2% in terms of Bj{\\o}ntegaard-Delta\nbitrate.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u53d8\u5206\u81ea\u7f16\u7801\u5668\u56fe\u50cf\u538b\u7f29\u7684\u989d\u5916\u5fae\u8c03\u8bad\u7ec3\u6b65\u9aa4\uff0c\u901a\u8fc7\u5728\u63a8\u7406\u9636\u6bb5\u5bf9\u91cf\u5316\u6f5c\u5728\u8868\u793a\u8fdb\u884c\u91cd\u65b0\u8bad\u7ec3\uff0c\u63d0\u5347\u4e86\u7f16\u7801\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u65e0\u6cd5\u51c6\u786e\u6a21\u62df\u91cf\u5316\u566a\u58f0\uff0c\u5bfc\u81f4\u7f51\u7edc\u6027\u80fd\u6b21\u4f18\u3002", "method": "\u5728\u4f20\u7edf\u7aef\u5230\u7aef\u8bad\u7ec3\u540e\uff0c\u5bf9\u7f51\u7edc\u90e8\u5206\u8fdb\u884c\u57fa\u4e8e\u91cf\u5316\u6f5c\u5728\u8868\u793a\u7684\u91cd\u65b0\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5747\u5300\u6807\u91cf\u91cf\u5316\u548c\u71b5\u7ea6\u675f\u91cf\u5316\u4e0b\u5747\u80fd\u5e26\u6765\u7f16\u7801\u589e\u76ca\uff0c\u6700\u9ad8\u53ef\u8fbe2.2%\u7684\u6bd4\u7279\u7387\u8282\u7701\u3002", "conclusion": "\u901a\u8fc7\u6b63\u786e\u91cf\u5316\u6570\u636e\u7684\u91cd\u65b0\u8bad\u7ec3\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u56fe\u50cf\u538b\u7f29\u7684\u6027\u80fd\uff0c\u4e14\u4e0d\u589e\u52a0\u63a8\u7406\u590d\u6742\u5ea6\u3002"}}
{"id": "2506.08669", "pdf": "https://arxiv.org/pdf/2506.08669", "abs": "https://arxiv.org/abs/2506.08669", "authors": ["Dongge Han", "Menglin Xia", "Daniel Madrigal Diaz", "Samuel Kessler", "Ankur Mallick", "Xuchao Zhang", "Mirian Del Carmen Hipolito Garcia", "Jin Xu", "Victor R\u00fchle", "Saravan Rajmohan"], "title": "Enhancing Reasoning Capabilities of Small Language Models with Blueprints and Prompt Template Search", "categories": ["cs.LG", "cs.AI"], "comment": "TTODLer-FM Workshop@ICML'25 (Tiny Titans: The next wave of On-Device\n  Learning for Foundational Models)", "summary": "Small language models (SLMs) offer promising and efficient alternatives to\nlarge language models (LLMs). However, SLMs' limited capacity restricts their\nreasoning capabilities and makes them sensitive to prompt variations. To\naddress these challenges, we propose a novel framework that enhances SLM\nreasoning capabilities through LLM generated blueprints. The blueprints provide\nstructured, high-level reasoning guides that help SLMs systematically tackle\nrelated problems. Furthermore, our framework integrates a prompt template\nsearch mechanism to mitigate the SLMs' sensitivity to prompt variations. Our\nframework demonstrates improved SLM performance across various tasks, including\nmath (GSM8K), coding (MBPP), and logic reasoning (BBH). Our approach improves\nthe reasoning capabilities of SLMs without increasing model size or requiring\nadditional training, offering a lightweight and deployment-friendly solution\nfor on-device or resource-constrained environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7LLM\u751f\u6210\u7684\u84dd\u56fe\u589e\u5f3a\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08SLM\uff09\u63a8\u7406\u80fd\u529b\u7684\u6846\u67b6\uff0c\u5e76\u89e3\u51b3\u4e86SLM\u5bf9\u63d0\u793a\u53d8\u5316\u7684\u654f\u611f\u6027\u95ee\u9898\u3002", "motivation": "SLM\u867d\u7136\u9ad8\u6548\uff0c\u4f46\u5176\u6709\u9650\u7684\u63a8\u7406\u80fd\u529b\u548c\u5bf9\u63d0\u793a\u53d8\u5316\u7684\u654f\u611f\u6027\u9650\u5236\u4e86\u5176\u5e94\u7528\u3002", "method": "\u5229\u7528LLM\u751f\u6210\u7ed3\u6784\u5316\u63a8\u7406\u84dd\u56fe\uff0c\u5e76\u7ed3\u5408\u63d0\u793a\u6a21\u677f\u641c\u7d22\u673a\u5236\u3002", "result": "\u5728\u6570\u5b66\u3001\u7f16\u7a0b\u548c\u903b\u8f91\u63a8\u7406\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u5347\u4e86SLM\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u6846\u67b6\u65e0\u9700\u589e\u52a0\u6a21\u578b\u89c4\u6a21\u6216\u989d\u5916\u8bad\u7ec3\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u63d0\u4f9b\u4e86\u8f7b\u91cf\u7ea7\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.08673", "pdf": "https://arxiv.org/pdf/2506.08673", "abs": "https://arxiv.org/abs/2506.08673", "authors": ["Diptarka Chakraborty", "Kushagra Chatterjee", "Debarati Das", "Tien Long Nguyen", "Romina Nobahari"], "title": "Towards Fair Representation: Clustering and Consensus", "categories": ["cs.LG", "cs.DS"], "comment": "The paper has been accepted at the Conference on Learning Theory\n  (COLT) 2025", "summary": "Consensus clustering, a fundamental task in machine learning and data\nanalysis, aims to aggregate multiple input clusterings of a dataset,\npotentially based on different non-sensitive attributes, into a single\nclustering that best represents the collective structure of the data. In this\nwork, we study this fundamental problem through the lens of fair clustering, as\nintroduced by Chierichetti et al. [NeurIPS'17], which incorporates the\ndisparate impact doctrine to ensure proportional representation of each\nprotected group in the dataset within every cluster. Our objective is to find a\nconsensus clustering that is not only representative but also fair with respect\nto specific protected attributes. To the best of our knowledge, we are the\nfirst to address this problem and provide a constant-factor approximation.\n  As part of our investigation, we examine how to minimally modify an existing\nclustering to enforce fairness -- an essential postprocessing step in many\nclustering applications that require fair representation. We develop an optimal\nalgorithm for datasets with equal group representation and near-linear time\nconstant factor approximation algorithms for more general scenarios with\ndifferent proportions of two group sizes. We complement our approximation\nresult by showing that the problem is NP-hard for two unequal-sized groups.\nGiven the fundamental nature of this problem, we believe our results on Closest\nFair Clustering could have broader implications for other clustering problems,\nparticularly those for which no prior approximation guarantees exist for their\nfair variants.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5171\u8bc6\u805a\u7c7b\u4e2d\u7684\u516c\u5e73\u6027\u95ee\u9898\uff0c\u9996\u6b21\u63d0\u51fa\u4e86\u4e00\u79cd\u5e38\u6570\u56e0\u5b50\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u5e76\u63a2\u8ba8\u4e86\u5982\u4f55\u6700\u5c0f\u5316\u4fee\u6539\u73b0\u6709\u805a\u7c7b\u4ee5\u5b9e\u73b0\u516c\u5e73\u6027\u3002", "motivation": "\u5171\u8bc6\u805a\u7c7b\u901a\u5e38\u57fa\u4e8e\u975e\u654f\u611f\u5c5e\u6027\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u516c\u5e73\u6027\u7684\u8003\u8651\u3002\u8be5\u7814\u7a76\u65e8\u5728\u5c06\u516c\u5e73\u6027\u5f15\u5165\u5171\u8bc6\u805a\u7c7b\uff0c\u786e\u4fdd\u6bcf\u4e2a\u53d7\u4fdd\u62a4\u7ec4\u5728\u805a\u7c7b\u4e2d\u5f97\u5230\u6bd4\u4f8b\u4ee3\u8868\u3002", "method": "\u7814\u7a76\u5f00\u53d1\u4e86\u9488\u5bf9\u7b49\u6bd4\u4f8b\u7ec4\u7684\u6700\u4f18\u7b97\u6cd5\uff0c\u4ee5\u53ca\u9488\u5bf9\u4e0d\u7b49\u6bd4\u4f8b\u7ec4\u7684\u8fd1\u7ebf\u6027\u65f6\u95f4\u5e38\u6570\u56e0\u5b50\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u5e76\u8bc1\u660e\u4e86\u95ee\u9898\u7684NP\u96be\u5ea6\u3002", "result": "\u63d0\u51fa\u4e86\u9996\u4e2a\u516c\u5e73\u5171\u8bc6\u805a\u7c7b\u7684\u5e38\u6570\u56e0\u5b50\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u4e0d\u7b49\u6bd4\u4f8b\u7ec4\u4e2d\u7684\u9ad8\u6548\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u516c\u5e73\u805a\u7c7b\u95ee\u9898\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u7b97\u6cd5\uff0c\u53ef\u80fd\u5bf9\u5176\u4ed6\u805a\u7c7b\u95ee\u9898\u7684\u516c\u5e73\u53d8\u4f53\u4ea7\u751f\u5e7f\u6cdb\u5f71\u54cd\u3002"}}
{"id": "2506.08681", "pdf": "https://arxiv.org/pdf/2506.08681", "abs": "https://arxiv.org/abs/2506.08681", "authors": ["Phuc Minh Nguyen", "Ngoc-Hieu Nguyen", "Duy H. M. Nguyen", "Anji Liu", "An Mai", "Binh T. Nguyen", "Daniel Sonntag", "Khoa D. Doan"], "title": "Mitigating Reward Over-optimization in Direct Alignment Algorithms with Importance Sampling", "categories": ["cs.LG"], "comment": "First version", "summary": "Direct Alignment Algorithms (DAAs) such as Direct Preference Optimization\n(DPO) have emerged as alternatives to the standard Reinforcement Learning from\nHuman Feedback (RLHF) for aligning large language models (LLMs) with human\nvalues. However, these methods are more susceptible to over-optimization, in\nwhich the model drifts away from the reference policy, leading to degraded\nperformance as training progresses. This paper proposes a novel\nimportance-sampling approach to mitigate the over-optimization problem of\noffline DAAs. This approach, called (IS-DAAs), multiplies the DAA objective\nwith an importance ratio that accounts for the reference policy distribution.\nIS-DAAs additionally avoid the high variance issue associated with importance\nsampling by clipping the importance ratio to a maximum value. Our extensive\nexperiments demonstrate that IS-DAAs can effectively mitigate\nover-optimization, especially under low regularization strength, and achieve\nbetter performance than other methods designed to address this problem. Our\nimplementations are provided publicly at this link.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u91cd\u8981\u6027\u91c7\u6837\u7684\u65b9\u6cd5\uff08IS-DAAs\uff09\uff0c\u7528\u4e8e\u7f13\u89e3\u76f4\u63a5\u5bf9\u9f50\u7b97\u6cd5\uff08DAAs\uff09\u4e2d\u7684\u8fc7\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u76f4\u63a5\u5bf9\u9f50\u7b97\u6cd5\uff08\u5982DPO\uff09\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5bb9\u6613\u51fa\u73b0\u8fc7\u4f18\u5316\u95ee\u9898\uff0c\u5bfc\u81f4\u6a21\u578b\u6027\u80fd\u4e0b\u964d\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u7f13\u89e3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u91cd\u8981\u6027\u91c7\u6837\u65b9\u6cd5\uff08IS-DAAs\uff09\uff0c\u901a\u8fc7\u4e58\u4e0a\u4e00\u4e2a\u91cd\u8981\u6027\u6bd4\u7387\u6765\u8003\u8651\u53c2\u8003\u7b56\u7565\u5206\u5e03\uff0c\u5e76\u901a\u8fc7\u88c1\u526a\u6bd4\u7387\u6765\u907f\u514d\u9ad8\u65b9\u5dee\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cIS-DAAs\u80fd\u6709\u6548\u7f13\u89e3\u8fc7\u4f18\u5316\u95ee\u9898\uff0c\u5c24\u5176\u5728\u4f4e\u6b63\u5219\u5316\u5f3a\u5ea6\u4e0b\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "conclusion": "IS-DAAs\u4e3a\u89e3\u51b3DAAs\u4e2d\u7684\u8fc7\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u4e14\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.08698", "pdf": "https://arxiv.org/pdf/2506.08698", "abs": "https://arxiv.org/abs/2506.08698", "authors": ["Boyu Xie", "Tangtang Xie"], "title": "Variational Autoencoder-Based Approach to Latent Feature Analysis on Efficient Representation of Power Load Monitoring Data", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages, 2 figures", "summary": "With the development of smart grids, High-Dimensional and Incomplete (HDI)\nPower Load Monitoring (PLM) data challenges the performance of Power Load\nForecasting (PLF) models. In this paper, we propose a potential\ncharacterization model VAE-LF based on Variational Autoencoder (VAE) for\nefficiently representing and complementing PLM missing data. VAE-LF learns a\nlow-dimensional latent representation of the data using an Encoder-Decoder\nstructure by splitting the HDI PLM data into vectors and feeding them\nsequentially into the VAE-LF model, and generates the complementary data.\nExperiments on the UK-DALE dataset show that VAE-LF outperforms other benchmark\nmodels in both 5% and 10% sparsity test cases, with significantly lower RMSE\nand MAE, and especially outperforms on low sparsity ratio data. The method\nprovides an efficient data-completion solution for electric load management in\nsmart grids.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09\u7684VAE-LF\u6a21\u578b\uff0c\u7528\u4e8e\u9ad8\u6548\u8868\u793a\u548c\u8865\u5145\u9ad8\u7ef4\u4e0d\u5b8c\u6574\uff08HDI\uff09\u7535\u529b\u8d1f\u8377\u76d1\u6d4b\uff08PLM\uff09\u6570\u636e\uff0c\u63d0\u5347\u7535\u529b\u8d1f\u8377\u9884\u6d4b\uff08PLF\uff09\u6027\u80fd\u3002", "motivation": "\u667a\u80fd\u7535\u7f51\u4e2d\u9ad8\u7ef4\u4e0d\u5b8c\u6574\u7684PLM\u6570\u636e\u5bf9PLF\u6a21\u578b\u6027\u80fd\u63d0\u51fa\u6311\u6218\uff0c\u9700\u8981\u9ad8\u6548\u7684\u6570\u636e\u8868\u793a\u548c\u8865\u5168\u65b9\u6cd5\u3002", "method": "VAE-LF\u901a\u8fc7\u7f16\u7801\u5668-\u89e3\u7801\u5668\u7ed3\u6784\u5b66\u4e60\u6570\u636e\u7684\u4f4e\u7ef4\u6f5c\u5728\u8868\u793a\uff0c\u5c06HDI PLM\u6570\u636e\u5206\u5757\u8f93\u5165\u6a21\u578b\u5e76\u751f\u6210\u8865\u5168\u6570\u636e\u3002", "result": "\u5728UK-DALE\u6570\u636e\u96c6\u4e0a\uff0cVAE-LF\u57285%\u548c10%\u7a00\u758f\u5ea6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u51c6\u6a21\u578b\uff0cRMSE\u548cMAE\u663e\u8457\u964d\u4f4e\uff0c\u5c24\u5176\u5728\u4f4e\u7a00\u758f\u5ea6\u6570\u636e\u4e0a\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "VAE-LF\u4e3a\u667a\u80fd\u7535\u7f51\u4e2d\u7684\u7535\u529b\u8d1f\u8377\u7ba1\u7406\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u6570\u636e\u8865\u5168\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.08727", "pdf": "https://arxiv.org/pdf/2506.08727", "abs": "https://arxiv.org/abs/2506.08727", "authors": ["Samarth Sikand", "Rohit Mehra", "Priyavanshi Pathania", "Nikhil Bamby", "Vibhu Saujanya Sharma", "Vikrant Kaulgud", "Sanjay Podder", "Adam P. Burden"], "title": "Breaking the ICE: Exploring promises and challenges of benchmarks for Inference Carbon & Energy estimation for LLMs", "categories": ["cs.LG", "cs.AI", "cs.CY", "cs.SE"], "comment": "5 pages. To be published in the proceedings of 9th International\n  Workshop on Green and Sustainable Software (GREENS '25), April 29, 2025,\n  Ottawa, Canada (Co-located with ICSE 2025)", "summary": "While Generative AI stands to be one of the fastest adopted technologies\never, studies have made evident that the usage of Large Language Models (LLMs)\nputs significant burden on energy grids and our environment. It may prove a\nhindrance to the Sustainability goals of any organization. A crucial step in\nany Sustainability strategy is monitoring or estimating the energy consumption\nof various components. While there exist multiple tools for monitoring energy\nconsumption, there is a dearth of tools/frameworks for estimating the\nconsumption or carbon emissions. Current drawbacks of both monitoring and\nestimation tools include high input data points, intrusive nature, high error\nmargin, etc. We posit that leveraging emerging LLM benchmarks and related data\npoints can help overcome aforementioned challenges while balancing accuracy of\nthe emission estimations. To that extent, we discuss the challenges of current\napproaches and present our evolving framework, R-ICE, which estimates prompt\nlevel inference carbon emissions by leveraging existing state-of-the-art(SOTA)\nbenchmark. This direction provides a more practical and non-intrusive way to\nenable emerging use-cases like dynamic LLM routing, carbon accounting, etc. Our\npromising validation results suggest that benchmark-based modelling holds great\npotential for inference emission estimation and warrants further exploration\nfrom the scientific community.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u751f\u6210\u5f0fAI\uff08\u5982LLMs\uff09\u5bf9\u80fd\u6e90\u548c\u73af\u5883\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u73b0\u6709SOTA\u57fa\u51c6\u7684\u6846\u67b6R-ICE\uff0c\u7528\u4e8e\u4f30\u7b97\u63a8\u7406\u78b3\u6392\u653e\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5de5\u5177\u7684\u4e0d\u8db3\u3002", "motivation": "\u751f\u6210\u5f0fAI\u7684\u5feb\u901f\u666e\u53ca\u5bf9\u80fd\u6e90\u548c\u73af\u5883\u9020\u6210\u8d1f\u62c5\uff0c\u73b0\u6709\u5de5\u5177\u5728\u76d1\u6d4b\u548c\u4f30\u7b97\u78b3\u6392\u653e\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u3001\u975e\u4fb5\u5165\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faR-ICE\u6846\u67b6\uff0c\u5229\u7528\u73b0\u6709SOTA\u57fa\u51c6\u6570\u636e\u4f30\u7b97\u63a8\u7406\u78b3\u6392\u653e\uff0c\u514b\u670d\u4e86\u9ad8\u6570\u636e\u9700\u6c42\u3001\u4fb5\u5165\u6027\u548c\u8bef\u5dee\u5927\u7684\u95ee\u9898\u3002", "result": "\u9a8c\u8bc1\u7ed3\u679c\u8868\u660e\uff0c\u57fa\u4e8e\u57fa\u51c6\u7684\u5efa\u6a21\u5728\u4f30\u7b97\u78b3\u6392\u653e\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u652f\u6301\u52a8\u6001LLM\u8def\u7531\u548c\u78b3\u6838\u7b97\u7b49\u5e94\u7528\u3002", "conclusion": "R-ICE\u6846\u67b6\u4e3a\u78b3\u6392\u653e\u4f30\u7b97\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u975e\u4fb5\u5165\u6027\u7684\u65b9\u6cd5\uff0c\u503c\u5f97\u79d1\u5b66\u754c\u8fdb\u4e00\u6b65\u63a2\u7d22\u3002"}}
{"id": "2506.08737", "pdf": "https://arxiv.org/pdf/2506.08737", "abs": "https://arxiv.org/abs/2506.08737", "authors": ["Haozhe Ma", "Guoji Fu", "Zhengding Luo", "Jiele Wu", "Tze-Yun Leong"], "title": "Exploration by Random Reward Perturbation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We introduce Random Reward Perturbation (RRP), a novel exploration strategy\nfor reinforcement learning (RL). Our theoretical analyses demonstrate that\nadding zero-mean noise to environmental rewards effectively enhances policy\ndiversity during training, thereby expanding the range of exploration. RRP is\nfully compatible with the action-perturbation-based exploration strategies,\nsuch as $\\epsilon$-greedy, stochastic policies, and entropy regularization,\nproviding additive improvements to exploration effects. It is general,\nlightweight, and can be integrated into existing RL algorithms with minimal\nimplementation effort and negligible computational overhead. RRP establishes a\ntheoretical connection between reward shaping and noise-driven exploration,\nhighlighting their complementary potential. Experiments show that RRP\nsignificantly boosts the performance of Proximal Policy Optimization and Soft\nActor-Critic, achieving higher sample efficiency and escaping local optima\nacross various tasks, under both sparse and dense reward scenarios.", "AI": {"tldr": "RRP\u662f\u4e00\u79cd\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u63a2\u7d22\u7b56\u7565\uff0c\u901a\u8fc7\u5411\u73af\u5883\u5956\u52b1\u6dfb\u52a0\u96f6\u5747\u503c\u566a\u58f0\u589e\u5f3a\u7b56\u7565\u591a\u6837\u6027\uff0c\u63d0\u5347\u63a2\u7d22\u8303\u56f4\u3002", "motivation": "\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u4e2d\u63a2\u7d22\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u5956\u52b1\u6270\u52a8\u589e\u5f3a\u7b56\u7565\u591a\u6837\u6027\u3002", "method": "\u5728\u73af\u5883\u5956\u52b1\u4e2d\u6dfb\u52a0\u96f6\u5747\u503c\u566a\u58f0\uff0c\u4e0e\u73b0\u6709\u63a2\u7d22\u7b56\u7565\u517c\u5bb9\u3002", "result": "\u663e\u8457\u63d0\u5347PPO\u548cSAC\u7684\u6027\u80fd\uff0c\u63d0\u9ad8\u6837\u672c\u6548\u7387\u5e76\u907f\u514d\u5c40\u90e8\u6700\u4f18\u3002", "conclusion": "RRP\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u901a\u7528\u7684\u63a2\u7d22\u7b56\u7565\uff0c\u80fd\u6709\u6548\u63d0\u5347\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u7684\u6027\u80fd\u3002"}}
{"id": "2506.08740", "pdf": "https://arxiv.org/pdf/2506.08740", "abs": "https://arxiv.org/abs/2506.08740", "authors": ["Sidhika Balachandar", "Shuvom Sadhuka", "Bonnie Berger", "Emma Pierson", "Nikhil Garg"], "title": "Urban Incident Prediction with Graph Neural Networks: Integrating Government Ratings and Crowdsourced Reports", "categories": ["cs.LG"], "comment": null, "summary": "Graph neural networks (GNNs) are widely used in urban spatiotemporal\nforecasting, such as predicting infrastructure problems. In this setting,\ngovernment officials wish to know in which neighborhoods incidents like\npotholes or rodent issues occur. The true state of incidents (e.g., street\nconditions) for each neighborhood is observed via government inspection\nratings. However, these ratings are only conducted for a sparse set of\nneighborhoods and incident types. We also observe the state of incidents via\ncrowdsourced reports, which are more densely observed but may be biased due to\nheterogeneous reporting behavior. First, for such settings, we propose a\nmultiview, multioutput GNN-based model that uses both unbiased rating data and\nbiased reporting data to predict the true latent state of incidents. Second, we\ninvestigate a case study of New York City urban incidents and collect,\nstandardize, and make publicly available a dataset of 9,615,863 crowdsourced\nreports and 1,041,415 government inspection ratings over 3 years and across 139\ntypes of incidents. Finally, we show on both real and semi-synthetic data that\nour model can better predict the latent state compared to models that use only\nreporting data or models that use only rating data, especially when rating data\nis sparse and reports are predictive of ratings. We also quantify demographic\nbiases in crowdsourced reporting, e.g., higher-income neighborhoods report\nproblems at higher rates. Our analysis showcases a widely applicable approach\nfor latent state prediction using heterogeneous, sparse, and biased data.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eGNN\u7684\u591a\u89c6\u56fe\u591a\u8f93\u51fa\u6a21\u578b\uff0c\u7ed3\u5408\u653f\u5e9c\u68c0\u67e5\u6570\u636e\u548c\u4f17\u5305\u62a5\u544a\u6570\u636e\u9884\u6d4b\u57ce\u5e02\u4e8b\u4ef6\u7684\u771f\u5b9e\u72b6\u6001\uff0c\u5e76\u5728\u7ebd\u7ea6\u5e02\u6848\u4f8b\u4e2d\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u653f\u5e9c\u68c0\u67e5\u6570\u636e\u7a00\u758f\u4e14\u4f17\u5305\u62a5\u544a\u6570\u636e\u5b58\u5728\u504f\u5dee\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u7ed3\u5408\u4e24\u8005\u9884\u6d4b\u4e8b\u4ef6\u7684\u771f\u5b9e\u72b6\u6001\u3002", "method": "\u4f7f\u7528\u591a\u89c6\u56fe\u3001\u591a\u8f93\u51fa\u7684GNN\u6a21\u578b\uff0c\u6574\u5408\u653f\u5e9c\u68c0\u67e5\u6570\u636e\u548c\u4f17\u5305\u62a5\u544a\u6570\u636e\u3002", "result": "\u6a21\u578b\u5728\u771f\u5b9e\u548c\u534a\u5408\u6210\u6570\u636e\u4e0a\u8868\u73b0\u4f18\u4e8e\u4ec5\u4f7f\u7528\u5355\u4e00\u6570\u636e\u6e90\u7684\u6a21\u578b\uff0c\u5c24\u5176\u662f\u5728\u68c0\u67e5\u6570\u636e\u7a00\u758f\u65f6\u3002\u540c\u65f6\u91cf\u5316\u4e86\u4f17\u5305\u62a5\u544a\u7684\u504f\u5dee\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5229\u7528\u5f02\u6784\u3001\u7a00\u758f\u548c\u504f\u5dee\u6570\u636e\u8fdb\u884c\u6f5c\u5728\u72b6\u6001\u9884\u6d4b\u63d0\u4f9b\u4e86\u5e7f\u6cdb\u9002\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.08764", "pdf": "https://arxiv.org/pdf/2506.08764", "abs": "https://arxiv.org/abs/2506.08764", "authors": ["Benjamin Dadoun", "Soufiane Hayou", "Hanan Salam", "Mohamed El Amine Seddik", "Pierre Youssef"], "title": "On the Stability of the Jacobian Matrix in Deep Neural Networks", "categories": ["cs.LG", "68T07, 60B20"], "comment": "16 pages, 26 figures", "summary": "Deep neural networks are known to suffer from exploding or vanishing\ngradients as depth increases, a phenomenon closely tied to the spectral\nbehavior of the input-output Jacobian. Prior work has identified critical\ninitialization schemes that ensure Jacobian stability, but these analyses are\ntypically restricted to fully connected networks with i.i.d. weights. In this\nwork, we go significantly beyond these limitations: we establish a general\nstability theorem for deep neural networks that accommodates sparsity (such as\nthat introduced by pruning) and non-i.i.d., weakly correlated weights (e.g.\ninduced by training). Our results rely on recent advances in random matrix\ntheory, and provide rigorous guarantees for spectral stability in a much\nbroader class of network models. This extends the theoretical foundation for\ninitialization schemes in modern neural networks with structured and dependent\nrandomness.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9002\u7528\u4e8e\u7a00\u758f\u6027\u548c\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6743\u91cd\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7a33\u5b9a\u6027\u5b9a\u7406\uff0c\u6269\u5c55\u4e86\u73b0\u4ee3\u795e\u7ecf\u7f51\u7edc\u521d\u59cb\u5316\u65b9\u6848\u7684\u7406\u8bba\u57fa\u7840\u3002", "motivation": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5728\u6df1\u5ea6\u589e\u52a0\u65f6\u5bb9\u6613\u51fa\u73b0\u68af\u5ea6\u7206\u70b8\u6216\u6d88\u5931\u95ee\u9898\uff0c\u73b0\u6709\u7814\u7a76\u591a\u9650\u4e8e\u5168\u8fde\u63a5\u7f51\u7edc\u548c\u72ec\u7acb\u540c\u5206\u5e03\u6743\u91cd\uff0c\u672c\u6587\u65e8\u5728\u7a81\u7834\u8fd9\u4e9b\u9650\u5236\u3002", "method": "\u5229\u7528\u968f\u673a\u77e9\u9635\u7406\u8bba\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u5206\u6790\u7a00\u758f\u6027\u548c\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6743\u91cd\u5bf9\u7f51\u7edc\u7a33\u5b9a\u6027\u7684\u5f71\u54cd\u3002", "result": "\u5efa\u7acb\u4e86\u9002\u7528\u4e8e\u66f4\u5e7f\u6cdb\u7f51\u7edc\u6a21\u578b\u7684\u8c31\u7a33\u5b9a\u6027\u7406\u8bba\uff0c\u4e3a\u7ed3\u6784\u5316\u6743\u91cd\u548c\u4f9d\u8d56\u968f\u673a\u6027\u7684\u521d\u59cb\u5316\u65b9\u6848\u63d0\u4f9b\u4e86\u4e25\u683c\u4fdd\u8bc1\u3002", "conclusion": "\u672c\u6587\u6269\u5c55\u4e86\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7a33\u5b9a\u6027\u7406\u8bba\uff0c\u4e3a\u73b0\u4ee3\u7f51\u7edc\u4e2d\u7684\u521d\u59cb\u5316\u65b9\u6848\u63d0\u4f9b\u4e86\u66f4\u5e7f\u6cdb\u7684\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2506.08837", "pdf": "https://arxiv.org/pdf/2506.08837", "abs": "https://arxiv.org/abs/2506.08837", "authors": ["Luca Beurer-Kellner", "Beat Buesser Ana-Maria Cre\u0163u", "Edoardo Debenedetti", "Daniel Dobos", "Daniel Fabian", "Marc Fischer", "David Froelicher", "Kathrin Grosse", "Daniel Naeff", "Ezinwanne Ozoani", "Andrew Paverd", "Florian Tram\u00e8r", "V\u00e1clav Volhejn"], "title": "Design Patterns for Securing LLM Agents against Prompt Injections", "categories": ["cs.LG"], "comment": null, "summary": "As AI agents powered by Large Language Models (LLMs) become increasingly\nversatile and capable of addressing a broad spectrum of tasks, ensuring their\nsecurity has become a critical challenge. Among the most pressing threats are\nprompt injection attacks, which exploit the agent's resilience on natural\nlanguage inputs -- an especially dangerous threat when agents are granted tool\naccess or handle sensitive information. In this work, we propose a set of\nprincipled design patterns for building AI agents with provable resistance to\nprompt injection. We systematically analyze these patterns, discuss their\ntrade-offs in terms of utility and security, and illustrate their real-world\napplicability through a series of case studies.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u5957\u8bbe\u8ba1\u6a21\u5f0f\uff0c\u7528\u4e8e\u6784\u5efa\u80fd\u591f\u62b5\u6297\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u7684AI\u4ee3\u7406\uff0c\u5e76\u5206\u6790\u4e86\u8fd9\u4e9b\u6a21\u5f0f\u5728\u5b9e\u7528\u6027\u548c\u5b89\u5168\u6027\u4e4b\u95f4\u7684\u6743\u8861\u3002", "motivation": "\u968f\u7740\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684AI\u4ee3\u7406\u80fd\u529b\u589e\u5f3a\uff0c\u5176\u5b89\u5168\u6027\u95ee\u9898\u65e5\u76ca\u7a81\u51fa\uff0c\u5c24\u5176\u662f\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u5bf9\u4ee3\u7406\u7684\u5a01\u80c1\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u5957\u8bbe\u8ba1\u6a21\u5f0f\uff0c\u7cfb\u7edf\u5206\u6790\u4e86\u8fd9\u4e9b\u6a21\u5f0f\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u3002", "result": "\u8bbe\u8ba1\u6a21\u5f0f\u80fd\u591f\u4e3aAI\u4ee3\u7406\u63d0\u4f9b\u53ef\u8bc1\u660e\u7684\u62b5\u6297\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u7684\u80fd\u529b\u3002", "conclusion": "\u8fd9\u4e9b\u8bbe\u8ba1\u6a21\u5f0f\u5728\u5b9e\u7528\u6027\u548c\u5b89\u5168\u6027\u4e4b\u95f4\u53d6\u5f97\u4e86\u5e73\u8861\uff0c\u4e3a\u6784\u5efa\u5b89\u5168\u7684AI\u4ee3\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2506.08844", "pdf": "https://arxiv.org/pdf/2506.08844", "abs": "https://arxiv.org/abs/2506.08844", "authors": ["Siyi Sun", "David Antony Selby", "Yunchuan Huang", "Sebastian Vollmer", "Seth Flaxman", "Anisoara Calinescu"], "title": "IMAGIC-500: IMputation benchmark on A Generative Imaginary Country (500k samples)", "categories": ["cs.LG", "cs.CE"], "comment": null, "summary": "Missing data imputation in tabular datasets remains a pivotal challenge in\ndata science and machine learning, particularly within socioeconomic research.\nHowever, real-world socioeconomic datasets are typically subject to strict data\nprotection protocols, which often prohibit public sharing, even for synthetic\nderivatives. This severely limits the reproducibility and accessibility of\nbenchmark studies in such settings. Further, there are very few publicly\navailable synthetic datasets. Thus, there is limited availability of benchmarks\nfor systematic evaluation of imputation methods on socioeconomic datasets,\nwhether real or synthetic. In this study, we utilize the World Bank's publicly\navailable synthetic dataset, Synthetic Data for an Imaginary Country, which\nclosely mimics a real World Bank household survey while being fully public,\nenabling broad access for methodological research. With this as a starting\npoint, we derived the IMAGIC-500 dataset: we select a subset of 500k\nindividuals across approximately 100k households with 19 socioeconomic\nfeatures, designed to reflect the hierarchical structure of real-world\nhousehold surveys. This paper introduces a comprehensive missing data\nimputation benchmark on IMAGIC-500 under various missing mechanisms (MCAR, MAR,\nMNAR) and missingness ratios (10\\%, 20\\%, 30\\%, 40\\%, 50\\%). Our evaluation\nconsiders the imputation accuracy for continuous and categorical variables,\ncomputational efficiency, and impact on downstream predictive tasks, such as\nestimating educational attainment at the individual level. The results\nhighlight the strengths and weaknesses of statistical, traditional machine\nlearning, and deep learning imputation techniques, including recent\ndiffusion-based methods. The IMAGIC-500 dataset and benchmark aim to facilitate\nthe development of robust imputation algorithms and foster reproducible social\nscience research.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5229\u7528\u516c\u5f00\u7684\u5408\u6210\u6570\u636e\u96c6IMAGIC-500\uff0c\u4e3a\u793e\u4f1a\u7ecf\u6d4e\u6570\u636e\u4e2d\u7684\u7f3a\u5931\u503c\u586b\u8865\u65b9\u6cd5\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u4e86\u591a\u79cd\u586b\u8865\u6280\u672f\u7684\u6548\u679c\u3002", "motivation": "\u793e\u4f1a\u7ecf\u6d4e\u6570\u636e\u56e0\u9690\u79c1\u4fdd\u62a4\u96be\u4ee5\u516c\u5f00\u5171\u4eab\uff0c\u5bfc\u81f4\u7f3a\u5931\u503c\u586b\u8865\u65b9\u6cd5\u7684\u7814\u7a76\u7f3a\u4e4f\u53ef\u590d\u73b0\u6027\u548c\u57fa\u51c6\u6570\u636e\u96c6\u3002", "method": "\u4f7f\u7528\u4e16\u754c\u94f6\u884c\u7684\u5408\u6210\u6570\u636e\u96c6\uff0c\u6784\u5efaIMAGIC-500\uff0c\u5e76\u5728\u4e0d\u540c\u7f3a\u5931\u673a\u5236\u548c\u6bd4\u4f8b\u4e0b\u6d4b\u8bd5\u591a\u79cd\u586b\u8865\u65b9\u6cd5\u3002", "result": "\u8bc4\u4f30\u4e86\u7edf\u8ba1\u3001\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u7684\u6548\u679c\uff0c\u63ed\u793a\u4e86\u5404\u79cd\u6280\u672f\u7684\u4f18\u7f3a\u70b9\u3002", "conclusion": "IMAGIC-500\u6570\u636e\u96c6\u548c\u57fa\u51c6\u6d4b\u8bd5\u6709\u52a9\u4e8e\u5f00\u53d1\u9c81\u68d2\u7684\u586b\u8865\u7b97\u6cd5\uff0c\u4fc3\u8fdb\u793e\u4f1a\u79d1\u5b66\u7814\u7a76\u7684\u53ef\u590d\u73b0\u6027\u3002"}}
{"id": "2506.08850", "pdf": "https://arxiv.org/pdf/2506.08850", "abs": "https://arxiv.org/abs/2506.08850", "authors": ["Amin Avan", "Akramul Azim", "Qusay Mahmoud"], "title": "Agile Reinforcement Learning for Real-Time Task Scheduling in Edge Computing", "categories": ["cs.LG"], "comment": null, "summary": "Soft real-time applications are becoming increasingly complex, posing\nsignificant challenges for scheduling offloaded tasks in edge computing\nenvironments while meeting task timing constraints. Moreover, the exponential\ngrowth of the search space, presence of multiple objectives and parameters, and\nhighly dynamic nature of edge computing environments further exacerbate the\ncomplexity of task scheduling. As a result, schedulers based on heuristic and\nmetaheuristic algorithms frequently encounter difficulties in generating\noptimal or near-optimal task schedules due to their constrained ability to\nadapt to the dynamic conditions and complex environmental characteristics of\nedge computing. Accordingly, reinforcement learning algorithms have been\nincorporated into schedulers to address the complexity and dynamic conditions\ninherent in task scheduling in edge computing. However, a significant\nlimitation of reinforcement learning algorithms is the prolonged learning time\nrequired to adapt to new environments and to address medium- and large-scale\nproblems. This challenge arises from the extensive global action space and\nfrequent random exploration of irrelevant actions. Therefore, this study\nproposes Agile Reinforcement learning (aRL), in which the RL-agent performs\ninformed exploration and executes only relevant actions. Consequently, the\npredictability of the RL-agent is enhanced, leading to rapid adaptation and\nconvergence, which positions aRL as a suitable candidate for scheduling the\ntasks of soft real-time applications in edge computing. The experiments\ndemonstrate that the combination of informed exploration and action-masking\nmethods enables aRL to achieve a higher hit-ratio and converge faster than the\nbaseline approaches.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u654f\u6377\u5f3a\u5316\u5b66\u4e60\uff08aRL\uff09\u65b9\u6cd5\uff0c\u7528\u4e8e\u8fb9\u7f18\u8ba1\u7b97\u4e2d\u8f6f\u5b9e\u65f6\u5e94\u7528\u7684\u4efb\u52a1\u8c03\u5ea6\uff0c\u901a\u8fc7\u667a\u80fd\u63a2\u7d22\u548c\u52a8\u4f5c\u5c4f\u853d\u6280\u672f\u63d0\u9ad8\u8c03\u5ea6\u6548\u7387\u548c\u6536\u655b\u901f\u5ea6\u3002", "motivation": "\u8fb9\u7f18\u8ba1\u7b97\u73af\u5883\u4e2d\u4efb\u52a1\u8c03\u5ea6\u7684\u590d\u6742\u6027\u3001\u52a8\u6001\u6027\u548c\u591a\u76ee\u6807\u6027\u4f7f\u5f97\u4f20\u7edf\u542f\u53d1\u5f0f\u548c\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u96be\u4ee5\u751f\u6210\u6700\u4f18\u8c03\u5ea6\u65b9\u6848\uff0c\u800c\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u7684\u5b66\u4e60\u65f6\u95f4\u8fc7\u957f\u4e5f\u9650\u5236\u4e86\u5176\u5e94\u7528\u3002", "method": "\u63d0\u51faaRL\u65b9\u6cd5\uff0c\u7ed3\u5408\u667a\u80fd\u63a2\u7d22\u548c\u52a8\u4f5c\u5c4f\u853d\u6280\u672f\uff0c\u51cf\u5c11\u65e0\u5173\u52a8\u4f5c\u7684\u968f\u673a\u63a2\u7d22\uff0c\u63d0\u5347RL-agent\u7684\u9884\u6d4b\u80fd\u529b\u548c\u9002\u5e94\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0caRL\u5728\u547d\u4e2d\u7387\u548c\u6536\u655b\u901f\u5ea6\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "aRL\u662f\u4e00\u79cd\u9002\u5408\u8fb9\u7f18\u8ba1\u7b97\u4e2d\u8f6f\u5b9e\u65f6\u5e94\u7528\u4efb\u52a1\u8c03\u5ea6\u7684\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2506.08871", "pdf": "https://arxiv.org/pdf/2506.08871", "abs": "https://arxiv.org/abs/2506.08871", "authors": ["Victor M. Tenorio", "Madeline Navarro", "Samuel Rey", "Santiago Segarra", "Antonio G. Marques"], "title": "Adapting to Heterophilic Graph Data with Structure-Guided Neighbor Discovery", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Graph Neural Networks (GNNs) often struggle with heterophilic data, where\nconnected nodes may have dissimilar labels, as they typically assume homophily\nand rely on local message passing. To address this, we propose creating\nalternative graph structures by linking nodes with similar structural\nattributes (e.g., role-based or global), thereby fostering higher label\nhomophily on these new graphs. We theoretically prove that GNN performance can\nbe improved by utilizing graphs with fewer false positive edges (connections\nbetween nodes of different classes) and that considering multiple graph views\nincreases the likelihood of finding such beneficial structures. Building on\nthese insights, we introduce Structure-Guided GNN (SG-GNN), an architecture\nthat processes the original graph alongside the newly created structural\ngraphs, adaptively learning to weigh their contributions. Extensive experiments\non various benchmark datasets, particularly those with heterophilic\ncharacteristics, demonstrate that our SG-GNN achieves state-of-the-art or\nhighly competitive performance, highlighting the efficacy of exploiting\nstructural information to guide GNNs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u6784\u5f15\u5bfc\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\uff08SG-GNN\uff09\uff0c\u901a\u8fc7\u6784\u5efa\u5177\u6709\u66f4\u9ad8\u6807\u7b7e\u540c\u8d28\u6027\u7684\u65b0\u56fe\u7ed3\u6784\u6765\u63d0\u5347GNN\u5728\u5f02\u8d28\u6027\u6570\u636e\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "GNN\u901a\u5e38\u5047\u8bbe\u540c\u8d28\u6027\uff0c\u4f46\u5728\u5f02\u8d28\u6027\u6570\u636e\uff08\u8fde\u63a5\u8282\u70b9\u6807\u7b7e\u4e0d\u540c\uff09\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u56e0\u6b64\u9700\u8981\u6539\u8fdb\u3002", "method": "\u901a\u8fc7\u8fde\u63a5\u5177\u6709\u76f8\u4f3c\u7ed3\u6784\u5c5e\u6027\u7684\u8282\u70b9\u521b\u5efa\u65b0\u56fe\u7ed3\u6784\uff0c\u5e76\u5f15\u5165SG-GNN\uff0c\u81ea\u9002\u5e94\u5730\u5b66\u4e60\u539f\u59cb\u56fe\u548c\u65b0\u56fe\u7684\u6743\u91cd\u3002", "result": "\u5728\u591a\u4e2a\u5f02\u8d28\u6027\u6570\u636e\u96c6\u4e0a\uff0cSG-GNN\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u6216\u6781\u5177\u7ade\u4e89\u529b\u7684\u6027\u80fd\u3002", "conclusion": "\u5229\u7528\u7ed3\u6784\u4fe1\u606f\u5f15\u5bfcGNN\u80fd\u6709\u6548\u63d0\u5347\u5176\u5728\u5f02\u8d28\u6027\u6570\u636e\u4e0a\u7684\u8868\u73b0\u3002"}}
{"id": "2506.08882", "pdf": "https://arxiv.org/pdf/2506.08882", "abs": "https://arxiv.org/abs/2506.08882", "authors": ["Dimitrios Amaxilatis", "Themistoklis Sarantakos", "Ioannis Chatzigiannakis", "Georgios Mylonas"], "title": "Filling in the Blanks: Applying Data Imputation in incomplete Water Metering Data", "categories": ["cs.LG"], "comment": null, "summary": "In this work, we explore the application of recent data imputation techniques\nto enhance monitoring and management of water distribution networks using smart\nwater meters, based on data derived from a real-world IoT water grid monitoring\ndeployment. Despite the detailed data produced by such meters, data gaps due to\ntechnical issues can significantly impact operational decisions and efficiency.\nOur results, by comparing various imputation methods, such as k-Nearest\nNeighbors, MissForest, Transformers, and Recurrent Neural Networks, indicate\nthat effective data imputation can substantially enhance the quality of the\ninsights derived from water consumption data as we study their effect on\naccuracy and reliability of water metering data to provide solutions in\napplications like leak detection and predictive maintenance scheduling.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u6570\u636e\u586b\u8865\u6280\u672f\u5728\u6c34\u5206\u914d\u7f51\u7edc\u76d1\u6d4b\u4e2d\u7684\u5e94\u7528\uff0c\u6bd4\u8f83\u4e86\u591a\u79cd\u65b9\u6cd5\u5bf9\u6570\u636e\u8d28\u91cf\u548c\u53ef\u9760\u6027\u7684\u5f71\u54cd\u3002", "motivation": "\u667a\u80fd\u6c34\u8868\u6570\u636e\u5b58\u5728\u7f3a\u5931\uff0c\u5f71\u54cd\u51b3\u7b56\u6548\u7387\uff0c\u9700\u586b\u8865\u6280\u672f\u63d0\u5347\u6570\u636e\u8d28\u91cf\u3002", "method": "\u6bd4\u8f83\u4e86k\u8fd1\u90bb\u3001MissForest\u3001Transformer\u548c\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u7b49\u586b\u8865\u65b9\u6cd5\u3002", "result": "\u6709\u6548\u7684\u6570\u636e\u586b\u8865\u663e\u8457\u63d0\u5347\u4e86\u6c34\u6d88\u8017\u6570\u636e\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002", "conclusion": "\u586b\u8865\u6280\u672f\u53ef\u4f18\u5316\u6f0f\u635f\u68c0\u6d4b\u548c\u9884\u6d4b\u6027\u7ef4\u62a4\u7b49\u5e94\u7528\u3002"}}
{"id": "2506.08884", "pdf": "https://arxiv.org/pdf/2506.08884", "abs": "https://arxiv.org/abs/2506.08884", "authors": ["Shiqin Tang", "Shujian Yu"], "title": "InfoDPCCA: Information-Theoretic Dynamic Probabilistic Canonical Correlation Analysis", "categories": ["cs.LG", "cs.IT", "math.IT"], "comment": "accepted by UAI-25, code is available at\n  \\url{https://github.com/marcusstang/InfoDPCCA}", "summary": "Extracting meaningful latent representations from high-dimensional sequential\ndata is a crucial challenge in machine learning, with applications spanning\nnatural science and engineering. We introduce InfoDPCCA, a dynamic\nprobabilistic Canonical Correlation Analysis (CCA) framework designed to model\ntwo interdependent sequences of observations. InfoDPCCA leverages a novel\ninformation-theoretic objective to extract a shared latent representation that\ncaptures the mutual structure between the data streams and balances\nrepresentation compression and predictive sufficiency while also learning\nseparate latent components that encode information specific to each sequence.\nUnlike prior dynamic CCA models, such as DPCCA, our approach explicitly\nenforces the shared latent space to encode only the mutual information between\nthe sequences, improving interpretability and robustness. We further introduce\na two-step training scheme to bridge the gap between information-theoretic\nrepresentation learning and generative modeling, along with a residual\nconnection mechanism to enhance training stability. Through experiments on\nsynthetic and medical fMRI data, we demonstrate that InfoDPCCA excels as a tool\nfor representation learning. Code of InfoDPCCA is available at\nhttps://github.com/marcusstang/InfoDPCCA.", "AI": {"tldr": "InfoDPCCA\u662f\u4e00\u79cd\u52a8\u6001\u6982\u7387CCA\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u53d6\u4e24\u4e2a\u76f8\u5173\u5e8f\u5217\u7684\u5171\u4eab\u6f5c\u5728\u8868\u793a\uff0c\u540c\u65f6\u5b66\u4e60\u5e8f\u5217\u7279\u5b9a\u7684\u4fe1\u606f\u3002", "motivation": "\u4ece\u9ad8\u7ef4\u5e8f\u5217\u6570\u636e\u4e2d\u63d0\u53d6\u6709\u610f\u4e49\u7684\u6f5c\u5728\u8868\u793a\u662f\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u5c24\u5176\u5728\u81ea\u7136\u79d1\u5b66\u548c\u5de5\u7a0b\u9886\u57df\u3002", "method": "\u91c7\u7528\u4fe1\u606f\u8bba\u76ee\u6807\u63d0\u53d6\u5171\u4eab\u6f5c\u5728\u8868\u793a\uff0c\u7ed3\u5408\u4e24\u6b65\u8bad\u7ec3\u65b9\u6848\u548c\u6b8b\u5dee\u8fde\u63a5\u673a\u5236\u3002", "result": "\u5728\u5408\u6210\u548c\u533b\u5b66fMRI\u6570\u636e\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "InfoDPCCA\u662f\u4e00\u79cd\u6709\u6548\u7684\u8868\u793a\u5b66\u4e60\u5de5\u5177\uff0c\u63d0\u9ad8\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2506.08889", "pdf": "https://arxiv.org/pdf/2506.08889", "abs": "https://arxiv.org/abs/2506.08889", "authors": ["Yizhao Gao", "Shuming Guo", "Shijie Cao", "Yuqing Xia", "Yu Cheng", "Lei Wang", "Lingxiao Ma", "Yutao Sun", "Tianzhu Ye", "Li Dong", "Hayden Kwok-Hay So", "Yu Hua", "Ting Cao", "Fan Yang", "Mao Yang"], "title": "SeerAttention-R: Sparse Attention Adaptation for Long Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We introduce SeerAttention-R, a sparse attention framework specifically\ntailored for the long decoding of reasoning models. Extended from\nSeerAttention, SeerAttention-R retains the design of learning attention\nsparsity through a self-distilled gating mechanism, while removing query\npooling to accommodate auto-regressive decoding. With a lightweight plug-in\ngating, SeerAttention-R is flexible and can be easily integrated into existing\npretrained model without modifying the original parameters. We demonstrate that\nSeerAttention-R, trained on just 0.4B tokens, maintains near-lossless reasoning\naccuracy with 4K token budget in AIME benchmark under large sparse attention\nblock sizes (64/128). Using TileLang, we develop a highly optimized sparse\ndecoding kernel that achieves near-theoretical speedups of up to 9x over\nFlashAttention-3 on H100 GPU at 90% sparsity. Code is available at:\nhttps://github.com/microsoft/SeerAttention.", "AI": {"tldr": "SeerAttention-R\u662f\u4e00\u4e2a\u7a00\u758f\u6ce8\u610f\u529b\u6846\u67b6\uff0c\u4e13\u4e3a\u63a8\u7406\u6a21\u578b\u7684\u957f\u89e3\u7801\u8bbe\u8ba1\uff0c\u901a\u8fc7\u81ea\u84b8\u998f\u95e8\u63a7\u673a\u5236\u5b66\u4e60\u6ce8\u610f\u529b\u7a00\u758f\u6027\uff0c\u5e76\u4f18\u5316\u89e3\u7801\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u957f\u89e3\u7801\u4efb\u52a1\u4e2d\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236\u7684\u6548\u7387\u548c\u6027\u80fd\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u63a8\u7406\u51c6\u786e\u6027\u3002", "method": "\u6269\u5c55SeerAttention\u6846\u67b6\uff0c\u79fb\u9664\u67e5\u8be2\u6c60\u5316\u4ee5\u9002\u5e94\u81ea\u56de\u5f52\u89e3\u7801\uff0c\u5e76\u5f15\u5165\u8f7b\u91cf\u7ea7\u95e8\u63a7\u673a\u5236\u3002", "result": "\u5728AIME\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4ec5\u75280.4B token\u8bad\u7ec3\uff0cSeerAttention-R\u57284K token\u9884\u7b97\u4e0b\u4fdd\u6301\u63a5\u8fd1\u65e0\u635f\u7684\u63a8\u7406\u51c6\u786e\u6027\uff0c\u5e76\u5728H100 GPU\u4e0a\u5b9e\u73b09\u500d\u901f\u5ea6\u63d0\u5347\u3002", "conclusion": "SeerAttention-R\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u7075\u6d3b\u7684\u7a00\u758f\u6ce8\u610f\u529b\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u957f\u89e3\u7801\u4efb\u52a1\uff0c\u4e14\u6613\u4e8e\u96c6\u6210\u5230\u73b0\u6709\u9884\u8bad\u7ec3\u6a21\u578b\u4e2d\u3002"}}
{"id": "2506.08902", "pdf": "https://arxiv.org/pdf/2506.08902", "abs": "https://arxiv.org/abs/2506.08902", "authors": ["Chongyi Zheng", "Seohong Park", "Sergey Levine", "Benjamin Eysenbach"], "title": "Intention-Conditioned Flow Occupancy Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large-scale pre-training has fundamentally changed how machine learning\nresearch is done today: large foundation models are trained once, and then can\nbe used by anyone in the community (including those without data or compute\nresources to train a model from scratch) to adapt and fine-tune to specific\ntasks. Applying this same framework to reinforcement learning (RL) is appealing\nbecause it offers compelling avenues for addressing core challenges in RL,\nincluding sample efficiency and robustness. However, there remains a\nfundamental challenge to pre-train large models in the context of RL: actions\nhave long-term dependencies, so training a foundation model that reasons across\ntime is important. Recent advances in generative AI have provided new tools for\nmodeling highly complex distributions. In this paper, we build a probabilistic\nmodel to predict which states an agent will visit in the temporally distant\nfuture (i.e., an occupancy measure) using flow matching. As large datasets are\noften constructed by many distinct users performing distinct tasks, we include\nin our model a latent variable capturing the user intention. This intention\nincreases the expressivity of our model, and enables adaptation with\ngeneralized policy improvement. We call our proposed method\nintention-conditioned flow occupancy models (InFOM). Comparing with alternative\nmethods for pre-training, our experiments on $36$ state-based and $4$\nimage-based benchmark tasks demonstrate that the proposed method achieves $1.8\n\\times$ median improvement in returns and increases success rates by $36\\%$.\nWebsite: https://chongyi-zheng.github.io/infom Code:\nhttps://github.com/chongyi-zheng/infom", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u610f\u56fe\u6761\u4ef6\u6d41\u5360\u7528\u6a21\u578b\uff08InFOM\uff09\u7684\u5f3a\u5316\u5b66\u4e60\u9884\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u9884\u6d4b\u672a\u6765\u72b6\u6001\u5206\u5e03\u548c\u7528\u6237\u610f\u56fe\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4efb\u52a1\u8868\u73b0\u3002", "motivation": "\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u4e2d\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u6311\u6218\uff0c\u5982\u52a8\u4f5c\u7684\u957f\u671f\u4f9d\u8d56\u6027\u548c\u6837\u672c\u6548\u7387\uff0c\u5229\u7528\u751f\u6210\u5f0fAI\u7684\u65b0\u5de5\u5177\u5efa\u6a21\u590d\u6742\u5206\u5e03\u3002", "method": "\u4f7f\u7528\u6d41\u5339\u914d\u6784\u5efa\u6982\u7387\u6a21\u578b\u9884\u6d4b\u672a\u6765\u72b6\u6001\u5206\u5e03\uff0c\u5f15\u5165\u7528\u6237\u610f\u56fe\u7684\u9690\u53d8\u91cf\u589e\u5f3a\u6a21\u578b\u8868\u8fbe\u80fd\u529b\uff0c\u652f\u6301\u5e7f\u4e49\u7b56\u7565\u6539\u8fdb\u3002", "result": "\u572836\u4e2a\u72b6\u6001\u57fa\u51c6\u548c4\u4e2a\u56fe\u50cf\u57fa\u51c6\u4efb\u52a1\u4e2d\uff0cInFOM\u65b9\u6cd5\u7684\u4e2d\u4f4d\u6570\u56de\u62a5\u63d0\u53471.8\u500d\uff0c\u6210\u529f\u7387\u63d0\u9ad836%\u3002", "conclusion": "InFOM\u901a\u8fc7\u5efa\u6a21\u672a\u6765\u72b6\u6001\u548c\u7528\u6237\u610f\u56fe\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5f3a\u5316\u5b66\u4e60\u9884\u8bad\u7ec3\u7684\u6548\u679c\uff0c\u4e3a\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2506.08916", "pdf": "https://arxiv.org/pdf/2506.08916", "abs": "https://arxiv.org/abs/2506.08916", "authors": ["Maria-Veronica Ciocanel", "John T. Nardini", "Kevin B. Flores", "Erica M. Rutter", "Suzanne S. Sindi", "Alexandria Volkening"], "title": "Enhancing generalizability of model discovery across parameter space with multi-experiment equation learning (ME-EQL)", "categories": ["cs.LG", "math.DS", "q-bio.QM"], "comment": "31 pages, 10 figures", "summary": "Agent-based modeling (ABM) is a powerful tool for understanding\nself-organizing biological systems, but it is computationally intensive and\noften not analytically tractable. Equation learning (EQL) methods can derive\ncontinuum models from ABM data, but they typically require extensive\nsimulations for each parameter set, raising concerns about generalizability. In\nthis work, we extend EQL to Multi-experiment equation learning (ME-EQL) by\nintroducing two methods: one-at-a-time ME-EQL (OAT ME-EQL), which learns\nindividual models for each parameter set and connects them via interpolation,\nand embedded structure ME-EQL (ES ME-EQL), which builds a unified model library\nacross parameters. We demonstrate these methods using a birth--death mean-field\nmodel and an on-lattice agent-based model of birth, death, and migration with\nspatial structure. Our results show that both methods significantly reduce the\nrelative error in recovering parameters from agent-based simulations, with OAT\nME-EQL offering better generalizability across parameter space. Our findings\nhighlight the potential of equation learning from multiple experiments to\nenhance the generalizability and interpretability of learned models for complex\nbiological systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e24\u79cd\u591a\u5b9e\u9a8c\u65b9\u7a0b\u5b66\u4e60\u65b9\u6cd5\uff08ME-EQL\uff09\uff0c\u901a\u8fc7\u63d2\u503c\u6216\u7edf\u4e00\u6a21\u578b\u5e93\u63d0\u9ad8\u4eceABM\u6570\u636e\u4e2d\u5b66\u4e60\u8fde\u7eed\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u65b9\u7a0b\u5b66\u4e60\u65b9\u6cd5\uff08EQL\uff09\u56e0\u9700\u5927\u91cf\u6a21\u62df\u800c\u6cdb\u5316\u6027\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faOAT ME-EQL\uff08\u9010\u4e2a\u53c2\u6570\u5b66\u4e60\u5e76\u63d2\u503c\uff09\u548cES ME-EQL\uff08\u8de8\u53c2\u6570\u7edf\u4e00\u6a21\u578b\u5e93\uff09\u4e24\u79cd\u65b9\u6cd5\u3002", "result": "\u4e24\u79cd\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u53c2\u6570\u6062\u590d\u8bef\u5dee\uff0cOAT ME-EQL\u5728\u53c2\u6570\u7a7a\u95f4\u6cdb\u5316\u6027\u66f4\u4f18\u3002", "conclusion": "\u591a\u5b9e\u9a8c\u65b9\u7a0b\u5b66\u4e60\u80fd\u63d0\u5347\u590d\u6742\u751f\u7269\u7cfb\u7edf\u6a21\u578b\u7684\u6cdb\u5316\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2506.08928", "pdf": "https://arxiv.org/pdf/2506.08928", "abs": "https://arxiv.org/abs/2506.08928", "authors": ["Zhongyuan Liang", "Zachary T. Rewolinski", "Abhineet Agarwal", "Tiffany M. Tang", "Bin Yu"], "title": "Local MDI+: Local Feature Importances for Tree-Based Models", "categories": ["cs.LG", "stat.ME", "stat.ML"], "comment": null, "summary": "Tree-based ensembles such as random forests remain the go-to for tabular data\nover deep learning models due to their prediction performance and computational\nefficiency. These advantages have led to their widespread deployment in\nhigh-stakes domains, where interpretability is essential for ensuring\ntrustworthy predictions. This has motivated the development of popular local\n(i.e. sample-specific) feature importance (LFI) methods such as LIME and\nTreeSHAP. However, these approaches rely on approximations that ignore the\nmodel's internal structure and instead depend on potentially unstable\nperturbations. These issues are addressed in the global setting by MDI+, a\nfeature importance method which exploits an equivalence between decision trees\nand linear models on a transformed node basis. However, the global MDI+ scores\nare not able to explain predictions when faced with heterogeneous individual\ncharacteristics. To address this gap, we propose Local MDI+ (LMDI+), a novel\nextension of the MDI+ framework to the sample specific setting. LMDI+\noutperforms existing baselines LIME and TreeSHAP in identifying\ninstance-specific signal features, averaging a 10% improvement in downstream\ntask performance across twelve real-world benchmark datasets. It further\ndemonstrates greater stability by consistently producing similar instance-level\nfeature importance rankings across multiple random forest fits. Finally, LMDI+\nenables local interpretability use cases, including the identification of\ncloser counterfactuals and the discovery of homogeneous subgroups.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLMDI+\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u73b0\u6709\u5c40\u90e8\u7279\u5f81\u91cd\u8981\u6027\u65b9\u6cd5\uff08\u5982LIME\u548cTreeSHAP\uff09\u7684\u4e0d\u8db3\uff0c\u901a\u8fc7\u6269\u5c55\u5168\u5c40MDI+\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u6027\u80fd\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u5728\u9700\u8981\u53ef\u89e3\u91ca\u6027\u7684\u9ad8\u98ce\u9669\u9886\u57df\uff0c\u73b0\u6709\u5c40\u90e8\u7279\u5f81\u91cd\u8981\u6027\u65b9\u6cd5\u4f9d\u8d56\u8fd1\u4f3c\u4e14\u4e0d\u7a33\u5b9a\u7684\u6270\u52a8\uff0c\u65e0\u6cd5\u5145\u5206\u5229\u7528\u6a21\u578b\u5185\u90e8\u7ed3\u6784\u3002", "method": "\u63d0\u51faLocal MDI+\uff08LMDI+\uff09\uff0c\u5c06MDI+\u6846\u67b6\u6269\u5c55\u5230\u6837\u672c\u7279\u5b9a\u573a\u666f\uff0c\u5229\u7528\u51b3\u7b56\u6811\u4e0e\u7ebf\u6027\u6a21\u578b\u5728\u8282\u70b9\u57fa\u7840\u4e0a\u7684\u7b49\u4ef7\u6027\u3002", "result": "LMDI+\u572812\u4e2a\u771f\u5b9e\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5e73\u5747\u63d0\u534710%\u7684\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\uff0c\u5e76\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u7a33\u5b9a\u6027\u3002", "conclusion": "LMDI+\u4e0d\u4ec5\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u8fd8\u652f\u6301\u5c40\u90e8\u53ef\u89e3\u91ca\u6027\u7528\u4f8b\uff0c\u5982\u8bc6\u522b\u66f4\u63a5\u8fd1\u7684\u53cd\u4e8b\u5b9e\u548c\u53d1\u73b0\u540c\u8d28\u5b50\u7ec4\u3002"}}
{"id": "2506.08936", "pdf": "https://arxiv.org/pdf/2506.08936", "abs": "https://arxiv.org/abs/2506.08936", "authors": ["Amina Mollaysa", "Artem Moskale", "Pushpak Pati", "Tommaso Mansi", "Mangal Prakash", "Rui Liao"], "title": "BioLangFusion: Multimodal Fusion of DNA, mRNA, and Protein Language Models", "categories": ["cs.LG"], "comment": "Proceedings of ICML 2025 Workshop on Multi-modal Foundation\n  Proceedings of ICML 2025 Workshop on Multi-modal Foundation Proceedings of\n  ICML 2025 Workshop on Multi-modal Foundation Models and Large Language Models\n  for Life Sciences", "summary": "We present BioLangFusion, a simple approach for integrating pre-trained DNA,\nmRNA, and protein language models into unified molecular representations.\nMotivated by the central dogma of molecular biology (information flow from gene\nto transcript to protein), we align per-modality embeddings at the biologically\nmeaningful codon level (three nucleotides encoding one amino acid) to ensure\ndirect cross-modal correspondence. BioLangFusion studies three standard fusion\ntechniques: (i) codon-level embedding concatenation, (ii) entropy-regularized\nattention pooling inspired by multiple-instance learning, and (iii) cross-modal\nmulti-head attention -- each technique providing a different inductive bias for\ncombining modality-specific signals. These methods require no additional\npre-training or modification of the base models, allowing straightforward\nintegration with existing sequence-based foundation models. Across five\nmolecular property prediction tasks, BioLangFusion outperforms strong unimodal\nbaselines, showing that even simple fusion of pre-trained models can capture\ncomplementary multi-omic information with minimal overhead.", "AI": {"tldr": "BioLangFusion\u6574\u5408DNA\u3001mRNA\u548c\u86cb\u767d\u8d28\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u4e09\u79cd\u878d\u5408\u6280\u672f\u5b9e\u73b0\u8de8\u6a21\u6001\u7edf\u4e00\u8868\u793a\uff0c\u65e0\u9700\u989d\u5916\u9884\u8bad\u7ec3\uff0c\u5728\u5206\u5b50\u5c5e\u6027\u9884\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u5355\u6a21\u6001\u57fa\u7ebf\u3002", "motivation": "\u57fa\u4e8e\u5206\u5b50\u751f\u7269\u5b66\u7684\u4e2d\u5fc3\u6cd5\u5219\uff08\u57fa\u56e0\u5230\u8f6c\u5f55\u5230\u86cb\u767d\u8d28\u7684\u4fe1\u606f\u6d41\uff09\uff0c\u901a\u8fc7\u751f\u7269\u610f\u4e49\u660e\u786e\u7684\u5bc6\u7801\u5b50\u7ea7\u522b\u5bf9\u9f50\uff0c\u5b9e\u73b0\u8de8\u6a21\u6001\u76f4\u63a5\u5bf9\u5e94\u3002", "method": "\u91c7\u7528\u4e09\u79cd\u6807\u51c6\u878d\u5408\u6280\u672f\uff1a(i) \u5bc6\u7801\u5b50\u7ea7\u5d4c\u5165\u62fc\u63a5\uff0c(ii) \u57fa\u4e8e\u591a\u5b9e\u4f8b\u5b66\u4e60\u7684\u71b5\u6b63\u5219\u5316\u6ce8\u610f\u529b\u6c60\u5316\uff0c(iii) \u8de8\u6a21\u6001\u591a\u5934\u6ce8\u610f\u529b\u3002", "result": "\u5728\u4e94\u4e2a\u5206\u5b50\u5c5e\u6027\u9884\u6d4b\u4efb\u52a1\u4e2d\uff0cBioLangFusion\u8868\u73b0\u4f18\u4e8e\u5355\u6a21\u6001\u57fa\u7ebf\uff0c\u8868\u660e\u7b80\u5355\u878d\u5408\u9884\u8bad\u7ec3\u6a21\u578b\u5373\u53ef\u9ad8\u6548\u6355\u83b7\u591a\u7ec4\u5b66\u4e92\u8865\u4fe1\u606f\u3002", "conclusion": "BioLangFusion\u5c55\u793a\u4e86\u9884\u8bad\u7ec3\u6a21\u578b\u7b80\u5355\u878d\u5408\u7684\u6f5c\u529b\uff0c\u80fd\u4ee5\u6700\u5c0f\u5f00\u9500\u6574\u5408\u591a\u6a21\u6001\u4fe1\u606f\u3002"}}
{"id": "2506.08939", "pdf": "https://arxiv.org/pdf/2506.08939", "abs": "https://arxiv.org/abs/2506.08939", "authors": ["Hang Ye", "Gaoxiang Duan", "Haoran Zeng", "Yangxin Zhu", "Lingxue Meng", "Xiaoying Zheng", "Yongxin Zhu"], "title": "KARMA: A Multilevel Decomposition Hybrid Mamba Framework for Multivariate Long-Term Time Series Forecasting", "categories": ["cs.LG"], "comment": "10 pages,3 figures, published to WASA2025", "summary": "Multivariate long-term and efficient time series forecasting is a key\nrequirement for a variety of practical applications, and there are complex\ninterleaving time dynamics in time series data that require decomposition\nmodeling. Traditional time series decomposition methods are single and rely on\nfixed rules, which are insufficient for mining the potential information of the\nseries and adapting to the dynamic characteristics of complex series. On the\nother hand, the Transformer-based models for time series forecasting struggle\nto effectively model long sequences and intricate dynamic relationships due to\ntheir high computational complexity. To overcome these limitations, we\nintroduce KARMA, with an Adaptive Time Channel Decomposition module (ATCD) to\ndynamically extract trend and seasonal components. It further integrates a\nHybrid Frequency-Time Decomposition module (HFTD) to further decompose Series\ninto frequency-domain and time-domain. These components are coupled with\nmulti-scale Mamba-based KarmaBlock to efficiently process global and local\ninformation in a coordinated manner. Experiments on eight real-world datasets\nfrom diverse domains well demonstrated that KARMA significantly outperforms\nmainstream baseline methods in both predictive accuracy and computational\nefficiency. Code and full results are available at this repository:\nhttps://github.com/yedadasd/KARMA", "AI": {"tldr": "KARMA\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u65f6\u95f4\u901a\u9053\u5206\u89e3\u6a21\u5757\uff08ATCD\uff09\u548c\u6df7\u5408\u9891\u65f6\u5206\u89e3\u6a21\u5757\uff08HFTD\uff09\uff0c\u7ed3\u5408\u591a\u5c3a\u5ea6Mamba-based KarmaBlock\uff0c\u663e\u8457\u63d0\u5347\u4e86\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u7cbe\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u65f6\u95f4\u5e8f\u5217\u5206\u89e3\u65b9\u6cd5\u56fa\u5b9a\u4e14\u5355\u4e00\uff0c\u65e0\u6cd5\u6316\u6398\u6f5c\u5728\u4fe1\u606f\uff1bTransformer\u6a21\u578b\u56e0\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u96be\u4ee5\u5904\u7406\u957f\u5e8f\u5217\u548c\u590d\u6742\u52a8\u6001\u5173\u7cfb\u3002", "method": "KARMA\u901a\u8fc7ATCD\u52a8\u6001\u63d0\u53d6\u8d8b\u52bf\u548c\u5b63\u8282\u6027\u6210\u5206\uff0cHFTD\u8fdb\u4e00\u6b65\u5206\u89e3\u5e8f\u5217\u4e3a\u9891\u57df\u548c\u65f6\u57df\uff0c\u7ed3\u5408KarmaBlock\u9ad8\u6548\u5904\u7406\u5168\u5c40\u548c\u5c40\u90e8\u4fe1\u606f\u3002", "result": "\u5728\u516b\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0cKARMA\u5728\u9884\u6d4b\u7cbe\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u5747\u663e\u8457\u4f18\u4e8e\u4e3b\u6d41\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "KARMA\u901a\u8fc7\u52a8\u6001\u5206\u89e3\u548c\u9ad8\u6548\u4fe1\u606f\u5904\u7406\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u548cTransformer\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2506.08961", "pdf": "https://arxiv.org/pdf/2506.08961", "abs": "https://arxiv.org/abs/2506.08961", "authors": ["Chenxu Wang", "Huaping Liu"], "title": "Towards Robust Deep Reinforcement Learning against Environmental State Perturbation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Adversarial attacks and robustness in Deep Reinforcement Learning (DRL) have\nbeen widely studied in various threat models; however, few consider\nenvironmental state perturbations, which are natural in embodied scenarios. To\nimprove the robustness of DRL agents, we formulate the problem of environmental\nstate perturbation, introducing a preliminary non-targeted attack method as a\ncalibration adversary, and then propose a defense framework, named Boosted\nAdversarial Training (BAT), which first tunes the agents via supervised\nlearning to avoid catastrophic failure and subsequently adversarially trains\nthe agent with reinforcement learning. Extensive experimental results\nsubstantiate the vulnerability of mainstream agents under environmental state\nperturbations and the effectiveness of our proposed attack. The defense results\ndemonstrate that while existing robust reinforcement learning algorithms may\nnot be suitable, our BAT framework can significantly enhance the robustness of\nagents against environmental state perturbations across various situations.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u4e2d\u73af\u5883\u72b6\u6001\u6270\u52a8\u7684\u5bf9\u6297\u653b\u51fb\u4e0e\u9632\u5fa1\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aBAT\u7684\u9632\u5fa1\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7406\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8f83\u5c11\u5173\u6ce8\u73af\u5883\u72b6\u6001\u6270\u52a8\uff0c\u800c\u8fd9\u7c7b\u6270\u52a8\u5728\u5177\u4f53\u573a\u666f\u4e2d\u5f88\u5e38\u89c1\u3002\u4e3a\u63d0\u9ad8DRL\u4ee3\u7406\u7684\u9c81\u68d2\u6027\uff0c\u8bba\u6587\u63a2\u8ba8\u4e86\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u9996\u5148\u63d0\u51fa\u4e00\u79cd\u975e\u76ee\u6807\u653b\u51fb\u65b9\u6cd5\u4f5c\u4e3a\u6821\u51c6\u5bf9\u624b\uff0c\u968f\u540e\u63d0\u51faBAT\u9632\u5fa1\u6846\u67b6\uff0c\u7ed3\u5408\u76d1\u7763\u5b66\u4e60\u548c\u5bf9\u6297\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u4e3b\u6d41\u4ee3\u7406\u5728\u73af\u5883\u72b6\u6001\u6270\u52a8\u4e0b\u7684\u8106\u5f31\u6027\u53caBAT\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "conclusion": "BAT\u6846\u67b6\u80fd\u663e\u8457\u63d0\u5347\u4ee3\u7406\u5728\u5404\u79cd\u73af\u5883\u72b6\u6001\u6270\u52a8\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u800c\u73b0\u6709\u7b97\u6cd5\u53ef\u80fd\u4e0d\u9002\u7528\u3002"}}
{"id": "2506.08965", "pdf": "https://arxiv.org/pdf/2506.08965", "abs": "https://arxiv.org/abs/2506.08965", "authors": ["Yiyang Zhao", "Huiyu Bai", "Xuejiao Zhao"], "title": "GFRIEND: Generative Few-shot Reward Inference through EfficieNt DPO", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The ability to train high-performing reward models with few-shot data is\ncritical for enhancing the efficiency and scalability of Reinforcement Learning\nfrom Human Feedback (RLHF). We propose a data augmentation and expansion\nframework that enables generative reward models trained on small datasets to\nachieve comparable performance to those trained on large-scale datasets.\nTraditional methods to train a generative reward model, such as Direct\nPreference Optimization (DPO), are constrained by inefficiencies in sample\npairing and limited data diversity. This work introduces preference refinement,\nwhich employs Chain-of-Thought (CoT) sampling to uncover diverse and\nhigh-quality preference relationships. It also incorporates a perplexity-based\nscoring mechanism to assign nuanced preference levels and utilizes Multi-level\nDirect Preference Optimization (M-DPO) to enable the model to capture\nfiner-grained preference differences between samples. Experimental results\ndemonstrate that the proposed method significantly enhances data efficiency and\nmodel performance, enabling reward models trained in a few-shot setting to\nachieve results on par with those trained on large-scale datasets. This study\nunderscores the potential of data-efficient strategies in advancing reward\nmodel optimization, offering a robust solution for low-resource RLHF\napplications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6570\u636e\u589e\u5f3a\u548c\u6269\u5c55\u6846\u67b6\uff0c\u901a\u8fc7\u504f\u597d\u7ec6\u5316\u548c\u591a\u7ea7\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08M-DPO\uff09\uff0c\u5728\u5c0f\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u751f\u6210\u5956\u52b1\u6a21\u578b\uff0c\u6027\u80fd\u5ab2\u7f8e\u5927\u89c4\u6a21\u6570\u636e\u96c6\u8bad\u7ec3\u7684\u7ed3\u679c\u3002", "motivation": "\u63d0\u5347\u4ece\u4eba\u7c7b\u53cd\u9988\u4e2d\u5f3a\u5316\u5b66\u4e60\uff08RLHF\uff09\u7684\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u6837\u672c\u914d\u5bf9\u548c\u6570\u636e\u591a\u6837\u6027\u4e0a\u7684\u4e0d\u8db3\u3002", "method": "\u91c7\u7528\u504f\u597d\u7ec6\u5316\uff08Chain-of-Thought\u91c7\u6837\uff09\u548c\u56f0\u60d1\u5ea6\u8bc4\u5206\u673a\u5236\uff0c\u7ed3\u5408\u591a\u7ea7\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08M-DPO\uff09\u6765\u6355\u6349\u7ec6\u7c92\u5ea6\u504f\u597d\u5dee\u5f02\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u6570\u636e\u6548\u7387\u548c\u6a21\u578b\u6027\u80fd\uff0c\u5c0f\u6837\u672c\u8bad\u7ec3\u7684\u5956\u52b1\u6a21\u578b\u6027\u80fd\u4e0e\u5927\u89c4\u6a21\u6570\u636e\u96c6\u8bad\u7ec3\u76f8\u5f53\u3002", "conclusion": "\u6570\u636e\u9ad8\u6548\u7b56\u7565\u5728\u5956\u52b1\u6a21\u578b\u4f18\u5316\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4e3a\u4f4e\u8d44\u6e90RLHF\u5e94\u7528\u63d0\u4f9b\u4e86\u7a33\u5065\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.08977", "pdf": "https://arxiv.org/pdf/2506.08977", "abs": "https://arxiv.org/abs/2506.08977", "authors": ["Victoria Hankemeier", "Malte Schilling"], "title": "Tailored Architectures for Time Series Forecasting: Evaluating Deep Learning Models on Gaussian Process-Generated Data", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at IJCNN25, Code: https://github.com/vicky-hnk/time-flex", "summary": "Developments in Deep Learning have significantly improved time series\nforecasting by enabling more accurate modeling of complex temporal dependencies\ninherent in sequential data. The effectiveness of such models is often\ndemonstrated on limited sets of specific real-world data. Although this allows\nfor comparative analysis, it still does not demonstrate how specific data\ncharacteristics align with the architectural strengths of individual models.\nOur research aims at uncovering clear connections between time series\ncharacteristics and particular models. We introduce a novel dataset generated\nusing Gaussian Processes, specifically designed to display distinct, known\ncharacteristics for targeted evaluations of model adaptability to them.\nFurthermore, we present TimeFlex, a new model that incorporates a modular\narchitecture tailored to handle diverse temporal dynamics, including trends and\nperiodic patterns. This model is compared to current state-of-the-art models,\noffering a deeper understanding of how models perform under varied time series\nconditions.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u6570\u636e\u96c6\u548c\u6a21\u578bTimeFlex\uff0c\u7528\u4e8e\u7814\u7a76\u65f6\u95f4\u5e8f\u5217\u7279\u6027\u4e0e\u6a21\u578b\u6027\u80fd\u7684\u5173\u7cfb\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u63ed\u793a\u65f6\u95f4\u5e8f\u5217\u7279\u6027\u4e0e\u7279\u5b9a\u6a21\u578b\u6027\u80fd\u4e4b\u95f4\u7684\u660e\u786e\u8054\u7cfb\uff0c\u586b\u8865\u73b0\u6709\u7814\u7a76\u5728\u6a21\u578b\u9002\u5e94\u6027\u8bc4\u4f30\u4e0a\u7684\u4e0d\u8db3\u3002", "method": "\u4f7f\u7528\u9ad8\u65af\u8fc7\u7a0b\u751f\u6210\u5177\u6709\u5df2\u77e5\u7279\u6027\u7684\u65b0\u6570\u636e\u96c6\uff0c\u5e76\u5f00\u53d1\u6a21\u5757\u5316\u67b6\u6784\u6a21\u578bTimeFlex\uff0c\u4ee5\u5904\u7406\u591a\u6837\u5316\u7684\u65f6\u95f4\u52a8\u6001\u3002", "result": "TimeFlex\u5728\u591a\u6837\u65f6\u95f4\u5e8f\u5217\u6761\u4ef6\u4e0b\u8868\u73b0\u4f18\u5f02\uff0c\u63d0\u4f9b\u4e86\u6a21\u578b\u6027\u80fd\u7684\u6df1\u5165\u7406\u89e3\u3002", "conclusion": "\u7814\u7a76\u4e3a\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u63d0\u4f9b\u4e86\u66f4\u6e05\u6670\u7684\u6a21\u578b\u9009\u62e9\u4f9d\u636e\uff0cTimeFlex\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u9002\u5e94\u6027\u3002"}}
{"id": "2506.08978", "pdf": "https://arxiv.org/pdf/2506.08978", "abs": "https://arxiv.org/abs/2506.08978", "authors": ["Anna Langedijk", "Jaap Jumelet", "Willem Zuidema"], "title": "Propositional Logic for Probing Generalization in Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The extent to which neural networks are able to acquire and represent\nsymbolic rules remains a key topic of research and debate. Much current work\nfocuses on the impressive capabilities of large language models, as well as\ntheir often ill-understood failures on a wide range of reasoning tasks. In this\npaper, in contrast, we investigate the generalization behavior of three key\nneural architectures (Transformers, Graph Convolution Networks and LSTMs) in a\ncontrolled task rooted in propositional logic. The task requires models to\ngenerate satisfying assignments for logical formulas, making it a structured\nand interpretable setting for studying compositionality. We introduce a\nbalanced extension of an existing dataset to eliminate superficial patterns and\nenable testing on unseen operator combinations. Using this dataset, we evaluate\nthe ability of the three architectures to generalize beyond the training\ndistribution. While all models perform well in-distribution, we find that\ngeneralization to unseen patterns, particularly those involving negation,\nremains a significant challenge. Transformers fail to apply negation\ncompositionally, unless structural biases are introduced. Our findings\nhighlight persistent limitations in the ability of standard architectures to\nlearn systematic representations of logical operators, suggesting the need for\nstronger inductive biases to support robust rule-based reasoning.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u4e09\u79cd\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff08Transformers\u3001GCNs\u3001LSTMs\uff09\u5728\u547d\u9898\u903b\u8f91\u4efb\u52a1\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u53d1\u73b0\u5b83\u4eec\u5728\u5904\u7406\u672a\u89c1\u8fc7\u7684\u6a21\u5f0f\uff08\u5c24\u5176\u662f\u5426\u5b9a\u64cd\u4f5c\uff09\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u8868\u660e\u9700\u8981\u66f4\u5f3a\u7684\u5f52\u7eb3\u504f\u7f6e\u3002", "motivation": "\u63a2\u8ba8\u795e\u7ecf\u7f51\u7edc\u662f\u5426\u80fd\u83b7\u53d6\u548c\u8868\u793a\u7b26\u53f7\u89c4\u5219\uff0c\u7279\u522b\u662f\u5728\u547d\u9898\u903b\u8f91\u4efb\u52a1\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u6269\u5c55\u7684\u6570\u636e\u96c6\u8bc4\u4f30\u4e09\u79cd\u67b6\u6784\u5728\u751f\u6210\u903b\u8f91\u516c\u5f0f\u6ee1\u8db3\u8d4b\u503c\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u91cd\u70b9\u5173\u6ce8\u672a\u89c1\u8fc7\u7684\u64cd\u4f5c\u7ec4\u5408\u3002", "result": "\u6240\u6709\u6a21\u578b\u5728\u8bad\u7ec3\u5206\u5e03\u5185\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5bf9\u672a\u89c1\u6a21\u5f0f\uff08\u5c24\u5176\u662f\u5426\u5b9a\u64cd\u4f5c\uff09\u7684\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0cTransformers\u9700\u7ed3\u6784\u504f\u7f6e\u624d\u80fd\u7ec4\u5408\u6027\u5e94\u7528\u5426\u5b9a\u3002", "conclusion": "\u6807\u51c6\u67b6\u6784\u5728\u7cfb\u7edf\u5b66\u4e60\u903b\u8f91\u64cd\u4f5c\u8868\u793a\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u66f4\u5f3a\u7684\u5f52\u7eb3\u504f\u7f6e\u4ee5\u652f\u6301\u57fa\u4e8e\u89c4\u5219\u7684\u63a8\u7406\u3002"}}
{"id": "2506.08982", "pdf": "https://arxiv.org/pdf/2506.08982", "abs": "https://arxiv.org/abs/2506.08982", "authors": ["Ivan Rubachev", "Akim Kotelnikov", "Nikolay Kartashev"], "title": "On Finetuning Tabular Foundation Models", "categories": ["cs.LG"], "comment": null, "summary": "Foundation models are an emerging research direction in tabular deep\nlearning. Notably, TabPFNv2 recently claimed superior performance over\ntraditional GBDT-based methods on small-scale datasets using an in-context\nlearning paradigm, which does not adapt model parameters to target datasets.\nHowever, the optimal finetuning approach for adapting tabular foundational\nmodels, and how this adaptation reshapes their internal mechanisms, remains\nunderexplored. While prior works studied finetuning for earlier foundational\nmodels, inconsistent findings and TabPFNv2's unique architecture necessitate\nfresh investigation. To address these questions, we first systematically\nevaluate various finetuning strategies on diverse datasets. Our findings\nestablish full finetuning as the most practical solution for TabPFNv2 in terms\nof time-efficiency and effectiveness. We then investigate how finetuning alters\nTabPFNv2's inner mechanisms, drawing an analogy to retrieval-augmented models.\nWe reveal that the success of finetuning stems from the fact that after\ngradient-based adaptation, the dot products of the query-representations of\ntest objects and the key-representations of in-context training objects more\naccurately reflect their target similarity. This improved similarity allows\nfinetuned TabPFNv2 to better approximate target dependency by appropriately\nweighting relevant in-context samples, improving the retrieval-based prediction\nlogic. From the practical perspective, we managed to finetune TabPFNv2 on\ndatasets with up to 50K objects, observing performance improvements on almost\nall tasks. More precisely, on academic datasets with I.I.D. splits, finetuning\nallows TabPFNv2 to achieve state-of-the-art results, while on datasets with\ngradual temporal shifts and rich feature sets, TabPFNv2 is less stable and\nprior methods remain better.", "AI": {"tldr": "TabPFNv2\u662f\u4e00\u79cd\u65b0\u5174\u7684\u8868\u683c\u6df1\u5ea6\u5b66\u4e60\u57fa\u7840\u6a21\u578b\uff0c\u7814\u7a76\u53d1\u73b0\u5168\u5fae\u8c03\u662f\u5176\u6700\u5b9e\u7528\u7684\u4f18\u5316\u7b56\u7565\uff0c\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u5c24\u5176\u5728I.I.D.\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u6700\u4f18\u7ed3\u679c\u3002", "motivation": "\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u5fae\u8c03\u4f18\u5316TabPFNv2\u7684\u6027\u80fd\uff0c\u5e76\u7814\u7a76\u5fae\u8c03\u5982\u4f55\u6539\u53d8\u5176\u5185\u90e8\u673a\u5236\u3002", "method": "\u7cfb\u7edf\u8bc4\u4f30\u591a\u79cd\u5fae\u8c03\u7b56\u7565\uff0c\u5206\u6790\u5fae\u8c03\u5bf9\u6a21\u578b\u5185\u90e8\u673a\u5236\u7684\u5f71\u54cd\uff0c\u7c7b\u6bd4\u68c0\u7d22\u589e\u5f3a\u6a21\u578b\u3002", "result": "\u5168\u5fae\u8c03\u5728\u65f6\u95f4\u548c\u6548\u679c\u4e0a\u6700\u4f18\uff0c\u5fae\u8c03\u540e\u6a21\u578b\u80fd\u66f4\u51c6\u786e\u5730\u8861\u91cf\u6d4b\u8bd5\u5bf9\u8c61\u4e0e\u8bad\u7ec3\u5bf9\u8c61\u7684\u76f8\u4f3c\u6027\uff0c\u63d0\u5347\u6027\u80fd\u3002\u5728I.I.D.\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u6700\u4f18\uff0c\u4f46\u5728\u65f6\u5e8f\u53d8\u5316\u548c\u590d\u6742\u7279\u5f81\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4e0d\u7a33\u5b9a\u3002", "conclusion": "\u5168\u5fae\u8c03\u662fTabPFNv2\u7684\u6700\u4f73\u5b9e\u8df5\uff0c\u5c24\u5176\u5728I.I.D.\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u590d\u6742\u573a\u666f\u4e0b\u4ecd\u9700\u6539\u8fdb\u3002"}}
{"id": "2506.08989", "pdf": "https://arxiv.org/pdf/2506.08989", "abs": "https://arxiv.org/abs/2506.08989", "authors": ["Xiao Liang", "Zhong-Zhi Li", "Yeyun Gong", "Yang Wang", "Hengyuan Zhang", "Yelong Shen", "Ying Nian Wu", "Weizhu Chen"], "title": "SwS: Self-aware Weakness-driven Problem Synthesis in Reinforcement Learning for LLM Reasoning", "categories": ["cs.LG", "cs.CL"], "comment": "Reinforcement Learning; Large Language Models; LLM Reasoning", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has proven effective\nfor training large language models (LLMs) on complex reasoning tasks, such as\nmathematical problem solving. A prerequisite for the scalability of RLVR is a\nhigh-quality problem set with precise and verifiable answers. However, the\nscarcity of well-crafted human-labeled math problems and limited-verification\nanswers in existing distillation-oriented synthetic datasets limit their\neffectiveness in RL. Additionally, most problem synthesis strategies\nindiscriminately expand the problem set without considering the model's\ncapabilities, leading to low efficiency in generating useful questions. To\nmitigate this issue, we introduce a Self-aware Weakness-driven problem\nSynthesis framework (SwS) that systematically identifies model deficiencies and\nleverages them for problem augmentation. Specifically, we define weaknesses as\nquestions that the model consistently fails to learn through its iterative\nsampling during RL training. We then extract the core concepts from these\nfailure cases and synthesize new problems to strengthen the model's weak areas\nin subsequent augmented training, enabling it to focus on and gradually\novercome its weaknesses. Without relying on external knowledge distillation,\nour framework enables robust generalization byempowering the model to\nself-identify and address its weaknesses in RL, yielding average performance\ngains of 10.0% and 7.7% on 7B and 32B models across eight mainstream reasoning\nbenchmarks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u6211\u611f\u77e5\u7684\u5f31\u70b9\u9a71\u52a8\u95ee\u9898\u5408\u6210\u6846\u67b6\uff08SwS\uff09\uff0c\u901a\u8fc7\u8bc6\u522b\u6a21\u578b\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5f31\u70b9\u5e76\u9488\u5bf9\u6027\u751f\u6210\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u95ee\u9898\u5408\u6210\u65b9\u6cd5\u6548\u7387\u4f4e\u4e14\u672a\u8003\u8651\u6a21\u578b\u80fd\u529b\uff0c\u5bfc\u81f4\u5f3a\u5316\u5b66\u4e60\u6548\u679c\u53d7\u9650\u3002", "method": "\u5b9a\u4e49\u6a21\u578b\u5f31\u70b9\u4e3a\u6838\u5fc3\u6982\u5ff5\uff0c\u9488\u5bf9\u6027\u5408\u6210\u65b0\u95ee\u9898\u4ee5\u589e\u5f3a\u6a21\u578b\u5f31\u9879\u3002", "result": "\u57288\u4e2a\u4e3b\u6d41\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c7B\u548c32B\u6a21\u578b\u7684\u5e73\u5747\u6027\u80fd\u5206\u522b\u63d0\u534710.0%\u548c7.7%\u3002", "conclusion": "SwS\u6846\u67b6\u65e0\u9700\u5916\u90e8\u77e5\u8bc6\u84b8\u998f\uff0c\u901a\u8fc7\u81ea\u6211\u8bc6\u522b\u548c\u89e3\u51b3\u5f31\u70b9\u5b9e\u73b0\u4e86\u9c81\u68d2\u6cdb\u5316\u3002"}}
{"id": "2506.09007", "pdf": "https://arxiv.org/pdf/2506.09007", "abs": "https://arxiv.org/abs/2506.09007", "authors": ["Sophia Tang", "Yinuo Zhang", "Alexander Tong", "Pranam Chatterjee"], "title": "Branched Schr\u00f6dinger Bridge Matching", "categories": ["cs.LG"], "comment": null, "summary": "Predicting the intermediate trajectories between an initial and target\ndistribution is a central problem in generative modeling. Existing approaches,\nsuch as flow matching and Schr\\\"odinger Bridge Matching, effectively learn\nmappings between two distributions by modeling a single stochastic path.\nHowever, these methods are inherently limited to unimodal transitions and\ncannot capture branched or divergent evolution from a common origin to multiple\ndistinct outcomes. To address this, we introduce Branched Schr\\\"odinger Bridge\nMatching (BranchSBM), a novel framework that learns branched Schr\\\"odinger\nbridges. BranchSBM parameterizes multiple time-dependent velocity fields and\ngrowth processes, enabling the representation of population-level divergence\ninto multiple terminal distributions. We show that BranchSBM is not only more\nexpressive but also essential for tasks involving multi-path surface\nnavigation, modeling cell fate bifurcations from homogeneous progenitor states,\nand simulating diverging cellular responses to perturbations.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u6846\u67b6BranchSBM\uff0c\u7528\u4e8e\u5b66\u4e60\u5206\u652f\u7684Schr\u00f6dinger\u6865\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u6355\u6349\u591a\u8def\u5f84\u6f14\u5316\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\uff08\u5982\u6d41\u5339\u914d\u548cSchr\u00f6dinger\u6865\u5339\u914d\uff09\u53ea\u80fd\u5efa\u6a21\u5355\u4e00\u8def\u5f84\uff0c\u65e0\u6cd5\u5904\u7406\u4ece\u5171\u540c\u8d77\u6e90\u5230\u591a\u4e2a\u4e0d\u540c\u7ed3\u679c\u7684\u5206\u652f\u6f14\u5316\u3002", "method": "BranchSBM\u901a\u8fc7\u53c2\u6570\u5316\u591a\u4e2a\u65f6\u95f4\u4f9d\u8d56\u7684\u901f\u5ea6\u573a\u548c\u589e\u957f\u8fc7\u7a0b\uff0c\u5b9e\u73b0\u4e86\u5bf9\u591a\u7ec8\u7aef\u5206\u5e03\u7684\u5206\u652f\u6f14\u5316\u5efa\u6a21\u3002", "result": "BranchSBM\u4e0d\u4ec5\u66f4\u5177\u8868\u8fbe\u80fd\u529b\uff0c\u800c\u4e14\u5728\u591a\u8def\u5f84\u5bfc\u822a\u3001\u7ec6\u80de\u547d\u8fd0\u5206\u53c9\u548c\u7ec6\u80de\u54cd\u5e94\u6a21\u62df\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "BranchSBM\u4e3a\u89e3\u51b3\u591a\u8def\u5f84\u6f14\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u590d\u6742\u573a\u666f\u3002"}}
{"id": "2506.09010", "pdf": "https://arxiv.org/pdf/2506.09010", "abs": "https://arxiv.org/abs/2506.09010", "authors": ["Sebastian Schmidt", "Prasanga Dhungel", "Christoffer L\u00f6ffler", "Bj\u00f6rn Nieth", "Stephan G\u00fcnnemann", "Leo Schwinn"], "title": "Effective Data Pruning through Score Extrapolation", "categories": ["cs.LG"], "comment": null, "summary": "Training advanced machine learning models demands massive datasets, resulting\nin prohibitive computational costs. To address this challenge, data pruning\ntechniques identify and remove redundant training samples while preserving\nmodel performance. Yet, existing pruning techniques predominantly require a\nfull initial training pass to identify removable samples, negating any\nefficiency benefits for single training runs. To overcome this limitation, we\nintroduce a novel importance score extrapolation framework that requires\ntraining on only a small subset of data. We present two initial approaches in\nthis framework - k-nearest neighbors and graph neural networks - to accurately\npredict sample importance for the entire dataset using patterns learned from\nthis minimal subset. We demonstrate the effectiveness of our approach for 2\nstate-of-the-art pruning methods (Dynamic Uncertainty and TDDS), 4 different\ndatasets (CIFAR-10, CIFAR-100, Places-365, and ImageNet), and 3 training\nparadigms (supervised, unsupervised, and adversarial). Our results indicate\nthat score extrapolation is a promising direction to scale expensive score\ncalculation methods, such as pruning, data attribution, or other tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u91cd\u8981\u6027\u5206\u6570\u5916\u63a8\u6846\u67b6\uff0c\u4ec5\u9700\u8bad\u7ec3\u5c11\u91cf\u6570\u636e\u5373\u53ef\u9884\u6d4b\u6574\u4e2a\u6570\u636e\u96c6\u7684\u6837\u672c\u91cd\u8981\u6027\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u526a\u679d\u6280\u672f\u9700\u5b8c\u6574\u8bad\u7ec3\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u5927\u89c4\u6a21\u6570\u636e\u96c6\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u73b0\u6709\u526a\u679d\u6280\u672f\u9700\u5b8c\u6574\u8bad\u7ec3\uff0c\u6548\u7387\u4f4e\u3002", "method": "\u5f15\u5165\u91cd\u8981\u6027\u5206\u6570\u5916\u63a8\u6846\u67b6\uff0c\u57fa\u4e8e\u5c11\u91cf\u6570\u636e\u8bad\u7ec3\uff0c\u91c7\u7528k\u8fd1\u90bb\u548c\u56fe\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u6837\u672c\u91cd\u8981\u6027\u3002", "result": "\u5728\u591a\u79cd\u6570\u636e\u96c6\u548c\u8bad\u7ec3\u8303\u5f0f\u4e0b\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u9002\u7528\u4e8e\u52a8\u6001\u4e0d\u786e\u5b9a\u6027\u548cTDDS\u7b49\u526a\u679d\u65b9\u6cd5\u3002", "conclusion": "\u5206\u6570\u5916\u63a8\u662f\u6269\u5c55\u6602\u8d35\u5206\u6570\u8ba1\u7b97\u4efb\u52a1\uff08\u5982\u526a\u679d\u3001\u6570\u636e\u5f52\u56e0\uff09\u7684\u6709\u524d\u666f\u65b9\u5411\u3002"}}
{"id": "2506.09016", "pdf": "https://arxiv.org/pdf/2506.09016", "abs": "https://arxiv.org/abs/2506.09016", "authors": ["Ruiqi Zhang", "Daman Arora", "Song Mei", "Andrea Zanette"], "title": "SPEED-RL: Faster Training of Reasoning Models via Online Curriculum Learning", "categories": ["cs.LG"], "comment": "pre-print", "summary": "Training large language models with reinforcement learning (RL) against\nverifiable rewards significantly enhances their reasoning abilities, yet\nremains computationally expensive due to inefficient uniform prompt sampling.\nWe introduce Selective Prompting with Efficient Estimation of Difficulty\n(SPEED), an adaptive online RL curriculum that selectively chooses training\nexamples of intermediate difficulty to maximize learning efficiency.\nTheoretically, we establish that intermediate-difficulty prompts improve the\ngradient estimator's signal-to-noise ratio, accelerating convergence.\nEmpirically, our efficient implementation leads to 2x to 6x faster training\nwithout degrading accuracy, requires no manual tuning, and integrates\nseamlessly into standard RL algorithms.", "AI": {"tldr": "SPEED\u662f\u4e00\u79cd\u81ea\u9002\u5e94\u5728\u7ebfRL\u8bfe\u7a0b\uff0c\u901a\u8fc7\u9009\u62e9\u4e2d\u7b49\u96be\u5ea6\u7684\u8bad\u7ec3\u793a\u4f8b\u6765\u63d0\u9ad8\u5b66\u4e60\u6548\u7387\uff0c\u5b9e\u73b02x\u81f36x\u7684\u8bad\u7ec3\u52a0\u901f\u4e14\u4e0d\u5f71\u54cd\u51c6\u786e\u6027\u3002", "motivation": "\u4f20\u7edf\u5747\u5300\u91c7\u6837\u63d0\u793a\u7684\u65b9\u6cd5\u5728\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65f6\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u63d0\u51faSPEED\u65b9\u6cd5\uff0c\u9009\u62e9\u6027\u91c7\u6837\u4e2d\u7b49\u96be\u5ea6\u7684\u63d0\u793a\uff0c\u4f18\u5316\u68af\u5ea6\u4f30\u8ba1\u5668\u7684\u4fe1\u566a\u6bd4\u3002", "result": "\u5b9e\u9a8c\u663e\u793aSPEED\u5b9e\u73b02x\u81f36x\u7684\u8bad\u7ec3\u52a0\u901f\uff0c\u65e0\u9700\u624b\u52a8\u8c03\u53c2\u4e14\u4e0d\u5f71\u54cd\u51c6\u786e\u6027\u3002", "conclusion": "SPEED\u662f\u4e00\u79cd\u9ad8\u6548\u3001\u81ea\u9002\u5e94\u7684\u65b9\u6cd5\uff0c\u53ef\u65e0\u7f1d\u96c6\u6210\u5230\u6807\u51c6RL\u7b97\u6cd5\u4e2d\u3002"}}
{"id": "2506.09018", "pdf": "https://arxiv.org/pdf/2506.09018", "abs": "https://arxiv.org/abs/2506.09018", "authors": ["Marton Havasi", "Brian Karrer", "Itai Gat", "Ricky T. Q. Chen"], "title": "Edit Flows: Flow Matching with Edit Operations", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Autoregressive generative models naturally generate variable-length\nsequences, while non-autoregressive models struggle, often imposing rigid,\ntoken-wise structures. We propose Edit Flows, a non-autoregressive model that\novercomes these limitations by defining a discrete flow over sequences through\nedit operations-insertions, deletions, and substitutions. By modeling these\noperations within a Continuous-time Markov Chain over the sequence space, Edit\nFlows enable flexible, position-relative generation that aligns more closely\nwith the structure of sequence data. Our training method leverages an expanded\nstate space with auxiliary variables, making the learning process efficient and\ntractable. Empirical results show that Edit Flows outperforms both\nautoregressive and mask models on image captioning and significantly\noutperforms the mask construction in text and code generation.", "AI": {"tldr": "Edit Flows\u662f\u4e00\u79cd\u975e\u81ea\u56de\u5f52\u6a21\u578b\uff0c\u901a\u8fc7\u7f16\u8f91\u64cd\u4f5c\uff08\u63d2\u5165\u3001\u5220\u9664\u3001\u66ff\u6362\uff09\u5728\u5e8f\u5217\u7a7a\u95f4\u4e0a\u5b9a\u4e49\u79bb\u6563\u6d41\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u975e\u81ea\u56de\u5f52\u6a21\u578b\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u4f20\u7edf\u975e\u81ea\u56de\u5f52\u6a21\u578b\u5728\u751f\u6210\u53d8\u957f\u5e8f\u5217\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u901a\u5e38\u9700\u8981\u5f3a\u5236\u7684\u56fa\u5b9a\u7ed3\u6784\u3002Edit Flows\u65e8\u5728\u901a\u8fc7\u7075\u6d3b\u7684\u7f16\u8f91\u64cd\u4f5c\u66f4\u8d34\u8fd1\u5e8f\u5217\u6570\u636e\u7684\u771f\u5b9e\u7ed3\u6784\u3002", "method": "Edit Flows\u5229\u7528\u8fde\u7eed\u65f6\u95f4\u9a6c\u5c14\u53ef\u592b\u94fe\u5728\u5e8f\u5217\u7a7a\u95f4\u4e0a\u5efa\u6a21\u7f16\u8f91\u64cd\u4f5c\uff0c\u5e76\u901a\u8fc7\u6269\u5c55\u72b6\u6001\u7a7a\u95f4\u548c\u8f85\u52a9\u53d8\u91cf\u5b9e\u73b0\u9ad8\u6548\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cEdit Flows\u5728\u56fe\u50cf\u63cf\u8ff0\u751f\u6210\u4efb\u52a1\u4e0a\u4f18\u4e8e\u81ea\u56de\u5f52\u548c\u63a9\u7801\u6a21\u578b\uff0c\u5728\u6587\u672c\u548c\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u63a9\u7801\u6784\u9020\u65b9\u6cd5\u3002", "conclusion": "Edit Flows\u901a\u8fc7\u7075\u6d3b\u7684\u7f16\u8f91\u64cd\u4f5c\u548c\u9ad8\u6548\u8bad\u7ec3\u65b9\u6cd5\uff0c\u4e3a\u975e\u81ea\u56de\u5f52\u5e8f\u5217\u751f\u6210\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.09026", "pdf": "https://arxiv.org/pdf/2506.09026", "abs": "https://arxiv.org/abs/2506.09026", "authors": ["Amrith Setlur", "Matthew Y. R. Yang", "Charlie Snell", "Jeremy Greer", "Ian Wu", "Virginia Smith", "Max Simchowitz", "Aviral Kumar"], "title": "e3: Learning to Explore Enables Extrapolation of Test-Time Compute for LLMs", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Test-time scaling offers a promising path to improve LLM reasoning by\nutilizing more compute at inference time; however, the true promise of this\nparadigm lies in extrapolation (i.e., improvement in performance on hard\nproblems as LLMs keep \"thinking\" for longer, beyond the maximum token budget\nthey were trained on). Surprisingly, we find that most existing reasoning\nmodels do not extrapolate well. We show that one way to enable extrapolation is\nby training the LLM to perform in-context exploration: training the LLM to\neffectively spend its test time budget by chaining operations (such as\ngeneration, verification, refinement, etc.), or testing multiple hypotheses\nbefore it commits to an answer. To enable in-context exploration, we identify\nthree key ingredients as part of our recipe e3: (1) chaining skills that the\nbase LLM has asymmetric competence in, e.g., chaining verification (easy) with\ngeneration (hard), as a way to implement in-context search; (2) leveraging\n\"negative\" gradients from incorrect traces to amplify exploration during RL,\nresulting in longer search traces that chains additional asymmetries; and (3)\ncoupling task difficulty with training token budget during training via a\nspecifically-designed curriculum to structure in-context exploration. Our\nrecipe e3 produces the best known 1.7B model according to AIME'25 and HMMT'25\nscores, and extrapolates to 2x the training token budget. Our e3-1.7B model not\nonly attains high pass@1 scores, but also improves pass@k over the base model.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u6d4b\u8bd5\u65f6\u6269\u5c55\uff08test-time scaling\uff09\u63d0\u5347LLM\u63a8\u7406\u80fd\u529b\u7684\u65b9\u6cd5\uff0c\u91cd\u70b9\u5728\u4e8e\u5b9e\u73b0\u5916\u63a8\uff08extrapolation\uff09\uff0c\u5373\u6a21\u578b\u5728\u8d85\u51fa\u8bad\u7ec3\u65f6\u7684\u6700\u5927token\u9884\u7b97\u65f6\u4ecd\u80fd\u63d0\u5347\u6027\u80fd\u3002\u901a\u8fc7\u8bad\u7ec3LLM\u8fdb\u884c\u4e0a\u4e0b\u6587\u63a2\u7d22\uff08in-context exploration\uff09\uff0c\u7ed3\u5408\u4e09\u79cd\u5173\u952e\u8981\u7d20\uff08e3\u914d\u65b9\uff09\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u63a8\u7406\u6a21\u578b\u5728\u5916\u63a8\u6027\u80fd\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u65e0\u6cd5\u5145\u5206\u5229\u7528\u6d4b\u8bd5\u65f6\u7684\u8ba1\u7b97\u8d44\u6e90\u3002\u8bba\u6587\u65e8\u5728\u901a\u8fc7\u4e0a\u4e0b\u6587\u63a2\u7d22\u8bad\u7ec3\u65b9\u6cd5\uff0c\u4f7f\u6a21\u578b\u5728\u66f4\u957f\u601d\u8003\u65f6\u95f4\u5185\u6301\u7eed\u63d0\u5347\u6027\u80fd\u3002", "method": "\u63d0\u51fae3\u914d\u65b9\uff0c\u5305\u62ec\uff1a\uff081\uff09\u7ed3\u5408LLM\u4e0d\u5bf9\u79f0\u80fd\u529b\u7684\u64cd\u4f5c\u94fe\uff08\u5982\u9a8c\u8bc1\u4e0e\u751f\u6210\uff09\uff1b\uff082\uff09\u5229\u7528\u9519\u8bef\u8f68\u8ff9\u7684\u8d1f\u68af\u5ea6\u5f3a\u5316\u63a2\u7d22\uff1b\uff083\uff09\u901a\u8fc7\u7279\u5b9a\u8bbe\u8ba1\u7684\u8bfe\u7a0b\u5b66\u4e60\u5c06\u4efb\u52a1\u96be\u5ea6\u4e0e\u8bad\u7ec3token\u9884\u7b97\u8026\u5408\u3002", "result": "e3-1.7B\u6a21\u578b\u5728AIME'25\u548cHMMT'25\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u5916\u63a8\u80fd\u529b\u8fbe\u5230\u8bad\u7ec3token\u9884\u7b97\u76842\u500d\uff0c\u4e14\u5728pass@1\u548cpass@k\u6307\u6807\u4e0a\u5747\u4f18\u4e8e\u57fa\u7840\u6a21\u578b\u3002", "conclusion": "\u901a\u8fc7\u4e0a\u4e0b\u6587\u63a2\u7d22\u8bad\u7ec3\u65b9\u6cd5\uff0ce3\u914d\u65b9\u663e\u8457\u63d0\u5347\u4e86LLM\u7684\u5916\u63a8\u80fd\u529b\u548c\u63a8\u7406\u6027\u80fd\uff0c\u4e3a\u6d4b\u8bd5\u65f6\u6269\u5c55\u63d0\u4f9b\u4e86\u6709\u6548\u8def\u5f84\u3002"}}
{"id": "2506.09034", "pdf": "https://arxiv.org/pdf/2506.09034", "abs": "https://arxiv.org/abs/2506.09034", "authors": ["Sizhe Dang", "Yangyang Guo", "Yanjun Zhao", "Haishan Ye", "Xiaodong Zheng", "Guang Dai", "Ivor Tsang"], "title": "FZOO: Fast Zeroth-Order Optimizer for Fine-Tuning Large Language Models towards Adam-Scale Speed", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Fine-tuning large language models (LLMs) often faces GPU memory bottlenecks:\nthe backward pass of first-order optimizers like Adam increases memory usage to\nmore than 10 times the inference level (e.g., 633 GB for OPT-30B). Zeroth-order\n(ZO) optimizers avoid this cost by estimating gradients only from forward\npasses, yet existing methods like MeZO usually require many more steps to\nconverge. Can this trade-off between speed and memory in ZO be fundamentally\nimproved? Normalized-SGD demonstrates strong empirical performance with greater\nmemory efficiency than Adam. In light of this, we introduce FZOO, a Fast\nZeroth-Order Optimizer toward Adam-Scale Speed. FZOO reduces the total forward\npasses needed for convergence by employing batched one-sided estimates that\nadapt step sizes based on the standard deviation of batch losses. It also\naccelerates per-batch computation through the use of Rademacher random vector\nperturbations coupled with CUDA's parallel processing. Extensive experiments on\ndiverse models, including RoBERTa-large, OPT (350M-66B), Phi-2, and Llama3,\nacross 11 tasks validate FZOO's effectiveness. On average, FZOO outperforms\nMeZO by 3 percent in accuracy while requiring 3 times fewer forward passes. For\nRoBERTa-large, FZOO achieves average improvements of 5.6 percent in accuracy\nand an 18 times reduction in forward passes compared to MeZO, achieving\nconvergence speeds comparable to Adam. We also provide theoretical analysis\nproving FZOO's formal equivalence to a normalized-SGD update rule and its\nconvergence guarantees. FZOO integrates smoothly into PEFT techniques, enabling\neven larger memory savings. Overall, our results make single-GPU, high-speed,\nfull-parameter fine-tuning practical and point toward future work on\nmemory-efficient pre-training.", "AI": {"tldr": "FZOO\u662f\u4e00\u79cd\u5feb\u901f\u96f6\u9636\u4f18\u5316\u5668\uff0c\u663e\u8457\u51cf\u5c11\u6536\u655b\u6240\u9700\u7684\u524d\u5411\u4f20\u9012\u6b21\u6570\uff0c\u540c\u65f6\u4fdd\u6301\u4e0eAdam\u76f8\u5f53\u7684\u901f\u5ea6\uff0c\u9002\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u4e2dGPU\u5185\u5b58\u74f6\u9888\u95ee\u9898\uff0c\u73b0\u6709\u96f6\u9636\u4f18\u5316\u5668\uff08\u5982MeZO\uff09\u6536\u655b\u901f\u5ea6\u6162\u3002", "method": "FZOO\u91c7\u7528\u6279\u91cf\u5355\u8fb9\u4f30\u8ba1\u548c\u81ea\u9002\u5e94\u6b65\u957f\u8c03\u6574\uff0c\u7ed3\u5408CUDA\u5e76\u884c\u5904\u7406\u52a0\u901f\u8ba1\u7b97\u3002", "result": "FZOO\u572811\u4e2a\u4efb\u52a1\u4e2d\u5e73\u5747\u6bd4MeZO\u51c6\u786e\u7387\u63d0\u9ad83%\uff0c\u524d\u5411\u4f20\u9012\u6b21\u6570\u51cf\u5c113\u500d\uff1bRoBERTa-large\u4e0a\u51c6\u786e\u7387\u63d0\u53475.6%\uff0c\u524d\u5411\u4f20\u9012\u51cf\u5c1118\u500d\u3002", "conclusion": "FZOO\u5b9e\u73b0\u4e86\u5355GPU\u9ad8\u901f\u5168\u53c2\u6570\u5fae\u8c03\uff0c\u4e3a\u5185\u5b58\u9ad8\u6548\u9884\u8bad\u7ec3\u6307\u660e\u65b9\u5411\u3002"}}
{"id": "2506.09044", "pdf": "https://arxiv.org/pdf/2506.09044", "abs": "https://arxiv.org/abs/2506.09044", "authors": ["Javier Sanguino", "Thomas Kehrenberg", "Jose A. Lozano", "Novi Quadrianto"], "title": "The Decoupled Risk Landscape in Performative Prediction", "categories": ["cs.LG"], "comment": null, "summary": "Performative Prediction addresses scenarios where deploying a model induces a\ndistribution shift in the input data, such as individuals modifying their\nfeatures and reapplying for a bank loan after rejection. Literature has had a\ntheoretical perspective giving mathematical guarantees for convergence (either\nto the stable or optimal point). We believe that visualization of the loss\nlandscape can complement this theoretical advances with practical insights.\nTherefore, (1) we introduce a simple decoupled risk visualization method\ninspired in the two-step process that performative prediction is. Our approach\nvisualizes the risk landscape with respect to two parameter vectors: model\nparameters and data parameters. We use this method to propose new properties of\nthe interest points, to examine how existing algorithms traverse the risk\nlandscape and perform under more realistic conditions, including strategic\nclassification with non-linear models. (2) Building on this decoupled risk\nvisualization, we introduce a novel setting - extended Performative Prediction\n- which captures scenarios where the distribution reacts to a model different\nfrom the decision-making one, reflecting the reality that agents often lack\nfull access to the deployed model.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u89c6\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u8865\u5145Performative Prediction\u7684\u7406\u8bba\u7814\u7a76\uff0c\u5e76\u5f15\u5165\u6269\u5c55\u7684Performative Prediction\u65b0\u573a\u666f\u3002", "motivation": "\u73b0\u6709\u6587\u732e\u4e3b\u8981\u4ece\u7406\u8bba\u89d2\u5ea6\u7814\u7a76Performative Prediction\uff0c\u7f3a\u4e4f\u5b9e\u8df5\u89c6\u89d2\u3002\u901a\u8fc7\u53ef\u89c6\u5316\u635f\u5931\u666f\u89c2\uff0c\u53ef\u4ee5\u66f4\u76f4\u89c2\u5730\u7406\u89e3\u6a21\u578b\u4e0e\u6570\u636e\u7684\u4ea4\u4e92\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u89e3\u8026\u98ce\u9669\u53ef\u89c6\u5316\u65b9\u6cd5\uff0c\u5c06\u98ce\u9669\u666f\u89c2\u5206\u4e3a\u6a21\u578b\u53c2\u6570\u548c\u6570\u636e\u53c2\u6570\u4e24\u90e8\u5206\uff0c\u5e76\u57fa\u4e8e\u6b64\u5f15\u5165\u4e86\u6269\u5c55\u7684Performative Prediction\u573a\u666f\u3002", "result": "\u53ef\u89c6\u5316\u65b9\u6cd5\u63ed\u793a\u4e86\u5174\u8da3\u70b9\u7684\u65b0\u7279\u6027\uff0c\u5e76\u9a8c\u8bc1\u4e86\u73b0\u6709\u7b97\u6cd5\u5728\u66f4\u73b0\u5b9e\u6761\u4ef6\u4e0b\u7684\u8868\u73b0\u3002", "conclusion": "\u53ef\u89c6\u5316\u65b9\u6cd5\u4e3aPerformative Prediction\u63d0\u4f9b\u4e86\u5b9e\u8df5\u8865\u5145\uff0c\u6269\u5c55\u7684\u65b0\u573a\u666f\u66f4\u8d34\u8fd1\u73b0\u5b9e\u60c5\u51b5\u3002"}}
{"id": "2506.09046", "pdf": "https://arxiv.org/pdf/2506.09046", "abs": "https://arxiv.org/abs/2506.09046", "authors": ["Xiaowen Ma", "Chenyang Lin", "Yao Zhang", "Volker Tresp", "Yunpu Ma"], "title": "Agentic Neural Networks: Self-Evolving Multi-Agent Systems via Textual Backpropagation", "categories": ["cs.LG", "cs.AI", "cs.MA"], "comment": null, "summary": "Leveraging multiple Large Language Models(LLMs) has proven effective for\naddressing complex, high-dimensional tasks, but current approaches often rely\non static, manually engineered multi-agent configurations. To overcome these\nconstraints, we present the Agentic Neural Network(ANN), a framework that\nconceptualizes multi-agent collaboration as a layered neural network\narchitecture. In this design, each agent operates as a node, and each layer\nforms a cooperative \"team\" focused on a specific subtask. Agentic Neural\nNetwork follows a two-phase optimization strategy: (1) Forward Phase-Drawing\ninspiration from neural network forward passes, tasks are dynamically\ndecomposed into subtasks, and cooperative agent teams with suitable aggregation\nmethods are constructed layer by layer. (2) Backward Phase-Mirroring\nbackpropagation, we refine both global and local collaboration through\niterative feedback, allowing agents to self-evolve their roles, prompts, and\ncoordination. This neuro-symbolic approach enables ANN to create new or\nspecialized agent teams post-training, delivering notable gains in accuracy and\nadaptability. Across four benchmark datasets, ANN surpasses leading multi-agent\nbaselines under the same configurations, showing consistent performance\nimprovements. Our findings indicate that ANN provides a scalable, data-driven\nframework for multi-agent systems, combining the collaborative capabilities of\nLLMs with the efficiency and flexibility of neural network principles. We plan\nto open-source the entire framework.", "AI": {"tldr": "Agentic Neural Network\uff08ANN\uff09\u901a\u8fc7\u5c06\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u5efa\u6a21\u4e3a\u5206\u5c42\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u52a8\u6001\u5206\u89e3\u4efb\u52a1\u5e76\u4f18\u5316\u534f\u4f5c\uff0c\u663e\u8457\u63d0\u5347\u4e86\u51c6\u786e\u6027\u548c\u9002\u5e94\u6027\u3002", "motivation": "\u5f53\u524d\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4f9d\u8d56\u9759\u6001\u914d\u7f6e\uff0c\u9650\u5236\u4e86\u7075\u6d3b\u6027\u548c\u6027\u80fd\u3002ANN\u65e8\u5728\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u7684\u52a8\u6001\u6027\u548c\u53cd\u9988\u673a\u5236\uff0c\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u3002", "method": "ANN\u91c7\u7528\u4e24\u9636\u6bb5\u4f18\u5316\u7b56\u7565\uff1a\u524d\u5411\u9636\u6bb5\u52a8\u6001\u5206\u89e3\u4efb\u52a1\u5e76\u6784\u5efa\u534f\u4f5c\u56e2\u961f\uff1b\u540e\u5411\u9636\u6bb5\u901a\u8fc7\u53cd\u9988\u4f18\u5316\u5168\u5c40\u548c\u5c40\u90e8\u534f\u4f5c\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cANN\u5728\u76f8\u540c\u914d\u7f6e\u4e0b\u4f18\u4e8e\u73b0\u6709\u591a\u667a\u80fd\u4f53\u57fa\u7ebf\uff0c\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u9002\u5e94\u6027\u3002", "conclusion": "ANN\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u6570\u636e\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7ed3\u5408\u4e86LLM\u7684\u534f\u4f5c\u80fd\u529b\u548c\u795e\u7ecf\u7f51\u7edc\u7684\u9ad8\u6548\u6027\uff0c\u672a\u6765\u5c06\u5f00\u6e90\u3002"}}
{"id": "2506.09048", "pdf": "https://arxiv.org/pdf/2506.09048", "abs": "https://arxiv.org/abs/2506.09048", "authors": ["Yuxin Dong", "Jiachen Jiang", "Zhihui Zhu", "Xia Ning"], "title": "Understanding Task Vectors in In-Context Learning: Emergence, Functionality, and Limitations", "categories": ["cs.LG"], "comment": null, "summary": "Task vectors offer a compelling mechanism for accelerating inference in\nin-context learning (ICL) by distilling task-specific information into a\nsingle, reusable representation. Despite their empirical success, the\nunderlying principles governing their emergence and functionality remain\nunclear. This work proposes the Linear Combination Conjecture, positing that\ntask vectors act as single in-context demonstrations formed through linear\ncombinations of the original ones. We provide both theoretical and empirical\nsupport for this conjecture. First, we show that task vectors naturally emerge\nin linear transformers trained on triplet-formatted prompts through loss\nlandscape analysis. Next, we predict the failure of task vectors on\nrepresenting high-rank mappings and confirm this on practical LLMs. Our\nfindings are further validated through saliency analyses and parameter\nvisualization, suggesting an enhancement of task vectors by injecting multiple\nones into few-shot prompts. Together, our results advance the understanding of\ntask vectors and shed light on the mechanisms underlying ICL in\ntransformer-based models.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u7ebf\u6027\u7ec4\u5408\u731c\u60f3\uff0c\u8ba4\u4e3a\u4efb\u52a1\u5411\u91cf\u662f\u539f\u59cb\u6f14\u793a\u7684\u7ebf\u6027\u7ec4\u5408\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u4efb\u52a1\u5411\u91cf\u5728\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5176\u5de5\u4f5c\u539f\u7406\u5c1a\u4e0d\u660e\u786e\uff0c\u7814\u7a76\u65e8\u5728\u63ed\u793a\u5176\u673a\u5236\u3002", "method": "\u901a\u8fc7\u635f\u5931\u666f\u89c2\u5206\u6790\u9a8c\u8bc1\u4efb\u52a1\u5411\u91cf\u7684\u81ea\u7136\u6d8c\u73b0\uff0c\u5e76\u9884\u6d4b\u5176\u5728\u8868\u793a\u9ad8\u79e9\u6620\u5c04\u65f6\u7684\u5931\u8d25\u3002", "result": "\u5b9e\u9a8c\u8bc1\u5b9e\u4efb\u52a1\u5411\u91cf\u5728\u9ad8\u79e9\u6620\u5c04\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u4f46\u901a\u8fc7\u6ce8\u5165\u591a\u4e2a\u4efb\u52a1\u5411\u91cf\u53ef\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "\u7814\u7a76\u6df1\u5316\u4e86\u5bf9\u4efb\u52a1\u5411\u91cf\u7684\u7406\u89e3\uff0c\u63ed\u793a\u4e86\u57fa\u4e8eTransformer\u6a21\u578b\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u673a\u5236\u3002"}}
{"id": "2506.00160", "pdf": "https://arxiv.org/pdf/2506.00160", "abs": "https://arxiv.org/abs/2506.00160", "authors": ["Qihui Fan", "Enfu Nan", "Wenbo Li", "Lei Lu", "Pu Zhao", "Yanzhi Wang"], "title": "Werewolf: A Straightforward Game Framework with TTS for Improved User Engagement", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "The growing popularity of social deduction game systems for both business\napplications and AI research has greatly benefited from the rapid advancements\nin Large Language Models (LLMs), which now demonstrate stronger reasoning and\npersuasion capabilities. Especially with the raise of DeepSeek R1 and V3\nmodels, LLMs should enable a more engaging experience for human players in\nLLM-agent-based social deduction games like Werewolf. Previous works either\nfine-tuning, advanced prompting engineering, or additional experience pool to\nachieve engaging text-format Werewolf game experience. We propose a novel yet\nstraightforward LLM-based Werewolf game system with tuned Text-to-Speech(TTS)\nmodels designed for enhanced compatibility with various LLM models, and\nimproved user engagement. We argue with ever enhancing LLM reasoning, extra\ncomponents will be unnecessary in the case of Werewolf.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u72fc\u4eba\u6740\u6e38\u620f\u7cfb\u7edf\uff0c\u901a\u8fc7\u4f18\u5316\u7684TTS\u6a21\u578b\u63d0\u5347\u517c\u5bb9\u6027\u548c\u7528\u6237\u4f53\u9a8c\uff0c\u8ba4\u4e3a\u968f\u7740LLM\u63a8\u7406\u80fd\u529b\u7684\u589e\u5f3a\uff0c\u989d\u5916\u7ec4\u4ef6\u5c06\u4e0d\u518d\u5fc5\u8981\u3002", "motivation": "\u968f\u7740LLM\u63a8\u7406\u548c\u8bf4\u670d\u80fd\u529b\u7684\u63d0\u5347\uff0c\u7ed3\u5408\u793e\u4ea4\u63a8\u7406\u6e38\u620f\u7684\u6d41\u884c\uff0c\u672c\u6587\u65e8\u5728\u8bbe\u8ba1\u4e00\u4e2a\u66f4\u5438\u5f15\u4eba\u7684LLM\u4ee3\u7406\u72fc\u4eba\u6740\u6e38\u620f\u7cfb\u7edf\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u4e14\u76f4\u63a5\u7684\u57fa\u4e8eLLM\u7684\u72fc\u4eba\u6740\u7cfb\u7edf\uff0c\u7ed3\u5408\u4f18\u5316\u7684TTS\u6a21\u578b\uff0c\u65e0\u9700\u989d\u5916\u7ec4\u4ef6\u3002", "result": "\u7cfb\u7edf\u901a\u8fc7\u4f18\u5316\u7684TTS\u6a21\u578b\u63d0\u5347\u4e86\u4e0e\u591a\u79cdLLM\u6a21\u578b\u7684\u517c\u5bb9\u6027\uff0c\u5e76\u6539\u5584\u4e86\u7528\u6237\u53c2\u4e0e\u5ea6\u3002", "conclusion": "\u968f\u7740LLM\u63a8\u7406\u80fd\u529b\u7684\u6301\u7eed\u589e\u5f3a\uff0c\u72fc\u4eba\u6740\u6e38\u620f\u4e2d\u7684\u989d\u5916\u7ec4\u4ef6\u5c06\u53d8\u5f97\u591a\u4f59\u3002"}}
{"id": "2506.08023", "pdf": "https://arxiv.org/pdf/2506.08023", "abs": "https://arxiv.org/abs/2506.08023", "authors": ["Qifeng Wu", "Zhengzhe Liu", "Han Zhu", "Yizhou Zhao", "Daisuke Kihara", "Min Xu"], "title": "Aligning Proteins and Language: A Foundation Model for Protein Retrieval", "categories": ["q-bio.BM", "cs.AI", "cs.CE", "cs.CV", "cs.LG"], "comment": "4 pages for body, 3 pages for appendix, 11 figures. Accepted to CVPR\n  2025 Workshop on Multimodal Foundation Models for Biomedicine: Challenges and\n  Opportunities(MMFM-BIOMED)", "summary": "This paper aims to retrieve proteins with similar structures and semantics\nfrom large-scale protein dataset, facilitating the functional interpretation of\nprotein structures derived by structural determination methods like\ncryo-Electron Microscopy (cryo-EM). Motivated by the recent progress of\nvision-language models (VLMs), we propose a CLIP-style framework for aligning\n3D protein structures with functional annotations using contrastive learning.\nFor model training, we propose a large-scale dataset of approximately 200,000\nprotein-caption pairs with rich functional descriptors. We evaluate our model\nin both in-domain and more challenging cross-database retrieval on Protein Data\nBank (PDB) and Electron Microscopy Data Bank (EMDB) dataset, respectively. In\nboth cases, our approach demonstrates promising zero-shot retrieval\nperformance, highlighting the potential of multimodal foundation models for\nstructure-function understanding in protein biology.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eCLIP\u98ce\u683c\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u5bf9\u9f503D\u86cb\u767d\u8d28\u7ed3\u6784\u4e0e\u529f\u80fd\u6ce8\u91ca\uff0c\u7528\u4e8e\u5927\u89c4\u6a21\u86cb\u767d\u8d28\u6570\u636e\u96c6\u4e2d\u68c0\u7d22\u76f8\u4f3c\u7ed3\u6784\u548c\u8bed\u4e49\u7684\u86cb\u767d\u8d28\u3002", "motivation": "\u8fd1\u5e74\u6765\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u7684\u8fdb\u5c55\u4e3a\u86cb\u767d\u8d28\u7ed3\u6784\u4e0e\u529f\u80fd\u6ce8\u91ca\u7684\u5bf9\u9f50\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u65e8\u5728\u4fc3\u8fdb\u7ed3\u6784\u89e3\u6790\u65b9\u6cd5\uff08\u5982\u51b7\u51bb\u7535\u955c\uff09\u5f97\u5230\u7684\u86cb\u767d\u8d28\u7ed3\u6784\u7684\u529f\u80fd\u89e3\u91ca\u3002", "method": "\u91c7\u7528CLIP\u98ce\u683c\u7684\u6846\u67b6\uff0c\u5229\u7528\u5bf9\u6bd4\u5b66\u4e60\u5bf9\u9f503D\u86cb\u767d\u8d28\u7ed3\u6784\u4e0e\u529f\u80fd\u6ce8\u91ca\uff0c\u5e76\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u7ea620\u4e07\u86cb\u767d\u8d28-\u63cf\u8ff0\u5bf9\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\u7528\u4e8e\u6a21\u578b\u8bad\u7ec3\u3002", "result": "\u5728\u86cb\u767d\u8d28\u6570\u636e\u5e93\uff08PDB\uff09\u548c\u7535\u5b50\u663e\u5fae\u955c\u6570\u636e\u5e93\uff08EMDB\uff09\u4e0a\u5206\u522b\u8fdb\u884c\u4e86\u57df\u5185\u548c\u8de8\u6570\u636e\u5e93\u68c0\u7d22\u8bc4\u4f30\uff0c\u6a21\u578b\u5728\u96f6\u6837\u672c\u68c0\u7d22\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u5728\u86cb\u767d\u8d28\u751f\u7269\u5b66\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u80fd\u591f\u6709\u6548\u652f\u6301\u7ed3\u6784\u4e0e\u529f\u80fd\u7684\u7406\u89e3\u3002"}}
{"id": "2506.08026", "pdf": "https://arxiv.org/pdf/2506.08026", "abs": "https://arxiv.org/abs/2506.08026", "authors": ["Xibai Wang"], "title": "TIP-Search: Time-Predictable Inference Scheduling for Market Prediction under Uncertain Load", "categories": ["cs.AI", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "This paper proposes TIP-Search, a time-predictable inference scheduling\nframework for real-time market prediction under uncertain workloads. Motivated\nby the strict latency demands in high-frequency financial systems, TIP-Search\ndynamically selects a deep learning model from a heterogeneous pool, aiming to\nmaximize predictive accuracy while satisfying per-task deadline constraints.\nOur approach profiles latency and generalization performance offline, then\nperforms online task-aware selection without relying on explicit input domain\nlabels. We evaluate TIP-Search on three real-world limit order book datasets\n(FI-2010, Binance BTC/USDT, LOBSTER AAPL) and demonstrate that it outperforms\nstatic baselines with up to 8.5% improvement in accuracy and 100% deadline\nsatisfaction. Our results highlight the effectiveness of TIP-Search in robust\nlow-latency financial inference under uncertainty.", "AI": {"tldr": "TIP-Search\u662f\u4e00\u4e2a\u65f6\u95f4\u53ef\u9884\u6d4b\u7684\u63a8\u7406\u8c03\u5ea6\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u4e0d\u786e\u5b9a\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u8fdb\u884c\u5b9e\u65f6\u5e02\u573a\u9884\u6d4b\uff0c\u52a8\u6001\u9009\u62e9\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4ee5\u6ee1\u8db3\u4e25\u683c\u5ef6\u8fdf\u9700\u6c42\u3002", "motivation": "\u9ad8\u9891\u91d1\u878d\u7cfb\u7edf\u5bf9\u5ef6\u8fdf\u6709\u4e25\u683c\u8981\u6c42\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5728\u6ee1\u8db3\u4efb\u52a1\u622a\u6b62\u65f6\u95f4\u7684\u540c\u65f6\u6700\u5927\u5316\u9884\u6d4b\u51c6\u786e\u6027\u7684\u65b9\u6cd5\u3002", "method": "TIP-Search\u901a\u8fc7\u79bb\u7ebf\u5206\u6790\u5ef6\u8fdf\u548c\u6cdb\u5316\u6027\u80fd\uff0c\u5728\u7ebf\u8fdb\u884c\u4efb\u52a1\u611f\u77e5\u9009\u62e9\uff0c\u65e0\u9700\u663e\u5f0f\u8f93\u5165\u57df\u6807\u7b7e\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\uff0cTIP-Search\u6bd4\u9759\u6001\u57fa\u7ebf\u65b9\u6cd5\u51c6\u786e\u7387\u63d0\u53478.5%\uff0c\u4e14100%\u6ee1\u8db3\u622a\u6b62\u65f6\u95f4\u3002", "conclusion": "TIP-Search\u5728\u4e0d\u786e\u5b9a\u73af\u5883\u4e0b\u5b9e\u73b0\u4e86\u4f4e\u5ef6\u8fdf\u4e14\u7a33\u5065\u7684\u91d1\u878d\u63a8\u7406\u3002"}}
{"id": "2506.08029", "pdf": "https://arxiv.org/pdf/2506.08029", "abs": "https://arxiv.org/abs/2506.08029", "authors": ["Jiayu Li", "Masood Mortazavi", "Ning Yan", "Yihong Ma", "Reza Zafarani"], "title": "Inverse Design in Distributed Circuits Using Single-Step Reinforcement Learning", "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.SY"], "comment": "A briefer version of this paper was accepted as a Work-in-Progress\n  (WIP) at the Design Automation Conference (DAC) 2024", "summary": "The goal of inverse design in distributed circuits is to generate\nnear-optimal designs that meet a desirable transfer function specification.\nExisting design exploration methods use some combination of strategies\ninvolving artificial grids, differentiable evaluation procedures, and specific\ntemplate topologies. However, real-world design practices often require\nnon-differentiable evaluation procedures, varying topologies, and\nnear-continuous placement spaces. In this paper, we propose DCIDA, a design\nexploration framework that learns a near-optimal design sampling policy for a\ntarget transfer function. DCIDA decides all design factors in a compound\nsingle-step action by sampling from a set of jointly-trained conditional\ndistributions generated by the policy. Utilizing an injective interdependent\n``map\", DCIDA transforms raw sampled design ``actions\" into uniquely equivalent\nphysical representations, enabling the framework to learn the conditional\ndependencies among joint ``raw'' design decisions. Our experiments demonstrate\nDCIDA's Transformer-based policy network achieves significant reductions in\ndesign error compared to state-of-the-art approaches, with significantly better\nfit in cases involving more complex transfer functions.", "AI": {"tldr": "DCIDA\u662f\u4e00\u79cd\u5206\u5e03\u5f0f\u7535\u8def\u9006\u5411\u8bbe\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u5408\u8bad\u7ec3\u7684\u91c7\u6837\u7b56\u7565\u751f\u6210\u8fd1\u6700\u4f18\u8bbe\u8ba1\uff0c\u663e\u8457\u964d\u4f4e\u8bbe\u8ba1\u8bef\u5dee\u3002", "motivation": "\u73b0\u6709\u8bbe\u8ba1\u65b9\u6cd5\u4f9d\u8d56\u53ef\u5fae\u5206\u8bc4\u4f30\u3001\u56fa\u5b9a\u62d3\u6251\u548c\u79bb\u6563\u7a7a\u95f4\uff0c\u800c\u5b9e\u9645\u9700\u6c42\u6d89\u53ca\u975e\u53ef\u5fae\u5206\u8bc4\u4f30\u3001\u591a\u53d8\u62d3\u6251\u548c\u8fde\u7eed\u7a7a\u95f4\u3002", "method": "DCIDA\u901a\u8fc7\u8054\u5408\u8bad\u7ec3\u7684\u91c7\u6837\u7b56\u7565\u751f\u6210\u8bbe\u8ba1\u51b3\u7b56\uff0c\u5229\u7528\u6ce8\u5165\u5f0f\u6620\u5c04\u5c06\u539f\u59cb\u8bbe\u8ba1\u52a8\u4f5c\u8f6c\u6362\u4e3a\u7269\u7406\u8868\u793a\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cDCIDA\u7684Transformer\u7b56\u7565\u7f51\u7edc\u663e\u8457\u964d\u4f4e\u8bbe\u8ba1\u8bef\u5dee\uff0c\u5c24\u5176\u5728\u590d\u6742\u4f20\u8f93\u51fd\u6570\u573a\u666f\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "DCIDA\u4e3a\u5206\u5e03\u5f0f\u7535\u8def\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u9002\u5e94\u6027\u5f3a\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.08030", "pdf": "https://arxiv.org/pdf/2506.08030", "abs": "https://arxiv.org/abs/2506.08030", "authors": ["Brian Liu", "Rahul Mazumder"], "title": "MOSS: Multi-Objective Optimization for Stable Rule Sets", "categories": ["math.OC", "cs.LG", "stat.ML"], "comment": null, "summary": "We present MOSS, a multi-objective optimization framework for constructing\nstable sets of decision rules. MOSS incorporates three important criteria for\ninterpretability: sparsity, accuracy, and stability, into a single\nmulti-objective optimization framework. Importantly, MOSS allows a practitioner\nto rapidly evaluate the trade-off between accuracy and stability in sparse rule\nsets in order to select an appropriate model. We develop a specialized cutting\nplane algorithm in our framework to rapidly compute the Pareto frontier between\nthese two objectives, and our algorithm scales to problem instances beyond the\ncapabilities of commercial optimization solvers. Our experiments show that MOSS\noutperforms state-of-the-art rule ensembles in terms of both predictive\nperformance and stability.", "AI": {"tldr": "MOSS\u662f\u4e00\u4e2a\u591a\u76ee\u6807\u4f18\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u6784\u5efa\u7a33\u5b9a\u7684\u51b3\u7b56\u89c4\u5219\u96c6\uff0c\u7ed3\u5408\u4e86\u7a00\u758f\u6027\u3001\u51c6\u786e\u6027\u548c\u7a33\u5b9a\u6027\uff0c\u5e76\u901a\u8fc7\u5feb\u901f\u8bc4\u4f30\u6743\u8861\u6765\u9009\u62e9\u5408\u9002\u7684\u6a21\u578b\u3002", "motivation": "\u89e3\u51b3\u51b3\u7b56\u89c4\u5219\u96c6\u4e2d\u7a00\u758f\u6027\u3001\u51c6\u786e\u6027\u548c\u7a33\u5b9a\u6027\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\uff0c\u63d0\u4f9b\u9ad8\u6548\u7684\u6a21\u578b\u9009\u62e9\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u4e13\u7528\u7684\u5207\u5272\u5e73\u9762\u7b97\u6cd5\uff0c\u5feb\u901f\u8ba1\u7b97Pareto\u524d\u6cbf\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u95ee\u9898\u3002", "result": "MOSS\u5728\u9884\u6d4b\u6027\u80fd\u548c\u7a33\u5b9a\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u89c4\u5219\u96c6\u6210\u65b9\u6cd5\u3002", "conclusion": "MOSS\u4e3a\u6784\u5efa\u7a33\u5b9a\u4e14\u53ef\u89e3\u91ca\u7684\u51b3\u7b56\u89c4\u5219\u96c6\u63d0\u4f9b\u4e86\u9ad8\u6548\u6846\u67b6\u3002"}}
{"id": "2506.08033", "pdf": "https://arxiv.org/pdf/2506.08033", "abs": "https://arxiv.org/abs/2506.08033", "authors": ["Axel TahmasebiMoradi", "Vincent Ren", "Benjamin Le-Creurer", "Chetra Mang"], "title": "Feasibility Study of CNNs and MLPs for Radiation Heat Transfer in 2-D Furnaces with Spectrally Participative Gases", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": null, "summary": "Aiming to reduce the computational cost of numerical simulations, a\nconvolutional neural network (CNN) and a multi-layer perceptron (MLP) are\nintroduced to build a surrogate model to approximate radiative heat transfer\nsolutions in a 2-D walled domain with participative gases. The originality of\nthis work lays in the adaptation of the inputs of the problem (gas and wall\nproperties) in order to fit with the CNN architecture, more commonly used for\nimage processing. Two precision datasets have been created with the classical\nsolver, ICARUS2D, that uses the discrete transfer radiation method with the\nstatistical narrow bands model. The performance of the CNN architecture is\ncompared to a more classical MLP architecture in terms of speed and accuracy.\nThanks to Optuna, all results are obtained using the optimized hyper parameters\nnetworks. The results show a significant speedup with industrially acceptable\nrelative errors compared to the classical solver for both architectures.\nAdditionally, the CNN outperforms the MLP in terms of precision and is more\nrobust and stable to changes in hyper-parameters. A performance analysis on the\ndataset size of the samples have also been carried out to gain a deeper\nunderstanding of the model behavior.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eCNN\u548cMLP\u7684\u66ff\u4ee3\u6a21\u578b\uff0c\u7528\u4e8e\u8fd1\u4f3c2D\u58c1\u57df\u4e2d\u53c2\u4e0e\u6027\u6c14\u4f53\u7684\u8f90\u5c04\u70ed\u4f20\u9012\u89e3\uff0c\u4ee5\u51cf\u5c11\u8ba1\u7b97\u6210\u672c\u3002CNN\u5728\u7cbe\u5ea6\u548c\u7a33\u5b9a\u6027\u4e0a\u4f18\u4e8eMLP\u3002", "motivation": "\u964d\u4f4e\u6570\u503c\u6a21\u62df\u7684\u8ba1\u7b97\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u5de5\u4e1a\u53ef\u63a5\u53d7\u7684\u7cbe\u5ea6\u3002", "method": "\u4f7f\u7528CNN\u548cMLP\u6784\u5efa\u66ff\u4ee3\u6a21\u578b\uff0c\u901a\u8fc7Optuna\u4f18\u5316\u8d85\u53c2\u6570\uff0c\u5e76\u4e0e\u4f20\u7edf\u6c42\u89e3\u5668ICARUS2D\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "CNN\u548cMLP\u5747\u663e\u8457\u52a0\u901f\u8ba1\u7b97\u4e14\u8bef\u5dee\u53ef\u63a5\u53d7\uff0cCNN\u5728\u7cbe\u5ea6\u548c\u7a33\u5b9a\u6027\u4e0a\u4f18\u4e8eMLP\u3002", "conclusion": "CNN\u662f\u66f4\u4f18\u7684\u66ff\u4ee3\u6a21\u578b\u9009\u62e9\uff0c\u9002\u7528\u4e8e\u5de5\u4e1a\u5e94\u7528\u3002"}}
{"id": "2506.08043", "pdf": "https://arxiv.org/pdf/2506.08043", "abs": "https://arxiv.org/abs/2506.08043", "authors": ["Ashkan Shahbazi", "Kyvia Pereira", "Jon S. Heiselman", "Elaheh Akbari", "Annie C. Benson", "Sepehr Seifi", "Xinyuan Liu", "Garrison L. Johnston", "Erwin Terpstra", "Anne Draaisma", "Jan-Jaap Severes", "Jie Ying Wu", "Nabil Simaan", "Michael L. Miga", "Soheil Kolouri"], "title": "Neural-Augmented Kelvinlet: Real-Time Soft Tissue Deformation with Multiple Graspers", "categories": ["cs.GR", "cs.CV", "cs.LG", "cs.RO"], "comment": null, "summary": "Fast and accurate simulation of soft tissue deformation is a critical factor\nfor surgical robotics and medical training. In this paper, we introduce a novel\nphysics-informed neural simulator that approximates soft tissue deformations in\na realistic and real-time manner. Our framework integrates Kelvinlet-based\npriors into neural simulators, making it the first approach to leverage\nKelvinlets for residual learning and regularization in data-driven soft tissue\nmodeling. By incorporating large-scale Finite Element Method (FEM) simulations\nof both linear and nonlinear soft tissue responses, our method improves neural\nnetwork predictions across diverse architectures, enhancing accuracy and\nphysical consistency while maintaining low latency for real-time performance.\nWe demonstrate the effectiveness of our approach by performing accurate\nsurgical maneuvers that simulate the use of standard laparoscopic tissue\ngrasping tools with high fidelity. These results establish Kelvinlet-augmented\nlearning as a powerful and efficient strategy for real-time, physics-aware soft\ntissue simulation in surgical applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7269\u7406\u4fe1\u606f\u7684\u795e\u7ecf\u6a21\u62df\u5668\uff0c\u5229\u7528Kelvinlet\u5148\u9a8c\u548cFEM\u6a21\u62df\uff0c\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u3001\u4f4e\u5ef6\u8fdf\u7684\u8f6f\u7ec4\u7ec7\u53d8\u5f62\u5b9e\u65f6\u6a21\u62df\u3002", "motivation": "\u624b\u672f\u673a\u5668\u4eba\u548c\u533b\u5b66\u8bad\u7ec3\u9700\u8981\u5feb\u901f\u51c6\u786e\u7684\u8f6f\u7ec4\u7ec7\u53d8\u5f62\u6a21\u62df\u3002", "method": "\u7ed3\u5408Kelvinlet\u5148\u9a8c\u548cFEM\u6a21\u62df\uff0c\u901a\u8fc7\u6b8b\u5dee\u5b66\u4e60\u548c\u6b63\u5219\u5316\u6539\u8fdb\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u3002", "result": "\u5b9e\u73b0\u4e86\u9ad8\u4fdd\u771f\u5ea6\u7684\u5b9e\u65f6\u8f6f\u7ec4\u7ec7\u6a21\u62df\uff0c\u9002\u7528\u4e8e\u8179\u8154\u955c\u624b\u672f\u64cd\u4f5c\u3002", "conclusion": "Kelvinlet\u589e\u5f3a\u5b66\u4e60\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u7269\u7406\u611f\u77e5\u7684\u8f6f\u7ec4\u7ec7\u6a21\u62df\u7b56\u7565\u3002"}}
{"id": "2506.08047", "pdf": "https://arxiv.org/pdf/2506.08047", "abs": "https://arxiv.org/abs/2506.08047", "authors": ["A. G. R. Sandeepa", "Sanka Mohottala"], "title": "Evaluation of Machine Learning Models in Student Academic Performance Prediction", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": "Paper Accepted for IEEE ICARC Conference (2025). 6 pages, 5 figures", "summary": "This research investigates the use of machine learning methods to forecast\nstudents' academic performance in a school setting. Students' data with\nbehavioral, academic, and demographic details were used in implementations with\nstandard classical machine learning models including multi-layer perceptron\nclassifier (MLPC). MLPC obtained 86.46% maximum accuracy for test set across\nall implementations. Under 10-fold cross validation, MLPC obtained 79.58%\naverage accuracy for test set while for train set, it was 99.65%. MLP's better\nperformance over other machine learning models strongly suggest the potential\nuse of neural networks as data-efficient models. Feature selection approach\nplayed a crucial role in improving the performance and multiple evaluation\napproaches were used in order to compare with existing literature. Explainable\nmachine learning methods were utilized to demystify the black box models and to\nvalidate the feature selection approach.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u9884\u6d4b\u5b66\u751f\u5b66\u4e1a\u8868\u73b0\u7684\u6548\u679c\uff0c\u591a\u5c42\u611f\u77e5\u673a\u5206\u7c7b\u5668\uff08MLPC\uff09\u8868\u73b0\u6700\u4f73\uff0c\u6d4b\u8bd5\u96c6\u51c6\u786e\u7387\u8fbe86.46%\u3002", "motivation": "\u63a2\u7d22\u673a\u5668\u5b66\u4e60\uff0c\u5c24\u5176\u662f\u795e\u7ecf\u7f51\u7edc\uff0c\u5728\u9884\u6d4b\u5b66\u751f\u5b66\u4e1a\u8868\u73b0\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u5e76\u9a8c\u8bc1\u5176\u6570\u636e\u6548\u7387\u3002", "method": "\u4f7f\u7528\u5b66\u751f\u884c\u4e3a\u3001\u5b66\u672f\u548c\u4eba\u53e3\u7edf\u8ba1\u6570\u636e\uff0c\u91c7\u7528\u591a\u5c42\u611f\u77e5\u673a\u5206\u7c7b\u5668\uff08MLPC\uff09\u7b49\u6807\u51c6\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u7ed3\u5408\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u3002", "result": "MLPC\u5728\u6d4b\u8bd5\u96c6\u4e0a\u6700\u9ad8\u51c6\u786e\u7387\u8fbe86.46%\uff0c10\u6298\u4ea4\u53c9\u9a8c\u8bc1\u5e73\u5747\u51c6\u786e\u7387\u4e3a79.58%\uff0c\u8bad\u7ec3\u96c6\u51c6\u786e\u7387\u9ad8\u8fbe99.65%\u3002", "conclusion": "\u795e\u7ecf\u7f51\u7edc\uff08\u5982MLPC\uff09\u5728\u9884\u6d4b\u5b66\u751f\u8868\u73b0\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u7279\u5f81\u9009\u62e9\u5bf9\u6027\u80fd\u63d0\u5347\u81f3\u5173\u91cd\u8981\uff0c\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u6709\u52a9\u4e8e\u9a8c\u8bc1\u6a21\u578b\u3002"}}
{"id": "2506.08049", "pdf": "https://arxiv.org/pdf/2506.08049", "abs": "https://arxiv.org/abs/2506.08049", "authors": ["Tengfei Lyu", "Weijia Zhang", "Hao Liu"], "title": "Physics-Informed Teleconnection-Aware Transformer for Global Subseasonal-to-Seasonal Forecasting", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "Subseasonal-to-seasonal (S2S) forecasting, which predicts climate conditions\nfrom several weeks to months in advance, presents significant challenges due to\nthe chaotic dynamics of atmospheric systems and complex interactions across\nmultiple scales. Current approaches often fail to explicitly model underlying\nphysical processes and teleconnections that are crucial at S2S timescales. We\nintroduce TelePiT, a novel deep learning architecture that enhances global S2S\nforecasting through integrated multi-scale physics and teleconnection\nawareness. Our approach consists of three key components: (1) Spherical\nHarmonic Embedding, which accurately encodes global atmospheric variables onto\nspherical geometry; (2) Multi-Scale Physics-Informed Neural ODE, which\nexplicitly captures atmospheric physical processes across multiple learnable\nfrequency bands; (3) Teleconnection-Aware Transformer, which models critical\nglobal climate interactions through tactfully injecting teleconnection patterns\ninto the self-attention. Extensive experiments demonstrate that TelePiT\nsignificantly outperforms state-of-the-art data-driven baselines and\noperational numerical weather prediction systems, with remarkable improvements\nfor atmospheric variables including a 57.7% reduction in RMSE for 2-meter\ntemperature compared to previous best models.", "AI": {"tldr": "TelePiT\u662f\u4e00\u79cd\u65b0\u578b\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\uff0c\u901a\u8fc7\u591a\u5c3a\u5ea6\u7269\u7406\u548c\u9065\u76f8\u5173\u5efa\u6a21\u63d0\u5347\u5168\u7403S2S\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "S2S\u9884\u6d4b\u56e0\u5927\u6c14\u7cfb\u7edf\u7684\u6df7\u6c8c\u6027\u548c\u591a\u5c3a\u5ea6\u590d\u6742\u4ea4\u4e92\u800c\u5177\u6709\u6311\u6218\u6027\uff0c\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u660e\u786e\u5efa\u6a21\u5173\u952e\u7269\u7406\u8fc7\u7a0b\u548c\u9065\u76f8\u5173\u3002", "method": "TelePiT\u5305\u542b\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a\u7403\u8c10\u5d4c\u5165\u3001\u591a\u5c3a\u5ea6\u7269\u7406\u4fe1\u606f\u795e\u7ecfODE\u548c\u9065\u76f8\u5173\u611f\u77e5Transformer\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cTelePiT\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u548c\u6570\u503c\u5929\u6c14\u9884\u62a5\u7cfb\u7edf\uff0c\u59822\u7c73\u6e29\u5ea6RMSE\u964d\u4f4e57.7%\u3002", "conclusion": "TelePiT\u901a\u8fc7\u6574\u5408\u591a\u5c3a\u5ea6\u7269\u7406\u548c\u9065\u76f8\u5173\u5efa\u6a21\uff0c\u663e\u8457\u63d0\u5347\u4e86S2S\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2506.08059", "pdf": "https://arxiv.org/pdf/2506.08059", "abs": "https://arxiv.org/abs/2506.08059", "authors": ["Huong Van Le", "Weibin Ren", "Junhong Kim", "Yukyung Yun", "Young Bin Park", "Young Jun Kim", "Bok Kyung Han", "Inho Choi", "Jong IL Park", "Hwi-Yeol Yun", "Jae-Mun Choi"], "title": "CaliciBoost: Performance-Driven Evaluation of Molecular Representations for Caco-2 Permeability Prediction", "categories": ["q-bio.QM", "cs.AI", "cs.LG"], "comment": "49 pages, 11 figures", "summary": "Caco-2 permeability serves as a critical in vitro indicator for predicting\nthe oral absorption of drug candidates during early-stage drug discovery. To\nenhance the accuracy and efficiency of computational predictions, we\nsystematically investigated the impact of eight molecular feature\nrepresentation types including 2D/3D descriptors, structural fingerprints, and\ndeep learning-based embeddings combined with automated machine learning\ntechniques to predict Caco-2 permeability. Using two datasets of differing\nscale and diversity (TDC benchmark and curated OCHEM data), we assessed model\nperformance across representations and identified PaDEL, Mordred, and RDKit\ndescriptors as particularly effective for Caco-2 prediction. Notably, the\nAutoML-based model CaliciBoost achieved the best MAE performance. Furthermore,\nfor both PaDEL and Mordred representations, the incorporation of 3D descriptors\nresulted in a 15.73% reduction in MAE compared to using 2D features alone, as\nconfirmed by feature importance analysis. These findings highlight the\neffectiveness of AutoML approaches in ADMET modeling and offer practical\nguidance for feature selection in data-limited prediction tasks.", "AI": {"tldr": "\u901a\u8fc7\u7cfb\u7edf\u7814\u7a76\u516b\u79cd\u5206\u5b50\u7279\u5f81\u8868\u793a\u7c7b\u578b\u5e76\u7ed3\u5408AutoML\u6280\u672f\uff0c\u63d0\u5347\u4e86Caco-2\u6e17\u900f\u7387\u7684\u9884\u6d4b\u7cbe\u5ea6\u548c\u6548\u7387\u3002", "motivation": "Caco-2\u6e17\u900f\u7387\u662f\u65e9\u671f\u836f\u7269\u53d1\u73b0\u4e2d\u9884\u6d4b\u53e3\u670d\u5438\u6536\u7684\u5173\u952e\u6307\u6807\uff0c\u9700\u63d0\u9ad8\u8ba1\u7b97\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "method": "\u7ed3\u54082D/3D\u63cf\u8ff0\u7b26\u3001\u7ed3\u6784\u6307\u7eb9\u548c\u6df1\u5ea6\u5b66\u4e60\u5d4c\u5165\uff0c\u4f7f\u7528AutoML\u6280\u672f\u9884\u6d4bCaco-2\u6e17\u900f\u7387\uff0c\u5e76\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u6027\u80fd\u3002", "result": "PaDEL\u3001Mordred\u548cRDKit\u63cf\u8ff0\u7b26\u8868\u73b0\u6700\u4f73\uff0cAutoML\u6a21\u578bCaliciBoost\u7684MAE\u6027\u80fd\u6700\u4f18\uff1b3D\u63cf\u8ff0\u7b26\u4f7fMAE\u964d\u4f4e15.73%\u3002", "conclusion": "AutoML\u65b9\u6cd5\u5728ADMET\u5efa\u6a21\u4e2d\u9ad8\u6548\uff0c\u4e3a\u6570\u636e\u6709\u9650\u7684\u4efb\u52a1\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u7279\u5f81\u9009\u62e9\u6307\u5bfc\u3002"}}
{"id": "2506.08065", "pdf": "https://arxiv.org/pdf/2506.08065", "abs": "https://arxiv.org/abs/2506.08065", "authors": ["Ye Zhu", "Duo Xu", "Zhiwei Deng", "Jonathon C. Tan", "Olga Russakovsky"], "title": "Dynamic Diffusion Schr\u00f6dinger Bridge in Astrophysical Observational Inversions", "categories": ["astro-ph.IM", "cs.LG"], "comment": "Preprint. Code will be available at\n  https://github.com/L-YeZhu/AstroDSB", "summary": "We study Diffusion Schr\\\"odinger Bridge (DSB) models in the context of\ndynamical astrophysical systems, specifically tackling observational inverse\nprediction tasks within Giant Molecular Clouds (GMCs) for star formation. We\nintroduce the Astro-DSB model, a variant of DSB with the pairwise domain\nassumption tailored for astrophysical dynamics. By investigating its learning\nprocess and prediction performance in both physically simulated data and in\nreal observations (the Taurus B213 data), we present two main takeaways. First,\nfrom the astrophysical perspective, our proposed paired DSB method improves\ninterpretability, learning efficiency, and prediction performance over\nconventional astrostatistical and other machine learning methods. Second, from\nthe generative modeling perspective, probabilistic generative modeling reveals\nimprovements over discriminative pixel-to-pixel modeling in Out-Of-Distribution\n(OOD) testing cases of physical simulations with unseen initial conditions and\ndifferent dominant physical processes. Our study expands research into\ndiffusion models beyond the traditional visual synthesis application and\nprovides evidence of the models' learning abilities beyond pure data\nstatistics, paving a path for future physics-aware generative models which can\nalign dynamics between machine learning and real (astro)physical systems.", "AI": {"tldr": "Astro-DSB\u6a21\u578b\u662f\u4e00\u79cd\u9488\u5bf9\u5929\u4f53\u7269\u7406\u52a8\u529b\u5b66\u8bbe\u8ba1\u7684\u6269\u6563\u859b\u5b9a\u8c14\u6865\u6a21\u578b\uff0c\u5728GMC\u4e2d\u7528\u4e8e\u6052\u661f\u5f62\u6210\u7684\u89c2\u6d4b\u9006\u9884\u6d4b\u4efb\u52a1\uff0c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u548c\u751f\u6210\u6a21\u578b\u3002", "motivation": "\u7814\u7a76\u6269\u6563\u6a21\u578b\u5728\u5929\u4f53\u7269\u7406\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\uff0c\u89e3\u51b3GMC\u4e2d\u6052\u661f\u5f62\u6210\u7684\u89c2\u6d4b\u9006\u9884\u6d4b\u95ee\u9898\uff0c\u63d0\u5347\u6a21\u578b\u7684\u89e3\u91ca\u6027\u548c\u5b66\u4e60\u6548\u7387\u3002", "method": "\u63d0\u51faAstro-DSB\u6a21\u578b\uff0c\u57fa\u4e8e\u6210\u5bf9\u57df\u5047\u8bbe\uff0c\u901a\u8fc7\u7269\u7406\u6a21\u62df\u548c\u771f\u5b9e\u89c2\u6d4b\u6570\u636e\uff08Taurus B213\uff09\u9a8c\u8bc1\u5176\u6027\u80fd\u3002", "result": "Astro-DSB\u5728\u89e3\u91ca\u6027\u3001\u5b66\u4e60\u6548\u7387\u548c\u9884\u6d4b\u6027\u80fd\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u4e14\u5728OOD\u6d4b\u8bd5\u4e2d\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u7814\u7a76\u6269\u5c55\u4e86\u6269\u6563\u6a21\u578b\u7684\u5e94\u7528\u8303\u56f4\uff0c\u5c55\u793a\u4e86\u5176\u5728\u7269\u7406\u7cfb\u7edf\u5b66\u4e60\u4e2d\u7684\u6f5c\u529b\uff0c\u4e3a\u672a\u6765\u7269\u7406\u611f\u77e5\u751f\u6210\u6a21\u578b\u94fa\u8def\u3002"}}
{"id": "2506.08066", "pdf": "https://arxiv.org/pdf/2506.08066", "abs": "https://arxiv.org/abs/2506.08066", "authors": ["Alexander Stepikin", "Evgenia Romanenkova", "Alexey Zaytsev"], "title": "WWAggr: A Window Wasserstein-based Aggregation for Ensemble Change Point Detection", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "Change Point Detection (CPD) aims to identify moments of abrupt distribution\nshifts in data streams. Real-world high-dimensional CPD remains challenging due\nto data pattern complexity and violation of common assumptions. Resorting to\nstandalone deep neural networks, the current state-of-the-art detectors have\nyet to achieve perfect quality. Concurrently, ensembling provides more robust\nsolutions, boosting the performance. In this paper, we investigate ensembles of\ndeep change point detectors and realize that standard prediction aggregation\ntechniques, e.g., averaging, are suboptimal and fail to account for problem\npeculiarities. Alternatively, we introduce WWAggr -- a novel task-specific\nmethod of ensemble aggregation based on the Wasserstein distance. Our procedure\nis versatile, working effectively with various ensembles of deep CPD models.\nMoreover, unlike existing solutions, we practically lift a long-standing\nproblem of the decision threshold selection for CPD.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eWasserstein\u8ddd\u79bb\u7684\u65b0\u578b\u96c6\u6210\u805a\u5408\u65b9\u6cd5WWAggr\uff0c\u7528\u4e8e\u63d0\u5347\u9ad8\u7ef4\u53d8\u5316\u70b9\u68c0\u6d4b\u7684\u6027\u80fd\uff0c\u5e76\u89e3\u51b3\u4e86\u51b3\u7b56\u9608\u503c\u9009\u62e9\u95ee\u9898\u3002", "motivation": "\u9ad8\u7ef4\u6570\u636e\u6d41\u4e2d\u7684\u53d8\u5316\u70b9\u68c0\u6d4b\uff08CPD\uff09\u9762\u4e34\u6570\u636e\u6a21\u5f0f\u590d\u6742\u6027\u548c\u5e38\u89c1\u5047\u8bbe\u4e0d\u6210\u7acb\u7684\u6311\u6218\uff0c\u73b0\u6709\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u68c0\u6d4b\u5668\u6027\u80fd\u4ecd\u6709\u63d0\u5347\u7a7a\u95f4\u3002", "method": "\u5f15\u5165WWAggr\u65b9\u6cd5\uff0c\u5229\u7528Wasserstein\u8ddd\u79bb\u8fdb\u884c\u4efb\u52a1\u7279\u5b9a\u7684\u96c6\u6210\u805a\u5408\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u6df1\u5ea6CPD\u6a21\u578b\u3002", "result": "WWAggr\u65b9\u6cd5\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u6807\u51c6\u805a\u5408\u6280\u672f\uff0c\u5e76\u6709\u6548\u89e3\u51b3\u4e86\u51b3\u7b56\u9608\u503c\u9009\u62e9\u95ee\u9898\u3002", "conclusion": "WWAggr\u4e3a\u9ad8\u7ef4CPD\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u7a33\u5065\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\u548c\u5b9e\u9645\u4ef7\u503c\u3002"}}
{"id": "2506.08073", "pdf": "https://arxiv.org/pdf/2506.08073", "abs": "https://arxiv.org/abs/2506.08073", "authors": ["Yu Liu", "Utkarsh Pratiush", "Kamyar Barakati", "Hiroshi Funakubo", "Ching-Che Lin", "Jaegyu Kim", "Lane W. Martin", "Sergei V. Kalinin"], "title": "Domain Switching on the Pareto Front: Multi-Objective Deep Kernel Learning in Automated Piezoresponse Force Microscopy", "categories": ["cond-mat.mtrl-sci", "cond-mat.mes-hall", "cs.AI", "cs.LG"], "comment": null, "summary": "Ferroelectric polarization switching underpins the functional performance of\na wide range of materials and devices, yet its dependence on complex local\nmicrostructural features renders systematic exploration by manual or grid-based\nspectroscopic measurements impractical. Here, we introduce a multi-objective\nkernel-learning workflow that infers the microstructural rules governing\nswitching behavior directly from high-resolution imaging data. Applied to\nautomated piezoresponse force microscopy (PFM) experiments, our framework\nefficiently identifies the key relationships between domain-wall configurations\nand local switching kinetics, revealing how specific wall geometries and defect\ndistributions modulate polarization reversal. Post-experiment analysis projects\nabstract reward functions, such as switching ease and domain symmetry, onto\nphysically interpretable descriptors including domain configuration and\nproximity to boundaries. This enables not only high-throughput active learning,\nbut also mechanistic insight into the microstructural control of switching\nphenomena. While demonstrated for ferroelectric domain switching, our approach\nprovides a powerful, generalizable tool for navigating complex,\nnon-differentiable design spaces, from structure-property correlations in\nmolecular discovery to combinatorial optimization across diverse imaging\nmodalities.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u76ee\u6807\u6838\u5b66\u4e60\u5de5\u4f5c\u6d41\uff0c\u7528\u4e8e\u4ece\u9ad8\u5206\u8fa8\u7387\u6210\u50cf\u6570\u636e\u4e2d\u63a8\u65ad\u94c1\u7535\u6781\u5316\u5207\u6362\u7684\u5fae\u89c2\u7ed3\u6784\u89c4\u5219\uff0c\u63ed\u793a\u4e86\u57df\u58c1\u6784\u578b\u548c\u7f3a\u9677\u5206\u5e03\u5bf9\u5207\u6362\u52a8\u529b\u5b66\u7684\u5f71\u54cd\u3002", "motivation": "\u94c1\u7535\u6781\u5316\u5207\u6362\u7684\u5fae\u89c2\u7ed3\u6784\u4f9d\u8d56\u6027\u590d\u6742\uff0c\u4f20\u7edf\u624b\u52a8\u6216\u7f51\u683c\u5149\u8c31\u6d4b\u91cf\u96be\u4ee5\u7cfb\u7edf\u7814\u7a76\u3002", "method": "\u91c7\u7528\u591a\u76ee\u6807\u6838\u5b66\u4e60\u5de5\u4f5c\u6d41\uff0c\u7ed3\u5408\u81ea\u52a8\u5316\u538b\u7535\u54cd\u5e94\u529b\u663e\u5fae\u955c\u5b9e\u9a8c\uff0c\u5206\u6790\u57df\u58c1\u6784\u578b\u4e0e\u5c40\u90e8\u5207\u6362\u52a8\u529b\u5b66\u7684\u5173\u7cfb\u3002", "result": "\u63ed\u793a\u4e86\u7279\u5b9a\u57df\u58c1\u51e0\u4f55\u548c\u7f3a\u9677\u5206\u5e03\u5982\u4f55\u8c03\u63a7\u6781\u5316\u53cd\u8f6c\uff0c\u5e76\u5c06\u62bd\u8c61\u5956\u52b1\u51fd\u6570\u6620\u5c04\u5230\u7269\u7406\u53ef\u89e3\u91ca\u7684\u63cf\u8ff0\u7b26\u4e0a\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u652f\u6301\u9ad8\u901a\u91cf\u4e3b\u52a8\u5b66\u4e60\uff0c\u8fd8\u4e3a\u7406\u89e3\u5207\u6362\u73b0\u8c61\u7684\u5fae\u89c2\u7ed3\u6784\u63a7\u5236\u63d0\u4f9b\u4e86\u673a\u5236\u6027\u89c1\u89e3\uff0c\u9002\u7528\u4e8e\u590d\u6742\u975e\u53ef\u5fae\u8bbe\u8ba1\u7a7a\u95f4\u7684\u63a2\u7d22\u3002"}}
{"id": "2506.08121", "pdf": "https://arxiv.org/pdf/2506.08121", "abs": "https://arxiv.org/abs/2506.08121", "authors": ["Qi Feng", "Gu Wang"], "title": "Continuous Policy and Value Iteration for Stochastic Control Problems and Its Convergence", "categories": ["math.OC", "cs.LG", "93E20, 93E35, 60H10"], "comment": "37 pages", "summary": "We introduce a continuous policy-value iteration algorithm where the\napproximations of the value function of a stochastic control problem and the\noptimal control are simultaneously updated through Langevin-type dynamics. This\nframework applies to both the entropy-regularized relaxed control problems and\nthe classical control problems, with infinite horizon. We establish policy\nimprovement and demonstrate convergence to the optimal control under the\nmonotonicity condition of the Hamiltonian. By utilizing Langevin-type\nstochastic differential equations for continuous updates along the policy\niteration direction, our approach enables the use of distribution sampling and\nnon-convex learning techniques in machine learning to optimize the value\nfunction and identify the optimal control simultaneously.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8fde\u7eed\u7b56\u7565-\u4ef7\u503c\u8fed\u4ee3\u7b97\u6cd5\uff0c\u901a\u8fc7Langevin\u578b\u52a8\u6001\u540c\u65f6\u66f4\u65b0\u968f\u673a\u63a7\u5236\u95ee\u9898\u7684\u4ef7\u503c\u51fd\u6570\u548c\u6700\u4f18\u63a7\u5236\u7684\u8fd1\u4f3c\u89e3\u3002", "motivation": "\u89e3\u51b3\u71b5\u6b63\u5219\u5316\u677e\u5f1b\u63a7\u5236\u95ee\u9898\u548c\u7ecf\u5178\u63a7\u5236\u95ee\u9898\u4e2d\u7684\u65e0\u9650\u65f6\u57df\u4f18\u5316\uff0c\u540c\u65f6\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u7684\u5206\u5e03\u91c7\u6837\u548c\u975e\u51f8\u5b66\u4e60\u6280\u672f\u3002", "method": "\u5229\u7528Langevin\u578b\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u8fdb\u884c\u8fde\u7eed\u66f4\u65b0\uff0c\u7ed3\u5408\u7b56\u7565\u8fed\u4ee3\u65b9\u5411\uff0c\u540c\u65f6\u4f18\u5316\u4ef7\u503c\u51fd\u6570\u548c\u6700\u4f18\u63a7\u5236\u3002", "result": "\u5728\u54c8\u5bc6\u987f\u5355\u8c03\u6027\u6761\u4ef6\u4e0b\uff0c\u8bc1\u660e\u4e86\u7b56\u7565\u6539\u8fdb\u548c\u6536\u655b\u5230\u6700\u4f18\u63a7\u5236\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u968f\u673a\u63a7\u5236\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u975e\u51f8\u4f18\u5316\u573a\u666f\u3002"}}
{"id": "2506.08127", "pdf": "https://arxiv.org/pdf/2506.08127", "abs": "https://arxiv.org/abs/2506.08127", "authors": ["Cyrille Kone", "Emilie Kaufmann", "Laura Richert"], "title": "Constrained Pareto Set Identification with Bandit Feedback", "categories": ["stat.ML", "cs.LG"], "comment": "To appear in Proceedings of ICML2025", "summary": "In this paper, we address the problem of identifying the Pareto Set under\nfeasibility constraints in a multivariate bandit setting. Specifically, given a\n$K$-armed bandit with unknown means $\\mu_1, \\dots, \\mu_K \\in \\mathbb{R}^d$, the\ngoal is to identify the set of arms whose mean is not uniformly worse than that\nof another arm (i.e., not smaller for all objectives), while satisfying some\nknown set of linear constraints, expressing, for example, some minimal\nperformance on each objective. Our focus lies in fixed-confidence\nidentification, for which we introduce an algorithm that significantly\noutperforms racing-like algorithms and the intuitive two-stage approach that\nfirst identifies feasible arms and then their Pareto Set. We further prove an\ninformation-theoretic lower bound on the sample complexity of any algorithm for\nconstrained Pareto Set identification, showing that the sample complexity of\nour approach is near-optimal. Our theoretical results are supported by an\nextensive empirical evaluation on a series of benchmarks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u53ef\u884c\u6027\u7ea6\u675f\u4e0b\u8bc6\u522b\u591a\u76ee\u6807\u5e15\u7d2f\u6258\u96c6\u7684\u7b97\u6cd5\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u6837\u672c\u590d\u6742\u5ea6\u7684\u8fd1\u4f18\u6027\u3002", "motivation": "\u89e3\u51b3\u5728\u591a\u76ee\u6807\u81c2\u95ee\u9898\u4e2d\u8bc6\u522b\u5e15\u7d2f\u6258\u96c6\u65f6\u9700\u6ee1\u8db3\u53ef\u884c\u6027\u7ea6\u675f\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u56fa\u5b9a\u7f6e\u4fe1\u5ea6\u8bc6\u522b\u7b97\u6cd5\uff0c\u4f18\u4e8e\u4f20\u7edf\u7684\u4e24\u9636\u6bb5\u65b9\u6cd5\u548c\u7ade\u8d5b\u7c7b\u7b97\u6cd5\u3002", "result": "\u7b97\u6cd5\u5728\u6837\u672c\u590d\u6742\u5ea6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u7406\u8bba\u8bc1\u660e\u5176\u8fd1\u4f18\u6027\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "conclusion": "\u6240\u63d0\u7b97\u6cd5\u5728\u7406\u8bba\u548c\u5b9e\u9a8c\u4e0a\u5747\u8868\u73b0\u51fa\u8272\uff0c\u9002\u7528\u4e8e\u591a\u76ee\u6807\u7ea6\u675f\u4e0b\u7684\u5e15\u7d2f\u6258\u96c6\u8bc6\u522b\u3002"}}
{"id": "2506.08147", "pdf": "https://arxiv.org/pdf/2506.08147", "abs": "https://arxiv.org/abs/2506.08147", "authors": ["Muhammad Usman", "Muhammad Ahmad", "M. Shahiki Tash", "Irina Gelbukh", "Rolando Quintero Tellez", "Grigori Sidorov"], "title": "Multilingual Hate Speech Detection in Social Media Using Translation-Based Approaches with Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Social media platforms are critical spaces for public discourse, shaping\nopinions and community dynamics, yet their widespread use has amplified harmful\ncontent, particularly hate speech, threatening online safety and inclusivity.\nWhile hate speech detection has been extensively studied in languages like\nEnglish and Spanish, Urdu remains underexplored, especially using\ntranslation-based approaches. To address this gap, we introduce a trilingual\ndataset of 10,193 tweets in English (3,834 samples), Urdu (3,197 samples), and\nSpanish (3,162 samples), collected via keyword filtering, with a balanced\ndistribution of 4,849 Hateful and 5,344 Not-Hateful labels. Our methodology\nleverages attention layers as a precursor to transformer-based models and large\nlanguage models (LLMs), enhancing feature extraction for multilingual hate\nspeech detection. For non-transformer models, we use TF-IDF for feature\nextraction. The dataset is benchmarked using state-of-the-art models, including\nGPT-3.5 Turbo and Qwen 2.5 72B, alongside traditional machine learning models\nlike SVM and other transformers (e.g., BERT, RoBERTa). Three annotators,\nfollowing rigorous guidelines, ensured high dataset quality, achieving a\nFleiss' Kappa of 0.821. Our approach, integrating attention layers with GPT-3.5\nTurbo and Qwen 2.5 72B, achieves strong performance, with macro F1 scores of\n0.87 for English (GPT-3.5 Turbo), 0.85 for Spanish (GPT-3.5 Turbo), 0.81 for\nUrdu (Qwen 2.5 72B), and 0.88 for the joint multilingual model (Qwen 2.5 72B).\nThese results reflect improvements of 8.75% in English (over SVM baseline\n0.80), 8.97% in Spanish (over SVM baseline 0.78), 5.19% in Urdu (over SVM\nbaseline 0.77), and 7.32% in the joint multilingual model (over SVM baseline\n0.82). Our framework offers a robust solution for multilingual hate speech\ndetection, fostering safer digital communities worldwide.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u8bed\u8a00\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u5c42\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982GPT-3.5 Turbo\u548cQwen 2.5 72B\uff09\u63d0\u5347\u6027\u80fd\uff0c\u5e76\u5728\u82f1\u8bed\u3001\u897f\u73ed\u7259\u8bed\u548c\u4e4c\u5c14\u90fd\u8bed\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\u3002", "motivation": "\u793e\u4ea4\u5a92\u4f53\u4e0a\u7684\u4ec7\u6068\u8a00\u8bba\u5a01\u80c1\u5728\u7ebf\u5b89\u5168\u548c\u5305\u5bb9\u6027\uff0c\u4f46\u4e4c\u5c14\u90fd\u8bed\u7684\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u7814\u7a76\u8f83\u5c11\uff0c\u5c24\u5176\u662f\u57fa\u4e8e\u7ffb\u8bd1\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u6ce8\u610f\u529b\u5c42\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982GPT-3.5 Turbo\u548cQwen 2.5 72B\uff09\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u5e76\u5728\u591a\u8bed\u8a00\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u5728\u82f1\u8bed\u3001\u897f\u73ed\u7259\u8bed\u548c\u4e4c\u5c14\u90fd\u8bed\u6570\u636e\u96c6\u4e0a\uff0cF1\u5206\u6570\u5206\u522b\u8fbe\u52300.87\u30010.85\u548c0.81\uff0c\u591a\u8bed\u8a00\u6a21\u578bF1\u5206\u6570\u4e3a0.88\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u591a\u8bed\u8a00\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u52a9\u4e8e\u6784\u5efa\u66f4\u5b89\u5168\u7684\u6570\u5b57\u793e\u533a\u3002"}}
{"id": "2506.08153", "pdf": "https://arxiv.org/pdf/2506.08153", "abs": "https://arxiv.org/abs/2506.08153", "authors": ["Renato Cordeiro Ferreira"], "title": "A Metrics-Oriented Architectural Model to Characterize Complexity on Machine Learning-Enabled Systems", "categories": ["cs.SE", "cs.AI", "cs.LG", "D.2.11; D.2.8; I.2.0"], "comment": "4 pages, 3 figures (2 diagrams, 1 table), to be published in CAIN\n  2025", "summary": "How can the complexity of ML-enabled systems be managed effectively? The goal\nof this research is to investigate how complexity affects ML-Enabled Systems\n(MLES). To address this question, this research aims to introduce a\nmetrics-based architectural model to characterize the complexity of MLES. The\ngoal is to support architectural decisions, providing a guideline for the\ninception and growth of these systems. This paper showcases the first step for\ncreating the metrics-based architectural model: an extension of a reference\narchitecture that can describe MLES to collect their metrics.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u57fa\u4e8e\u6307\u6807\u7684\u67b6\u6784\u6a21\u578b\uff0c\u4ee5\u7ba1\u7406ML\u7cfb\u7edf\u7684\u590d\u6742\u6027\u3002", "motivation": "\u63a2\u8ba8\u590d\u6742\u6027\u5982\u4f55\u5f71\u54cdML\u7cfb\u7edf\uff0c\u5e76\u652f\u6301\u67b6\u6784\u51b3\u7b56\u3002", "method": "\u6269\u5c55\u53c2\u8003\u67b6\u6784\u4ee5\u63cf\u8ff0ML\u7cfb\u7edf\u5e76\u6536\u96c6\u6307\u6807\u3002", "result": "\u5c55\u793a\u4e86\u6784\u5efa\u6307\u6807\u6a21\u578b\u7684\u7b2c\u4e00\u6b65\u3002", "conclusion": "\u4e3aML\u7cfb\u7edf\u7684\u590d\u6742\u6027\u7ba1\u7406\u63d0\u4f9b\u4e86\u521d\u6b65\u6846\u67b6\u3002"}}
{"id": "2506.08192", "pdf": "https://arxiv.org/pdf/2506.08192", "abs": "https://arxiv.org/abs/2506.08192", "authors": ["Jared Claypoole", "Steven Cheung", "Ashish Gehani", "Vinod Yegneswaran", "Ahmad Ridley"], "title": "Interpreting Agent Behaviors in Reinforcement-Learning-Based Cyber-Battle Simulation Platforms", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "We analyze two open source deep reinforcement learning agents submitted to\nthe CAGE Challenge 2 cyber defense challenge, where each competitor submitted\nan agent to defend a simulated network against each of several provided\nrules-based attack agents. We demonstrate that one can gain interpretability of\nagent successes and failures by simplifying the complex state and action spaces\nand by tracking important events, shedding light on the fine-grained behavior\nof both the defense and attack agents in each experimental scenario. By\nanalyzing important events within an evaluation episode, we identify patterns\nin infiltration and clearing events that tell us how well the attacker and\ndefender played their respective roles; for example, defenders were generally\nable to clear infiltrations within one or two timesteps of a host being\nexploited. By examining transitions in the environment's state caused by the\nvarious possible actions, we determine which actions tended to be effective and\nwhich did not, showing that certain important actions are between 40% and 99%\nineffective. We examine how decoy services affect exploit success, concluding\nfor instance that decoys block up to 94% of exploits that would directly grant\nprivileged access to a host. Finally, we discuss the realism of the challenge\nand ways that the CAGE Challenge 4 has addressed some of our concerns.", "AI": {"tldr": "\u5206\u6790\u4e86\u4e24\u6b3e\u5f00\u6e90\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u5728CAGE Challenge 2\u4e2d\u7684\u8868\u73b0\uff0c\u901a\u8fc7\u7b80\u5316\u72b6\u6001\u548c\u52a8\u4f5c\u7a7a\u95f4\u4ee5\u53ca\u8ffd\u8e2a\u5173\u952e\u4e8b\u4ef6\uff0c\u63ed\u793a\u4e86\u9632\u5fa1\u548c\u653b\u51fb\u4ee3\u7406\u7684\u7ec6\u7c92\u5ea6\u884c\u4e3a\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u7b80\u5316\u590d\u6742\u72b6\u6001\u548c\u52a8\u4f5c\u7a7a\u95f4\u4ee5\u53ca\u8ffd\u8e2a\u5173\u952e\u4e8b\u4ef6\uff0c\u63d0\u9ad8\u5bf9\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u884c\u4e3a\u7684\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u901a\u8fc7\u5206\u6790\u8bc4\u4f30\u573a\u666f\u4e2d\u7684\u5173\u952e\u4e8b\u4ef6\u548c\u72b6\u6001\u8f6c\u6362\uff0c\u8bc6\u522b\u653b\u51fb\u548c\u9632\u5fa1\u4ee3\u7406\u7684\u884c\u4e3a\u6a21\u5f0f\u53ca\u52a8\u4f5c\u6709\u6548\u6027\u3002", "result": "\u9632\u5fa1\u4ee3\u7406\u901a\u5e38\u57281-2\u4e2a\u65f6\u95f4\u6b65\u5185\u6e05\u9664\u5165\u4fb5\uff1b\u67d0\u4e9b\u5173\u952e\u52a8\u4f5c\u7684\u6709\u6548\u6027\u4ec5\u4e3a1%-60%\uff1b\u8bf1\u9975\u670d\u52a1\u53ef\u963b\u6b62\u9ad8\u8fbe94%\u7684\u7279\u6743\u8bbf\u95ee\u653b\u51fb\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u4ee3\u7406\u884c\u4e3a\u7684\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\uff0c\u5e76\u6307\u51fa\u4e86CAGE Challenge 4\u5bf9\u90e8\u5206\u95ee\u9898\u7684\u6539\u8fdb\u3002"}}
{"id": "2506.08210", "pdf": "https://arxiv.org/pdf/2506.08210", "abs": "https://arxiv.org/abs/2506.08210", "authors": ["Andrew Z. Wang", "Songwei Ge", "Tero Karras", "Ming-Yu Liu", "Yogesh Balaji"], "title": "A Comprehensive Study of Decoder-Only LLMs for Text-to-Image Generation", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": "CVPR 2025", "summary": "Both text-to-image generation and large language models (LLMs) have made\nsignificant advancements. However, many text-to-image models still employ the\nsomewhat outdated T5 and CLIP as their text encoders. In this work, we\ninvestigate the effectiveness of using modern decoder-only LLMs as text\nencoders for text-to-image diffusion models. We build a standardized training\nand evaluation pipeline that allows us to isolate and evaluate the effect of\ndifferent text embeddings. We train a total of 27 text-to-image models with 12\ndifferent text encoders to analyze the critical aspects of LLMs that could\nimpact text-to-image generation, including the approaches to extract\nembeddings, different LLMs variants, and model sizes. Our experiments reveal\nthat the de facto way of using last-layer embeddings as conditioning leads to\ninferior performance. Instead, we explore embeddings from various layers and\nfind that using layer-normalized averaging across all layers significantly\nimproves alignment with complex prompts. Most LLMs with this conditioning\noutperform the baseline T5 model, showing enhanced performance in advanced\nvisio-linguistic reasoning skills.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u4f7f\u7528\u73b0\u4ee3\u4ec5\u89e3\u7801\u5668LLM\u4f5c\u4e3a\u6587\u672c\u7f16\u7801\u5668\u5728\u6587\u672c\u5230\u56fe\u50cf\u6269\u6563\u6a21\u578b\u4e2d\u7684\u6548\u679c\uff0c\u53d1\u73b0\u591a\u5c42\u7ea7\u5e73\u5747\u5d4c\u5165\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u4ecd\u4f7f\u7528\u8fc7\u65f6\u7684T5\u548cCLIP\u4f5c\u4e3a\u6587\u672c\u7f16\u7801\u5668\uff0c\u5e0c\u671b\u901a\u8fc7\u73b0\u4ee3LLM\u63d0\u5347\u6027\u80fd\u3002", "method": "\u6784\u5efa\u6807\u51c6\u5316\u8bad\u7ec3\u4e0e\u8bc4\u4f30\u6d41\u7a0b\uff0c\u8bad\u7ec327\u4e2a\u6a21\u578b\uff0c\u5206\u679012\u79cd\u6587\u672c\u7f16\u7801\u5668\u7684\u5d4c\u5165\u63d0\u53d6\u65b9\u5f0f\u3001\u53d8\u4f53\u548c\u6a21\u578b\u5927\u5c0f\u3002", "result": "\u591a\u5c42\u7ea7\u5e73\u5747\u5d4c\u5165\u663e\u8457\u63d0\u5347\u590d\u6742\u63d0\u793a\u7684\u5bf9\u9f50\u6027\uff0c\u591a\u6570LLM\u6027\u80fd\u4f18\u4e8eT5\u57fa\u7ebf\u3002", "conclusion": "\u73b0\u4ee3LLM\u4f5c\u4e3a\u6587\u672c\u7f16\u7801\u5668\u5728\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u4e2d\u8868\u73b0\u66f4\u4f18\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u590d\u6742\u89c6\u89c9\u8bed\u8a00\u63a8\u7406\u3002"}}
{"id": "2506.08263", "pdf": "https://arxiv.org/pdf/2506.08263", "abs": "https://arxiv.org/abs/2506.08263", "authors": ["Pouya Agheli", "Tugce Kobal", "Fran\u00e7ois Durand", "Matthew Andrews"], "title": "Learning-Based Multiuser Scheduling in MIMO-OFDM Systems with Hybrid Beamforming", "categories": ["cs.IT", "cs.LG", "eess.SP", "math.IT"], "comment": "To appear in the proceedings of the European Conference on Networks\n  and Communications (EuCNC) & 6G Summit, 2025", "summary": "We investigate the multiuser scheduling problem in multiple-input\nmultiple-output (MIMO) systems using orthogonal frequency division multiplexing\n(OFDM) and hybrid beamforming in which a base station (BS) communicates with\nmultiple users over millimeter wave (mmWave) channels in the downlink. Improved\nscheduling is critical for enhancing spectral efficiency and the long-term\nperformance of the system from the perspective of proportional fairness (PF)\nmetric in hybrid beamforming systems due to its limited multiplexing gain. Our\nobjective is to maximize PF by properly designing the analog and digital\nprecoders within the hybrid beamforming and selecting the users subject to the\nnumber of radio frequency (RF) chains. Leveraging the characteristics of mmWave\nchannels, we apply a two-timescale protocol. On a long timescale, we assign an\nanalog beam to each user. Scheduling the users and designing the digital\nprecoder are done accordingly on a short timescale. To conduct scheduling, we\npropose combinatorial solutions, such as greedy and sorting algorithms,\nfollowed by a machine learning (ML) approach. Our numerical results highlight\nthe trade-off between the performance and complexity of the proposed\napproaches. Consequently, we show that the choice of approach depends on the\nspecific criteria within a given scenario.", "AI": {"tldr": "\u7814\u7a76\u591a\u7528\u6237\u8c03\u5ea6\u95ee\u9898\uff0c\u7ed3\u5408MIMO-OFDM\u548c\u6df7\u5408\u6ce2\u675f\u6210\u5f62\uff0c\u901a\u8fc7\u4e24\u65f6\u95f4\u5c3a\u5ea6\u534f\u8bae\u548c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u4f18\u5316\u6bd4\u4f8b\u516c\u5e73\u6027\u3002", "motivation": "\u5728\u6beb\u7c73\u6ce2\u4fe1\u9053\u4e2d\uff0c\u6df7\u5408\u6ce2\u675f\u6210\u5f62\u7cfb\u7edf\u7684\u591a\u8def\u590d\u7528\u589e\u76ca\u6709\u9650\uff0c\u4f18\u5316\u8c03\u5ea6\u5bf9\u63d0\u5347\u9891\u8c31\u6548\u7387\u548c\u957f\u671f\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002", "method": "\u91c7\u7528\u4e24\u65f6\u95f4\u5c3a\u5ea6\u534f\u8bae\uff1a\u957f\u65f6\u5c3a\u5ea6\u5206\u914d\u6a21\u62df\u6ce2\u675f\uff0c\u77ed\u65f6\u5c3a\u5ea6\u8c03\u5ea6\u7528\u6237\u5e76\u8bbe\u8ba1\u6570\u5b57\u9884\u7f16\u7801\u5668\uff1b\u63d0\u51fa\u7ec4\u5408\u7b97\u6cd5\uff08\u8d2a\u5a6a\u3001\u6392\u5e8f\uff09\u548c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u3002", "result": "\u6570\u503c\u7ed3\u679c\u5c55\u793a\u4e86\u6027\u80fd\u4e0e\u590d\u6742\u5ea6\u7684\u6743\u8861\uff0c\u4e0d\u540c\u65b9\u6cd5\u9002\u7528\u4e8e\u4e0d\u540c\u573a\u666f\u3002", "conclusion": "\u65b9\u6cd5\u9009\u62e9\u9700\u6839\u636e\u5177\u4f53\u573a\u666f\u6807\u51c6\uff0c\u6df7\u5408\u6ce2\u675f\u6210\u5f62\u548c\u8c03\u5ea6\u7b56\u7565\u80fd\u6709\u6548\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2506.08276", "pdf": "https://arxiv.org/pdf/2506.08276", "abs": "https://arxiv.org/abs/2506.08276", "authors": ["Yichuan Wang", "Shu Liu", "Zhifei Li", "Yongji Wu", "Ziming Mao", "Yilong Zhao", "Xiao Yan", "Zhiying Xu", "Yang Zhou", "Ion Stoica", "Sewon Min", "Matei Zaharia", "Joseph E. Gonzalez"], "title": "LEANN: A Low-Storage Vector Index", "categories": ["cs.DB", "cs.LG"], "comment": null, "summary": "Embedding-based search is widely used in applications such as recommendation\nand retrieval-augmented generation (RAG). Recently, there is a growing demand\nto support these capabilities over personal data stored locally on devices.\nHowever, maintaining the necessary data structure associated with the\nembedding-based search is often infeasible due to its high storage overhead.\nFor example, indexing 100 GB of raw data requires 150 to 700 GB of storage,\nmaking local deployment impractical. Reducing this overhead while maintaining\nsearch quality and latency becomes a critical challenge. In this paper, we\npresent LEANN, a storage-efficient approximate nearest neighbor (ANN) search\nindex optimized for resource-constrained personal devices. LEANN combines a\ncompact graph-based structure with an efficient on-the-fly recomputation\nstrategy to enable fast and accurate retrieval with minimal storage overhead.\nOur evaluation shows that LEANN reduces index size to under 5% of the original\nraw data, achieving up to 50 times smaller storage than standard indexes, while\nmaintaining 90% top-3 recall in under 2 seconds on real-world question\nanswering benchmarks.", "AI": {"tldr": "LEANN\u662f\u4e00\u79cd\u9488\u5bf9\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u7684\u5b58\u50a8\u9ad8\u6548\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\u7d22\u5f15\uff0c\u663e\u8457\u51cf\u5c11\u5b58\u50a8\u5f00\u9500\uff0c\u540c\u65f6\u4fdd\u6301\u641c\u7d22\u8d28\u91cf\u548c\u5ef6\u8fdf\u3002", "motivation": "\u672c\u5730\u8bbe\u5907\u4e0a\u652f\u6301\u57fa\u4e8e\u5d4c\u5165\u7684\u641c\u7d22\u9700\u6c42\u589e\u957f\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u5b58\u50a8\u5f00\u9500\u8fc7\u9ad8\uff0c\u96be\u4ee5\u5b9e\u73b0\u3002", "method": "LEANN\u7ed3\u5408\u7d27\u51d1\u7684\u56fe\u7ed3\u6784\u548c\u52a8\u6001\u91cd\u8ba1\u7b97\u7b56\u7565\uff0c\u5b9e\u73b0\u5feb\u901f\u51c6\u786e\u68c0\u7d22\u3002", "result": "LEANN\u5c06\u7d22\u5f15\u5927\u5c0f\u964d\u81f3\u539f\u59cb\u6570\u636e\u76845%\uff0c\u5b58\u50a8\u51cf\u5c1150\u500d\uff0c\u4fdd\u630190%\u7684top-3\u53ec\u56de\u7387\uff0c\u5ef6\u8fdf\u4f4e\u4e8e2\u79d2\u3002", "conclusion": "LEANN\u4e3a\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5b58\u50a8\u9700\u6c42\u3002"}}
{"id": "2506.08277", "pdf": "https://arxiv.org/pdf/2506.08277", "abs": "https://arxiv.org/abs/2506.08277", "authors": ["Subba Reddy Oota", "Khushbu Pahwa", "Prachi Jindal", "Satya Sai Srinath Namburi", "Maneesh Singh", "Tanmoy Chakraborty", "Bapi S. Raju", "Manish Gupta"], "title": "Instruction-Tuned Video-Audio Models Elucidate Functional Specialization in the Brain", "categories": ["q-bio.NC", "cs.AI", "cs.CL", "cs.CV", "cs.LG"], "comment": "39 pages, 22 figures", "summary": "Recent voxel-wise multimodal brain encoding studies have shown that\nmultimodal large language models (MLLMs) exhibit a higher degree of brain\nalignment compared to unimodal models in both unimodal and multimodal stimulus\nsettings. More recently, instruction-tuned multimodal models have shown to\ngenerate task-specific representations that align strongly with brain activity.\nHowever, prior work evaluating the brain alignment of MLLMs has primarily\nfocused on unimodal settings or relied on non-instruction-tuned multimodal\nmodels for multimodal stimuli. To address this gap, we investigated brain\nalignment, that is, measuring the degree of predictivity of neural activity\nrecorded while participants were watching naturalistic movies (video along with\naudio) with representations derived from MLLMs. We utilized\ninstruction-specific embeddings from six video and two audio instruction-tuned\nMLLMs. Experiments with 13 video task-specific instructions show that\ninstruction-tuned video MLLMs significantly outperform non-instruction-tuned\nmultimodal (by 15%) and unimodal models (by 20%). Our evaluation of MLLMs for\nboth video and audio tasks using language-guided instructions shows clear\ndisentanglement in task-specific representations from MLLMs, leading to precise\ndifferentiation of multimodal functional processing in the brain. We also find\nthat MLLM layers align hierarchically with the brain, with early sensory areas\nshowing strong alignment with early layers, while higher-level visual and\nlanguage regions align more with middle to late layers. These findings provide\nclear evidence for the role of task-specific instructions in improving the\nalignment between brain activity and MLLMs, and open new avenues for mapping\njoint information processing in both the systems. We make the code publicly\navailable [https://github.com/subbareddy248/mllm_videos].", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u6307\u4ee4\u8c03\u4f18\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5728\u89c6\u9891\u548c\u97f3\u9891\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u975e\u6307\u4ee4\u8c03\u4f18\u6a21\u578b\uff0c\u4e14\u5176\u5c42\u6b21\u7ed3\u6784\u4e0e\u5927\u8111\u6d3b\u52a8\u5bf9\u9f50\u3002", "motivation": "\u586b\u8865\u73b0\u6709\u7814\u7a76\u5728\u8bc4\u4f30MLLMs\u4e0e\u5927\u8111\u5bf9\u9f50\u6027\u65f6\u672a\u5145\u5206\u63a2\u7d22\u6307\u4ee4\u8c03\u4f18\u6a21\u578b\u5728\u591a\u5a92\u4f53\u523a\u6fc0\u4e0b\u7684\u8868\u73b0\u7684\u7a7a\u767d\u3002", "method": "\u5229\u752813\u4e2a\u89c6\u9891\u4efb\u52a1\u6307\u4ee4\u8c03\u4f18\u7684MLLMs\uff0c\u6d4b\u91cf\u5176\u8868\u5f81\u5bf9\u81ea\u7136\u7535\u5f71\u89c2\u770b\u65f6\u795e\u7ecf\u6d3b\u52a8\u7684\u9884\u6d4b\u80fd\u529b\u3002", "result": "\u6307\u4ee4\u8c03\u4f18\u7684MLLMs\u5728\u89c6\u9891\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u975e\u6307\u4ee4\u8c03\u4f18\u6a21\u578b15%\uff0c\u5728\u97f3\u9891\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u5355\u6a21\u6001\u6a21\u578b20%\u3002", "conclusion": "\u4efb\u52a1\u7279\u5b9a\u6307\u4ee4\u663e\u8457\u63d0\u5347MLLMs\u4e0e\u5927\u8111\u6d3b\u52a8\u7684\u5bf9\u9f50\u6027\uff0c\u4e3a\u7814\u7a76\u5927\u8111\u4e0e\u6a21\u578b\u7684\u4fe1\u606f\u5904\u7406\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2506.08279", "pdf": "https://arxiv.org/pdf/2506.08279", "abs": "https://arxiv.org/abs/2506.08279", "authors": ["Aditi Sundararaman", "Amogh Adishesha", "Andrew Jaegle", "Dan Bigioi", "Hyoung-Kyu Song", "Jon Kyl", "Justin Mao", "Kevin Lan", "Mojtaba Komeili", "ShahRukh Athar", "Sheila Babayan", "Stanislau Beliasau", "William Buchwalter"], "title": "Seeing Voices: Generating A-Roll Video from Audio with Mirage", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Technical report website: mirage.app/research/seeing-voices, product\n  website: mirage.app", "summary": "From professional filmmaking to user-generated content, creators and\nconsumers have long recognized that the power of video depends on the\nharmonious integration of what we hear (the video's audio track) with what we\nsee (the video's image sequence). Current approaches to video generation either\nignore sound to focus on general-purpose but silent image sequence generation\nor address both visual and audio elements but focus on restricted application\ndomains such as re-dubbing. We introduce Mirage, an audio-to-video foundation\nmodel that excels at generating realistic, expressive output imagery from\nscratch given an audio input. When integrated with existing methods for speech\nsynthesis (text-to-speech, or TTS), Mirage results in compelling multimodal\nvideo. When trained on audio-video footage of people talking (A-roll) and\nconditioned on audio containing speech, Mirage generates video of people\ndelivering a believable interpretation of the performance implicit in input\naudio. Our central technical contribution is a unified method for training\nself-attention-based audio-to-video generation models, either from scratch or\ngiven existing weights. This methodology allows Mirage to retain generality as\nan approach to audio-to-video generation while producing outputs of superior\nsubjective quality to methods that incorporate audio-specific architectures or\nloss components specific to people, speech, or details of how images or audio\nare captured. We encourage readers to watch and listen to the results of Mirage\nfor themselves (see paper and comments for links).", "AI": {"tldr": "Mirage\u662f\u4e00\u79cd\u97f3\u9891\u5230\u89c6\u9891\u7684\u57fa\u7840\u6a21\u578b\uff0c\u80fd\u591f\u6839\u636e\u97f3\u9891\u8f93\u5165\u751f\u6210\u903c\u771f\u3001\u5bcc\u6709\u8868\u73b0\u529b\u7684\u89c6\u9891\uff0c\u9002\u7528\u4e8e\u591a\u6a21\u6001\u89c6\u9891\u751f\u6210\u3002", "motivation": "\u89c6\u9891\u7684\u97f3\u9891\u548c\u56fe\u50cf\u5e8f\u5217\u7684\u548c\u8c10\u7ed3\u5408\u5bf9\u89c6\u9891\u6548\u679c\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u5ffd\u7565\u58f0\u97f3\uff0c\u8981\u4e48\u5c40\u9650\u4e8e\u7279\u5b9a\u9886\u57df\u3002Mirage\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u8bad\u7ec3\u65b9\u6cd5\uff0c\u57fa\u4e8e\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff0c\u652f\u6301\u4ece\u96f6\u5f00\u59cb\u8bad\u7ec3\u6216\u5229\u7528\u73b0\u6709\u6743\u91cd\uff0c\u751f\u6210\u9ad8\u8d28\u91cf\u89c6\u9891\u3002", "result": "Mirage\u751f\u6210\u7684\u89c6\u9891\u5728\u4e3b\u89c2\u8d28\u91cf\u4e0a\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u80fd\u591f\u903c\u771f\u5730\u8868\u73b0\u97f3\u9891\u4e2d\u7684\u8868\u6f14\u5185\u5bb9\u3002", "conclusion": "Mirage\u4e3a\u97f3\u9891\u5230\u89c6\u9891\u751f\u6210\u63d0\u4f9b\u4e86\u901a\u7528\u4e14\u9ad8\u8d28\u91cf\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u591a\u6a21\u6001\u89c6\u9891\u751f\u6210\u3002"}}
{"id": "2506.08325", "pdf": "https://arxiv.org/pdf/2506.08325", "abs": "https://arxiv.org/abs/2506.08325", "authors": ["Marcos Matabuena", "Rahul Ghosal", "Pavlo Mozharovskyi", "Oscar Hernan Madrid Padilla", "Jukka-Pekka Onnela"], "title": "Model-Free Kernel Conformal Depth Measures Algorithm for Uncertainty Quantification in Regression Models in Separable Hilbert Spaces", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": "arXiv admin note: substantial text overlap with arXiv:2405.13970", "summary": "Depth measures are powerful tools for defining level sets in emerging,\nnon--standard, and complex random objects such as high-dimensional multivariate\ndata, functional data, and random graphs. Despite their favorable theoretical\nproperties, the integration of depth measures into regression modeling to\nprovide prediction regions remains a largely underexplored area of research. To\naddress this gap, we propose a novel, model-free uncertainty quantification\nalgorithm based on conditional depth measures--specifically, conditional kernel\nmean embeddings and an integrated depth measure. These new algorithms can be\nused to define prediction and tolerance regions when predictors and responses\nare defined in separable Hilbert spaces. The use of kernel mean embeddings\nensures faster convergence rates in prediction region estimation. To enhance\nthe practical utility of the algorithms with finite samples, we also introduce\na conformal prediction variant that provides marginal, non-asymptotic\nguarantees for the derived prediction regions. Additionally, we establish both\nconditional and unconditional consistency results, as well as fast convergence\nrates in certain homoscedastic settings. We evaluate the finite--sample\nperformance of our model in extensive simulation studies involving various\ntypes of functional data and traditional Euclidean scenarios. Finally, we\ndemonstrate the practical relevance of our approach through a digital health\napplication related to physical activity, aiming to provide personalized\nrecommendations", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6761\u4ef6\u6df1\u5ea6\u5ea6\u91cf\u7684\u65b0\u578b\u6a21\u578b\u65e0\u5173\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7b97\u6cd5\uff0c\u7528\u4e8e\u5b9a\u4e49\u9884\u6d4b\u533a\u57df\uff0c\u9002\u7528\u4e8e\u53ef\u5206\u79bb\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u4e2d\u7684\u9884\u6d4b\u53d8\u91cf\u548c\u54cd\u5e94\u53d8\u91cf\u3002", "motivation": "\u6df1\u5ea6\u5ea6\u91cf\u5728\u590d\u6742\u968f\u673a\u5bf9\u8c61\u4e2d\u5b9a\u4e49\u6c34\u5e73\u96c6\u5177\u6709\u5f3a\u5927\u80fd\u529b\uff0c\u4f46\u5176\u5728\u56de\u5f52\u5efa\u6a21\u4e2d\u7684\u5e94\u7528\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u7ed3\u5408\u6761\u4ef6\u6838\u5747\u503c\u5d4c\u5165\u548c\u96c6\u6210\u6df1\u5ea6\u5ea6\u91cf\uff0c\u63d0\u51fa\u7b97\u6cd5\uff0c\u5e76\u5f15\u5165\u4fdd\u5f62\u9884\u6d4b\u53d8\u4f53\u4ee5\u589e\u5f3a\u5b9e\u7528\u6027\u3002", "result": "\u7b97\u6cd5\u5728\u4eff\u771f\u7814\u7a76\u548c\u5b9e\u9645\u6570\u5b57\u5065\u5eb7\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u63d0\u4f9b\u5feb\u901f\u6536\u655b\u7387\u548c\u4e00\u81f4\u6027\u7ed3\u679c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u590d\u6742\u6570\u636e\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u9884\u6d4b\u533a\u57df\u5b9a\u4e49\u5de5\u5177\uff0c\u5177\u6709\u7406\u8bba\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2506.08336", "pdf": "https://arxiv.org/pdf/2506.08336", "abs": "https://arxiv.org/abs/2506.08336", "authors": ["Li Changjiang", "Liang Jiacheng", "Cao Bochuan", "Chen Jinghui", "Wang Ting"], "title": "Your Agent Can Defend Itself against Backdoor Attacks", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "Despite their growing adoption across domains, large language model\n(LLM)-powered agents face significant security risks from backdoor attacks\nduring training and fine-tuning. These compromised agents can subsequently be\nmanipulated to execute malicious operations when presented with specific\ntriggers in their inputs or environments. To address this pressing risk, we\npresent ReAgent, a novel defense against a range of backdoor attacks on\nLLM-based agents. Intuitively, backdoor attacks often result in inconsistencies\namong the user's instruction, the agent's planning, and its execution. Drawing\non this insight, ReAgent employs a two-level approach to detect potential\nbackdoors. At the execution level, ReAgent verifies consistency between the\nagent's thoughts and actions; at the planning level, ReAgent leverages the\nagent's capability to reconstruct the instruction based on its thought\ntrajectory, checking for consistency between the reconstructed instruction and\nthe user's instruction. Extensive evaluation demonstrates ReAgent's\neffectiveness against various backdoor attacks across tasks. For instance,\nReAgent reduces the attack success rate by up to 90\\% in database operation\ntasks, outperforming existing defenses by large margins. This work reveals the\npotential of utilizing compromised agents themselves to mitigate backdoor\nrisks.", "AI": {"tldr": "ReAgent\u662f\u4e00\u79cd\u9488\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee3\u7406\u540e\u95e8\u653b\u51fb\u7684\u65b0\u578b\u9632\u5fa1\u65b9\u6cd5\uff0c\u901a\u8fc7\u68c0\u6d4b\u7528\u6237\u6307\u4ee4\u3001\u4ee3\u7406\u89c4\u5212\u548c\u6267\u884c\u95f4\u7684\u4e0d\u4e00\u81f4\u6027\u6765\u8bc6\u522b\u540e\u95e8\u3002", "motivation": "\u968f\u7740LLM\u4ee3\u7406\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u540e\u95e8\u653b\u51fb\u5728\u8bad\u7ec3\u548c\u5fae\u8c03\u9636\u6bb5\u5e26\u6765\u7684\u5b89\u5168\u98ce\u9669\u65e5\u76ca\u7a81\u51fa\uff0c\u53ef\u80fd\u5bfc\u81f4\u4ee3\u7406\u5728\u7279\u5b9a\u89e6\u53d1\u6761\u4ef6\u4e0b\u6267\u884c\u6076\u610f\u64cd\u4f5c\u3002", "method": "ReAgent\u91c7\u7528\u4e24\u7ea7\u68c0\u6d4b\u65b9\u6cd5\uff1a\u6267\u884c\u5c42\u9a8c\u8bc1\u4ee3\u7406\u601d\u7ef4\u4e0e\u884c\u52a8\u7684\u4e00\u81f4\u6027\uff1b\u89c4\u5212\u5c42\u901a\u8fc7\u4ee3\u7406\u91cd\u5efa\u6307\u4ee4\u7684\u80fd\u529b\u68c0\u67e5\u5176\u4e0e\u7528\u6237\u6307\u4ee4\u7684\u4e00\u81f4\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cReAgent\u80fd\u6709\u6548\u964d\u4f4e\u653b\u51fb\u6210\u529f\u7387\uff08\u5982\u6570\u636e\u5e93\u64cd\u4f5c\u4efb\u52a1\u4e2d\u653b\u51fb\u6210\u529f\u7387\u964d\u4f4e90%\uff09\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u3002", "conclusion": "ReAgent\u63ed\u793a\u4e86\u5229\u7528\u88ab\u653b\u51fb\u4ee3\u7406\u81ea\u8eab\u80fd\u529b\u7f13\u89e3\u540e\u95e8\u98ce\u9669\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.08338", "pdf": "https://arxiv.org/pdf/2506.08338", "abs": "https://arxiv.org/abs/2506.08338", "authors": ["Ryoichi Asashiba", "Reiji Kozuma", "Hirokazu Iwasawa"], "title": "midr: Learning from Black-Box Models by Maximum Interpretation Decomposition", "categories": ["stat.ME", "cs.LG"], "comment": "20 pages, 10 figures", "summary": "The use of appropriate methods of Interpretable Machine Learning (IML) and\neXplainable Artificial Intelligence (XAI) is essential for adopting black-box\npredictive models in fields where model and prediction explainability is\nrequired. As a novel tool for interpreting black-box models, we introduce the R\npackage midr, which implements Maximum Interpretation Decomposition (MID). MID\nis a functional decomposition approach that derives a low-order additive\nrepresentation of a black-box model by minimizing the squared error between the\nmodel's prediction function and this additive representation. midr enables\nlearning from black-box models by constructing a global surrogate model with\nadvanced analytical capabilities. After reviewing related work and the\ntheoretical foundation of MID, we demonstrate the package's usage and discuss\nsome of its key features.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3amidr\u7684R\u5305\uff0c\u7528\u4e8e\u5b9e\u73b0\u6700\u5927\u89e3\u91ca\u5206\u89e3\uff08MID\uff09\uff0c\u65e8\u5728\u901a\u8fc7\u529f\u80fd\u5206\u89e3\u65b9\u6cd5\u89e3\u91ca\u9ed1\u76d2\u6a21\u578b\u3002", "motivation": "\u5728\u9700\u8981\u6a21\u578b\u548c\u9884\u6d4b\u53ef\u89e3\u91ca\u6027\u7684\u9886\u57df\uff0c\u91c7\u7528\u9002\u5f53\u7684\u53ef\u89e3\u91ca\u673a\u5668\u5b66\u4e60\uff08IML\uff09\u548c\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\uff08XAI\uff09\u65b9\u6cd5\u81f3\u5173\u91cd\u8981\u3002", "method": "MID\u662f\u4e00\u79cd\u529f\u80fd\u5206\u89e3\u65b9\u6cd5\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u9ed1\u76d2\u6a21\u578b\u9884\u6d4b\u51fd\u6570\u4e0e\u4f4e\u9636\u52a0\u6027\u8868\u793a\u4e4b\u95f4\u7684\u5e73\u65b9\u8bef\u5dee\uff0c\u6784\u5efa\u5168\u5c40\u66ff\u4ee3\u6a21\u578b\u3002", "result": "midr\u5305\u80fd\u591f\u4ece\u9ed1\u76d2\u6a21\u578b\u4e2d\u5b66\u4e60\uff0c\u5e76\u63d0\u4f9b\u9ad8\u7ea7\u5206\u6790\u529f\u80fd\u3002", "conclusion": "\u8bba\u6587\u5c55\u793a\u4e86midr\u5305\u7684\u7528\u6cd5\uff0c\u5e76\u8ba8\u8bba\u4e86\u5176\u5173\u952e\u7279\u6027\u3002"}}
{"id": "2506.08344", "pdf": "https://arxiv.org/pdf/2506.08344", "abs": "https://arxiv.org/abs/2506.08344", "authors": ["Ne\u015fet \u00dcnver Akmandor", "Sarvesh Prajapati", "Mark Zolotas", "Ta\u015fk\u0131n Pad\u0131r"], "title": "Re4MPC: Reactive Nonlinear MPC for Multi-model Motion Planning via Deep Reinforcement Learning", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.SY", "eess.SY"], "comment": "Accepted to the 2025 IEEE International Conference on Automation\n  Science and Engineering (CASE)", "summary": "Traditional motion planning methods for robots with many degrees-of-freedom,\nsuch as mobile manipulators, are often computationally prohibitive for\nreal-world settings. In this paper, we propose a novel multi-model motion\nplanning pipeline, termed Re4MPC, which computes trajectories using Nonlinear\nModel Predictive Control (NMPC). Re4MPC generates trajectories in a\ncomputationally efficient manner by reactively selecting the model, cost, and\nconstraints of the NMPC problem depending on the complexity of the task and\nrobot state. The policy for this reactive decision-making is learned via a Deep\nReinforcement Learning (DRL) framework. We introduce a mathematical formulation\nto integrate NMPC into this DRL framework. To validate our methodology and\ndesign choices, we evaluate DRL training and test outcomes in a physics-based\nsimulation involving a mobile manipulator. Experimental results demonstrate\nthat Re4MPC is more computationally efficient and achieves higher success rates\nin reaching end-effector goals than the NMPC baseline, which computes\nwhole-body trajectories without our learning mechanism.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRe4MPC\u7684\u65b0\u578b\u591a\u6a21\u578b\u8fd0\u52a8\u89c4\u5212\u7ba1\u9053\uff0c\u901a\u8fc7\u7ed3\u5408\u975e\u7ebf\u6027\u6a21\u578b\u9884\u6d4b\u63a7\u5236\uff08NMPC\uff09\u548c\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\uff0c\u9ad8\u6548\u751f\u6210\u673a\u5668\u4eba\u8f68\u8ff9\u3002", "motivation": "\u4f20\u7edf\u7684\u9ad8\u81ea\u7531\u5ea6\u673a\u5668\u4eba\u8fd0\u52a8\u89c4\u5212\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u96be\u4ee5\u9002\u7528\u4e8e\u5b9e\u9645\u573a\u666f\u3002", "method": "Re4MPC\u901a\u8fc7DRL\u6846\u67b6\u5b66\u4e60\u53cd\u5e94\u6027\u9009\u62e9NMPC\u6a21\u578b\u3001\u6210\u672c\u548c\u7ea6\u675f\u7684\u7b56\u7565\uff0c\u5e76\u7ed3\u5408NMPC\u751f\u6210\u9ad8\u6548\u8f68\u8ff9\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cRe4MPC\u6bd4\u4f20\u7edfNMPC\u65b9\u6cd5\u8ba1\u7b97\u6548\u7387\u66f4\u9ad8\uff0c\u4e14\u672b\u7aef\u6267\u884c\u5668\u76ee\u6807\u8fbe\u6210\u7387\u66f4\u9ad8\u3002", "conclusion": "Re4MPC\u4e3a\u9ad8\u81ea\u7531\u5ea6\u673a\u5668\u4eba\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u8fd0\u52a8\u89c4\u5212\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.08362", "pdf": "https://arxiv.org/pdf/2506.08362", "abs": "https://arxiv.org/abs/2506.08362", "authors": ["Lesi Chen", "Chengchang Liu", "Luo Luo", "Jingzhao Zhang"], "title": "Solving Convex-Concave Problems with $\\tilde{\\mathcal{O}}(\u03b5^{-4/7})$ Second-Order Oracle Complexity", "categories": ["math.OC", "cs.LG"], "comment": "COLT 2025", "summary": "Previous algorithms can solve convex-concave minimax problems $\\min_{x \\in\n\\mathcal{X}} \\max_{y \\in \\mathcal{Y}} f(x,y)$ with\n$\\mathcal{O}(\\epsilon^{-2/3})$ second-order oracle calls using Newton-type\nmethods. This result has been speculated to be optimal because the upper bound\nis achieved by a natural generalization of the optimal first-order method. In\nthis work, we show an improved upper bound of\n$\\tilde{\\mathcal{O}}(\\epsilon^{-4/7})$ by generalizing the optimal second-order\nmethod for convex optimization to solve the convex-concave minimax problem. We\nfurther apply a similar technique to lazy Hessian algorithms and show that our\nproposed algorithm can also be seen as a second-order ``Catalyst'' framework\n(Lin et al., JMLR 2018) that could accelerate any globally convergent\nalgorithms for solving minimax problems.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.08381", "pdf": "https://arxiv.org/pdf/2506.08381", "abs": "https://arxiv.org/abs/2506.08381", "authors": ["He Yang", "Fei Ren", "Hai-Sui Yu", "Xueyu Geng", "Pei-Zhi Zhuang"], "title": "TS-PIELM: Time-Stepping Physics-Informed Extreme Learning Machine Facilitates Soil Consolidation Analyses", "categories": ["physics.geo-ph", "cs.LG"], "comment": null, "summary": "Accuracy and efficiency of the conventional physics-informed neural network\n(PINN) need to be improved before it can be a competitive alternative for soil\nconsolidation analyses. This paper aims to overcome these limitations by\nproposing a highly accurate and efficient physics-informed machine learning\n(PIML) approach, termed time-stepping physics-informed extreme learning machine\n(TS-PIELM). In the TS-PIELM framework the consolidation process is divided into\nnumerous time intervals, which helps overcome the limitation of PIELM in\nsolving differential equations with sharp gradients. To accelerate network\ntraining, the solution is approximated by a single-layer feedforward extreme\nlearning machine (ELM), rather than using a fully connected neural network in\nPINN. The input layer weights of the ELM network are generated randomly and\nfixed during the training process. Subsequently, the output layer weights are\ndirectly computed by solving a system of linear equations, which significantly\nenhances the training efficiency compared to the time-consuming gradient\ndescent method in PINN. Finally, the superior performance of TS-PIELM is\ndemonstrated by solving three typical Terzaghi consolidation problems. Compared\nto PINN, results show that the computational efficiency and accuracy of the\nnovel TS-PIELM framework are improved by more than 1000 times and 100 times for\none-dimensional cases, respectively. This paper provides compelling evidence\nthat PIML can be a powerful tool for computational geotechnics.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u9ad8\u7cbe\u5ea6\u7684\u7269\u7406\u4fe1\u606f\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff08TS-PIELM\uff09\uff0c\u7528\u4e8e\u6539\u8fdb\u4f20\u7edfPINN\u5728\u571f\u58e4\u56fa\u7ed3\u5206\u6790\u4e2d\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u4f20\u7edf\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\uff08PINN\uff09\u5728\u571f\u58e4\u56fa\u7ed3\u5206\u6790\u4e2d\u7684\u7cbe\u5ea6\u548c\u6548\u7387\u4e0d\u8db3\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "\u63d0\u51faTS-PIELM\u6846\u67b6\uff0c\u5c06\u56fa\u7ed3\u8fc7\u7a0b\u5206\u4e3a\u591a\u4e2a\u65f6\u95f4\u533a\u95f4\uff0c\u4f7f\u7528\u5355\u5c42\u524d\u9988\u6781\u9650\u5b66\u4e60\u673a\uff08ELM\uff09\u52a0\u901f\u8bad\u7ec3\uff0c\u76f4\u63a5\u8ba1\u7b97\u8f93\u51fa\u5c42\u6743\u91cd\u3002", "result": "TS-PIELM\u7684\u8ba1\u7b97\u6548\u7387\u548c\u7cbe\u5ea6\u5206\u522b\u6bd4PINN\u63d0\u9ad8\u4e861000\u500d\u548c100\u500d\u3002", "conclusion": "TS-PIELM\u8bc1\u660e\u4e86\u7269\u7406\u4fe1\u606f\u673a\u5668\u5b66\u4e60\u5728\u8ba1\u7b97\u5ca9\u571f\u5de5\u7a0b\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.08399", "pdf": "https://arxiv.org/pdf/2506.08399", "abs": "https://arxiv.org/abs/2506.08399", "authors": ["Jiachen Ma", "Zhanhui Zhou", "Chao Yang", "Chaochao Lu"], "title": "SafeCoT: Improving VLM Safety with Minimal Reasoning", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Ensuring safe and appropriate responses from vision-language models (VLMs)\nremains a critical challenge, particularly in high-risk or ambiguous scenarios.\nWe introduce SafeCoT, a lightweight, interpretable framework that leverages\nrule-based chain-of-thought (CoT) supervision to improve refusal behavior in\nVLMs. Unlike prior methods that rely on large-scale safety annotations or\ncomplex modeling, SafeCoT uses minimal supervision to help models reason about\nsafety risks and make context-aware refusals. Experiments across multiple\nbenchmarks show that SafeCoT significantly reduces overrefusal and enhances\ngeneralization, even with limited training data. Our approach offers a scalable\nsolution for aligning VLMs with safety-critical objectives.", "AI": {"tldr": "SafeCoT\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u3001\u53ef\u89e3\u91ca\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u89c4\u5219\u5f15\u5bfc\u7684\u601d\u7ef4\u94fe\u76d1\u7763\u6539\u8fdb\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u62d2\u7edd\u884c\u4e3a\uff0c\u51cf\u5c11\u8fc7\u5ea6\u62d2\u7edd\u5e76\u63d0\u5347\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u9ad8\u98ce\u9669\u6216\u6a21\u7cca\u573a\u666f\u4e2d\u7684\u5b89\u5168\u54cd\u5e94\u4ecd\u662f\u4e00\u4e2a\u5173\u952e\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u8f7b\u91cf\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "SafeCoT\u5229\u7528\u89c4\u5219\u5f15\u5bfc\u7684\u601d\u7ef4\u94fe\u76d1\u7763\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u76d1\u7763\u5e2e\u52a9\u6a21\u578b\u63a8\u7406\u5b89\u5168\u98ce\u9669\u5e76\u505a\u51fa\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u62d2\u7edd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSafeCoT\u663e\u8457\u51cf\u5c11\u4e86\u8fc7\u5ea6\u62d2\u7edd\u5e76\u63d0\u5347\u4e86\u6cdb\u5316\u80fd\u529b\uff0c\u5373\u4f7f\u5728\u6709\u9650\u8bad\u7ec3\u6570\u636e\u4e0b\u4e5f\u8868\u73b0\u826f\u597d\u3002", "conclusion": "SafeCoT\u4e3a\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u5bf9\u9f50\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.08400", "pdf": "https://arxiv.org/pdf/2506.08400", "abs": "https://arxiv.org/abs/2506.08400", "authors": ["Luel Hagos Beyene", "Vivek Verma", "Min Ma", "Jesujoba O. Alabi", "Fabian David Schmidt", "Joyce Nakatumba-Nabende", "David Ifeoluwa Adelani"], "title": "mSTEB: Massively Multilingual Evaluation of LLMs on Speech and Text Tasks", "categories": ["cs.CL", "cs.LG", "cs.SD"], "comment": "working paper", "summary": "Large Language models (LLMs) have demonstrated impressive performance on a\nwide range of tasks, including in multimodal settings such as speech. However,\ntheir evaluation is often limited to English and a few high-resource languages.\nFor low-resource languages, there is no standardized evaluation benchmark. In\nthis paper, we address this gap by introducing mSTEB, a new benchmark to\nevaluate the performance of LLMs on a wide range of tasks covering language\nidentification, text classification, question answering, and translation tasks\non both speech and text modalities. We evaluated the performance of leading\nLLMs such as Gemini 2.0 Flash and GPT-4o (Audio) and state-of-the-art open\nmodels such as Qwen 2 Audio and Gemma 3 27B. Our evaluation shows a wide gap in\nperformance between high-resource and low-resource languages, especially for\nlanguages spoken in Africa and Americas/Oceania. Our findings show that more\ninvestment is needed to address their under-representation in LLMs coverage.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86mSTEB\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30LLMs\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u9ad8\u8d44\u6e90\u4e0e\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u6027\u80fd\u5dee\u8ddd\u3002", "motivation": "\u73b0\u6709LLMs\u8bc4\u4f30\u591a\u96c6\u4e2d\u4e8e\u82f1\u8bed\u548c\u9ad8\u8d44\u6e90\u8bed\u8a00\uff0c\u7f3a\u4e4f\u5bf9\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u6807\u51c6\u5316\u8bc4\u4f30\u3002", "method": "\u5f15\u5165mSTEB\u57fa\u51c6\uff0c\u6db5\u76d6\u8bed\u8a00\u8bc6\u522b\u3001\u6587\u672c\u5206\u7c7b\u3001\u95ee\u7b54\u548c\u7ffb\u8bd1\u4efb\u52a1\uff0c\u8bc4\u4f30\u4e86Gemini 2.0 Flash\u3001GPT-4o (Audio)\u7b49\u6a21\u578b\u3002", "result": "\u9ad8\u8d44\u6e90\u4e0e\u4f4e\u8d44\u6e90\u8bed\u8a00\uff08\u5c24\u5176\u662f\u975e\u6d32\u548c\u7f8e\u6d32/\u5927\u6d0b\u6d32\u8bed\u8a00\uff09\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u6027\u80fd\u5dee\u8ddd\u3002", "conclusion": "\u9700\u8981\u66f4\u591a\u6295\u8d44\u4ee5\u89e3\u51b3\u4f4e\u8d44\u6e90\u8bed\u8a00\u5728LLMs\u4e2d\u7684\u4ee3\u8868\u6027\u4e0d\u8db3\u95ee\u9898\u3002"}}
{"id": "2506.08423", "pdf": "https://arxiv.org/pdf/2506.08423", "abs": "https://arxiv.org/abs/2506.08423", "authors": ["Utkarsh Pratiush", "Austin Houston", "Kamyar Barakati", "Aditya Raghavan", "Dasol Yoon", "Harikrishnan KP", "Zhaslan Baraissov", "Desheng Ma", "Samuel S. Welborn", "Mikolaj Jakowski", "Shawn-Patrick Barhorst", "Alexander J. Pattison", "Panayotis Manganaris", "Sita Sirisha Madugula", "Sai Venkata Gayathri Ayyagari", "Vishal Kennedy", "Ralph Bulanadi", "Michelle Wang", "Kieran J. Pang", "Ian Addison-Smith", "Willy Menacho", "Horacio V. Guzman", "Alexander Kiefer", "Nicholas Furth", "Nikola L. Kolev", "Mikhail Petrov", "Viktoriia Liu", "Sergey Ilyev", "Srikar Rairao", "Tommaso Rodani", "Ivan Pinto-Huguet", "Xuli Chen", "Josep Crua\u00f1es", "Marta Torrens", "Jovan Pomar", "Fanzhi Su", "Pawan Vedanti", "Zhiheng Lyu", "Xingzhi Wang", "Lehan Yao", "Amir Taqieddin", "Forrest Laskowski", "Xiangyu Yin", "Yu-Tsun Shao", "Benjamin Fein-Ashley", "Yi Jiang", "Vineet Kumar", "Himanshu Mishra", "Yogesh Paul", "Adib Bazgir", "Rama chandra Praneeth Madugula", "Yuwen Zhang", "Pravan Omprakash", "Jian Huang", "Eric Montufar-Morales", "Vivek Chawla", "Harshit Sethi", "Jie Huang", "Lauri Kurki", "Grace Guinan", "Addison Salvador", "Arman Ter-Petrosyan", "Madeline Van Winkle", "Steven R. Spurgeon", "Ganesh Narasimha", "Zijie Wu", "Richard Liu", "Yongtao Liu", "Boris Slautin", "Andrew R Lupini", "Rama Vasudevan", "Gerd Duscher", "Sergei V. Kalinin"], "title": "Mic-hackathon 2024: Hackathon on Machine Learning for Electron and Scanning Probe Microscopy", "categories": ["cond-mat.mtrl-sci", "cs.LG", "physics.ins-det"], "comment": null, "summary": "Microscopy is a primary source of information on materials structure and\nfunctionality at nanometer and atomic scales. The data generated is often\nwell-structured, enriched with metadata and sample histories, though not always\nconsistent in detail or format. The adoption of Data Management Plans (DMPs) by\nmajor funding agencies promotes preservation and access. However, deriving\ninsights remains difficult due to the lack of standardized code ecosystems,\nbenchmarks, and integration strategies. As a result, data usage is inefficient\nand analysis time is extensive. In addition to post-acquisition analysis, new\nAPIs from major microscope manufacturers enable real-time, ML-based analytics\nfor automated decision-making and ML-agent-controlled microscope operation.\nYet, a gap remains between the ML and microscopy communities, limiting the\nimpact of these methods on physics, materials discovery, and optimization.\nHackathons help bridge this divide by fostering collaboration between ML\nresearchers and microscopy experts. They encourage the development of novel\nsolutions that apply ML to microscopy, while preparing a future workforce for\ninstrumentation, materials science, and applied ML. This hackathon produced\nbenchmark datasets and digital twins of microscopes to support community growth\nand standardized workflows. All related code is available at GitHub:\nhttps://github.com/KalininGroup/Mic-hackathon-2024-codes-publication/tree/1.0.0.1", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u663e\u5fae\u955c\u6570\u636e\u7ba1\u7406\u4e2d\u7684\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u901a\u8fc7\u9ed1\u5ba2\u9a6c\u62c9\u677e\u4fc3\u8fdbML\u4e0e\u663e\u5fae\u955c\u793e\u533a\u5408\u4f5c\uff0c\u4ee5\u5f00\u53d1\u6807\u51c6\u5316\u5de5\u5177\u548c\u6570\u636e\u96c6\u3002", "motivation": "\u663e\u5fae\u955c\u6570\u636e\u867d\u4e30\u5bcc\u4f46\u683c\u5f0f\u4e0d\u4e00\u81f4\uff0c\u7f3a\u4e4f\u6807\u51c6\u5316\u5de5\u5177\u548c\u96c6\u6210\u7b56\u7565\uff0c\u5bfc\u81f4\u5206\u6790\u6548\u7387\u4f4e\u4e0b\u3002ML\u4e0e\u663e\u5fae\u955c\u793e\u533a\u95f4\u7684\u9694\u9602\u9650\u5236\u4e86\u6280\u672f\u8fdb\u6b65\u3002", "method": "\u901a\u8fc7\u9ed1\u5ba2\u9a6c\u62c9\u677e\u4fc3\u8fdbML\u7814\u7a76\u8005\u4e0e\u663e\u5fae\u955c\u4e13\u5bb6\u5408\u4f5c\uff0c\u5f00\u53d1\u6807\u51c6\u5316\u4ee3\u7801\u3001\u57fa\u51c6\u6570\u636e\u96c6\u548c\u6570\u5b57\u5b6a\u751f\u663e\u5fae\u955c\u3002", "result": "\u751f\u6210\u4e86\u57fa\u51c6\u6570\u636e\u96c6\u548c\u663e\u5fae\u955c\u6570\u5b57\u5b6a\u751f\uff0c\u652f\u6301\u793e\u533a\u53d1\u5c55\u548c\u6807\u51c6\u5316\u5de5\u4f5c\u6d41\u7a0b\u3002", "conclusion": "\u9ed1\u5ba2\u9a6c\u62c9\u677e\u662f\u5f25\u5408ML\u4e0e\u663e\u5fae\u955c\u793e\u533a\u5dee\u8ddd\u7684\u6709\u6548\u65b9\u5f0f\uff0c\u4e3a\u672a\u6765\u6280\u672f\u53d1\u5c55\u548c\u4eba\u624d\u57f9\u517b\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.08428", "pdf": "https://arxiv.org/pdf/2506.08428", "abs": "https://arxiv.org/abs/2506.08428", "authors": ["Evan Markou", "Thalaiyasingam Ajanthan", "Stephen Gould"], "title": "Sharper Convergence Rates for Nonconvex Optimisation via Reduction Mappings", "categories": ["math.OC", "cs.LG"], "comment": "37 pages, 5 figures", "summary": "Many high-dimensional optimisation problems exhibit rich geometric structures\nin their set of minimisers, often forming smooth manifolds due to\nover-parametrisation or symmetries. When this structure is known, at least\nlocally, it can be exploited through reduction mappings that reparametrise part\nof the parameter space to lie on the solution manifold. These reductions\nnaturally arise from inner optimisation problems and effectively remove\nredundant directions, yielding a lower-dimensional objective. In this work, we\nintroduce a general framework to understand how such reductions influence the\noptimisation landscape. We show that well-designed reduction mappings improve\ncurvature properties of the objective, leading to better-conditioned problems\nand theoretically faster convergence for gradient-based methods. Our analysis\nunifies a range of scenarios where structural information at optimality is\nleveraged to accelerate convergence, offering a principled explanation for the\nempirical gains observed in such optimisation algorithms.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u9ad8\u7ef4\u4f18\u5316\u95ee\u9898\u4e2d\u6700\u5c0f\u5316\u5668\u7684\u51e0\u4f55\u7ed3\u6784\uff08\u5982\u6d41\u5f62\uff09\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u964d\u7ef4\u6620\u5c04\u6539\u5584\u4f18\u5316\u95ee\u9898\u7684\u66f2\u7387\u6027\u8d28\uff0c\u4ece\u800c\u52a0\u901f\u68af\u5ea6\u65b9\u6cd5\u7684\u6536\u655b\u3002", "motivation": "\u9ad8\u7ef4\u4f18\u5316\u95ee\u9898\u7684\u6700\u5c0f\u5316\u5668\u5e38\u5f62\u6210\u5149\u6ed1\u6d41\u5f62\uff0c\u5229\u7528\u8fd9\u79cd\u7ed3\u6784\u53ef\u4ee5\u53bb\u9664\u5197\u4f59\u65b9\u5411\uff0c\u6539\u5584\u4f18\u5316\u95ee\u9898\u7684\u6027\u8d28\u3002", "method": "\u5f15\u5165\u964d\u7ef4\u6620\u5c04\u6846\u67b6\uff0c\u901a\u8fc7\u91cd\u65b0\u53c2\u6570\u5316\u53c2\u6570\u7a7a\u95f4\uff0c\u4f7f\u5176\u4f4d\u4e8e\u89e3\u6d41\u5f62\u4e0a\uff0c\u4ece\u800c\u964d\u4f4e\u76ee\u6807\u51fd\u6570\u7684\u7ef4\u5ea6\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u8bbe\u8ba1\u826f\u597d\u7684\u964d\u7ef4\u6620\u5c04\u80fd\u6539\u5584\u76ee\u6807\u51fd\u6570\u7684\u66f2\u7387\uff0c\u4f7f\u95ee\u9898\u66f4\u6613\u6c42\u89e3\uff0c\u7406\u8bba\u4e0a\u52a0\u901f\u68af\u5ea6\u65b9\u6cd5\u7684\u6536\u655b\u3002", "conclusion": "\u8be5\u6846\u67b6\u7edf\u4e00\u4e86\u591a\u79cd\u5229\u7528\u7ed3\u6784\u4fe1\u606f\u52a0\u901f\u4f18\u5316\u7684\u573a\u666f\uff0c\u4e3a\u5b9e\u9645\u7b97\u6cd5\u4e2d\u7684\u6027\u80fd\u63d0\u5347\u63d0\u4f9b\u4e86\u7406\u8bba\u89e3\u91ca\u3002"}}
{"id": "2506.08433", "pdf": "https://arxiv.org/pdf/2506.08433", "abs": "https://arxiv.org/abs/2506.08433", "authors": ["Hern\u00e1n Maina", "Nicol\u00e1s Wolovick", "Luciana Benotti"], "title": "Low-resource domain adaptation while minimizing energy and hardware resource consumption", "categories": ["cs.CL", "cs.DC", "cs.LG"], "comment": "A shorter version of this work was accepted as a two-page abstract\n  for presentation at the Widening Natural Language Processing (WiNLP) 2023\n  Workshop. That version was not publicly released, and this is the first\n  public version of the work", "summary": "Training Large Language Models (LLMs) is costly in terms of energy, hardware,\nand annotated data, often resulting in a positionality rooted in predominant\ncultures and values (Santy et al., 2023). Domain adaptation has emerged as a\npromising strategy to better align models with diverse cultural and value\ncontexts (Hershcovich et al., 2022), but its computational cost remains a\nsignificant barrier, particularly for research groups lacking access to\nlarge-scale infrastructure. In this paper, we evaluate how the use of different\nnumerical precisions and data parallelization strategies impacts both training\nspeed (as a proxy to energy and hardware consumption) and model accuracy, with\nthe goal of facilitating domain adaptation in low-resource environments. Our\nfindings are relevant to any setting where energy efficiency, accessibility, or\nlimited hardware availability are key concerns.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u4e0d\u540c\u6570\u503c\u7cbe\u5ea6\u548c\u6570\u636e\u5e76\u884c\u5316\u7b56\u7565\u5bf9LLM\u8bad\u7ec3\u901f\u5ea6\u548c\u6a21\u578b\u7cbe\u5ea6\u7684\u5f71\u54cd\uff0c\u65e8\u5728\u652f\u6301\u4f4e\u8d44\u6e90\u73af\u5883\u4e0b\u7684\u9886\u57df\u9002\u5e94\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u6210\u672c\u9ad8\u4e14\u5b58\u5728\u6587\u5316\u504f\u89c1\uff0c\u9886\u57df\u9002\u5e94\u867d\u6709\u6548\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u5c24\u5176\u5728\u8d44\u6e90\u6709\u9650\u7684\u73af\u5883\u4e2d\u3002", "method": "\u8bc4\u4f30\u4e0d\u540c\u6570\u503c\u7cbe\u5ea6\u548c\u6570\u636e\u5e76\u884c\u5316\u7b56\u7565\u5bf9\u8bad\u7ec3\u901f\u5ea6\u548c\u6a21\u578b\u7cbe\u5ea6\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u5bf9\u80fd\u6e90\u6548\u7387\u3001\u53ef\u8bbf\u95ee\u6027\u6216\u786c\u4ef6\u8d44\u6e90\u6709\u9650\u7684\u73af\u5883\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "conclusion": "\u901a\u8fc7\u4f18\u5316\u6570\u503c\u7cbe\u5ea6\u548c\u5e76\u884c\u5316\u7b56\u7565\uff0c\u53ef\u4ee5\u964d\u4f4e\u9886\u57df\u9002\u5e94\u7684\u8ba1\u7b97\u6210\u672c\uff0c\u4fc3\u8fdb\u4f4e\u8d44\u6e90\u73af\u5883\u4e0b\u7684\u5e94\u7528\u3002"}}
{"id": "2506.08436", "pdf": "https://arxiv.org/pdf/2506.08436", "abs": "https://arxiv.org/abs/2506.08436", "authors": ["Jiujun He", "Huazhen Lin"], "title": "Olica: Efficient Structured Pruning of Large Language Models without Retraining", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted to ICML 2025", "summary": "Most existing structured pruning methods for Large Language Models (LLMs)\nrequire substantial computational and data resources for retraining to\nreestablish the corrupted correlations, making them prohibitively expensive. To\naddress this, we propose a pruning framework for LLMs called Orthogonal\ndecomposition and Linear Calibration (Olica), which eliminates the need for\nretraining. A key observation is that the multi-head attention (MHA) layer\ndepends on two types of matrix products. By treating these matrix products as\nunified entities and applying principal component analysis (PCA), we extract\nthe most important information to compress LLMs without sacrificing accuracy or\ndisrupting their original structure. Consequently, retraining becomes\nunnecessary. A fast decomposition method is devised, reducing the complexity of\nPCA by a factor of the square of the number of attention heads. Additionally,\nto mitigate error accumulation problem caused by pruning the feed-forward\nnetwork (FFN) layer, we introduce a linear calibration method to reconstruct\nthe residual errors of pruned layers using low-rank matrices. By leveraging\nsingular value decomposition (SVD) on the solution of the least-squares\nproblem, these matrices are obtained without requiring retraining. Extensive\nexperiments show that the proposed Olica is efficient in terms of data usage,\nGPU memory, and running time, while delivering superior performance across\nmultiple benchmarks.", "AI": {"tldr": "Olica\u662f\u4e00\u79cd\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u7684LLM\u526a\u679d\u6846\u67b6\uff0c\u901a\u8fc7\u6b63\u4ea4\u5206\u89e3\u548c\u7ebf\u6027\u6821\u51c6\u538b\u7f29\u6a21\u578b\uff0c\u4fdd\u6301\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709LLM\u526a\u679d\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u8ba1\u7b97\u548c\u6570\u636e\u8d44\u6e90\u91cd\u65b0\u8bad\u7ec3\uff0c\u6210\u672c\u9ad8\u6602\u3002", "method": "\u5229\u7528PCA\u5904\u7406\u591a\u5934\u6ce8\u610f\u529b\u5c42\u7684\u77e9\u9635\u4e58\u79ef\uff0c\u8bbe\u8ba1\u5feb\u901f\u5206\u89e3\u65b9\u6cd5\uff1b\u901a\u8fc7SVD\u89e3\u51b3\u6700\u5c0f\u4e8c\u4e58\u95ee\u9898\uff0c\u7ebf\u6027\u6821\u51c6FFN\u5c42\u6b8b\u5dee\u3002", "result": "Olica\u5728\u6570\u636e\u4f7f\u7528\u3001GPU\u5185\u5b58\u548c\u8fd0\u884c\u65f6\u95f4\u4e0a\u9ad8\u6548\uff0c\u6027\u80fd\u4f18\u4e8e\u57fa\u51c6\u3002", "conclusion": "Olica\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u7684LLM\u526a\u679d\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.08448", "pdf": "https://arxiv.org/pdf/2506.08448", "abs": "https://arxiv.org/abs/2506.08448", "authors": ["Hyakka Nakada", "Shu Tanaka"], "title": "Systematic and Efficient Construction of Quadratic Unconstrained Binary Optimization Forms for High-order and Dense Interactions", "categories": ["quant-ph", "cs.LG"], "comment": null, "summary": "Quantum Annealing (QA) can efficiently solve combinatorial optimization\nproblems whose objective functions are represented by Quadratic Unconstrained\nBinary Optimization (QUBO) formulations. For broader applicability of QA,\nquadratization methods are used to transform higher-order problems into QUBOs.\nHowever, quadratization methods for complex problems involving Machine Learning\n(ML) remain largely unknown. In these problems, strong nonlinearity and dense\ninteractions prevent conventional methods from being applied. Therefore, we\nmodel target functions by the sum of rectified linear unit bases, which not\nonly have the ability of universal approximation, but also have an equivalent\nquadratic-polynomial representation. In this study, the proof of concept is\nverified both numerically and analytically. In addition, by combining QA with\nthe proposed quadratization, we design a new black-box optimization scheme, in\nwhich ML surrogate regressors are inputted to QA after the quadratization\nprocess.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u91cf\u5b50\u9000\u706b\uff08QA\uff09\u89e3\u51b3\u9ad8\u9636\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f7f\u7528ReLU\u57fa\u51fd\u6570\u5c06\u76ee\u6807\u51fd\u6570\u8f6c\u5316\u4e3a\u4e8c\u6b21\u65e0\u7ea6\u675f\u4e8c\u8fdb\u5236\u4f18\u5316\uff08QUBO\uff09\u5f62\u5f0f\u3002", "motivation": "\u4f20\u7edf\u4e8c\u6b21\u5316\u65b9\u6cd5\u5728\u5904\u7406\u6d89\u53ca\u673a\u5668\u5b66\u4e60\u7684\u590d\u6742\u95ee\u9898\u65f6\u6548\u679c\u4e0d\u4f73\uff0c\u56e0\u4e3a\u8fd9\u4e9b\u95ee\u9898\u5177\u6709\u5f3a\u975e\u7ebf\u6027\u548c\u5bc6\u96c6\u4ea4\u4e92\u6027\u3002", "method": "\u5229\u7528ReLU\u57fa\u51fd\u6570\u5bf9\u76ee\u6807\u51fd\u6570\u5efa\u6a21\uff0c\u5e76\u5c06\u5176\u8f6c\u5316\u4e3a\u7b49\u6548\u7684\u4e8c\u6b21\u591a\u9879\u5f0f\u8868\u793a\uff0c\u540c\u65f6\u7ed3\u5408QA\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u7684\u9ed1\u76d2\u4f18\u5316\u65b9\u6848\u3002", "result": "\u901a\u8fc7\u6570\u503c\u548c\u89e3\u6790\u65b9\u6cd5\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u53ef\u884c\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u9ed1\u76d2\u4f18\u5316\u4e2d\u7684\u5e94\u7528\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u590d\u6742\u673a\u5668\u5b66\u4e60\u95ee\u9898\u7684\u9ad8\u6548\u4e8c\u6b21\u5316\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u6269\u5c55\u4e86QA\u7684\u5e94\u7528\u8303\u56f4\u3002"}}
{"id": "2506.08455", "pdf": "https://arxiv.org/pdf/2506.08455", "abs": "https://arxiv.org/abs/2506.08455", "authors": ["Julian Berberich", "Tobias Fellner", "Christian Holm"], "title": "The interplay of robustness and generalization in quantum machine learning", "categories": ["quant-ph", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "While adversarial robustness and generalization have individually received\nsubstantial attention in the recent literature on quantum machine learning,\ntheir interplay is much less explored. In this chapter, we address this\ninterplay for variational quantum models, which were recently proposed as\nfunction approximators in supervised learning. We discuss recent results\nquantifying both robustness and generalization via Lipschitz bounds, which\nexplicitly depend on model parameters. Thus, they give rise to a\nregularization-based training approach for robust and generalizable quantum\nmodels, highlighting the importance of trainable data encoding strategies. The\npractical implications of the theoretical results are demonstrated with an\napplication to time series analysis.", "AI": {"tldr": "\u63a2\u8ba8\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u4e2d\u5bf9\u6297\u9c81\u68d2\u6027\u4e0e\u6cdb\u5316\u6027\u7684\u5173\u7cfb\uff0c\u63d0\u51fa\u57fa\u4e8eLipschitz\u754c\u7684\u6b63\u5219\u5316\u8bad\u7ec3\u65b9\u6cd5\u3002", "motivation": "\u7814\u7a76\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u4e2d\u5bf9\u6297\u9c81\u68d2\u6027\u4e0e\u6cdb\u5316\u6027\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u586b\u8865\u73b0\u6709\u6587\u732e\u7684\u7a7a\u767d\u3002", "method": "\u901a\u8fc7Lipschitz\u754c\u91cf\u5316\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u6027\uff0c\u63d0\u51fa\u57fa\u4e8e\u6a21\u578b\u53c2\u6570\u7684\u6b63\u5219\u5316\u8bad\u7ec3\u65b9\u6cd5\u3002", "result": "\u7406\u8bba\u7ed3\u679c\u5728\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u4e2d\u5f97\u5230\u9a8c\u8bc1\uff0c\u5c55\u793a\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "conclusion": "\u5f3a\u8c03\u53ef\u8bad\u7ec3\u6570\u636e\u7f16\u7801\u7b56\u7565\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u9c81\u68d2\u4e14\u6cdb\u5316\u6027\u5f3a\u7684\u91cf\u5b50\u6a21\u578b\u63d0\u4f9b\u65b0\u601d\u8def\u3002"}}
{"id": "2506.08500", "pdf": "https://arxiv.org/pdf/2506.08500", "abs": "https://arxiv.org/abs/2506.08500", "authors": ["Arie Cattan", "Alon Jacovi", "Ori Ram", "Jonathan Herzig", "Roee Aharoni", "Sasha Goldshtein", "Eran Ofek", "Idan Szpektor", "Avi Caciularu"], "title": "DRAGged into Conflicts: Detecting and Addressing Conflicting Sources in Search-Augmented LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Retrieval Augmented Generation (RAG) is a commonly used approach for\nenhancing large language models (LLMs) with relevant and up-to-date\ninformation. However, the retrieved sources can often contain conflicting\ninformation and it remains unclear how models should address such\ndiscrepancies. In this work, we first propose a novel taxonomy of knowledge\nconflict types in RAG, along with the desired model behavior for each type. We\nthen introduce CONFLICTS, a high-quality benchmark with expert annotations of\nconflict types in a realistic RAG setting. CONFLICTS is the first benchmark\nthat enables tracking progress on how models address a wide range of knowledge\nconflicts. We conduct extensive experiments on this benchmark, showing that\nLLMs often struggle to appropriately resolve conflicts between sources. While\nprompting LLMs to explicitly reason about the potential conflict in the\nretrieved documents significantly improves the quality and appropriateness of\ntheir responses, substantial room for improvement in future research remains.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86RAG\u4e2d\u77e5\u8bc6\u51b2\u7a81\u7684\u5206\u7c7b\u6cd5\uff0c\u5e76\u521b\u5efa\u4e86CONFLICTS\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30LLMs\u5728\u89e3\u51b3\u51b2\u7a81\u65f6\u7684\u8868\u73b0\u3002\u5b9e\u9a8c\u8868\u660e\uff0cLLMs\u5728\u89e3\u51b3\u51b2\u7a81\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u4f46\u901a\u8fc7\u63d0\u793a\u5176\u663e\u5f0f\u63a8\u7406\u53ef\u6539\u5584\u7ed3\u679c\u3002", "motivation": "\u89e3\u51b3RAG\u4e2d\u68c0\u7d22\u5230\u7684\u4fe1\u606f\u51b2\u7a81\u95ee\u9898\uff0c\u660e\u786e\u6a21\u578b\u5e94\u5982\u4f55\u5904\u7406\u4e0d\u540c\u7c7b\u578b\u7684\u51b2\u7a81\u3002", "method": "\u63d0\u51fa\u77e5\u8bc6\u51b2\u7a81\u5206\u7c7b\u6cd5\uff0c\u521b\u5efaCONFLICTS\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30LLMs\u7684\u8868\u73b0\u3002", "result": "LLMs\u5728\u89e3\u51b3\u51b2\u7a81\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u4f46\u663e\u5f0f\u63a8\u7406\u63d0\u793a\u80fd\u663e\u8457\u6539\u5584\u7ed3\u679c\u3002", "conclusion": "\u672a\u6765\u7814\u7a76\u4ecd\u9700\u6539\u8fdbLLMs\u5728\u89e3\u51b3\u77e5\u8bc6\u51b2\u7a81\u65b9\u9762\u7684\u80fd\u529b\u3002"}}
{"id": "2506.08504", "pdf": "https://arxiv.org/pdf/2506.08504", "abs": "https://arxiv.org/abs/2506.08504", "authors": ["Divyaksh Shukla", "Ritesh Baviskar", "Dwijesh Gohil", "Aniket Tiwari", "Atul Shree", "Ashutosh Modi"], "title": "CoMuMDR: Code-mixed Multi-modal Multi-domain corpus for Discourse paRsing in conversations", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted at ACL Findings 2025 (16 pages: 5 pages main content + 3\n  pages references + 8 pages appendix)", "summary": "Discourse parsing is an important task useful for NLU applications such as\nsummarization, machine comprehension, and emotion recognition. The current\ndiscourse parsing datasets based on conversations consists of written English\ndialogues restricted to a single domain. In this resource paper, we introduce\nCoMuMDR: Code-mixed Multi-modal Multi-domain corpus for Discourse paRsing in\nconversations. The corpus (code-mixed in Hindi and English) has both audio and\ntranscribed text and is annotated with nine discourse relations. We experiment\nwith various SoTA baseline models; the poor performance of SoTA models\nhighlights the challenges of multi-domain code-mixed corpus, pointing towards\nthe need for developing better models for such realistic settings.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86CoMuMDR\u8bed\u6599\u5e93\uff0c\u7528\u4e8e\u591a\u6a21\u6001\u591a\u9886\u57df\u4ee3\u7801\u6df7\u5408\u5bf9\u8bdd\u7684\u7bc7\u7ae0\u89e3\u6790\uff0c\u5e76\u5c55\u793a\u4e86\u73b0\u6709\u6a21\u578b\u7684\u6027\u80fd\u4e0d\u8db3\u3002", "motivation": "\u5f53\u524d\u7bc7\u7ae0\u89e3\u6790\u6570\u636e\u96c6\u5c40\u9650\u4e8e\u5355\u4e00\u9886\u57df\u7684\u82f1\u6587\u5bf9\u8bdd\uff0c\u7f3a\u4e4f\u591a\u6a21\u6001\u548c\u4ee3\u7801\u6df7\u5408\u7684\u8bed\u6599\u5e93\u3002", "method": "\u6784\u5efa\u4e86\u5305\u542b\u5370\u5730\u8bed\u548c\u82f1\u8bed\u4ee3\u7801\u6df7\u5408\u7684\u591a\u6a21\u6001\u8bed\u6599\u5e93CoMuMDR\uff0c\u6807\u6ce8\u4e86\u4e5d\u79cd\u7bc7\u7ae0\u5173\u7cfb\uff0c\u5e76\u6d4b\u8bd5\u4e86\u591a\u79cd\u57fa\u7ebf\u6a21\u578b\u3002", "result": "\u73b0\u6709\u6a21\u578b\u5728\u4ee3\u7801\u6df7\u5408\u591a\u9886\u57df\u8bed\u6599\u5e93\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u51f8\u663e\u4e86\u5f00\u53d1\u66f4\u4f18\u6a21\u578b\u7684\u5fc5\u8981\u6027\u3002", "conclusion": "\u591a\u6a21\u6001\u4ee3\u7801\u6df7\u5408\u8bed\u6599\u5e93\u4e3a\u7bc7\u7ae0\u89e3\u6790\u63d0\u51fa\u4e86\u65b0\u6311\u6218\uff0c\u9700\u8fdb\u4e00\u6b65\u6539\u8fdb\u6a21\u578b\u4ee5\u9002\u5e94\u73b0\u5b9e\u573a\u666f\u3002"}}
{"id": "2506.08507", "pdf": "https://arxiv.org/pdf/2506.08507", "abs": "https://arxiv.org/abs/2506.08507", "authors": ["Kuo Yang", "Xingjie Yang", "Linhui Yu", "Qing Xu", "Yan Fang", "Xu Wang", "Zhengyang Zhou", "Yang Wang"], "title": "MasHost Builds It All: Autonomous Multi-Agent System Directed by Reinforcement Learning", "categories": ["cs.MA", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Model (LLM)-driven Multi-agent systems (Mas) have recently\nemerged as a powerful paradigm for tackling complex real-world tasks. However,\nexisting Mas construction methods typically rely on manually crafted\ninteraction mechanisms or heuristic rules, introducing human biases and\nconstraining the autonomous ability. Even with recent advances in adaptive Mas\nconstruction, existing systems largely remain within the paradigm of\nsemi-autonomous patterns. In this work, we propose MasHost, a Reinforcement\nLearning (RL)-based framework for autonomous and query-adaptive Mas design. By\nformulating Mas construction as a graph search problem, our proposed MasHost\njointly samples agent roles and their interactions through a unified\nprobabilistic sampling mechanism. Beyond the accuracy and efficiency objectives\npursued in prior works, we introduce component rationality as an additional and\nnovel design principle in Mas. To achieve this multi-objective optimization, we\npropose Hierarchical Relative Policy Optimization (HRPO), a novel RL strategy\nthat collaboratively integrates group-relative advantages and action-wise\nrewards. To our knowledge, our proposed MasHost is the first RL-driven\nframework for autonomous Mas graph construction. Extensive experiments on six\nbenchmarks demonstrate that MasHost consistently outperforms most competitive\nbaselines, validating its effectiveness, efficiency, and structure rationality.", "AI": {"tldr": "MasHost\u662f\u4e00\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u4e3b\u548c\u67e5\u8be2\u81ea\u9002\u5e94\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u901a\u8fc7\u56fe\u641c\u7d22\u95ee\u9898\u548c\u6982\u7387\u91c7\u6837\u673a\u5236\u4f18\u5316\u667a\u80fd\u4f53\u89d2\u8272\u548c\u4ea4\u4e92\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6784\u5efa\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u8bbe\u8ba1\u7684\u4ea4\u4e92\u673a\u5236\u6216\u542f\u53d1\u5f0f\u89c4\u5219\uff0c\u9650\u5236\u4e86\u81ea\u4e3b\u80fd\u529b\u5e76\u5f15\u5165\u4eba\u4e3a\u504f\u89c1\u3002", "method": "\u5c06\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6784\u5efa\u5efa\u6a21\u4e3a\u56fe\u641c\u7d22\u95ee\u9898\uff0c\u901a\u8fc7\u7edf\u4e00\u7684\u6982\u7387\u91c7\u6837\u673a\u5236\u8054\u5408\u91c7\u6837\u667a\u80fd\u4f53\u89d2\u8272\u548c\u4ea4\u4e92\uff0c\u5e76\u5f15\u5165\u5206\u5c42\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff08HRPO\uff09\u8fdb\u884c\u591a\u76ee\u6807\u4f18\u5316\u3002", "result": "\u5728\u516d\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMasHost\u8868\u73b0\u4f18\u4e8e\u5927\u591a\u6570\u7ade\u4e89\u57fa\u7ebf\uff0c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3001\u6548\u7387\u548c\u7ed3\u6784\u5408\u7406\u6027\u3002", "conclusion": "MasHost\u662f\u9996\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u81ea\u4e3b\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u56fe\u6784\u5efa\u6846\u67b6\uff0c\u4e3a\u590d\u6742\u4efb\u52a1\u63d0\u4f9b\u4e86\u66f4\u81ea\u4e3b\u548c\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.08518", "pdf": "https://arxiv.org/pdf/2506.08518", "abs": "https://arxiv.org/abs/2506.08518", "authors": ["Sunny Gupta", "Nikita Jangid", "Shounak Das", "Amit Sethi"], "title": "FEDTAIL: Federated Long-Tailed Domain Generalization with Sharpness-Guided Gradient Matching", "categories": ["cs.AI", "cs.CV", "cs.LG", "I.2.6; C.1.4; D.1.3; I.5.1; H.3.4; I.2.10; I.4.0; I.4.1; I.4.2;\n  I.4.6; I.4.7; I.4.8; I.4.9; I.4.10; I.5.1; I.5.2; I.5.4; J.2; I.2.11; I.2.10"], "comment": "Accepted at ICML 2025 Workshop on Collaborative and Federated Agentic\n  Workflows CFAgentic @ ICML'25", "summary": "Domain Generalization (DG) seeks to train models that perform reliably on\nunseen target domains without access to target data during training. While\nrecent progress in smoothing the loss landscape has improved generalization,\nexisting methods often falter under long-tailed class distributions and\nconflicting optimization objectives. We introduce FedTAIL, a federated domain\ngeneralization framework that explicitly addresses these challenges through\nsharpness-guided, gradient-aligned optimization. Our method incorporates a\ngradient coherence regularizer to mitigate conflicts between classification and\nadversarial objectives, leading to more stable convergence. To combat class\nimbalance, we perform class-wise sharpness minimization and propose a\ncurvature-aware dynamic weighting scheme that adaptively emphasizes\nunderrepresented tail classes. Furthermore, we enhance conditional distribution\nalignment by integrating sharpness-aware perturbations into entropy\nregularization, improving robustness under domain shift. FedTAIL unifies\noptimization harmonization, class-aware regularization, and conditional\nalignment into a scalable, federated-compatible framework. Extensive\nevaluations across standard domain generalization benchmarks demonstrate that\nFedTAIL achieves state-of-the-art performance, particularly in the presence of\ndomain shifts and label imbalance, validating its effectiveness in both\ncentralized and federated settings. Code: https://github.com/sunnyinAI/FedTail", "AI": {"tldr": "FedTAIL\u662f\u4e00\u4e2a\u8054\u90a6\u9886\u57df\u6cdb\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u68af\u5ea6\u5bf9\u9f50\u4f18\u5316\u548c\u7c7b\u611f\u77e5\u6b63\u5219\u5316\u89e3\u51b3\u957f\u5c3e\u5206\u5e03\u548c\u4f18\u5316\u51b2\u7a81\u95ee\u9898\uff0c\u5728\u9886\u57df\u6cdb\u5316\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u89e3\u51b3\u9886\u57df\u6cdb\u5316\u4e2d\u957f\u5c3e\u7c7b\u5206\u5e03\u548c\u4f18\u5316\u76ee\u6807\u51b2\u7a81\u7684\u95ee\u9898\uff0c\u63d0\u5347\u6a21\u578b\u5728\u672a\u89c1\u76ee\u6807\u57df\u4e0a\u7684\u6027\u80fd\u3002", "method": "\u91c7\u7528\u68af\u5ea6\u4e00\u81f4\u6027\u6b63\u5219\u5316\u51cf\u5c11\u5206\u7c7b\u4e0e\u5bf9\u6297\u76ee\u6807\u7684\u51b2\u7a81\uff0c\u7c7b\u611f\u77e5\u9510\u5ea6\u6700\u5c0f\u5316\u53ca\u52a8\u6001\u52a0\u6743\u65b9\u6848\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\uff0c\u7ed3\u5408\u9510\u5ea6\u611f\u77e5\u6270\u52a8\u589e\u5f3a\u6761\u4ef6\u5206\u5e03\u5bf9\u9f50\u3002", "result": "\u5728\u6807\u51c6\u9886\u57df\u6cdb\u5316\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cFedTAIL\u8868\u73b0\u6700\u4f18\uff0c\u5c24\u5176\u5728\u9886\u57df\u504f\u79fb\u548c\u6807\u7b7e\u4e0d\u5e73\u8861\u60c5\u51b5\u4e0b\u3002", "conclusion": "FedTAIL\u901a\u8fc7\u4f18\u5316\u534f\u8c03\u3001\u7c7b\u611f\u77e5\u6b63\u5219\u5316\u548c\u6761\u4ef6\u5bf9\u9f50\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u5728\u96c6\u4e2d\u5f0f\u548c\u8054\u90a6\u8bbe\u7f6e\u4e0b\u5747\u6709\u6548\u63d0\u5347\u6cdb\u5316\u6027\u80fd\u3002"}}
{"id": "2506.08528", "pdf": "https://arxiv.org/pdf/2506.08528", "abs": "https://arxiv.org/abs/2506.08528", "authors": ["Yu Guan", "Zhiyu Yin", "Haoyu Chen", "Sheng Cheng", "Chaojie Yang", "Tianyin Xu", "Yang Zhang", "Hanyu Zhao", "Yong Li", "Dennis Cai", "Ennan Zhai"], "title": "PerfTracker: Online Performance Troubleshooting for Large-scale Model Training in Production", "categories": ["cs.DC", "cs.LG", "cs.OS"], "comment": null, "summary": "Troubleshooting performance problems of large model training (LMT) is\nimmensely challenging, due to unprecedented scales of modern GPU clusters, the\ncomplexity of software-hardware interactions, and the data intensity of the\ntraining process. Existing troubleshooting approaches designed for traditional\ndistributed systems or datacenter networks fall short and can hardly apply to\nreal-world training systems. In this paper, we present PerfTracker, the first\nonline troubleshooting system utilizing fine-grained profiling, to diagnose\nperformance issues of large-scale model training in production. PerfTracker can\ndiagnose performance issues rooted in both hardware (e.g., GPUs and their\ninterconnects) and software (e.g., Python functions and GPU operations). It\nscales to LMT on modern GPU clusters. PerfTracker effectively summarizes\nruntime behavior patterns of fine-grained LMT functions via online profiling,\nand leverages differential observability to localize the root cause with\nminimal production impact. PerfTracker has been deployed as a production\nservice for large-scale GPU clusters of O(10, 000) GPUs (product homepage\nhttps://help.aliyun.com/zh/pai/user-guide/perftracker-online-performance-analysis-diagnostic-tool).\nIt has been used to diagnose a variety of difficult performance issues.", "AI": {"tldr": "PerfTracker\u662f\u4e00\u4e2a\u5728\u7ebf\u6027\u80fd\u8bca\u65ad\u7cfb\u7edf\uff0c\u7528\u4e8e\u89e3\u51b3\u5927\u89c4\u6a21\u6a21\u578b\u8bad\u7ec3\u4e2d\u7684\u6027\u80fd\u95ee\u9898\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u5206\u6790\u548c\u5dee\u5f02\u53ef\u89c2\u6d4b\u6027\u5b9a\u4f4d\u95ee\u9898\u6839\u6e90\u3002", "motivation": "\u73b0\u4ee3GPU\u96c6\u7fa4\u89c4\u6a21\u5e9e\u5927\uff0c\u8f6f\u786c\u4ef6\u4ea4\u4e92\u590d\u6742\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u5927\u89c4\u6a21\u6a21\u578b\u8bad\u7ec3\u7684\u6027\u80fd\u95ee\u9898\u3002", "method": "PerfTracker\u5229\u7528\u7ec6\u7c92\u5ea6\u5206\u6790\u548c\u5728\u7ebf\u6027\u80fd\u5206\u6790\uff0c\u7ed3\u5408\u5dee\u5f02\u53ef\u89c2\u6d4b\u6027\uff0c\u8bca\u65ad\u786c\u4ef6\u548c\u8f6f\u4ef6\u5c42\u9762\u7684\u6027\u80fd\u95ee\u9898\u3002", "result": "PerfTracker\u5df2\u90e8\u7f72\u5728\u4e07\u7ea7GPU\u96c6\u7fa4\u4e2d\uff0c\u6210\u529f\u8bca\u65ad\u591a\u79cd\u590d\u6742\u6027\u80fd\u95ee\u9898\u3002", "conclusion": "PerfTracker\u4e3a\u5927\u89c4\u6a21\u6a21\u578b\u8bad\u7ec3\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u6027\u80fd\u95ee\u9898\u8bca\u65ad\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.08535", "pdf": "https://arxiv.org/pdf/2506.08535", "abs": "https://arxiv.org/abs/2506.08535", "authors": ["Ronald Katende"], "title": "Structured Variational $D$-Decomposition for Accurate and Stable Low-Rank Approximation", "categories": ["math.NA", "cs.LG", "cs.NA"], "comment": null, "summary": "We introduce the $D$-decomposition, a non-orthogonal matrix factorization of\nthe form $A \\approx P D Q$, where $P \\in \\mathbb{R}^{n \\times k}$, $D \\in\n\\mathbb{R}^{k \\times k}$, and $Q \\in \\mathbb{R}^{k \\times n}$. The\ndecomposition is defined variationally by minimizing a regularized Frobenius\nloss, allowing control over rank, sparsity, and conditioning. Unlike algebraic\nfactorizations such as LU or SVD, it is computed by alternating minimization.\nWe establish existence and perturbation stability of the solution and show that\neach update has complexity $\\mathcal{O}(n^2k)$. Benchmarks against truncated\nSVD, CUR, and nonnegative matrix factorization show improved reconstruction\naccuracy on MovieLens, MNIST, Olivetti Faces, and gene expression matrices,\nparticularly under sparsity and noise.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u975e\u6b63\u4ea4\u77e9\u9635\u5206\u89e3\u65b9\u6cd5$D$-decomposition\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u6b63\u5219\u5316Frobenius\u635f\u5931\u5b9e\u73b0\uff0c\u652f\u6301\u63a7\u5236\u79e9\u3001\u7a00\u758f\u6027\u548c\u6761\u4ef6\u6570\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u4e3a$\\mathcal{O}(n^2k)$\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u77e9\u9635\u5206\u89e3\u65b9\u6cd5\uff08\u5982LU\u6216SVD\uff09\u5728\u63a7\u5236\u79e9\u3001\u7a00\u758f\u6027\u548c\u6761\u4ef6\u6570\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u7075\u6d3b\u4e14\u8ba1\u7b97\u9ad8\u6548\u7684\u975e\u6b63\u4ea4\u5206\u89e3\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa$D$-decomposition\uff0c\u5f62\u5f0f\u4e3a$A \\approx P D Q$\uff0c\u901a\u8fc7\u4ea4\u66ff\u6700\u5c0f\u5316\u6b63\u5219\u5316Frobenius\u635f\u5931\u5b9e\u73b0\u5206\u89e3\uff0c\u652f\u6301\u5bf9\u79e9\u3001\u7a00\u758f\u6027\u548c\u6761\u4ef6\u6570\u7684\u63a7\u5236\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728MovieLens\u3001MNIST\u3001Olivetti Faces\u548c\u57fa\u56e0\u8868\u8fbe\u77e9\u9635\u4e0a\uff0c\u5c24\u5176\u5728\u7a00\u758f\u6027\u548c\u566a\u58f0\u6761\u4ef6\u4e0b\uff0c\u91cd\u5efa\u7cbe\u5ea6\u4f18\u4e8e\u622a\u65adSVD\u3001CUR\u548c\u975e\u8d1f\u77e9\u9635\u5206\u89e3\u3002", "conclusion": "$D$-decomposition\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u7075\u6d3b\u7684\u975e\u6b63\u4ea4\u77e9\u9635\u5206\u89e3\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u5b9e\u9645\u573a\u666f\uff0c\u5c24\u5176\u5728\u7a00\u758f\u548c\u566a\u58f0\u6570\u636e\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2506.08548", "pdf": "https://arxiv.org/pdf/2506.08548", "abs": "https://arxiv.org/abs/2506.08548", "authors": ["Moria Mayala", "Erwan Scornet", "Charles Tillier", "Olivier Wintenberger"], "title": "Asymptotic Normality of Infinite Centered Random Forests -Application to Imbalanced Classification", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Many classification tasks involve imbalanced data, in which a class is\nlargely underrepresented. Several techniques consists in creating a rebalanced\ndataset on which a classifier is trained. In this paper, we study theoretically\nsuch a procedure, when the classifier is a Centered Random Forests (CRF). We\nestablish a Central Limit Theorem (CLT) on the infinite CRF with explicit rates\nand exact constant. We then prove that the CRF trained on the rebalanced\ndataset exhibits a bias, which can be removed with appropriate techniques.\nBased on an importance sampling (IS) approach, the resulting debiased\nestimator, called IS-ICRF, satisfies a CLT centered at the prediction function\nvalue. For high imbalance settings, we prove that the IS-ICRF estimator enjoys\na variance reduction compared to the ICRF trained on the original data.\nTherefore, our theoretical analysis highlights the benefits of training random\nforests on a rebalanced dataset (followed by a debiasing procedure) compared to\nusing the original data. Our theoretical results, especially the variance rates\nand the variance reduction, appear to be valid for Breiman's random forests in\nour experiments.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u7c7b\u522b\u4e0d\u5e73\u8861\u6570\u636e\u4e0a\u8bad\u7ec3\u4e2d\u5fc3\u5316\u968f\u673a\u68ee\u6797\uff08CRF\uff09\u7684\u7406\u8bba\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u91cd\u8981\u6027\u91c7\u6837\uff08IS\uff09\u7684\u53bb\u504f\u4f30\u8ba1\u5668\uff08IS-ICRF\uff09\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u5728\u9ad8\u5ea6\u4e0d\u5e73\u8861\u6570\u636e\u4e2d\u5177\u6709\u65b9\u5dee\u51cf\u5c11\u7684\u4f18\u52bf\u3002", "motivation": "\u7c7b\u522b\u4e0d\u5e73\u8861\u6570\u636e\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u5e38\u89c1\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u53ef\u80fd\u5bfc\u81f4\u5206\u7c7b\u5668\u504f\u5dee\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u7406\u8bba\u5206\u6790\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u4e2d\u5fc3\u5316\u968f\u673a\u68ee\u6797\uff08CRF\uff09\u5728\u91cd\u5e73\u8861\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\uff0c\u5e76\u901a\u8fc7\u91cd\u8981\u6027\u91c7\u6837\uff08IS\uff09\u53bb\u504f\uff0c\u63d0\u51faIS-ICRF\u4f30\u8ba1\u5668\u3002", "result": "\u8bc1\u660e\u4e86IS-ICRF\u6ee1\u8db3\u4e2d\u5fc3\u6781\u9650\u5b9a\u7406\uff08CLT\uff09\uff0c\u5e76\u5728\u9ad8\u5ea6\u4e0d\u5e73\u8861\u6570\u636e\u4e2d\u5b9e\u73b0\u4e86\u65b9\u5dee\u51cf\u5c11\u3002", "conclusion": "\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u91cd\u5e73\u8861\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u968f\u673a\u68ee\u6797\uff08\u5e76\u53bb\u504f\uff09\u4f18\u4e8e\u76f4\u63a5\u4f7f\u7528\u539f\u59cb\u6570\u636e\u3002"}}
{"id": "2506.08558", "pdf": "https://arxiv.org/pdf/2506.08558", "abs": "https://arxiv.org/abs/2506.08558", "authors": ["William de Vazelhes", "Xiao-Tong Yuan", "Bin Gu"], "title": "Optimization over Sparse Support-Preserving Sets: Two-Step Projection with Global Optimality Guarantees", "categories": ["math.OC", "cs.LG"], "comment": "Accepted for publication at ICML 2025", "summary": "In sparse optimization, enforcing hard constraints using the $\\ell_0$\npseudo-norm offers advantages like controlled sparsity compared to convex\nrelaxations. However, many real-world applications demand not only sparsity\nconstraints but also some extra constraints. While prior algorithms have been\ndeveloped to address this complex scenario with mixed combinatorial and convex\nconstraints, they typically require the closed form projection onto the mixed\nconstraints which might not exist, and/or only provide local guarantees of\nconvergence which is different from the global guarantees commonly sought in\nsparse optimization. To fill this gap, in this paper, we study the problem of\nsparse optimization with extra \\qw{\\textit{support-preserving}} constraints\ncommonly encountered in the literature. We present a new variant of iterative\nhard-thresholding algorithm equipped with a two-step consecutive projection\noperator customized for these mixed constraints, serving as a simple\nalternative to the Euclidean projection onto the mixed constraint. By\nintroducing a novel trade-off between sparsity relaxation and sub-optimality,\nwe provide global guarantees in objective value for the output of our\nalgorithm, in the deterministic, stochastic, and zeroth-order settings, under\nthe conventional restricted strong-convexity/smoothness assumptions. As a\nfundamental contribution in proof techniques, we develop a novel extension of\nthe classic three-point lemma to the considered two-step non-convex projection\noperator, which allows us to analyze the convergence in objective value in an\nelegant way that has not been possible with existing techniques. In the\nzeroth-order case, such technique also improves upon the state-of-the-art\nresult from de Vazelhes et. al. (2022), even in the case without additional\nconstraints, by allowing us to remove a non-vanishing system error present in\ntheir work.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.08570", "pdf": "https://arxiv.org/pdf/2506.08570", "abs": "https://arxiv.org/abs/2506.08570", "authors": ["Or Tal", "Felix Kreuk", "Yossi Adi"], "title": "Auto-Regressive vs Flow-Matching: a Comparative Study of Modeling Paradigms for Text-to-Music Generation", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "comment": null, "summary": "Recent progress in text-to-music generation has enabled models to synthesize\nhigh-quality musical segments, full compositions, and even respond to\nfine-grained control signals, e.g. chord progressions. State-of-the-art (SOTA)\nsystems differ significantly across many dimensions, such as training datasets,\nmodeling paradigms, and architectural choices. This diversity complicates\nefforts to evaluate models fairly and pinpoint which design choices most\ninfluence performance. While factors like data and architecture are important,\nin this study we focus exclusively on the modeling paradigm. We conduct a\nsystematic empirical analysis to isolate its effects, offering insights into\nassociated trade-offs and emergent behaviors that can guide future\ntext-to-music generation systems. Specifically, we compare the two arguably\nmost common modeling paradigms: Auto-Regressive decoding and Conditional\nFlow-Matching. We conduct a controlled comparison by training all models from\nscratch using identical datasets, training configurations, and similar backbone\narchitectures. Performance is evaluated across multiple axes, including\ngeneration quality, robustness to inference configurations, scalability,\nadherence to both textual and temporally aligned conditioning, and editing\ncapabilities in the form of audio inpainting. This comparative study sheds\nlight on distinct strengths and limitations of each paradigm, providing\nactionable insights that can inform future architectural and training decisions\nin the evolving landscape of text-to-music generation. Audio sampled examples\nare available at: https://huggingface.co/spaces/ortal1602/ARvsFM", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u7cfb\u7edf\u6bd4\u8f83\u81ea\u56de\u5f52\u89e3\u7801\u548c\u6761\u4ef6\u6d41\u5339\u914d\u4e24\u79cd\u5efa\u6a21\u8303\u5f0f\uff0c\u5206\u6790\u4e86\u5b83\u4eec\u5728\u6587\u672c\u5230\u97f3\u4e50\u751f\u6210\u4e2d\u7684\u8868\u73b0\uff0c\u4e3a\u672a\u6765\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u6307\u5bfc\u3002", "motivation": "\u5f53\u524d\u6587\u672c\u5230\u97f3\u4e50\u751f\u6210\u6a21\u578b\u7684\u591a\u6837\u6027\u4f7f\u5f97\u516c\u5e73\u8bc4\u4f30\u548c\u8bbe\u8ba1\u9009\u62e9\u7684\u5f71\u54cd\u96be\u4ee5\u786e\u5b9a\uff0c\u7814\u7a76\u4e13\u6ce8\u4e8e\u5efa\u6a21\u8303\u5f0f\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u76f8\u540c\u6570\u636e\u96c6\u3001\u8bad\u7ec3\u914d\u7f6e\u548c\u7c7b\u4f3c\u67b6\u6784\uff0c\u5bf9\u6bd4\u81ea\u56de\u5f52\u89e3\u7801\u548c\u6761\u4ef6\u6d41\u5339\u914d\u4e24\u79cd\u8303\u5f0f\uff0c\u8bc4\u4f30\u751f\u6210\u8d28\u91cf\u3001\u9c81\u68d2\u6027\u7b49\u3002", "result": "\u63ed\u793a\u4e86\u4e24\u79cd\u8303\u5f0f\u7684\u4f18\u7f3a\u70b9\uff0c\u4e3a\u672a\u6765\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\u3002", "conclusion": "\u7814\u7a76\u4e3a\u6587\u672c\u5230\u97f3\u4e50\u751f\u6210\u7cfb\u7edf\u7684\u5efa\u6a21\u8303\u5f0f\u9009\u62e9\u63d0\u4f9b\u4e86\u4f9d\u636e\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2506.08591", "pdf": "https://arxiv.org/pdf/2506.08591", "abs": "https://arxiv.org/abs/2506.08591", "authors": ["Chengchao Shen", "Hourun Zhu", "Gongfan Fang", "Jianxin Wang", "Xinchao Wang"], "title": "Diversity-Guided MLP Reduction for Efficient Large Vision Transformers", "categories": ["cs.CV", "cs.LG", "cs.MM"], "comment": null, "summary": "Transformer models achieve excellent scaling property, where the performance\nis improved with the increment of model capacity. However, large-scale model\nparameters lead to an unaffordable cost of computing and memory. We analyze\npopular transformer architectures and find that multilayer perceptron (MLP)\nmodules take up the majority of model parameters. To this end, we focus on the\nrecoverability of the compressed models and propose a Diversity-Guided MLP\nReduction (DGMR) method to significantly reduce the parameters of large vision\ntransformers with only negligible performance degradation. Specifically, we\nconduct a Gram-Schmidt weight pruning strategy to eliminate redundant neurons\nof MLP hidden layer, while preserving weight diversity for better performance\nrecover during distillation. Compared to the model trained from scratch, our\npruned model only requires 0.06\\% data of LAION-2B (for the training of large\nvision transformers) without labels (ImageNet-1K) to recover the original\nperformance. Experimental results on several state-of-the-art large vision\ntransformers demonstrate that our method achieves a more than 57.0\\% parameter\nand FLOPs reduction in a near lossless manner. Notably, for EVA-CLIP-E (4.4B),\nour method accomplishes a 71.5\\% parameter and FLOPs reduction without\nperformance degradation. The source code and trained weights are available at\nhttps://github.com/visresearch/DGMR.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6837\u6027\u5f15\u5bfc\u7684MLP\u538b\u7f29\u65b9\u6cd5\uff08DGMR\uff09\uff0c\u663e\u8457\u51cf\u5c11\u5927\u578b\u89c6\u89c9Transformer\u7684\u53c2\u6570\u548c\u8ba1\u7b97\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u6027\u80fd\u3002", "motivation": "\u5927\u578bTransformer\u6a21\u578b\u53c2\u6570\u8fc7\u591a\u5bfc\u81f4\u8ba1\u7b97\u548c\u5185\u5b58\u6210\u672c\u9ad8\u6602\uff0cMLP\u6a21\u5757\u5360\u7528\u4e86\u5927\u90e8\u5206\u53c2\u6570\u3002", "method": "\u91c7\u7528Gram-Schmidt\u6743\u91cd\u526a\u679d\u7b56\u7565\uff0c\u6d88\u9664MLP\u9690\u85cf\u5c42\u7684\u5197\u4f59\u795e\u7ecf\u5143\uff0c\u540c\u65f6\u4fdd\u7559\u6743\u91cd\u591a\u6837\u6027\u4ee5\u5728\u84b8\u998f\u8fc7\u7a0b\u4e2d\u6062\u590d\u6027\u80fd\u3002", "result": "\u5728\u591a\u4e2a\u5927\u578b\u89c6\u89c9Transformer\u4e0a\uff0cDGMR\u5b9e\u73b0\u4e8657%\u4ee5\u4e0a\u7684\u53c2\u6570\u548cFLOPs\u51cf\u5c11\uff0c\u6027\u80fd\u635f\u5931\u6781\u5c0f\uff1b\u5728EVA-CLIP-E\uff084.4B\uff09\u4e0a\uff0c\u53c2\u6570\u548cFLOPs\u51cf\u5c1171.5%\u4e14\u65e0\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "DGMR\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u6a21\u578b\u538b\u7f29\u65b9\u6cd5\uff0c\u663e\u8457\u964d\u4f4e\u8d44\u6e90\u9700\u6c42\uff0c\u540c\u65f6\u4fdd\u6301\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u89c6\u89c9Transformer\u3002"}}
{"id": "2506.08592", "pdf": "https://arxiv.org/pdf/2506.08592", "abs": "https://arxiv.org/abs/2506.08592", "authors": ["Liyan Xu", "Zhenlin Su", "Mo Yu", "Jiangnan Li", "Fandong Meng", "Jie Zhou"], "title": "Dense Retrievers Can Fail on Simple Queries: Revealing The Granularity Dilemma of Embeddings", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "This work focuses on an observed limitation of text encoders: embeddings may\nnot be able to recognize fine-grained entities or events within the semantics,\nresulting in failed dense retrieval on even simple cases. To examine such\nbehaviors, we first introduce a new evaluation dataset in Chinese, named\nCapRetrieval, whose passages are image captions, and queries are phrases\ninquiring entities or events in various forms. Zero-shot evaluation suggests\nthat encoders may fail on these fine-grained matching, regardless of training\nsources or model sizes. Aiming for enhancement, we proceed to finetune encoders\nwith our proposed data generation strategies, which obtains the best\nperformance on CapRetrieval. Within this process, we further identify an issue\nof granularity dilemma, a challenge for embeddings to express fine-grained\nsalience while aligning with overall semantics. Our dataset, code and models in\nthis work are publicly released at https://github.com/lxucs/CapRetrieval.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u6587\u672c\u7f16\u7801\u5668\u5728\u8bc6\u522b\u7ec6\u7c92\u5ea6\u5b9e\u4f53\u6216\u4e8b\u4ef6\u65f6\u7684\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u4e86\u4e2d\u6587\u8bc4\u4f30\u6570\u636e\u96c6CapRetrieval\uff0c\u5e76\u901a\u8fc7\u5fae\u8c03\u7f16\u7801\u5668\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6587\u672c\u7f16\u7801\u5668\u5728\u7ec6\u7c92\u5ea6\u8bed\u4e49\u5339\u914d\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u5bfc\u81f4\u5bc6\u96c6\u68c0\u7d22\u5931\u8d25\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u5f15\u5165CapRetrieval\u6570\u636e\u96c6\uff0c\u63d0\u51fa\u6570\u636e\u751f\u6210\u7b56\u7565\u5fae\u8c03\u7f16\u7801\u5668\u3002", "result": "\u5fae\u8c03\u540e\u7684\u7f16\u7801\u5668\u5728CapRetrieval\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u4f46\u53d1\u73b0\u7c92\u5ea6\u56f0\u5883\u95ee\u9898\u3002", "conclusion": "\u7ec6\u7c92\u5ea6\u8bed\u4e49\u5339\u914d\u4ecd\u9700\u6539\u8fdb\uff0c\u6570\u636e\u96c6\u548c\u6a21\u578b\u5df2\u5f00\u6e90\u3002"}}
{"id": "2506.08594", "pdf": "https://arxiv.org/pdf/2506.08594", "abs": "https://arxiv.org/abs/2506.08594", "authors": ["Yixuan Ma", "Chang Liu", "Weikang Li", "Shun-Yao Zhang", "L. -M. Duan", "Yukai Wu", "Dong-Ling Deng"], "title": "Solving excited states for long-range interacting trapped ions with neural networks", "categories": ["quant-ph", "cond-mat.dis-nn", "cs.AI", "cs.LG"], "comment": null, "summary": "The computation of excited states in strongly interacting quantum many-body\nsystems is of fundamental importance. Yet, it is notoriously challenging due to\nthe exponential scaling of the Hilbert space dimension with the system size.\nHere, we introduce a neural network-based algorithm that can simultaneously\noutput multiple low-lying excited states of a quantum many-body spin system in\nan accurate and efficient fashion. This algorithm, dubbed the neural quantum\nexcited-state (NQES) algorithm, requires no explicit orthogonalization of the\nstates and is generally applicable to higher dimensions. We demonstrate,\nthrough concrete examples including the Haldane-Shastry model with all-to-all\ninteractions, that the NQES algorithm is capable of efficiently computing\nmultiple excited states and their related observable expectations. In addition,\nwe apply the NQES algorithm to two classes of long-range interacting\ntrapped-ion systems in a two-dimensional Wigner crystal. For non-decaying\nall-to-all interactions with alternating signs, our computed low-lying excited\nstates bear spatial correlation patterns similar to those of the ground states,\nwhich closely match recent experimental observations that the\nquasi-adiabatically prepared state accurately reproduces analytical\nground-state correlations. For a system of up to 300 ions with power-law\ndecaying antiferromagnetic interactions, we successfully uncover its gap\nscaling and correlation features. Our results establish a scalable and\nefficient algorithm for computing excited states of interacting quantum\nmany-body systems, which holds potential applications ranging from benchmarking\nquantum devices to photoisomerization.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u7b97\u6cd5\uff08NQES\uff09\uff0c\u7528\u4e8e\u9ad8\u6548\u8ba1\u7b97\u91cf\u5b50\u591a\u4f53\u7cfb\u7edf\u7684\u4f4e\u6fc0\u53d1\u6001\uff0c\u65e0\u9700\u663e\u5f0f\u6b63\u4ea4\u5316\uff0c\u9002\u7528\u4e8e\u9ad8\u7ef4\u7cfb\u7edf\uff0c\u5e76\u5728\u591a\u79cd\u6a21\u578b\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5f3a\u76f8\u4e92\u4f5c\u7528\u91cf\u5b50\u591a\u4f53\u7cfb\u7edf\u7684\u6fc0\u53d1\u6001\u8ba1\u7b97\u5177\u6709\u57fa\u7840\u91cd\u8981\u6027\uff0c\u4f46\u7531\u4e8e\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u7ef4\u5ea6\u7684\u6307\u6570\u589e\u957f\uff0c\u4f20\u7edf\u65b9\u6cd5\u9762\u4e34\u5de8\u5927\u6311\u6218\u3002", "method": "\u5f00\u53d1\u4e86NQES\u7b97\u6cd5\uff0c\u5229\u7528\u795e\u7ecf\u7f51\u7edc\u540c\u65f6\u8f93\u51fa\u591a\u4e2a\u4f4e\u6fc0\u53d1\u6001\uff0c\u9002\u7528\u4e8e\u9ad8\u7ef4\u7cfb\u7edf\uff0c\u5e76\u5728Haldane-Shastry\u6a21\u578b\u548c\u957f\u7a0b\u76f8\u4e92\u4f5c\u7528\u79bb\u5b50\u7cfb\u7edf\u4e2d\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "result": "NQES\u7b97\u6cd5\u80fd\u591f\u9ad8\u6548\u8ba1\u7b97\u591a\u4e2a\u6fc0\u53d1\u6001\u53ca\u5176\u53ef\u89c2\u6d4b\u91cf\u671f\u671b\u503c\uff0c\u5728300\u79bb\u5b50\u7cfb\u7edf\u4e2d\u6210\u529f\u63ed\u793a\u4e86\u80fd\u9699\u6807\u5ea6\u548c\u5173\u8054\u7279\u5f81\u3002", "conclusion": "NQES\u7b97\u6cd5\u4e3a\u91cf\u5b50\u591a\u4f53\u7cfb\u7edf\u6fc0\u53d1\u6001\u8ba1\u7b97\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684\u65b9\u6cd5\uff0c\u5177\u6709\u4ece\u91cf\u5b50\u8bbe\u5907\u57fa\u51c6\u6d4b\u8bd5\u5230\u5149\u5f02\u6784\u5316\u7b49\u6f5c\u5728\u5e94\u7528\u3002"}}
{"id": "2506.08616", "pdf": "https://arxiv.org/pdf/2506.08616", "abs": "https://arxiv.org/abs/2506.08616", "authors": ["Julien Fageot", "Peva Blanchard", "Gilles Bareilles", "L\u00ea-Nguy\u00ean Hoang"], "title": "Generalizing while preserving monotonicity in comparison-based preference learning models", "categories": ["math.ST", "cs.LG", "stat.TH"], "comment": null, "summary": "If you tell a learning model that you prefer an alternative $a$ over another\nalternative $b$, then you probably expect the model to be monotone, that is,\nthe valuation of $a$ increases, and that of $b$ decreases. Yet, perhaps\nsurprisingly, many widely deployed comparison-based preference learning models,\nincluding large language models, fail to have this guarantee. Until now, the\nonly comparison-based preference learning algorithms that were proved to be\nmonotone are the Generalized Bradley-Terry models. Yet, these models are unable\nto generalize to uncompared data. In this paper, we advance the understanding\nof the set of models with generalization ability that are monotone. Namely, we\npropose a new class of Linear Generalized Bradley-Terry models with Diffusion\nPriors, and identify sufficient conditions on alternatives' embeddings that\nguarantee monotonicity. Our experiments show that this monotonicity is far from\nbeing a general guarantee, and that our new class of generalizing models\nimproves accuracy, especially when the dataset is limited.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7ebf\u6027\u5e7f\u4e49Bradley-Terry\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u504f\u597d\u5b66\u4e60\u6a21\u578b\u7f3a\u4e4f\u5355\u8c03\u6027\u4fdd\u8bc1\u7684\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6bd4\u8f83\u7684\u504f\u597d\u5b66\u4e60\u6a21\u578b\uff08\u5305\u62ec\u5927\u8bed\u8a00\u6a21\u578b\uff09\u7f3a\u4e4f\u5355\u8c03\u6027\u4fdd\u8bc1\uff0c\u4e14\u552f\u4e00\u88ab\u8bc1\u660e\u5355\u8c03\u7684\u5e7f\u4e49Bradley-Terry\u6a21\u578b\u65e0\u6cd5\u6cdb\u5316\u5230\u672a\u6bd4\u8f83\u6570\u636e\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7ebf\u6027\u5e7f\u4e49Bradley-Terry\u6a21\u578b\uff0c\u7ed3\u5408\u6269\u6563\u5148\u9a8c\uff0c\u5e76\u786e\u5b9a\u4e86\u4fdd\u8bc1\u5355\u8c03\u6027\u7684\u5d4c\u5165\u6761\u4ef6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u65b0\u6a21\u578b\u5728\u6709\u9650\u6570\u636e\u96c6\u4e0a\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\uff0c\u4e14\u5355\u8c03\u6027\u5e76\u975e\u666e\u904d\u4fdd\u8bc1\u3002", "conclusion": "\u65b0\u6a21\u578b\u5728\u4fdd\u8bc1\u5355\u8c03\u6027\u7684\u540c\u65f6\u5177\u6709\u6cdb\u5316\u80fd\u529b\uff0c\u5c24\u5176\u5728\u6570\u636e\u6709\u9650\u65f6\u8868\u73b0\u66f4\u4f18\u3002"}}
{"id": "2506.08646", "pdf": "https://arxiv.org/pdf/2506.08646", "abs": "https://arxiv.org/abs/2506.08646", "authors": ["Mingyu Zheng", "Zhifan Feng", "Jia Wang", "Lanrui Wang", "Zheng Lin", "Yang Hao", "Weiping Wang"], "title": "TableDreamer: Progressive and Weakness-guided Data Synthesis from Scratch for Table Instruction Tuning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "27 pages, 19 figures, Findings of ACL 2025", "summary": "Despite the commendable progress of recent LLM-based data synthesis methods,\nthey face two limitations in generating table instruction tuning data. First,\nthey can not thoroughly explore the vast input space of table understanding\ntasks, leading to limited data diversity. Second, they ignore the weaknesses in\ntable understanding ability of the target LLM and blindly pursue the increase\nof data quantity, resulting in suboptimal data efficiency. In this paper, we\nintroduce a progressive and weakness-guided data synthesis framework tailored\nfor table instruction tuning, named TableDreamer, to mitigate the above issues.\nSpecifically, we first synthesize diverse tables and related instructions as\nseed data, and then perform an iterative exploration of the input space under\nthe guidance of the newly identified weakness data, which eventually serve as\nthe final training data for fine-tuning the target LLM. Extensive experiments\non 10 tabular benchmarks demonstrate the effectiveness of the proposed\nframework, which boosts the average accuracy of Llama3.1-8B-instruct by 11.62%\n(49.07% to 60.69%) with 27K GPT-4o synthetic data and outperforms\nstate-of-the-art data synthesis baselines which use more training data. The\ncode and data is available at https://github.com/SpursGoZmy/TableDreamer", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTableDreamer\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6e10\u8fdb\u5f0f\u548c\u5f31\u70b9\u5f15\u5bfc\u7684\u6570\u636e\u5408\u6210\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709LLM\u5728\u8868\u6307\u4ee4\u8c03\u4f18\u6570\u636e\u751f\u6210\u4e2d\u7684\u591a\u6837\u6027\u548c\u6548\u7387\u95ee\u9898\u3002", "motivation": "\u73b0\u6709LLM\u5728\u8868\u6307\u4ee4\u8c03\u4f18\u6570\u636e\u751f\u6210\u4e2d\u5b58\u5728\u8f93\u5165\u7a7a\u95f4\u63a2\u7d22\u4e0d\u8db3\u548c\u6570\u636e\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\u3002", "method": "TableDreamer\u9996\u5148\u751f\u6210\u591a\u6837\u5316\u7684\u79cd\u5b50\u6570\u636e\uff0c\u7136\u540e\u57fa\u4e8e\u65b0\u53d1\u73b0\u7684\u5f31\u70b9\u6570\u636e\u8fed\u4ee3\u63a2\u7d22\u8f93\u5165\u7a7a\u95f4\uff0c\u6700\u7ec8\u751f\u6210\u7528\u4e8e\u5fae\u8c03\u76ee\u6807LLM\u7684\u8bad\u7ec3\u6570\u636e\u3002", "result": "\u572810\u4e2a\u8868\u683c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cTableDreamer\u663e\u8457\u63d0\u5347\u4e86\u76ee\u6807LLM\u7684\u6027\u80fd\uff08\u5e73\u5747\u51c6\u786e\u7387\u63d0\u534711.62%\uff09\uff0c\u4e14\u4f18\u4e8e\u4f7f\u7528\u66f4\u591a\u8bad\u7ec3\u6570\u636e\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "TableDreamer\u901a\u8fc7\u5f31\u70b9\u5f15\u5bfc\u7684\u6570\u636e\u5408\u6210\u65b9\u6cd5\uff0c\u6709\u6548\u63d0\u5347\u4e86\u8868\u6307\u4ee4\u8c03\u4f18\u6570\u636e\u7684\u591a\u6837\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2506.08654", "pdf": "https://arxiv.org/pdf/2506.08654", "abs": "https://arxiv.org/abs/2506.08654", "authors": ["Ciro Benito Raggio", "Paolo Zaffino", "Maria Francesca Spadea"], "title": "A Privacy-Preserving Federated Learning Framework for Generalizable CBCT to Synthetic CT Translation in Head and Neck", "categories": ["physics.med-ph", "cs.LG"], "comment": null, "summary": "Shortened Abstract\n  Cone-beam computed tomography (CBCT) has become a widely adopted modality for\nimage-guided radiotherapy (IGRT). However, CBCT suffers from increased noise,\nlimited soft-tissue contrast, and artifacts, resulting in unreliable Hounsfield\nunit values and hindering direct dose calculation. Synthetic CT (sCT)\ngeneration from CBCT addresses these issues, especially using deep learning\n(DL) methods. Existing approaches are limited by institutional heterogeneity,\nscanner-dependent variations, and data privacy regulations that prevent\nmulti-center data sharing.\n  To overcome these challenges, we propose a cross-silo horizontal federated\nlearning (FL) approach for CBCT-to-sCT synthesis in the head and neck region,\nextending our FedSynthCT framework. A conditional generative adversarial\nnetwork was collaboratively trained on data from three European medical centers\nin the public SynthRAD2025 challenge dataset.\n  The federated model demonstrated effective generalization across centers,\nwith mean absolute error (MAE) ranging from $64.38\\pm13.63$ to $85.90\\pm7.10$\nHU, structural similarity index (SSIM) from $0.882\\pm0.022$ to $0.922\\pm0.039$,\nand peak signal-to-noise ratio (PSNR) from $32.86\\pm0.94$ to $34.91\\pm1.04$ dB.\nNotably, on an external validation dataset of 60 patients, comparable\nperformance was achieved (MAE: $75.22\\pm11.81$ HU, SSIM: $0.904\\pm0.034$, PSNR:\n$33.52\\pm2.06$ dB) without additional training, confirming robust\ngeneralization despite protocol, scanner differences and registration errors.\n  These findings demonstrate the technical feasibility of FL for CBCT-to-sCT\nsynthesis while preserving data privacy and offer a collaborative solution for\ndeveloping generalizable models across institutions without centralized data\nsharing or site-specific fine-tuning.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8054\u90a6\u5b66\u4e60\u7684CBCT\u5230sCT\u5408\u6210\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u591a\u4e2d\u5fc3\u6570\u636e\u5171\u4eab\u7684\u9690\u79c1\u95ee\u9898\uff0c\u5e76\u5728\u5934\u9888\u90e8\u533a\u57df\u9a8c\u8bc1\u4e86\u5176\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "CBCT\u5728\u56fe\u50cf\u5f15\u5bfc\u653e\u7597\u4e2d\u5b58\u5728\u566a\u58f0\u3001\u8f6f\u7ec4\u7ec7\u5bf9\u6bd4\u5ea6\u4f4e\u548c\u4f2a\u5f71\u7b49\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u53d7\u9650\u4e8e\u673a\u6784\u5f02\u8d28\u6027\u548c\u6570\u636e\u9690\u79c1\u6cd5\u89c4\u3002", "method": "\u91c7\u7528\u8de8\u673a\u6784\u6c34\u5e73\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff08FedSynthCT\uff09\uff0c\u57fa\u4e8e\u6761\u4ef6\u751f\u6210\u5bf9\u6297\u7f51\u7edc\u5728\u591a\u4e2d\u5fc3\u6570\u636e\u4e0a\u534f\u540c\u8bad\u7ec3\u3002", "result": "\u8054\u90a6\u6a21\u578b\u5728\u591a\u4e2a\u4e2d\u5fc3\u8868\u73b0\u51fa\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff0cMAE\u3001SSIM\u548cPSNR\u6307\u6807\u5747\u8fbe\u5230\u8f83\u9ad8\u6c34\u5e73\uff0c\u4e14\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u5373\u53ef\u9002\u5e94\u5916\u90e8\u6570\u636e\u96c6\u3002", "conclusion": "\u8054\u90a6\u5b66\u4e60\u4e3aCBCT\u5230sCT\u5408\u6210\u63d0\u4f9b\u4e86\u9690\u79c1\u4fdd\u62a4\u7684\u534f\u4f5c\u89e3\u51b3\u65b9\u6848\uff0c\u65e0\u9700\u96c6\u4e2d\u6570\u636e\u5171\u4eab\u6216\u7ad9\u70b9\u7279\u5b9a\u5fae\u8c03\u3002"}}
{"id": "2506.08670", "pdf": "https://arxiv.org/pdf/2506.08670", "abs": "https://arxiv.org/abs/2506.08670", "authors": ["Renjie Xu", "Chong Wu", "Maolin Che", "Zhuoheng Ran", "Yimin Wei", "Hong Yan"], "title": "sparseGeoHOPCA: A Geometric Solution to Sparse Higher-Order PCA Without Covariance Estimation", "categories": ["math.NA", "cs.LG", "cs.NA", "math.OC"], "comment": null, "summary": "We propose sparseGeoHOPCA, a novel framework for sparse higher-order\nprincipal component analysis (SHOPCA) that introduces a geometric perspective\nto high-dimensional tensor decomposition. By unfolding the input tensor along\neach mode and reformulating the resulting subproblems as structured binary\nlinear optimization problems, our method transforms the original nonconvex\nsparse objective into a tractable geometric form. This eliminates the need for\nexplicit covariance estimation and iterative deflation, enabling significant\ngains in both computational efficiency and interpretability, particularly in\nhigh-dimensional and unbalanced data scenarios. We theoretically establish the\nequivalence between the geometric subproblems and the original SHOPCA\nformulation, and derive worst-case approximation error bounds based on\nclassical PCA residuals, providing data-dependent performance guarantees. The\nproposed algorithm achieves a total computational complexity of\n$O\\left(\\sum_{n=1}^{N} (k_n^3 + J_n k_n^2)\\right)$, which scales linearly with\ntensor size. Extensive experiments demonstrate that sparseGeoHOPCA accurately\nrecovers sparse supports in synthetic settings, preserves classification\nperformance under 10$\\times$ compression, and achieves high-quality image\nreconstruction on ImageNet, highlighting its robustness and versatility.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3asparseGeoHOPCA\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u51e0\u4f55\u89c6\u89d2\u89e3\u51b3\u9ad8\u7ef4\u5f20\u91cf\u5206\u89e3\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u89e3\u51b3\u9ad8\u7ef4\u5f20\u91cf\u5206\u89e3\u4e2d\u7684\u975e\u51f8\u7a00\u758f\u76ee\u6807\u95ee\u9898\uff0c\u907f\u514d\u663e\u5f0f\u534f\u65b9\u5dee\u4f30\u8ba1\u548c\u8fed\u4ee3\u653e\u6c14\uff0c\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u901a\u8fc7\u6cbf\u6bcf\u4e2a\u6a21\u5f0f\u5c55\u5f00\u8f93\u5165\u5f20\u91cf\uff0c\u5c06\u5b50\u95ee\u9898\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u4e8c\u5143\u7ebf\u6027\u4f18\u5316\u95ee\u9898\uff0c\u5c06\u539f\u59cb\u975e\u51f8\u7a00\u758f\u76ee\u6807\u8f6c\u5316\u4e3a\u53ef\u5904\u7406\u7684\u51e0\u4f55\u5f62\u5f0f\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u4e86\u51e0\u4f55\u5b50\u95ee\u9898\u4e0e\u539f\u59cbSHOPCA\u516c\u5f0f\u7684\u7b49\u4ef7\u6027\uff0c\u5e76\u57fa\u4e8e\u7ecf\u5178PCA\u6b8b\u5dee\u63a8\u5bfc\u4e86\u6700\u574f\u60c5\u51b5\u8fd1\u4f3c\u8bef\u5dee\u754c\u9650\u3002\u5b9e\u9a8c\u663e\u793a\u5728\u5408\u6210\u8bbe\u7f6e\u4e2d\u51c6\u786e\u6062\u590d\u7a00\u758f\u652f\u6301\uff0c\u5e76\u5728\u538b\u7f29\u548c\u56fe\u50cf\u91cd\u5efa\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "sparseGeoHOPCA\u5728\u8ba1\u7b97\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u9002\u7528\u4e8e\u9ad8\u7ef4\u548c\u4e0d\u5e73\u8861\u6570\u636e\u573a\u666f\u3002"}}
{"id": "2506.08712", "pdf": "https://arxiv.org/pdf/2506.08712", "abs": "https://arxiv.org/abs/2506.08712", "authors": ["Hee Suk Yoon", "Eunseop Yoon", "Mark A. Hasegawa-Johnson", "Sungwoong Kim", "Chang D. Yoo"], "title": "ConfPO: Exploiting Policy Model Confidence for Critical Token Selection in Large Language Model Preference Optimization", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "ICML 2025", "summary": "We introduce ConfPO, a method for preference learning in Large Language\nModels (LLMs) that identifies and optimizes preference-critical tokens based\nsolely on the training policy's confidence, without requiring any auxiliary\nmodels or compute. Unlike prior Direct Alignment Algorithms (DAAs) such as\nDirect Preference Optimization (DPO), which uniformly adjust all token\nprobabilities regardless of their relevance to preference, ConfPO focuses\noptimization on the most impactful tokens. This targeted approach improves\nalignment quality while mitigating overoptimization (i.e., reward hacking) by\nusing the KL divergence budget more efficiently. In contrast to recent\ntoken-level methods that rely on credit-assignment models or AI annotators,\nraising concerns about scalability and reliability, ConfPO is simple,\nlightweight, and model-free. Experimental results on challenging alignment\nbenchmarks, including AlpacaEval 2 and Arena-Hard, demonstrate that ConfPO\nconsistently outperforms uniform DAAs across various LLMs, delivering better\nalignment with zero additional computational overhead.", "AI": {"tldr": "ConfPO\u662f\u4e00\u79cd\u7528\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u504f\u597d\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ec5\u57fa\u4e8e\u8bad\u7ec3\u7b56\u7565\u7684\u7f6e\u4fe1\u5ea6\u8bc6\u522b\u548c\u4f18\u5316\u504f\u597d\u5173\u952e\u4ee4\u724c\uff0c\u65e0\u9700\u8f85\u52a9\u6a21\u578b\u6216\u989d\u5916\u8ba1\u7b97\u3002", "motivation": "\u73b0\u6709\u76f4\u63a5\u5bf9\u9f50\u7b97\u6cd5\uff08\u5982DPO\uff09\u5bf9\u6240\u6709\u4ee4\u724c\u8fdb\u884c\u7edf\u4e00\u8c03\u6574\uff0c\u800cConfPO\u4e13\u6ce8\u4e8e\u5bf9\u504f\u597d\u5f71\u54cd\u6700\u5927\u7684\u4ee4\u724c\u8fdb\u884c\u4f18\u5316\uff0c\u4ee5\u63d0\u9ad8\u5bf9\u9f50\u8d28\u91cf\u5e76\u907f\u514d\u8fc7\u4f18\u5316\u3002", "method": "ConfPO\u901a\u8fc7KL\u6563\u5ea6\u9884\u7b97\u66f4\u9ad8\u6548\u5730\u4f18\u5316\u5173\u952e\u4ee4\u724c\uff0c\u65e0\u9700\u4f9d\u8d56\u4fe1\u7528\u5206\u914d\u6a21\u578b\u6216\u4eba\u5de5\u6807\u6ce8\uff0c\u65b9\u6cd5\u7b80\u5355\u8f7b\u91cf\u4e14\u65e0\u9700\u989d\u5916\u6a21\u578b\u3002", "result": "\u5728AlpacaEval 2\u548cArena-Hard\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cConfPO\u8868\u73b0\u4f18\u4e8e\u7edf\u4e00\u8c03\u6574\u7684DAA\u65b9\u6cd5\uff0c\u5bf9\u9f50\u6548\u679c\u66f4\u597d\u4e14\u65e0\u989d\u5916\u8ba1\u7b97\u5f00\u9500\u3002", "conclusion": "ConfPO\u901a\u8fc7\u805a\u7126\u5173\u952e\u4ee4\u724c\u4f18\u5316\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u8f7b\u91cf\u7684\u504f\u597d\u5b66\u4e60\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u7684\u5bf9\u9f50\u6548\u679c\u3002"}}
{"id": "2506.08725", "pdf": "https://arxiv.org/pdf/2506.08725", "abs": "https://arxiv.org/abs/2506.08725", "authors": ["Hyeon Jeon", "Jeongin Park", "Sungbok Shin", "Jinwook Seo"], "title": "Stop Misusing t-SNE and UMAP for Visual Analytics", "categories": ["cs.HC", "cs.LG"], "comment": "9 pages", "summary": "Misuses of t-SNE and UMAP in visual analytics have become increasingly\ncommon. For example, although t-SNE and UMAP projections often do not\nfaithfully reflect true distances between clusters, practitioners frequently\nuse them to investigate inter-cluster relationships. In this paper, we bring\nthis issue to the surface and comprehensively investigate why such misuse\noccurs and how to prevent it. We conduct a literature review of 114 papers to\nverify the prevalence of the misuse and analyze the reasonings behind it. We\nthen execute an interview study to uncover practitioners' implicit motivations\nfor using these techniques -- rationales often undisclosed in the literature.\nOur findings indicate that misuse of t-SNE and UMAP primarily stems from\nlimited discourse on their appropriate use in visual analytics. We conclude by\nproposing future directions and concrete action items to promote more\nreasonable use of DR.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fat-SNE\u548cUMAP\u5728\u53ef\u89c6\u5316\u5206\u6790\u4e2d\u7684\u8bef\u7528\u73b0\u8c61\u666e\u904d\uff0c\u63a2\u8ba8\u4e86\u539f\u56e0\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u5efa\u8bae\u3002", "motivation": "\u63ed\u793at-SNE\u548cUMAP\u8bef\u7528\u7684\u666e\u904d\u6027\u53ca\u5176\u80cc\u540e\u7684\u539f\u56e0\uff0c\u4ee5\u4fc3\u8fdb\u66f4\u5408\u7406\u7684\u4f7f\u7528\u3002", "method": "\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\uff08114\u7bc7\u8bba\u6587\uff09\u548c\u8bbf\u8c08\u7814\u7a76\uff0c\u5206\u6790\u8bef\u7528\u73b0\u8c61\u53ca\u539f\u56e0\u3002", "result": "\u8bef\u7528\u4e3b\u8981\u6e90\u4e8e\u5bf9\u6280\u672f\u9002\u7528\u6027\u7684\u8ba8\u8bba\u4e0d\u8db3\uff0c\u63d0\u51fa\u4e86\u6539\u8fdb\u65b9\u5411\u3002", "conclusion": "\u5efa\u8bae\u52a0\u5f3a\u6280\u672f\u9002\u7528\u6027\u8ba8\u8bba\uff0c\u63a8\u52a8\u66f4\u5408\u7406\u7684\u964d\u7ef4\u6280\u672f\u4f7f\u7528\u3002"}}
{"id": "2506.08734", "pdf": "https://arxiv.org/pdf/2506.08734", "abs": "https://arxiv.org/abs/2506.08734", "authors": ["Nelvin Tan", "Yu-Ching Shih", "Dong Yang", "Amol Salunkhe"], "title": "Flexible and Efficient Drift Detection without Labels", "categories": ["stat.ML", "cs.LG", "stat.AP"], "comment": "9 pages, 4 figures", "summary": "Machine learning models are being increasingly used to automate decisions in\nalmost every domain, and ensuring the performance of these models is crucial\nfor ensuring high quality machine learning enabled services. Ensuring concept\ndrift is detected early is thus of the highest importance. A lot of research on\nconcept drift has focused on the supervised case that assumes the true labels\nof supervised tasks are available immediately after making predictions.\nControlling for false positives while monitoring the performance of predictive\nmodels used to make inference from extremely large datasets periodically, where\nthe true labels are not instantly available, becomes extremely challenging. We\npropose a flexible and efficient concept drift detection algorithm that uses\nclassical statistical process control in a label-less setting to accurately\ndetect concept drifts. We shown empirically that under computational\nconstraints, our approach has better statistical power than previous known\nmethods. Furthermore, we introduce a new drift detection framework to model the\nscenario of detecting drift (without labels) given prior detections, and show\nour how our drift detection algorithm can be incorporated effectively into this\nframework. We demonstrate promising performance via numerical simulations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u6807\u7b7e\u73af\u5883\u4e0b\u7684\u7075\u6d3b\u9ad8\u6548\u7684\u6982\u5ff5\u6f02\u79fb\u68c0\u6d4b\u7b97\u6cd5\uff0c\u57fa\u4e8e\u7ecf\u5178\u7edf\u8ba1\u8fc7\u7a0b\u63a7\u5236\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5e7f\u6cdb\u7528\u4e8e\u81ea\u52a8\u5316\u51b3\u7b56\uff0c\u6982\u5ff5\u6f02\u79fb\u7684\u65e9\u671f\u68c0\u6d4b\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u591a\u57fa\u4e8e\u76d1\u7763\u4efb\u52a1\uff0c\u6807\u7b7e\u5ef6\u8fdf\u65f6\u68c0\u6d4b\u56f0\u96be\u3002", "method": "\u4f7f\u7528\u7ecf\u5178\u7edf\u8ba1\u8fc7\u7a0b\u63a7\u5236\uff0c\u8bbe\u8ba1\u65e0\u6807\u7b7e\u73af\u5883\u4e0b\u7684\u6982\u5ff5\u6f02\u79fb\u68c0\u6d4b\u7b97\u6cd5\uff0c\u5e76\u5f15\u5165\u65b0\u6846\u67b6\u7ed3\u5408\u5148\u9a8c\u68c0\u6d4b\u7ed3\u679c\u3002", "result": "\u5728\u8ba1\u7b97\u9650\u5236\u4e0b\uff0c\u7b97\u6cd5\u7edf\u8ba1\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u6570\u503c\u6a21\u62df\u663e\u793a\u826f\u597d\u6548\u679c\u3002", "conclusion": "\u65b0\u7b97\u6cd5\u5728\u65e0\u6807\u7b7e\u73af\u5883\u4e0b\u9ad8\u6548\u68c0\u6d4b\u6982\u5ff5\u6f02\u79fb\uff0c\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u6570\u636e\u96c6\u3002"}}
{"id": "2506.08743", "pdf": "https://arxiv.org/pdf/2506.08743", "abs": "https://arxiv.org/abs/2506.08743", "authors": ["Michael F\u00e4rber", "David Lamprecht", "Yuni Susanti"], "title": "Bridging RDF Knowledge Graphs with Graph Neural Networks for Semantically-Rich Recommender Systems", "categories": ["cs.IR", "cs.AI", "cs.DB", "cs.LG"], "comment": "Accepted at DASFAA 2025", "summary": "Graph Neural Networks (GNNs) have substantially advanced the field of\nrecommender systems. However, despite the creation of more than a thousand\nknowledge graphs (KGs) under the W3C standard RDF, their rich semantic\ninformation has not yet been fully leveraged in GNN-based recommender systems.\nTo address this gap, we propose a comprehensive integration of RDF KGs with\nGNNs that utilizes both the topological information from RDF object properties\nand the content information from RDF datatype properties. Our main focus is an\nin-depth evaluation of various GNNs, analyzing how different semantic feature\ninitializations and types of graph structure heterogeneity influence their\nperformance in recommendation tasks. Through experiments across multiple\nrecommendation scenarios involving multi-million-node RDF graphs, we\ndemonstrate that harnessing the semantic richness of RDF KGs significantly\nimproves recommender systems and lays the groundwork for GNN-based recommender\nsystems for the Linked Open Data cloud. The code and data are available on our\nGitHub repository: https://github.com/davidlamprecht/rdf-gnn-recommendation", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06RDF\u77e5\u8bc6\u56fe\u8c31\u4e0eGNN\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u5145\u5206\u5229\u7528\u5176\u8bed\u4e49\u4fe1\u606f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u5df2\u6709\u5927\u91cfRDF\u77e5\u8bc6\u56fe\u8c31\uff0c\u4f46\u5176\u4e30\u5bcc\u7684\u8bed\u4e49\u4fe1\u606f\u5728\u57fa\u4e8eGNN\u7684\u63a8\u8350\u7cfb\u7edf\u4e2d\u5c1a\u672a\u88ab\u5145\u5206\u5229\u7528\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7efc\u5408\u96c6\u6210\u65b9\u6cd5\uff0c\u5229\u7528RDF\u5bf9\u8c61\u5c5e\u6027\u7684\u62d3\u6251\u4fe1\u606f\u548c\u6570\u636e\u7c7b\u578b\u5c5e\u6027\u7684\u5185\u5bb9\u4fe1\u606f\uff0c\u5e76\u8bc4\u4f30\u4e0d\u540cGNN\u7684\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5229\u7528RDF\u77e5\u8bc6\u56fe\u8c31\u7684\u8bed\u4e49\u4e30\u5bcc\u6027\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u7cfb\u7edf\u7684\u6548\u679c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u57fa\u4e8eGNN\u7684\u63a8\u8350\u7cfb\u7edf\u5728Linked Open Data\u4e91\u4e2d\u7684\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.08746", "pdf": "https://arxiv.org/pdf/2506.08746", "abs": "https://arxiv.org/abs/2506.08746", "authors": ["Muhammad Anwar", "Mishca de Costa", "Issam Hammad", "Daniel Lau"], "title": "Towards Secure and Private Language Models for Nuclear Power Plants", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "This paper introduces a domain-specific Large Language Model for nuclear\napplications, built from the publicly accessible Essential CANDU textbook.\nDrawing on a compact Transformer-based architecture, the model is trained on a\nsingle GPU to protect the sensitive data inherent in nuclear operations.\nDespite relying on a relatively small dataset, it shows encouraging signs of\ncapturing specialized nuclear vocabulary, though the generated text sometimes\nlacks syntactic coherence. By focusing exclusively on nuclear content, this\napproach demonstrates the feasibility of in-house LLM solutions that align with\nrigorous cybersecurity and data confidentiality standards. Early successes in\ntext generation underscore the model's utility for specialized tasks, while\nalso revealing the need for richer corpora, more sophisticated preprocessing,\nand instruction fine-tuning to enhance domain accuracy. Future directions\ninclude extending the dataset to cover diverse nuclear subtopics, refining\ntokenization to reduce noise, and systematically evaluating the model's\nreadiness for real-world applications in nuclear domain.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u9488\u5bf9\u6838\u5e94\u7528\u9886\u57df\u7684\u7279\u5b9a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u57fa\u4e8e\u516c\u5f00\u7684Essential CANDU\u6559\u6750\u6784\u5efa\uff0c\u91c7\u7528\u7d27\u51d1\u7684Transformer\u67b6\u6784\uff0c\u5728\u5355GPU\u4e0a\u8bad\u7ec3\u4ee5\u4fdd\u62a4\u6838\u64cd\u4f5c\u4e2d\u7684\u654f\u611f\u6570\u636e\u3002\u6a21\u578b\u5728\u6355\u83b7\u4e13\u4e1a\u6838\u8bcd\u6c47\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u751f\u6210\u6587\u672c\u6709\u65f6\u7f3a\u4e4f\u53e5\u6cd5\u8fde\u8d2f\u6027\u3002", "motivation": "\u5f00\u53d1\u4e00\u79cd\u7b26\u5408\u4e25\u683c\u7f51\u7edc\u5b89\u5168\u548c\u6570\u636e\u4fdd\u5bc6\u6807\u51c6\u7684\u5185\u90e8LLM\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u6ee1\u8db3\u6838\u5e94\u7528\u9886\u57df\u7684\u7279\u5b9a\u9700\u6c42\u3002", "method": "\u57fa\u4e8eTransformer\u67b6\u6784\uff0c\u4f7f\u7528\u516c\u5f00\u7684Essential CANDU\u6559\u6750\u4f5c\u4e3a\u8bad\u7ec3\u6570\u636e\uff0c\u5728\u5355GPU\u4e0a\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u6a21\u578b\u80fd\u591f\u6355\u83b7\u4e13\u4e1a\u6838\u8bcd\u6c47\uff0c\u4f46\u751f\u6210\u6587\u672c\u7684\u53e5\u6cd5\u8fde\u8d2f\u6027\u6709\u5f85\u63d0\u9ad8\u3002\u521d\u6b65\u5c55\u793a\u4e86\u5728\u4e13\u4e1a\u4efb\u52a1\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "\u672a\u6765\u9700\u6269\u5c55\u6570\u636e\u96c6\u8986\u76d6\u66f4\u591a\u6838\u5b50\u9886\u57df\uff0c\u4f18\u5316\u9884\u5904\u7406\u548c\u6307\u4ee4\u5fae\u8c03\u4ee5\u63d0\u5347\u51c6\u786e\u6027\uff0c\u5e76\u8bc4\u4f30\u6a21\u578b\u5728\u6838\u9886\u57df\u7684\u5b9e\u9645\u5e94\u7528\u51c6\u5907\u5ea6\u3002"}}
{"id": "2506.08749", "pdf": "https://arxiv.org/pdf/2506.08749", "abs": "https://arxiv.org/abs/2506.08749", "authors": ["Viktoria Patapovich", "Mo Kordzanganeh", "Alexey Melnikov"], "title": "Superposed Parameterised Quantum Circuits", "categories": ["quant-ph", "cs.ET", "cs.LG", "cs.NE"], "comment": "20 pages, 6 figures, 3 tables", "summary": "Quantum machine learning has shown promise for high-dimensional data\nanalysis, yet many existing approaches rely on linear unitary operations and\nshared trainable parameters across outputs. These constraints limit\nexpressivity and scalability relative to the multi-layered, non-linear\narchitectures of classical deep networks. We introduce superposed parameterised\nquantum circuits to overcome these limitations. By combining flip-flop quantum\nrandom-access memory with repeat-until-success protocols, a superposed\nparameterised quantum circuit embeds an exponential number of parameterised\nsub-models in a single circuit and induces polynomial activation functions\nthrough amplitude transformations and post-selection. We provide an analytic\ndescription of the architecture, showing how multiple parameter sets are\ntrained in parallel while non-linear amplitude transformations broaden\nrepresentational power beyond conventional quantum kernels. Numerical\nexperiments underscore these advantages: on a 1D step-function regression a\ntwo-qubit superposed parameterised quantum circuit cuts the mean-squared error\nby three orders of magnitude versus a parameter-matched variational baseline;\non a 2D star-shaped two-dimensional classification task, introducing a\nquadratic activation lifts accuracy to 81.4% and reduces run-to-run variance\nthree-fold. These results position superposed parameterised quantum circuits as\na hardware-efficient route toward deeper, more versatile parameterised quantum\ncircuits capable of learning complex decision boundaries.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53e0\u52a0\u53c2\u6570\u5316\u91cf\u5b50\u7535\u8def\uff08superposed parameterised quantum circuits\uff09\uff0c\u901a\u8fc7\u7ed3\u5408\u7ffb\u8f6c\u91cf\u5b50\u968f\u673a\u5b58\u53d6\u5b58\u50a8\u5668\u548c\u91cd\u590d\u76f4\u5230\u6210\u529f\u534f\u8bae\uff0c\u63d0\u9ad8\u4e86\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u7684\u8868\u8fbe\u80fd\u529b\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u73b0\u6709\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u53d7\u9650\u4e8e\u7ebf\u6027\u9149\u64cd\u4f5c\u548c\u5171\u4eab\u53ef\u8bad\u7ec3\u53c2\u6570\uff0c\u9650\u5236\u4e86\u5176\u8868\u8fbe\u80fd\u529b\u548c\u53ef\u6269\u5c55\u6027\uff0c\u65e0\u6cd5\u4e0e\u7ecf\u5178\u6df1\u5ea6\u7f51\u7edc\u7684\u591a\u5c42\u975e\u7ebf\u6027\u67b6\u6784\u76f8\u6bd4\u3002", "method": "\u91c7\u7528\u53e0\u52a0\u53c2\u6570\u5316\u91cf\u5b50\u7535\u8def\uff0c\u7ed3\u5408\u7ffb\u8f6c\u91cf\u5b50\u968f\u673a\u5b58\u53d6\u5b58\u50a8\u5668\u548c\u91cd\u590d\u76f4\u5230\u6210\u529f\u534f\u8bae\uff0c\u5d4c\u5165\u6307\u6570\u7ea7\u6570\u91cf\u7684\u53c2\u6570\u5316\u5b50\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u632f\u5e45\u53d8\u6362\u548c\u540e\u9009\u62e9\u5b9e\u73b0\u591a\u9879\u5f0f\u6fc0\u6d3b\u51fd\u6570\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u57281D\u9636\u8dc3\u51fd\u6570\u56de\u5f52\u4e2d\u6bd4\u57fa\u7ebf\u6a21\u578b\u964d\u4f4e\u4e86\u4e09\u4e2a\u6570\u91cf\u7ea7\u7684\u5747\u65b9\u8bef\u5dee\uff1b\u57282D\u661f\u5f62\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u5f15\u5165\u4e8c\u6b21\u6fc0\u6d3b\u51fd\u6570\u5c06\u51c6\u786e\u7387\u63d0\u5347\u81f381.4%\uff0c\u5e76\u51cf\u5c11\u4e86\u8fd0\u884c\u65b9\u5dee\u3002", "conclusion": "\u53e0\u52a0\u53c2\u6570\u5316\u91cf\u5b50\u7535\u8def\u4e3a\u6784\u5efa\u66f4\u6df1\u3001\u66f4\u901a\u7528\u7684\u53c2\u6570\u5316\u91cf\u5b50\u7535\u8def\u63d0\u4f9b\u4e86\u4e00\u79cd\u786c\u4ef6\u9ad8\u6548\u7684\u9014\u5f84\uff0c\u80fd\u591f\u5b66\u4e60\u590d\u6742\u51b3\u7b56\u8fb9\u754c\u3002"}}
{"id": "2506.08757", "pdf": "https://arxiv.org/pdf/2506.08757", "abs": "https://arxiv.org/abs/2506.08757", "authors": ["Mishca de Costa", "Muhammad Anwar", "Dave Mercier", "Mark Randall", "Issam Hammad"], "title": "Enhancing Accuracy and Maintainability in Nuclear Plant Data Retrieval: A Function-Calling LLM Approach Over NL-to-SQL", "categories": ["cs.CL", "cs.LG"], "comment": "44th Annual CNS Conference and the 49th Annual CNS/CNA Student\n  Conference, Westin Harbour Castle Hotel, Toronto, ON, Canada, June 8-11, 2025", "summary": "Retrieving operational data from nuclear power plants requires exceptional\naccuracy and transparency due to the criticality of the decisions it supports.\nTraditionally, natural language to SQL (NL-to-SQL) approaches have been\nexplored for querying such data. While NL-to-SQL promises ease of use, it poses\nsignificant risks: end-users cannot easily validate generated SQL queries, and\nlegacy nuclear plant databases -- often complex and poorly structured --\ncomplicate query generation due to decades of incremental modifications. These\nchallenges increase the likelihood of inaccuracies and reduce trust in the\napproach. In this work, we propose an alternative paradigm: leveraging\nfunction-calling large language models (LLMs) to address these challenges.\nInstead of directly generating SQL queries, we define a set of pre-approved,\npurpose-specific functions representing common use cases. Queries are processed\nby invoking these functions, which encapsulate validated SQL logic. This hybrid\napproach mitigates the risks associated with direct NL-to-SQL translations by\nensuring that SQL queries are reviewed and optimized by experts before\ndeployment. While this strategy introduces the upfront cost of developing and\nmaintaining the function library, we demonstrate how NL-to-SQL tools can assist\nin the initial generation of function code, allowing experts to focus on\nvalidation rather than creation. Our study includes a performance comparison\nbetween direct NL-to-SQL generation and the proposed function-based approach,\nhighlighting improvements in accuracy and maintainability. This work\nunderscores the importance of balancing user accessibility with operational\nsafety and provides a novel, actionable framework for robust data retrieval in\ncritical systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u51fd\u6570\u8c03\u7528\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4ee5\u89e3\u51b3\u4f20\u7edf\u81ea\u7136\u8bed\u8a00\u8f6cSQL\uff08NL-to-SQL\uff09\u5728\u6838\u7535\u7ad9\u6570\u636e\u67e5\u8be2\u4e2d\u7684\u98ce\u9669\u3002", "motivation": "\u6838\u7535\u7ad9\u64cd\u4f5c\u6570\u636e\u7684\u67e5\u8be2\u9700\u8981\u6781\u9ad8\u7684\u51c6\u786e\u6027\u548c\u900f\u660e\u5ea6\uff0c\u4f20\u7edfNL-to-SQL\u65b9\u6cd5\u5b58\u5728\u9a8c\u8bc1\u56f0\u96be\u548c\u590d\u6742\u6570\u636e\u5e93\u7ed3\u6784\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u4e0d\u51c6\u786e\u548c\u4fe1\u4efb\u7f3a\u5931\u3002", "method": "\u901a\u8fc7\u9884\u5b9a\u4e49\u4e00\u7ec4\u7ecf\u8fc7\u6279\u51c6\u7684\u3001\u7279\u5b9a\u7528\u9014\u7684\u51fd\u6570\u6765\u5c01\u88c5\u5df2\u9a8c\u8bc1\u7684SQL\u903b\u8f91\uff0c\u907f\u514d\u76f4\u63a5\u751f\u6210SQL\u67e5\u8be2\uff0c\u4ece\u800c\u964d\u4f4e\u98ce\u9669\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u57fa\u4e8e\u51fd\u6570\u7684\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u53ef\u7ef4\u62a4\u6027\u4e0a\u4f18\u4e8e\u76f4\u63a5NL-to-SQL\u751f\u6210\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5e73\u8861\u4e86\u7528\u6237\u6613\u7528\u6027\u4e0e\u64cd\u4f5c\u5b89\u5168\u6027\uff0c\u4e3a\u5173\u952e\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7a33\u5065\u7684\u6570\u636e\u68c0\u7d22\u6846\u67b6\u3002"}}
{"id": "2506.08762", "pdf": "https://arxiv.org/pdf/2506.08762", "abs": "https://arxiv.org/abs/2506.08762", "authors": ["Issa Sugiura", "Takashi Ishida", "Taro Makino", "Chieko Tazuke", "Takanori Nakagawa", "Kosuke Nakago", "David Ha"], "title": "EDINET-Bench: Evaluating LLMs on Complex Financial Tasks using Japanese Financial Statements", "categories": ["q-fin.ST", "cs.CE", "cs.CL", "cs.LG"], "comment": null, "summary": "Financial analysis presents complex challenges that could leverage large\nlanguage model (LLM) capabilities. However, the scarcity of challenging\nfinancial datasets, particularly for Japanese financial data, impedes academic\ninnovation in financial analytics. As LLMs advance, this lack of accessible\nresearch resources increasingly hinders their development and evaluation in\nthis specialized domain. To address this gap, we introduce EDINET-Bench, an\nopen-source Japanese financial benchmark designed to evaluate the performance\nof LLMs on challenging financial tasks including accounting fraud detection,\nearnings forecasting, and industry prediction. EDINET-Bench is constructed by\ndownloading annual reports from the past 10 years from Japan's Electronic\nDisclosure for Investors' NETwork (EDINET) and automatically assigning labels\ncorresponding to each evaluation task. Our experiments reveal that even\nstate-of-the-art LLMs struggle, performing only slightly better than logistic\nregression in binary classification for fraud detection and earnings\nforecasting. These results highlight significant challenges in applying LLMs to\nreal-world financial applications and underscore the need for domain-specific\nadaptation. Our dataset, benchmark construction code, and evaluation code is\npublicly available to facilitate future research in finance with LLMs.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86EDINET-Bench\uff0c\u4e00\u4e2a\u5f00\u6e90\u65e5\u672c\u91d1\u878d\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u91d1\u878d\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u6570\u636e\u7a00\u7f3a\u7684\u7a7a\u767d\u3002", "motivation": "\u65e5\u672c\u91d1\u878d\u6570\u636e\u7684\u7a00\u7f3a\u6027\u963b\u788d\u4e86\u91d1\u878d\u5206\u6790\u9886\u57df\u7684\u5b66\u672f\u521b\u65b0\uff0c\u5c24\u5176\u662fLLM\u5728\u8be5\u9886\u57df\u7684\u5e94\u7528\u548c\u53d1\u5c55\u3002", "method": "\u901a\u8fc7\u4ece\u65e5\u672cEDINET\u7cfb\u7edf\u4e0b\u8f7d\u8fc7\u53bb10\u5e74\u7684\u5e74\u5ea6\u62a5\u544a\uff0c\u5e76\u81ea\u52a8\u6807\u6ce8\u4efb\u52a1\u6807\u7b7e\uff0c\u6784\u5efa\u4e86EDINET-Bench\u6570\u636e\u96c6\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u5373\u4f7f\u662f\u5148\u8fdb\u7684LLM\u5728\u6b3a\u8bc8\u68c0\u6d4b\u548c\u76c8\u5229\u9884\u6d4b\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u4ec5\u7565\u4f18\u4e8e\u903b\u8f91\u56de\u5f52\u3002", "conclusion": "LLM\u5728\u91d1\u878d\u9886\u57df\u7684\u5b9e\u9645\u5e94\u7528\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u9886\u57df\u7279\u5b9a\u7684\u9002\u5e94\u3002\u6570\u636e\u96c6\u548c\u4ee3\u7801\u5df2\u516c\u5f00\u4ee5\u4fc3\u8fdb\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2506.08771", "pdf": "https://arxiv.org/pdf/2506.08771", "abs": "https://arxiv.org/abs/2506.08771", "authors": ["Yuni Susanti", "Michael F\u00e4rber"], "title": "Paths to Causality: Finding Informative Subgraphs Within Knowledge Graphs for Knowledge-Based Causal Discovery", "categories": ["cs.AI", "cs.CL", "cs.IR", "cs.LG"], "comment": "Accepted at KDD 2025 (full research paper)", "summary": "Inferring causal relationships between variable pairs is crucial for\nunderstanding multivariate interactions in complex systems. Knowledge-based\ncausal discovery -- which involves inferring causal relationships by reasoning\nover the metadata of variables (e.g., names or textual context) -- offers a\ncompelling alternative to traditional methods that rely on observational data.\nHowever, existing methods using Large Language Models (LLMs) often produce\nunstable and inconsistent results, compromising their reliability for causal\ninference. To address this, we introduce a novel approach that integrates\nKnowledge Graphs (KGs) with LLMs to enhance knowledge-based causal discovery.\nOur approach identifies informative metapath-based subgraphs within KGs and\nfurther refines the selection of these subgraphs using Learning-to-Rank-based\nmodels. The top-ranked subgraphs are then incorporated into zero-shot prompts,\nimproving the effectiveness of LLMs in inferring the causal relationship.\nExtensive experiments on biomedical and open-domain datasets demonstrate that\nour method outperforms most baselines by up to 44.4 points in F1 scores,\nevaluated across diverse LLMs and KGs. Our code and datasets are available on\nGitHub: https://github.com/susantiyuni/path-to-causality", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u77e5\u8bc6\u56fe\u8c31\uff08KGs\uff09\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u4ee5\u63d0\u5347\u57fa\u4e8e\u77e5\u8bc6\u7684\u56e0\u679c\u53d1\u73b0\uff0c\u89e3\u51b3\u4e86\u73b0\u6709LLMs\u65b9\u6cd5\u7ed3\u679c\u4e0d\u7a33\u5b9a\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u89c2\u6d4b\u6570\u636e\u7684\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u800c\u57fa\u4e8e\u77e5\u8bc6\u7684\u56e0\u679c\u53d1\u73b0\uff08\u5982\u5229\u7528\u53d8\u91cf\u5143\u6570\u636e\uff09\u662f\u4e00\u79cd\u6709\u6f5c\u529b\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4f46\u73b0\u6709LLMs\u65b9\u6cd5\u7ed3\u679c\u4e0d\u7a33\u5b9a\uff0c\u5f71\u54cd\u53ef\u9760\u6027\u3002", "method": "\u901a\u8fc7\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u5143\u8def\u5f84\u5b50\u56fe\u8bc6\u522b\uff0c\u7ed3\u5408\u5b66\u4e60\u6392\u5e8f\u6a21\u578b\u4f18\u5316\u5b50\u56fe\u9009\u62e9\uff0c\u5e76\u5c06\u6392\u540d\u9760\u524d\u7684\u5b50\u56fe\u878d\u5165\u96f6\u6837\u672c\u63d0\u793a\uff0c\u63d0\u5347LLMs\u7684\u56e0\u679c\u63a8\u7406\u80fd\u529b\u3002", "result": "\u5728\u751f\u7269\u533b\u5b66\u548c\u5f00\u653e\u9886\u57df\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728F1\u5206\u6570\u4e0a\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u6700\u9ad8\u63d0\u534744.4\u5206\u3002", "conclusion": "\u7ed3\u5408KGs\u4e0eLLMs\u7684\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u57fa\u4e8e\u77e5\u8bc6\u7684\u56e0\u679c\u53d1\u73b0\u7684\u7a33\u5b9a\u6027\u548c\u6548\u679c\uff0c\u4e3a\u590d\u6742\u7cfb\u7edf\u4e2d\u7684\u56e0\u679c\u63a8\u7406\u63d0\u4f9b\u4e86\u53ef\u9760\u5de5\u5177\u3002"}}
{"id": "2506.08780", "pdf": "https://arxiv.org/pdf/2506.08780", "abs": "https://arxiv.org/abs/2506.08780", "authors": ["Isaac Corley", "Lakshay Sharma", "Ruth Crasto"], "title": "Landsat-Bench: Datasets and Benchmarks for Landsat Foundation Models", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "The Landsat program offers over 50 years of globally consistent Earth\nimagery. However, the lack of benchmarks for this data constrains progress\ntowards Landsat-based Geospatial Foundation Models (GFM). In this paper, we\nintroduce Landsat-Bench, a suite of three benchmarks with Landsat imagery that\nadapt from existing remote sensing datasets -- EuroSAT-L, BigEarthNet-L, and\nLC100-L. We establish baseline and standardized evaluation methods across both\ncommon architectures and Landsat foundation models pretrained on the SSL4EO-L\ndataset. Notably, we provide evidence that SSL4EO-L pretrained GFMs extract\nbetter representations for downstream tasks in comparison to ImageNet,\nincluding performance gains of +4% OA and +5.1% mAP on EuroSAT-L and\nBigEarthNet-L.", "AI": {"tldr": "Landsat-Bench\u662f\u4e00\u5957\u57fa\u4e8eLandsat\u5f71\u50cf\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5730\u7406\u7a7a\u95f4\u57fa\u7840\u6a21\u578b\uff08GFM\uff09\u7684\u6027\u80fd\u3002", "motivation": "Landsat\u6570\u636e\u7f3a\u4e4f\u6807\u51c6\u5316\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u9650\u5236\u4e86\u57fa\u4e8eLandsat\u7684\u5730\u7406\u7a7a\u95f4\u57fa\u7840\u6a21\u578b\u7684\u53d1\u5c55\u3002", "method": "\u5f15\u5165\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\uff08EuroSAT-L\u3001BigEarthNet-L\u548cLC100-L\uff09\uff0c\u5e76\u4f7f\u7528SSL4EO-L\u9884\u8bad\u7ec3\u7684GFM\u4e0e\u5e38\u89c1\u67b6\u6784\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "SSL4EO-L\u9884\u8bad\u7ec3\u7684GFM\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8eImageNet\uff0c\u6027\u80fd\u63d0\u5347\u5206\u522b\u4e3a+4% OA\u548c+5.1% mAP\u3002", "conclusion": "Landsat-Bench\u4e3aLandsat\u6570\u636e\u7684\u6807\u51c6\u5316\u8bc4\u4f30\u63d0\u4f9b\u4e86\u5de5\u5177\uff0c\u5e76\u9a8c\u8bc1\u4e86SSL4EO-L\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2506.08783", "pdf": "https://arxiv.org/pdf/2506.08783", "abs": "https://arxiv.org/abs/2506.08783", "authors": ["Lukas Kammerer", "Deaglan J. Bartlett", "Gabriel Kronberger", "Harry Desmond", "Pedro G. Ferreira"], "title": "syren-baryon: Analytic emulators for the impact of baryons on the matter power spectrum", "categories": ["astro-ph.CO", "astro-ph.GA", "astro-ph.IM", "cs.LG", "cs.NE"], "comment": "14 pages, 6 figures. Submitted to A&A", "summary": "Baryonic physics has a considerable impact on the distribution of matter in\nour Universe on scales probed by current and future cosmological surveys,\nacting as a key systematic in such analyses. We seek simple symbolic\nparametrisations for the impact of baryonic physics on the matter power\nspectrum for a range of physically motivated models, as a function of\nwavenumber, redshift, cosmology, and parameters controlling the baryonic\nfeedback. We use symbolic regression to construct analytic approximations for\nthe ratio of the matter power spectrum in the presence of baryons to that\nwithout such effects. We obtain separate functions of each of four distinct\nsub-grid prescriptions of baryonic physics from the CAMELS suite of\nhydrodynamical simulations (Astrid, IllustrisTNG, SIMBA and Swift-EAGLE) as\nwell as for a baryonification algorithm. We also provide functions which\ndescribe the uncertainty on these predictions, due to both the stochastic\nnature of baryonic physics and the errors on our fits. The error on our\napproximations to the hydrodynamical simulations is comparable to the sample\nvariance estimated through varying initial conditions, and our baryonification\nexpression has a root mean squared error of better than one percent, although\nthis increases on small scales. These errors are comparable to those of\nprevious numerical emulators for these models. Our expressions are enforced to\nhave the physically correct behaviour on large scales and at high redshift. Due\nto their analytic form, we are able to directly interpret the impact of varying\ncosmology and feedback parameters, and we can identify parameters which have\nlittle to no effect. Each function is based on a different implementation of\nbaryonic physics, and can therefore be used to discriminate between these\nmodels when applied to real data. We provide publicly available code for all\nsymbolic approximations found.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7b26\u53f7\u56de\u5f52\u65b9\u6cd5\uff0c\u7528\u4e8e\u6784\u5efa\u91cd\u5b50\u7269\u7406\u5bf9\u7269\u8d28\u529f\u7387\u8c31\u5f71\u54cd\u7684\u89e3\u6790\u8fd1\u4f3c\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e0d\u540c\u91cd\u5b50\u7269\u7406\u6a21\u578b\u7684\u9884\u6d4b\u53ca\u5176\u4e0d\u786e\u5b9a\u6027\u3002", "motivation": "\u91cd\u5b50\u7269\u7406\u5bf9\u5b87\u5b99\u7269\u8d28\u5206\u5e03\u7684\u663e\u8457\u5f71\u54cd\u662f\u5f53\u524d\u548c\u672a\u6765\u5b87\u5b99\u5b66\u8c03\u67e5\u7684\u5173\u952e\u7cfb\u7edf\u8bef\u5dee\u6765\u6e90\uff0c\u9700\u8981\u7b80\u5355\u4e14\u7269\u7406\u5408\u7406\u7684\u53c2\u6570\u5316\u63cf\u8ff0\u3002", "method": "\u4f7f\u7528\u7b26\u53f7\u56de\u5f52\u4eceCAMELS\u6d41\u4f53\u52a8\u529b\u5b66\u6a21\u62df\u4e2d\u63d0\u53d6\u91cd\u5b50\u7269\u7406\u5bf9\u7269\u8d28\u529f\u7387\u8c31\u5f71\u54cd\u7684\u89e3\u6790\u8fd1\u4f3c\uff0c\u6db5\u76d6\u56db\u79cd\u4e0d\u540c\u5b50\u7f51\u683c\u6a21\u578b\u548c\u4e00\u4e2a\u91cd\u5b50\u5316\u7b97\u6cd5\u3002", "result": "\u89e3\u6790\u8fd1\u4f3c\u7684\u8bef\u5dee\u4e0e\u6837\u672c\u65b9\u5dee\u76f8\u5f53\uff0c\u91cd\u5b50\u5316\u8868\u8fbe\u5f0f\u7684\u5747\u65b9\u6839\u8bef\u5dee\u5c0f\u4e8e1%\uff0c\u4e14\u5728\u5927\u5c3a\u5ea6\u548c\u9ad8\u7ea2\u79fb\u4e0b\u5177\u6709\u7269\u7406\u6b63\u786e\u6027\u3002", "conclusion": "\u8fd9\u4e9b\u89e3\u6790\u5f62\u5f0f\u53ef\u76f4\u63a5\u89e3\u91ca\u5b87\u5b99\u5b66\u548c\u53cd\u9988\u53c2\u6570\u7684\u5f71\u54cd\uff0c\u5e76\u53ef\u7528\u4e8e\u533a\u5206\u4e0d\u540c\u91cd\u5b50\u7269\u7406\u6a21\u578b\uff0c\u76f8\u5173\u4ee3\u7801\u5df2\u516c\u5f00\u3002"}}
{"id": "2506.08860", "pdf": "https://arxiv.org/pdf/2506.08860", "abs": "https://arxiv.org/abs/2506.08860", "authors": ["Samah Kansab", "Francis Bordeleau", "Ali Tizghadam"], "title": "On The Impact of Merge Request Deviations on Code Review Practices", "categories": ["cs.SE", "cs.AI", "cs.LG"], "comment": null, "summary": "Code review is a key practice in software engineering, ensuring quality and\ncollaboration. However, industrial Merge Request (MR) workflows often deviate\nfrom standardized review processes, with many MRs serving non-review purposes\n(e.g., drafts, rebases, or dependency updates). We term these cases deviations\nand hypothesize that ignoring them biases analytics and undermines ML models\nfor review analysis.\n  We identify seven deviation categories, occurring in 37.02% of MRs, and\npropose a few-shot learning detection method (91% accuracy). By excluding\ndeviations, ML models predicting review completion time improve performance in\n53.33% of cases (up to 2.25x) and exhibit significant shifts in feature\nimportance (47% overall, 60% top-*k*).\n  Our contributions include: (1) a taxonomy of MR deviations, (2) an AI-driven\ndetection approach, and (3) empirical evidence of their impact on ML-based\nreview analytics. This work aids practitioners in optimizing review efforts and\nensuring reliable insights.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bc6\u522b\u4ee3\u7801\u5ba1\u67e5\u4e2d\u975e\u6807\u51c6\u5408\u5e76\u8bf7\u6c42\uff08MR\uff09\u7684\u65b9\u6cd5\uff0c\u5e76\u8bc1\u660e\u6392\u9664\u8fd9\u4e9b\u504f\u5dee\u80fd\u63d0\u5347\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u5de5\u4e1a\u4e2d\u7684\u5408\u5e76\u8bf7\u6c42\uff08MR\uff09\u6d41\u7a0b\u5e38\u504f\u79bb\u6807\u51c6\u5ba1\u67e5\u6d41\u7a0b\uff0c\u5bfc\u81f4\u5206\u6790\u548c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5b58\u5728\u504f\u5dee\u3002", "method": "\u63d0\u51fa\u4e86\u4e03\u79cd\u504f\u5dee\u7c7b\u522b\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u79cd\u5c11\u6837\u672c\u5b66\u4e60\u68c0\u6d4b\u65b9\u6cd5\uff08\u51c6\u786e\u738791%\uff09\u3002", "result": "\u6392\u9664\u504f\u5dee\u540e\uff0c\u9884\u6d4b\u5ba1\u67e5\u5b8c\u6210\u65f6\u95f4\u7684ML\u6a21\u578b\u6027\u80fd\u63d0\u534753.33%\uff0c\u7279\u5f81\u91cd\u8981\u6027\u663e\u8457\u53d8\u5316\u3002", "conclusion": "\u7814\u7a76\u4e3a\u4f18\u5316\u4ee3\u7801\u5ba1\u67e5\u63d0\u4f9b\u4e86\u504f\u5dee\u5206\u7c7b\u3001\u68c0\u6d4b\u65b9\u6cd5\u53ca\u5176\u5bf9ML\u5206\u6790\u5f71\u54cd\u7684\u5b9e\u8bc1\u652f\u6301\u3002"}}
{"id": "2506.08862", "pdf": "https://arxiv.org/pdf/2506.08862", "abs": "https://arxiv.org/abs/2506.08862", "authors": ["Zike Wu", "Qi Yan", "Xuanyu Yi", "Lele Wang", "Renjie Liao"], "title": "StreamSplat: Towards Online Dynamic 3D Reconstruction from Uncalibrated Video Streams", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Real-time reconstruction of dynamic 3D scenes from uncalibrated video streams\nis crucial for numerous real-world applications. However, existing methods\nstruggle to jointly address three key challenges: 1) processing uncalibrated\ninputs in real time, 2) accurately modeling dynamic scene evolution, and 3)\nmaintaining long-term stability and computational efficiency. To this end, we\nintroduce StreamSplat, the first fully feed-forward framework that transforms\nuncalibrated video streams of arbitrary length into dynamic 3D Gaussian\nSplatting (3DGS) representations in an online manner, capable of recovering\nscene dynamics from temporally local observations. We propose two key technical\ninnovations: a probabilistic sampling mechanism in the static encoder for 3DGS\nposition prediction, and a bidirectional deformation field in the dynamic\ndecoder that enables robust and efficient dynamic modeling. Extensive\nexperiments on static and dynamic benchmarks demonstrate that StreamSplat\nconsistently outperforms prior works in both reconstruction quality and dynamic\nscene modeling, while uniquely supporting online reconstruction of arbitrarily\nlong video streams. Code and models are available at\nhttps://github.com/nickwzk/StreamSplat.", "AI": {"tldr": "StreamSplat\u662f\u4e00\u4e2a\u5b9e\u65f6\u52a8\u60013D\u573a\u666f\u91cd\u5efa\u6846\u67b6\uff0c\u901a\u8fc7\u524d\u9988\u65b9\u5f0f\u5904\u7406\u672a\u6821\u51c6\u89c6\u9891\u6d41\uff0c\u89e3\u51b3\u4e86\u5b9e\u65f6\u6027\u3001\u52a8\u6001\u5efa\u6a21\u548c\u957f\u671f\u7a33\u5b9a\u6027\u7684\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u5904\u7406\u672a\u6821\u51c6\u8f93\u5165\u7684\u5b9e\u65f6\u6027\u3001\u52a8\u6001\u573a\u666f\u5efa\u6a21\u7684\u51c6\u786e\u6027\u4ee5\u53ca\u957f\u671f\u7a33\u5b9a\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002", "method": "\u63d0\u51faStreamSplat\u6846\u67b6\uff0c\u5305\u542b\u9759\u6001\u7f16\u7801\u5668\u4e2d\u7684\u6982\u7387\u91c7\u6837\u673a\u5236\u548c\u52a8\u6001\u89e3\u7801\u5668\u4e2d\u7684\u53cc\u5411\u53d8\u5f62\u573a\u3002", "result": "\u5728\u9759\u6001\u548c\u52a8\u6001\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u652f\u6301\u4efb\u610f\u957f\u5ea6\u89c6\u9891\u6d41\u7684\u5728\u7ebf\u91cd\u5efa\u3002", "conclusion": "StreamSplat\u5728\u91cd\u5efa\u8d28\u91cf\u548c\u52a8\u6001\u5efa\u6a21\u65b9\u9762\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u9002\u7528\u4e8e\u5b9e\u65f6\u5e94\u7528\u3002"}}
{"id": "2506.08885", "pdf": "https://arxiv.org/pdf/2506.08885", "abs": "https://arxiv.org/abs/2506.08885", "authors": ["Danush Khanna", "Krishna Kumar", "Basab Ghosh", "Vinija Jain", "Vasu Sharma", "Aman Chadha", "Amitava Das"], "title": "AdversariaL attacK sAfety aLIgnment(ALKALI): Safeguarding LLMs through GRACE: Geometric Representation-Aware Contrastive Enhancement- Introducing Adversarial Vulnerability Quality Index (AVQI)", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Adversarial threats against LLMs are escalating faster than current defenses\ncan adapt. We expose a critical geometric blind spot in alignment: adversarial\nprompts exploit latent camouflage, embedding perilously close to the safe\nrepresentation manifold while encoding unsafe intent thereby evading surface\nlevel defenses like Direct Preference Optimization (DPO), which remain blind to\nthe latent geometry. We introduce ALKALI, the first rigorously curated\nadversarial benchmark and the most comprehensive to date spanning 9,000 prompts\nacross three macro categories, six subtypes, and fifteen attack families.\nEvaluation of 21 leading LLMs reveals alarmingly high Attack Success Rates\n(ASRs) across both open and closed source models, exposing an underlying\nvulnerability we term latent camouflage, a structural blind spot where\nadversarial completions mimic the latent geometry of safe ones. To mitigate\nthis vulnerability, we introduce GRACE - Geometric Representation Aware\nContrastive Enhancement, an alignment framework coupling preference learning\nwith latent space regularization. GRACE enforces two constraints: latent\nseparation between safe and adversarial completions, and adversarial cohesion\namong unsafe and jailbreak behaviors. These operate over layerwise pooled\nembeddings guided by a learned attention profile, reshaping internal geometry\nwithout modifying the base model, and achieve up to 39% ASR reduction.\nMoreover, we introduce AVQI, a geometry aware metric that quantifies latent\nalignment failure via cluster separation and compactness. AVQI reveals when\nunsafe completions mimic the geometry of safe ones, offering a principled lens\ninto how models internally encode safety. We make the code publicly available\nat https://anonymous.4open.science/r/alkali-B416/README.md.", "AI": {"tldr": "\u8bba\u6587\u63ed\u793a\u4e86LLM\u5bf9\u6297\u6027\u5a01\u80c1\u7684\u51e0\u4f55\u76f2\u70b9\uff0c\u63d0\u51faALKALI\u57fa\u51c6\u548cGRACE\u6846\u67b6\u4ee5\u63d0\u5347\u9632\u5fa1\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u9632\u5fa1\u65b9\u6cd5\u65e0\u6cd5\u5e94\u5bf9\u5feb\u901f\u589e\u957f\u7684\u5bf9\u6297\u6027\u5a01\u80c1\uff0c\u5c24\u5176\u662f\u9488\u5bf9LLM\u7684\u6f5c\u5728\u4f2a\u88c5\u653b\u51fb\u3002", "method": "\u5f15\u5165ALKALI\u57fa\u51c6\u8bc4\u4f3021\u79cdLLM\uff0c\u63d0\u51faGRACE\u6846\u67b6\u7ed3\u5408\u504f\u597d\u5b66\u4e60\u548c\u6f5c\u5728\u7a7a\u95f4\u6b63\u5219\u5316\u3002", "result": "GRACE\u663e\u8457\u964d\u4f4e\u653b\u51fb\u6210\u529f\u7387\uff08ASR\uff09\u8fbe39%\uff0c\u5e76\u5f00\u53d1AVQI\u6307\u6807\u91cf\u5316\u6f5c\u5728\u5bf9\u9f50\u5931\u8d25\u3002", "conclusion": "GRACE\u548cAVQI\u4e3aLLM\u5b89\u5168\u63d0\u4f9b\u4e86\u65b0\u7684\u9632\u5fa1\u548c\u8bc4\u4f30\u5de5\u5177\u3002"}}
{"id": "2506.08893", "pdf": "https://arxiv.org/pdf/2506.08893", "abs": "https://arxiv.org/abs/2506.08893", "authors": ["Kai Zhou", "Youbiao He", "Chong Zhong", "Yifu Wu"], "title": "Real-Time Cascade Mitigation in Power Systems Using Influence Graph Improved by Reinforcement Learning", "categories": ["physics.soc-ph", "cs.LG", "physics.data-an"], "comment": null, "summary": "Despite high reliability, modern power systems with growing renewable\npenetration face an increasing risk of cascading outages. Real-time cascade\nmitigation requires fast, complex operational decisions under uncertainty. In\nthis work, we extend the influence graph into a Markov decision process model\n(MDP) for real-time mitigation of cascading outages in power transmission\nsystems, accounting for uncertainties in generation, load, and initial\ncontingencies. The MDP includes a do-nothing action to allow for conservative\ndecision-making and is solved using reinforcement learning. We present a policy\ngradient learning algorithm initialized with a policy corresponding to the\nunmitigated case and designed to handle invalid actions. The proposed learning\nmethod converges faster than the conventional algorithm. Through careful reward\ndesign, we learn a policy that takes conservative actions without deteriorating\nsystem conditions. The model is validated on the IEEE 14-bus and IEEE 118-bus\nsystems. The results show that proactive line disconnections can effectively\nreduce cascading risk, and certain lines consistently emerge as critical in\nmitigating cascade propagation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08MDP\uff09\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5b9e\u65f6\u7f13\u89e3\u7535\u529b\u4f20\u8f93\u7cfb\u7edf\u4e2d\u7684\u7ea7\u8054\u505c\u7535\u98ce\u9669\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u5feb\u901f\u751f\u6210\u4fdd\u5b88\u51b3\u7b56\u3002", "motivation": "\u73b0\u4ee3\u7535\u529b\u7cfb\u7edf\u867d\u53ef\u9760\u6027\u9ad8\uff0c\u4f46\u53ef\u518d\u751f\u80fd\u6e90\u6e17\u900f\u7387\u589e\u52a0\u5bfc\u81f4\u7ea7\u8054\u505c\u7535\u98ce\u9669\u4e0a\u5347\uff0c\u9700\u5feb\u901f\u5e94\u5bf9\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u5c06\u5f71\u54cd\u56fe\u6269\u5c55\u4e3aMDP\u6a21\u578b\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\uff08\u7b56\u7565\u68af\u5ea6\u7b97\u6cd5\uff09\u5904\u7406\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u8bbe\u8ba1\u4fdd\u5b88\u52a8\u4f5c\uff08\u5982\u201c\u4e0d\u884c\u52a8\u201d\uff09\u548c\u5956\u52b1\u673a\u5236\u3002", "result": "\u5728IEEE 14\u548c118\u603b\u7ebf\u7cfb\u7edf\u9a8c\u8bc1\u4e2d\uff0c\u4e3b\u52a8\u65ad\u5f00\u7ebf\u8def\u53ef\u6709\u6548\u964d\u4f4e\u7ea7\u8054\u98ce\u9669\uff0c\u67d0\u4e9b\u7ebf\u8def\u88ab\u8bc6\u522b\u4e3a\u5173\u952e\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u5feb\u901f\u6536\u655b\u5e76\u751f\u6210\u4fdd\u5b88\u7b56\u7565\uff0c\u4e3a\u5b9e\u65f6\u7f13\u89e3\u7ea7\u8054\u505c\u7535\u63d0\u4f9b\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2506.08911", "pdf": "https://arxiv.org/pdf/2506.08911", "abs": "https://arxiv.org/abs/2506.08911", "authors": ["Petar Jaku\u0161", "Hrvoje D\u017eapo"], "title": "Implementing Keyword Spotting on the MCUX947 Microcontroller with Integrated NPU", "categories": ["cs.HC", "cs.LG", "cs.SD"], "comment": "4 pages", "summary": "This paper presents a keyword spotting (KWS) system implemented on the NXP\nMCXN947 microcontroller with an integrated Neural Processing Unit (NPU),\nenabling real-time voice interaction on resource-constrained devices. The\nsystem combines MFCC feature extraction with a CNN classifier, optimized using\nQuantization Aware Training to reduce model size with minimal accuracy drop.\nExperimental results demonstrate a 59x speedup in inference time when\nleveraging the NPU compared to CPU-only execution, achieving 97.06% accuracy\nwith a model size of 30.58 KB, demonstrating the feasibility of efficient,\nlow-power voice interfaces on embedded platforms.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u5728NXP MCXN947\u5fae\u63a7\u5236\u5668\u4e0a\u5b9e\u73b0\u7684\u5173\u952e\u8bcd\u68c0\u6d4b\u7cfb\u7edf\uff0c\u5229\u7528\u96c6\u6210\u7684NPU\u5b9e\u73b0\u5b9e\u65f6\u8bed\u97f3\u4ea4\u4e92\uff0c\u5e76\u901a\u8fc7\u91cf\u5316\u611f\u77e5\u8bad\u7ec3\u4f18\u5316\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u63a8\u7406\u901f\u5ea6\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u5b9e\u65f6\u8bed\u97f3\u4ea4\u4e92\u7684\u6311\u6218\uff0c\u901a\u8fc7\u4f18\u5316\u6a21\u578b\u548c\u786c\u4ef6\u52a0\u901f\u5b9e\u73b0\u9ad8\u6548\u4f4e\u529f\u8017\u7684\u8bed\u97f3\u63a5\u53e3\u3002", "method": "\u7ed3\u5408MFCC\u7279\u5f81\u63d0\u53d6\u4e0eCNN\u5206\u7c7b\u5668\uff0c\u91c7\u7528\u91cf\u5316\u611f\u77e5\u8bad\u7ec3\u4f18\u5316\u6a21\u578b\uff0c\u51cf\u5c11\u6a21\u578b\u5927\u5c0f\u5e76\u4fdd\u6301\u8f83\u9ad8\u51c6\u786e\u7387\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5229\u7528NPU\u6bd4\u4ec5\u7528CPU\u63a8\u7406\u901f\u5ea6\u5feb59\u500d\uff0c\u6a21\u578b\u5927\u5c0f\u4e3a30.58 KB\uff0c\u51c6\u786e\u7387\u8fbe97.06%\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u8bc1\u660e\u4e86\u5728\u5d4c\u5165\u5f0f\u5e73\u53f0\u4e0a\u5b9e\u73b0\u9ad8\u6548\u4f4e\u529f\u8017\u8bed\u97f3\u63a5\u53e3\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2506.08920", "pdf": "https://arxiv.org/pdf/2506.08920", "abs": "https://arxiv.org/abs/2506.08920", "authors": ["Zeyu Leo Liu", "Greg Durrett", "Eunsol Choi"], "title": "PropMEND: Hypernetworks for Knowledge Propagation in LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Under review", "summary": "Knowledge editing techniques for large language models (LLMs) can inject\nknowledge that is later reproducible verbatim, but they fall short on\npropagating that knowledge: models cannot answer questions that require\nreasoning with the injected knowledge. We present a hypernetwork-based approach\nfor knowledge propagation, named PropMEND, where we meta-learn how to modify\ngradients of a language modeling loss to encourage injected information to\npropagate. Our approach extends the meta-objective of MEND [29] so that\ngradient updates on knowledge are transformed to enable answering multi-hop\nquestions involving that knowledge. We show improved performance on the\nRippleEdit dataset, showing almost 2x accuracy on challenging multi-hop\nquestions whose answers are not explicitly stated in the injected fact. We\nfurther introduce a new dataset, Controlled RippleEdit, to evaluate the\ngeneralization of our hypernetwork, testing knowledge propagation along\nrelations and entities unseen during hypernetwork training. PropMEND still\noutperforms existing approaches in unseen entity-relation pairs, yet the\nperformance gap decreases substantially, suggesting future work in propagating\nknowledge to a wide range of relations.", "AI": {"tldr": "PropMEND\u662f\u4e00\u79cd\u57fa\u4e8e\u8d85\u7f51\u7edc\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u6539\u8fdb\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u77e5\u8bc6\u4f20\u64ad\u80fd\u529b\uff0c\u4f7f\u5176\u80fd\u591f\u56de\u7b54\u6d89\u53ca\u6ce8\u5165\u77e5\u8bc6\u7684\u63a8\u7406\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u77e5\u8bc6\u7f16\u8f91\u6280\u672f\u65e0\u6cd5\u6709\u6548\u4f20\u64ad\u6ce8\u5165\u7684\u77e5\u8bc6\uff0c\u5bfc\u81f4\u6a21\u578b\u65e0\u6cd5\u56de\u7b54\u9700\u8981\u63a8\u7406\u7684\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5143\u5b66\u4e60\u4fee\u6539\u8bed\u8a00\u5efa\u6a21\u635f\u5931\u7684\u68af\u5ea6\uff0c\u4ee5\u4fc3\u8fdb\u77e5\u8bc6\u4f20\u64ad\uff0c\u6269\u5c55\u4e86MEND\u7684\u5143\u76ee\u6807\u3002", "result": "\u5728RippleEdit\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u591a\u8df3\u95ee\u9898\u51c6\u786e\u7387\u63d0\u5347\u8fd12\u500d\uff1b\u5728Controlled RippleEdit\u6570\u636e\u96c6\u4e0a\u4ecd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "PropMEND\u5728\u77e5\u8bc6\u4f20\u64ad\u65b9\u9762\u8868\u73b0\u4f18\u8d8a\uff0c\u4f46\u5728\u672a\u89c1\u5b9e\u4f53\u5173\u7cfb\u4e0a\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\u3002"}}
{"id": "2506.08935", "pdf": "https://arxiv.org/pdf/2506.08935", "abs": "https://arxiv.org/abs/2506.08935", "authors": ["Andrew Shin"], "title": "Can A Gamer Train A Mathematical Reasoning Model?", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "While large language models (LLMs) have achieved remarkable performance in\nvarious tasks including mathematical reasoning, their development typically\ndemands prohibitive computational resources. Recent advancements have reduced\ncosts for training capable models, yet even these approaches rely on high-end\nhardware clusters. In this paper, we demonstrate that a single average gaming\nGPU can train a solid mathematical reasoning model, by integrating\nreinforcement learning and memory optimization techniques. Specifically, we\ntrain a 1.5B parameter mathematical reasoning model on RTX 3080 Ti of 16GB\nmemory that achieves comparable or better performance on mathematical reasoning\nbenchmarks than models several times larger, in resource-constrained\nenvironments. Our results challenge the paradigm that state-of-the-art\nmathematical reasoning necessitates massive infrastructure, democratizing\naccess to high-performance AI research.\nhttps://github.com/shinandrew/YouronMath.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u5355\u5f20\u6e38\u620fGPU\u4e0a\u8bad\u7ec3\u9ad8\u6027\u80fd\u6570\u5b66\u63a8\u7406\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u548c\u5185\u5b58\u4f18\u5316\u6280\u672f\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8bad\u7ec3\u6210\u672c\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u7b49\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5176\u8bad\u7ec3\u901a\u5e38\u9700\u8981\u9ad8\u6602\u7684\u8ba1\u7b97\u8d44\u6e90\u3002\u672c\u6587\u65e8\u5728\u8bc1\u660e\uff0c\u901a\u8fc7\u4f18\u5316\u6280\u672f\uff0c\u53ef\u4ee5\u5728\u8d44\u6e90\u6709\u9650\u7684\u73af\u5883\u4e2d\u5b9e\u73b0\u9ad8\u6027\u80fd\u3002", "method": "\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u548c\u5185\u5b58\u4f18\u5316\u6280\u672f\uff0c\u5728\u5355\u5f20RTX 3080 Ti\uff0816GB\u5185\u5b58\uff09\u4e0a\u8bad\u7ec3\u4e86\u4e00\u4e2a1.5B\u53c2\u6570\u7684\u6570\u5b66\u63a8\u7406\u6a21\u578b\u3002", "result": "\u8be5\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u6216\u63a5\u8fd1\u66f4\u5927\u89c4\u6a21\u7684\u6a21\u578b\uff0c\u8bc1\u660e\u4e86\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u9ad8\u6027\u80fdAI\u7814\u7a76\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u7814\u7a76\u6311\u6218\u4e86\u9ad8\u6027\u80fd\u6570\u5b66\u63a8\u7406\u9700\u8981\u5927\u89c4\u6a21\u57fa\u7840\u8bbe\u65bd\u7684\u4f20\u7edf\u89c2\u5ff5\uff0c\u4e3a\u8d44\u6e90\u6709\u9650\u7684\u7814\u7a76\u8005\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2506.08954", "pdf": "https://arxiv.org/pdf/2506.08954", "abs": "https://arxiv.org/abs/2506.08954", "authors": ["Ruben Weitzman", "Peter M\u00f8rch Groth", "Lood Van Niekerk", "Aoi Otani", "Yarin Gal", "Debora Marks", "Pascal Notin"], "title": "Protriever: End-to-End Differentiable Protein Homology Search for Fitness Prediction", "categories": ["q-bio.QM", "cs.LG"], "comment": "Accepted at ICML 2025", "summary": "Retrieving homologous protein sequences is essential for a broad range of\nprotein modeling tasks such as fitness prediction, protein design, structure\nmodeling, and protein-protein interactions. Traditional workflows have relied\non a two-step process: first retrieving homologs via Multiple Sequence\nAlignments (MSA), then training models on one or more of these alignments.\nHowever, MSA-based retrieval is computationally expensive, struggles with\nhighly divergent sequences or complex insertions & deletions patterns, and\noperates independently of the downstream modeling objective. We introduce\nProtriever, an end-to-end differentiable framework that learns to retrieve\nrelevant homologs while simultaneously training for the target task. When\napplied to protein fitness prediction, Protriever achieves state-of-the-art\nperformance compared to sequence-based models that rely on MSA-based homolog\nretrieval, while being two orders of magnitude faster through efficient vector\nsearch. Protriever is both architecture- and task-agnostic, and can flexibly\nadapt to different retrieval strategies and protein databases at inference time\n-- offering a scalable alternative to alignment-centric approaches.", "AI": {"tldr": "Protriever\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u53ef\u5fae\u5206\u6846\u67b6\uff0c\u7528\u4e8e\u68c0\u7d22\u540c\u6e90\u86cb\u767d\u5e8f\u5217\u5e76\u540c\u65f6\u8bad\u7ec3\u76ee\u6807\u4efb\u52a1\uff0c\u76f8\u6bd4\u4f20\u7edfMSA\u65b9\u6cd5\u66f4\u5feb\u4e14\u6027\u80fd\u66f4\u4f18\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8eMSA\u7684\u540c\u6e90\u86cb\u767d\u68c0\u7d22\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u4e14\u96be\u4ee5\u5904\u7406\u9ad8\u5ea6\u5206\u5316\u7684\u5e8f\u5217\u6216\u590d\u6742\u7684\u63d2\u5165/\u5220\u9664\u6a21\u5f0f\u3002", "method": "Protriever\u901a\u8fc7\u7aef\u5230\u7aef\u53ef\u5fae\u5206\u6846\u67b6\uff0c\u7ed3\u5408\u9ad8\u6548\u7684\u5411\u91cf\u641c\u7d22\uff0c\u540c\u65f6\u5b66\u4e60\u68c0\u7d22\u540c\u6e90\u5e8f\u5217\u5e76\u8bad\u7ec3\u76ee\u6807\u4efb\u52a1\u3002", "result": "\u5728\u86cb\u767d\u9002\u5e94\u6027\u9884\u6d4b\u4efb\u52a1\u4e2d\uff0cProtriever\u6027\u80fd\u4f18\u4e8e\u57fa\u4e8eMSA\u7684\u6a21\u578b\uff0c\u4e14\u901f\u5ea6\u5feb\u4e24\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "Protriever\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u4e0d\u540c\u68c0\u7d22\u7b56\u7565\u548c\u86cb\u767d\u6570\u636e\u5e93\u3002"}}
{"id": "2506.08955", "pdf": "https://arxiv.org/pdf/2506.08955", "abs": "https://arxiv.org/abs/2506.08955", "authors": ["Chunming He", "Kai Li", "Yachao Zhang", "Ziyun Yang", "Youwei Pang", "Longxiang Tang", "Chengyu Fang", "Yulun Zhang", "Linghe Kong", "Xiu Li", "Sina Farsiu"], "title": "Segment Concealed Objects with Incomplete Supervision", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "IEEE TPAMI", "summary": "Incompletely-Supervised Concealed Object Segmentation (ISCOS) involves\nsegmenting objects that seamlessly blend into their surrounding environments,\nutilizing incompletely annotated data, such as weak and semi-annotations, for\nmodel training. This task remains highly challenging due to (1) the limited\nsupervision provided by the incompletely annotated training data, and (2) the\ndifficulty of distinguishing concealed objects from the background, which\narises from the intrinsic similarities in concealed scenarios. In this paper,\nwe introduce the first unified method for ISCOS to address these challenges. To\ntackle the issue of incomplete supervision, we propose a unified mean-teacher\nframework, SEE, that leverages the vision foundation model, ``\\emph{Segment\nAnything Model (SAM)}'', to generate pseudo-labels using coarse masks produced\nby the teacher model as prompts. To mitigate the effect of low-quality\nsegmentation masks, we introduce a series of strategies for pseudo-label\ngeneration, storage, and supervision. These strategies aim to produce\ninformative pseudo-labels, store the best pseudo-labels generated, and select\nthe most reliable components to guide the student model, thereby ensuring\nrobust network training. Additionally, to tackle the issue of intrinsic\nsimilarity, we design a hybrid-granularity feature grouping module that groups\nfeatures at different granularities and aggregates these results. By clustering\nsimilar features, this module promotes segmentation coherence, facilitating\nmore complete segmentation for both single-object and multiple-object images.\nWe validate the effectiveness of our approach across multiple ISCOS tasks, and\nexperimental results demonstrate that our method achieves state-of-the-art\nperformance. Furthermore, SEE can serve as a plug-and-play solution, enhancing\nthe performance of existing models.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u65b9\u6cd5SEE\uff0c\u7528\u4e8e\u4e0d\u5b8c\u5168\u76d1\u7763\u7684\u9690\u853d\u7269\u4f53\u5206\u5272\uff08ISCOS\uff09\uff0c\u901a\u8fc7\u7ed3\u5408SAM\u751f\u6210\u4f2a\u6807\u7b7e\u548c\u6df7\u5408\u7c92\u5ea6\u7279\u5f81\u5206\u7ec4\u6a21\u5757\uff0c\u89e3\u51b3\u4e86\u4e0d\u5b8c\u5168\u76d1\u7763\u548c\u9690\u853d\u7269\u4f53\u4e0e\u80cc\u666f\u76f8\u4f3c\u6027\u7684\u6311\u6218\u3002", "motivation": "\u9690\u853d\u7269\u4f53\u5206\u5272\u4efb\u52a1\u9762\u4e34\u4e0d\u5b8c\u5168\u6807\u6ce8\u6570\u636e\u548c\u7269\u4f53\u4e0e\u80cc\u666f\u9ad8\u5ea6\u76f8\u4f3c\u7684\u53cc\u91cd\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u89e3\u51b3\u3002", "method": "\u63d0\u51faSEE\u6846\u67b6\uff0c\u5229\u7528SAM\u751f\u6210\u4f2a\u6807\u7b7e\uff0c\u5e76\u901a\u8fc7\u4f2a\u6807\u7b7e\u751f\u6210\u3001\u5b58\u50a8\u548c\u76d1\u7763\u7b56\u7565\u4f18\u5316\u8bad\u7ec3\uff1b\u8bbe\u8ba1\u6df7\u5408\u7c92\u5ea6\u7279\u5f81\u5206\u7ec4\u6a21\u5757\u63d0\u5347\u5206\u5272\u4e00\u81f4\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSEE\u5728\u591a\u4e2aISCOS\u4efb\u52a1\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5e76\u53ef\u4f5c\u4e3a\u5373\u63d2\u5373\u7528\u65b9\u6848\u63d0\u5347\u73b0\u6709\u6a21\u578b\u3002", "conclusion": "SEE\u901a\u8fc7\u7edf\u4e00\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86ISCOS\u7684\u6838\u5fc3\u6311\u6218\uff0c\u5177\u6709\u5b9e\u7528\u6027\u548c\u63a8\u5e7f\u6027\u3002"}}
{"id": "2506.08956", "pdf": "https://arxiv.org/pdf/2506.08956", "abs": "https://arxiv.org/abs/2506.08956", "authors": ["DaeEun Yoon", "Semin Kim", "SangWook Yoo", "Jongha Lee"], "title": "Data Augmentation For Small Object using Fast AutoAugment", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted and published in the USB Proceedings of the 20th\n  International Conference on Modeling Decisions for Artificial Intelligence\n  (MDAI 2023), Ume{\\aa}, Sweden, June 19--22, 2023, ISBN 978-91-527-7293-5,\n  pp.\\ 12--21", "summary": "In recent years, there has been tremendous progress in object detection\nperformance. However, despite these advances, the detection performance for\nsmall objects is significantly inferior to that of large objects. Detecting\nsmall objects is one of the most challenging and important problems in computer\nvision. To improve the detection performance for small objects, we propose an\noptimal data augmentation method using Fast AutoAugment. Through our proposed\nmethod, we can quickly find optimal augmentation policies that can overcome\ndegradation when detecting small objects, and we achieve a 20% performance\nimprovement on the DOTA dataset.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eFast AutoAugment\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5c0f\u76ee\u6807\u68c0\u6d4b\u6027\u80fd\uff0c\u5728DOTA\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e8620%\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u5c3d\u7ba1\u76ee\u6807\u68c0\u6d4b\u6574\u4f53\u6027\u80fd\u6709\u663e\u8457\u8fdb\u6b65\uff0c\u4f46\u5c0f\u76ee\u6807\u68c0\u6d4b\u6027\u80fd\u4ecd\u8fdc\u4f4e\u4e8e\u5927\u76ee\u6807\uff0c\u8fd9\u662f\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2d\u7684\u91cd\u8981\u6311\u6218\u3002", "method": "\u91c7\u7528Fast AutoAugment\u5feb\u901f\u5bfb\u627e\u6700\u4f18\u6570\u636e\u589e\u5f3a\u7b56\u7565\uff0c\u4ee5\u514b\u670d\u5c0f\u76ee\u6807\u68c0\u6d4b\u4e2d\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\u3002", "result": "\u5728DOTA\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e8620%\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u63d0\u51fa\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u5c0f\u76ee\u6807\u68c0\u6d4b\u6027\u80fd\uff0c\u4e3a\u89e3\u51b3\u8fd9\u4e00\u91cd\u8981\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.08957", "pdf": "https://arxiv.org/pdf/2506.08957", "abs": "https://arxiv.org/abs/2506.08957", "authors": ["Yash Ranjan", "Rahul Sengupta", "Anand Rangarajan", "Sanjay Ranka"], "title": "IntTrajSim: Trajectory Prediction for Simulating Multi-Vehicle driving at Signalized Intersections", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Traffic simulators are widely used to study the operational efficiency of\nroad infrastructure, but their rule-based approach limits their ability to\nmimic real-world driving behavior. Traffic intersections are critical\ncomponents of the road infrastructure, both in terms of safety risk (nearly 28%\nof fatal crashes and 58% of nonfatal crashes happen at intersections) as well\nas the operational efficiency of a road corridor. This raises an important\nquestion: can we create a data-driven simulator that can mimic the macro- and\nmicro-statistics of the driving behavior at a traffic intersection? Deep\nGenerative Modeling-based trajectory prediction models provide a good starting\npoint to model the complex dynamics of vehicles at an intersection. But they\nare not tested in a \"live\" micro-simulation scenario and are not evaluated on\ntraffic engineering-related metrics. In this study, we propose traffic\nengineering-related metrics to evaluate generative trajectory prediction models\nand provide a simulation-in-the-loop pipeline to do so. We also provide a\nmulti-headed self-attention-based trajectory prediction model that incorporates\nthe signal information, which outperforms our previous models on the evaluation\nmetrics.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6570\u636e\u9a71\u52a8\u7684\u4ea4\u901a\u6a21\u62df\u5668\uff0c\u901a\u8fc7\u6df1\u5ea6\u751f\u6210\u6a21\u578b\u6a21\u62df\u4ea4\u901a\u8def\u53e3\u7684\u9a7e\u9a76\u884c\u4e3a\uff0c\u5e76\u5f15\u5165\u4ea4\u901a\u5de5\u7a0b\u76f8\u5173\u6307\u6807\u8fdb\u884c\u8bc4\u4f30\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u89c4\u5219\u7684\u4ea4\u901a\u6a21\u62df\u5668\u96be\u4ee5\u771f\u5b9e\u6a21\u62df\u9a7e\u9a76\u884c\u4e3a\uff0c\u800c\u4ea4\u901a\u8def\u53e3\u5728\u5b89\u5168\u548c\u6548\u7387\u65b9\u9762\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u6b64\u9700\u8981\u6570\u636e\u9a71\u52a8\u7684\u6a21\u62df\u5668\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u5934\u81ea\u6ce8\u610f\u529b\u8f68\u8ff9\u9884\u6d4b\u6a21\u578b\uff0c\u7ed3\u5408\u4fe1\u53f7\u4fe1\u606f\uff0c\u5e76\u901a\u8fc7\u6a21\u62df\u95ed\u73af\u7ba1\u9053\u8bc4\u4f30\u751f\u6210\u6a21\u578b\u3002", "result": "\u65b0\u6a21\u578b\u5728\u4ea4\u901a\u5de5\u7a0b\u76f8\u5173\u6307\u6807\u4e0a\u4f18\u4e8e\u4e4b\u524d\u7684\u6a21\u578b\u3002", "conclusion": "\u7814\u7a76\u4e3a\u4ea4\u901a\u8def\u53e3\u7684\u6570\u636e\u9a71\u52a8\u6a21\u62df\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\u548c\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2506.08966", "pdf": "https://arxiv.org/pdf/2506.08966", "abs": "https://arxiv.org/abs/2506.08966", "authors": ["Marek Kadl\u010d\u00edk", "Michal \u0160tef\u00e1nik", "Timothee Mickus", "Michal Spiegel", "Josef Kucha\u0159"], "title": "Pre-trained Language Models Learn Remarkably Accurate Representations of Numbers", "categories": ["cs.CL", "cs.LG", "cs.NE"], "comment": null, "summary": "Pretrained language models (LMs) are prone to arithmetic errors. Existing\nwork showed limited success in probing numeric values from models'\nrepresentations, indicating that these errors can be attributed to the inherent\nunreliability of distributionally learned embeddings in representing exact\nquantities. However, we observe that previous probing methods are inadequate\nfor the emergent structure of learned number embeddings with sinusoidal\npatterns.\n  In response, we propose a novel probing technique that decodes numeric values\nfrom input embeddings with near-perfect accuracy across a range of open-source\nLMs. This proves that after the sole pre-training, LMs represent numbers with\nremarkable precision. Finally, we find that the embeddings' preciseness judged\nby our probe's accuracy explains a large portion of LM's errors in elementary\narithmetic, and show that aligning the embeddings with the pattern discovered\nby our probe can mitigate these errors.", "AI": {"tldr": "\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff08LM\uff09\u5728\u7b97\u672f\u4efb\u52a1\u4e2d\u5bb9\u6613\u51fa\u9519\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u51c6\u786e\u63a2\u6d4b\u6570\u503c\u5d4c\u5165\u3002\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u65b0\u63a2\u6d4b\u6280\u672f\uff0c\u80fd\u9ad8\u7cbe\u5ea6\u89e3\u7801\u6570\u503c\uff0c\u8bc1\u660eLM\u5728\u9884\u8bad\u7ec3\u540e\u80fd\u7cbe\u786e\u8868\u793a\u6570\u5b57\u3002", "motivation": "\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u5728\u7b97\u672f\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u73b0\u6709\u63a2\u6d4b\u65b9\u6cd5\u672a\u80fd\u6355\u6349\u5230\u6570\u503c\u5d4c\u5165\u7684\u6b63\u5f26\u6a21\u5f0f\u7ed3\u6784\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u578b\u63a2\u6d4b\u6280\u672f\uff0c\u4ece\u8f93\u5165\u5d4c\u5165\u4e2d\u89e3\u7801\u6570\u503c\uff0c\u9a8c\u8bc1LM\u9884\u8bad\u7ec3\u540e\u5bf9\u6570\u5b57\u7684\u7cbe\u786e\u8868\u793a\u80fd\u529b\u3002", "result": "\u65b0\u63a2\u6d4b\u6280\u672f\u80fd\u8fd1\u4e4e\u5b8c\u7f8e\u5730\u89e3\u7801\u6570\u503c\uff0c\u4e14\u5d4c\u5165\u7684\u7cbe\u786e\u5ea6\u89e3\u91ca\u4e86LM\u5728\u57fa\u7840\u7b97\u672f\u4e2d\u7684\u5927\u90e8\u5206\u9519\u8bef\u3002", "conclusion": "\u901a\u8fc7\u8c03\u6574\u5d4c\u5165\u4ee5\u5339\u914d\u63a2\u6d4b\u53d1\u73b0\u7684\u6a21\u5f0f\uff0c\u53ef\u4ee5\u663e\u8457\u51cf\u5c11LM\u7684\u7b97\u672f\u9519\u8bef\u3002"}}
{"id": "2506.08990", "pdf": "https://arxiv.org/pdf/2506.08990", "abs": "https://arxiv.org/abs/2506.08990", "authors": ["Chenyu Lian", "Hong-Yu Zhou", "Dongyun Liang", "Jing Qin", "Liansheng Wang"], "title": "Efficient Medical Vision-Language Alignment Through Adapting Masked Vision Models", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "TMI 2025", "summary": "Medical vision-language alignment through cross-modal contrastive learning\nshows promising performance in image-text matching tasks, such as retrieval and\nzero-shot classification. However, conventional cross-modal contrastive\nlearning (CLIP-based) methods suffer from suboptimal visual representation\ncapabilities, which also limits their effectiveness in vision-language\nalignment. In contrast, although the models pretrained via multimodal masked\nmodeling struggle with direct cross-modal matching, they excel in visual\nrepresentation. To address this contradiction, we propose ALTA (ALign Through\nAdapting), an efficient medical vision-language alignment method that utilizes\nonly about 8% of the trainable parameters and less than 1/5 of the\ncomputational consumption required for masked record modeling. ALTA achieves\nsuperior performance in vision-language matching tasks like retrieval and\nzero-shot classification by adapting the pretrained vision model from masked\nrecord modeling. Additionally, we integrate temporal-multiview radiograph\ninputs to enhance the information consistency between radiographs and their\ncorresponding descriptions in reports, further improving the vision-language\nalignment. Experimental evaluations show that ALTA outperforms the\nbest-performing counterpart by over 4% absolute points in text-to-image\naccuracy and approximately 6% absolute points in image-to-text retrieval\naccuracy. The adaptation of vision-language models during efficient alignment\nalso promotes better vision and language understanding. Code is publicly\navailable at https://github.com/DopamineLcy/ALTA.", "AI": {"tldr": "ALTA\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u533b\u5b66\u89c6\u89c9-\u8bed\u8a00\u5bf9\u9f50\u65b9\u6cd5\uff0c\u901a\u8fc7\u9002\u5e94\u9884\u8bad\u7ec3\u7684\u89c6\u89c9\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u68c0\u7d22\u548c\u96f6\u6837\u672c\u5206\u7c7b\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u7684\u8de8\u6a21\u6001\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\u5728\u89c6\u89c9\u8868\u793a\u80fd\u529b\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u800c\u591a\u6a21\u6001\u63a9\u7801\u5efa\u6a21\u65b9\u6cd5\u867d\u5728\u89c6\u89c9\u8868\u793a\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u8de8\u6a21\u6001\u5339\u914d\u4e0a\u6548\u679c\u6709\u9650\u3002ALTA\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u77db\u76fe\u3002", "method": "ALTA\u901a\u8fc7\u9002\u5e94\u9884\u8bad\u7ec3\u7684\u89c6\u89c9\u6a21\u578b\uff08\u6765\u81ea\u63a9\u7801\u8bb0\u5f55\u5efa\u6a21\uff09\uff0c\u4ec5\u9700\u7ea68%\u7684\u53ef\u8bad\u7ec3\u53c2\u6570\u548c\u4e0d\u52301/5\u7684\u8ba1\u7b97\u6d88\u8017\uff0c\u5e76\u7ed3\u5408\u65f6\u95f4\u591a\u89c6\u56fe\u653e\u5c04\u5f71\u50cf\u8f93\u5165\u589e\u5f3a\u4fe1\u606f\u4e00\u81f4\u6027\u3002", "result": "ALTA\u5728\u6587\u672c-\u56fe\u50cf\u51c6\u786e\u7387\u548c\u56fe\u50cf-\u6587\u672c\u68c0\u7d22\u51c6\u786e\u7387\u4e0a\u5206\u522b\u6bd4\u6700\u4f73\u5bf9\u6bd4\u65b9\u6cd5\u9ad8\u51fa4%\u548c6%\u3002", "conclusion": "ALTA\u4e0d\u4ec5\u63d0\u5347\u4e86\u89c6\u89c9-\u8bed\u8a00\u5bf9\u9f50\u4efb\u52a1\u7684\u6027\u80fd\uff0c\u8fd8\u4fc3\u8fdb\u4e86\u89c6\u89c9\u548c\u8bed\u8a00\u7406\u89e3\u7684\u63d0\u5347\u3002"}}
{"id": "2506.09024", "pdf": "https://arxiv.org/pdf/2506.09024", "abs": "https://arxiv.org/abs/2506.09024", "authors": ["Felix Wagner", "Pramit Saha", "Harry Anthony", "J. Alison Noble", "Konstantinos Kamnitsas"], "title": "DIsoN: Decentralized Isolation Networks for Out-of-Distribution Detection in Medical Imaging", "categories": ["cs.CV", "cs.LG", "I.2.11; I.4.9; I.4.9; J.3; I.2.0"], "comment": null, "summary": "Safe deployment of machine learning (ML) models in safety-critical domains\nsuch as medical imaging requires detecting inputs with characteristics not seen\nduring training, known as out-of-distribution (OOD) detection, to prevent\nunreliable predictions. Effective OOD detection after deployment could benefit\nfrom access to the training data, enabling direct comparison between test\nsamples and the training data distribution to identify differences.\nState-of-the-art OOD detection methods, however, either discard training data\nafter deployment or assume that test samples and training data are centrally\nstored together, an assumption that rarely holds in real-world settings. This\nis because shipping training data with the deployed model is usually impossible\ndue to the size of training databases, as well as proprietary or privacy\nconstraints. We introduce the Isolation Network, an OOD detection framework\nthat quantifies the difficulty of separating a target test sample from the\ntraining data by solving a binary classification task. We then propose\nDecentralized Isolation Networks (DIsoN), which enables the comparison of\ntraining and test data when data-sharing is impossible, by exchanging only\nmodel parameters between the remote computational nodes of training and\ndeployment. We further extend DIsoN with class-conditioning, comparing a target\nsample solely with training data of its predicted class. We evaluate DIsoN on\nfour medical imaging datasets (dermatology, chest X-ray, breast ultrasound,\nhistopathology) across 12 OOD detection tasks. DIsoN performs favorably against\nexisting methods while respecting data-privacy. This decentralized OOD\ndetection framework opens the way for a new type of service that ML developers\ncould provide along with their models: providing remote, secure utilization of\ntheir training data for OOD detection services. Code will be available upon\nacceptance at: *****", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53bb\u4e2d\u5fc3\u5316\u7684OOD\u68c0\u6d4b\u6846\u67b6DIsoN\uff0c\u901a\u8fc7\u4ea4\u6362\u6a21\u578b\u53c2\u6570\u800c\u975e\u6570\u636e\uff0c\u89e3\u51b3\u4e86\u8bad\u7ec3\u6570\u636e\u9690\u79c1\u548c\u5b58\u50a8\u95ee\u9898\uff0c\u5e76\u5728\u533b\u5b66\u5f71\u50cf\u6570\u636e\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5728\u5b89\u5168\u5173\u952e\u9886\u57df\uff08\u5982\u533b\u5b66\u5f71\u50cf\uff09\u90e8\u7f72ML\u6a21\u578b\u65f6\uff0c\u9700\u8981\u68c0\u6d4b\u8bad\u7ec3\u6570\u636e\u4e4b\u5916\u7684\u8f93\u5165\uff08OOD\uff09\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u56e0\u6570\u636e\u9690\u79c1\u6216\u5b58\u50a8\u9650\u5236\u65e0\u6cd5\u76f4\u63a5\u6bd4\u8f83\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6570\u636e\u3002", "method": "\u63d0\u51fa\u4e86Isolation Network\u6846\u67b6\uff0c\u901a\u8fc7\u4e8c\u5143\u5206\u7c7b\u4efb\u52a1\u91cf\u5316\u6d4b\u8bd5\u6837\u672c\u4e0e\u8bad\u7ec3\u6570\u636e\u7684\u5206\u79bb\u96be\u5ea6\uff0c\u5e76\u8fdb\u4e00\u6b65\u6269\u5c55\u4e3aDIsoN\uff0c\u652f\u6301\u53bb\u4e2d\u5fc3\u5316\u6bd4\u8f83\u3002", "result": "\u5728\u56db\u4e2a\u533b\u5b66\u5f71\u50cf\u6570\u636e\u96c6\u4e0a\u768412\u4e2aOOD\u68c0\u6d4b\u4efb\u52a1\u4e2d\uff0cDIsoN\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u3002", "conclusion": "DIsoN\u4e3aML\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u670d\u52a1\u6a21\u5f0f\uff0c\u53ef\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u524d\u63d0\u4e0b\u8fdc\u7a0b\u5229\u7528\u8bad\u7ec3\u6570\u636e\u8fdb\u884cOOD\u68c0\u6d4b\u3002"}}
{"id": "2506.09027", "pdf": "https://arxiv.org/pdf/2506.09027", "abs": "https://arxiv.org/abs/2506.09027", "authors": ["Runqian Wang", "Kaiming He"], "title": "Diffuse and Disperse: Image Generation with Representation Regularization", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "The development of diffusion-based generative models over the past decade has\nlargely proceeded independently of progress in representation learning. These\ndiffusion models typically rely on regression-based objectives and generally\nlack explicit regularization. In this work, we propose \\textit{Dispersive\nLoss}, a simple plug-and-play regularizer that effectively improves\ndiffusion-based generative models. Our loss function encourages internal\nrepresentations to disperse in the hidden space, analogous to contrastive\nself-supervised learning, with the key distinction that it requires no positive\nsample pairs and therefore does not interfere with the sampling process used\nfor regression. Compared to the recent method of representation alignment\n(REPA), our approach is self-contained and minimalist, requiring no\npre-training, no additional parameters, and no external data. We evaluate\nDispersive Loss on the ImageNet dataset across a range of models and report\nconsistent improvements over widely used and strong baselines. We hope our work\nwill help bridge the gap between generative modeling and representation\nlearning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDispersive Loss\u7684\u7b80\u5355\u63d2\u4ef6\u5f0f\u6b63\u5219\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u6539\u8fdb\u6269\u6563\u751f\u6210\u6a21\u578b\uff0c\u65e0\u9700\u989d\u5916\u6570\u636e\u6216\u9884\u8bad\u7ec3\u3002", "motivation": "\u6269\u6563\u751f\u6210\u6a21\u578b\u901a\u5e38\u7f3a\u4e4f\u663e\u5f0f\u6b63\u5219\u5316\uff0c\u4e14\u4e0e\u8868\u793a\u5b66\u4e60\u7684\u8fdb\u5c55\u72ec\u7acb\u53d1\u5c55\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7Dispersive Loss\u5f25\u5408\u751f\u6210\u6a21\u578b\u4e0e\u8868\u793a\u5b66\u4e60\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u63d0\u51faDispersive Loss\uff0c\u9f13\u52b1\u9690\u7a7a\u95f4\u4e2d\u7684\u8868\u793a\u5206\u6563\uff0c\u7c7b\u4f3c\u4e8e\u5bf9\u6bd4\u81ea\u76d1\u7763\u5b66\u4e60\uff0c\u4f46\u65e0\u9700\u6b63\u6837\u672c\u5bf9\uff0c\u4e0d\u5f71\u54cd\u56de\u5f52\u91c7\u6837\u8fc7\u7a0b\u3002", "result": "\u5728ImageNet\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\uff0cDispersive Loss\u5728\u591a\u79cd\u6a21\u578b\u4e2d\u5747\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "Dispersive Loss\u662f\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u6b63\u5219\u5316\u65b9\u6cd5\uff0c\u6709\u671b\u4fc3\u8fdb\u751f\u6210\u6a21\u578b\u4e0e\u8868\u793a\u5b66\u4e60\u7684\u7ed3\u5408\u3002"}}
{"id": "2506.09033", "pdf": "https://arxiv.org/pdf/2506.09033", "abs": "https://arxiv.org/abs/2506.09033", "authors": ["Haozhen Zhang", "Tao Feng", "Jiaxuan You"], "title": "Router-R1: Teaching LLMs Multi-Round Routing and Aggregation via Reinforcement Learning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Code is available at https://github.com/ulab-uiuc/Router-R1", "summary": "The rapid emergence of diverse large language models (LLMs) has spurred the\ndevelopment of LLM routers that assign user queries to the most suitable model.\nHowever, existing LLM routers typically perform a single-round, one-to-one\nmapping (\\textit{i.e.}, assigning each query to a single model in isolation),\nwhich limits their capability to tackle complex tasks that demand the\ncomplementary strengths of multiple LLMs. In this paper, we present\n\\textbf{Router-R1}, a reinforcement learning (RL)-based framework that\nformulates multi-LLM routing and aggregation as a sequential decision process.\nRouter-R1 instantiates the router itself as a capable LLM, leveraging its\nreasoning ability to interleave \"think\" actions (internal deliberation) with\n\"route\" actions (dynamic model invocation), and integrates each response into\nits evolving context. To guide learning, we employ a lightweight rule-based\nreward comprising format rewards, final outcome rewards, and a novel cost\nreward for performance and cost trade-off optimization, opening a pathway\ntoward optimizing performance-cost tradeoffs via RL. Router-R1 also conditions\nonly on simple model descriptors such as pricing, latency, and example\nperformance, enabling strong generalization to unseen model selection.\nExperiments on seven general and multi-hop QA benchmarks show that Router-R1\noutperforms over several strong baselines, achieving superior performance while\nmaintaining robust generalization and cost management.Code is available at\nhttps://github.com/ulab-uiuc/Router-R1.", "AI": {"tldr": "Router-R1\u662f\u4e00\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8def\u7531\u548c\u805a\u5408\u591a\u4e2aLLM\u7684\u80fd\u529b\uff0c\u4f18\u5316\u590d\u6742\u4efb\u52a1\u7684\u6027\u80fd\u4e0e\u6210\u672c\u6743\u8861\u3002", "motivation": "\u73b0\u6709LLM\u8def\u7531\u5668\u901a\u5e38\u4ec5\u652f\u6301\u5355\u8f6e\u3001\u4e00\u5bf9\u4e00\u7684\u6620\u5c04\uff0c\u65e0\u6cd5\u5145\u5206\u5229\u7528\u591a\u4e2aLLM\u7684\u4e92\u8865\u4f18\u52bf\u3002", "method": "Router-R1\u5c06\u8def\u7531\u548c\u805a\u5408\u5efa\u6a21\u4e3a\u5e8f\u5217\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5229\u7528LLM\u7684\u63a8\u7406\u80fd\u529b\u52a8\u6001\u8c03\u7528\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u8f7b\u91cf\u7ea7\u89c4\u5219\u5956\u52b1\u6307\u5bfc\u5b66\u4e60\u3002", "result": "\u5728\u4e03\u4e2aQA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRouter-R1\u8868\u73b0\u4f18\u4e8e\u591a\u4e2a\u57fa\u7ebf\uff0c\u5b9e\u73b0\u4e86\u6027\u80fd\u4e0e\u6210\u672c\u7684\u4f18\u5316\u3002", "conclusion": "Router-R1\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5b9e\u73b0\u4e86\u591aLLM\u7684\u52a8\u6001\u8def\u7531\u4e0e\u805a\u5408\uff0c\u5c55\u793a\u4e86\u6027\u80fd\u4e0e\u6210\u672c\u6743\u8861\u7684\u6f5c\u529b\u3002"}}
