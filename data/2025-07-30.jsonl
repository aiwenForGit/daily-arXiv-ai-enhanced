{"id": "2507.21109", "pdf": "https://arxiv.org/pdf/2507.21109", "abs": "https://arxiv.org/abs/2507.21109", "authors": ["Prital Bamnodkar"], "title": "Task-Focused Consolidation with Spaced Recall: Making Neural Networks learn like college students", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Deep Neural Networks often suffer from a critical limitation known as\nCatastrophic Forgetting, where performance on past tasks degrades after\nlearning new ones. This paper introduces a novel continual learning approach\ninspired by human learning strategies like Active Recall, Deliberate Practice\nand Spaced Repetition, named Task Focused Consolidation with Spaced Recall\n(TFC-SR). TFC-SR enhances the standard experience replay with a mechanism we\ntermed the Active Recall Probe. It is a periodic, task-aware evaluation of the\nmodel's memory that stabilizes the representations of past knowledge. We test\nTFC-SR on the Split MNIST and Split CIFAR-100 benchmarks against leading\nregularization-based and replay-based baselines. Our results show that TFC-SR\nperforms significantly better than these methods. For instance, on the Split\nCIFAR-100, it achieves a final accuracy of 13.17% compared to standard replay's\n7.40%. We demonstrate that this advantage comes from the stabilizing effect of\nthe probe itself, and not from the difference in replay volume. Additionally,\nwe analyze the trade-off between memory size and performance and show that\nwhile TFC-SR performs better in memory-constrained environments, higher replay\nvolume is still more effective when available memory is abundant. We conclude\nthat TFC-SR is a robust and efficient approach, highlighting the importance of\nintegrating active memory retrieval mechanisms into continual learning systems."}
{"id": "2507.21119", "pdf": "https://arxiv.org/pdf/2507.21119", "abs": "https://arxiv.org/abs/2507.21119", "authors": ["Yousuf Moiz Ali", "Jaroslaw E. Prilepsky", "Nicola Sambo", "Jo√£o Pedro", "Mohammad M. Hosseini", "Antonio Napoli", "Sergei K. Turitsyn", "Pedro Freire"], "title": "Pre-, In-, and Post-Processing Class Imbalance Mitigation Techniques for Failure Detection in Optical Networks", "categories": ["cs.LG", "eess.SP", "physics.optics"], "comment": "3 pages + 1 page for acknowledgement and references", "summary": "We compare pre-, in-, and post-processing techniques for class imbalance\nmitigation in optical network failure detection. Threshold Adjustment achieves\nthe highest F1 gain (15.3%), while Random Under-sampling (RUS) offers the\nfastest inference, highlighting a key performance-complexity trade-off."}
{"id": "2507.21135", "pdf": "https://arxiv.org/pdf/2507.21135", "abs": "https://arxiv.org/abs/2507.21135", "authors": ["Alexander G. Abanov", "Luca Candelori", "Harold C. Steinacker", "Martin T. Wells", "Jerome R. Busemeyer", "Cameron J. Hogan", "Vahagn Kirakosyan", "Nicola Marzari", "Sunil Pinnamaneni", "Dario Villani", "Mengjia Xu", "Kharen Musaelian"], "title": "Quantum Geometry of Data", "categories": ["cs.LG", "quant-ph", "stat.ML"], "comment": "27 pages, 14 figures, 1 table", "summary": "We demonstrate how Quantum Cognition Machine Learning (QCML) encodes data as\nquantum geometry. In QCML, features of the data are represented by learned\nHermitian matrices, and data points are mapped to states in Hilbert space. The\nquantum geometry description endows the dataset with rich geometric and\ntopological structure - including intrinsic dimension, quantum metric, and\nBerry curvature - derived directly from the data. QCML captures global\nproperties of data, while avoiding the curse of dimensionality inherent in\nlocal methods. We illustrate this on a number of synthetic and real-world\nexamples. Quantum geometric representation of QCML could advance our\nunderstanding of cognitive phenomena within the framework of quantum cognition."}
{"id": "2507.21136", "pdf": "https://arxiv.org/pdf/2507.21136", "abs": "https://arxiv.org/abs/2507.21136", "authors": ["Mojtaba Moattari"], "title": "A Study on Variants of Conventional, Fuzzy, and Nullspace-Based Independence Criteria for Improving Supervised and Unsupervised Learning", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Unsupervised and supervised learning methods conventionally use kernels to\ncapture nonlinearities inherent in data structure. However experts have to\nensure their proposed nonlinearity maximizes variability and capture inherent\ndiversity of data. We reviewed all independence criteria to design unsupervised\nlearners. Then we proposed 3 independence criteria and used them to design\nunsupervised and supervised dimensionality reduction methods. We evaluated\ncontrast, accuracy and interpretability of these methods in both linear and\nneural nonlinear settings. The results show that the methods have outperformed\nthe baseline (tSNE, PCA, regularized LDA, VAE with (un)supervised learner and\nlayer sharing) and opened a new line of interpretable machine learning (ML) for\nthe researchers."}
{"id": "2507.21147", "pdf": "https://arxiv.org/pdf/2507.21147", "abs": "https://arxiv.org/abs/2507.21147", "authors": ["Fabrizio Lo Scudo", "Alessio De Rango", "Luca Furnari", "Alfonso Senatore", "Donato D'Ambrosio", "Giuseppe Mendicino", "Gianluigi Greco"], "title": "Advancing Wildfire Risk Prediction via Morphology-Aware Curriculum Contrastive Learning", "categories": ["cs.LG", "cs.AI"], "comment": "To appear in the Proceedings of ECAI 2025", "summary": "Wildfires significantly impact natural ecosystems and human health, leading\nto biodiversity loss, increased hydrogeological risks, and elevated emissions\nof toxic substances. Climate change exacerbates these effects, particularly in\nregions with rising temperatures and prolonged dry periods, such as the\nMediterranean. This requires the development of advanced risk management\nstrategies that utilize state-of-the-art technologies. However, in this\ncontext, the data show a bias toward an imbalanced setting, where the incidence\nof wildfire events is significantly lower than typical situations. This\nimbalance, coupled with the inherent complexity of high-dimensional\nspatio-temporal data, poses significant challenges for training deep learning\narchitectures. Moreover, since precise wildfire predictions depend mainly on\nweather data, finding a way to reduce computational costs to enable more\nfrequent updates using the latest weather forecasts would be beneficial. This\npaper investigates how adopting a contrastive framework can address these\nchallenges through enhanced latent representations for the patch's dynamic\nfeatures. We thus introduce a new morphology-based curriculum contrastive\nlearning that mitigates issues associated with diverse regional characteristics\nand enables the use of smaller patch sizes without compromising performance. An\nexperimental analysis is performed to validate the effectiveness of the\nproposed modeling strategies."}
{"id": "2507.21152", "pdf": "https://arxiv.org/pdf/2507.21152", "abs": "https://arxiv.org/abs/2507.21152", "authors": ["Hangli Ge", "Noboru Koshizuka"], "title": "Deep Unfolding for MIMO Signal Detection", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In this paper, we propose a deep unfolding neural network-based MIMO detector\nthat incorporates complex-valued computations using Wirtinger calculus. The\nmethod, referred as Dynamic Partially Shrinkage Thresholding (DPST), enables\nefficient, interpretable, and low-complexity MIMO signal detection. Unlike\nprior approaches that rely on real-valued approximations, our method operates\nnatively in the complex domain, aligning with the fundamental nature of signal\nprocessing tasks. The proposed algorithm requires only a small number of\ntrainable parameters, allowing for simplified training. Numerical results\ndemonstrate that the proposed method achieves superior detection performance\nwith fewer iterations and lower computational complexity, making it a practical\nsolution for next-generation massive MIMO systems."}
{"id": "2507.21153", "pdf": "https://arxiv.org/pdf/2507.21153", "abs": "https://arxiv.org/abs/2507.21153", "authors": ["Abderaouf Bahi", "Amel Ourici"], "title": "Deep Reinforcement Learning for Real-Time Green Energy Integration in Data Centers", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "comment": null, "summary": "This paper explores the implementation of a Deep Reinforcement Learning\n(DRL)-optimized energy management system for e-commerce data centers, aimed at\nenhancing energy efficiency, cost-effectiveness, and environmental\nsustainability. The proposed system leverages DRL algorithms to dynamically\nmanage the integration of renewable energy sources, energy storage, and grid\npower, adapting to fluctuating energy availability in real time. The study\ndemonstrates that the DRL-optimized system achieves a 38\\% reduction in energy\ncosts, significantly outperforming traditional Reinforcement Learning (RL)\nmethods (28\\%) and heuristic approaches (22\\%). Additionally, it maintains a\nlow SLA violation rate of 1.5\\%, compared to 3.0\\% for RL and 4.8\\% for\nheuristic methods. The DRL-optimized approach also results in an 82\\%\nimprovement in energy efficiency, surpassing other methods, and a 45\\%\nreduction in carbon emissions, making it the most environmentally friendly\nsolution. The system's cumulative reward of 950 reflects its superior\nperformance in balancing multiple objectives. Through rigorous testing and\nablation studies, the paper validates the effectiveness of the DRL model's\narchitecture and parameters, offering a robust solution for energy management\nin data centers. The findings highlight the potential of DRL in advancing\nenergy optimization strategies and addressing sustainability challenges."}
{"id": "2507.21155", "pdf": "https://arxiv.org/pdf/2507.21155", "abs": "https://arxiv.org/abs/2507.21155", "authors": ["Malcolm Wolff", "Matthew Li", "Ravi Kiran Selvam", "Hanjing Zhu", "Kin G. Olivares", "Ruijun Ma", "Abhinav Katoch", "Shankar Ramasubramanian", "Mengfei Cao", "Roberto Bandarra", "Rahul Gopalsamy", "Stefania La Vattiata", "Sitan Yang", "Michael M. Mahoney"], "title": "SPADE-S: A Sparsity-Robust Foundational Forecaster", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Despite significant advancements in time series forecasting, accurate\nmodeling of time series with strong heterogeneity in magnitude and/or sparsity\npatterns remains challenging for state-of-the-art deep learning architectures.\nWe identify several factors that lead existing models to systematically\nunderperform on low-magnitude and sparse time series, including loss functions\nwith implicit biases toward high-magnitude series, training-time sampling\nmethods, and limitations of time series encoding methods.\n  SPADE-S is a robust forecasting architecture that significantly reduces\nmagnitude- and sparsity-based systematic biases and improves overall prediction\naccuracy. Empirical results demonstrate that SPADE-S outperforms existing\nstate-of-the-art approaches across a diverse set of use cases in demand\nforecasting. In particular, we show that, depending on the quantile forecast\nand magnitude of the series, SPADE-S can improve forecast accuracy by up to\n15%. This results in P90 overall forecast accuracy gains of 2.21%, 6.58%, and\n4.28%, and P50 forecast accuracy gains of 0.92%, 0.77%, and 1.95%,\nrespectively, for each of three distinct datasets, ranging from 3 million to\n700 million series, from a large online retailer."}
{"id": "2507.21160", "pdf": "https://arxiv.org/pdf/2507.21160", "abs": "https://arxiv.org/abs/2507.21160", "authors": ["Lakpa Tamang", "Mohamed Reda Bouadjenek", "Richard Dazeley", "Sunil Aryal"], "title": "Handling Out-of-Distribution Data: A Survey", "categories": ["cs.LG", "cs.AI", "68T07 (Primary), 68T45, 68T10 (Secondary)", "I.5.1"], "comment": "20 pages, 6 figures, 6 tables. Accepted at IEEE Transactions on\n  Knowledge and Data Engineering", "summary": "In the field of Machine Learning (ML) and data-driven applications, one of\nthe significant challenge is the change in data distribution between the\ntraining and deployment stages, commonly known as distribution shift. This\npaper outlines different mechanisms for handling two main types of distribution\nshifts: (i) Covariate shift: where the value of features or covariates change\nbetween train and test data, and (ii) Concept/Semantic-shift: where model\nexperiences shift in the concept learned during training due to emergence of\nnovel classes in the test phase. We sum up our contributions in three folds.\nFirst, we formalize distribution shifts, recite on how the conventional method\nfails to handle them adequately and urge for a model that can simultaneously\nperform better in all types of distribution shifts. Second, we discuss why\nhandling distribution shifts is important and provide an extensive review of\nthe methods and techniques that have been developed to detect, measure, and\nmitigate the effects of these shifts. Third, we discuss the current state of\ndistribution shift handling mechanisms and propose future research directions\nin this area. Overall, we provide a retrospective synopsis of the literature in\nthe distribution shift, focusing on OOD data that had been overlooked in the\nexisting surveys."}
{"id": "2507.21164", "pdf": "https://arxiv.org/pdf/2507.21164", "abs": "https://arxiv.org/abs/2507.21164", "authors": ["Nicolas Pinon", "Carole Lartizien"], "title": "OCSVM-Guided Representation Learning for Unsupervised Anomaly Detection", "categories": ["cs.LG", "cs.AI", "eess.IV", "stat.ML"], "comment": null, "summary": "Unsupervised anomaly detection (UAD) aims to detect anomalies without labeled\ndata, a necessity in many machine learning applications where anomalous samples\nare rare or not available. Most state-of-the-art methods fall into two\ncategories: reconstruction-based approaches, which often reconstruct anomalies\ntoo well, and decoupled representation learning with density estimators, which\ncan suffer from suboptimal feature spaces. While some recent methods attempt to\ncouple feature learning and anomaly detection, they often rely on surrogate\nobjectives, restrict kernel choices, or introduce approximations that limit\ntheir expressiveness and robustness. To address this challenge, we propose a\nnovel method that tightly couples representation learning with an analytically\nsolvable one-class SVM (OCSVM), through a custom loss formulation that directly\naligns latent features with the OCSVM decision boundary. The model is evaluated\non two tasks: a new benchmark based on MNIST-C, and a challenging brain MRI\nsubtle lesion detection task. Unlike most methods that focus on large,\nhyperintense lesions at the image level, our approach succeeds to target small,\nnon-hyperintense lesions, while we evaluate voxel-wise metrics, addressing a\nmore clinically relevant scenario. Both experiments evaluate a form of\nrobustness to domain shifts, including corruption types in MNIST-C and\nscanner/age variations in MRI. Results demonstrate performance and robustness\nof our proposed mode,highlighting its potential for general UAD and real-world\nmedical imaging applications. The source code is available at\nhttps://github.com/Nicolas-Pinon/uad_ocsvm_guided_repr_learning"}
{"id": "2507.21166", "pdf": "https://arxiv.org/pdf/2507.21166", "abs": "https://arxiv.org/abs/2507.21166", "authors": ["Ren Zhuang", "Ben Wang", "Shuifa Sun"], "title": "AGORA: Incentivizing Group Emergence Capability in LLMs via Group Distillation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Progress in complex reasoning is constrained by the static nature of the\ncurrent training datasets. We propose structured interaction as a new scaling\naxis, moving beyond the prevailing paradigm of increasing model parameters. Our\nself-evolving framework, AGORA, enables a collaborative ensemble to achieve\nreasoning performance exceeding state-of-the-art monolithic systems by up to\n4.45 percentage points on challenging mathematical benchmarks. This gain stems\nfrom group emergent ability-the synthesis of collective capabilities\nunattainable by isolated models, validating interaction as a scalable driver of\nintelligence. Our results position the engineering of collaborative ecosystems\nas a vital frontier for capability emergence."}
{"id": "2507.21179", "pdf": "https://arxiv.org/pdf/2507.21179", "abs": "https://arxiv.org/abs/2507.21179", "authors": ["Yuqi Jin", "Zihan Hu", "Weiteng Zhang", "Weihao Xie", "Jianwei Shuai", "Xian Shen", "Zhen Feng"], "title": "LLM-Adapted Interpretation Framework for Machine Learning Models", "categories": ["cs.LG", "cs.AI"], "comment": "11 pages, 8 figures, 2 tables", "summary": "Background & Aims: High-performance machine learning models like XGBoost are\noften \"black boxes,\" limiting their clinical adoption due to a lack of\ninterpretability. This study aims to bridge the gap between predictive accuracy\nand narrative transparency for sarcopenia risk assessment. Methods: We propose\nthe LLM-Adapted Interpretation Framework (LAI-ML), a novel knowledge\ndistillation architecture. LAI-ML transforms feature attributions from a\ntrained XGBoost model into a probabilistic format using specialized techniques\n(HAGA and CACS). A Large Language Model (LLM), guided by a reinforcement\nlearning loop and case-based retrieval, then generates data-faithful diagnostic\nnarratives. Results: The LAI-ML framework achieved 83% prediction accuracy,\nsignificantly outperforming the baseline XGBoost model, 13% higher. Notably,\nthe LLM not only replicated the teacher model's logic but also corrected its\npredictions in 21.7% of discordant cases, demonstrating enhanced reasoning.\nConclusion: LAI-ML effectively translates opaque model predictions into\ntrustworthy and interpretable clinical insights, offering a deployable solution\nto the \"black-box\" problem in medical AI."}
{"id": "2507.21183", "pdf": "https://arxiv.org/pdf/2507.21183", "abs": "https://arxiv.org/abs/2507.21183", "authors": ["Guangchen Lan", "Sipeng Zhang", "Tianle Wang", "Yuwei Zhang", "Daoan Zhang", "Xinpeng Wei", "Xiaoman Pan", "Hongming Zhang", "Dong-Jun Han", "Christopher G. Brinton"], "title": "MaPPO: Maximum a Posteriori Preference Optimization with Prior Knowledge", "categories": ["cs.LG", "cs.AI", "cs.CL", "I.2.6; I.2.7"], "comment": null, "summary": "As the era of large language models (LLMs) on behalf of users unfolds,\nPreference Optimization (PO) methods have become a central approach to aligning\nLLMs with human preferences and improving performance. We propose Maximum a\nPosteriori Preference Optimization (MaPPO), a framework for learning from\npreferences that explicitly incorporates prior reward knowledge into the\noptimization objective. While existing methods such as Direct Preference\nOptimization (DPO) and its variants treat preference learning as a Maximum\nLikelihood Estimation (MLE) problem, MaPPO extends this paradigm by integrating\nprior reward estimates into a principled Maximum a Posteriori (MaP) objective.\nThis not only generalizes DPO and its variants, but also enhances alignment by\nmitigating the oversimplified binary classification of responses. More\nimportantly, MaPPO introduces no additional hyperparameter, and supports\npreference optimization in both offline and online settings. In addition, MaPPO\ncan be used as a plugin with consistent improvement on DPO variants, including\nwidely used SimPO, IPO, and CPO. Extensive empirical evaluations of different\nmodel sizes and model series on three standard benchmarks, including MT-Bench,\nAlpacaEval 2.0, and Arena-Hard, demonstrate consistent improvements in\nalignment performance without sacrificing computational efficiency."}
{"id": "2507.21184", "pdf": "https://arxiv.org/pdf/2507.21184", "abs": "https://arxiv.org/abs/2507.21184", "authors": ["Haowei Lin", "Xiangyu Wang", "Jianzhu Ma", "Yitao Liang"], "title": "EvoSLD: Automated Neural Scaling Law Discovery With Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Scaling laws are fundamental mathematical relationships that predict how\nneural network performance evolves with changes in variables such as model\nsize, dataset size, and computational resources. Traditionally, discovering\nthese laws requires extensive human expertise and manual experimentation. We\nintroduce EvoSLD, an automated framework for Scaling Law Discovery (SLD) that\nleverages evolutionary algorithms guided by Large Language Models (LLMs) to\nco-evolve symbolic expressions and their optimization routines. Formulated to\nhandle scaling variables, control variables, and response metrics across\ndiverse experimental settings, EvoSLD searches for parsimonious, universal\nfunctional forms that minimize fitting errors on grouped data subsets.\nEvaluated on five real-world scenarios from recent literature, EvoSLD\nrediscovers exact human-derived laws in two cases and surpasses them in others,\nachieving up to orders-of-magnitude reductions in normalized mean squared error\non held-out test sets. Compared to baselines like symbolic regression and\nablated variants, EvoSLD demonstrates superior accuracy, interpretability, and\nefficiency, highlighting its potential to accelerate AI research. Code is\navailable at https://github.com/linhaowei1/SLD."}
{"id": "2507.21188", "pdf": "https://arxiv.org/pdf/2507.21188", "abs": "https://arxiv.org/abs/2507.21188", "authors": ["Raj Krishnan Vijayaraj"], "title": "Embeddings to Diagnosis: Latent Fragility under Agentic Perturbations in Clinical LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "LLMs for clinical decision support often fail under small but clinically\nmeaningful input shifts such as masking a symptom or negating a finding,\ndespite high performance on static benchmarks. These reasoning failures\nfrequently go undetected by standard NLP metrics, which are insensitive to\nlatent representation shifts that drive diagnosis instability. We propose a\ngeometry-aware evaluation framework, LAPD (Latent Agentic Perturbation\nDiagnostics), which systematically probes the latent robustness of clinical\nLLMs under structured adversarial edits. Within this framework, we introduce\nLatent Diagnosis Flip Rate (LDFR), a model-agnostic diagnostic signal that\ncaptures representational instability when embeddings cross decision boundaries\nin PCA-reduced latent space. Clinical notes are generated using a structured\nprompting pipeline grounded in diagnostic reasoning, then perturbed along four\naxes: masking, negation, synonym replacement, and numeric variation to simulate\ncommon ambiguities and omissions. We compute LDFR across both foundation and\nclinical LLMs, finding that latent fragility emerges even under minimal\nsurface-level changes. Finally, we validate our findings on 90 real clinical\nnotes from the DiReCT benchmark (MIMIC-IV), confirming the generalizability of\nLDFR beyond synthetic settings. Our results reveal a persistent gap between\nsurface robustness and semantic stability, underscoring the importance of\ngeometry-aware auditing in safety-critical clinical AI."}
{"id": "2507.21189", "pdf": "https://arxiv.org/pdf/2507.21189", "abs": "https://arxiv.org/abs/2507.21189", "authors": ["Andrew Kiruluta", "Andreas Lemos", "Priscilla Burity"], "title": "Operator-Based Machine Intelligence: A Hilbert Space Framework for Spectral Learning and Symbolic Reasoning", "categories": ["cs.LG"], "comment": null, "summary": "Traditional machine learning models, particularly neural networks, are rooted\nin finite-dimensional parameter spaces and nonlinear function approximations.\nThis report explores an alternative formulation where learning tasks are\nexpressed as sampling and computation in infinite dimensional Hilbert spaces,\nleveraging tools from functional analysis, signal processing, and spectral\ntheory. We review foundational concepts such as Reproducing Kernel Hilbert\nSpaces (RKHS), spectral operator learning, and wavelet-domain representations.\nWe present a rigorous mathematical formulation of learning in Hilbert spaces,\nhighlight recent models based on scattering transforms and Koopman operators,\nand discuss advantages and limitations relative to conventional neural\narchitectures. The report concludes by outlining directions for scalable and\ninterpretable machine learning grounded in Hilbertian signal processing."}
{"id": "2507.21190", "pdf": "https://arxiv.org/pdf/2507.21190", "abs": "https://arxiv.org/abs/2507.21190", "authors": ["Andrew Kiruluta", "Andreas Lemos", "Priscilla Burity"], "title": "Beyond Neural Networks: Symbolic Reasoning over Wavelet Logic Graph Signals", "categories": ["cs.LG"], "comment": null, "summary": "We present a fully non neural learning framework based on Graph Laplacian\nWavelet Transforms (GLWT). Unlike traditional architectures that rely on\nconvolutional, recurrent, or attention based neural networks, our model\noperates purely in the graph spectral domain using structured multiscale\nfiltering, nonlinear shrinkage, and symbolic logic over wavelet coefficients.\nSignals defined on graph nodes are decomposed via GLWT, modulated with\ninterpretable nonlinearities, and recombined for downstream tasks such as\ndenoising and token classification. The system supports compositional reasoning\nthrough a symbolic domain-specific language (DSL) over graph wavelet\nactivations. Experiments on synthetic graph denoising and linguistic token\ngraphs demonstrate competitive performance against lightweight GNNs with far\ngreater transparency and efficiency. This work proposes a principled,\ninterpretable, and resource-efficient alternative to deep neural architectures\nfor learning on graphs."}
{"id": "2507.21191", "pdf": "https://arxiv.org/pdf/2507.21191", "abs": "https://arxiv.org/abs/2507.21191", "authors": ["Garv Kaushik"], "title": "Exploring Adaptive Structure Learning for Heterophilic Graphs", "categories": ["cs.LG"], "comment": "Initially submitted this draft at Tiny ICLR 2025", "summary": "Graph Convolutional Networks (GCNs) gained traction for graph representation\nlearning, with recent attention on improving performance on heterophilic graphs\nfor various real-world applications. The localized feature aggregation in a\ntypical message-passing paradigm hinders the capturing of long-range\ndependencies between non-local nodes of the same class. The inherent\nconnectivity structure in heterophilic graphs often conflicts with information\nsharing between distant nodes of same class. We propose structure learning to\nrewire edges in shallow GCNs itself to avoid performance degradation in\ndownstream discriminative tasks due to oversmoothing. Parameterizing the\nadjacency matrix to learn connections between non-local nodes and extend the\nhop span of shallow GCNs facilitates the capturing of long-range dependencies.\nHowever, our method is not generalizable across heterophilic graphs and\nperforms inconsistently on node classification task contingent to the graph\nstructure."}
{"id": "2507.21196", "pdf": "https://arxiv.org/pdf/2507.21196", "abs": "https://arxiv.org/abs/2507.21196", "authors": ["Abir Ray"], "title": "EdgeAgentX-DT: Integrating Digital Twins and Generative AI for Resilient Edge Intelligence in Tactical Networks", "categories": ["cs.LG", "cs.AI"], "comment": "13 pages, 6 figures", "summary": "We introduce EdgeAgentX-DT, an advanced extension of the EdgeAgentX framework\nthat integrates digital twin simulations and generative AI-driven scenario\ntraining to significantly enhance edge intelligence in military networks.\nEdgeAgentX-DT utilizes network digital twins, virtual replicas synchronized\nwith real-world edge devices, to provide a secure, realistic environment for\ntraining and validation. Leveraging generative AI methods, such as diffusion\nmodels and transformers, the system creates diverse and adversarial scenarios\nfor robust simulation-based agent training. Our multi-layer architecture\nincludes: (1) on-device edge intelligence; (2) digital twin synchronization;\nand (3) generative scenario training. Experimental simulations demonstrate\nnotable improvements over EdgeAgentX, including faster learning convergence,\nhigher network throughput, reduced latency, and improved resilience against\njamming and node failures. A case study involving a complex tactical scenario\nwith simultaneous jamming attacks, agent failures, and increased network loads\nillustrates how EdgeAgentX-DT sustains operational performance, whereas\nbaseline methods fail. These results highlight the potential of\ndigital-twin-enabled generative training to strengthen edge AI deployments in\ncontested environments."}
{"id": "2507.21197", "pdf": "https://arxiv.org/pdf/2507.21197", "abs": "https://arxiv.org/abs/2507.21197", "authors": ["Ling Liao", "Eva Aagaard"], "title": "AdaptHetero: Machine Learning Interpretation-Driven Subgroup Adaptation for EHR-Based Clinical Prediction", "categories": ["cs.LG", "stat.ML"], "comment": "11 pages, 3 figures", "summary": "Machine learning interpretation has primarily been leveraged to build\nclinician trust and uncover actionable insights in EHRs. However, the intrinsic\ncomplexity and heterogeneity of EHR data limit its effectiveness in guiding\nsubgroup-specific modeling. We propose AdaptHetero, a novel MLI-driven\nframework that transforms interpretability insights into actionable guidance\nfor tailoring model training and evaluation across subpopulations within\nindividual hospital systems. Evaluated on three large-scale EHR datasets -\nGOSSIS-1-eICU, WiDS, and MIMIC-IV - AdaptHetero consistently identifies\nheterogeneous model behaviors in predicting ICU mortality, in-hospital death,\nand hidden hypoxemia. By integrating SHAP-based interpretation and unsupervised\nclustering, the framework enhances the identification of clinically meaningful\nsubgroup-specific characteristics, leading to improved predictive performance."}
{"id": "2507.21198", "pdf": "https://arxiv.org/pdf/2507.21198", "abs": "https://arxiv.org/abs/2507.21198", "authors": ["Xinguo Feng", "Zhongkui Ma", "Zihan Wang", "Eu Joe Chegne", "Mengyao Ma", "Alsharif Abuadbba", "Guangdong Bai"], "title": "Uncovering Gradient Inversion Risks in Practical Language Model Training", "categories": ["cs.LG", "cs.AI"], "comment": "15 Pages, 5 figures, 10 tables. Accepted by ACM CCS 2024", "summary": "The gradient inversion attack has been demonstrated as a significant privacy\nthreat to federated learning (FL), particularly in continuous domains such as\nvision models. In contrast, it is often considered less effective or highly\ndependent on impractical training settings when applied to language models, due\nto the challenges posed by the discrete nature of tokens in text data. As a\nresult, its potential privacy threats remain largely underestimated, despite FL\nbeing an emerging training method for language models. In this work, we propose\na domain-specific gradient inversion attack named Grab (gradient inversion with\nhybrid optimization). Grab features two alternating optimization processes to\naddress the challenges caused by practical training settings, including a\nsimultaneous optimization on dropout masks between layers for improved token\nrecovery and a discrete optimization for effective token sequencing. Grab can\nrecover a significant portion (up to 92.9% recovery rate) of the private\ntraining data, outperforming the attack strategy of utilizing discrete\noptimization with an auxiliary model by notable improvements of up to 28.9%\nrecovery rate in benchmark settings and 48.5% recovery rate in practical\nsettings. Grab provides a valuable step forward in understanding this privacy\nthreat in the emerging FL training mode of language models."}
{"id": "2507.21199", "pdf": "https://arxiv.org/pdf/2507.21199", "abs": "https://arxiv.org/abs/2507.21199", "authors": ["Xinye Cao", "Hongcan Guo", "Guoshun Nan", "Jiaoyang Cui", "Haoting Qian", "Yihan Lin", "Yilin Peng", "Diyang Zhang", "Yanzhao Hou", "Huici Wu", "Xiaofeng Tao", "Tony Q. S. Quek"], "title": "Advancing Compositional LLM Reasoning with Structured Task Relations in Interactive Multimodal Communications", "categories": ["cs.LG", "cs.AI", "cs.DC", "cs.HC"], "comment": "Accepted by IEEE JSAC. This work has been submitted to the IEEE for\n  possible publication", "summary": "Interactive multimodal applications (IMAs), such as route planning in the\nInternet of Vehicles, enrich users' personalized experiences by integrating\nvarious forms of data over wireless networks. Recent advances in large language\nmodels (LLMs) utilize mixture-of-experts (MoE) mechanisms to empower multiple\nIMAs, with each LLM trained individually for a specific task that presents\ndifferent business workflows. In contrast to existing approaches that rely on\nmultiple LLMs for IMAs, this paper presents a novel paradigm that accomplishes\nvarious IMAs using a single compositional LLM over wireless networks. The two\nprimary challenges include 1) guiding a single LLM to adapt to diverse IMA\nobjectives and 2) ensuring the flexibility and efficiency of the LLM in\nresource-constrained mobile environments. To tackle the first challenge, we\npropose ContextLoRA, a novel method that guides an LLM to learn the rich\nstructured context among IMAs by constructing a task dependency graph. We\npartition the learnable parameter matrix of neural layers for each IMA to\nfacilitate LLM composition. Then, we develop a step-by-step fine-tuning\nprocedure guided by task relations, including training, freezing, and masking\nphases. This allows the LLM to learn to reason among tasks for better\nadaptation, capturing the latent dependencies between tasks. For the second\nchallenge, we introduce ContextGear, a scheduling strategy to optimize the\ntraining procedure of ContextLoRA, aiming to minimize computational and\ncommunication costs through a strategic grouping mechanism. Experiments on\nthree benchmarks show the superiority of the proposed ContextLoRA and\nContextGear. Furthermore, we prototype our proposed paradigm on a real-world\nwireless testbed, demonstrating its practical applicability for various IMAs.\nWe will release our code to the community."}
{"id": "2507.21205", "pdf": "https://arxiv.org/pdf/2507.21205", "abs": "https://arxiv.org/abs/2507.21205", "authors": ["Harsh Rangwani"], "title": "Learning from Limited and Imperfect Data", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "PhD Thesis", "summary": "The distribution of data in the world (eg, internet, etc.) significantly\ndiffers from the well-curated datasets and is often over-populated with samples\nfrom common categories. The algorithms designed for well-curated datasets\nperform suboptimally when used for learning from imperfect datasets with\nlong-tailed imbalances and distribution shifts. To expand the use of deep\nmodels, it is essential to overcome the labor-intensive curation process by\ndeveloping robust algorithms that can learn from diverse, real-world data\ndistributions. Toward this goal, we develop practical algorithms for Deep\nNeural Networks which can learn from limited and imperfect data present in the\nreal world. This thesis is divided into four segments, each covering a scenario\nof learning from limited or imperfect data. The first part of the thesis\nfocuses on Learning Generative Models from Long-Tail Data, where we mitigate\nthe mode-collapse and enable diverse aesthetic image generations for tail\n(minority) classes. In the second part, we enable effective generalization on\ntail classes through Inductive Regularization schemes, which allow tail classes\nto generalize as effectively as the head classes without requiring explicit\ngeneration of images. In the third part, we develop algorithms for Optimizing\nRelevant Metrics for learning from long-tailed data with limited annotation\n(semi-supervised), followed by the fourth part, which focuses on the Efficient\nDomain Adaptation of the model to various domains with very few to zero labeled\nsamples."}
{"id": "2507.21244", "pdf": "https://arxiv.org/pdf/2507.21244", "abs": "https://arxiv.org/abs/2507.21244", "authors": ["Sheikh Md Shakeel Hassan", "Xianwei Zou", "Akash Dhruv", "Vishwanath Ganesan", "Aparna Chandramowlishwaran"], "title": "Bubbleformer: Forecasting Boiling with Transformers", "categories": ["cs.LG", "cs.AI", "cs.CE"], "comment": "39 pages, 13 figures, Submitted to NeurIPS 2025", "summary": "Modeling boiling (an inherently chaotic, multiphase process central to energy\nand thermal systems) remains a significant challenge for neural PDE surrogates.\nExisting models require future input (e.g., bubble positions) during inference\nbecause they fail to learn nucleation from past states, limiting their ability\nto autonomously forecast boiling dynamics. They also fail to model flow boiling\nvelocity fields, where sharp interface-momentum coupling demands long-range and\ndirectional inductive biases. We introduce Bubbleformer, a transformer-based\nspatiotemporal model that forecasts stable and long-range boiling dynamics\nincluding nucleation, interface evolution, and heat transfer without dependence\non simulation data during inference. Bubbleformer integrates factorized axial\nattention, frequency-aware scaling, and conditions on thermophysical parameters\nto generalize across fluids, geometries, and operating conditions. To evaluate\nphysical fidelity in chaotic systems, we propose interpretable physics-based\nmetrics that evaluate heat-flux consistency, interface geometry, and mass\nconservation. We also release BubbleML 2.0, a high-fidelity dataset that spans\ndiverse working fluids (cryogens, refrigerants, dielectrics), boiling\nconfigurations (pool and flow boiling), flow regimes (bubbly, slug, annular),\nand boundary conditions. Bubbleformer sets new benchmark results in both\nprediction and forecasting of two-phase boiling flows."}
{"id": "2507.21260", "pdf": "https://arxiv.org/pdf/2507.21260", "abs": "https://arxiv.org/abs/2507.21260", "authors": ["Amartya Banerjee", "Xingyu Xu", "Caroline Moosm√ºller", "Harlin Lee"], "title": "Adaptive Multimodal Protein Plug-and-Play with Diffusion-Based Priors", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "comment": "Code: https://github.com/amartya21/Adam-PnP", "summary": "In an inverse problem, the goal is to recover an unknown parameter (e.g., an\nimage) that has typically undergone some lossy or noisy transformation during\nmeasurement. Recently, deep generative models, particularly diffusion models,\nhave emerged as powerful priors for protein structure generation. However,\nintegrating noisy experimental data from multiple sources to guide these models\nremains a significant challenge. Existing methods often require precise\nknowledge of experimental noise levels and manually tuned weights for each data\nmodality. In this work, we introduce Adam-PnP, a Plug-and-Play framework that\nguides a pre-trained protein diffusion model using gradients from multiple,\nheterogeneous experimental sources. Our framework features an adaptive noise\nestimation scheme and a dynamic modality weighting mechanism integrated into\nthe diffusion process, which reduce the need for manual hyperparameter tuning.\nExperiments on complex reconstruction tasks demonstrate significantly improved\naccuracy using Adam-PnP."}
{"id": "2507.21273", "pdf": "https://arxiv.org/pdf/2507.21273", "abs": "https://arxiv.org/abs/2507.21273", "authors": ["Johannes Exenberger", "Sascha Ranftl", "Robert Peharz"], "title": "Deep Polynomial Chaos Expansion", "categories": ["cs.LG"], "comment": "8th Workshop on Tractable Probabilistic Modeling, UAI 2025", "summary": "Polynomial chaos expansion (PCE) is a classical and widely used surrogate\nmodeling technique in physical simulation and uncertainty quantification. By\ntaking a linear combination of a set of basis polynomials - orthonormal with\nrespect to the distribution of uncertain input parameters - PCE enables\ntractable inference of key statistical quantities, such as (conditional) means,\nvariances, covariances, and Sobol sensitivity indices, which are essential for\nunderstanding the modeled system and identifying influential parameters and\ntheir interactions. As the number of basis functions grows exponentially with\nthe number of parameters, PCE does not scale well to high-dimensional problems.\nWe address this challenge by combining PCE with ideas from probabilistic\ncircuits, resulting in the deep polynomial chaos expansion (DeepPCE) - a deep\ngeneralization of PCE that scales effectively to high-dimensional input spaces.\nDeepPCE achieves predictive performance comparable to that of multi-layer\nperceptrons (MLPs), while retaining PCE's ability to compute exact statistical\ninferences via simple forward passes."}
{"id": "2507.21274", "pdf": "https://arxiv.org/pdf/2507.21274", "abs": "https://arxiv.org/abs/2507.21274", "authors": ["Jiin Woo", "Alireza Bagheri Garakani", "Tianchen Zhou", "Zhishen Huang", "Yan Gao"], "title": "Large Language Model-Enhanced Reinforcement Learning for Diverse and Novel Recommendations", "categories": ["cs.LG"], "comment": null, "summary": "In recommendation systems, diversity and novelty are essential for capturing\nvaried user preferences and encouraging exploration, yet many systems\nprioritize click relevance. While reinforcement learning (RL) has been explored\nto improve diversity, it often depends on random exploration that may not align\nwith user interests. We propose LAAC (LLM-guided Adversarial Actor Critic), a\nnovel method that leverages large language models (LLMs) as reference policies\nto suggest novel items, while training a lightweight policy to refine these\nsuggestions using system-specific data. The method formulates training as a\nbilevel optimization between actor and critic networks, enabling the critic to\nselectively favor promising novel actions and the actor to improve its policy\nbeyond LLM recommendations. To mitigate overestimation of unreliable LLM\nsuggestions, we apply regularization that anchors critic values for unexplored\nitems close to well-estimated dataset actions. Experiments on real-world\ndatasets show that LAAC outperforms existing baselines in diversity, novelty,\nand accuracy, while remaining robust on imbalanced data, effectively\nintegrating LLM knowledge without expensive fine-tuning."}
{"id": "2507.21299", "pdf": "https://arxiv.org/pdf/2507.21299", "abs": "https://arxiv.org/abs/2507.21299", "authors": ["Alex Guo", "Michael D. Graham"], "title": "Blending data and physics for reduced-order modeling of systems with spatiotemporal chaotic dynamics", "categories": ["cs.LG"], "comment": null, "summary": "While data-driven techniques are powerful tools for reduced-order modeling of\nsystems with chaotic dynamics, great potential remains for leveraging known\nphysics (i.e. a full-order model (FOM)) to improve predictive capability. We\ndevelop a hybrid reduced order model (ROM), informed by both data and FOM, for\nevolving spatiotemporal chaotic dynamics on an invariant manifold whose\ncoordinates are found using an autoencoder. This approach projects the vector\nfield of the FOM onto the invariant manifold; then, this physics-derived vector\nfield is either corrected using dynamic data, or used as a Bayesian prior that\nis updated with data. In both cases, the neural ordinary differential equation\napproach is used. We consider simulated data from the Kuramoto-Sivashinsky and\ncomplex Ginzburg-Landau equations. Relative to the data-only approach, for\nscenarios of abundant data, scarce data, and even an incorrect FOM (i.e.\nerroneous parameter values), the hybrid approach yields substantially improved\ntime-series predictions."}
{"id": "2507.21350", "pdf": "https://arxiv.org/pdf/2507.21350", "abs": "https://arxiv.org/abs/2507.21350", "authors": ["Wenkai Tan", "Alvaro Velasquez", "Houbing Song"], "title": "DEM-NeRF: A Neuro-Symbolic Method for Scientific Discovery through Physics-Informed Simulation", "categories": ["cs.LG"], "comment": null, "summary": "Neural networks have emerged as a powerful tool for modeling physical\nsystems, offering the ability to learn complex representations from limited\ndata while integrating foundational scientific knowledge. In particular,\nneuro-symbolic approaches that combine data-driven learning, the neuro, with\nsymbolic equations and rules, the symbolic, address the tension between methods\nthat are purely empirical, which risk straying from established physical\nprinciples, and traditional numerical solvers that demand complete geometric\nknowledge and can be prohibitively expensive for high-fidelity simulations. In\nthis work, we present a novel neuro-symbolic framework for reconstructing and\nsimulating elastic objects directly from sparse multi-view image sequences,\nwithout requiring explicit geometric information. Specifically, we integrate a\nneural radiance field (NeRF) for object reconstruction with physics-informed\nneural networks (PINN) that incorporate the governing partial differential\nequations of elasticity. In doing so, our method learns a spatiotemporal\nrepresentation of deforming objects that leverages both image supervision and\nsymbolic physical constraints. To handle complex boundary and initial\nconditions, which are traditionally confronted using finite element methods,\nboundary element methods, or sensor-based measurements, we employ an\nenergy-constrained Physics-Informed Neural Network architecture. This design\nenhances both simulation accuracy and the explainability of results."}
{"id": "2507.21357", "pdf": "https://arxiv.org/pdf/2507.21357", "abs": "https://arxiv.org/abs/2507.21357", "authors": ["Yaoyu Zhang", "Chi-Guhn Lee"], "title": "A Contrastive Diffusion-based Network (CDNet) for Time Series Classification", "categories": ["cs.LG", "62M10", "I.5.1"], "comment": "19 pages, conference", "summary": "Deep learning models are widely used for time series classification (TSC) due\nto their scalability and efficiency. However, their performance degrades under\nchallenging data conditions such as class similarity, multimodal distributions,\nand noise. To address these limitations, we propose CDNet, a Contrastive\nDiffusion-based Network that enhances existing classifiers by generating\ninformative positive and negative samples via a learned diffusion process.\nUnlike traditional diffusion models that denoise individual samples, CDNet\nlearns transitions between samples--both within and across classes--through\nconvolutional approximations of reverse diffusion steps. We introduce a\ntheoretically grounded CNN-based mechanism to enable both denoising and mode\ncoverage, and incorporate an uncertainty-weighted composite loss for robust\ntraining. Extensive experiments on the UCR Archive and simulated datasets\ndemonstrate that CDNet significantly improves state-of-the-art (SOTA) deep\nlearning classifiers, particularly under noisy, similar, and multimodal\nconditions."}
{"id": "2507.21386", "pdf": "https://arxiv.org/pdf/2507.21386", "abs": "https://arxiv.org/abs/2507.21386", "authors": ["Xuan Wu", "Di Wang", "Chunguo Wu", "Kaifang Qi", "Chunyan Miao", "Yubin Xiao", "Jian Zhang", "You Zhou"], "title": "Efficient Neural Combinatorial Optimization Solver for the Min-max Heterogeneous Capacitated Vehicle Routing Problem", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Numerous Neural Combinatorial Optimization (NCO) solvers have been proposed\nto address Vehicle Routing Problems (VRPs). However, most of these solvers\nfocus exclusively on single-vehicle VRP variants, overlooking the more\nrealistic min-max Heterogeneous Capacitated Vehicle Routing Problem (MMHCVRP),\nwhich involves multiple vehicles. Existing MMHCVRP solvers typically select a\nvehicle and its next node to visit at each decoding step, but often make myopic\ndecoding decisions and overlook key properties of MMHCVRP, including local\ntopological relationships, vehicle permutation invariance, and node symmetry,\nresulting in suboptimal performance. To better address these limitations, we\npropose ECHO, an efficient NCO solver. First, ECHO exploits the proposed\ndual-modality node encoder to capture local topological relationships among\nnodes. Subsequently, to mitigate myopic decisions, ECHO employs the proposed\nParameter-Free Cross-Attention mechanism to prioritize the vehicle selected in\nthe preceding decoding step. Finally, leveraging vehicle permutation invariance\nand node symmetry, we introduce a tailored data augment strategy for MMHCVRP to\nstabilize the Reinforcement Learning training process. To assess the\nperformance of ECHO, we conduct extensive experiments. The experimental results\ndemonstrate that ECHO outperforms state-of-the-art NCO solvers across varying\nnumbers of vehicles and nodes, and exhibits well-performing generalization\nacross both scales and distribution patterns. Finally, ablation studies\nvalidate the effectiveness of all proposed methods."}
{"id": "2507.21394", "pdf": "https://arxiv.org/pdf/2507.21394", "abs": "https://arxiv.org/abs/2507.21394", "authors": ["Shiva Raja", "Cansu Demirkiran", "Aakash Sarkar", "Milos Popovic", "Ajay Joshi"], "title": "Systolic Array-based Accelerator for State-Space Models", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "Sequence modeling is crucial for AI to understand temporal data and detect\ncomplex time-dependent patterns. While recurrent neural networks (RNNs),\nconvolutional neural networks (CNNs), and Transformers have advanced in\ncapturing long-range dependencies, they struggle with achieving high accuracy\nwith very long sequences due to limited memory retention (fixed context\nwindow). State-Space Models (SSMs) leverage exponentially decaying memory\nenabling lengthy context window and so they process very long data sequences\nmore efficiently than recurrent and Transformer-based models. Unlike\ntraditional neural models like CNNs and RNNs, SSM-based models require solving\ndifferential equations through continuous integration, making training and\ninference both compute- and memory-intensive on conventional CPUs and GPUs. In\nthis paper we introduce a specialized hardware accelerator, EpochCore, for\naccelerating SSMs. EpochCore is based on systolic arrays (SAs) and is designed\nto enhance the energy efficiency and throughput of inference of SSM-based\nmodels for long-range sequence tasks. Within the SA, we propose a versatile\nprocessing element (PE) called LIMA-PE to perform traditional and specialized\nMAC operations to support traditional DNNs and SSMs. To complement the\nEpochCore microarchitecture, we propose a novel dataflow, ProDF, which enables\nhighly efficient execution of SSM-based models. By leveraging the LIMA-PE\nmicroarchitecture and ProDF, EpochCore achieves on average 250x gains in\nperformance and 45x improvement in energy efficiency, at the expense of 2x\nincrease in area cost over traditional SA-based accelerators, and around\n~2,000x improvement in latency/inference on LRA datasets compared to GPU kernel\noperations."}
{"id": "2507.21397", "pdf": "https://arxiv.org/pdf/2507.21397", "abs": "https://arxiv.org/abs/2507.21397", "authors": ["Fnu Hairi", "Jiao Yang", "Tianchen Zhou", "Haibo Yang", "Chaosheng Dong", "Fan Yang", "Michinari Momma", "Yan Gao", "Jia Liu"], "title": "Enabling Pareto-Stationarity Exploration in Multi-Objective Reinforcement Learning: A Multi-Objective Weighted-Chebyshev Actor-Critic Approach", "categories": ["cs.LG"], "comment": null, "summary": "In many multi-objective reinforcement learning (MORL) applications, being\nable to systematically explore the Pareto-stationary solutions under multiple\nnon-convex reward objectives with theoretical finite-time sample complexity\nguarantee is an important and yet under-explored problem. This motivates us to\ntake the first step and fill the important gap in MORL. Specifically, in this\npaper, we propose a \\uline{M}ulti-\\uline{O}bjective weighted-\\uline{CH}ebyshev\n\\uline{A}ctor-critic (MOCHA) algorithm for MORL, which judiciously integrates\nthe weighted-Chebychev (WC) and actor-critic framework to enable\nPareto-stationarity exploration systematically with finite-time sample\ncomplexity guarantee. Sample complexity result of MOCHA algorithm reveals an\ninteresting dependency on $p_{\\min}$ in finding an $\\epsilon$-Pareto-stationary\nsolution, where $p_{\\min}$ denotes the minimum entry of a given weight vector\n$\\mathbf{p}$ in WC-scarlarization. By carefully choosing learning rates, the\nsample complexity for each exploration can be\n$\\tilde{\\mathcal{O}}(\\epsilon^{-2})$. Furthermore, simulation studies on a\nlarge KuaiRand offline dataset, show that the performance of MOCHA algorithm\nsignificantly outperforms other baseline MORL approaches."}
{"id": "2507.21404", "pdf": "https://arxiv.org/pdf/2507.21404", "abs": "https://arxiv.org/abs/2507.21404", "authors": ["Amber Huang", "Ian Scott Knight", "Slava Naprienko"], "title": "Data Leakage and Redundancy in the LIT-PCBA Benchmark", "categories": ["cs.LG", "q-bio.QM"], "comment": null, "summary": "LIT-PCBA is a widely used benchmark for virtual screening, but our audit\nreveals it is fundamentally compromised. The dataset suffers from egregious\ndata leakage, rampant duplication, and pervasive analog redundancy -- flaws\nthat invalidate its use for fair model evaluation. Notably, we identify 2,491\ninactives duplicated across training and validation sets, and thousands more\nrepeated within individual data splits (2,945 in training, 789 in validation).\nCritically, three ligands in the query set -- meant to represent unseen test\ncases -- are leaked: two appear in the training set, one in validation.\nStructural redundancy compounds these issues: for some targets, over 80% of\nquery ligands are near duplicates, with Tanimoto similarity >= 0.9. In ALDH1\nalone, we find 323 highly similar active pairs between training and validation\nsets, invalidating claims of chemical diversity. These and other flaws\ncollectively cause models trained on LIT-PCBA to memorize rather than\ngeneralize. To demonstrate the consequences of these data integrity failures,\nwe implement a trivial memorization-based baseline -- using no learning, no\nphysics, and no modeling -- that outperforms state-of-the-art models, including\ndeep neural networks like CHEESE, on LIT-PCBA simply by exploiting these\nartifacts. Our findings render the benchmark unfit for its intended purpose and\ncall into question previous results based on its use. We share this audit to\nraise awareness and provide tooling to help the community develop more rigorous\nand reliable datasets going forward. All scripts necessary to reproduce our\naudit and the baseline implementation are available at:\nhttps://github.com/sievestack/LIT-PCBA-audit"}
{"id": "2507.21422", "pdf": "https://arxiv.org/pdf/2507.21422", "abs": "https://arxiv.org/abs/2507.21422", "authors": ["Sujia Huang", "Lele Fu", "Zhen Cui", "Tong Zhang", "Na Song", "Bo Huang"], "title": "Torque-based Graph Surgery:Enhancing Graph Neural Networks with Hierarchical Rewiring", "categories": ["cs.LG"], "comment": null, "summary": "Graph Neural Networks (GNNs) have emerged as powerful tools for learning from\ngraph-structured data, leveraging message passing to diffuse information and\nupdate node representations. However, most efforts have suggested that native\ninteractions encoded in the graph may not be friendly for this process,\nmotivating the development of graph rewiring methods. In this work, we propose\na torque-driven hierarchical rewiring strategy, inspired by the notion of\ntorque in classical mechanics, dynamically modulating message passing to\nimprove representation learning in heterophilous graphs and enhance robustness\nagainst noisy graphs. Specifically, we define an interference-aware torque\nmetric that integrates structural distance and energy scores to quantify the\nperturbation induced by edges, thereby encouraging each node to aggregate\ninformation from its nearest low-energy neighbors. We use the metric to\nhierarchically reconfigure the receptive field of each layer by judiciously\npruning high-torque edges and adding low-torque links, suppressing propagation\nnoise and boosting pertinent signals. Extensive evaluations on benchmark\ndatasets show that our approach surpasses state-of-the-art methods on both\nheterophilous and homophilous graphs, and maintains high accuracy on noisy\ngraph."}
{"id": "2507.21433", "pdf": "https://arxiv.org/pdf/2507.21433", "abs": "https://arxiv.org/abs/2507.21433", "authors": ["Kaiwen Chen", "Xin Tan", "Minchen Yu", "Hong Xu"], "title": "MemShare: Memory Efficient Inference for Large Reasoning Models through KV Cache Reuse", "categories": ["cs.LG", "cs.AI"], "comment": "11 pages, 7 figures, submitted to AAAI 2026", "summary": "Large Reasoning Models (LRMs) have achieved significant advances in\nmathematical reasoning and formal logic tasks. However, their tendency to\ngenerate lengthy chain-of-thought sequences leads to substantial memory\noverhead during inference. We observe that LRMs frequently produce highly\nsimilar intermediate reasoning steps, which correspond to similar KV cache\nstates across layers. Motivated by this observation, we propose MemShare, a\nnovel KV cache management approach that effectively reduces memory overhead.\nMemShare employs a collaborative filtering algorithm to efficiently identify\nreusable KV cache blocks and enables zero copy cache reuse to significantly\nreduce memory overhead, improve throughput while maintaining accuracy.\nExperimental results demonstrate that MemShare delivers up to 84.79\\%\nimprovement in throughput while maintaining better accuracy compared to\nexisting KV cache management methods."}
{"id": "2507.21437", "pdf": "https://arxiv.org/pdf/2507.21437", "abs": "https://arxiv.org/abs/2507.21437", "authors": ["Tiantian Sun", "Jian Zu"], "title": "PVD-ONet: A Multi-scale Neural Operator Method for Singularly Perturbed Boundary Layer Problems", "categories": ["cs.LG"], "comment": "34pages,14figures", "summary": "Physics-informed neural networks and Physics-informed DeepONet excel in\nsolving partial differential equations; however, they often fail to converge\nfor singularly perturbed problems. To address this, we propose two novel\nframeworks, Prandtl-Van Dyke neural network (PVD-Net) and its operator learning\nextension Prandtl-Van Dyke Deep Operator Network (PVD-ONet), which rely solely\non governing equations without data. To address varying task-specific\nrequirements, both PVD-Net and PVD-ONet are developed in two distinct versions,\ntailored respectively for stability-focused and high-accuracy modeling. The\nleading-order PVD-Net adopts a two-network architecture combined with Prandtl's\nmatching condition, targeting stability-prioritized scenarios. The high-order\nPVD-Net employs a five-network design with Van Dyke's matching principle to\ncapture fine-scale boundary layer structures, making it ideal for high-accuracy\nscenarios. PVD-ONet generalizes PVD-Net to the operator learning setting by\nassembling multiple DeepONet modules, directly mapping initial conditions to\nsolution operators and enabling instant predictions for an entire family of\nboundary layer problems without retraining. Numerical experiments on various\nmodels show that our proposed methods consistently outperform existing\nbaselines under various error metrics, thereby offering a powerful new approach\nfor multi-scale problems."}
{"id": "2507.21452", "pdf": "https://arxiv.org/pdf/2507.21452", "abs": "https://arxiv.org/abs/2507.21452", "authors": ["Sodtavilan Odonchimed", "Tatsuya Matsushima", "Simon Holk", "Yusuke Iwasawa", "Yutaka Matsuo"], "title": "Retrieve-Augmented Generation for Speeding up Diffusion Policy without Additional Training", "categories": ["cs.LG", "cs.RO"], "comment": null, "summary": "Diffusion Policies (DPs) have attracted attention for their ability to\nachieve significant accuracy improvements in various imitation learning tasks.\nHowever, DPs depend on Diffusion Models, which require multiple noise removal\nsteps to generate a single action, resulting in long generation times. To solve\nthis problem, knowledge distillation-based methods such as Consistency Policy\n(CP) have been proposed. However, these methods require a significant amount of\ntraining time, especially for difficult tasks. In this study, we propose RAGDP\n(Retrieve-Augmented Generation for Diffusion Policies) as a novel framework\nthat eliminates the need for additional training using a knowledge base to\nexpedite the inference of pre-trained DPs. In concrete, RAGDP encodes\nobservation-action pairs through the DP encoder to construct a vector database\nof expert demonstrations. During inference, the current observation is\nembedded, and the most similar expert action is extracted. This extracted\naction is combined with an intermediate noise removal step to reduce the number\nof steps required compared to the original diffusion step. We show that by\nusing RAGDP with the base model and existing acceleration methods, we improve\nthe accuracy and speed trade-off with no additional training. Even when\naccelerating the models 20 times, RAGDP maintains an advantage in accuracy,\nwith a 7% increase over distillation models such as CP."}
{"id": "2507.21479", "pdf": "https://arxiv.org/pdf/2507.21479", "abs": "https://arxiv.org/abs/2507.21479", "authors": ["Zheng Wen", "Doina Precup", "Benjamin Van Roy", "Satinder Singh"], "title": "Capacity-Constrained Continual Learning", "categories": ["cs.LG", "cs.AI", "cs.IT", "cs.SY", "eess.SY", "math.IT", "stat.ML"], "comment": null, "summary": "Any agents we can possibly build are subject to capacity constraints, as\nmemory and compute resources are inherently finite. However, comparatively\nlittle attention has been dedicated to understanding how agents with limited\ncapacity should allocate their resources for optimal performance. The goal of\nthis paper is to shed some light on this question by studying a simple yet\nrelevant continual learning problem: the capacity-constrained\nlinear-quadratic-Gaussian (LQG) sequential prediction problem. We derive a\nsolution to this problem under appropriate technical conditions. Moreover, for\nproblems that can be decomposed into a set of sub-problems, we also demonstrate\nhow to optimally allocate capacity across these sub-problems in the steady\nstate. We view the results of this paper as a first step in the systematic\ntheoretical study of learning under capacity constraints."}
{"id": "2507.21494", "pdf": "https://arxiv.org/pdf/2507.21494", "abs": "https://arxiv.org/abs/2507.21494", "authors": ["Wenxuan Bao", "Ruxi Deng", "Ruizhong Qiu", "Tianxin Wei", "Hanghang Tong", "Jingrui He"], "title": "Latte: Collaborative Test-Time Adaptation of Vision-Language Models in Federated Learning", "categories": ["cs.LG"], "comment": "Accepted by ICCV 2025", "summary": "Test-time adaptation with pre-trained vision-language models has gained\nincreasing attention for addressing distribution shifts during testing. Among\nthese approaches, memory-based algorithms stand out due to their training-free\nnature and ability to leverage historical test data. However, existing\ntest-time adaptation methods are typically designed for a single domain with\nabundant data. In decentralized settings such as federated learning, applying\nthese methods individually to each client suffers from limited test data, while\ndirectly sharing a single global memory via the server prevents proper\npersonalization to each client's unique distribution. To address this, we\npropose Latte, a novel framework where each client maintains a local memory to\nstore embeddings from its own historical test data and an external memory to\nstore class prototypes from other relevant clients. During communication, each\nclient retrieves prototypes from similar clients under the server's\ncoordination to expand its memory. For local adaptation, Latte utilizes both\nembedding similarity and uncertainty to enhance model performance. Our\ntheoretical analysis shows that Latte effectively leverages in-distribution\nclients while remaining robust to out-of-distribution clients. Extensive\nexperiments on domain adaptation and corruption benchmarks validate that Latte\nachieves superior performance in decentralized settings, while introducing only\nnegligible communication and computation costs. Our code is available at\nhttps://github.com/baowenxuan/Latte ."}
{"id": "2507.21504", "pdf": "https://arxiv.org/pdf/2507.21504", "abs": "https://arxiv.org/abs/2507.21504", "authors": ["Mahmoud Mohammadi", "Yipeng Li", "Jane Lo", "Wendy Yip"], "title": "Evaluation and Benchmarking of LLM Agents: A Survey", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The rise of LLM-based agents has opened new frontiers in AI applications, yet\nevaluating these agents remains a complex and underdeveloped area. This survey\nprovides an in-depth overview of the emerging field of LLM agent evaluation,\nintroducing a two-dimensional taxonomy that organizes existing work along (1)\nevaluation objectives -- what to evaluate, such as agent behavior,\ncapabilities, reliability, and safety -- and (2) evaluation process -- how to\nevaluate, including interaction modes, datasets and benchmarks, metric\ncomputation methods, and tooling. In addition to taxonomy, we highlight\nenterprise-specific challenges, such as role-based access to data, the need for\nreliability guarantees, dynamic and long-horizon interactions, and compliance,\nwhich are often overlooked in current research. We also identify future\nresearch directions, including holistic, more realistic, and scalable\nevaluation. This work aims to bring clarity to the fragmented landscape of\nagent evaluation and provide a framework for systematic assessment, enabling\nresearchers and practitioners to evaluate LLM agents for real-world deployment."}
{"id": "2507.21531", "pdf": "https://arxiv.org/pdf/2507.21531", "abs": "https://arxiv.org/abs/2507.21531", "authors": ["Pedram Rajaei", "Maryam Ostadsharif Memar", "Navid Ziaei", "Behzad Nazari", "Ali Yousefi"], "title": "Hierarchical Stochastic Differential Equation Models for Latent Manifold Learning in Neural Time Series", "categories": ["cs.LG"], "comment": null, "summary": "The manifold hypothesis suggests that high-dimensional neural time series lie\non a low-dimensional manifold shaped by simpler underlying dynamics. To uncover\nthis structure, latent dynamical variable models such as state-space models,\nrecurrent neural networks, neural ordinary differential equations, and Gaussian\nProcess Latent Variable Models are widely used. We propose a novel hierarchical\nstochastic differential equation (SDE) model that balances computational\nefficiency and interpretability, addressing key limitations of existing\nmethods. Our model assumes the trajectory of a manifold can be reconstructed\nfrom a sparse set of samples from the manifold trajectory. The latent space is\nmodeled using Brownian bridge SDEs, with points - specified in both time and\nvalue - sampled from a multivariate marked point process. These Brownian\nbridges define the drift of a second set of SDEs, which are then mapped to the\nobserved data. This yields a continuous, differentiable latent process capable\nof modeling arbitrarily complex time series as the number of manifold points\nincreases. We derive training and inference procedures and show that the\ncomputational cost of inference scales linearly with the length of the\nobservation data. We then validate our model on both synthetic data and neural\nrecordings to demonstrate that it accurately recovers the underlying manifold\nstructure and scales effectively with data dimensionality."}
{"id": "2507.21616", "pdf": "https://arxiv.org/pdf/2507.21616", "abs": "https://arxiv.org/abs/2507.21616", "authors": ["Kevin Doran", "Tom Baden"], "title": "Categorical Distributions are Effective Neural Network Outputs for Event Prediction", "categories": ["cs.LG"], "comment": "32 pages, 26 figures", "summary": "We demonstrate the effectiveness of using a simple neural network output, a\ncategorical probability distribution, for the task of next spike prediction.\nThis case study motivates an investigation into why this simple output\nstructure is not commonly used with neural temporal point process models. We\nfind evidence that many existing datasets for evaluating temporal point process\nmodels do not reveal much information about the underlying event generating\nprocesses, and many existing models perform well due to regularization effects\nof model size and constraints on output structure. We extend existing datasets\nand create new ones in order to explore outside of this information limited\nregime and find that outputting a simple categorical distribution is\ncompetitive across a wide range of datasets."}
{"id": "2507.21648", "pdf": "https://arxiv.org/pdf/2507.21648", "abs": "https://arxiv.org/abs/2507.21648", "authors": ["Raiyan R. Khan", "Philippe Chlenski", "Itsik Pe'er"], "title": "Hyperbolic Genome Embeddings", "categories": ["cs.LG"], "comment": "30 pages, 16 figures, 10 tables. Camera-ready version for ICLR 2025", "summary": "Current approaches to genomic sequence modeling often struggle to align the\ninductive biases of machine learning models with the evolutionarily-informed\nstructure of biological systems. To this end, we formulate a novel application\nof hyperbolic CNNs that exploits this structure, enabling more expressive DNA\nsequence representations. Our strategy circumvents the need for explicit\nphylogenetic mapping while discerning key properties of sequences pertaining to\ncore functional and regulatory behavior. Across 37 out of 42 genome\ninterpretation benchmark datasets, our hyperbolic models outperform their\nEuclidean equivalents. Notably, our approach even surpasses state-of-the-art\nperformance on seven GUE benchmark datasets, consistently outperforming many\nDNA language models while using orders of magnitude fewer parameters and\navoiding pretraining. Our results include a novel set of benchmark\ndatasets--the Transposable Elements Benchmark--which explores a major but\nunderstudied component of the genome with deep evolutionary significance. We\nfurther motivate our work by exploring how our hyperbolic models recognize\ngenomic signal under various data-generating conditions and by constructing an\nempirical method for interpreting the hyperbolicity of dataset embeddings.\nThroughout these assessments, we find persistent evidence highlighting the\npotential of our hyperbolic framework as a robust paradigm for genome\nrepresentation learning. Our code and benchmark datasets are available at\nhttps://github.com/rrkhan/HGE."}
{"id": "2507.21653", "pdf": "https://arxiv.org/pdf/2507.21653", "abs": "https://arxiv.org/abs/2507.21653", "authors": ["Yuan Li", "Jun Hu", "Bryan Hooi", "Bingsheng He", "Cheng Chen"], "title": "DGP: A Dual-Granularity Prompting Framework for Fraud Detection with Graph-Enhanced LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Real-world fraud detection applications benefit from graph learning\ntechniques that jointly exploit node features, often rich in textual data, and\ngraph structural information. Recently, Graph-Enhanced LLMs emerge as a\npromising graph learning approach that converts graph information into prompts,\nexploiting LLMs' ability to reason over both textual and structural\ninformation. Among them, text-only prompting, which converts graph information\nto prompts consisting solely of text tokens, offers a solution that relies only\non LLM tuning without requiring additional graph-specific encoders. However,\ntext-only prompting struggles on heterogeneous fraud-detection graphs:\nmulti-hop relations expand exponentially with each additional hop, leading to\nrapidly growing neighborhoods associated with dense textual information. These\nneighborhoods may overwhelm the model with long, irrelevant content in the\nprompt and suppress key signals from the target node, thereby degrading\nperformance. To address this challenge, we propose Dual Granularity Prompting\n(DGP), which mitigates information overload by preserving fine-grained textual\ndetails for the target node while summarizing neighbor information into\ncoarse-grained text prompts. DGP introduces tailored summarization strategies\nfor different data modalities, bi-level semantic abstraction for textual fields\nand statistical aggregation for numerical features, enabling effective\ncompression of verbose neighbor content into concise, informative prompts.\nExperiments across public and industrial datasets demonstrate that DGP operates\nwithin a manageable token budget while improving fraud detection performance by\nup to 6.8% (AUPRC) over state-of-the-art methods, showing the potential of\nGraph-Enhanced LLMs for fraud detection."}
{"id": "2507.21670", "pdf": "https://arxiv.org/pdf/2507.21670", "abs": "https://arxiv.org/abs/2507.21670", "authors": ["Paul Patrone", "Anthony Kearsley"], "title": "Probabilistic Consistency in Machine Learning and Its Connection to Uncertainty Quantification", "categories": ["cs.LG", "math.PR"], "comment": null, "summary": "Machine learning (ML) is often viewed as a powerful data analysis tool that\nis easy to learn because of its black-box nature. Yet this very nature also\nmakes it difficult to quantify confidence in predictions extracted from ML\nmodels, and more fundamentally, to understand how such models are mathematical\nabstractions of training data. The goal of this paper is to unravel these\nissues and their connections to uncertainty quantification (UQ) by pursuing a\nline of reasoning motivated by diagnostics. In such settings, prevalence - i.e.\nthe fraction of elements in class - is often of inherent interest. Here we\nanalyze the many interpretations of prevalence to derive a level-set theory of\nclassification, which shows that certain types of self-consistent ML models are\nequivalent to class-conditional probability distributions. We begin by studying\nthe properties of binary Bayes optimal classifiers, recognizing that their\nboundary sets can be reinterpreted as level-sets of pairwise density ratios. By\nparameterizing Bayes classifiers in terms of the prevalence, we then show that\nthey satisfy important monotonicity and class-switching properties that can be\nused to deduce the density ratios without direct access to the boundary sets.\nMoreover, this information is sufficient for tasks such as constructing the\nmulticlass Bayes-optimal classifier and estimating inherent uncertainty in the\nclass assignments. In the multiclass case, we use these results to deduce\nnormalization and self-consistency conditions, the latter being equivalent to\nthe law of total probability for classifiers. We also show that these are\nnecessary conditions for arbitrary ML models to have valid probabilistic\ninterpretations. Throughout we demonstrate how this analysis informs the\nbroader task of UQ for ML via an uncertainty propagation framework."}
{"id": "2507.21710", "pdf": "https://arxiv.org/pdf/2507.21710", "abs": "https://arxiv.org/abs/2507.21710", "authors": ["Hongwei Ma", "Junbin Gao", "Minh-Ngoc Tran"], "title": "PREIG: Physics-informed and Reinforcement-driven Interpretable GRU for Commodity Demand Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "Accurately forecasting commodity demand remains a critical challenge due to\nvolatile market dynamics, nonlinear dependencies, and the need for economically\nconsistent predictions. This paper introduces PREIG, a novel deep learning\nframework tailored for commodity demand forecasting. The model uniquely\nintegrates a Gated Recurrent Unit (GRU) architecture with physics-informed\nneural network (PINN) principles by embedding a domain-specific economic\nconstraint: the negative elasticity between price and demand. This constraint\nis enforced through a customized loss function that penalizes violations of the\nphysical rule, ensuring that model predictions remain interpretable and aligned\nwith economic theory. To further enhance predictive performance and stability,\nPREIG incorporates a hybrid optimization strategy that couples NAdam and L-BFGS\nwith Population-Based Training (POP). Experiments across multiple commodities\ndatasets demonstrate that PREIG significantly outperforms traditional\neconometric models (ARIMA,GARCH) and deep learning baselines (BPNN,RNN) in both\nRMSE and MAPE. When compared with GRU,PREIG maintains good explainability while\nstill performing well in prediction. By bridging domain knowledge, optimization\ntheory and deep learning, PREIG provides a robust, interpretable, and scalable\nsolution for high-dimensional nonlinear time series forecasting in economy."}
{"id": "2507.21720", "pdf": "https://arxiv.org/pdf/2507.21720", "abs": "https://arxiv.org/abs/2507.21720", "authors": ["Gang Wang", "Peng Hu"], "title": "Data-Driven Extended Corresponding State Approach for Residual Property Prediction of Hydrofluoroolefins", "categories": ["cs.LG"], "comment": null, "summary": "Hydrofluoroolefins are considered the most promising next-generation\nrefrigerants due to their extremely low global warming potential values, which\ncan effectively mitigate the global warming effect. However, the lack of\nreliable thermodynamic data hinders the discovery and application of newer and\nsuperior hydrofluoroolefin refrigerants. In this work, integrating the\nstrengths of theoretical method and data-driven method, we proposed a neural\nnetwork extended corresponding state model to predict the residual\nthermodynamic properties of hydrofluoroolefin refrigerants. The innovation is\nthat the fluids are characterized through their microscopic molecular\nstructures by the inclusion of graph neural network module and the specialized\ndesign of model architecture to enhance its generalization ability. The\nproposed model is trained using the highly accurate data of available known\nfluids, and evaluated via the leave-one-out cross-validation method. Compared\nto conventional extended corresponding state models or cubic equation of state,\nthe proposed model shows significantly improved accuracy for density and energy\nproperties in liquid and supercritical regions, with average absolute deviation\nof 1.49% (liquid) and 2.42% (supercritical) for density, 3.37% and 2.50% for\nresidual entropy, 1.85% and 1.34% for residual enthalpy. These results\ndemonstrate the effectiveness of embedding physics knowledge into the machine\nlearning model. The proposed neural network extended corresponding state model\nis expected to significantly accelerate the discovery of novel\nhydrofluoroolefin refrigerants."}
{"id": "2507.21738", "pdf": "https://arxiv.org/pdf/2507.21738", "abs": "https://arxiv.org/abs/2507.21738", "authors": ["Huiqiang Chen", "Tianqing Zhu", "Xin Yu", "Wanlei Zhou"], "title": "Zero-Shot Machine Unlearning with Proxy Adversarial Data Generation", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by IJCAI 2025", "summary": "Machine unlearning aims to remove the influence of specific samples from a\ntrained model. A key challenge in this process is over-unlearning, where the\nmodel's performance on the remaining data significantly drops due to the change\nin the model's parameters. Existing unlearning algorithms depend on the\nremaining data to prevent this issue. As such, these methods are inapplicable\nin a more practical scenario, where only the unlearning samples are available\n(i.e., zero-shot unlearning). This paper presents a novel framework, ZS-PAG, to\nfill this gap. Our approach offers three key innovations: (1) we approximate\nthe inaccessible remaining data by generating adversarial samples; (2)\nleveraging the generated samples, we pinpoint a specific subspace to perform\nthe unlearning process, therefore preventing over-unlearning in the challenging\nzero-shot scenario; and (3) we consider the influence of the unlearning process\non the remaining samples and design an influence-based pseudo-labeling\nstrategy. As a result, our method further improves the model's performance\nafter unlearning. The proposed method holds a theoretical guarantee, and\nexperiments on various benchmarks validate the effectiveness and superiority of\nour proposed method over several baselines."}
{"id": "2507.21748", "pdf": "https://arxiv.org/pdf/2507.21748", "abs": "https://arxiv.org/abs/2507.21748", "authors": ["Simon Daubner", "Alexander E. Cohen", "Benjamin D√∂rich", "Samuel J. Cooper"], "title": "evoxels: A differentiable physics framework for voxel-based microstructure simulations", "categories": ["cs.LG", "cond-mat.mtrl-sci", "cs.CE", "physics.comp-ph"], "comment": "9 pages, 3 figures, structure following JOSS style", "summary": "Materials science inherently spans disciplines: experimentalists use advanced\nmicroscopy to uncover micro- and nanoscale structure, while theorists and\ncomputational scientists develop models that link processing, structure, and\nproperties. Bridging these domains is essential for inverse material design\nwhere you start from desired performance and work backwards to optimal\nmicrostructures and manufacturing routes. Integrating high-resolution imaging\nwith predictive simulations and data-driven optimization accelerates discovery\nand deepens understanding of process-structure-property relationships. The\ndifferentiable physics framework evoxels is based on a fully Pythonic, unified\nvoxel-based approach that integrates segmented 3D microscopy data, physical\nsimulations, inverse modeling, and machine learning."}
{"id": "2507.21762", "pdf": "https://arxiv.org/pdf/2507.21762", "abs": "https://arxiv.org/abs/2507.21762", "authors": ["Nguyen Xuan-Vu", "Daniel Armstrong", "Zlatko Joncev", "Philippe Schwaller"], "title": "TempRe: Template generation for single and direct multi-step retrosynthesis", "categories": ["cs.LG"], "comment": null, "summary": "Retrosynthesis planning remains a central challenge in molecular discovery\ndue to the vast and complex chemical reaction space. While traditional\ntemplate-based methods offer tractability, they suffer from poor scalability\nand limited generalization, and template-free generative approaches risk\ngenerating invalid reactions. In this work, we propose TempRe, a generative\nframework that reformulates template-based approaches as sequence generation,\nenabling scalable, flexible, and chemically plausible retrosynthesis. We\nevaluated TempRe across single-step and multi-step retrosynthesis tasks,\ndemonstrating its superiority over both template classification and\nSMILES-based generation methods. On the PaRoutes multi-step benchmark, TempRe\nachieves strong top-k route accuracy. Furthermore, we extend TempRe to direct\nmulti-step synthesis route generation, providing a lightweight and efficient\nalternative to conventional single-step and search-based approaches. These\nresults highlight the potential of template generative modeling as a powerful\nparadigm in computer-aided synthesis planning."}
{"id": "2507.21799", "pdf": "https://arxiv.org/pdf/2507.21799", "abs": "https://arxiv.org/abs/2507.21799", "authors": ["Xie Zhang", "Yina Wang", "Chenshu Wu"], "title": "Unlocking Interpretability for RF Sensing: A Complex-Valued White-Box Transformer", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The empirical success of deep learning has spurred its application to the\nradio-frequency (RF) domain, leading to significant advances in Deep Wireless\nSensing (DWS). However, most existing DWS models function as black boxes with\nlimited interpretability, which hampers their generalizability and raises\nconcerns in security-sensitive physical applications. In this work, inspired by\nthe remarkable advances of white-box transformers, we present RF-CRATE, the\nfirst mathematically interpretable deep network architecture for RF sensing,\ngrounded in the principles of complex sparse rate reduction. To accommodate the\nunique RF signals, we conduct non-trivial theoretical derivations that extend\nthe original real-valued white-box transformer to the complex domain. By\nleveraging the CR-Calculus framework, we successfully construct a fully\ncomplex-valued white-box transformer with theoretically derived self-attention\nand residual multi-layer perceptron modules. Furthermore, to improve the\nmodel's ability to extract discriminative features from limited wireless data,\nwe introduce Subspace Regularization, a novel regularization strategy that\nenhances feature diversity, resulting in an average performance improvement of\n19.98% across multiple sensing tasks. We extensively evaluate RF-CRATE against\nseven baselines with multiple public and self-collected datasets involving\ndifferent RF signals. The results show that RF-CRATE achieves performance on\npar with thoroughly engineered black-box models, while offering full\nmathematical interpretability. More importantly, by extending CRATE to the\ncomplex domain, RF-CRATE yields substantial improvements, achieving an average\nclassification gain of 5.08% and reducing regression error by 10.34% across\ndiverse sensing tasks compared to CRATE. RF-CRATE is fully open-sourced at:\nhttps://github.com/rfcrate/RF_CRATE."}
{"id": "2507.21803", "pdf": "https://arxiv.org/pdf/2507.21803", "abs": "https://arxiv.org/abs/2507.21803", "authors": ["Sofianos Panagiotis Fotias", "Vassilis Gaganis"], "title": "Bayesian Neural Network Surrogates for Bayesian Optimization of Carbon Capture and Storage Operations", "categories": ["cs.LG"], "comment": null, "summary": "Carbon Capture and Storage (CCS) stands as a pivotal technology for fostering\na sustainable future. The process, which involves injecting supercritical\nCO$_2$ into underground formations, a method already widely used for Enhanced\nOil Recovery, serves a dual purpose: it not only curbs CO$_2$ emissions and\naddresses climate change but also extends the operational lifespan and\nsustainability of oil fields and platforms, easing the shift toward greener\npractices. This paper delivers a thorough comparative evaluation of strategies\nfor optimizing decision variables in CCS project development, employing a\nderivative-free technique known as Bayesian Optimization. In addition to\nGaussian Processes, which usually serve as the gold standard in BO, various\nnovel stochastic models were examined and compared within a BO framework. This\nresearch investigates the effectiveness of utilizing more exotic stochastic\nmodels than GPs for BO in environments where GPs have been shown to\nunderperform, such as in cases with a large number of decision variables or\nmultiple objective functions that are not similarly scaled. By incorporating\nNet Present Value (NPV) as a key objective function, the proposed framework\ndemonstrates its potential to improve economic viability while ensuring the\nsustainable deployment of CCS technologies. Ultimately, this study represents\nthe first application in the reservoir engineering industry of the growing body\nof BO research, specifically in the search for more appropriate stochastic\nmodels, highlighting its potential as a preferred method for enhancing\nsustainability in the energy sector."}
{"id": "2507.21833", "pdf": "https://arxiv.org/pdf/2507.21833", "abs": "https://arxiv.org/abs/2507.21833", "authors": ["Taeyoung Kim"], "title": "Analysis of Fourier Neural Operators via Effective Field Theory", "categories": ["cs.LG", "cs.AI"], "comment": "37 pages, 10 figures", "summary": "Fourier Neural Operators (FNOs) have emerged as leading surrogates for\nhigh-dimensional partial-differential equations, yet their stability,\ngeneralization and frequency behavior lack a principled explanation. We present\nthe first systematic effective-field-theory analysis of FNOs in an\ninfinite-dimensional function space, deriving closed recursion relations for\nthe layer kernel and four-point vertex and then examining three practically\nimportant settings-analytic activations, scale-invariant cases and\narchitectures with residual connections. The theory shows that nonlinear\nactivations inevitably couple frequency inputs to high-frequency modes that are\notherwise discarded by spectral truncation, and experiments confirm this\nfrequency transfer. For wide networks we obtain explicit criticality conditions\non the weight-initialization ensemble that keep small input perturbations to\nhave uniform scale across depth, and empirical tests validate these\npredictions. Taken together, our results quantify how nonlinearity enables\nneural operators to capture non-trivial features, supply criteria for\nhyper-parameter selection via criticality analysis, and explain why\nscale-invariant activations and residual connections enhance feature learning\nin FNOs."}
{"id": "2507.21841", "pdf": "https://arxiv.org/pdf/2507.21841", "abs": "https://arxiv.org/abs/2507.21841", "authors": ["Rahul Golder", "M. M. Faruque Hasan"], "title": "Discovering Interpretable Ordinary Differential Equations from Noisy Data", "categories": ["cs.LG", "physics.comp-ph"], "comment": "20 pages, 11 figures, 7 tables", "summary": "The data-driven discovery of interpretable models approximating the\nunderlying dynamics of a physical system has gained attraction in the past\ndecade. Current approaches employ pre-specified functional forms or basis\nfunctions and often result in models that lack physical meaning and\ninterpretability, let alone represent the true physics of the system. We\npropose an unsupervised parameter estimation methodology that first finds an\napproximate general solution, followed by a spline transformation to linearly\nestimate the coefficients of the governing ordinary differential equation\n(ODE). The approximate general solution is postulated using the same functional\nform as the analytical solution of a general homogeneous, linear,\nconstant-coefficient ODE. An added advantage is its ability to produce a\nhigh-fidelity, smooth functional form even in the presence of noisy data. The\nspline approximation obtains gradient information from the functional form\nwhich are linearly independent and creates the basis of the gradient matrix.\nThis gradient matrix is used in a linear system to find the coefficients of the\nODEs. From the case studies, we observed that our modeling approach discovers\nODEs with high accuracy and also promotes sparsity in the solution without\nusing any regularization techniques. The methodology is also robust to noisy\ndata and thus allows the integration of data-driven techniques into real\nexperimental setting for data-driven learning of physical phenomena."}
{"id": "2507.21898", "pdf": "https://arxiv.org/pdf/2507.21898", "abs": "https://arxiv.org/abs/2507.21898", "authors": ["Risshab Srinivas Ramesh", "Roshani T S Udupa", "Monisha J", "Kushi K K S"], "title": "Cardiovascular Disease Prediction using Machine Learning: A Comparative Analysis", "categories": ["cs.LG"], "comment": null, "summary": "Cardiovascular diseases (CVDs) are a main cause of mortality globally,\naccounting for 31% of all deaths. This study involves a cardiovascular disease\n(CVD) dataset comprising 68,119 records to explore the influence of numerical\n(age, height, weight, blood pressure, BMI) and categorical gender, cholesterol,\nglucose, smoking, alcohol, activity) factors on CVD occurrence. We have\nperformed statistical analyses, including t-tests, Chi-square tests, and ANOVA,\nto identify strong associations between CVD and elderly people, hypertension,\nhigher weight, and abnormal cholesterol levels, while physical activity (a\nprotective factor). A logistic regression model highlights age, blood pressure,\nand cholesterol as primary risk factors, with unexpected negative associations\nfor smoking and alcohol, suggesting potential data issues. Model performance\ncomparisons reveal CatBoost as the top performer with an accuracy of 0.734 and\nan ECE of 0.0064 and excels in probabilistic prediction (Brier score = 0.1824).\nData challenges, including outliers and skewed distributions, indicate a need\nfor improved preprocessing to enhance predictive reliability."}
{"id": "2507.21938", "pdf": "https://arxiv.org/pdf/2507.21938", "abs": "https://arxiv.org/abs/2507.21938", "authors": ["Alex Abrudan", "Sebastian Pujalte Ojeda", "Chaitanya K. Joshi", "Matthew Greenig", "Felipe Engelberger", "Alena Khmelinskaia", "Jens Meiler", "Michele Vendruscolo", "Tuomas P. J. Knowles"], "title": "Multi-state Protein Design with DynamicMPNN", "categories": ["cs.LG", "q-bio.BM", "I.2.6; J.3"], "comment": "ICML 2025 GenBio Workshop", "summary": "Structural biology has long been dominated by the one sequence, one\nstructure, one function paradigm, yet many critical biological processes - from\nenzyme catalysis to membrane transport - depend on proteins that adopt multiple\nconformational states. Existing multi-state design approaches rely on post-hoc\naggregation of single-state predictions, achieving poor experimental success\nrates compared to single-state design. We introduce DynamicMPNN, an inverse\nfolding model explicitly trained to generate sequences compatible with multiple\nconformations through joint learning across conformational ensembles. Trained\non 46,033 conformational pairs covering 75% of CATH superfamilies and evaluated\nusing AlphaFold initial guess, DynamicMPNN outperforms ProteinMPNN by up to 13%\non structure-normalized RMSD across our challenging multi-state protein\nbenchmark."}
{"id": "2507.21963", "pdf": "https://arxiv.org/pdf/2507.21963", "abs": "https://arxiv.org/abs/2507.21963", "authors": ["Siana Rizwan", "Tasnim Ahmed", "Salimur Choudhury"], "title": "SLA-Centric Automated Algorithm Selection Framework for Cloud Environments", "categories": ["cs.LG"], "comment": null, "summary": "Cloud computing offers on-demand resource access, regulated by Service-Level\nAgreements (SLAs) between consumers and Cloud Service Providers (CSPs). SLA\nviolations can impact efficiency and CSP profitability. In this work, we\npropose an SLA-aware automated algorithm-selection framework for combinatorial\noptimization problems in resource-constrained cloud environments. The framework\nuses an ensemble of machine learning models to predict performance and rank\nalgorithm-hardware pairs based on SLA constraints. We also apply our framework\nto the 0-1 knapsack problem. We curate a dataset comprising instance specific\nfeatures along with memory usage, runtime, and optimality gap for 6 algorithms.\nAs an empirical benchmark, we evaluate the framework on both classification and\nregression tasks. Our ablation study explores the impact of hyperparameters,\nlearning approaches, and large language models effectiveness in regression, and\nSHAP-based interpretability."}
{"id": "2507.21983", "pdf": "https://arxiv.org/pdf/2507.21983", "abs": "https://arxiv.org/abs/2507.21983", "authors": ["Daniel R. Jiang", "Alex Nikulkov", "Yu-Chia Chen", "Yang Bai", "Zheqing Zhu"], "title": "Improving Generative Ad Text on Facebook using Reinforcement Learning", "categories": ["cs.LG"], "comment": "D.J. and A.N. contributed equally, 41 pages, 6 figures", "summary": "Generative artificial intelligence (AI), in particular large language models\n(LLMs), is poised to drive transformative economic change. LLMs are pre-trained\non vast text data to learn general language patterns, but a subsequent\npost-training phase is critical to align them for specific real-world tasks.\nReinforcement learning (RL) is the leading post-training technique, yet its\neconomic impact remains largely underexplored and unquantified. We examine this\nquestion through the lens of the first deployment of an RL-trained LLM for\ngenerative advertising on Facebook. Integrated into Meta's Text Generation\nfeature, our model, \"AdLlama,\" powers an AI tool that helps advertisers create\nnew variations of human-written ad text. To train this model, we introduce\nreinforcement learning with performance feedback (RLPF), a post-training method\nthat uses historical ad performance data as a reward signal. In a large-scale\n10-week A/B test on Facebook spanning nearly 35,000 advertisers and 640,000 ad\nvariations, we find that AdLlama improves click-through rates by 6.7%\n(p=0.0296) compared to a supervised imitation model trained on curated ads.\nThis represents a substantial improvement in advertiser return on investment on\nFacebook. We also find that advertisers who used AdLlama generated more ad\nvariations, indicating higher satisfaction with the model's outputs. To our\nknowledge, this is the largest study to date on the use of generative AI in an\necologically valid setting, offering an important data point quantifying the\ntangible impact of RL post-training. Furthermore, the results show that RLPF is\na promising and generalizable approach for metric-driven post-training that\nbridges the gap between highly capable language models and tangible outcomes."}
{"id": "2507.21992", "pdf": "https://arxiv.org/pdf/2507.21992", "abs": "https://arxiv.org/abs/2507.21992", "authors": ["Siddhartha Pradhan", "Shikshya Shiwakoti", "Neha Bathuri"], "title": "Teach Me to Trick: Exploring Adversarial Transferability via Knowledge Distillation", "categories": ["cs.LG", "cs.AI"], "comment": "10 pages, 4 figures", "summary": "We investigate whether knowledge distillation (KD) from multiple\nheterogeneous teacher models can enhance the generation of transferable\nadversarial examples. A lightweight student model is trained using two KD\nstrategies: curriculum-based switching and joint optimization, with ResNet50\nand DenseNet-161 as teachers. The trained student is then used to generate\nadversarial examples using FG, FGS, and PGD attacks, which are evaluated\nagainst a black-box target model (GoogLeNet). Our results show that student\nmodels distilled from multiple teachers achieve attack success rates comparable\nto ensemble-based baselines, while reducing adversarial example generation time\nby up to a factor of six. An ablation study further reveals that lower\ntemperature settings and the inclusion of hard-label supervision significantly\nenhance transferability. These findings suggest that KD can serve not only as a\nmodel compression technique but also as a powerful tool for improving the\nefficiency and effectiveness of black-box adversarial attacks."}
{"id": "2507.22032", "pdf": "https://arxiv.org/pdf/2507.22032", "abs": "https://arxiv.org/abs/2507.22032", "authors": ["Mokhtar Al-Awadhi", "Ratnadeep Deshmukh"], "title": "Classification of Honey Botanical and Geographical Sources using Mineral Profiles and Machine Learning", "categories": ["cs.LG"], "comment": "13 pages, 7 figures, conference paper", "summary": "This paper proposes a machine learning-based approach for identifying honey\nfloral and geographical sources using mineral element profiles. The proposed\nmethod comprises two steps: preprocessing and classification. The preprocessing\nphase involves missing-value treatment and data normalization. In the\nclassification phase, we employ various supervised classification models for\ndiscriminating between six botanical sources and 13 geographical origins of\nhoney. We test the classifiers' performance on a publicly available honey\nmineral element dataset. The dataset contains mineral element profiles of\nhoneys from various floral and geographical origins. Results show that mineral\nelement content in honey provides discriminative information useful for\nclassifying honey botanical and geographical sources. Results also show that\nthe Random Forests (RF) classifier obtains the best performance on this\ndataset, achieving a cross-validation accuracy of 99.30% for classifying honey\nbotanical origins and 98.01% for classifying honey geographical origins."}
{"id": "2507.22040", "pdf": "https://arxiv.org/pdf/2507.22040", "abs": "https://arxiv.org/abs/2507.22040", "authors": ["Alvaro Maggiar", "Sohrab Andaz", "Akhil Bagaria", "Carson Eisenach", "Dean Foster", "Omer Gottesman", "Dominique Perrault-Joncas"], "title": "Structure-Informed Deep Reinforcement Learning for Inventory Management", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "This paper investigates the application of Deep Reinforcement Learning (DRL)\nto classical inventory management problems, with a focus on practical\nimplementation considerations. We apply a DRL algorithm based on DirectBackprop\nto several fundamental inventory management scenarios including multi-period\nsystems with lost sales (with and without lead times), perishable inventory\nmanagement, dual sourcing, and joint inventory procurement and removal. The DRL\napproach learns policies across products using only historical information that\nwould be available in practice, avoiding unrealistic assumptions about demand\ndistributions or access to distribution parameters. We demonstrate that our\ngeneric DRL implementation performs competitively against or outperforms\nestablished benchmarks and heuristics across these diverse settings, while\nrequiring minimal parameter tuning. Through examination of the learned\npolicies, we show that the DRL approach naturally captures many known\nstructural properties of optimal policies derived from traditional operations\nresearch methods. To further improve policy performance and interpretability,\nwe propose a Structure-Informed Policy Network technique that explicitly\nincorporates analytically-derived characteristics of optimal policies into the\nlearning process. This approach can help interpretability and add robustness to\nthe policy in out-of-sample performance, as we demonstrate in an example with\nrealistic demand data. Finally, we provide an illustrative application of DRL\nin a non-stationary setting. Our work bridges the gap between data-driven\nlearning and analytical insights in inventory management while maintaining\npractical applicability."}
{"id": "2507.22045", "pdf": "https://arxiv.org/pdf/2507.22045", "abs": "https://arxiv.org/abs/2507.22045", "authors": ["Haley Rosso", "Lars Ruthotto", "Khachik Sargsyan"], "title": "Weight-Parameterization in Continuous Time Deep Neural Networks for Surrogate Modeling", "categories": ["cs.LG", "math.OC"], "comment": "34 pages, 6 figures, submitted to the MoRE24 special issue of\n  Computational Science and Engineering", "summary": "Continuous-time deep learning models, such as neural ordinary differential\nequations (ODEs), offer a promising framework for surrogate modeling of complex\nphysical systems. A central challenge in training these models lies in learning\nexpressive yet stable time-varying weights, particularly under computational\nconstraints. This work investigates weight parameterization strategies that\nconstrain the temporal evolution of weights to a low-dimensional subspace\nspanned by polynomial basis functions. We evaluate both monomial and Legendre\npolynomial bases within neural ODE and residual network (ResNet) architectures\nunder discretize-then-optimize and optimize-then-discretize training paradigms.\nExperimental results across three high-dimensional benchmark problems show that\nLegendre parameterizations yield more stable training dynamics, reduce\ncomputational cost, and achieve accuracy comparable to or better than both\nmonomial parameterizations and unconstrained weight models. These findings\nelucidate the role of basis choice in time-dependent weight parameterization\nand demonstrate that using orthogonal polynomial bases offers a favorable\ntradeoff between model expressivity and training efficiency."}
{"id": "2507.22053", "pdf": "https://arxiv.org/pdf/2507.22053", "abs": "https://arxiv.org/abs/2507.22053", "authors": ["Wei Yang", "Defu Cao", "Yan Liu"], "title": "Foundation Models for Demand Forecasting via Dual-Strategy Ensembling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Accurate demand forecasting is critical for supply chain optimization, yet\nremains difficult in practice due to hierarchical complexity, domain shifts,\nand evolving external factors. While recent foundation models offer strong\npotential for time series forecasting, they often suffer from architectural\nrigidity and limited robustness under distributional change. In this paper, we\npropose a unified ensemble framework that enhances the performance of\nfoundation models for sales forecasting in real-world supply chains. Our method\ncombines two complementary strategies: (1) Hierarchical Ensemble (HE), which\npartitions training and inference by semantic levels (e.g., store, category,\ndepartment) to capture localized patterns; and (2) Architectural Ensemble (AE),\nwhich integrates predictions from diverse model backbones to mitigate bias and\nimprove stability. We conduct extensive experiments on the M5 benchmark and\nthree external sales datasets, covering both in-domain and zero-shot\nforecasting. Results show that our approach consistently outperforms strong\nbaselines, improves accuracy across hierarchical levels, and provides a simple\nyet effective mechanism for boosting generalization in complex forecasting\nenvironments."}
{"id": "2507.21054", "pdf": "https://arxiv.org/pdf/2507.21054", "abs": "https://arxiv.org/abs/2507.21054", "authors": ["Robert Sparrow", "Joshua Hatherley"], "title": "High hopes for \"Deep Medicine\"? AI, economics, and the future of care", "categories": ["cs.CY", "cs.AI", "cs.HC", "cs.LG"], "comment": null, "summary": "In the much-celebrated book Deep Medicine, Eric Topol argues that the\ndevelopment of artificial intelligence for health care will lead to a dramatic\nshift in the culture and practice of medicine. In the next several decades, he\nsuggests, AI will become sophisticated enough that many of the everyday tasks\nof physicians could be delegated to it. Topol is perhaps the most articulate\nadvocate of the benefits of AI in medicine, but he is hardly alone in spruiking\nits potential to allow physicians to dedicate more of their time and attention\nto providing empathetic care for their patients in the future. Unfortunately,\nseveral factors suggest a radically different picture for the future of health\ncare. Far from facilitating a return to a time of closer doctor-patient\nrelationships, the use of medical AI seems likely to further erode therapeutic\nrelationships and threaten professional and patient satisfaction."}
{"id": "2507.21065", "pdf": "https://arxiv.org/pdf/2507.21065", "abs": "https://arxiv.org/abs/2507.21065", "authors": ["Sabrina Patania", "Luca Annese", "Cansu Koyuturk", "Azzurra Ruggeri", "Dimitri Ognibene"], "title": "Dialogic Social Learning for Artificial Agents: Enhancing LLM Ontology Acquisition through Mixed-Initiative Educational Interactions", "categories": ["cs.CL", "cs.HC", "cs.LG", "cs.RO", "I.2.7, I.2.9, j.4,"], "comment": "submitted to ICSR2025", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nprocessing extensive offline datasets. However, they often face challenges in\nacquiring and integrating complex, knowledge online. Traditional AI training\nparadigms, predominantly based on supervised learning or reinforcement\nlearning, mirror a 'Piagetian' model of independent exploration. These\napproaches typically rely on large datasets and sparse feedback signals,\nlimiting the models' ability to learn efficiently from interactions. Drawing\ninspiration from Vygotsky's sociocultural theory, this study explores the\npotential of socially mediated learning paradigms to address these limitations.\n  We introduce a dynamic environment, termed the 'AI Social Gym', where an AI\nlearner agent engages in dyadic pedagogical dialogues with knowledgeable AI\nteacher agents. These interactions emphasize external, structured dialogue as a\ncore mechanism for knowledge acquisition, contrasting with methods that depend\nsolely on internal inference or pattern recognition.\n  Our investigation focuses on how different pedagogical strategies impact the\nAI learning process in the context of ontology acquisition. Empirical results\nindicate that such dialogic approaches-particularly those involving\nmixed-direction interactions combining top-down explanations with\nlearner-initiated questioning-significantly enhance the LLM's ability to\nacquire and apply new knowledge, outperforming both unidirectional\ninstructional methods and direct access to structured knowledge, formats\ntypically present in training datasets.\n  These findings suggest that integrating pedagogical and psychological\ninsights into AI and robot training can substantially improve post-training\nknowledge acquisition and response quality. This approach offers a\ncomplementary pathway to existing strategies like prompt engineering"}
{"id": "2507.21084", "pdf": "https://arxiv.org/pdf/2507.21084", "abs": "https://arxiv.org/abs/2507.21084", "authors": ["Aly M. Kassem", "Zhuan Shi", "Negar Rostamzadeh", "Golnoosh Farnadi"], "title": "Reviving Your MNEME: Predicting The Side Effects of LLM Unlearning and Fine-Tuning via Sparse Model Diffing", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) are frequently fine-tuned or unlearned to adapt\nto new tasks or eliminate undesirable behaviors. While existing evaluation\nmethods assess performance after such interventions, there remains no general\napproach for detecting unintended side effects, such as unlearning biology\ncontent degrading performance on chemistry tasks, particularly when these\neffects are unpredictable or emergent. To address this issue, we introduce\nMNEME, Model diffiNg for Evaluating Mechanistic Effects, a lightweight\nframework for identifying these side effects using sparse model diffing. MNEME\ncompares base and fine-tuned models on task-agnostic data (for example, The\nPile, LMSYS-Chat-1M) without access to fine-tuning data to isolate behavioral\nshifts. Applied to five LLMs across three scenarios: WMDP knowledge unlearning,\nemergent misalignment, and benign fine-tuning, MNEME achieves up to 95 percent\naccuracy in predicting side effects, aligning with known benchmarks and\nrequiring no custom heuristics. Furthermore, we show that retraining on\nhigh-activation samples can partially reverse these effects. Our results\ndemonstrate that sparse probing and diffing offer a scalable and automated lens\ninto fine-tuning-induced model changes, providing practical tools for\nunderstanding and managing LLM behavior."}
{"id": "2507.21112", "pdf": "https://arxiv.org/pdf/2507.21112", "abs": "https://arxiv.org/abs/2507.21112", "authors": ["Panyi Dong", "Zhiyu Quan"], "title": "InsurTech innovation using natural language processing", "categories": ["cs.CL", "cs.LG", "stat.ML"], "comment": null, "summary": "With the rapid rise of InsurTech, traditional insurance companies are\nincreasingly exploring alternative data sources and advanced technologies to\nsustain their competitive edge. This paper provides both a conceptual overview\nand practical case studies of natural language processing (NLP) and its\nemerging applications within insurance operations with a focus on transforming\nraw, unstructured text into structured data suitable for actuarial analysis and\ndecision-making. Leveraging real-world alternative data provided by an\nInsurTech industry partner that enriches traditional insurance data sources, we\napply various NLP techniques to demonstrate practical use cases in the\ncommercial insurance context. These enriched, text-derived insights not only\nadd to and refine traditional rating factors for commercial insurance pricing\nbut also offer novel perspectives for assessing underlying risk by introducing\nnovel industry classifications. Through these demonstrations, we show that NLP\nis not merely a supplementary tool but a foundational element for modern,\ndata-driven insurance analytics."}
{"id": "2507.21115", "pdf": "https://arxiv.org/pdf/2507.21115", "abs": "https://arxiv.org/abs/2507.21115", "authors": ["Sven Lankester", "Manel Slokom", "Gustavo de Carvalho Bertoli", "Matias Vizcaino", "Emmanuelle Beauxis Aussalet", "Laura Hollink"], "title": "FedFlex: Federated Learning for Diverse Netflix Recommendations", "categories": ["cs.IR", "cs.AI", "cs.DC", "cs.LG"], "comment": null, "summary": "Federated learning is a decentralized approach that enables collaborative\nmodel training across multiple devices while preserving data privacy. It has\nshown significant potential in various domains, including healthcare and\npersonalized recommendation systems. However, most existing work on federated\nrecommendation systems has focused primarily on improving accuracy, with\nlimited attention to fairness and diversity. In this paper, we introduce\nFedFlex, a federated recommender system for Netflix-style TV series\nrecommendations. FedFlex integrates two state-of-the-art matrix factorization\nalgorithms for personalized fine-tuning. FedFlex also applies Maximal Marginal\nRelevance (MMR) to re-rank items and enhance diversity. We conduct extensive\nexperiments comparing recommendations generated by SVD and BPR algorithms. In a\nlive two-week user study, participants received two recommendation lists: List\nA, based on SVD or BPR, and List B, a re-ranked version emphasizing diversity.\nParticipants were asked to click on the movies they were interested in\nwatching. Our findings demonstrate that FedFlex effectively introduces diverse\ncontent, such as new genres, into recommendations without necessarily\ncompromising user satisfaction."}
{"id": "2507.21118", "pdf": "https://arxiv.org/pdf/2507.21118", "abs": "https://arxiv.org/abs/2507.21118", "authors": ["Anass El Ayady", "Maxime Devanne", "Germain Forestier", "Nour El Mawas"], "title": "Failure Risk Prediction in a MOOC: A Multivariate Time Series Analysis Approach", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": "in French language, Environnements Informatiques pour l'Apprentissage\n  Humain 2025, Jun 2025, Villeneuve d'Ascq (Lille), France", "summary": "MOOCs offer free and open access to a wide audience, but completion rates\nremain low, often due to a lack of personalized content. To address this issue,\nit is essential to predict learner performance in order to provide tailored\nfeedback. Behavioral traces-such as clicks and events-can be analyzed as time\nseries to anticipate learners' outcomes. This work compares multivariate time\nseries classification methods to identify at-risk learners at different stages\nof the course (after 5, 10 weeks, etc.). The experimental evaluation, conducted\non the Open University Learning Analytics Dataset (OULAD), focuses on three\ncourses: two in STEM and one in SHS. Preliminary results show that the\nevaluated approaches are promising for predicting learner failure in MOOCs. The\nanalysis also suggests that prediction accuracy is influenced by the amount of\nrecorded interactions, highlighting the importance of rich and diverse\nbehavioral data."}
{"id": "2507.21123", "pdf": "https://arxiv.org/pdf/2507.21123", "abs": "https://arxiv.org/abs/2507.21123", "authors": ["Mark A. Kramer", "Aanchal Mathur", "Caroline E. Adams", "Jason A. Walonoski"], "title": "Leveraging Generative AI to Enhance Synthea Module Development", "categories": ["cs.AI", "cs.LG"], "comment": "Title: Leveraging Generative AI to Enhance Synthea Module Development\n  Word Count: [Approximately 12,000 words] Figures: 3 Tables: 3 Supplementary\n  Material: Extensive appendices with prompts and disease profiles", "summary": "This paper explores the use of large language models (LLMs) to assist in the\ndevelopment of new disease modules for Synthea, an open-source synthetic health\ndata generator. Incorporating LLMs into the module development process has the\npotential to reduce development time, reduce required expertise, expand model\ndiversity, and improve the overall quality of synthetic patient data. We\ndemonstrate four ways that LLMs can support Synthea module creation: generating\na disease profile, generating a disease module from a disease profile,\nevaluating an existing Synthea module, and refining an existing module. We\nintroduce the concept of progressive refinement, which involves iteratively\nevaluating the LLM-generated module by checking its syntactic correctness and\nclinical accuracy, and then using that information to modify the module. While\nthe use of LLMs in this context shows promise, we also acknowledge the\nchallenges and limitations, such as the need for human oversight, the\nimportance of rigorous testing and validation, and the potential for\ninaccuracies in LLM-generated content. The paper concludes with recommendations\nfor future research and development to fully realize the potential of LLM-aided\nsynthetic data creation."}
{"id": "2507.21124", "pdf": "https://arxiv.org/pdf/2507.21124", "abs": "https://arxiv.org/abs/2507.21124", "authors": ["Ayan Biswas", "Terece L. Turton", "Nishath Rajiv Ranasinghe", "Shawn Jones", "Bradley Love", "William Jones", "Aric Hagberg", "Han-Wei Shen", "Nathan DeBardeleben", "Earl Lawrence"], "title": "VizGenie: Toward Self-Refining, Domain-Aware Workflows for Next-Generation Scientific Visualization", "categories": ["cs.HC", "cs.AI", "cs.GR", "cs.LG"], "comment": null, "summary": "We present VizGenie, a self-improving, agentic framework that advances\nscientific visualization through large language model (LLM) by orchestrating of\na collection of domain-specific and dynamically generated modules. Users\ninitially access core functionalities--such as threshold-based filtering, slice\nextraction, and statistical analysis--through pre-existing tools. For tasks\nbeyond this baseline, VizGenie autonomously employs LLMs to generate new\nvisualization scripts (e.g., VTK Python code), expanding its capabilities\non-demand. Each generated script undergoes automated backend validation and is\nseamlessly integrated upon successful testing, continuously enhancing the\nsystem's adaptability and robustness. A distinctive feature of VizGenie is its\nintuitive natural language interface, allowing users to issue high-level\nfeature-based queries (e.g., ``visualize the skull\"). The system leverages\nimage-based analysis and visual question answering (VQA) via fine-tuned vision\nmodels to interpret these queries precisely, bridging domain expertise and\ntechnical implementation. Additionally, users can interactively query generated\nvisualizations through VQA, facilitating deeper exploration. Reliability and\nreproducibility are further strengthened by Retrieval-Augmented Generation\n(RAG), providing context-driven responses while maintaining comprehensive\nprovenance records. Evaluations on complex volumetric datasets demonstrate\nsignificant reductions in cognitive overhead for iterative visualization tasks.\nBy integrating curated domain-specific tools with LLM-driven flexibility,\nVizGenie not only accelerates insight generation but also establishes a\nsustainable, continuously evolving visualization practice. The resulting\nplatform dynamically learns from user interactions, consistently enhancing\nsupport for feature-centric exploration and reproducible research in scientific\nvisualization."}
{"id": "2507.21125", "pdf": "https://arxiv.org/pdf/2507.21125", "abs": "https://arxiv.org/abs/2507.21125", "authors": ["Karan Mirhosseini", "Arya Aftab", "Alireza Sheikh"], "title": "RATE: An LLM-Powered Retrieval Augmented Generation Technology-Extraction Pipeline", "categories": ["cs.IR", "cs.AI", "cs.LG", "cs.SY", "eess.SY"], "comment": "9 pages, 4 figures, 1 table", "summary": "In an era of radical technology transformations, technology maps play a\ncrucial role in enhancing decision making. These maps heavily rely on automated\nmethods of technology extraction. This paper introduces Retrieval Augmented\nTechnology Extraction (RATE), a Large Language Model (LLM) based pipeline for\nautomated technology extraction from scientific literature. RATE combines\nRetrieval Augmented Generation (RAG) with multi-definition LLM-based\nvalidation. This hybrid method results in high recall in candidate generation\nalongside with high precision in candidate filtering. While the pipeline is\ndesigned to be general and widely applicable, we demonstrate its use on 678\nresearch articles focused on Brain-Computer Interfaces (BCIs) and Extended\nReality (XR) as a case study. Consequently, The validated technology terms by\nRATE were mapped into a co-occurrence network, revealing thematic clusters and\nstructural features of the research landscape. For the purpose of evaluation, a\ngold standard dataset of technologies in 70 selected random articles had been\ncurated by the experts. In addition, a technology extraction model based on\nBidirectional Encoder Representations of Transformers (BERT) was used as a\ncomparative method. RATE achieved F1-score of 91.27%, Significantly\noutperforming BERT with F1-score of 53.73%. Our findings highlight the promise\nof definition-driven LLM methods for technology extraction and mapping. They\nalso offer new insights into emerging trends within the BCI-XR field. The\nsource code is available https://github.com/AryaAftab/RATE"}
{"id": "2507.21132", "pdf": "https://arxiv.org/pdf/2507.21132", "abs": "https://arxiv.org/abs/2507.21132", "authors": ["Joshua Adrian Cahyono", "Saran Subramanian"], "title": "Can You Trust an LLM with Your Life-Changing Decision? An Investigation into AI High-Stakes Responses", "categories": ["cs.AI", "cs.CY", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly consulted for high-stakes life\nadvice, yet they lack standard safeguards against providing confident but\nmisguided responses. This creates risks of sycophancy and over-confidence. This\npaper investigates these failure modes through three experiments: (1) a\nmultiple-choice evaluation to measure model stability against user pressure;\n(2) a free-response analysis using a novel safety typology and an LLM Judge;\nand (3) a mechanistic interpretability experiment to steer model behavior by\nmanipulating a \"high-stakes\" activation vector. Our results show that while\nsome models exhibit sycophancy, others like o4-mini remain robust.\nTop-performing models achieve high safety scores by frequently asking\nclarifying questions, a key feature of a safe, inquisitive approach, rather\nthan issuing prescriptive advice. Furthermore, we demonstrate that a model's\ncautiousness can be directly controlled via activation steering, suggesting a\nnew path for safety alignment. These findings underscore the need for nuanced,\nmulti-faceted benchmarks to ensure LLMs can be trusted with life-changing\ndecisions."}
{"id": "2507.21134", "pdf": "https://arxiv.org/pdf/2507.21134", "abs": "https://arxiv.org/abs/2507.21134", "authors": ["Zheng Hui", "Yijiang River Dong", "Ehsan Shareghi", "Nigel Collier"], "title": "TRIDENT: Benchmarking LLM Safety in Finance, Medicine, and Law", "categories": ["cs.CL", "cs.CY", "cs.LG"], "comment": null, "summary": "As large language models (LLMs) are increasingly deployed in high-risk\ndomains such as law, finance, and medicine, systematically evaluating their\ndomain-specific safety and compliance becomes critical. While prior work has\nlargely focused on improving LLM performance in these domains, it has often\nneglected the evaluation of domain-specific safety risks. To bridge this gap,\nwe first define domain-specific safety principles for LLMs based on the AMA\nPrinciples of Medical Ethics, the ABA Model Rules of Professional Conduct, and\nthe CFA Institute Code of Ethics. Building on this foundation, we introduce\nTrident-Bench, a benchmark specifically targeting LLM safety in the legal,\nfinancial, and medical domains. We evaluated 19 general-purpose and\ndomain-specialized models on Trident-Bench and show that it effectively reveals\nkey safety gaps -- strong generalist models (e.g., GPT, Gemini) can meet basic\nexpectations, whereas domain-specialized models often struggle with subtle\nethical nuances. This highlights an urgent need for finer-grained\ndomain-specific safety improvements. By introducing Trident-Bench, our work\nprovides one of the first systematic resources for studying LLM safety in law\nand finance, and lays the groundwork for future research aimed at reducing the\nsafety risks of deploying LLMs in professionally regulated fields. Code and\nbenchmark will be released at: https://github.com/zackhuiiiii/TRIDENT"}
{"id": "2507.21138", "pdf": "https://arxiv.org/pdf/2507.21138", "abs": "https://arxiv.org/abs/2507.21138", "authors": ["Oleg Atamanenko", "Anna Chalova", "Joseph Coombes", "Nikki Cope", "Phillip Dang", "Zhifeng Deng", "Jimmy Du", "Michael Ermolenko", "Feifan Fan", "Yufei Feng", "Cheryl Fichter", "Pavel Filimonov", "Louis Fischer", "Kylan Gibbs", "Valeria Gusarova", "Pavel Karpik", "Andreas Assad Kottner", "Ian Lee", "Oliver Louie", "Jasmine Mai", "Mikhail Mamontov", "Suri Mao", "Nurullah Morshed", "Igor Poletaev", "Florin Radu", "Dmytro Semernia", "Evgenii Shingarev", "Vikram Sivaraja", "Peter Skirko", "Rinat Takhautdinov", "Robert Villahermosa", "Jean Wang"], "title": "TTS-1 Technical Report", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SD", "eess.AS"], "comment": "20 pages, 10 figures. For associated modeling and training code, see\n  https://github.com/inworld-ai/tts", "summary": "We introduce Inworld TTS-1, a set of two Transformer-based autoregressive\ntext-to-speech (TTS) models. Our largest model, TTS-1-Max, has 8.8B parameters\nand is designed for utmost quality and expressiveness in demanding\napplications. TTS-1 is our most efficient model, with 1.6B parameters, built\nfor real-time speech synthesis and on-device use cases. By scaling train-time\ncompute and applying a sequential process of pre-training, fine-tuning, and\nRL-alignment of the speech-language model (SpeechLM) component, both models\nachieve state-of-the-art performance on a variety of benchmarks, demonstrating\nexceptional quality relying purely on in-context learning of the speaker's\nvoice. Inworld TTS-1 and TTS-1-Max can generate high-resolution 48 kHz speech\nwith low latency, and support 11 languages with fine-grained emotional control\nand non-verbal vocalizations through audio markups. We additionally open-source\nour training and modeling code under an MIT license."}
{"id": "2507.21156", "pdf": "https://arxiv.org/pdf/2507.21156", "abs": "https://arxiv.org/abs/2507.21156", "authors": ["Kunal Kawadkar"], "title": "Comparative Analysis of Vision Transformers and Convolutional Neural Networks for Medical Image Classification", "categories": ["eess.IV", "cs.CV", "cs.LG", "I.2.10; I.4.8"], "comment": "9 pages, 8 figures, 3 tables. Submitted to IEEE Access", "summary": "The emergence of Vision Transformers (ViTs) has revolutionized computer\nvision, yet their effectiveness compared to traditional Convolutional Neural\nNetworks (CNNs) in medical imaging remains under-explored. This study presents\na comprehensive comparative analysis of CNN and ViT architectures across three\ncritical medical imaging tasks: chest X-ray pneumonia detection, brain tumor\nclassification, and skin cancer melanoma detection. We evaluated four\nstate-of-the-art models - ResNet-50, EfficientNet-B0, ViT-Base, and DeiT-Small\n- across datasets totaling 8,469 medical images. Our results demonstrate\ntask-specific model advantages: ResNet-50 achieved 98.37% accuracy on chest\nX-ray classification, DeiT-Small excelled at brain tumor detection with 92.16%\naccuracy, and EfficientNet-B0 led skin cancer classification at 81.84%\naccuracy. These findings provide crucial insights for practitioners selecting\narchitectures for medical AI applications, highlighting the importance of\ntask-specific architecture selection in clinical decision support systems."}
{"id": "2507.21159", "pdf": "https://arxiv.org/pdf/2507.21159", "abs": "https://arxiv.org/abs/2507.21159", "authors": ["Zhihao Peng", "Liuxin Bao", "Shengyuan Liu", "Yixuan Yuan"], "title": "Adaptive Cluster Collaborativeness Boosts LLMs Medical Decision Support Capacity", "categories": ["cs.AI", "cs.LG", "cs.MA"], "comment": null, "summary": "The collaborativeness of large language models (LLMs) has proven effective in\nnatural language processing systems, holding considerable promise for\nhealthcare development. However, it lacks explicit component selection rules,\nnecessitating human intervention or clinical-specific validation. Moreover,\nexisting architectures heavily rely on a predefined LLM cluster, where partial\nLLMs underperform in medical decision support scenarios, invalidating the\ncollaborativeness of LLMs. To this end, we propose an adaptive cluster\ncollaborativeness methodology involving self-diversity and cross-consistency\nmaximization mechanisms to boost LLMs medical decision support capacity. For\nthe self-diversity, we calculate the fuzzy matching value of pairwise outputs\nwithin an LLM as its self-diversity value, subsequently prioritizing LLMs with\nhigh self-diversity values as cluster components in a training-free manner. For\nthe cross-consistency, we first measure cross-consistency values between the\nLLM with the highest self-diversity value and others, and then gradually mask\nout the LLM having the lowest cross-consistency value to eliminate the\npotential inconsistent output during the collaborative propagation. Extensive\nexperiments on two specialized medical datasets, NEJMQA and MMLU-Pro-health,\ndemonstrate the effectiveness of our method across physician-oriented\nspecialties. For example, on NEJMQA, our method achieves the accuracy rate up\nto the publicly official passing score across all disciplines, especially\nachieving ACC of 65.47\\% compared to the 56.12\\% achieved by GPT-4 on the\nObstetrics and Gynecology discipline."}
{"id": "2507.21161", "pdf": "https://arxiv.org/pdf/2507.21161", "abs": "https://arxiv.org/abs/2507.21161", "authors": ["Pallavi Zambare", "Venkata Nikhil Thanikella", "Ying Liu"], "title": "Seeing Beyond Frames: Zero-Shot Pedestrian Intention Prediction with Raw Temporal Video and Multimodal Cues", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted in IEEE 3rd International Conference on Artificial\n  Intelligence, Blockchain, and Internet of Things (AIBThings 2025)", "summary": "Pedestrian intention prediction is essential for autonomous driving in\ncomplex urban environments. Conventional approaches depend on supervised\nlearning over frame sequences and require extensive retraining to adapt to new\nscenarios. Here, we introduce BF-PIP (Beyond Frames Pedestrian Intention\nPrediction), a zero-shot approach built upon Gemini 2.5 Pro. It infers crossing\nintentions directly from short, continuous video clips enriched with structured\nJAAD metadata. In contrast to GPT-4V based methods that operate on discrete\nframes, BF-PIP processes uninterrupted temporal clips. It also incorporates\nbounding-box annotations and ego-vehicle speed via specialized multimodal\nprompts. Without any additional training, BF-PIP achieves 73% prediction\naccuracy, outperforming a GPT-4V baseline by 18 %. These findings illustrate\nthat combining temporal video inputs with contextual cues enhances\nspatiotemporal perception and improves intent inference under ambiguous\nconditions. This approach paves the way for agile, retraining-free perception\nmodule in intelligent transportation system."}
{"id": "2507.21162", "pdf": "https://arxiv.org/pdf/2507.21162", "abs": "https://arxiv.org/abs/2507.21162", "authors": ["Xu Yang", "Chenhui Lin", "Yue Yang", "Qi Wang", "Haotian Liu", "Haizhou Hua", "Wenchuan Wu"], "title": "Large Language Model Powered Automated Modeling and Optimization of Active Distribution Network Dispatch Problems", "categories": ["cs.AI", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "The increasing penetration of distributed energy resources into active\ndistribution networks (ADNs) has made effective ADN dispatch imperative.\nHowever, the numerous newly-integrated ADN operators, such as distribution\nsystem aggregators, virtual power plant managers, and end prosumers, often lack\nspecialized expertise in power system operation, modeling, optimization, and\nprogramming. This knowledge gap renders reliance on human experts both costly\nand time-intensive. To address this challenge and enable intelligent, flexible\nADN dispatch, this paper proposes a large language model (LLM) powered\nautomated modeling and optimization approach. First, the ADN dispatch problems\nare decomposed into sequential stages, and a multi-LLM coordination\narchitecture is designed. This framework comprises an Information Extractor, a\nProblem Formulator, and a Code Programmer, tasked with information retrieval,\noptimization problem formulation, and code implementation, respectively.\nAfterwards, tailored refinement techniques are developed for each LLM agent,\ngreatly improving the accuracy and reliability of generated content. The\nproposed approach features a user-centric interface that enables ADN operators\nto derive dispatch strategies via simple natural language queries, eliminating\ntechnical barriers and increasing efficiency. Comprehensive comparisons and\nend-to-end demonstrations on various test cases validate the effectiveness of\nthe proposed architecture and methods."}
{"id": "2507.21163", "pdf": "https://arxiv.org/pdf/2507.21163", "abs": "https://arxiv.org/abs/2507.21163", "authors": ["Ruiyang Zhao", "Bingbing Zhu", "Chuxuan Tong", "Xiaoyi Zhou", "Xi Zheng"], "title": "Generating Adversarial Point Clouds Using Diffusion Model", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "Adversarial attack methods for 3D point cloud classification reveal the\nvulnerabilities of point cloud recognition models. This vulnerability could\nlead to safety risks in critical applications that use deep learning models,\nsuch as autonomous vehicles. To uncover the deficiencies of these models,\nresearchers can evaluate their security through adversarial attacks. However,\nmost existing adversarial attack methods are based on white-box attacks. While\nthese methods achieve high attack success rates and imperceptibility, their\napplicability in real-world scenarios is limited. Black-box attacks, which are\nmore meaningful in real-world scenarios, often yield poor results. This paper\nproposes a novel black-box adversarial example generation method that utilizes\na diffusion model to improve the attack success rate and imperceptibility in\nthe black-box setting, without relying on the internal information of the point\ncloud classification model to generate adversarial samples. We use a 3D\ndiffusion model to use the compressed features of the point cloud as prior\nknowledge to guide the reverse diffusion process to add adversarial points to\nclean examples. Subsequently, its reverse process is employed to transform the\ndistribution of other categories into adversarial points, which are then added\nto the point cloud."}
{"id": "2507.21168", "pdf": "https://arxiv.org/pdf/2507.21168", "abs": "https://arxiv.org/abs/2507.21168", "authors": ["Rafael Rosales", "Santiago Miret"], "title": "Diverse LLMs or Diverse Question Interpretations? That is the Ensembling Question", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T50", "I.2.7; I.2.0"], "comment": null, "summary": "Effectively leveraging diversity has been shown to improve performance for\nvarious machine learning models, including large language models (LLMs).\nHowever, determining the most effective way of using diversity remains a\nchallenge. In this work, we compare two diversity approaches for answering\nbinary questions using LLMs: model diversity, which relies on multiple models\nanswering the same question, and question interpretation diversity, which\nrelies on using the same model to answer the same question framed in different\nways. For both cases, we apply majority voting as the ensemble consensus\nheuristic to determine the final answer. Our experiments on boolq, strategyqa,\nand pubmedqa show that question interpretation diversity consistently leads to\nbetter ensemble accuracy compared to model diversity. Furthermore, our analysis\nof GPT and LLaMa shows that model diversity typically produces results between\nthe best and the worst ensemble members without clear improvement."}
{"id": "2507.21177", "pdf": "https://arxiv.org/pdf/2507.21177", "abs": "https://arxiv.org/abs/2507.21177", "authors": ["Xinhai Yan", "Libing Wu", "Zhuangzhuang Zhang", "Bingyi Liu", "Lijuan Huo", "Jing Wang"], "title": "FedBAP: Backdoor Defense via Benign Adversarial Perturbation in Federated Learning", "categories": ["cs.CR", "cs.LG"], "comment": "Accepted to ACM Multimedia 2025", "summary": "Federated Learning (FL) enables collaborative model training while preserving\ndata privacy, but it is highly vulnerable to backdoor attacks. Most existing\ndefense methods in FL have limited effectiveness due to their neglect of the\nmodel's over-reliance on backdoor triggers, particularly as the proportion of\nmalicious clients increases. In this paper, we propose FedBAP, a novel defense\nframework for mitigating backdoor attacks in FL by reducing the model's\nreliance on backdoor triggers. Specifically, first, we propose a perturbed\ntrigger generation mechanism that creates perturbation triggers precisely\nmatching backdoor triggers in location and size, ensuring strong influence on\nmodel outputs. Second, we utilize these perturbation triggers to generate\nbenign adversarial perturbations that disrupt the model's dependence on\nbackdoor triggers while forcing it to learn more robust decision boundaries.\nFinally, we design an adaptive scaling mechanism to dynamically adjust\nperturbation intensity, effectively balancing defense strength and model\nperformance. The experimental results demonstrate that FedBAP reduces the\nattack success rates by 0.22%-5.34%, 0.48%-6.34%, and 97.22%-97.6% under three\ntypes of backdoor attacks, respectively. In particular, FedBAP demonstrates\noutstanding performance against novel backdoor attacks."}
{"id": "2507.21186", "pdf": "https://arxiv.org/pdf/2507.21186", "abs": "https://arxiv.org/abs/2507.21186", "authors": ["Sungmin Han", "Jeonghyun Lee", "Sangkyun Lee"], "title": "Contrast-CAT: Contrasting Activations for Enhanced Interpretability in Transformer-based Text Classifiers", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Transformers have profoundly influenced AI research, but explaining their\ndecisions remains challenging -- even for relatively simpler tasks such as\nclassification -- which hinders trust and safe deployment in real-world\napplications. Although activation-based attribution methods effectively explain\ntransformer-based text classification models, our findings reveal that these\nmethods can be undermined by class-irrelevant features within activations,\nleading to less reliable interpretations. To address this limitation, we\npropose Contrast-CAT, a novel activation contrast-based attribution method that\nrefines token-level attributions by filtering out class-irrelevant features. By\ncontrasting the activations of an input sequence with reference activations,\nContrast-CAT generates clearer and more faithful attribution maps. Experimental\nresults across various datasets and models confirm that Contrast-CAT\nconsistently outperforms state-of-the-art methods. Notably, under the MoRF\nsetting, it achieves average improvements of x1.30 in AOPC and x2.25 in LOdds\nover the most competing methods, demonstrating its effectiveness in enhancing\ninterpretability for transformer-based text classification."}
{"id": "2507.21193", "pdf": "https://arxiv.org/pdf/2507.21193", "abs": "https://arxiv.org/abs/2507.21193", "authors": ["Sotiris Chatzimiltis", "Mohammad Shojafar", "Mahdi Boloursaz Mashhadi", "Rahim Tafazolli"], "title": "Interpretable Anomaly-Based DDoS Detection in AI-RAN with XAI and LLMs", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "Next generation Radio Access Networks (RANs) introduce programmability,\nintelligence, and near real-time control through intelligent controllers,\nenabling enhanced security within the RAN and across broader 5G/6G\ninfrastructures. This paper presents a comprehensive survey highlighting\nopportunities, challenges, and research gaps for Large Language Models\n(LLMs)-assisted explainable (XAI) intrusion detection (IDS) for secure future\nRAN environments. Motivated by this, we propose an LLM interpretable\nanomaly-based detection system for distributed denial-of-service (DDoS) attacks\nusing multivariate time series key performance measures (KPMs), extracted from\nE2 nodes, within the Near Real-Time RAN Intelligent Controller (Near-RT RIC).\nAn LSTM-based model is trained to identify malicious User Equipment (UE)\nbehavior based on these KPMs. To enhance transparency, we apply post-hoc local\nexplainability methods such as LIME and SHAP to interpret individual\npredictions. Furthermore, LLMs are employed to convert technical explanations\ninto natural-language insights accessible to non-expert users. Experimental\nresults on real 5G network KPMs demonstrate that our framework achieves high\ndetection accuracy (F1-score > 0.96) while delivering actionable and\ninterpretable outputs."}
{"id": "2507.21200", "pdf": "https://arxiv.org/pdf/2507.21200", "abs": "https://arxiv.org/abs/2507.21200", "authors": ["Soren Pedersen", "Sanyam Jain", "Mikkel Chavez", "Viktor Ladehoff", "Bruna Neves de Freitas", "Ruben Pauwels"], "title": "PanoGAN A Deep Generative Model for Panoramic Dental Radiographs", "categories": ["cs.CV", "cs.ET", "cs.LG", "eess.IV"], "comment": null, "summary": "This paper presents the development of a generative adversarial network (GAN)\nfor synthesizing dental panoramic radiographs. Although exploratory in nature,\nthe study aims to address the scarcity of data in dental research and\neducation. We trained a deep convolutional GAN (DCGAN) using a Wasserstein loss\nwith gradient penalty (WGANGP) on a dataset of 2322 radiographs of varying\nquality. The focus was on the dentoalveolar regions, other anatomical\nstructures were cropped out. Extensive preprocessing and data cleaning were\nperformed to standardize the inputs while preserving anatomical variability. We\nexplored four candidate models by varying critic iterations, feature depth, and\nthe use of denoising prior to training. A clinical expert evaluated the\ngenerated radiographs based on anatomical visibility and realism, using a\n5-point scale (1 very poor 5 excellent). Most images showed moderate anatomical\ndepiction, although some were degraded by artifacts. A trade-off was observed\nthe model trained on non-denoised data yielded finer details especially in\nstructures like the mandibular canal and trabecular bone, while a model trained\non denoised data offered superior overall image clarity and sharpness. These\nfindings provide a foundation for future work on GAN-based methods in dental\nimaging."}
{"id": "2507.21202", "pdf": "https://arxiv.org/pdf/2507.21202", "abs": "https://arxiv.org/abs/2507.21202", "authors": ["Cameron Churchwell", "Minje Kim", "Paris Smaragdis"], "title": "Combolutional Neural Networks", "categories": ["cs.SD", "cs.LG", "eess.AS"], "comment": "4 pages, 3 figures, accepted to WASPAA 2025", "summary": "Selecting appropriate inductive biases is an essential step in the design of\nmachine learning models, especially when working with audio, where even short\nclips may contain millions of samples. To this end, we propose the\ncombolutional layer: a learned-delay IIR comb filter and fused envelope\ndetector, which extracts harmonic features in the time domain. We demonstrate\nthe efficacy of the combolutional layer on three information retrieval tasks,\nevaluate its computational cost relative to other audio frontends, and provide\nefficient implementations for training. We find that the combolutional layer is\nan effective replacement for convolutional layers in audio tasks where precise\nharmonic analysis is important, e.g., piano transcription, speaker\nclassification, and key detection. Additionally, the combolutional layer has\nseveral other key benefits over existing frontends, namely: low parameter\ncount, efficient CPU inference, strictly real-valued computations, and improved\ninterpretability."}
{"id": "2507.21203", "pdf": "https://arxiv.org/pdf/2507.21203", "abs": "https://arxiv.org/abs/2507.21203", "authors": ["Marcello D'Orazio"], "title": "An empirical comparison of some outlier detection methods with longitudinal data", "categories": ["stat.ME", "cs.LG", "stat.AP"], "comment": null, "summary": "This note investigates the problem of detecting outliers in longitudinal\ndata. It compares well-known methods used in official statistics with proposals\nfrom the fields of data mining and machine learning that are based on the\ndistance between observations or binary partitioning trees. This is achieved by\napplying the methods to panel survey data related to different types of\nstatistical units. Traditional methods are quite simple, enabling the direct\nidentification of potential outliers, but they require specific assumptions. In\ncontrast, recent methods provide only a score whose magnitude is directly\nrelated to the likelihood of an outlier being present. All the methods require\nthe user to set a number of tuning parameters. However, the most recent methods\nare more flexible and sometimes more effective than traditional methods. In\naddition, these methods can be applied to multidimensional data."}
{"id": "2507.21206", "pdf": "https://arxiv.org/pdf/2507.21206", "abs": "https://arxiv.org/abs/2507.21206", "authors": ["Yingxuan Yang", "Mulei Ma", "Yuxuan Huang", "Huacan Chai", "Chenyu Gong", "Haoran Geng", "Yuanjian Zhou", "Ying Wen", "Meng Fang", "Muhao Chen", "Shangding Gu", "Ming Jin", "Costas Spanos", "Yang Yang", "Pieter Abbeel", "Dawn Song", "Weinan Zhang", "Jun Wang"], "title": "Agentic Web: Weaving the Next Web with AI Agents", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "The emergence of AI agents powered by large language models (LLMs) marks a\npivotal shift toward the Agentic Web, a new phase of the internet defined by\nautonomous, goal-driven interactions. In this paradigm, agents interact\ndirectly with one another to plan, coordinate, and execute complex tasks on\nbehalf of users. This transition from human-driven to machine-to-machine\ninteraction allows intent to be delegated, relieving users from routine digital\noperations and enabling a more interactive, automated web experience. In this\npaper, we present a structured framework for understanding and building the\nAgentic Web. We trace its evolution from the PC and Mobile Web eras and\nidentify the core technological foundations that support this shift. Central to\nour framework is a conceptual model consisting of three key dimensions:\nintelligence, interaction, and economics. These dimensions collectively enable\nthe capabilities of AI agents, such as retrieval, recommendation, planning, and\ncollaboration. We analyze the architectural and infrastructural challenges\ninvolved in creating scalable agentic systems, including communication\nprotocols, orchestration strategies, and emerging paradigms such as the Agent\nAttention Economy. We conclude by discussing the potential applications,\nsocietal risks, and governance issues posed by agentic systems, and outline\nresearch directions for developing open, secure, and intelligent ecosystems\nshaped by both human intent and autonomous agent behavior. A continuously\nupdated collection of relevant studies for agentic web is available at:\nhttps://github.com/SafeRL-Lab/agentic-web."}
{"id": "2507.21222", "pdf": "https://arxiv.org/pdf/2507.21222", "abs": "https://arxiv.org/abs/2507.21222", "authors": ["Djamil Lakhdar-Hamina", "Xingxin Liu", "Richard Barney", "Sarah H. Miller", "Alaina M. Green", "Norbert M. Linke", "Victor Galitski"], "title": "Benchmarking a Tunable Quantum Neural Network on Trapped-Ion and Superconducting Hardware", "categories": ["quant-ph", "cond-mat.dis-nn", "cs.LG"], "comment": "6 pages, 3 figures", "summary": "We implement a quantum generalization of a neural network on trapped-ion and\nIBM superconducting quantum computers to classify MNIST images, a common\nbenchmark in computer vision. The network feedforward involves qubit rotations\nwhose angles depend on the results of measurements in the previous layer. The\nnetwork is trained via simulation, but inference is performed experimentally on\nquantum hardware. The classical-to-quantum correspondence is controlled by an\ninterpolation parameter, $a$, which is zero in the classical limit. Increasing\n$a$ introduces quantum uncertainty into the measurements, which is shown to\nimprove network performance at moderate values of the interpolation parameter.\nWe then focus on particular images that fail to be classified by a classical\nneural network but are detected correctly in the quantum network. For such\nborderline cases, we observe strong deviations from the simulated behavior. We\nattribute this to physical noise, which causes the output to fluctuate between\nnearby minima of the classification energy landscape. Such strong sensitivity\nto physical noise is absent for clear images. We further benchmark physical\nnoise by inserting additional single-qubit and two-qubit gate pairs into the\nneural network circuits. Our work provides a springboard toward more complex\nquantum neural networks on current devices: while the approach is rooted in\nstandard classical machine learning, scaling up such networks may prove\nclassically non-simulable and could offer a route to near-term quantum\nadvantage."}
{"id": "2507.21225", "pdf": "https://arxiv.org/pdf/2507.21225", "abs": "https://arxiv.org/abs/2507.21225", "authors": ["Annan Zhang", "Miguel Flores-Acton", "Andy Yu", "Anshul Gupta", "Maggie Yao", "Daniela Rus"], "title": "Fluidically Innervated Lattices Make Versatile and Durable Tactile Sensors", "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY"], "comment": "Accepted for publication in the proceedings of the 2025 International\n  Symposium on Experimental Robotics (ISER)", "summary": "Tactile sensing plays a fundamental role in enabling robots to navigate\ndynamic and unstructured environments, particularly in applications such as\ndelicate object manipulation, surface exploration, and human-robot interaction.\nIn this paper, we introduce a passive soft robotic fingertip with integrated\ntactile sensing, fabricated using a 3D-printed elastomer lattice with embedded\nair channels. This sensorization approach, termed fluidic innervation,\ntransforms the lattice into a tactile sensor by detecting pressure changes\nwithin sealed air channels, providing a simple yet robust solution to tactile\nsensing in robotics. Unlike conventional methods that rely on complex materials\nor designs, fluidic innervation offers a simple, scalable, single-material\nfabrication process. We characterize the sensors' response, develop a geometric\nmodel to estimate tip displacement, and train a neural network to accurately\npredict contact location and contact force. Additionally, we integrate the\nfingertip with an admittance controller to emulate spring-like behavior,\ndemonstrate its capability for environment exploration through tactile\nfeedback, and validate its durability under high impact and cyclic loading\nconditions. This tactile sensing technique offers advantages in terms of\nsimplicity, adaptability, and durability and opens up new opportunities for\nversatile robotic manipulation."}
{"id": "2507.21245", "pdf": "https://arxiv.org/pdf/2507.21245", "abs": "https://arxiv.org/abs/2507.21245", "authors": ["Gershy Ben-Arie", "Daniel Engelsman", "Rotem Dror", "Itzik Klein"], "title": "Diffusion Denoiser-Aided Gyrocompassing", "categories": ["cs.RO", "cs.LG"], "comment": "8 pages, 8 figures", "summary": "An accurate initial heading angle is essential for efficient and safe\nnavigation across diverse domains. Unlike magnetometers, gyroscopes can provide\naccurate heading reference independent of the magnetic disturbances in a\nprocess known as gyrocompassing. Yet, accurate and timely gyrocompassing, using\nlow-cost gyroscopes, remains a significant challenge in scenarios where\nexternal navigation aids are unavailable. Such challenges are commonly\naddressed in real-world applications such as autonomous vehicles, where size,\nweight, and power limitations restrict sensor quality, and noisy measurements\nseverely degrade gyrocompassing performance. To cope with this challenge, we\npropose a novel diffusion denoiser-aided gyrocompass approach. It integrates a\ndiffusion-based denoising framework with an enhanced learning-based heading\nestimation model. The diffusion denoiser processes raw inertial sensor signals\nbefore input to the deep learning model, resulting in accurate gyrocompassing.\nExperiments using both simulated and real sensor data demonstrate that our\nproposed approach improves gyrocompassing accuracy by 26% compared to\nmodel-based gyrocompassing and by 15% compared to other learning-driven\napproaches. This advancement holds particular significance for ensuring\naccurate and robust navigation in autonomous platforms that incorporate\nlow-cost gyroscopes within their navigation systems."}
{"id": "2507.21265", "pdf": "https://arxiv.org/pdf/2507.21265", "abs": "https://arxiv.org/abs/2507.21265", "authors": ["Tetiana Orlova", "Amaranta Membrillo Solis", "Hayley R. O. Sohn", "Tristan Madeleine", "Giampaolo D'Alessandro", "Ivan I. Smalyukh", "Malgosia Kaczmarek", "Jacek Brodzki"], "title": "Multiscale geometrical and topological learning in the analysis of soft matter collective dynamics", "categories": ["cond-mat.soft", "cond-mat.mtrl-sci", "cs.LG"], "comment": "13 pages, 6 figures", "summary": "Understanding the behavior and evolution of a dynamical many-body system by\nanalyzing patterns in their experimentally captured images is a promising\nmethod relevant for a variety of living and non-living self-assembled systems.\nThe arrays of moving liquid crystal skyrmions studied here are a representative\nexample of hierarchically organized materials that exhibit complex\nspatiotemporal dynamics driven by multiscale processes. Joint geometric and\ntopological data analysis (TDA) offers a powerful framework for investigating\nsuch systems by capturing the underlying structure of the data at multiple\nscales. In the TDA approach, we introduce the $\\Psi$-function, a robust\nnumerical topological descriptor related to both the spatiotemporal changes in\nthe size and shape of individual topological solitons and the emergence of\nregions with their different spatial organization. The geometric method based\non the analysis of vector fields generated from images of skyrmion ensembles\noffers insights into the nonlinear physical mechanisms of the system's response\nto external stimuli and provides a basis for comparison with theoretical\npredictions. The methodology presented here is very general and can provide a\ncharacterization of system behavior both at the level of individual\npattern-forming agents and as a whole, allowing one to relate the results of\nimage data analysis to processes occurring in a physical, chemical, or\nbiological system in the real world."}
{"id": "2507.21269", "pdf": "https://arxiv.org/pdf/2507.21269", "abs": "https://arxiv.org/abs/2507.21269", "authors": ["Patrick Chatain", "Michael Rizvi-Martel", "Guillaume Rabusseau", "Adam Oberman"], "title": "Numerical PDE solvers outperform neural PDE solvers", "categories": ["math.NA", "cs.LG", "cs.NA", "35R30 (Primary) 65M06 65M32 65C20 68T07 (Secondary)"], "comment": "17 pages, 7 figures", "summary": "We present DeepFDM, a differentiable finite-difference framework for learning\nspatially varying coefficients in time-dependent partial differential equations\n(PDEs). By embedding a classical forward-Euler discretization into a\nconvolutional architecture, DeepFDM enforces stability and first-order\nconvergence via CFL-compliant coefficient parameterizations. Model weights\ncorrespond directly to PDE coefficients, yielding an interpretable\ninverse-problem formulation. We evaluate DeepFDM on a benchmark suite of scalar\nPDEs: advection, diffusion, advection-diffusion, reaction-diffusion and\ninhomogeneous Burgers' equations-in one, two and three spatial dimensions. In\nboth in-distribution and out-of-distribution tests (quantified by the Hellinger\ndistance between coefficient priors), DeepFDM attains normalized mean-squared\nerrors one to two orders of magnitude smaller than Fourier Neural Operators,\nU-Nets and ResNets; requires 10-20X fewer training epochs; and uses 5-50X fewer\nparameters. Moreover, recovered coefficient fields accurately match\nground-truth parameters. These results establish DeepFDM as a robust,\nefficient, and transparent baseline for data-driven solution and identification\nof parametric PDEs."}
{"id": "2507.21270", "pdf": "https://arxiv.org/pdf/2507.21270", "abs": "https://arxiv.org/abs/2507.21270", "authors": ["Matthijs Mars", "Tob√≠as I. Liaudat", "Jessica J. Whitney", "Marta M. Betcke", "Jason D. McEwen"], "title": "Generative imaging for radio interferometry with fast uncertainty quantification", "categories": ["astro-ph.IM", "cs.LG"], "comment": null, "summary": "With the rise of large radio interferometric telescopes, particularly the\nSKA, there is a growing demand for computationally efficient image\nreconstruction techniques. Existing reconstruction methods, such as the CLEAN\nalgorithm or proximal optimisation approaches, are iterative in nature,\nnecessitating a large amount of compute. These methods either provide no\nuncertainty quantification or require large computational overhead to do so.\nLearned reconstruction methods have shown promise in providing efficient and\nhigh quality reconstruction. In this article we explore the use of generative\nneural networks that enable efficient approximate sampling of the posterior\ndistribution for high quality reconstructions with uncertainty quantification.\nOur RI-GAN framework, builds on the regularised conditional generative\nadversarial network (rcGAN) framework by integrating a gradient U-Net (GU-Net)\narchitecture - a hybrid reconstruction model that embeds the measurement\noperator directly into the network. This framework uses Wasserstein GANs to\nimprove training stability in combination with regularisation terms that combat\nmode collapse, which are typical problems for conditional GANs. This approach\ntakes as input the dirty image and the point spread function (PSF) of the\nobservation and provides efficient, high-quality image reconstructions that are\nrobust to varying visibility coverages, generalises to images with an increased\ndynamic range, and provides informative uncertainty quantification. Our methods\nprovide a significant step toward computationally efficient, scalable, and\nuncertainty-aware imaging for next-generation radio telescopes."}
{"id": "2507.21330", "pdf": "https://arxiv.org/pdf/2507.21330", "abs": "https://arxiv.org/abs/2507.21330", "authors": ["Ananya Anand"], "title": "Predicting VBAC Outcomes from U.S. Natality Data using Deep and Classical Machine Learning Models", "categories": ["stat.AP", "cs.LG"], "comment": "12 pages, 10 figures, 1 table", "summary": "Accurately predicting the outcome of a trial of labor after cesarean (TOLAC)\nis essential for guiding prenatal counseling and minimizing delivery-related\nrisks. This study presents supervised machine learning models for predicting\nvaginal birth after cesarean (VBAC) using 643,029 TOLAC cases from the CDC\nWONDER Natality dataset (2017-2023). After filtering for singleton births with\none or two prior cesareans and complete data across 47 prenatal-period\nfeatures, three classifiers were trained: logistic regression, XGBoost, and a\nmultilayer perceptron (MLP). The MLP achieved the highest performance with an\nAUC of 0.7287, followed closely by XGBoost (AUC = 0.727), both surpassing the\nlogistic regression baseline (AUC = 0.709). To address class imbalance, class\nweighting was applied to the MLP, and a custom loss function was implemented in\nXGBoost. Evaluation metrics included ROC curves, confusion matrices, and\nprecision-recall analysis. Logistic regression coefficients highlighted\nmaternal BMI, education, parity, comorbidities, and prenatal care indicators as\nkey predictors. Overall, the results demonstrate that routinely collected,\nearly-pregnancy variables can support scalable and moderately high-performing\nVBAC prediction models. These models offer potential utility in clinical\ndecision support, particularly in settings lacking access to specialized\nintrapartum data."}
{"id": "2507.21334", "pdf": "https://arxiv.org/pdf/2507.21334", "abs": "https://arxiv.org/abs/2507.21334", "authors": ["Zhanhong Cheng", "Lingqian Hu", "Yuheng Bu", "Yuqi Zhou", "Shenhao Wang"], "title": "Graph neural networks for residential location choice: connection to classical logit models", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Researchers have adopted deep learning for classical discrete choice analysis\nas it can capture complex feature relationships and achieve higher predictive\nperformance. However, the existing deep learning approaches cannot explicitly\ncapture the relationship among choice alternatives, which has been a\nlong-lasting focus in classical discrete choice models. To address the gap,\nthis paper introduces Graph Neural Network (GNN) as a novel framework to\nanalyze residential location choice. The GNN-based discrete choice models\n(GNN-DCMs) offer a structured approach for neural networks to capture\ndependence among spatial alternatives, while maintaining clear connections to\nclassical random utility theory. Theoretically, we demonstrate that the\nGNN-DCMs incorporate the nested logit (NL) model and the spatially correlated\nlogit (SCL) model as two specific cases, yielding novel algorithmic\ninterpretation through message passing among alternatives' utilities.\nEmpirically, the GNN-DCMs outperform benchmark MNL, SCL, and feedforward neural\nnetworks in predicting residential location choices among Chicago's 77\ncommunity areas. Regarding model interpretation, the GNN-DCMs can capture\nindividual heterogeneity and exhibit spatially-aware substitution patterns.\nOverall, these results highlight the potential of GNN-DCMs as a unified and\nexpressive framework for synergizing discrete choice modeling and deep learning\nin the complex spatial choice contexts."}
{"id": "2507.21353", "pdf": "https://arxiv.org/pdf/2507.21353", "abs": "https://arxiv.org/abs/2507.21353", "authors": ["Deep Anil Patel", "Iain Melvin", "Zachary Izzo", "Martin Renqiang Min"], "title": "Group Relative Augmentation for Data Efficient Action Detection", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Adapting large Video-Language Models (VLMs) for action detection using only a\nfew examples poses challenges like overfitting and the granularity mismatch\nbetween scene-level pre-training and required person-centric understanding. We\npropose an efficient adaptation strategy combining parameter-efficient tuning\n(LoRA) with a novel learnable internal feature augmentation. Applied within the\nfrozen VLM backbone using FiLM, these augmentations generate diverse feature\nvariations directly relevant to the task. Additionally, we introduce a\ngroup-weighted loss function that dynamically modulates the training\ncontribution of each augmented sample based on its prediction divergence\nrelative to the group average. This promotes robust learning by prioritizing\ninformative yet reasonable augmentations. We demonstrate our method's\neffectiveness on complex multi-label, multi-person action detection datasets\n(AVA, MOMA), achieving strong mAP performance and showcasing significant data\nefficiency for adapting VLMs from limited examples."}
{"id": "2507.21372", "pdf": "https://arxiv.org/pdf/2507.21372", "abs": "https://arxiv.org/abs/2507.21372", "authors": ["Sarah McClure", "Sylvia Ratnasamy", "Scott Shenker"], "title": "Load Balancing for AI Training Workloads", "categories": ["cs.NI", "cs.LG"], "comment": null, "summary": "We investigate the performance of various load balancing algorithms for\nlarge-scale AI training workloads that are running on dedicated infrastructure.\nThe performance of load balancing depends on both the congestion control and\nloss recovery algorithms, so our evaluation also sheds light on the appropriate\nchoices for those designs as well."}
{"id": "2507.21377", "pdf": "https://arxiv.org/pdf/2507.21377", "abs": "https://arxiv.org/abs/2507.21377", "authors": ["Alexander Yeung", "Peter DelMastro", "Arjun Karuvally", "Hava Siegelmann", "Edward Rietman", "Hananel Hazan"], "title": "Reservoir Computation with Networks of Differentiating Neuron Ring Oscillators", "categories": ["cs.NE", "cs.LG"], "comment": "8 pages, 5 figures", "summary": "Reservoir Computing is a machine learning approach that uses the rich\nrepertoire of complex system dynamics for function approximation. Current\napproaches to reservoir computing use a network of coupled integrating neurons\nthat require a steady current to maintain activity. Here, we introduce a small\nworld graph of differentiating neurons that are active only when there are\nchanges in input as an alternative to integrating neurons as a reservoir\ncomputing substrate. We find the coupling strength and network topology that\nenable these small world networks to function as an effective reservoir. We\ndemonstrate the efficacy of these networks in the MNIST digit recognition task,\nachieving comparable performance of 90.65% to existing reservoir computing\napproaches. The findings suggest that differentiating neurons can be a\npotential alternative to integrating neurons and can provide a sustainable\nfuture alternative for power-hungry AI applications."}
{"id": "2507.21412", "pdf": "https://arxiv.org/pdf/2507.21412", "abs": "https://arxiv.org/abs/2507.21412", "authors": ["Yuntao Du", "Jiacheng Li", "Yuetian Chen", "Kaiyuan Zhang", "Zhizhen Yuan", "Hanshen Xiao", "Bruno Ribeiro", "Ninghui Li"], "title": "Cascading and Proxy Membership Inference Attacks", "categories": ["cs.CR", "cs.LG"], "comment": "Our code is available at: https://github.com/zealscott/MIA", "summary": "A Membership Inference Attack (MIA) assesses how much a trained machine\nlearning model reveals about its training data by determining whether specific\nquery instances were included in the dataset. We classify existing MIAs into\nadaptive or non-adaptive, depending on whether the adversary is allowed to\ntrain shadow models on membership queries. In the adaptive setting, where the\nadversary can train shadow models after accessing query instances, we highlight\nthe importance of exploiting membership dependencies between instances and\npropose an attack-agnostic framework called Cascading Membership Inference\nAttack (CMIA), which incorporates membership dependencies via conditional\nshadow training to boost membership inference performance.\n  In the non-adaptive setting, where the adversary is restricted to training\nshadow models before obtaining membership queries, we introduce Proxy\nMembership Inference Attack (PMIA). PMIA employs a proxy selection strategy\nthat identifies samples with similar behaviors to the query instance and uses\ntheir behaviors in shadow models to perform a membership posterior odds test\nfor membership inference. We provide theoretical analyses for both attacks, and\nextensive experimental results demonstrate that CMIA and PMIA substantially\noutperform existing MIAs in both settings, particularly in the low\nfalse-positive regime, which is crucial for evaluating privacy risks."}
{"id": "2507.21423", "pdf": "https://arxiv.org/pdf/2507.21423", "abs": "https://arxiv.org/abs/2507.21423", "authors": ["Thomas Monninger", "Zihan Zhang", "Zhipeng Mo", "Md Zafar Anwar", "Steffen Staab", "Sihao Ding"], "title": "MapDiffusion: Generative Diffusion for Vectorized Online HD Map Construction and Uncertainty Estimation in Autonomous Driving", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "comment": "Accepted for 2025 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS 2025)", "summary": "Autonomous driving requires an understanding of the static environment from\nsensor data. Learned Bird's-Eye View (BEV) encoders are commonly used to fuse\nmultiple inputs, and a vector decoder predicts a vectorized map representation\nfrom the latent BEV grid. However, traditional map construction models provide\ndeterministic point estimates, failing to capture uncertainty and the inherent\nambiguities of real-world environments, such as occlusions and missing lane\nmarkings. We propose MapDiffusion, a novel generative approach that leverages\nthe diffusion paradigm to learn the full distribution of possible vectorized\nmaps. Instead of predicting a single deterministic output from learned queries,\nMapDiffusion iteratively refines randomly initialized queries, conditioned on a\nBEV latent grid, to generate multiple plausible map samples. This allows\naggregating samples to improve prediction accuracy and deriving uncertainty\nestimates that directly correlate with scene ambiguity. Extensive experiments\non the nuScenes dataset demonstrate that MapDiffusion achieves state-of-the-art\nperformance in online map construction, surpassing the baseline by 5% in\nsingle-sample performance. We further show that aggregating multiple samples\nconsistently improves performance along the ROC curve, validating the benefit\nof distribution modeling. Additionally, our uncertainty estimates are\nsignificantly higher in occluded areas, reinforcing their value in identifying\nregions with ambiguous sensor input. By modeling the full map distribution,\nMapDiffusion enhances the robustness and reliability of online vectorized HD\nmap construction, enabling uncertainty-aware decision-making for autonomous\nvehicles in complex environments."}
{"id": "2507.21429", "pdf": "https://arxiv.org/pdf/2507.21429", "abs": "https://arxiv.org/abs/2507.21429", "authors": ["Agnideep Aich", "Ashit Baran Aich", "Bruce Wade"], "title": "From Sublinear to Linear: Fast Convergence in Deep Networks via Locally Polyak-Lojasiewicz Regions", "categories": ["stat.ML", "cs.LG", "68T07, 90C26, 65K10"], "comment": null, "summary": "The convergence of gradient descent (GD) on the non-convex loss landscapes of\ndeep neural networks (DNNs) presents a fundamental theoretical challenge. While\nrecent work has established that GD converges to a stationary point at a\nsublinear rate within locally quasi-convex regions (LQCRs), this fails to\nexplain the exponential convergence rates consistently observed in practice. In\nthis paper, we resolve this discrepancy by proving that under a mild assumption\non Neural Tangent Kernel (NTK) stability, these same regions satisfy a local\nPolyak-Lojasiewicz (PL) condition. We introduce the concept of a Locally\nPolyak-Lojasiewicz Region (LPLR), where the squared gradient norm lower-bounds\nthe suboptimality gap, prove that properly initialized finite-width networks\nadmit such regions around initialization, and establish that GD achieves linear\nconvergence within an LPLR, providing the first finite-width guarantee that\nmatches empirically observed rates. We validate our theory across diverse\nsettings, from controlled experiments on fully-connected networks to modern\nResNet architectures trained with stochastic methods, demonstrating that LPLR\nstructure emerges robustly in practical deep learning scenarios. By rigorously\nconnecting local landscape geometry to fast optimization through the NTK\nframework, our work provides a definitive theoretical explanation for the\nremarkable efficiency of gradient-based optimization in deep learning."}
{"id": "2507.21434", "pdf": "https://arxiv.org/pdf/2507.21434", "abs": "https://arxiv.org/abs/2507.21434", "authors": ["Agnideep Aich", "Ashit Baran Aich", "Bruce Wade"], "title": "Measuring Sample Quality with Copula Discrepancies", "categories": ["stat.ML", "cs.LG", "62H05, 62H12, 65C05, 68T05"], "comment": null, "summary": "The scalable Markov chain Monte Carlo (MCMC) algorithms that underpin modern\nBayesian machine learning, such as Stochastic Gradient Langevin Dynamics\n(SGLD), sacrifice asymptotic exactness for computational speed, creating a\ncritical diagnostic gap: traditional sample quality measures fail\ncatastrophically when applied to biased samplers. While powerful Stein-based\ndiagnostics can detect distributional mismatches, they provide no direct\nassessment of dependence structure, often the primary inferential target in\nmultivariate problems. We introduce the Copula Discrepancy (CD), a principled\nand computationally efficient diagnostic that leverages Sklar's theorem to\nisolate and quantify the fidelity of a sample's dependence structure\nindependent of its marginals. Our theoretical framework provides the first\nstructure-aware diagnostic specifically designed for the era of approximate\ninference. Empirically, we demonstrate that a moment-based CD dramatically\noutperforms standard diagnostics like effective sample size for hyperparameter\nselection in biased MCMC, correctly identifying optimal configurations where\ntraditional methods fail. Furthermore, our robust MLE-based variant can detect\nsubtle but critical mismatches in tail dependence that remain invisible to rank\ncorrelation-based approaches, distinguishing between samples with identical\nKendall's tau but fundamentally different extreme-event behavior. With\ncomputational overhead orders of magnitude lower than existing Stein\ndiscrepancies, the CD provides both immediate practical value for MCMC\npractitioners and a theoretical foundation for the next generation of\nstructure-aware sample quality assessment."}
{"id": "2507.21448", "pdf": "https://arxiv.org/pdf/2507.21448", "abs": "https://arxiv.org/abs/2507.21448", "authors": ["Teng", "Ma", "Sile Yin", "Li-Chia Yang", "Shuo Zhang"], "title": "Real-Time Audio-Visual Speech Enhancement Using Pre-trained Visual Representations", "categories": ["eess.AS", "cs.ET", "cs.LG"], "comment": "Accepted into Interspeech 2025", "summary": "Speech enhancement in audio-only settings remains challenging, particularly\nin the presence of interfering speakers. This paper presents a simple yet\neffective real-time audio-visual speech enhancement (AVSE) system, RAVEN, which\nisolates and enhances the on-screen target speaker while suppressing\ninterfering speakers and background noise. We investigate how visual embeddings\nlearned from audio-visual speech recognition (AVSR) and active speaker\ndetection (ASD) contribute to AVSE across different SNR conditions and numbers\nof interfering speakers. Our results show concatenating embeddings from AVSR\nand ASD models provides the greatest improvement in low-SNR, multi-speaker\nenvironments, while AVSR embeddings alone perform best in noise-only scenarios.\nIn addition, we develop a real-time streaming system that operates on a\ncomputer CPU and we provide a video demonstration and code repository. To our\nknowledge, this is the first open-source implementation of a real-time AVSE\nsystem."}
{"id": "2507.21449", "pdf": "https://arxiv.org/pdf/2507.21449", "abs": "https://arxiv.org/abs/2507.21449", "authors": ["Rohan Hitchcock", "Jesse Hoogland"], "title": "From Global to Local: A Scalable Benchmark for Local Posterior Sampling", "categories": ["stat.ML", "cs.LG"], "comment": "25 pages", "summary": "Degeneracy is an inherent feature of the loss landscape of neural networks,\nbut it is not well understood how stochastic gradient MCMC (SGMCMC) algorithms\ninteract with this degeneracy. In particular, current global convergence\nguarantees for common SGMCMC algorithms rely on assumptions which are likely\nincompatible with degenerate loss landscapes. In this paper, we argue that this\ngap requires a shift in focus from global to local posterior sampling, and, as\na first step, we introduce a novel scalable benchmark for evaluating the local\nsampling performance of SGMCMC algorithms. We evaluate a number of common\nalgorithms, and find that RMSProp-preconditioned SGLD is most effective at\nfaithfully representing the local geometry of the posterior distribution.\nAlthough we lack theoretical guarantees about global sampler convergence, our\nempirical results show that we are able to extract non-trivial local\ninformation in models with up to O(100M) parameters."}
{"id": "2507.21474", "pdf": "https://arxiv.org/pdf/2507.21474", "abs": "https://arxiv.org/abs/2507.21474", "authors": ["Daniel Szelogowski"], "title": "Hebbian Memory-Augmented Recurrent Networks: Engram Neurons in Deep Learning", "categories": ["cs.NE", "cs.AI", "cs.IR", "cs.LG", "q-bio.NC", "I.2.0; I.2.4; I.2.6; I.2.m; E.1; E.2; E.4; H.3; J.3; J.4"], "comment": "20 pages, 11 figures, 4 tables", "summary": "Despite success across diverse tasks, current artificial recurrent network\narchitectures rely primarily on implicit hidden-state memories, limiting their\ninterpretability and ability to model long-range dependencies. In contrast,\nbiological neural systems employ explicit, associative memory traces (i.e.,\nengrams) strengthened through Hebbian synaptic plasticity and activated\nsparsely during recall. Motivated by these neurobiological insights, we\nintroduce the Engram Neural Network (ENN), a novel recurrent architecture\nincorporating an explicit, differentiable memory matrix with Hebbian plasticity\nand sparse, attention-driven retrieval mechanisms. The ENN explicitly models\nmemory formation and recall through dynamic Hebbian traces, improving\ntransparency and interpretability compared to conventional RNN variants. We\nevaluate the ENN architecture on three canonical benchmarks: MNIST digit\nclassification, CIFAR-10 image sequence modeling, and WikiText-103 language\nmodeling. Our empirical results demonstrate that the ENN achieves accuracy and\ngeneralization performance broadly comparable to classical RNN, GRU, and LSTM\narchitectures, with all models converging to similar accuracy and perplexity on\nthe large-scale WikiText-103 task. At the same time, the ENN offers significant\nenhancements in interpretability through observable memory dynamics. Hebbian\ntrace visualizations further reveal biologically plausible, structured memory\nformation processes, validating the potential of neuroscience-inspired\nmechanisms to inform the development of more interpretable and robust deep\nlearning models."}
{"id": "2507.21486", "pdf": "https://arxiv.org/pdf/2507.21486", "abs": "https://arxiv.org/abs/2507.21486", "authors": ["Satoshi Kumabe", "Tianyu Song", "Ton Viet Ta"], "title": "Stochastic forest transition model dynamics and parameter estimation via deep learning", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Forest transitions, characterized by dynamic shifts between forest,\nagricultural, and abandoned lands, are complex phenomena. This study developed\na stochastic differential equation model to capture the intricate dynamics of\nthese transitions. We established the existence of global positive solutions\nfor the model and conducted numerical analyses to assess the impact of model\nparameters on deforestation incentives. To address the challenge of parameter\nestimation, we proposed a novel deep learning approach that estimates all model\nparameters from a single sample containing time-series observations of forest\nand agricultural land proportions. This innovative approach enables us to\nunderstand forest transition dynamics and deforestation trends at any future\ntime."}
{"id": "2507.21496", "pdf": "https://arxiv.org/pdf/2507.21496", "abs": "https://arxiv.org/abs/2507.21496", "authors": ["Ryo Terajima", "Katsuma Inoue", "Kohei Nakajima", "Yasuo Kuniyoshi"], "title": "Multifunctional physical reservoir computing in soft tensegrity robots", "categories": ["cs.RO", "cs.LG", "nlin.CD"], "comment": "25 pages, 12 figures. The following article has been accepted by\n  Chaos: An Interdisciplinary Journal of Nonlinear Science", "summary": "Recent studies have demonstrated that the dynamics of physical systems can be\nutilized for the desired information processing under the framework of physical\nreservoir computing (PRC). Robots with soft bodies are examples of such\nphysical systems, and their nonlinear body-environment dynamics can be used to\ncompute and generate the motor signals necessary for the control of their own\nbehavior. In this simulation study, we extend this approach to control and\nembed not only one but also multiple behaviors into a type of soft robot called\na tensegrity robot. The resulting system, consisting of the robot and the\nenvironment, is a multistable dynamical system that converges to different\nattractors from varying initial conditions. Furthermore, attractor analysis\nreveals that there exist \"untrained attractors\" in the state space of the\nsystem outside the training data. These untrained attractors reflect the\nintrinsic properties and structures of the tensegrity robot and its\ninteractions with the environment. The impacts of these recent findings in PRC\nremain unexplored in embodied AI research. We here illustrate their potential\nto understand various features of embodied cognition that have not been fully\naddressed to date."}
{"id": "2507.21509", "pdf": "https://arxiv.org/pdf/2507.21509", "abs": "https://arxiv.org/abs/2507.21509", "authors": ["Runjin Chen", "Andy Arditi", "Henry Sleight", "Owain Evans", "Jack Lindsey"], "title": "Persona Vectors: Monitoring and Controlling Character Traits in Language Models", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large language models interact with users through a simulated 'Assistant'\npersona. While the Assistant is typically trained to be helpful, harmless, and\nhonest, it sometimes deviates from these ideals. In this paper, we identify\ndirections in the model's activation space-persona vectors-underlying several\ntraits, such as evil, sycophancy, and propensity to hallucinate. We confirm\nthat these vectors can be used to monitor fluctuations in the Assistant's\npersonality at deployment time. We then apply persona vectors to predict and\ncontrol personality shifts that occur during training. We find that both\nintended and unintended personality changes after finetuning are strongly\ncorrelated with shifts along the relevant persona vectors. These shifts can be\nmitigated through post-hoc intervention, or avoided in the first place with a\nnew preventative steering method. Moreover, persona vectors can be used to flag\ntraining data that will produce undesirable personality changes, both at the\ndataset level and the individual sample level. Our method for extracting\npersona vectors is automated and can be applied to any personality trait of\ninterest, given only a natural-language description."}
{"id": "2507.21532", "pdf": "https://arxiv.org/pdf/2507.21532", "abs": "https://arxiv.org/abs/2507.21532", "authors": ["Meet Bhatt", "Nic Boilard", "Muhammad Rehan Chaudhary", "Cole Thompson", "Jacob Idoko", "Aakash Sorathiya", "Gouri Ginde"], "title": "Automatic Classification of User Requirements from Online Feedback -- A Replication Study", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "10 pages, 3 figures, Replication package available at\n  https://zenodo.org/records/15626782, Accepted at AIRE 2025 (12th\n  International Workshop on Artificial Intelligence and Requirements\n  Engineering)", "summary": "Natural language processing (NLP) techniques have been widely applied in the\nrequirements engineering (RE) field to support tasks such as classification and\nambiguity detection. Although RE research is rooted in empirical investigation,\nit has paid limited attention to replicating NLP for RE (NLP4RE) studies. The\nrapidly advancing realm of NLP is creating new opportunities for efficient,\nmachine-assisted workflows, which can bring new perspectives and results to the\nforefront. Thus, we replicate and extend a previous NLP4RE study (baseline),\n\"Classifying User Requirements from Online Feedback in Small Dataset\nEnvironments using Deep Learning\", which evaluated different deep learning\nmodels for requirement classification from user reviews. We reproduced the\noriginal results using publicly released source code, thereby helping to\nstrengthen the external validity of the baseline study. We then extended the\nsetup by evaluating model performance on an external dataset and comparing\nresults to a GPT-4o zero-shot classifier. Furthermore, we prepared the\nreplication study ID-card for the baseline study, important for evaluating\nreplication readiness. Results showed diverse reproducibility levels across\ndifferent models, with Naive Bayes demonstrating perfect reproducibility. In\ncontrast, BERT and other models showed mixed results. Our findings revealed\nthat baseline deep learning models, BERT and ELMo, exhibited good\ngeneralization capabilities on an external dataset, and GPT-4o showed\nperformance comparable to traditional baseline machine learning models.\nAdditionally, our assessment confirmed the baseline study's replication\nreadiness; however missing environment setup files would have further enhanced\nreadiness. We include this missing information in our replication package and\nprovide the replication study ID-card for our study to further encourage and\nsupport the replication of our study."}
{"id": "2507.21543", "pdf": "https://arxiv.org/pdf/2507.21543", "abs": "https://arxiv.org/abs/2507.21543", "authors": ["Shoju Enami", "Kenji Kashima"], "title": "On Policy Stochasticity in Mutual Information Optimal Control of Linear Systems", "categories": ["math.OC", "cs.LG", "cs.SY", "eess.SY"], "comment": "17 pages", "summary": "In recent years, mutual information optimal control has been proposed as an\nextension of maximum entropy optimal control. Both approaches introduce\nregularization terms to render the policy stochastic, and it is important to\ntheoretically clarify the relationship between the temperature parameter (i.e.,\nthe coefficient of the regularization term) and the stochasticity of the\npolicy. Unlike in maximum entropy optimal control, this relationship remains\nunexplored in mutual information optimal control. In this paper, we investigate\nthis relationship for a mutual information optimal control problem (MIOCP) of\ndiscrete-time linear systems. After extending the result of a previous study of\nthe MIOCP, we establish the existence of an optimal policy of the MIOCP, and\nthen derive the respective conditions on the temperature parameter under which\nthe optimal policy becomes stochastic and deterministic. Furthermore, we also\nderive the respective conditions on the temperature parameter under which the\npolicy obtained by an alternating optimization algorithm becomes stochastic and\ndeterministic. The validity of the theoretical results is demonstrated through\nnumerical experiments."}
{"id": "2507.21563", "pdf": "https://arxiv.org/pdf/2507.21563", "abs": "https://arxiv.org/abs/2507.21563", "authors": ["Minh-Anh Nguyen", "Bao Nguyen", "Ha Lan N. T.", "Tuan Anh Hoang", "Duc-Trong Le", "Dung D. Le"], "title": "Enhancing Graph-based Recommendations with Majority-Voting LLM-Rerank Augmentation", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "Recommendation systems often suffer from data sparsity caused by limited\nuser-item interactions, which degrade their performance and amplify popularity\nbias in real-world scenarios. This paper proposes a novel data augmentation\nframework that leverages Large Language Models (LLMs) and item textual\ndescriptions to enrich interaction data. By few-shot prompting LLMs multiple\ntimes to rerank items and aggregating the results via majority voting, we\ngenerate high-confidence synthetic user-item interactions, supported by\ntheoretical guarantees based on the concentration of measure. To effectively\nleverage the augmented data in the context of a graph recommendation system, we\nintegrate it into a graph contrastive learning framework to mitigate\ndistributional shift and alleviate popularity bias. Extensive experiments show\nthat our method improves accuracy and reduces popularity bias, outperforming\nstrong baselines."}
{"id": "2507.21569", "pdf": "https://arxiv.org/pdf/2507.21569", "abs": "https://arxiv.org/abs/2507.21569", "authors": ["Takeshi Kimura", "Kohtaro Kato", "Masahito Hayashi"], "title": "An em algorithm for quantum Boltzmann machines", "categories": ["quant-ph", "cs.LG"], "comment": "Main text: 10 pages, 2 figures. Appendix: 3 pages, 1 figure", "summary": "We develop a quantum version of the em algorithm for training quantum\nBoltzmann machines. The em algorithm is an information-geometric extension of\nthe well-known expectation-maximization (EM) algorithm, offering a structured\nalternative to gradient-based methods with potential advantages in stability\nand convergence. We implement the algorithm on a semi-quantum restricted\nBoltzmann machine, where quantum effects are confined to the hidden layer. This\nstructure enables analytical update rules while preserving quantum\nexpressivity. Numerical experiments on benchmark datasets show that the\nproposed method achieves stable learning and outperforms gradient-based\ntraining in several cases. These results demonstrate the potential of\ninformation-geometric optimization for quantum machine learning, particularly\nin settings where standard methods struggle due to non-commutativity or\nvanishing gradients."}
{"id": "2507.21638", "pdf": "https://arxiv.org/pdf/2507.21638", "abs": "https://arxiv.org/abs/2507.21638", "authors": ["Leonard Hinckeldey", "Elliot Fosong", "Elle Miller", "Rimvydas Rubavicius", "Trevor McInroe", "Patricia Wollstadt", "Christiane B. Wiebel-Herboth", "Subramanian Ramamoorthy", "Stefano V. Albrecht"], "title": "Assistax: A Hardware-Accelerated Reinforcement Learning Benchmark for Assistive Robotics", "categories": ["cs.AI", "cs.LG", "cs.RO"], "comment": "Accepted for the Coordination and Cooperation in Multi-Agent\n  Reinforcement Learning Workshop at the Reinforcement Learning Conference 2025", "summary": "The development of reinforcement learning (RL) algorithms has been largely\ndriven by ambitious challenge tasks and benchmarks. Games have dominated RL\nbenchmarks because they present relevant challenges, are inexpensive to run and\neasy to understand. While games such as Go and Atari have led to many\nbreakthroughs, they often do not directly translate to real-world embodied\napplications. In recognising the need to diversify RL benchmarks and addressing\ncomplexities that arise in embodied interaction scenarios, we introduce\nAssistax: an open-source benchmark designed to address challenges arising in\nassistive robotics tasks. Assistax uses JAX's hardware acceleration for\nsignificant speed-ups for learning in physics-based simulations. In terms of\nopen-loop wall-clock time, Assistax runs up to $370\\times$ faster when\nvectorising training runs compared to CPU-based alternatives. Assistax\nconceptualises the interaction between an assistive robot and an active human\npatient using multi-agent RL to train a population of diverse partner agents\nagainst which an embodied robotic agent's zero-shot coordination capabilities\ncan be tested. Extensive evaluation and hyperparameter tuning for popular\ncontinuous control RL and MARL algorithms provide reliable baselines and\nestablish Assistax as a practical benchmark for advancing RL research for\nassistive robotics. The code is available at:\nhttps://github.com/assistive-autonomy/assistax."}
{"id": "2507.21642", "pdf": "https://arxiv.org/pdf/2507.21642", "abs": "https://arxiv.org/abs/2507.21642", "authors": ["William Ravenscroft", "George Close", "Kit Bower-Morris", "Jamie Stacey", "Dmitry Sityaev", "Kris Y. Hong"], "title": "Whilter: A Whisper-based Data Filter for \"In-the-Wild\" Speech Corpora Using Utterance-level Multi-Task Classification", "categories": ["cs.SD", "cs.LG", "eess.AS"], "comment": "Accepted for Interspeech 2025", "summary": "Large-scale in-the-wild speech datasets have become more prevalent in recent\nyears due to increased interest in models that can learn useful features from\nunlabelled data for tasks such as speech recognition or synthesis. These\ndatasets often contain undesirable features, such as multiple speakers,\nnon-target languages, and music, which may impact model learning. The Whilter\nmodel is proposed as a multitask solution to identify these undesirable\nsamples. Whilter uses a Whisper encoder with an attention-based classifier to\nsolve five diverse classification problems at once. In addition, an annotated\ndataset is published for a subset of two popular in-the-wild corpora. Whilter\nachieves F1 scores above 85% and equal error rates of 6.5% to 7.8% for three of\nfive subtasks, outperforming a state-of-the-art BEATs classifier on\nspeech-specific classes, with a notable decrease in processing time compared to\na combination of single-task alternatives."}
{"id": "2507.21684", "pdf": "https://arxiv.org/pdf/2507.21684", "abs": "https://arxiv.org/abs/2507.21684", "authors": ["Rene Winchenbach", "Nils Thuerey"], "title": "diffSPH: Differentiable Smoothed Particle Hydrodynamics for Adjoint Optimization and Machine Learning", "categories": ["physics.flu-dyn", "cs.AI", "cs.LG", "I.2.0; I.6.0; G.1.4"], "comment": null, "summary": "We present diffSPH, a novel open-source differentiable Smoothed Particle\nHydrodynamics (SPH) framework developed entirely in PyTorch with GPU\nacceleration. diffSPH is designed centrally around differentiation to\nfacilitate optimization and machine learning (ML) applications in Computational\nFluid Dynamics~(CFD), including training neural networks and the development of\nhybrid models. Its differentiable SPH core, and schemes for compressible (with\nshock capturing and multi-phase flows), weakly compressible (with boundary\nhandling and free-surface flows), and incompressible physics, enable a broad\nrange of application areas. We demonstrate the framework's unique capabilities\nthrough several applications, including addressing particle shifting via a\nnovel, target-oriented approach by minimizing physical and regularization loss\nterms, a task often intractable in traditional solvers. Further examples\ninclude optimizing initial conditions and physical parameters to match target\ntrajectories, shape optimization, implementing a solver-in-the-loop setup to\nemulate higher-order integration, and demonstrating gradient propagation\nthrough hundreds of full simulation steps. Prioritizing readability, usability,\nand extensibility, this work offers a foundational platform for the CFD\ncommunity to develop and deploy novel neural networks and adjoint optimization\napplications."}
{"id": "2507.21712", "pdf": "https://arxiv.org/pdf/2507.21712", "abs": "https://arxiv.org/abs/2507.21712", "authors": ["Urban Eriksson"], "title": "An Equal-Probability Partition of the Sample Space: A Non-parametric Inference from Finite Samples", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": null, "summary": "This paper investigates what can be inferred about an arbitrary continuous\nprobability distribution from a finite sample of $N$ observations drawn from\nit. The central finding is that the $N$ sorted sample points partition the real\nline into $N+1$ segments, each carrying an expected probability mass of exactly\n$1/(N+1)$. This non-parametric result, which follows from fundamental\nproperties of order statistics, holds regardless of the underlying\ndistribution's shape. This equal-probability partition yields a discrete\nentropy of $\\log_2(N+1)$ bits, which quantifies the information gained from the\nsample and contrasts with Shannon's results for continuous variables. I compare\nthis partition-based framework to the conventional ECDF and discuss its\nimplications for robust non-parametric inference, particularly in density and\ntail estimation."}
{"id": "2507.21726", "pdf": "https://arxiv.org/pdf/2507.21726", "abs": "https://arxiv.org/abs/2507.21726", "authors": ["Marius Willner", "Marco Trenti", "Dirk Lebiedz"], "title": "Riemannian Optimization on Tree Tensor Networks with Application in Machine Learning", "categories": ["math.OC", "cond-mat.other", "cs.LG", "15A69, 53C20, 65K10"], "comment": "24 pages, 6 figures, 4 pseudo-code algorithms, 1 table", "summary": "Tree tensor networks (TTNs) are widely used in low-rank approximation and\nquantum many-body simulation. In this work, we present a formal analysis of the\ndifferential geometry underlying TTNs. Building on this foundation, we develop\nefficient first- and second-order optimization algorithms that exploit the\nintrinsic quotient structure of TTNs. Additionally, we devise a backpropagation\nalgorithm for training TTNs in a kernel learning setting. We validate our\nmethods through numerical experiments on a representative machine learning\ntask."}
{"id": "2507.21728", "pdf": "https://arxiv.org/pdf/2507.21728", "abs": "https://arxiv.org/abs/2507.21728", "authors": ["Agastya Raj", "Zehao Wang", "Tingjun Chen", "Daniel C Kilper", "Marco Ruffini"], "title": "Generalized few-shot transfer learning architecture for modeling the EDFA gain spectrum", "categories": ["cs.NI", "cs.LG"], "comment": "This is a preprint of a paper accepted and published in the Journal\n  of Optical Communications and Networking (JOCN). The final published version\n  is available at: https://doi.org/10.1364/JOCN.560987", "summary": "Accurate modeling of the gain spectrum in Erbium-Doped Fiber Amplifiers\n(EDFAs) is essential for optimizing optical network performance, particularly\nas networks evolve toward multi-vendor solutions. In this work, we propose a\ngeneralized few-shot transfer learning architecture based on a Semi-Supervised\nSelf-Normalizing Neural Network (SS-NN) that leverages internal EDFA features -\nsuch as VOA input or output power and attenuation, to improve gain spectrum\nprediction. Our SS-NN model employs a two-phase training strategy comprising\nunsupervised pre-training with noise-augmented measurements and supervised\nfine-tuning with a custom weighted MSE loss. Furthermore, we extend the\nframework with transfer learning (TL) techniques that enable both homogeneous\n(same-feature space) and heterogeneous (different-feature sets) model\nadaptation across booster, preamplifier, and ILA EDFAs. To address feature\nmismatches in heterogeneous TL, we incorporate a covariance matching loss to\nalign second-order feature statistics between source and target domains.\nExtensive experiments conducted across 26 EDFAs in the COSMOS and Open Ireland\ntestbeds demonstrate that the proposed approach significantly reduces the\nnumber of measurements requirements on the system while achieving lower mean\nabsolute errors and improved error distributions compared to benchmark methods."}
{"id": "2507.21749", "pdf": "https://arxiv.org/pdf/2507.21749", "abs": "https://arxiv.org/abs/2507.21749", "authors": ["D. Veerababu", "Ashwin A. Raikar", "Prasanta K. Ghosh"], "title": "Improving Neural Network Training using Dynamic Learning Rate Schedule for PINNs and Image Classification", "categories": ["cs.CE", "cs.LG", "34A06", "G.1.6; I.6.4; J.2"], "comment": "10 pages", "summary": "Training neural networks can be challenging, especially as the complexity of\nthe problem increases. Despite using wider or deeper networks, training them\ncan be a tedious process, especially if a wrong choice of the hyperparameter is\nmade. The learning rate is one of such crucial hyperparameters, which is\nusually kept static during the training process. Learning dynamics in complex\nsystems often requires a more adaptive approach to the learning rate. This\nadaptability becomes crucial to effectively navigate varying gradients and\noptimize the learning process during the training process. In this paper, a\ndynamic learning rate scheduler (DLRS) algorithm is presented that adapts the\nlearning rate based on the loss values calculated during the training process.\nExperiments are conducted on problems related to physics-informed neural\nnetworks (PINNs) and image classification using multilayer perceptrons and\nconvolutional neural networks, respectively. The results demonstrate that the\nproposed DLRS accelerates training and improves stability."}
{"id": "2507.21760", "pdf": "https://arxiv.org/pdf/2507.21760", "abs": "https://arxiv.org/abs/2507.21760", "authors": ["Andrea Fantasia", "Daniele Lanzoni", "Niccol√≤ Di Eugenio", "Angelo Monteleone", "Roberto Bergamaschini", "Francesco Montalenti"], "title": "Unified machine-learning framework for property prediction and time-evolution simulation of strained alloy microstructure", "categories": ["cond-mat.mtrl-sci", "cond-mat.mes-hall", "cs.LG", "physics.comp-ph"], "comment": "19 pages, 9 figures", "summary": "We introduce a unified machine-learning framework designed to conveniently\ntackle the temporal evolution of alloy microstructures under the influence of\nan elastic field. This approach allows for the simultaneous extraction of\nelastic parameters from a short trajectory and for the prediction of further\nmicrostructure evolution under their influence. This is demonstrated by\nfocusing on spinodal decomposition in the presence of a lattice mismatch eta,\nand by carrying out an extensive comparison between the ground-truth evolution\nsupplied by phase field simulations and the predictions of suitable\nconvolutional recurrent neural network architectures. The two tasks may then be\nperformed subsequently into a cascade framework. Under a wide spectrum of\nmisfit conditions, the here-presented cascade model accurately predicts eta and\nthe full corresponding microstructure evolution, also when approaching critical\nconditions for spinodal decomposition. Scalability to larger computational\ndomain sizes and mild extrapolation errors in time (for time sequences five\ntimes longer than the sampled ones during training) are demonstrated. The\nproposed framework is general and can be applied beyond the specific,\nprototypical system considered here as an example. Intriguingly, experimental\nvideos could be used to infer unknown external parameters, prior to simulating\nfurther temporal evolution."}
{"id": "2507.21763", "pdf": "https://arxiv.org/pdf/2507.21763", "abs": "https://arxiv.org/abs/2507.21763", "authors": ["Daniele Lanzoni", "Olivier Pierre-Louis", "Roberto Bergamaschini", "Francesco Montalenti"], "title": "Learning Kinetic Monte Carlo stochastic dynamics with Deep Generative Adversarial Networks", "categories": ["cond-mat.stat-mech", "cond-mat.mtrl-sci", "cs.AI", "cs.LG", "physics.comp-ph"], "comment": "15 pages, 8 figures, 2 appendices", "summary": "We show that Generative Adversarial Networks (GANs) may be fruitfully\nexploited to learn stochastic dynamics, surrogating traditional models while\ncapturing thermal fluctuations. Specifically, we showcase the application to a\ntwo-dimensional, many-particle system, focusing on surface-step fluctuations\nand on the related time-dependent roughness. After the construction of a\ndataset based on Kinetic Monte Carlo simulations, a conditional GAN is trained\nto propagate stochastically the state of the system in time, allowing the\ngeneration of new sequences with a reduced computational cost. Modifications\nwith respect to standard GANs, which facilitate convergence and increase\naccuracy, are discussed. The trained network is demonstrated to quantitatively\nreproduce equilibrium and kinetic properties, including scaling laws, with\ndeviations of a few percent from the exact value. Extrapolation limits and\nfuture perspectives are critically discussed."}
{"id": "2507.21783", "pdf": "https://arxiv.org/pdf/2507.21783", "abs": "https://arxiv.org/abs/2507.21783", "authors": ["Malte Londschien", "Manuel Burger", "Gunnar R√§tsch", "Peter B√ºhlmann"], "title": "Domain Generalization and Adaptation in Intensive Care with Anchor Regression", "categories": ["stat.AP", "cs.LG", "stat.ME", "stat.ML"], "comment": null, "summary": "The performance of predictive models in clinical settings often degrades when\ndeployed in new hospitals due to distribution shifts. This paper presents a\nlarge-scale study of causality-inspired domain generalization on heterogeneous\nmulti-center intensive care unit (ICU) data. We apply anchor regression and\nintroduce anchor boosting, a novel, tree-based nonlinear extension, to a large\ndataset comprising 400,000 patients from nine distinct ICU databases. The\nanchor regularization consistently improves out-of-distribution performance,\nparticularly for the most dissimilar target domains. The methods appear robust\nto violations of theoretical assumptions, such as anchor exogeneity.\nFurthermore, we propose a novel conceptual framework to quantify the utility of\nlarge external data datasets. By evaluating performance as a function of\navailable target-domain data, we identify three regimes: (i) a domain\ngeneralization regime, where only the external model should be used, (ii) a\ndomain adaptation regime, where refitting the external model is optimal, and\n(iii) a data-rich regime, where external data provides no additional value."}
{"id": "2507.21807", "pdf": "https://arxiv.org/pdf/2507.21807", "abs": "https://arxiv.org/abs/2507.21807", "authors": ["Robert Kuchen"], "title": "MIBoost: A Gradient Boosting Algorithm for Variable Selection After Multiple Imputation", "categories": ["stat.ML", "cs.LG", "62J07, 62H12, 62F07"], "comment": "21 pages, 2 algorithms, includes a simulation study", "summary": "Statistical learning methods for automated variable selection, such as LASSO,\nelastic nets, or gradient boosting, have become increasingly popular tools for\nbuilding powerful prediction models. Yet, in practice, analyses are often\ncomplicated by missing data. The most widely used approach to address\nmissingness is multiple imputation, which creates several completed datasets.\nHowever, there is an ongoing debate on how to perform model selection in the\npresence of multiple imputed datasets. Simple strategies, such as pooling\nmodels across datasets, have been shown to have suboptimal properties. Although\nmore sophisticated methods exist, they are often difficult to implement and\ntherefore not widely applied. In contrast, two recent approaches modify the\nregularization methods LASSO and elastic nets by defining a single loss\nfunction, resulting in a unified set of coefficients across imputations. Our\nkey contribution is to extend this principle to the framework of component-wise\ngradient boosting by proposing MIBoost, a novel algorithm that employs a\nuniform variable-selection mechanism across imputed datasets. Simulation\nstudies suggest that our approach yields prediction performance comparable to\nthat of these recently proposed methods."}
{"id": "2507.21831", "pdf": "https://arxiv.org/pdf/2507.21831", "abs": "https://arxiv.org/abs/2507.21831", "authors": ["Andreas Reich", "Claudia Thoms", "Tobias Schrimpf"], "title": "Introducing HALC: A general pipeline for finding optimal prompting strategies for automated coding with LLMs in the computational social sciences", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "48 pages, 9 figures and 8 tables", "summary": "LLMs are seeing widespread use for task automation, including automated\ncoding in the social sciences. However, even though researchers have proposed\ndifferent prompting strategies, their effectiveness varies across LLMs and\ntasks. Often trial and error practices are still widespread. We propose\nHALC$-$a general pipeline that allows for the systematic and reliable\nconstruction of optimal prompts for any given coding task and model, permitting\nthe integration of any prompting strategy deemed relevant. To investigate LLM\ncoding and validate our pipeline, we sent a total of 1,512 individual prompts\nto our local LLMs in over two million requests. We test prompting strategies\nand LLM task performance based on few expert codings (ground truth). When\ncompared to these expert codings, we find prompts that code reliably for single\nvariables (${\\alpha}$climate = .76; ${\\alpha}$movement = .78) and across two\nvariables (${\\alpha}$climate = .71; ${\\alpha}$movement = .74) using the LLM\nMistral NeMo. Our prompting strategies are set up in a way that aligns the LLM\nto our codebook$-$we are not optimizing our codebook for LLM friendliness. Our\npaper provides insights into the effectiveness of different prompting\nstrategies, crucial influencing factors, and the identification of reliable\nprompts for each coding task and model."}
{"id": "2507.21871", "pdf": "https://arxiv.org/pdf/2507.21871", "abs": "https://arxiv.org/abs/2507.21871", "authors": ["Katerina Marie Simkova", "Adrien Doerig", "Clayton Hickey", "Ian Charest"], "title": "Representations in vision and language converge in a shared, multidimensional space of perceived similarities", "categories": ["q-bio.NC", "cs.LG"], "comment": "51 pages, 15 figures", "summary": "Humans can effortlessly describe what they see, yet establishing a shared\nrepresentational format between vision and language remains a significant\nchallenge. Emerging evidence suggests that human brain representations in both\nvision and language are well predicted by semantic feature spaces obtained from\nlarge language models (LLMs). This raises the possibility that sensory systems\nconverge in their inherent ability to transform their inputs onto shared,\nembedding-like representational space. However, it remains unclear how such a\nspace manifests in human behaviour. To investigate this, sixty-three\nparticipants performed behavioural similarity judgements separately on 100\nnatural scene images and 100 corresponding sentence captions from the Natural\nScenes Dataset. We found that visual and linguistic similarity judgements not\nonly converge at the behavioural level but also predict a remarkably similar\nnetwork of fMRI brain responses evoked by viewing the natural scene images.\nFurthermore, computational models trained to map images onto LLM-embeddings\noutperformed both category-trained and AlexNet controls in explaining the\nbehavioural similarity structure. These findings demonstrate that human visual\nand linguistic similarity judgements are grounded in a shared,\nmodality-agnostic representational structure that mirrors how the visual system\nencodes experience. The convergence between sensory and artificial systems\nsuggests a common capacity of how conceptual representations are formed-not as\narbitrary products of first order, modality-specific input, but as structured\nrepresentations that reflect the stable, relational properties of the external\nworld."}
{"id": "2507.21886", "pdf": "https://arxiv.org/pdf/2507.21886", "abs": "https://arxiv.org/abs/2507.21886", "authors": ["Stefanos Gkikas", "Ioannis Kyprakis", "Manolis Tsiknakis"], "title": "Efficient Pain Recognition via Respiration Signals: A Single Cross-Attention Transformer Multi-Window Fusion Pipeline", "categories": ["cs.AI", "cs.LG", "eess.SP"], "comment": null, "summary": "Pain is a complex condition affecting a large portion of the population.\nAccurate and consistent evaluation is essential for individuals experiencing\npain, and it supports the development of effective and advanced management\nstrategies. Automatic pain assessment systems provide continuous monitoring and\nsupport clinical decision-making, aiming to reduce distress and prevent\nfunctional decline. This study has been submitted to the \\textit{Second\nMultimodal Sensing Grand Challenge for Next-Gen Pain Assessment (AI4PAIN)}. The\nproposed method introduces a pipeline that leverages respiration as the input\nsignal and incorporates a highly efficient cross-attention transformer\nalongside a multi-windowing strategy. Extensive experiments demonstrate that\nrespiration is a valuable physiological modality for pain assessment. Moreover,\nexperiments revealed that compact and efficient models, when properly\noptimized, can achieve strong performance, often surpassing larger\ncounterparts. The proposed multi-window approach effectively captures both\nshort-term and long-term features, as well as global characteristics, thereby\nenhancing the model's representational capacity."}
{"id": "2507.21890", "pdf": "https://arxiv.org/pdf/2507.21890", "abs": "https://arxiv.org/abs/2507.21890", "authors": ["Baoyang Zhang", "Zhen Lu", "Yaomin Zhao", "Yue Yang"], "title": "Data-driven quantum Koopman method for simulating nonlinear dynamics", "categories": ["quant-ph", "cs.AI", "cs.LG", "physics.comp-ph", "physics.flu-dyn"], "comment": null, "summary": "Quantum computation offers potential exponential speedups for simulating\ncertain physical systems, but its application to nonlinear dynamics is\ninherently constrained by the requirement of unitary evolution. We propose the\nquantum Koopman method (QKM), a data-driven framework that bridges this gap\nthrough transforming nonlinear dynamics into linear unitary evolution in\nhigher-dimensional observable spaces. Leveraging the Koopman operator theory to\nachieve a global linearization, our approach maps system states into a\nhierarchy of Hilbert spaces using a deep autoencoder. Within the linearized\nembedding spaces, the state representation is decomposed into modulus and phase\ncomponents, and the evolution is governed by a set of unitary Koopman operators\nthat act exclusively on the phase. These operators are constructed from\ndiagonal Hamiltonians with coefficients learned from data, a structure designed\nfor efficient implementation on quantum hardware. This architecture enables\ndirect multi-step prediction, and the operator's computational complexity\nscales logarithmically with the observable space dimension. The QKM is\nvalidated across diverse nonlinear systems. Its predictions maintain relative\nerrors below 6% for reaction-diffusion systems and shear flows, and capture key\nstatistics in 2D turbulence. This work establishes a practical pathway for\nquantum-accelerated simulation of nonlinear phenomena, exploring a framework\nbuilt on the synergy between deep learning for global linearization and quantum\nalgorithms for unitary dynamics evolution."}
{"id": "2507.21899", "pdf": "https://arxiv.org/pdf/2507.21899", "abs": "https://arxiv.org/abs/2507.21899", "authors": ["Malik Uzair Mehmood", "Shahid Hussain", "Wen Li Wang", "Muhammad Usama Malik"], "title": "LLM-based Content Classification Approach for GitHub Repositories by the README Files", "categories": ["cs.AI", "cs.LG", "cs.SE"], "comment": "8 pages, 4 Figures", "summary": "GitHub is the world's most popular platform for storing, sharing, and\nmanaging code. Every GitHub repository has a README file associated with it.\nThe README files should contain project-related information as per the\nrecommendations of GitHub to support the usage and improvement of repositories.\nHowever, GitHub repository owners sometimes neglected these recommendations.\nThis prevents a GitHub repository from reaching its full potential. This\nresearch posits that the comprehensiveness of a GitHub repository's README file\nsignificantly influences its adoption and utilization, with a lack of detail\npotentially hindering its full potential for widespread engagement and impact\nwithin the research community. Large Language Models (LLMs) have shown great\nperformance in many text-based tasks including text classification, text\ngeneration, text summarization and text translation. In this study, an approach\nis developed to fine-tune LLMs for automatically classifying different sections\nof GitHub README files. Three encoder-only LLMs are utilized, including BERT,\nDistilBERT and RoBERTa. These pre-trained models are then fine-tuned based on a\ngold-standard dataset consisting of 4226 README file sections. This approach\noutperforms current state-of-the-art methods and has achieved an overall F1\nscore of 0.98. Moreover, we have also investigated the use of\nParameter-Efficient Fine-Tuning (PEFT) techniques like Low-Rank Adaptation\n(LoRA) and shown an economical alternative to full fine-tuning without\ncompromising much performance. The results demonstrate the potential of using\nLLMs in designing an automatic classifier for categorizing the content of\nGitHub README files. Consequently, this study contributes to the development of\nautomated tools for GitHub repositories to improve their identifications and\npotential usages."}
{"id": "2507.21902", "pdf": "https://arxiv.org/pdf/2507.21902", "abs": "https://arxiv.org/abs/2507.21902", "authors": ["Md Mushfiqul Islam", "Nishat N. Labiba", "Lawrence O. Hall", "David S. Simmons"], "title": "Reducing Data Requirements for Sequence-Property Prediction in Copolymer Compatibilizers via Deep Neural Network Tuning", "categories": ["cond-mat.mtrl-sci", "cond-mat.soft", "cond-mat.stat-mech", "cs.LG", "physics.chem-ph"], "comment": "23 pages, 6 figures", "summary": "Synthetic sequence-controlled polymers promise to transform polymer science\nby combining the chemical versatility of synthetic polymers with the precise\nsequence-mediated functionality of biological proteins. However, design of\nthese materials has proven extraordinarily challenging, because they lack the\nmassive datasets of closely related evolved molecules that accelerate design of\nproteins. Here we report on a new Artifical Intelligence strategy to\ndramatically reduce the amount of data necessary to accelerate these materials'\ndesign. We focus on data connecting the repeat-unit-sequence of a\n\\emph{compatibilizer} molecule to its ability to reduce the interfacial tension\nbetween distinct polymer domains. The optimal sequence of these molecules,\nwhich are essential for applications such as mixed-waste polymer recycling,\ndepends strongly on variables such as concentration and chemical details of the\npolymer. With current methods, this would demand an entirely distinct dataset\nto enable design at each condition. Here we show that a deep neural network\ntrained on low-fidelity data for sequence/interfacial tension relations at one\nset of conditions can be rapidly tuned to make higher-fidelity predictions at a\ndistinct set of conditions, requiring far less data that would ordinarily be\nneeded. This priming-and-tuning approach should allow a single low-fidelity\nparent dataset to dramatically accelerate prediction and design in an entire\nconstellation of related systems. In the long run, it may also provide an\napproach to bootstrapping quantitative atomistic design with AI insights from\nfast, coarse simulations."}
{"id": "2507.21905", "pdf": "https://arxiv.org/pdf/2507.21905", "abs": "https://arxiv.org/abs/2507.21905", "authors": ["Viacheslav Pirogov", "Maksim Artemev"], "title": "Evaluating Deepfake Detectors in the Wild", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted to the ICML 2025 Workshop 'DataWorld: Unifying Data Curation\n  Frameworks Across Domains'", "summary": "Deepfakes powered by advanced machine learning models present a significant\nand evolving threat to identity verification and the authenticity of digital\nmedia. Although numerous detectors have been developed to address this problem,\ntheir effectiveness has yet to be tested when applied to real-world data. In\nthis work we evaluate modern deepfake detectors, introducing a novel testing\nprocedure designed to mimic real-world scenarios for deepfake detection. Using\nstate-of-the-art deepfake generation methods, we create a comprehensive dataset\ncontaining more than 500,000 high-quality deepfake images. Our analysis shows\nthat detecting deepfakes still remains a challenging task. The evaluation shows\nthat in fewer than half of the deepfake detectors tested achieved an AUC score\ngreater than 60%, with the lowest being 50%. We demonstrate that basic image\nmanipulations, such as JPEG compression or image enhancement, can significantly\nreduce model performance. All code and data are publicly available at\nhttps://github.com/messlav/Deepfake-Detectors-in-the-Wild."}
{"id": "2507.21952", "pdf": "https://arxiv.org/pdf/2507.21952", "abs": "https://arxiv.org/abs/2507.21952", "authors": ["Peihong Lin", "Pengfei Wang", "Xu Zhou", "Wei Xie", "Gen Zhang", "Kai Lu"], "title": "DeepGo: Predictive Directed Greybox Fuzzing", "categories": ["cs.SE", "cs.LG"], "comment": null, "summary": "The state-of-the-art DGF techniques redefine and optimize the fitness metric\nto reach the target sites precisely and quickly. However, optimizations for\nfitness metrics are mainly based on heuristic algorithms, which usually rely on\nhistorical execution information and lack foresight on paths that have not been\nexercised yet. Thus, those hard-to-execute paths with complex constraints would\nhinder DGF from reaching the targets, making DGF less efficient. In this paper,\nwe propose DeepGo, a predictive directed grey-box fuzzer that can combine\nhistorical and predicted information to steer DGF to reach the target site via\nan optimal path. We first propose the path transition model, which models DGF\nas a process of reaching the target site through specific path transition\nsequences. The new seed generated by mutation would cause the path transition,\nand the path corresponding to the high-reward path transition sequence\nindicates a high likelihood of reaching the target site through it. Then, to\npredict the path transitions and the corresponding rewards, we use deep neural\nnetworks to construct a Virtual Ensemble Environment (VEE), which gradually\nimitates the path transition model and predicts the rewards of path transitions\nthat have not been taken yet. To determine the optimal path, we develop a\nReinforcement Learning for Fuzzing (RLF) model to generate the transition\nsequences with the highest sequence rewards. The RLF model can combine\nhistorical and predicted path transitions to generate the optimal path\ntransition sequences, along with the policy to guide the mutation strategy of\nfuzzing. Finally, to exercise the high-reward path transition sequence, we\npropose the concept of an action group, which comprehensively optimizes the\ncritical steps of fuzzing to realize the optimal path to reach the target\nefficiently."}
{"id": "2507.21964", "pdf": "https://arxiv.org/pdf/2507.21964", "abs": "https://arxiv.org/abs/2507.21964", "authors": ["Sourish Gunesh Dhekane", "Thomas Ploetz"], "title": "Thou Shalt Not Prompt: Zero-Shot Human Activity Recognition in Smart Homes via Language Modeling of Sensor Data & Activities", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Developing zero-shot human activity recognition (HAR) methods is a critical\ndirection in smart home research -- considering its impact on making HAR\nsystems work across smart homes having diverse sensing modalities, layouts, and\nactivities of interest. The state-of-the-art solutions along this direction are\nbased on generating natural language descriptions of the sensor data and\nfeeding it via a carefully crafted prompt to the LLM to perform classification.\nDespite their performance guarantees, such ``prompt-the-LLM'' approaches carry\nseveral risks, including privacy invasion, reliance on an external service, and\ninconsistent predictions due to version changes, making a case for alternative\nzero-shot HAR methods that do not require prompting the LLMs. In this paper, we\npropose one such solution that models sensor data and activities using natural\nlanguage, leveraging its embeddings to perform zero-shot classification and\nthereby bypassing the need to prompt the LLMs for activity predictions. The\nimpact of our work lies in presenting a detailed case study on six datasets,\nhighlighting how language modeling can bolster HAR systems in zero-shot\nrecognition."}
{"id": "2507.21984", "pdf": "https://arxiv.org/pdf/2507.21984", "abs": "https://arxiv.org/abs/2507.21984", "authors": ["Jona Nagerl", "Natalia G. Berloff"], "title": "Higher-Order Kuramoto Oscillator Network for Dense Associative Memory", "categories": ["nlin.AO", "cond-mat.dis-nn", "cond-mat.stat-mech", "cs.ET", "cs.LG"], "comment": "13 pages, 7 figures", "summary": "Networks of phase oscillators can serve as dense associative memories if they\nincorporate higher-order coupling beyond the classical Kuramoto model's\npairwise interactions. Here we introduce a generalized Kuramoto model with\ncombined second-harmonic (pairwise) and fourth-harmonic (quartic) coupling,\ninspired by dense Hopfield memory theory. Using mean-field theory and its\ndynamical approximation, we obtain a phase diagram for dense associative memory\nmodel that exhibits a tricritical point at which the continuous onset of memory\nretrieval is supplanted by a discontinuous, hysteretic transition. In the\nquartic-dominated regime, the system supports bistable phase-locked states\ncorresponding to stored memory patterns, with a sizable energy barrier between\nmemory and incoherent states. We analytically determine this bistable region\nand show that the escape time from a memory state (due to noise) grows\nexponentially with network size, indicating robust storage. Extending the\ntheory to finite memory load, we show that higher-order couplings achieve\nsuperlinear scaling of memory capacity with system size, far exceeding the\nlimit of pairwise-only oscillators. Large-scale simulations of the oscillator\nnetwork confirm our theoretical predictions, demonstrating rapid pattern\nretrieval and robust storage of many phase patterns. These results bridge the\nKuramoto synchronization with modern Hopfield memories, pointing toward\nexperimental realization of high-capacity, analog associative memory in\noscillator systems."}
{"id": "2507.22000", "pdf": "https://arxiv.org/pdf/2507.22000", "abs": "https://arxiv.org/abs/2507.22000", "authors": ["Oliver J. Sutton", "Qinghua Zhou", "George Leete", "Alexander N. Gorban", "Ivan Y. Tyukin"], "title": "Staining and locking computer vision models without retraining", "categories": ["cs.CV", "cs.AI", "cs.LG", "68T07, 68T45, 68W40", "I.2.10; F.2.0; K.5.1; K.6.5"], "comment": "10 pages, 9 pages of appendices, 10 figures", "summary": "We introduce new methods of staining and locking computer vision models, to\nprotect their owners' intellectual property. Staining, also known as\nwatermarking, embeds secret behaviour into a model which can later be used to\nidentify it, while locking aims to make a model unusable unless a secret\ntrigger is inserted into input images. Unlike existing methods, our algorithms\ncan be used to stain and lock pre-trained models without requiring fine-tuning\nor retraining, and come with provable, computable guarantees bounding their\nworst-case false positive rates. The stain and lock are implemented by directly\nmodifying a small number of the model's weights and have minimal impact on the\n(unlocked) model's performance. Locked models are unlocked by inserting a small\n`trigger patch' into the corner of the input image. We present experimental\nresults showing the efficacy of our methods and demonstrating their practical\nperformance on a variety of computer vision models."}
{"id": "2507.22010", "pdf": "https://arxiv.org/pdf/2507.22010", "abs": "https://arxiv.org/abs/2507.22010", "authors": ["Justin Curry", "Brennan Lagasse", "Ngoc B. Lam", "Gregory Cox", "David Rosenbluth", "Alberto Speranzon"], "title": "Exploring the Stratified Space Structure of an RL Game with the Volume Growth Transform", "categories": ["math.AT", "cs.AI", "cs.CG", "cs.LG", "math.DG", "58A35"], "comment": "17 pages and 8 figures. Preliminary report. Feedback welcome!", "summary": "In this work, we explore the structure of the embedding space of a\ntransformer model trained for playing a particular reinforcement learning (RL)\ngame. Specifically, we investigate how a transformer-based Proximal Policy\nOptimization (PPO) model embeds visual inputs in a simple environment where an\nagent must collect \"coins\" while avoiding dynamic obstacles consisting of\n\"spotlights.\" By adapting Robinson et al.'s study of the volume growth\ntransform for LLMs to the RL setting, we find that the token embedding space\nfor our visual coin collecting game is also not a manifold, and is better\nmodeled as a stratified space, where local dimension can vary from point to\npoint. We further strengthen Robinson's method by proving that fairly general\nvolume growth curves can be realized by stratified spaces. Finally, we carry\nout an analysis that suggests that as an RL agent acts, its latent\nrepresentation alternates between periods of low local dimension, while\nfollowing a fixed sub-strategy, and bursts of high local dimension, where the\nagent achieves a sub-goal (e.g., collecting an object) or where the\nenvironmental complexity increases (e.g., more obstacles appear). Consequently,\nour work suggests that the distribution of dimensions in a stratified latent\nspace may provide a new geometric indicator of complexity for RL games."}
{"id": "2507.22034", "pdf": "https://arxiv.org/pdf/2507.22034", "abs": "https://arxiv.org/abs/2507.22034", "authors": ["Cheng Qian", "Zuxin Liu", "Akshara Prabhakar", "Zhiwei Liu", "Jianguo Zhang", "Haolin Chen", "Heng Ji", "Weiran Yao", "Shelby Heinecke", "Silvio Savarese", "Caiming Xiong", "Huan Wang"], "title": "UserBench: An Interactive Gym Environment for User-Centric Agents", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "25 Pages, 17 Figures, 6 Tables", "summary": "Large Language Models (LLMs)-based agents have made impressive progress in\nreasoning and tool use, enabling them to solve complex tasks. However, their\nability to proactively collaborate with users, especially when goals are vague,\nevolving, or indirectly expressed, remains underexplored. To address this gap,\nwe introduce UserBench, a user-centric benchmark designed to evaluate agents in\nmulti-turn, preference-driven interactions. UserBench features simulated users\nwho start with underspecified goals and reveal preferences incrementally,\nrequiring agents to proactively clarify intent and make grounded decisions with\ntools. Our evaluation of leading open- and closed-source LLMs reveals a\nsignificant disconnect between task completion and user alignment. For\ninstance, models provide answers that fully align with all user intents only\n20% of the time on average, and even the most advanced models uncover fewer\nthan 30% of all user preferences through active interaction. These results\nhighlight the challenges of building agents that are not just capable task\nexecutors, but true collaborative partners. UserBench offers an interactive\nenvironment to measure and advance this critical capability."}
{"id": "2507.22039", "pdf": "https://arxiv.org/pdf/2507.22039", "abs": "https://arxiv.org/abs/2507.22039", "authors": ["Marco Parigi", "Mehran Khosrojerdi", "Filippo Caruso", "Leonardo Banchi"], "title": "Supervised Quantum Image Processing", "categories": ["quant-ph", "cs.AI", "cs.CV", "cs.LG", "81P68, 81P70, 81P40, 68Q12, 68T01", "I.2; I.4; J.2"], "comment": "13 pages, 11 figures", "summary": "In the era of big data and artificial intelligence, the increasing volume of\ndata and the demand to solve more and more complex computational challenges are\ntwo driving forces for improving the efficiency of data storage, processing and\nanalysis. Quantum image processing (QIP) is an interdisciplinary field between\nquantum information science and image processing, which has the potential to\nalleviate some of these challenges by leveraging the power of quantum\ncomputing. In this work, we compare and examine the compression properties of\nfour different Quantum Image Representations (QImRs): namely, Tensor Network\nRepresentation (TNR), Flexible Representation of Quantum Image (FRQI), Novel\nEnhanced Quantum Representation NEQR, and Quantum Probability Image Encoding\n(QPIE). Our simulations show that FRQI performs a higher compression of image\ninformation than TNR, NEQR, and QPIE. Furthermore, we investigate the trade-off\nbetween accuracy and memory in binary classification problems, evaluating the\nperformance of quantum kernels based on QImRs compared to the classical linear\nkernel. Our results indicate that quantum kernels provide comparable\nclassification average accuracy but require exponentially fewer resources for\nimage storage."}
