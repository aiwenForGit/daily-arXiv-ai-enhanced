{"id": "2509.16215", "pdf": "https://arxiv.org/pdf/2509.16215", "abs": "https://arxiv.org/abs/2509.16215", "authors": ["Izavan dos S. Correia", "Henrique C. T. Santos", "Tiago A. E. Ferreira"], "title": "Discovering Software Parallelization Points Using Deep Neural Networks", "categories": ["cs.LG", "cs.AI", "cs.DC", "cs.NE", "cs.PL", "cs.SE"], "comment": "17 pages, 10 figures", "summary": "This study proposes a deep learning-based approach for discovering loops in\nprogramming code according to their potential for parallelization. Two genetic\nalgorithm-based code generators were developed to produce two distinct types of\ncode: (i) independent loops, which are parallelizable, and (ii) ambiguous\nloops, whose dependencies are unclear, making them impossible to define if the\nloop is parallelizable or not. The generated code snippets were tokenized and\npreprocessed to ensure a robust dataset. Two deep learning models - a Deep\nNeural Network (DNN) and a Convolutional Neural Network (CNN) - were\nimplemented to perform the classification. Based on 30 independent runs, a\nrobust statistical analysis was employed to verify the expected performance of\nboth models, DNN and CNN. The CNN showed a slightly higher mean performance,\nbut the two models had a similar variability. Experiments with varying dataset\nsizes highlighted the importance of data diversity for model performance. These\nresults demonstrate the feasibility of using deep learning to automate the\nidentification of parallelizable structures in code, offering a promising tool\nfor software optimization and performance improvement."}
{"id": "2509.16233", "pdf": "https://arxiv.org/pdf/2509.16233", "abs": "https://arxiv.org/abs/2509.16233", "authors": ["Dipayan Sanpui", "Anirban Chandra", "Henry Chan", "Sukriti Manna", "Subramanian KRS Sankaranarayanan"], "title": "Comparison of Deterministic and Probabilistic Machine Learning Algorithms for Precise Dimensional Control and Uncertainty Quantification in Additive Manufacturing", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We present a probabilistic framework to accurately estimate dimensions of\nadditively manufactured components. Using a dataset of 405 parts from nine\nproduction runs involving two machines, three polymer materials, and two-part\nconfigurations, we examine five key design features. To capture both design\ninformation and manufacturing variability, we employ models integrating\ncontinuous and categorical factors. For predicting Difference from Target (DFT)\nvalues, we test deterministic and probabilistic machine learning methods.\nDeterministic models, trained on 80% of the dataset, provide precise point\nestimates, with Support Vector Regression (SVR) achieving accuracy close to\nprocess repeatability. To address systematic deviations, we adopt Gaussian\nProcess Regression (GPR) and Bayesian Neural Networks (BNNs). GPR delivers\nstrong predictive performance and interpretability, while BNNs capture both\naleatoric and epistemic uncertainties. We investigate two BNN approaches: one\nbalancing accuracy and uncertainty capture, and another offering richer\nuncertainty decomposition but with lower dimensional accuracy. Our results\nunderscore the importance of quantifying epistemic uncertainty for robust\ndecision-making, risk assessment, and model improvement. We discuss trade-offs\nbetween GPR and BNNs in terms of predictive power, interpretability, and\ncomputational efficiency, noting that model choice depends on analytical needs.\nBy combining deterministic precision with probabilistic uncertainty\nquantification, our study provides a rigorous foundation for uncertainty-aware\npredictive modeling in AM. This approach not only enhances dimensional accuracy\nbut also supports reliable, risk-informed design strategies, thereby advancing\ndata-driven manufacturing methodologies."}
{"id": "2509.16273", "pdf": "https://arxiv.org/pdf/2509.16273", "abs": "https://arxiv.org/abs/2509.16273", "authors": ["Jungseob Yi", "Seoyoung Choi", "Sun Kim", "Sangseon Lee"], "title": "SubDyve: Subgraph-Driven Dynamic Propagation for Virtual Screening Enhancement Controlling False Positive", "categories": ["cs.LG", "cs.AI"], "comment": "33 pages, 12 figures", "summary": "Virtual screening (VS) aims to identify bioactive compounds from vast\nchemical libraries, but remains difficult in low-label regimes where only a few\nactives are known. Existing methods largely rely on general-purpose molecular\nfingerprints and overlook class-discriminative substructures critical to\nbioactivity. Moreover, they consider molecules independently, limiting\neffectiveness in low-label regimes. We introduce SubDyve, a network-based VS\nframework that constructs a subgraph-aware similarity network and propagates\nactivity signals from a small known actives. When few active compounds are\navailable, SubDyve performs iterative seed refinement, incrementally promoting\nnew candidates based on local false discovery rate. This strategy expands the\nseed set with promising candidates while controlling false positives from\ntopological bias and overexpansion. We evaluate SubDyve on ten DUD-E targets\nunder zero-shot conditions and on the CDK7 target with a 10-million-compound\nZINC dataset. SubDyve consistently outperforms existing fingerprint or\nembedding-based approaches, achieving margins of up to +34.0 on the BEDROC and\n+24.6 on the EF1% metric."}
{"id": "2509.16277", "pdf": "https://arxiv.org/pdf/2509.16277", "abs": "https://arxiv.org/abs/2509.16277", "authors": ["Haobo Yang", "Shiyan Zhang", "Zhuoyi Yang", "Jilong Guo", "Jun Yang", "Xinyu Zhang"], "title": "Stabilizing Information Flow Entropy: Regularization for Safe and Interpretable Autonomous Driving Perception", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Deep perception networks in autonomous driving traditionally rely on\ndata-intensive training regimes and post-hoc anomaly detection, often\ndisregarding fundamental information-theoretic constraints governing stable\ninformation processing. We reconceptualize deep neural encoders as hierarchical\ncommunication chains that incrementally compress raw sensory inputs into\ntask-relevant latent features. Within this framework, we establish two\ntheoretically justified design principles for robust perception: (D1) smooth\nvariation of mutual information between consecutive layers, and (D2) monotonic\ndecay of latent entropy with network depth. Our analysis shows that, under\nrealistic architectural assumptions, particularly blocks comprising repeated\nlayers of similar capacity, enforcing smooth information flow (D1) naturally\nencourages entropy decay (D2), thus ensuring stable compression. Guided by\nthese insights, we propose Eloss, a novel entropy-based regularizer designed as\na lightweight, plug-and-play training objective. Rather than marginal accuracy\nimprovements, this approach represents a conceptual shift: it unifies\ninformation-theoretic stability with standard perception tasks, enabling\nexplicit, principled detection of anomalous sensor inputs through entropy\ndeviations. Experimental validation on large-scale 3D object detection\nbenchmarks (KITTI and nuScenes) demonstrates that incorporating Eloss\nconsistently achieves competitive or improved accuracy while dramatically\nenhancing sensitivity to anomalies, amplifying distribution-shift signals by up\nto two orders of magnitude. This stable information-compression perspective not\nonly improves interpretability but also establishes a solid theoretical\nfoundation for safer, more robust autonomous driving perception systems."}
{"id": "2509.16287", "pdf": "https://arxiv.org/pdf/2509.16287", "abs": "https://arxiv.org/abs/2509.16287", "authors": ["Shanookha Ali", "Nitha Niralda", "Sunil Mathew"], "title": "Architectural change in neural networks using fuzzy vertex pooling", "categories": ["cs.LG", "05C22, 05C90, 68R10"], "comment": null, "summary": "The process of pooling vertices involves the creation of a new vertex, which\nbecomes adjacent to all the vertices that were originally adjacent to the\nendpoints of the vertices being pooled. After this, the endpoints of these\nvertices and all edges connected to them are removed. In this document, we\nintroduce a formal framework for the concept of fuzzy vertex pooling (FVP) and\nprovide an overview of its key properties with its applications to neural\nnetworks. The pooling model demonstrates remarkable efficiency in minimizing\nloss rapidly while maintaining competitive accuracy, even with fewer hidden\nlayer neurons. However, this advantage diminishes over extended training\nperiods or with larger datasets, where the model's performance tends to\ndegrade. This study highlights the limitations of pooling in later stages of\ndeep learning training, rendering it less effective for prolonged or\nlarge-scale applications. Consequently, pooling is recommended as a strategy\nfor early-stage training in advanced deep learning models to leverage its\ninitial efficiency."}
{"id": "2509.16293", "pdf": "https://arxiv.org/pdf/2509.16293", "abs": "https://arxiv.org/abs/2509.16293", "authors": ["Borui Wan", "Gaohong Liu", "Zuquan Song", "Jun Wang", "Yun Zhang", "Guangming Sheng", "Shuguang Wang", "Houmin Wei", "Chenyuan Wang", "Weiqiang Lou", "Xi Yang", "Mofan Zhang", "Kaihua Jiang", "Cheng Ren", "Xiaoyun Zhi", "Menghan Yu", "Zhe Nan", "Zhuolin Zheng", "Baoquan Zhong", "Qinlong Wang", "Huan Yu", "Jinxin Chi", "Wang Zhang", "Yuhan Li", "Zixian Du", "Sida Zhao", "Yongqiang Zhang", "Jingzhe Tang", "Zherui Liu", "Chuan Wu", "Yanghua Peng", "Haibin Lin", "Wencong Xiao", "Xin Liu", "Liang Xiang"], "title": "Robust LLM Training Infrastructure at ByteDance", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": null, "summary": "The training scale of large language models (LLMs) has reached tens of\nthousands of GPUs and is still continuously expanding, enabling faster learning\nof larger models. Accompanying the expansion of the resource scale is the\nprevalence of failures (CUDA error, NaN values, job hang, etc.), which poses\nsignificant challenges to training stability. Any large-scale LLM training\ninfrastructure should strive for minimal training interruption, efficient fault\ndiagnosis, and effective failure tolerance to enable highly efficient\ncontinuous training. This paper presents ByteRobust, a large-scale GPU\ninfrastructure management system tailored for robust and stable training of\nLLMs. It exploits the uniqueness of LLM training process and gives top\npriorities to detecting and recovering failures in a routine manner. Leveraging\nparallelisms and characteristics of LLM training, ByteRobust enables\nhigh-capacity fault tolerance, prompt fault demarcation, and localization with\nan effective data-driven approach, comprehensively ensuring continuous and\nefficient training of LLM tasks. ByteRobust is deployed on a production GPU\nplatform with over 200,000 GPUs and achieves 97% ETTR for a three-month\ntraining job on 9,600 GPUs."}
{"id": "2509.16300", "pdf": "https://arxiv.org/pdf/2509.16300", "abs": "https://arxiv.org/abs/2509.16300", "authors": ["Manh Cuong Dao", "The Hung Tran", "Phi Le Nguyen", "Thao Nguyen Truong", "Trong Nghia Hoang"], "title": "ROOT: Rethinking Offline Optimization as Distributional Translation via Probabilistic Bridge", "categories": ["cs.LG"], "comment": "The first two authors contributed equally", "summary": "This paper studies the black-box optimization task which aims to find the\nmaxima of a black-box function using a static set of its observed input-output\npairs. This is often achieved via learning and optimizing a surrogate function\nwith that offline data. Alternatively, it can also be framed as an inverse\nmodeling task that maps a desired performance to potential input candidates\nthat achieve it. Both approaches are constrained by the limited amount of\noffline data. To mitigate this limitation, we introduce a new perspective that\ncasts offline optimization as a distributional translation task. This is\nformulated as learning a probabilistic bridge transforming an implicit\ndistribution of low-value inputs (i.e., offline data) into another distribution\nof high-value inputs (i.e., solution candidates). Such probabilistic bridge can\nbe learned using low- and high-value inputs sampled from synthetic functions\nthat resemble the target function. These synthetic functions are constructed as\nthe mean posterior of multiple Gaussian processes fitted with different\nparameterizations on the offline data, alleviating the data bottleneck. The\nproposed approach is evaluated on an extensive benchmark comprising most recent\nmethods, demonstrating significant improvement and establishing a new\nstate-of-the-art performance."}
{"id": "2509.16324", "pdf": "https://arxiv.org/pdf/2509.16324", "abs": "https://arxiv.org/abs/2509.16324", "authors": ["Jiale Han", "Chun Gan", "Chengcheng Zhang", "Jie He", "Zhangang Lin", "Ching Law", "Xiaowu Dai"], "title": "Auto-bidding under Return-on-Spend Constraints with Uncertainty Quantification", "categories": ["cs.LG", "cs.GT"], "comment": null, "summary": "Auto-bidding systems are widely used in advertising to automatically\ndetermine bid values under constraints such as total budget and Return-on-Spend\n(RoS) targets. Existing works often assume that the value of an ad impression,\nsuch as the conversion rate, is known. This paper considers the more realistic\nscenario where the true value is unknown. We propose a novel method that uses\nconformal prediction to quantify the uncertainty of these values based on\nmachine learning methods trained on historical bidding data with contextual\nfeatures, without assuming the data are i.i.d. This approach is compatible with\ncurrent industry systems that use machine learning to predict values. Building\non prediction intervals, we introduce an adjusted value estimator derived from\nmachine learning predictions, and show that it provides performance guarantees\nwithout requiring knowledge of the true value. We apply this method to enhance\nexisting auto-bidding algorithms with budget and RoS constraints, and establish\ntheoretical guarantees for achieving high reward while keeping RoS violations\nlow. Empirical results on both simulated and real-world industrial datasets\ndemonstrate that our approach improves performance while maintaining\ncomputational efficiency."}
{"id": "2509.16339", "pdf": "https://arxiv.org/pdf/2509.16339", "abs": "https://arxiv.org/abs/2509.16339", "authors": ["Josias K. Moukpe", "Philip K. Chan", "Ming Zhang"], "title": "Highly Imbalanced Regression with Tabular Data in SEP and Other Applications", "categories": ["cs.LG", "cs.AI"], "comment": "ICMLA 2025", "summary": "We investigate imbalanced regression with tabular data that have an imbalance\nratio larger than 1,000 (\"highly imbalanced\"). Accurately estimating the target\nvalues of rare instances is important in applications such as forecasting the\nintensity of rare harmful Solar Energetic Particle (SEP) events. For\nregression, the MSE loss does not consider the correlation between predicted\nand actual values. Typical inverse importance functions allow only convex\nfunctions. Uniform sampling might yield mini-batches that do not have rare\ninstances. We propose CISIR that incorporates correlation, Monotonically\nDecreasing Involution (MDI) importance, and stratified sampling. Based on five\ndatasets, our experimental results indicate that CISIR can achieve lower error\nand higher correlation than some recent methods. Also, adding our correlation\ncomponent to other recent methods can improve their performance. Lastly, MDI\nimportance can outperform other importance functions. Our code can be found in\nhttps://github.com/Machine-Earning/CISIR."}
{"id": "2509.16345", "pdf": "https://arxiv.org/pdf/2509.16345", "abs": "https://arxiv.org/abs/2509.16345", "authors": ["Minxiao Wang", "Runze Yan", "Carol Li", "Saurabh Kataria", "Xiao Hu", "Matthew Clark", "Timothy Ruchti", "Timothy G. Buchman", "Sivasubramanium V Bhavani", "Randall J. Lee"], "title": "Estimating Clinical Lab Test Result Trajectories from PPG using Physiological Foundation Model and Patient-Aware State Space Model -- a UNIPHY+ Approach", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Clinical laboratory tests provide essential biochemical measurements for\ndiagnosis and treatment, but are limited by intermittent and invasive sampling.\nIn contrast, photoplethysmogram (PPG) is a non-invasive, continuously recorded\nsignal in intensive care units (ICUs) that reflects cardiovascular dynamics and\ncan serve as a proxy for latent physiological changes. We propose UNIPHY+Lab, a\nframework that combines a large-scale PPG foundation model for local waveform\nencoding with a patient-aware Mamba model for long-range temporal modeling. Our\narchitecture addresses three challenges: (1) capturing extended temporal trends\nin laboratory values, (2) accounting for patient-specific baseline variation\nvia FiLM-modulated initial states, and (3) performing multi-task estimation for\ninterrelated biomarkers. We evaluate our method on the two ICU datasets for\npredicting the five key laboratory tests. The results show substantial\nimprovements over the LSTM and carry-forward baselines in MAE, RMSE, and $R^2$\namong most of the estimation targets. This work demonstrates the feasibility of\ncontinuous, personalized lab value estimation from routine PPG monitoring,\noffering a pathway toward non-invasive biochemical surveillance in critical\ncare."}
{"id": "2509.16354", "pdf": "https://arxiv.org/pdf/2509.16354", "abs": "https://arxiv.org/abs/2509.16354", "authors": ["Sivan Sarafian", "Yehudit Aperstein"], "title": "Improving Deep Tabular Learning", "categories": ["cs.LG"], "comment": "18 pages, 4 figures", "summary": "Tabular data remain a dominant form of real-world information but pose\npersistent challenges for deep learning due to heterogeneous feature types,\nlack of natural structure, and limited label-preserving augmentations. As a\nresult, ensemble models based on decision trees continue to dominate benchmark\nleaderboards. In this work, we introduce RuleNet, a transformer-based\narchitecture specifically designed for deep tabular learning. RuleNet\nincorporates learnable rule embeddings in a decoder, a piecewise linear\nquantile projection for numerical features, and feature masking ensembles for\nrobustness and uncertainty estimation. Evaluated on eight benchmark datasets,\nRuleNet matches or surpasses state-of-the-art tree-based methods in most cases,\nwhile remaining computationally efficient, offering a practical neural\nalternative for tabular prediction tasks."}
{"id": "2509.16357", "pdf": "https://arxiv.org/pdf/2509.16357", "abs": "https://arxiv.org/abs/2509.16357", "authors": ["Aniruddh Raghu", "Sebastian Ober", "Maxwell Kazman", "Hunter Elliott"], "title": "Guided Sequence-Structure Generative Modeling for Iterative Antibody Optimization", "categories": ["cs.LG"], "comment": "GEM Workshop, ICLR 2025", "summary": "Therapeutic antibody candidates often require extensive engineering to\nimprove key functional and developability properties before clinical\ndevelopment. This can be achieved through iterative design, where starting\nmolecules are optimized over several rounds of in vitro experiments. While\nprotein structure can provide a strong inductive bias, it is rarely used in\niterative design due to the lack of structural data for continually evolving\nlead molecules over the course of optimization. In this work, we propose a\nstrategy for iterative antibody optimization that leverages both sequence and\nstructure as well as accumulating lab measurements of binding and\ndevelopability. Building on prior work, we first train a sequence-structure\ndiffusion generative model that operates on antibody-antigen complexes. We then\noutline an approach to use this model, together with carefully predicted\nantibody-antigen complexes, to optimize lead candidates throughout the\niterative design process. Further, we describe a guided sampling approach that\nbiases generation toward desirable properties by integrating models trained on\nexperimental data from iterative design. We evaluate our approach in multiple\nin silico and in vitro experiments, demonstrating that it produces\nhigh-affinity binders at multiple stages of an active antibody optimization\ncampaign."}
{"id": "2509.16379", "pdf": "https://arxiv.org/pdf/2509.16379", "abs": "https://arxiv.org/abs/2509.16379", "authors": ["Xinran Liu", "Shansita D. Sharma", "Soheil Kolouri"], "title": "EMPEROR: Efficient Moment-Preserving Representation of Distributions", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We introduce EMPEROR (Efficient Moment-Preserving Representation of\nDistributions), a mathematically rigorous and computationally efficient\nframework for representing high-dimensional probability measures arising in\nneural network representations. Unlike heuristic global pooling operations,\nEMPEROR encodes a feature distribution through its statistical moments. Our\napproach leverages the theory of sliced moments: features are projected onto\nmultiple directions, lightweight univariate Gaussian mixture models (GMMs) are\nfit to each projection, and the resulting slice parameters are aggregated into\na compact descriptor. We establish determinacy guarantees via Carleman's\ncondition and the Cram\\'er-Wold theorem, ensuring that the GMM is uniquely\ndetermined by its sliced moments, and we derive finite-sample error bounds that\nscale optimally with the number of slices and samples. Empirically, EMPEROR\ncaptures richer distributional information than common pooling schemes across\nvarious data modalities, while remaining computationally efficient and broadly\napplicable."}
{"id": "2509.16391", "pdf": "https://arxiv.org/pdf/2509.16391", "abs": "https://arxiv.org/abs/2509.16391", "authors": ["Yasser H. Khalil", "Mehdi Setayesh", "Hongliang Li"], "title": "CoUn: Empowering Machine Unlearning via Contrastive Learning", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Machine unlearning (MU) aims to remove the influence of specific \"forget\"\ndata from a trained model while preserving its knowledge of the remaining\n\"retain\" data. Existing MU methods based on label manipulation or model weight\nperturbations often achieve limited unlearning effectiveness. To address this,\nwe introduce CoUn, a novel MU framework inspired by the observation that a\nmodel retrained from scratch using only retain data classifies forget data\nbased on their semantic similarity to the retain data. CoUn emulates this\nbehavior by adjusting learned data representations through contrastive learning\n(CL) and supervised learning, applied exclusively to retain data. Specifically,\nCoUn (1) leverages semantic similarity between data samples to indirectly\nadjust forget representations using CL, and (2) maintains retain\nrepresentations within their respective clusters through supervised learning.\nExtensive experiments across various datasets and model architectures show that\nCoUn consistently outperforms state-of-the-art MU baselines in unlearning\neffectiveness. Additionally, integrating our CL module into existing baselines\nempowers their unlearning effectiveness."}
{"id": "2509.16393", "pdf": "https://arxiv.org/pdf/2509.16393", "abs": "https://arxiv.org/abs/2509.16393", "authors": ["Manuel Noseda", "Alberto De Luca", "Lukas Von Briel", "Nathan Lacour"], "title": "Federated Learning for Financial Forecasting", "categories": ["cs.LG", "stat.AP"], "comment": null, "summary": "This paper studies Federated Learning (FL) for binary classification of\nvolatile financial market trends. Using a shared Long Short-Term Memory (LSTM)\nclassifier, we compare three scenarios: (i) a centralized model trained on the\nunion of all data, (ii) a single-agent model trained on an individual data\nsubset, and (iii) a privacy-preserving FL collaboration in which agents\nexchange only model updates, never raw data. We then extend the study with\nadditional market features, deliberately introducing not independent and\nidentically distributed data (non-IID) across agents, personalized FL and\nemploying differential privacy. Our numerical experiments show that FL achieves\naccuracy and generalization on par with the centralized baseline, while\nsignificantly outperforming the single-agent model. The results show that\ncollaborative, privacy-preserving learning provides collective tangible value\nin finance, even under realistic data heterogeneity and personalization\nrequirements."}
{"id": "2509.16397", "pdf": "https://arxiv.org/pdf/2509.16397", "abs": "https://arxiv.org/abs/2509.16397", "authors": ["Taqiya Ehsan", "Shuren Xia", "Jorge Ortiz"], "title": "GRID: Graph-based Reasoning for Intervention and Discovery in Built Environments", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Manual HVAC fault diagnosis in commercial buildings takes 8-12 hours per\nincident and achieves only 60 percent diagnostic accuracy, reflecting analytics\nthat stop at correlation instead of causation. To close this gap, we present\nGRID (Graph-based Reasoning for Intervention and Discovery), a three-stage\ncausal discovery pipeline that combines constraint-based search, neural\nstructural equation modeling, and language model priors to recover directed\nacyclic graphs from building sensor data. Across six benchmarks: synthetic\nrooms, EnergyPlus simulation, the ASHRAE Great Energy Predictor III dataset,\nand a live office testbed, GRID achieves F1 scores ranging from 0.65 to 1.00,\nwith exact recovery (F1 = 1.00) in three controlled environments (Base, Hidden,\nPhysical) and strong performance on real-world data (F1 = 0.89 on ASHRAE, 0.86\nin noisy conditions). The method outperforms ten baseline approaches across all\nevaluation scenarios. Intervention scheduling achieves low operational impact\nin most scenarios (cost <= 0.026) while reducing risk metrics compared to\nbaseline approaches. The framework integrates constraint-based methods, neural\narchitectures, and domain-specific language model prompts to address the\nobservational-causal gap in building analytics."}
{"id": "2509.16447", "pdf": "https://arxiv.org/pdf/2509.16447", "abs": "https://arxiv.org/abs/2509.16447", "authors": ["Arwen Bradley"], "title": "Local Mechanisms of Compositional Generalization in Conditional Diffusion", "categories": ["cs.LG"], "comment": "10 pages, 7 figures", "summary": "Conditional diffusion models appear capable of compositional generalization,\ni.e., generating convincing samples for out-of-distribution combinations of\nconditioners, but the mechanisms underlying this ability remain unclear. To\nmake this concrete, we study length generalization, the ability to generate\nimages with more objects than seen during training. In a controlled CLEVR\nsetting (Johnson et al., 2017), we find that length generalization is\nachievable in some cases but not others, suggesting that models only sometimes\nlearn the underlying compositional structure. We then investigate locality as a\nstructural mechanism for compositional generalization. Prior works proposed\nscore locality as a mechanism for creativity in unconditional diffusion models\n(Kamb & Ganguli, 2024; Niedoba et al., 2024), but did not address flexible\nconditioning or compositional generalization. In this paper, we prove an exact\nequivalence between a specific compositional structure (\"conditional projective\ncomposition\") (Bradley et al., 2025) and scores with sparse dependencies on\nboth pixels and conditioners (\"local conditional scores\"). This theory also\nextends to feature-space compositionality. We validate our theory empirically:\nCLEVR models that succeed at length generalization exhibit local conditional\nscores, while those that fail do not. Furthermore, we show that a causal\nintervention explicitly enforcing local conditional scores restores length\ngeneralization in a previously failing model. Finally, we investigate\nfeature-space compositionality in color-conditioned CLEVR, and find preliminary\nevidence of compositional structure in SDXL."}
{"id": "2509.16463", "pdf": "https://arxiv.org/pdf/2509.16463", "abs": "https://arxiv.org/abs/2509.16463", "authors": ["Spencer Compton", "Kristjan Greenewald", "Dmitriy Katz", "Murat Kocaoglu"], "title": "Entropic Causal Inference: Graph Identifiability", "categories": ["cs.LG", "cs.AI"], "comment": "Presented at ICML 2022. This version corrects a bug in semi-synthetic\n  experiments", "summary": "Entropic causal inference is a recent framework for learning the causal graph\nbetween two variables from observational data by finding the\ninformation-theoretically simplest structural explanation of the data, i.e.,\nthe model with smallest entropy. In our work, we first extend the causal graph\nidentifiability result in the two-variable setting under relaxed assumptions.\nWe then show the first identifiability result using the entropic approach for\nlearning causal graphs with more than two nodes. Our approach utilizes the\nproperty that ancestrality between a source node and its descendants can be\ndetermined using the bivariate entropic tests. We provide a sound sequential\npeeling algorithm for general graphs that relies on this property. We also\npropose a heuristic algorithm for small graphs that shows strong empirical\nperformance. We rigorously evaluate the performance of our algorithms on\nsynthetic data generated from a variety of models, observing improvement over\nprior work. Finally we test our algorithms on real-world datasets."}
{"id": "2509.16475", "pdf": "https://arxiv.org/pdf/2509.16475", "abs": "https://arxiv.org/abs/2509.16475", "authors": ["Tianchun Li", "Tianci Liu", "Xingchen Wang", "Rongzhe Wei", "Pan Li", "Lu Su", "Jing Gao"], "title": "Towards Universal Debiasing for Language Models-based Tabular Data Generation", "categories": ["cs.LG", "cs.CL"], "comment": "EMNLP 2025 Findings", "summary": "Large language models (LLMs) have achieved promising results in tabular data\ngeneration. However, inherent historical biases in tabular datasets often cause\nLLMs to exacerbate fairness issues, particularly when multiple advantaged and\nprotected features are involved. In this work, we introduce a universal\ndebiasing framework that minimizes group-level dependencies by simultaneously\nreducing the mutual information between advantaged and protected attributes. By\nleveraging the autoregressive structure and analytic sampling distributions of\nLLM-based tabular data generators, our approach efficiently computes mutual\ninformation, reducing the need for cumbersome numerical estimations. Building\non this foundation, we propose two complementary methods: a direct preference\noptimization (DPO)-based strategy, namely UDF-DPO, that integrates seamlessly\nwith existing models, and a targeted debiasing technique, namely UDF-MIX, that\nachieves debiasing without tuning the parameters of LLMs. Extensive experiments\ndemonstrate that our framework effectively balances fairness and utility,\noffering a scalable and practical solution for debiasing in high-stakes\napplications."}
{"id": "2509.16490", "pdf": "https://arxiv.org/pdf/2509.16490", "abs": "https://arxiv.org/abs/2509.16490", "authors": ["Ziyao Cui", "Erick Jiang", "Nicholas Sortisio", "Haiyan Wang", "Eric Chen", "Cynthia Rudin"], "title": "Revisiting Broken Windows Theory", "categories": ["cs.LG"], "comment": null, "summary": "We revisit the longstanding question of how physical structures in urban\nlandscapes influence crime. Leveraging machine learning-based matching\ntechniques to control for demographic composition, we estimate the effects of\nseveral types of urban structures on the incidence of violent crime in New York\nCity and Chicago. We additionally contribute to a growing body of literature\ndocumenting the relationship between perception of crime and actual crime rates\nby separately analyzing how the physical urban landscape shapes subjective\nfeelings of safety. Our results are twofold. First, in consensus with prior\nwork, we demonstrate a \"broken windows\" effect in which abandoned buildings, a\nsign of social disorder, are associated with both greater incidence of crime\nand a heightened perception of danger. This is also true of types of urban\nstructures that draw foot traffic such as public transportation infrastructure.\nSecond, these effects are not uniform within or across cities. The criminogenic\neffects of the same structure types across two cities differ in magnitude,\ndegree of spatial localization, and heterogeneity across subgroups, while\nwithin the same city, the effects of different structure types are confounded\nby different demographic variables. Taken together, these results emphasize\nthat one-size-fits-all approaches to crime reduction are untenable and policy\ninterventions must be specifically tailored to their targets."}
{"id": "2509.16491", "pdf": "https://arxiv.org/pdf/2509.16491", "abs": "https://arxiv.org/abs/2509.16491", "authors": ["Lovely Yeswanth Panchumarthi", "Saurabh Kataria", "Yi Wu", "Xiao Hu", "Alex Fedorov", "Hyunjung Gloria Kwak"], "title": "FairTune: A Bias-Aware Fine-Tuning Framework Towards Fair Heart Rate Prediction from PPG", "categories": ["cs.LG", "cs.CE"], "comment": null, "summary": "Foundation models pretrained on physiological data such as\nphotoplethysmography (PPG) signals are increasingly used to improve heart rate\n(HR) prediction across diverse settings. Fine-tuning these models for local\ndeployment is often seen as a practical and scalable strategy. However, its\nimpact on demographic fairness particularly under domain shifts remains\nunderexplored. We fine-tune PPG-GPT a transformer-based foundation model\npretrained on intensive care unit (ICU) data across three heterogeneous\ndatasets (ICU, wearable, smartphone) and systematically evaluate the effects on\nHR prediction accuracy and gender fairness. While fine-tuning substantially\nreduces mean absolute error (up to 80%), it can simultaneously widen fairness\ngaps, especially in larger models and under significant distributional\ncharacteristics shifts. To address this, we introduce FairTune, a bias-aware\nfine-tuning framework in which we benchmark three mitigation strategies: class\nweighting based on inverse group frequency (IF), Group Distributionally Robust\nOptimization (GroupDRO), and adversarial debiasing (ADV). We find that IF and\nGroupDRO significantly reduce fairness gaps without compromising accuracy, with\neffectiveness varying by deployment domain. Representation analyses further\nreveal that mitigation techniques reshape internal embeddings to reduce\ndemographic clustering. Our findings highlight that fairness does not emerge as\na natural byproduct of fine-tuning and that explicit mitigation is essential\nfor equitable deployment of physiological foundation models."}
{"id": "2509.16499", "pdf": "https://arxiv.org/pdf/2509.16499", "abs": "https://arxiv.org/abs/2509.16499", "authors": ["Lianghe Shi", "Meng Wu", "Huijie Zhang", "Zekai Zhang", "Molei Tao", "Qing Qu"], "title": "A Closer Look at Model Collapse: From a Generalization-to-Memorization Perspective", "categories": ["cs.LG"], "comment": "NeurIPS 2025 Spotlight paper", "summary": "The widespread use of diffusion models has led to an abundance of\nAI-generated data, raising concerns about model collapse -- a phenomenon in\nwhich recursive iterations of training on synthetic data lead to performance\ndegradation. Prior work primarily characterizes this collapse via variance\nshrinkage or distribution shift, but these perspectives miss practical\nmanifestations of model collapse. This paper identifies a transition from\ngeneralization to memorization during model collapse in diffusion models, where\nmodels increasingly replicate training data instead of generating novel content\nduring iterative training on synthetic samples. This transition is directly\ndriven by the declining entropy of the synthetic training data produced in each\ntraining cycle, which serves as a clear indicator of model degradation.\nMotivated by this insight, we propose an entropy-based data selection strategy\nto mitigate the transition from generalization to memorization and alleviate\nmodel collapse. Empirical results show that our approach significantly enhances\nvisual quality and diversity in recursive generation, effectively preventing\ncollapse."}
{"id": "2509.16502", "pdf": "https://arxiv.org/pdf/2509.16502", "abs": "https://arxiv.org/abs/2509.16502", "authors": ["Jialin Chen", "Houyu Zhang", "Seongjun Yun", "Alejandro Mottini", "Rex Ying", "Xiang Song", "Vassilis N. Ioannidis", "Zheng Li", "Qingjun Cui"], "title": "GRIL: Knowledge Graph Retrieval-Integrated Learning with Large Language Models", "categories": ["cs.LG"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) has significantly mitigated the\nhallucinations of Large Language Models (LLMs) by grounding the generation with\nexternal knowledge. Recent extensions of RAG to graph-based retrieval offer a\npromising direction, leveraging the structural knowledge for multi-hop\nreasoning. However, existing graph RAG typically decouples retrieval and\nreasoning processes, which prevents the retriever from adapting to the\nreasoning needs of the LLM. They also struggle with scalability when performing\nmulti-hop expansion over large-scale graphs, or depend heavily on annotated\nground-truth entities, which are often unavailable in open-domain settings. To\naddress these challenges, we propose a novel graph retriever trained end-to-end\nwith LLM, which features an attention-based growing and pruning mechanism,\nadaptively navigating multi-hop relevant entities while filtering out noise.\nWithin the extracted subgraph, structural knowledge and semantic features are\nencoded via soft tokens and the verbalized graph, respectively, which are\ninfused into the LLM together, thereby enhancing its reasoning capability and\nfacilitating interactive joint training of the graph retriever and the LLM\nreasoner. Experimental results across three QA benchmarks show that our\napproach consistently achieves state-of-the-art performance, validating the\nstrength of joint graph-LLM optimization for complex reasoning tasks. Notably,\nour framework eliminates the need for predefined ground-truth entities by\ndirectly optimizing the retriever using LLM logits as implicit feedback, making\nit especially effective in open-domain settings."}
{"id": "2509.16508", "pdf": "https://arxiv.org/pdf/2509.16508", "abs": "https://arxiv.org/abs/2509.16508", "authors": ["Marijan Fofonjka", "Shahryar Zehtabi", "Alireza Behtash", "Tyler Mauer", "David Stout"], "title": "Federated Learning with Ad-hoc Adapter Insertions: The Case of Soft-Embeddings for Training Classifier-as-Retriever", "categories": ["cs.LG"], "comment": "22 pages, 7 figures, 3 tables", "summary": "When existing retrieval-augmented generation (RAG) solutions are intended to\nbe used for new knowledge domains, it is necessary to update their encoders,\nwhich are taken to be pretrained large language models (LLMs). However, fully\nfinetuning these large models is compute- and memory-intensive, and even\ninfeasible when deployed on resource-constrained edge devices. We propose a\nnovel encoder architecture in this work that addresses this limitation by using\na frozen small language model (SLM), which satisfies the memory constraints of\nedge devices, and inserting a small adapter network before the transformer\nblocks of the SLM. The trainable adapter takes the token embeddings of the new\ncorpus and learns to produce enhanced soft embeddings for it, while requiring\nsignificantly less compute power to update than full fine-tuning. We further\npropose a novel retrieval mechanism by attaching a classifier head to the SLM\nencoder, which is trained to learn a similarity mapping of the input embeddings\nto their corresponding documents. Finally, to enable the online fine-tuning of\nboth (i) the encoder soft embeddings and (ii) the classifier-as-retriever on\nedge devices, we adopt federated learning (FL) and differential privacy (DP) to\nachieve an efficient, privacy-preserving, and product-grade training solution.\nWe conduct a theoretical analysis of our methodology, establishing convergence\nguarantees under mild assumptions on gradient variance when deployed for\ngeneral smooth nonconvex loss functions. Through extensive numerical\nexperiments, we demonstrate (i) the efficacy of obtaining soft embeddings to\nenhance the encoder, (ii) training a classifier to improve the retriever, and\n(iii) the role of FL in achieving speedup."}
{"id": "2509.16516", "pdf": "https://arxiv.org/pdf/2509.16516", "abs": "https://arxiv.org/abs/2509.16516", "authors": ["Md Mezbaur Rahman", "Cornelia Caragea"], "title": "LLM-Guided Co-Training for Text Classification", "categories": ["cs.LG"], "comment": null, "summary": "In this paper, we introduce a novel weighted co-training approach that is\nguided by Large Language Models (LLMs). Namely, in our co-training approach, we\nuse LLM labels on unlabeled data as target labels and co-train two encoder-only\nbased networks that train each other over multiple iterations: first, all\nsamples are forwarded through each network and historical estimates of each\nnetwork's confidence in the LLM label are recorded; second, a dynamic\nimportance weight is derived for each sample according to each network's belief\nin the quality of the LLM label for that sample; finally, the two networks\nexchange importance weights with each other -- each network back-propagates all\nsamples weighted with the importance weights coming from its peer network and\nupdates its own parameters. By strategically utilizing LLM-generated guidance,\nour approach significantly outperforms conventional SSL methods, particularly\nin settings with abundant unlabeled data. Empirical results show that it\nachieves state-of-the-art performance on 4 out of 5 benchmark datasets and\nranks first among 14 compared methods according to the Friedman test. Our\nresults highlight a new direction in semi-supervised learning -- where LLMs\nserve as knowledge amplifiers, enabling backbone co-training models to achieve\nstate-of-the-art performance efficiently."}
{"id": "2509.16521", "pdf": "https://arxiv.org/pdf/2509.16521", "abs": "https://arxiv.org/abs/2509.16521", "authors": ["Yifan Yan", "Shuai Yang", "Xiuzhen Guo", "Xiangguang Wang", "Wei Chow", "Yuanchao Shu", "Shibo He"], "title": "mmExpert: Integrating Large Language Models for Comprehensive mmWave Data Synthesis and Understanding", "categories": ["cs.LG"], "comment": "Accepted to ACM MobiHoc '25", "summary": "Millimeter-wave (mmWave) sensing technology holds significant value in\nhuman-centric applications, yet the high costs associated with data acquisition\nand annotation limit its widespread adoption in our daily lives. Concurrently,\nthe rapid evolution of large language models (LLMs) has opened up opportunities\nfor addressing complex human needs. This paper presents mmExpert, an innovative\nmmWave understanding framework consisting of a data generation flywheel that\nleverages LLMs to automate the generation of synthetic mmWave radar datasets\nfor specific application scenarios, thereby training models capable of\nzero-shot generalization in real-world environments. Extensive experiments\ndemonstrate that the data synthesized by mmExpert significantly enhances the\nperformance of downstream models and facilitates the successful deployment of\nlarge models for mmWave understanding."}
{"id": "2509.16548", "pdf": "https://arxiv.org/pdf/2509.16548", "abs": "https://arxiv.org/abs/2509.16548", "authors": ["Yuyang Ding", "Xinyu Shi", "Juntao Li", "Xiaobo Liang", "Zhaopeng Tu", "Min Zhang"], "title": "SCAN: Self-Denoising Monte Carlo Annotation for Robust Process Reward Learning", "categories": ["cs.LG", "cs.CL"], "comment": "NeurIPS 2025. Project page: https://scan-prm.github.io/", "summary": "Process reward models (PRMs) offer fine-grained, step-level evaluations that\nfacilitate deeper reasoning processes in large language models (LLMs), proving\neffective in complex tasks like mathematical reasoning. However, developing\nPRMs is challenging due to the high cost and limited scalability of\nhuman-annotated data. Synthetic data from Monte Carlo (MC) estimation is a\npromising alternative but suffers from a high noise ratio, which can cause\noverfitting and hinder large-scale training. In this work, we conduct a\npreliminary study on the noise distribution in synthetic data from MC\nestimation, identifying that annotation models tend to both underestimate and\noverestimate step correctness due to limitations in their annotation\ncapabilities. Building on these insights, we propose Self-Denoising Monte Carlo\nAnnotation (SCAN), an efficient data synthesis and noise-tolerant learning\nframework. Our key findings indicate that: (1) Even lightweight models (e.g.,\n1.5B parameters) can produce high-quality annotations through a self-denoising\nstrategy, enabling PRMs to achieve superior performance with only 6% the\ninference cost required by vanilla MC estimation. (2) With our robust learning\nstrategy, PRMs can effectively learn from this weak supervision, achieving a\n39.2 F1 score improvement (from 19.9 to 59.1) in ProcessBench. Despite using\nonly a compact synthetic dataset, our models surpass strong baselines,\nincluding those trained on large-scale human-annotated datasets such as\nPRM800K. Furthermore, performance continues to improve as we scale up the\nsynthetic data, highlighting the potential of SCAN for scalable,\ncost-efficient, and robust PRM training."}
{"id": "2509.16554", "pdf": "https://arxiv.org/pdf/2509.16554", "abs": "https://arxiv.org/abs/2509.16554", "authors": ["Vahid Jebraeeli", "Hamid Krim", "Derya Cansever"], "title": "ViTCAE: ViT-based Class-conditioned Autoencoder", "categories": ["cs.LG", "cs.CV"], "comment": "-", "summary": "Vision Transformer (ViT) based autoencoders often underutilize the global\nClass token and employ static attention mechanisms, limiting both generative\ncontrol and optimization efficiency. This paper introduces ViTCAE, a framework\nthat addresses these issues by re-purposing the Class token into a generative\nlinchpin. In our architecture, the encoder maps the Class token to a global\nlatent variable that dictates the prior distribution for local, patch-level\nlatent variables, establishing a robust dependency where global semantics\ndirectly inform the synthesis of local details. Drawing inspiration from\nopinion dynamics, we treat each attention head as a dynamical system of\ninteracting tokens seeking consensus. This perspective motivates a\nconvergence-aware temperature scheduler that adaptively anneals each head's\ninfluence function based on its distributional stability. This process enables\na principled head-freezing mechanism, guided by theoretically-grounded\ndiagnostics like an attention evolution distance and a consensus/cluster\nfunctional. This technique prunes converged heads during training to\nsignificantly improve computational efficiency without sacrificing fidelity. By\nunifying a generative Class token with an adaptive attention mechanism rooted\nin multi-agent consensus theory, ViTCAE offers a more efficient and\ncontrollable approach to transformer-based generation."}
{"id": "2509.16577", "pdf": "https://arxiv.org/pdf/2509.16577", "abs": "https://arxiv.org/abs/2509.16577", "authors": ["Antonio Tarizzo", "Mohammad Kazemi", "Deniz Gündüz"], "title": "Learned Digital Codes for Over-the-Air Federated Learning", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Federated edge learning (FEEL) enables distributed model training across\nwireless devices without centralising raw data, but deployment is constrained\nby the wireless uplink. A promising direction is over-the-air (OTA)\naggregation, which merges communication with computation. Existing digital OTA\nmethods can achieve either strong convergence or robustness to noise, but\nstruggle to achieve both simultaneously, limiting performance in low\nsignal-to-noise ratios (SNRs) where many IoT devices operate. This work\nproposes a learnt digital OTA framework that extends reliable operation into\nlow-SNR conditions while maintaining the same uplink overhead as\nstate-of-the-art. The proposed method combines an unrolled decoder with a\njointly learnt unsourced random access codebook. Results show an extension of\nreliable operation by more than 7 dB, with improved global model convergence\nacross all SNR levels, highlighting the potential of learning-based design for\nFEEL."}
{"id": "2509.16586", "pdf": "https://arxiv.org/pdf/2509.16586", "abs": "https://arxiv.org/abs/2509.16586", "authors": ["Yukuan Wei", "Xudong Li", "Lin F. Yang"], "title": "Near-Optimal Sample Complexity Bounds for Constrained Average-Reward MDPs", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Recent advances have significantly improved our understanding of the sample\ncomplexity of learning in average-reward Markov decision processes (AMDPs)\nunder the generative model. However, much less is known about the constrained\naverage-reward MDP (CAMDP), where policies must satisfy long-run average\nconstraints. In this work, we address this gap by studying the sample\ncomplexity of learning an $\\epsilon$-optimal policy in CAMDPs under a\ngenerative model. We propose a model-based algorithm that operates under two\nsettings: (i) relaxed feasibility, which allows small constraint violations,\nand (ii) strict feasibility, where the output policy satisfies the constraint.\nWe show that our algorithm achieves sample complexities of\n$\\tilde{O}\\left(\\frac{S A (B+H)}{ \\epsilon^2}\\right)$ and $\\tilde{O}\n\\left(\\frac{S A (B+H)}{\\epsilon^2 \\zeta^2} \\right)$ under the relaxed and\nstrict feasibility settings, respectively. Here, $\\zeta$ is the Slater constant\nindicating the size of the feasible region, $H$ is the span bound of the bias\nfunction, and $B$ is the transient time bound. Moreover, a matching lower bound\nof $\\tilde{\\Omega}\\left(\\frac{S A (B+H)}{ \\epsilon^2\\zeta^2}\\right)$ for the\nstrict feasibility case is established, thus providing the first\nminimax-optimal bounds for CAMDPs. Our results close the theoretical gap in\nunderstanding the complexity of constrained average-reward MDPs."}
{"id": "2509.16625", "pdf": "https://arxiv.org/pdf/2509.16625", "abs": "https://arxiv.org/abs/2509.16625", "authors": ["Lorenzo Guerra", "Thomas Chapuis", "Guillaume Duc", "Pavlo Mozharovskyi", "Van-Tam Nguyen"], "title": "Self-Supervised Learning of Graph Representations for Network Intrusion Detection", "categories": ["cs.LG", "cs.CR"], "comment": "Accepted at NeurIPS 2025", "summary": "Detecting intrusions in network traffic is a challenging task, particularly\nunder limited supervision and constantly evolving attack patterns. While recent\nworks have leveraged graph neural networks for network intrusion detection,\nthey often decouple representation learning from anomaly detection, limiting\nthe utility of the embeddings for identifying attacks. We propose GraphIDS, a\nself-supervised intrusion detection model that unifies these two stages by\nlearning local graph representations of normal communication patterns through a\nmasked autoencoder. An inductive graph neural network embeds each flow with its\nlocal topological context to capture typical network behavior, while a\nTransformer-based encoder-decoder reconstructs these embeddings, implicitly\nlearning global co-occurrence patterns via self-attention without requiring\nexplicit positional information. During inference, flows with unusually high\nreconstruction errors are flagged as potential intrusions. This end-to-end\nframework ensures that embeddings are directly optimized for the downstream\ntask, facilitating the recognition of malicious traffic. On diverse NetFlow\nbenchmarks, GraphIDS achieves up to 99.98% PR-AUC and 99.61% macro F1-score,\noutperforming baselines by 5-25 percentage points."}
{"id": "2509.16629", "pdf": "https://arxiv.org/pdf/2509.16629", "abs": "https://arxiv.org/abs/2509.16629", "authors": ["Kaichen Xu", "Yihang Du", "Mianpeng Liu", "Zimu Yu", "Xiaobo Sun"], "title": "Causality-Induced Positional Encoding for Transformer-Based Representation Learning of Non-Sequential Features", "categories": ["cs.LG", "q-bio.QM"], "comment": "Accepted by NeurIPS 2025", "summary": "Positional encoding is essential for supplementing transformer with\npositional information of tokens. Existing positional encoding methods demand\npredefined token/feature order, rendering them unsuitable for real-world data\nwith non-sequential yet causally-related features. To address this limitation,\nwe propose CAPE, a novel method that identifies underlying causal structure\nover non-sequential features as a weighted directed acyclic graph (DAG) using\ngeneralized structural equation modeling. The DAG is then embedded in\nhyperbolic space where its geometric structure is well-preserved using a\nhyperboloid model-based approach that effectively captures two important causal\ngraph properties (causal strength & causal specificity). This step yields\ncausality-aware positional encodings for the features, which are converted into\ntheir rotary form for integrating with transformer's self-attention mechanism.\nTheoretical analysis reveals that CAPE-generated rotary positional encodings\npossess three valuable properties for enhanced self-attention, including causal\ndistance-induced attenuation, causal generality-induced attenuation, and\nrobustness to positional disturbances. We evaluate CAPE over both synthetic and\nreal-word datasets, empirically demonstrating its theoretical properties and\neffectiveness in enhancing transformer for data with non-sequential features.\nOur code is available at https://github.com/Catchxu/CAPE."}
{"id": "2509.16664", "pdf": "https://arxiv.org/pdf/2509.16664", "abs": "https://arxiv.org/abs/2509.16664", "authors": ["Simone Ricci", "Niccolò Biondi", "Federico Pernici", "Ioannis Patras", "Alberto Del Bimbo"], "title": "$\\boldsymbolλ$-Orthogonality Regularization for Compatible Representation Learning", "categories": ["cs.LG"], "comment": "Accepted at NeurIPS2025", "summary": "Retrieval systems rely on representations learned by increasingly powerful\nmodels. However, due to the high training cost and inconsistencies in learned\nrepresentations, there is significant interest in facilitating communication\nbetween representations and ensuring compatibility across independently trained\nneural networks. In the literature, two primary approaches are commonly used to\nadapt different learned representations: affine transformations, which adapt\nwell to specific distributions but can significantly alter the original\nrepresentation, and orthogonal transformations, which preserve the original\nstructure with strict geometric constraints but limit adaptability. A key\nchallenge is adapting the latent spaces of updated models to align with those\nof previous models on downstream distributions while preserving the newly\nlearned representation spaces. In this paper, we impose a relaxed orthogonality\nconstraint, namely $\\lambda$-orthogonality regularization, while learning an\naffine transformation, to obtain distribution-specific adaptation while\nretaining the original learned representations. Extensive experiments across\nvarious architectures and datasets validate our approach, demonstrating that it\npreserves the model's zero-shot performance and ensures compatibility across\nmodel updates. Code available at:\nhttps://github.com/miccunifi/lambda_orthogonality"}
{"id": "2509.16709", "pdf": "https://arxiv.org/pdf/2509.16709", "abs": "https://arxiv.org/abs/2509.16709", "authors": ["Nicolò Botteghi", "Matteo Tomasetto", "Urban Fasel", "Francesco Braghin", "Andrea Manzoni"], "title": "HypeMARL: Multi-Agent Reinforcement Learning For High-Dimensional, Parametric, and Distributed Systems", "categories": ["cs.LG"], "comment": null, "summary": "Deep reinforcement learning has recently emerged as a promising feedback\ncontrol strategy for complex dynamical systems governed by partial differential\nequations (PDEs). When dealing with distributed, high-dimensional problems in\nstate and control variables, multi-agent reinforcement learning (MARL) has been\nproposed as a scalable approach for breaking the curse of dimensionality. In\nparticular, through decentralized training and execution, multiple agents\ncooperate to steer the system towards a target configuration, relying solely on\nlocal state and reward information. However, the principle of locality may\nbecome a limiting factor whenever a collective, nonlocal behavior of the agents\nis crucial to maximize the reward function, as typically happens in\nPDE-constrained optimal control problems. In this work, we propose HypeMARL: a\ndecentralized MARL algorithm tailored to the control of high-dimensional,\nparametric, and distributed systems. HypeMARL employs hypernetworks to\neffectively parametrize the agents' policies and value functions with respect\nto the system parameters and the agents' relative positions, encoded by\nsinusoidal positional encoding. Through the application on challenging control\nproblems, such as density and flow control, we show that HypeMARL (i) can\neffectively control systems through a collective behavior of the agents,\noutperforming state-of-the-art decentralized MARL, (ii) can efficiently deal\nwith parametric dependencies, (iii) requires minimal hyperparameter tuning and\n(iv) can reduce the amount of expensive environment interactions by a factor of\n~10 thanks to its model-based extension, MB-HypeMARL, which relies on\ncomputationally efficient deep learning-based surrogate models approximating\nthe dynamics locally, with minimal deterioration of the policy performance."}
{"id": "2509.16743", "pdf": "https://arxiv.org/pdf/2509.16743", "abs": "https://arxiv.org/abs/2509.16743", "authors": ["Subhabrata Das", "Bodruzzaman Khan", "Xiao-Yang Liu"], "title": "A Hybrid PCA-PR-Seq2Seq-Adam-LSTM Framework for Time-Series Power Outage Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Accurately forecasting power outages is a complex task influenced by diverse\nfactors such as weather conditions [1], vegetation, wildlife, and load\nfluctuations. These factors introduce substantial variability and noise into\noutage data, making reliable prediction challenging. Long Short-Term Memory\n(LSTM) networks, a type of Recurrent Neural Network (RNN), are particularly\neffective for modeling nonlinear and dynamic time-series data, with proven\napplications in stock price forecasting [2], energy demand prediction, demand\nresponse [3], and traffic flow management [4]. This paper introduces a hybrid\ndeep learning framework, termed PCA-PR-Seq2Seq-Adam-LSTM, that integrates\nPrincipal Component Analysis (PCA), Poisson Regression (PR), a\nSequence-to-Sequence (Seq2Seq) architecture, and an Adam-optimized LSTM. PCA is\nemployed to reduce dimensionality and stabilize data variance, while Poisson\nRegression effectively models discrete outage events. The Seq2Seq-Adam-LSTM\ncomponent enhances temporal feature learning through efficient gradient\noptimization and long-term dependency capture. The framework is evaluated using\nreal-world outage records from Michigan, and results indicate that the proposed\napproach significantly improves forecasting accuracy and robustness compared to\nexisting methods."}
{"id": "2509.16750", "pdf": "https://arxiv.org/pdf/2509.16750", "abs": "https://arxiv.org/abs/2509.16750", "authors": ["Alejandro Almodóvar", "Patricia A. Apellániz", "Alba Garrido", "Fernando Fernández-Salvador", "Santiago Zazo", "Juan Parras"], "title": "Interpretable Clinical Classification with Kolgomorov-Arnold Networks", "categories": ["cs.LG"], "comment": null, "summary": "Why should a clinician trust an Artificial Intelligence (AI) prediction?\nDespite the increasing accuracy of machine learning methods in medicine, the\nlack of transparency continues to hinder their adoption in clinical practice.\nIn this work, we explore Kolmogorov-Arnold Networks (KANs) for clinical\nclassification tasks on tabular data. Unlike traditional neural networks, KANs\nare function-based architectures that offer intrinsic interpretability through\ntransparent, symbolic representations. We introduce Logistic-KAN, a flexible\ngeneralization of logistic regression, and Kolmogorov-Arnold Additive Model\n(KAAM), a simplified additive variant that delivers transparent, symbolic\nformulas. Unlike black-box models that require post-hoc explainability tools,\nour models support built-in patient-level insights, intuitive visualizations,\nand nearest-patient retrieval. Across multiple health datasets, our models\nmatch or outperform standard baselines, while remaining fully interpretable.\nThese results position KANs as a promising step toward trustworthy AI that\nclinicians can understand, audit, and act upon."}
{"id": "2509.16756", "pdf": "https://arxiv.org/pdf/2509.16756", "abs": "https://arxiv.org/abs/2509.16756", "authors": ["Yuchen Liang", "Yingbin Liang", "Lifeng Lai", "Ness Shroff"], "title": "Discrete Diffusion Models: Novel Analysis and New Sampler Guarantees", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Discrete diffusion models have recently gained significant prominence in\napplications involving natural language and graph data. A key factor\ninfluencing their effectiveness is the efficiency of discretized samplers.\nAmong these, $\\tau$-leaping samplers have become particularly popular due to\ntheir empirical success. However, existing theoretical analyses of\n$\\tau$-leaping often rely on somewhat restrictive and difficult-to-verify\nregularity assumptions, and their convergence bounds contain quadratic\ndependence on the vocabulary size. In this work, we introduce a new analytical\napproach for discrete diffusion models that removes the need for such\nassumptions. For the standard $\\tau$-leaping method, we establish convergence\nguarantees in KL divergence that scale linearly with vocabulary size, improving\nupon prior results with quadratic dependence. Our approach is also more broadly\napplicable: it provides the first convergence guarantees for other widely used\nsamplers, including the Euler method and Tweedie $\\tau$-leaping. Central to our\napproach is a novel technique based on differential inequalities, offering a\nmore flexible alternative to the traditional Girsanov change-of-measure\nmethods. This technique may also be of independent interest for the analysis of\nother stochastic processes."}
{"id": "2509.16769", "pdf": "https://arxiv.org/pdf/2509.16769", "abs": "https://arxiv.org/abs/2509.16769", "authors": ["Prasanth K K", "Shubham Sharma"], "title": "Geometric Mixture Classifier (GMC): A Discriminative Per-Class Mixture of Hyperplanes", "categories": ["cs.LG", "cs.AI", "cs.CL", "68T05, 62H30, 62M45", "I.2.6; I.5.1; I.5.2; G.3"], "comment": "21 pages, 6 figures, 14 tables", "summary": "Many real world categories are multimodal, with single classes occupying\ndisjoint regions in feature space. Classical linear models (logistic\nregression, linear SVM) use a single global hyperplane and perform poorly on\nsuch data, while high-capacity methods (kernel SVMs, deep nets) fit multimodal\nstructure but at the expense of interpretability, heavier tuning, and higher\ncomputational cost. We propose the Geometric Mixture Classifier (GMC), a\ndiscriminative model that represents each class as a mixture of hyperplanes.\nWithin each class, GMC combines plane scores via a temperature-controlled\nsoft-OR (log-sum-exp), smoothly approximating the max; across classes, standard\nsoftmax yields probabilistic posteriors. GMC optionally uses Random Fourier\nFeatures (RFF) for nonlinear mappings while keeping inference linear in the\nnumber of planes and features. Our practical training recipe: geometry-aware\nk-means initialization, silhouette-based plane budgeting, alpha annealing,\nusage-aware L2 regularization, label smoothing, and early stopping, makes GMC\nplug-and-play. Across synthetic multimodal datasets (moons, circles, blobs,\nspirals) and tabular/image benchmarks (iris, wine, WDBC, digits), GMC\nconsistently outperforms linear baselines and k-NN, is competitive with\nRBF-SVM, Random Forests, and small MLPs, and provides geometric introspection\nvia per-plane and class responsibility visualizations. Inference scales\nlinearly in planes and features, making GMC CPU-friendly, with single-digit\nmicrosecond latency per example, often faster than RBF-SVM and compact MLPs.\nPost-hoc temperature scaling reduces ECE from about 0.06 to 0.02. GMC thus\nstrikes a favorable balance of accuracy, interpretability, and efficiency: it\nis more expressive than linear models and lighter, more transparent, and faster\nthan kernel or deep models."}
{"id": "2509.16820", "pdf": "https://arxiv.org/pdf/2509.16820", "abs": "https://arxiv.org/abs/2509.16820", "authors": ["Max Torop", "Aria Masoomi", "Masih Eskandar", "Jennifer Dy"], "title": "DISCO: Disentangled Communication Steering for Large Language Models", "categories": ["cs.LG"], "comment": null, "summary": "A variety of recent methods guide large language model outputs via the\ninference-time addition of steering vectors to residual-stream or\nattention-head representations. In contrast, we propose to inject steering\nvectors directly into the query and value representation spaces within\nattention heads. We provide evidence that a greater portion of these spaces\nexhibit high linear discriminability of concepts --a key property motivating\nthe use of steering vectors-- than attention head outputs. We analytically\ncharacterize the effect of our method, which we term DISentangled COmmunication\n(DISCO) Steering, on attention head outputs. Our analysis reveals that DISCO\ndisentangles a strong but underutilized baseline, steering attention inputs,\nwhich implicitly modifies queries and values in a rigid manner. In contrast,\nDISCO's direct modulation of these components enables more granular control. We\nfind that DISCO achieves superior performance over a number of steering vector\nbaselines across multiple datasets on LLaMA 3.1 8B and Gemma 2 9B, with\nsteering efficacy scoring up to 19.1% higher than the runner-up. Our results\nsupport the conclusion that the query and value spaces are powerful building\nblocks for steering vector methods."}
{"id": "2509.16825", "pdf": "https://arxiv.org/pdf/2509.16825", "abs": "https://arxiv.org/abs/2509.16825", "authors": ["Jin Lee", "Ziming Liu", "Xinling Yu", "Yixuan Wang", "Haewon Jeong", "Murphy Yuezhen Niu", "Zheng Zhang"], "title": "KANO: Kolmogorov-Arnold Neural Operator", "categories": ["cs.LG", "cs.AI", "cs.CE"], "comment": null, "summary": "We introduce Kolmogorov--Arnold Neural Operator (KANO), a dual-domain neural\noperator jointly parameterized by both spectral and spatial bases with\nintrinsic symbolic interpretability. We theoretically demonstrate that KANO\novercomes the pure-spectral bottleneck of Fourier Neural Operator (FNO): KANO\nremains expressive over generic position-dependent dynamics for any physical\ninput, whereas FNO stays practical only for spectrally sparse operators and\nstrictly imposes a fast-decaying input Fourier tail. We verify our claims\nempirically on position-dependent differential operators, for which KANO\nrobustly generalizes but FNO fails to. In the quantum Hamiltonian learning\nbenchmark, KANO reconstructs ground-truth Hamiltonians in closed-form symbolic\nrepresentations accurate to the fourth decimal place in coefficients and\nattains $\\approx 6\\times10^{-6}$ state infidelity from projective measurement\ndata, substantially outperforming that of the FNO trained with ideal full wave\nfunction data, $\\approx 1.5\\times10^{-2}$, by orders of magnitude."}
{"id": "2509.16833", "pdf": "https://arxiv.org/pdf/2509.16833", "abs": "https://arxiv.org/abs/2509.16833", "authors": ["Shaharyar Ahmed Khan Tareen", "Lei Fan", "Xiaojing Yuan", "Qin Lin", "Bin Hu"], "title": "SOLAR: Switchable Output Layer for Accuracy and Robustness in Once-for-All Training", "categories": ["cs.LG", "cs.CV"], "comment": "10 pages, 7 figures, 6 tables", "summary": "Once-for-All (OFA) training enables a single super-net to generate multiple\nsub-nets tailored to diverse deployment scenarios, supporting flexible\ntrade-offs among accuracy, robustness, and model-size without retraining.\nHowever, as the number of supported sub-nets increases, excessive parameter\nsharing in the backbone limits representational capacity, leading to degraded\ncalibration and reduced overall performance. To address this, we propose SOLAR\n(Switchable Output Layer for Accuracy and Robustness in Once-for-All Training),\na simple yet effective technique that assigns each sub-net a separate\nclassification head. By decoupling the logit learning process across sub-nets,\nthe Switchable Output Layer (SOL) reduces representational interference and\nimproves optimization, without altering the shared backbone. We evaluate SOLAR\non five datasets (SVHN, CIFAR-10, STL-10, CIFAR-100, and TinyImageNet) using\nfour super-net backbones (ResNet-34, WideResNet-16-8, WideResNet-40-2, and\nMobileNetV2) for two OFA training frameworks (OATS and SNNs). Experiments show\nthat SOLAR outperforms the baseline methods: compared to OATS, it improves\naccuracy of sub-nets up to 1.26 %, 4.71 %, 1.67 %, and 1.76 %, and robustness\nup to 9.01 %, 7.71 %, 2.72 %, and 1.26 % on SVHN, CIFAR-10, STL-10, and\nCIFAR-100, respectively. Compared to SNNs, it improves TinyImageNet accuracy by\nup to 2.93 %, 2.34 %, and 1.35 % using ResNet-34, WideResNet-16-8, and\nMobileNetV2 backbones (with 8 sub-nets), respectively."}
{"id": "2509.16860", "pdf": "https://arxiv.org/pdf/2509.16860", "abs": "https://arxiv.org/abs/2509.16860", "authors": ["Mohammad Abdul Hafeez Khan", "Marcello Mattei Di Eugeni", "Benjamin Diaz", "Ruth E. White", "Siddhartha Bhattacharyya", "Venkat Keshav Chivukula"], "title": "LVADNet3D: A Deep Autoencoder for Reconstructing 3D Intraventricular Flow from Sparse Hemodynamic Data", "categories": ["cs.LG"], "comment": "Accepted to International Conference on Machine Learning and\n  Applications (ICMLA), 6 pages, 4 figure, 3 tables", "summary": "Accurate assessment of intraventricular blood flow is essential for\nevaluating hemodynamic conditions in patients supported by Left Ventricular\nAssist Devices (LVADs). However, clinical imaging is either incompatible with\nLVADs or yields sparse, low-quality velocity data. While Computational Fluid\nDynamics (CFD) simulations provide high-fidelity data, they are computationally\nintensive and impractical for routine clinical use. To address this, we propose\nLVADNet3D, a 3D convolutional autoencoder that reconstructs full-resolution\nintraventricular velocity fields from sparse velocity vector inputs. In\ncontrast to a standard UNet3D model, LVADNet3D incorporates hybrid downsampling\nand a deeper encoder-decoder architecture with increased channel capacity to\nbetter capture spatial flow patterns. To train and evaluate the models, we\ngenerate a high-resolution synthetic dataset of intraventricular blood flow in\nLVAD-supported hearts using CFD simulations. We also investigate the effect of\nconditioning the models on anatomical and physiological priors. Across various\ninput configurations, LVADNet3D outperforms the baseline UNet3D model, yielding\nlower reconstruction error and higher PSNR results."}
{"id": "2509.16875", "pdf": "https://arxiv.org/pdf/2509.16875", "abs": "https://arxiv.org/abs/2509.16875", "authors": ["Qishuai Wen", "Zhiyuan Huang", "Chun-Guang Li"], "title": "Towards Interpretable and Efficient Attention: Compressing All by Contracting a Few", "categories": ["cs.LG", "cs.CV"], "comment": "NeurIPS 2025 Spotlight", "summary": "Attention mechanisms in Transformers have gained significant empirical\nsuccess. Nonetheless, the optimization objectives underlying their forward pass\nare still unclear. Additionally, the quadratic complexity of self-attention is\nincreasingly prohibitive. Unlike the prior work on addressing the\ninterpretability or efficiency issue separately, we propose a unified\noptimization objective to alleviate both issues simultaneously. By unrolling\nthe optimization over the objective, we derive an inherently interpretable and\nefficient attention mechanism, which compresses all tokens into low-dimensional\nstructures by contracting a few representative tokens and then broadcasting the\ncontractions back. This Contract-and-Broadcast Self-Attention (CBSA) mechanism\ncan not only scale linearly but also generalize existing attention mechanisms\nas its special cases. Experiments further demonstrate comparable performance\nand even superior advantages of CBSA on several visual tasks. Code is available\nat this https URL."}
{"id": "2509.16882", "pdf": "https://arxiv.org/pdf/2509.16882", "abs": "https://arxiv.org/abs/2509.16882", "authors": ["Junzhuo Li", "Bo Wang", "Xiuze Zhou", "Xuming Hu"], "title": "Dynamic Expert Specialization: Towards Catastrophic Forgetting-Free Multi-Domain MoE Adaptation", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "EMNLP 2025 Main Conference", "summary": "Mixture-of-Experts (MoE) models offer immense capacity via sparsely gated\nexpert subnetworks, yet adapting them to multiple domains without catastrophic\nforgetting remains an open challenge. Existing approaches either incur\nprohibitive computation, suffer cross-domain interference, or require separate\nruns per domain. We propose DES-MoE, a dynamic expert specialization framework\nfor multi-domain adaptation of Mixture-of-Experts models. DES-MoE addresses\ncatastrophic forgetting through three innovations: (1) an adaptive router\nbalancing pre-trained knowledge retention and task-specific updates via\ndistillation, (2) real-time expert-domain correlation mapping to isolate\ndomain-specific gradients, and (3) a three-phase adaptive fine-tuning schedule\nthat progressively freezes non-specialized parameters. Evaluated on six domains\n(math, code, law, etc.), DES-MoE matches single-domain ESFT performance while\ntraining one unified model, reduces forgetting by 89% compared to full\nfine-tuning as domains scale from 2 to 6, and achieves 68% faster convergence\nthan conventional methods. Our work establishes dynamic expert isolation as a\nscalable paradigm for multi-task MoE adaptation."}
{"id": "2509.16893", "pdf": "https://arxiv.org/pdf/2509.16893", "abs": "https://arxiv.org/abs/2509.16893", "authors": ["Faramarz Farhangian", "Leandro A. Ensina", "George D. C. Cavalcanti", "Rafael M. O. Cruz"], "title": "DRES: Fake news detection by dynamic representation and ensemble selection", "categories": ["cs.LG", "cs.CL"], "comment": "Accepted as oral presentation at EMNLP 2025", "summary": "The rapid spread of information via social media has made text-based fake\nnews detection critically important due to its societal impact. This paper\npresents a novel detection method called Dynamic Representation and Ensemble\nSelection (DRES) for identifying fake news based solely on text. DRES leverages\ninstance hardness measures to estimate the classification difficulty for each\nnews article across multiple textual feature representations. By dynamically\nselecting the textual representation and the most competent ensemble of\nclassifiers for each instance, DRES significantly enhances prediction accuracy.\nExtensive experiments show that DRES achieves notable improvements over\nstate-of-the-art methods, confirming the effectiveness of representation\nselection based on instance hardness and dynamic ensemble selection in boosting\nperformance. Codes and data are available at:\nhttps://github.com/FFarhangian/FakeNewsDetection_DRES"}
{"id": "2509.16898", "pdf": "https://arxiv.org/pdf/2509.16898", "abs": "https://arxiv.org/abs/2509.16898", "authors": ["Jingming Yan", "Yiyuan Luo", "Vaggos Chatziafratis", "Ioannis Panageas", "Parnian Shahkar", "Stelios Stavroulakis"], "title": "The Complexity of Finding Local Optima in Contrastive Learning", "categories": ["cs.LG", "cs.CC", "math.OC"], "comment": "To appear as a conference paper in NeurIPS 2025", "summary": "Contrastive learning is a powerful technique for discovering meaningful data\nrepresentations by optimizing objectives based on $\\textit{contrastive\ninformation}$, often given as a set of weighted triplets $\\{(x_i, y_i^+,\nz_{i}^-)\\}_{i = 1}^m$ indicating that an \"anchor\" $x_i$ is more similar to a\n\"positive\" example $y_i$ than to a \"negative\" example $z_i$. The goal is to\nfind representations (e.g., embeddings in $\\mathbb{R}^d$ or a tree metric)\nwhere anchors are placed closer to positive than to negative examples. While\nfinding $\\textit{global}$ optima of contrastive objectives is\n$\\mathsf{NP}$-hard, the complexity of finding $\\textit{local}$ optima --\nrepresentations that do not improve by local search algorithms such as\ngradient-based methods -- remains open. Our work settles the complexity of\nfinding local optima in various contrastive learning problems by proving\n$\\mathsf{PLS}$-hardness in discrete settings (e.g., maximize satisfied\ntriplets) and $\\mathsf{CLS}$-hardness in continuous settings (e.g., minimize\nTriplet Loss), where $\\mathsf{PLS}$ (Polynomial Local Search) and\n$\\mathsf{CLS}$ (Continuous Local Search) are well-studied complexity classes\ncapturing local search dynamics in discrete and continuous optimization,\nrespectively. Our results imply that no polynomial time algorithm (local search\nor otherwise) can find a local optimum for various contrastive learning\nproblems, unless $\\mathsf{PLS}\\subseteq\\mathsf{P}$ (or $\\mathsf{CLS}\\subseteq\n\\mathsf{P}$ for continuous problems). Even in the unlikely scenario that\n$\\mathsf{PLS}\\subseteq\\mathsf{P}$ (or $\\mathsf{CLS}\\subseteq \\mathsf{P}$), our\nreductions imply that there exist instances where local search algorithms need\nexponential time to reach a local optimum, even for $d=1$ (embeddings on a\nline)."}
{"id": "2509.16902", "pdf": "https://arxiv.org/pdf/2509.16902", "abs": "https://arxiv.org/abs/2509.16902", "authors": ["Letian Zhang", "Bo Chen", "Jieming Bian", "Lei Wang", "Jie Xu"], "title": "FedEL: Federated Elastic Learning for Heterogeneous Devices", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Federated learning (FL) enables distributed devices to collaboratively train\nmachine learning models while maintaining data privacy. However, the\nheterogeneous hardware capabilities of devices often result in significant\ntraining delays, as straggler clients with limited resources prolong the\naggregation process. Existing solutions such as client selection, asynchronous\nFL, and partial training partially address these challenges but encounter\nissues such as reduced accuracy, stale updates, and compromised model\nperformance due to inconsistent training contributions. To overcome these\nlimitations, we propose FedEL, a federated elastic learning framework that\nenhances training efficiency while maintaining model accuracy. FedEL introduces\na novel window-based training process, sliding the window to locate the\ntraining part of the model and dynamically selecting important tensors for\ntraining within a coordinated runtime budget. This approach ensures progressive\nand balanced training across all clients, including stragglers. Additionally,\nFedEL employs a tensor importance adjustment module, harmonizing local and\nglobal tensor importance to mitigate biases caused by data heterogeneity. The\nexperiment results show that FedEL achieves up to 3.87x improvement in\ntime-to-accuracy compared to baselines while maintaining or exceeding final\ntest accuracy."}
{"id": "2509.16930", "pdf": "https://arxiv.org/pdf/2509.16930", "abs": "https://arxiv.org/abs/2509.16930", "authors": ["Nathan Derhake", "Siddartha Devic", "Dutch Hansen", "Kuan Liu", "Vatsal Sharan"], "title": "Auditability and the Landscape of Distance to Multicalibration", "categories": ["cs.LG"], "comment": "41 pages", "summary": "Calibration is a critical property for establishing the trustworthiness of\npredictors that provide uncertainty estimates. Multicalibration is a\nstrengthening of calibration which requires that predictors be calibrated on a\npotentially overlapping collection of subsets of the domain. As\nmulticalibration grows in popularity with practitioners, an essential question\nis: how do we measure how multicalibrated a predictor is? B{\\l}asiok et al.\n(2023) considered this question for standard calibration by introducing the\ndistance to calibration framework (dCE) to understand how calibration metrics\nrelate to each other and the ground truth. Building on the dCE framework, we\nconsider the auditability of the distance to multicalibration of a predictor\n$f$.\n  We begin by considering two natural generalizations of dCE to multiple\nsubgroups: worst group dCE (wdMC), and distance to multicalibration (dMC). We\nargue that there are two essential properties of any multicalibration error\nmetric: 1) the metric should capture how much $f$ would need to be modified in\norder to be perfectly multicalibrated; and 2) the metric should be auditable in\nan information theoretic sense. We show that wdMC and dMC each fail to satisfy\none of these two properties, and that similar barriers arise when considering\nthe auditability of general distance to multigroup fairness notions. We then\npropose two (equivalent) multicalibration metrics which do satisfy these\nrequirements: 1) a continuized variant of dMC; and 2) a distance to\nintersection multicalibration, which leans on intersectional fairness\ndesiderata. Along the way, we shed light on the loss-landscape of distance to\nmulticalibration and the geometry of the set of perfectly multicalibrated\npredictors. Our findings may have implications for the development of stronger\nmulticalibration algorithms as well as multigroup auditing more generally."}
{"id": "2509.16936", "pdf": "https://arxiv.org/pdf/2509.16936", "abs": "https://arxiv.org/abs/2509.16936", "authors": ["Cuiqianhe Du", "Chia-En Chiang", "Tianyi Huang", "Zikun Cui"], "title": "Adaptive Graph Convolution and Semantic-Guided Attention for Multimodal Risk Detection in Social Networks", "categories": ["cs.LG"], "comment": null, "summary": "This paper focuses on the detection of potentially dangerous tendencies of\nsocial media users in an innovative multimodal way. We integrate Natural\nLanguage Processing (NLP) and Graph Neural Networks (GNNs) together. Firstly,\nwe apply NLP on the user-generated text and conduct semantic analysis,\nsentiment recognition and keyword extraction to get subtle risk signals from\nsocial media posts. Meanwhile, we build a heterogeneous user relationship graph\nbased on social interaction and propose a novel relational graph convolutional\nnetwork to model user relationship, attention relationship and content\ndissemination path to discover some important structural information and user\nbehaviors. Finally, we combine textual features extracted from these two models\nabove with graph structural information, which provides a more robust and\neffective way to discover at-risk users. Our experiments on real social media\ndatasets from different platforms show that our model can achieve significant\nimprovement over single-modality methods."}
{"id": "2509.16959", "pdf": "https://arxiv.org/pdf/2509.16959", "abs": "https://arxiv.org/abs/2509.16959", "authors": ["Santosh Patapati", "Trisanth Srinivasan"], "title": "Gradient Interference-Aware Graph Coloring for Multitask Learning", "categories": ["cs.LG", "cs.AI", "cs.NE", "stat.ML"], "comment": null, "summary": "When different objectives conflict with each other in multi-task learning,\ngradients begin to interfere and slow convergence, thereby reducing the final\nmodel's performance. To address this, we introduce a scheduler that computes\ngradient interference, constructs an interference graph, and then applies\ngreedy graph-coloring to partition tasks into groups that align well with each\nother. At each training step, only one group (color class) of tasks are\nactivated. The grouping partition is constantly recomputed as task\nrelationships evolve throughout training. By ensuring that each mini-batch\ncontains only tasks that pull the model in the same direction, our method\nimproves the effectiveness of any underlying multi-task learning optimizer\nwithout additional tuning. Since tasks within these groups will update in\ncompatible directions, model performance will be improved rather than impeded.\nEmpirical results on six different datasets show that this interference-aware\ngraph-coloring approach consistently outperforms baselines and state-of-the-art\nmulti-task optimizers."}
{"id": "2509.16989", "pdf": "https://arxiv.org/pdf/2509.16989", "abs": "https://arxiv.org/abs/2509.16989", "authors": ["He Xiao", "Runming Yang", "Qingyao Yang", "Wendong Xu", "Zheng Li", "Yupeng Su", "Zhengwu Liu", "Hongxia Yang", "Ngai Wong"], "title": "PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": "under review", "summary": "Post-training quantization (PTQ) of large language models (LLMs) to extremely\nlow bit-widths remains challenging due to the fundamental trade-off between\ncomputational efficiency and model expressiveness. While existing ultra-low-bit\nPTQ methods rely on binary approximations or complex compensation mechanisms,\nthey suffer from either limited representational capacity or computational\noverhead that undermines their efficiency gains. We introduce PTQ to\nTrit-Planes (PTQTP), the first ternary-weight PTQ framework that decomposes\nweight matrices into structured ternary {-1, 0, 1} trit-planes using 2x1.58-bit\nrepresentation. PTQTP achieves multiplication-free inference, identical to\n1-bit quantization, while maintaining superior expressiveness through its novel\nstructured decomposition. Our approach provides: (1) a theoretically grounded\nprogressive approximation algorithm ensuring global weight consistency; (2)\nmodel-agnostic deployment across diverse modern LLMs without architectural\nmodifications; and (3) uniform ternary operations that eliminate the need for\nmixed-precision or compensation schemes. Comprehensive experiments across\nLLaMA3.x and Qwen3 model families (0.6B-70B parameters) demonstrate that PTQTP\nsignificantly outperforms existing low-bit PTQ methods, achieving 82.4%\nmathematical reasoning retention versus 0% for competing approaches. PTQTP\napproaches and sometimes surpasses 1.58-bit quantization-aware training\nperformance while requiring only single-hour quantization compared to 10-14 GPU\ndays for training-based methods. These results establish PTQTP as a practical\nsolution for efficient LLM deployment in resource-constrained environments."}
{"id": "2509.16999", "pdf": "https://arxiv.org/pdf/2509.16999", "abs": "https://arxiv.org/abs/2509.16999", "authors": ["Matteo Pegoraro"], "title": "Persistence Spheres: Bi-continuous Representations of Persistence Diagrams", "categories": ["cs.LG"], "comment": null, "summary": "We introduce persistence spheres, a novel functional representation of\npersistence diagrams. Unlike existing embeddings (such as persistence images,\nlandscapes, or kernel methods), persistence spheres provide a bi-continuous\nmapping: they are Lipschitz continuous with respect to the 1-Wasserstein\ndistance and admit a continuous inverse on their image. This ensures, in a\ntheoretically optimal way, both stability and geometric fidelity, making\npersistence spheres the representation that most closely mirrors the\nWasserstein geometry of PDs in linear space. We derive explicit formulas for\npersistence spheres, showing that they can be computed efficiently and\nparallelized with minimal overhead. Empirically, we evaluate them on diverse\nregression and classification tasks involving functional data, time series,\ngraphs, meshes, and point clouds. Across these benchmarks, persistence spheres\nconsistently deliver state-of-the-art or competitive performance compared to\npersistence images, persistence landscapes, and the sliced Wasserstein kernel."}
{"id": "2509.17000", "pdf": "https://arxiv.org/pdf/2509.17000", "abs": "https://arxiv.org/abs/2509.17000", "authors": ["Shuhao Jiang", "Songbo Wang", "Yang Qiao", "Chun Xu", "Chaoyang Zheng", "Shengyi Zhou", "Huanjun Wang", "Fangming Li", "Cong Zhang", "Jiyu Wang"], "title": "Adaptive Overclocking: Dynamic Control of Thinking Path Length via Real-Time Reasoning Signals", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large Reasoning Models (LRMs) often suffer from computational inefficiency\ndue to overthinking, where a fixed reasoning budget fails to match the varying\ncomplexity of tasks. To address this issue, we propose Adaptive Overclocking, a\nmethod that makes the overclocking hyperparameter $\\alpha$ dynamic and\ncontext-aware. Our method adjusts reasoning speed in real time through two\ncomplementary signals: (1) token-level model uncertainty for fine-grained\nstep-wise control, and (2) input complexity estimation for informed\ninitialization. We implement this approach with three strategies:\nUncertainty-Aware Alpha Scheduling (UA-$\\alpha$S), Complexity-Guided Alpha\nInitialization (CG-$\\alpha$I), and a Hybrid Adaptive Control (HAC) that\ncombines both. Experiments on GSM8K, MATH, and SVAMP show that HAC achieves\nsuperior accuracy-latency trade-offs, reducing unnecessary computation on\nsimple problems while allocating more resources to challenging ones. By\nmitigating overthinking, Adaptive Overclocking enhances both efficiency and\noverall reasoning performance."}
{"id": "2509.17034", "pdf": "https://arxiv.org/pdf/2509.17034", "abs": "https://arxiv.org/abs/2509.17034", "authors": ["Shuai Feng", "Yuxin Ge", "Yuntao Du", "Mingcai Chen", "Lei Feng"], "title": "Long-Tailed Out-of-Distribution Detection with Refined Separate Class Learning", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Out-of-distribution (OOD) detection is crucial for deploying robust machine\nlearning models. However, when training data follows a long-tailed\ndistribution, the model's ability to accurately detect OOD samples is\nsignificantly compromised, due to the confusion between OOD samples and\nhead/tail classes. To distinguish OOD samples from both head and tail classes,\nthe separate class learning (SCL) approach has emerged as a promising solution,\nwhich separately conduct head-specific and tail-specific class learning. To\nthis end, we examine the limitations of existing works of SCL and reveal that\nthe OOD detection performance is notably influenced by the use of static\nscaling temperature value and the presence of uninformative outliers. To\nmitigate these limitations, we propose a novel approach termed Refined Separate\nClass Learning (RSCL), which leverages dynamic class-wise temperature\nadjustment to modulate the temperature parameter for each in-distribution class\nand informative outlier mining to identify diverse types of outliers based on\ntheir affinity with head and tail classes. Extensive experiments demonstrate\nthat RSCL achieves superior OOD detection performance while improving the\nclassification accuracy on in-distribution data."}
{"id": "2509.17051", "pdf": "https://arxiv.org/pdf/2509.17051", "abs": "https://arxiv.org/abs/2509.17051", "authors": ["Riccardo Doyle"], "title": "Enhancing Performance and Calibration in Quantile Hyperparameter Optimization", "categories": ["cs.LG", "stat.ML"], "comment": "19 pages, 15 figures, 1 table", "summary": "Bayesian hyperparameter optimization relies heavily on Gaussian Process (GP)\nsurrogates, due to robust distributional posteriors and strong performance on\nlimited training samples. GPs however underperform in categorical\nhyperparameter environments or when assumptions of normality,\nheteroskedasticity and symmetry are excessively challenged. Conformalized\nquantile regression can address these estimation weaknesses, while still\nproviding robust calibration guarantees. This study builds upon early work in\nthis area by addressing feedback covariate shift in sequential acquisition and\nintegrating a wider range of surrogate architectures and acquisition functions.\nProposed algorithms are rigorously benchmarked against a range of state of the\nart hyperparameter optimization methods (GP, TPE and SMAC). Findings identify\nquantile surrogate architectures and acquisition functions yielding superior\nperformance to the current quantile literature, while validating the beneficial\nimpact of conformalization on calibration and search performance."}
{"id": "2509.17063", "pdf": "https://arxiv.org/pdf/2509.17063", "abs": "https://arxiv.org/abs/2509.17063", "authors": ["Shuang Liang", "Chaochuan Hou", "Xu Yao", "Shiping Wang", "Minqi Jiang", "Songqiao Han", "Hailiang Huang"], "title": "TSGym: Design Choices for Deep Multivariate Time-Series Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "Recently, deep learning has driven significant advancements in multivariate\ntime series forecasting (MTSF) tasks. However, much of the current research in\nMTSF tends to evaluate models from a holistic perspective, which obscures the\nindividual contributions and leaves critical issues unaddressed. Adhering to\nthe current modeling paradigms, this work bridges these gaps by systematically\ndecomposing deep MTSF methods into their core, fine-grained components like\nseries-patching tokenization, channel-independent strategy, attention modules,\nor even Large Language Models and Time-series Foundation Models. Through\nextensive experiments and component-level analysis, our work offers more\nprofound insights than previous benchmarks that typically discuss models as a\nwhole.\n  Furthermore, we propose a novel automated solution called TSGym for MTSF\ntasks. Unlike traditional hyperparameter tuning, neural architecture searching\nor fixed model selection, TSGym performs fine-grained component selection and\nautomated model construction, which enables the creation of more effective\nsolutions tailored to diverse time series data, therefore enhancing model\ntransferability across different data sources and robustness against\ndistribution shifts. Extensive experiments indicate that TSGym significantly\noutperforms existing state-of-the-art MTSF and AutoML methods. All code is\npublicly available on https://github.com/SUFE-AILAB/TSGym."}
{"id": "2509.17092", "pdf": "https://arxiv.org/pdf/2509.17092", "abs": "https://arxiv.org/abs/2509.17092", "authors": ["Michelangelo Conserva", "Remo Sasso", "Paulo Rauber"], "title": "On the Limits of Tabular Hardness Metrics for Deep RL: A Study with the Pharos Benchmark", "categories": ["cs.LG"], "comment": null, "summary": "Principled evaluation is critical for progress in deep reinforcement learning\n(RL), yet it lags behind the theory-driven benchmarks of tabular RL. While\ntabular settings benefit from well-understood hardness measures like MDP\ndiameter and suboptimality gaps, deep RL benchmarks are often chosen based on\nintuition and popularity. This raises a critical question: can tabular hardness\nmetrics be adapted to guide non-tabular benchmarking? We investigate this\nquestion and reveal a fundamental gap. Our primary contribution is\ndemonstrating that the difficulty of non-tabular environments is dominated by a\nfactor that tabular metrics ignore: representation hardness. The same\nunderlying MDP can pose vastly different challenges depending on whether the\nagent receives state vectors or pixel-based observations. To enable this\nanalysis, we introduce \\texttt{pharos}, a new open-source library for\nprincipled RL benchmarking that allows for systematic control over both\nenvironment structure and agent representations. Our extensive case study using\n\\texttt{pharos} shows that while tabular metrics offer some insight, they are\npoor predictors of deep RL agent performance on their own. This work highlights\nthe urgent need for new, representation-aware hardness measures and positions\n\\texttt{pharos} as a key tool for developing them."}
{"id": "2509.17095", "pdf": "https://arxiv.org/pdf/2509.17095", "abs": "https://arxiv.org/abs/2509.17095", "authors": ["Jinbao Wang", "Jun Liu", "Shiliang Zhang", "Xuehui Ma"], "title": "Ultra-short-term solar power forecasting by deep learning and data reconstruction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The integration of solar power has been increasing as the green energy\ntransition rolls out. The penetration of solar power challenges the grid\nstability and energy scheduling, due to its intermittent energy generation.\nAccurate and near real-time solar power prediction is of critical importance to\ntolerant and support the permeation of distributed and volatile solar power\nproduction in the energy system. In this paper, we propose a deep-learning\nbased ultra-short-term solar power prediction with data reconstruction. We\ndecompose the data for the prediction to facilitate extensive exploration of\nthe spatial and temporal dependencies within the data. Particularly, we\nreconstruct the data into low- and high-frequency components, using ensemble\nempirical model decomposition with adaptive noise (CEEMDAN). We integrate\nmeteorological data with those two components, and employ deep-learning models\nto capture long- and short-term dependencies towards the target prediction\nperiod. In this way, we excessively exploit the features in historical data in\npredicting a ultra-short-term solar power production. Furthermore, as\nultra-short-term prediction is vulnerable to local optima, we modify the\noptimization in our deep-learning training by penalizing long prediction\nintervals. Numerical experiments with diverse settings demonstrate that,\ncompared to baseline models, the proposed method achieves improved\ngeneralization in data reconstruction and higher prediction accuracy for\nultra-short-term solar power production."}
{"id": "2509.17105", "pdf": "https://arxiv.org/pdf/2509.17105", "abs": "https://arxiv.org/abs/2509.17105", "authors": ["Haoxin Guo", "Jiawen Pan", "Weixin Zhai"], "title": "GRPOformer: Advancing Hyperparameter Optimization via Group Relative Policy Optimization", "categories": ["cs.LG"], "comment": null, "summary": "Hyperparameter optimization (HPO) plays a critical role in improving model\nperformance. Transformer-based HPO methods have shown great potential; however,\nexisting approaches rely heavily on large-scale historical optimization\ntrajectories and lack effective reinforcement learning (RL) techniques, thereby\nlimiting their efficiency and performance improvements. Inspired by the success\nof Group Relative Policy Optimization (GRPO) in large language models (LLMs),\nwe propose GRPOformer -- a novel hyperparameter optimization framework that\nintegrates reinforcement learning (RL) with Transformers. In GRPOformer,\nTransformers are employed to generate new hyperparameter configurations from\nhistorical optimization trajectories, while GRPO enables rapid trajectory\nconstruction and optimization strategy learning from scratch. Moreover, we\nintroduce Policy Churn Regularization (PCR) to enhance the stability of GRPO\ntraining. Experimental results on OpenML demonstrate that GRPOformer\nconsistently outperforms baseline methods across diverse tasks, offering new\ninsights into the application of RL for HPO."}
{"id": "2509.17119", "pdf": "https://arxiv.org/pdf/2509.17119", "abs": "https://arxiv.org/abs/2509.17119", "authors": ["Yifei Wu", "Bo Wang", "Jingshi Cui", "Pei-chun Lin", "Junzo Watada"], "title": "ScenGAN: Attention-Intensive Generative Model for Uncertainty-Aware Renewable Scenario Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "To address the intermittency of renewable energy source (RES) generation,\nscenario forecasting offers a series of stochastic realizations for predictive\nobjects with superior flexibility and direct views. Based on a long time-series\nperspective, this paper explores uncertainties in the realms of renewable power\nand deep learning. Then, an uncertainty-aware model is meticulously designed\nfor renewable scenario forecasting, which leverages an attention mechanism and\ngenerative adversarial networks (GANs) to precisely capture complex\nspatial-temporal dynamics. To improve the interpretability of uncertain\nbehavior in RES generation, Bayesian deep learning and adaptive instance\nnormalization (AdaIN) are incorporated to simulate typical patterns and\nvariations. Additionally, the integration of meteorological information,\nforecasts, and historical trajectories in the processing layer improves the\nsynergistic forecasting capability for multiscale periodic regularities.\nNumerical experiments and case analyses demonstrate that the proposed approach\nprovides an appropriate interpretation for renewable uncertainty\nrepresentation, including both aleatoric and epistemic uncertainties, and shows\nsuperior performance over state-of-the-art methods."}
{"id": "2509.17145", "pdf": "https://arxiv.org/pdf/2509.17145", "abs": "https://arxiv.org/abs/2509.17145", "authors": ["Amaan Ansari", "Lukas Kirchdorfer", "Raheleh Hadian"], "title": "On the Simplification of Neural Network Architectures for Predictive Process Monitoring", "categories": ["cs.LG"], "comment": null, "summary": "Predictive Process Monitoring (PPM) aims to forecast the future behavior of\nongoing process instances using historical event data, enabling proactive\ndecision-making. While recent advances rely heavily on deep learning models\nsuch as LSTMs and Transformers, their high computational cost hinders practical\nadoption. Prior work has explored data reduction techniques and alternative\nfeature encodings, but the effect of simplifying model architectures themselves\nremains underexplored. In this paper, we analyze how reducing model complexity,\nboth in terms of parameter count and architectural depth, impacts predictive\nperformance, using two established PPM approaches. Across five diverse event\nlogs, we show that shrinking the Transformer model by 85% results in only a\n2-3% drop in performance across various PPM tasks, while the LSTM proves\nslightly more sensitive, particularly for waiting time prediction. Overall, our\nfindings suggest that substantial model simplification can preserve predictive\naccuracy, paving the way for more efficient and scalable PPM solutions."}
{"id": "2509.17153", "pdf": "https://arxiv.org/pdf/2509.17153", "abs": "https://arxiv.org/abs/2509.17153", "authors": ["Moule Lin", "Andrea Patane", "Weipeng Jing", "Shuhao Guan", "Goetz Botterweck"], "title": "Flow-Induced Diagonal Gaussian Processes", "categories": ["cs.LG", "cs.AI"], "comment": "15 pages", "summary": "We present Flow-Induced Diagonal Gaussian Processes (FiD-GP), a compression\nframework that incorporates a compact inducing weight matrix to project a\nneural network's weight uncertainty into a lower-dimensional subspace.\nCritically, FiD-GP relies on normalising-flow priors and spectral\nregularisations to augment its expressiveness and align the inducing subspace\nwith feature-gradient geometry through a numerically stable projection\nmechanism objective. Furthermore, we demonstrate how the prediction framework\nin FiD-GP can help to design a single-pass projection for Out-of-Distribution\n(OoD) detection. Our analysis shows that FiD-GP improves uncertainty estimation\nability on various tasks compared with SVGP-based baselines, satisfies tight\nspectral residual bounds with theoretically guaranteed OoD detection, and\nsignificantly compresses the neural network's storage requirements at the cost\nof increased inference computation dependent on the number of inducing weights\nemployed. Specifically, in a comprehensive empirical study spanning regression,\nimage classification, semantic segmentation, and out-of-distribution detection\nbenchmarks, it cuts Bayesian training cost by several orders of magnitude,\ncompresses parameters by roughly 51%, reduces model size by about 75%, and\nmatches state-of-the-art accuracy and uncertainty estimation."}
{"id": "2509.17156", "pdf": "https://arxiv.org/pdf/2509.17156", "abs": "https://arxiv.org/abs/2509.17156", "authors": ["Samar Hadou", "Alejandro Ribeiro"], "title": "Unrolled Graph Neural Networks for Constrained Optimization", "categories": ["cs.LG"], "comment": null, "summary": "In this paper, we unroll the dynamics of the dual ascent (DA) algorithm in\ntwo coupled graph neural networks (GNNs) to solve constrained optimization\nproblems. The two networks interact with each other at the layer level to find\na saddle point of the Lagrangian. The primal GNN finds a stationary point for a\ngiven dual multiplier, while the dual network iteratively refines its estimates\nto reach an optimal solution. We force the primal and dual networks to mirror\nthe dynamics of the DA algorithm by imposing descent and ascent constraints. We\npropose a joint training scheme that alternates between updating the primal and\ndual networks. Our numerical experiments demonstrate that our approach yields\nnear-optimal near-feasible solutions and generalizes well to\nout-of-distribution (OOD) problems."}
{"id": "2509.17165", "pdf": "https://arxiv.org/pdf/2509.17165", "abs": "https://arxiv.org/abs/2509.17165", "authors": ["Sahar Koohfar", "Wubeshet Woldemariam"], "title": "Time Series Forecasting Using a Hybrid Deep Learning Method: A Bi-LSTM Embedding Denoising Auto Encoder Transformer", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Time series data is a prevalent form of data found in various fields. It\nconsists of a series of measurements taken over time. Forecasting is a crucial\napplication of time series models, where future values are predicted based on\nhistorical data. Accurate forecasting is essential for making well-informed\ndecisions across industries. When it comes to electric vehicles (EVs), precise\npredictions play a key role in planning infrastructure development, load\nbalancing, and energy management. This study introduces a BI-LSTM embedding\ndenoising autoencoder model (BDM) designed to address time series problems,\nfocusing on short-term EV charging load prediction. The performance of the\nproposed model is evaluated by comparing it with benchmark models like\nTransformer, CNN, RNN, LSTM, and GRU. Based on the results of the study, the\nproposed model outperforms the benchmark models in four of the five-time steps,\ndemonstrating its effectiveness for time series forecasting. This research\nmakes a significant contribution to enhancing time series forecasting, thereby\nimproving decision-making processes."}
{"id": "2509.17175", "pdf": "https://arxiv.org/pdf/2509.17175", "abs": "https://arxiv.org/abs/2509.17175", "authors": ["Niál Perry", "Peter P. Pedersen", "Charles N. Christensen", "Emanuel Nussli", "Sanelma Heinonen", "Lorena Gordillo Dagallier", "Raphaël Jacquat", "Sebastian Horstmann", "Christoph Franck"], "title": "Detecting Urban PM$_{2.5}$ Hotspots with Mobile Sensing and Gaussian Process Regression", "categories": ["cs.LG", "stat.AP", "62P12", "I.2.6"], "comment": "39 pages, 12 figures", "summary": "Low-cost mobile sensors can be used to collect PM$_{2.5}$ concentration data\nthroughout an entire city. However, identifying air pollution hotspots from the\ndata is challenging due to the uneven spatial sampling, temporal variations in\nthe background air quality, and the dynamism of urban air pollution sources.\nThis study proposes a method to identify urban PM$_{2.5}$ hotspots that\naddresses these challenges, involving four steps: (1) equip citizen scientists\nwith mobile PM$_{2.5}$ sensors while they travel; (2) normalise the raw data to\nremove the influence of background ambient pollution levels; (3) fit a Gaussian\nprocess regression model to the normalised data and (4) calculate a grid of\nspatially explicit 'hotspot scores' using the probabilistic framework of\nGaussian processes, which conveniently summarise the relative pollution levels\nthroughout the city. We apply our method to create the first ever map of\nPM$_{2.5}$ pollution in Kigali, Rwanda, at a 200m resolution. Our results\nsuggest that the level of ambient PM$_{2.5}$ pollution in Kigali is dangerously\nhigh, and we identify the hotspots in Kigali where pollution consistently\nexceeds the city-wide average. We also evaluate our method using simulated\nmobile sensing data for Beijing, China, where we find that the hotspot scores\nare probabilistically well calibrated and accurately reflect the 'ground truth'\nspatial profile of PM$_{2.5}$ pollution. Thanks to the use of open-source\nsoftware, our method can be re-applied in cities throughout the world with a\nhandful of low-cost sensors. The method can help fill the gap in urban air\nquality information and empower public health officials."}
{"id": "2509.17176", "pdf": "https://arxiv.org/pdf/2509.17176", "abs": "https://arxiv.org/abs/2509.17176", "authors": ["Ganesh Khekare", "Shivam Sunda", "Yash Bothra"], "title": "A Comprehensive Performance Comparison of Traditional and Ensemble Machine Learning Models for Online Fraud Detection", "categories": ["cs.LG"], "comment": "6 pages, 6 figures. Presented at IEEE INTERNATIONAL CONFERENCE ON\n  COMPUTING, COMMUNICATION AND NETWORKING TECHNOLOGIES (ICCCNT), 2025", "summary": "In the era of the digitally driven economy, where there has been an\nexponential surge in digital payment systems and other online activities,\nvarious forms of fraudulent activities have accompanied the digital growth, out\nof which credit card fraud has become an increasingly significant threat. To\ndeal with this, real-time fraud detection is essential for financial security\nbut remains challenging due to high transaction volumes and the complexity of\nmodern fraud patterns. This study presents a comprehensive performance\ncomparison between traditional machine learning models like Random Forest, SVM,\nLogistic Regression, XGBoost, and ensemble methods like Stacking and Voting\nClassifier for detecting credit card fraud on a heavily imbalanced public\ndataset, where the number of fraudulent transactions is 492 out of 284,807\ntotal transactions. Application-specific preprocessing techniques were applied,\nand the models were evaluated using various performance metrics. The ensemble\nmethods achieved an almost perfect precision of around 0.99, but traditional\nmethods demonstrated superior performance in terms of recall, which highlights\nthe trade-off between false positives and false negatives. The comprehensive\ncomparison reveals distinct performance strengths and limitations for each\nalgorithm, offering insights to guide practitioners in selecting the most\neffective model for robust fraud detection applications in real-world settings."}
{"id": "2509.17180", "pdf": "https://arxiv.org/pdf/2509.17180", "abs": "https://arxiv.org/abs/2509.17180", "authors": ["David Arbour", "Harsh Parikh", "Bijan Niknam", "Elizabeth Stuart", "Kara Rudolph", "Avi Feller"], "title": "Regularizing Extrapolation in Causal Inference", "categories": ["cs.LG", "econ.EM", "stat.ME"], "comment": null, "summary": "Many common estimators in machine learning and causal inference are linear\nsmoothers, where the prediction is a weighted average of the training outcomes.\nSome estimators, such as ordinary least squares and kernel ridge regression,\nallow for arbitrarily negative weights, which improve feature imbalance but\noften at the cost of increased dependence on parametric modeling assumptions\nand higher variance. By contrast, estimators like importance weighting and\nrandom forests (sometimes implicitly) restrict weights to be non-negative,\nreducing dependence on parametric modeling and variance at the cost of worse\nimbalance. In this paper, we propose a unified framework that directly\npenalizes the level of extrapolation, replacing the current practice of a hard\nnon-negativity constraint with a soft constraint and corresponding\nhyperparameter. We derive a worst-case extrapolation error bound and introduce\na novel \"bias-bias-variance\" tradeoff, encompassing biases due to feature\nimbalance, model misspecification, and estimator variance; this tradeoff is\nespecially pronounced in high dimensions, particularly when positivity is poor.\nWe then develop an optimization procedure that regularizes this bound while\nminimizing imbalance and outline how to use this approach as a sensitivity\nanalysis for dependence on parametric modeling assumptions. We demonstrate the\neffectiveness of our approach through synthetic experiments and a real-world\napplication, involving the generalization of randomized controlled trial\nestimates to a target population of interest."}
{"id": "2509.17182", "pdf": "https://arxiv.org/pdf/2509.17182", "abs": "https://arxiv.org/abs/2509.17182", "authors": ["Sam Jacob Jacob", "Markus Mrosek", "Carsten Othmer", "Harald Köstler"], "title": "PMRT: A Training Recipe for Fast, 3D High-Resolution Aerodynamic Prediction", "categories": ["cs.LG"], "comment": null, "summary": "The aerodynamic optimization of cars requires close collaboration between\naerodynamicists and stylists, while slow, expensive simulations remain a\nbottleneck. Surrogate models have been shown to accurately predict aerodynamics\nwithin the design space for which they were trained. However, many of these\nmodels struggle to scale to higher resolutions because of the 3D nature of the\nproblem and data scarcity. We propose Progressive Multi-Resolution Training\n(PMRT), a probabilistic multi-resolution training schedule that enables\ntraining a U-Net to predict the drag coefficient ($c_d$) and high-resolution\nvelocity fields (512 x 128 x 128) in 24 hours on a single NVIDIA H100 GPU, 7x\ncheaper than the high-resolution-only baseline, with similar accuracy. PMRT\nsamples batches from three resolutions based on probabilities that change\nduring training, starting with an emphasis on lower resolutions and gradually\nshifting toward higher resolutions. Since this is a training methodology, it\ncan be adapted to other high-resolution-focused backbones. We also show that a\nsingle model can be trained across five datasets from different solvers,\nincluding a real-world dataset, by conditioning on the simulation parameters.\nIn the DrivAerML dataset, our models achieve a $c_d$ $R^2$ of 0.975, matching\nliterature baselines at a fraction of the training cost."}
{"id": "2509.17186", "pdf": "https://arxiv.org/pdf/2509.17186", "abs": "https://arxiv.org/abs/2509.17186", "authors": ["Dehao Zhang", "Malu Zhang", "Shuai Wang", "Jingya Wang", "Wenjie Wei", "Zeyu Ma", "Guoqing Wang", "Yang Yang", "HaiZhou Li"], "title": "Dendritic Resonate-and-Fire Neuron for Effective and Efficient Long Sequence Modeling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The explosive growth in sequence length has intensified the demand for\neffective and efficient long sequence modeling. Benefiting from intrinsic\noscillatory membrane dynamics, Resonate-and-Fire (RF) neurons can efficiently\nextract frequency components from input signals and encode them into\nspatiotemporal spike trains, making them well-suited for long sequence\nmodeling. However, RF neurons exhibit limited effective memory capacity and a\ntrade-off between energy efficiency and training speed on complex temporal\ntasks. Inspired by the dendritic structure of biological neurons, we propose a\nDendritic Resonate-and-Fire (D-RF) model, which explicitly incorporates a\nmulti-dendritic and soma architecture. Each dendritic branch encodes specific\nfrequency bands by utilizing the intrinsic oscillatory dynamics of RF neurons,\nthereby collectively achieving comprehensive frequency representation.\nFurthermore, we introduce an adaptive threshold mechanism into the soma\nstructure that adjusts the threshold based on historical spiking activity,\nreducing redundant spikes while maintaining training efficiency in long\nsequence tasks. Extensive experiments demonstrate that our method maintains\ncompetitive accuracy while substantially ensuring sparse spikes without\ncompromising computational efficiency during training. These results underscore\nits potential as an effective and efficient solution for long sequence modeling\non edge platforms."}
{"id": "2509.17197", "pdf": "https://arxiv.org/pdf/2509.17197", "abs": "https://arxiv.org/abs/2509.17197", "authors": ["Junlong Ke", "Qiying Hu", "Shenghai Yuan", "Yuecong Xu", "Jianfei Yang"], "title": "SignalLLM: A General-Purpose LLM Agent Framework for Automated Signal Processing", "categories": ["cs.LG", "cs.AI", "eess.SP"], "comment": "11 pages", "summary": "Modern signal processing (SP) pipelines, whether model-based or data-driven,\noften constrained by complex and fragmented workflow, rely heavily on expert\nknowledge and manual engineering, and struggle with adaptability and\ngeneralization under limited data. In contrast, Large Language Models (LLMs)\noffer strong reasoning capabilities, broad general-purpose knowledge,\nin-context learning, and cross-modal transfer abilities, positioning them as\npowerful tools for automating and generalizing SP workflows. Motivated by these\npotentials, we introduce SignalLLM, the first general-purpose LLM-based agent\nframework for general SP tasks. Unlike prior LLM-based SP approaches that are\nlimited to narrow applications or tricky prompting, SignalLLM introduces a\nprincipled, modular architecture. It decomposes high-level SP goals into\nstructured subtasks via in-context learning and domain-specific retrieval,\nfollowed by hierarchical planning through adaptive retrieval-augmented\ngeneration (RAG) and refinement; these subtasks are then executed through\nprompt-based reasoning, cross-modal reasoning, code synthesis, model\ninvocation, or data-driven LLM-assisted modeling. Its generalizable design\nenables the flexible selection of problem solving strategies across different\nsignal modalities, task types, and data conditions. We demonstrate the\nversatility and effectiveness of SignalLLM through five representative tasks in\ncommunication and sensing, such as radar target detection, human activity\nrecognition, and text compression. Experimental results show superior\nperformance over traditional and existing LLM-based methods, particularly in\nfew-shot and zero-shot settings."}
{"id": "2509.17205", "pdf": "https://arxiv.org/pdf/2509.17205", "abs": "https://arxiv.org/abs/2509.17205", "authors": ["Wook Lee", "Frans A. Oliehoek"], "title": "Conditional Policy Generator for Dynamic Constraint Satisfaction and Optimization", "categories": ["cs.LG"], "comment": null, "summary": "Leveraging machine learning methods to solve constraint satisfaction problems\nhas shown promising, but they are mostly limited to a static situation where\nthe problem description is completely known and fixed from the beginning. In\nthis work we present a new approach to constraint satisfaction and optimization\nin dynamically changing environments, particularly when variables in the\nproblem are statistically independent. We frame it as a reinforcement learning\nproblem and introduce a conditional policy generator by borrowing the idea of\nclass conditional generative adversarial networks (GANs). Assuming that the\nproblem includes both static and dynamic constraints, the former are used in a\nreward formulation to guide the policy training such that it learns to map to a\nprobabilistic distribution of solutions satisfying static constraints from a\nnoise prior, which is similar to a generator in GANs. On the other hand,\ndynamic constraints in the problem are encoded to different class labels and\nfed with the input noise. The policy is then simultaneously updated for maximum\nlikelihood of correctly classifying given the dynamic conditions in a\nsupervised manner. We empirically demonstrate a proof-of-principle experiment\nwith a multi-modal constraint satisfaction problem and compare between\nunconditional and conditional cases."}
{"id": "2509.17208", "pdf": "https://arxiv.org/pdf/2509.17208", "abs": "https://arxiv.org/abs/2509.17208", "authors": ["Kevin Bachelor", "Sanya Murdeshwar", "Daniel Sabo", "Razvan Marinescu"], "title": "Active Learning for Machine Learning Driven Molecular Dynamics", "categories": ["cs.LG", "physics.atm-clus", "I.6.5; I.2.1"], "comment": "8 pages, 4 figures, for Neurips Workshop: Machine Learning and the\n  Physical Sciences 2025", "summary": "Machine learned coarse grained (CG) potentials are fast, but degrade over\ntime when simulations reach undersampled biomolecular conformations, and\ngenerating widespread all atom (AA) data to combat this is computationally\ninfeasible. We propose a novel active learning framework for CG neural network\npotentials in molecular dynamics (MD). Building on the CGSchNet model, our\nmethod employs root mean squared deviation (RMSD) based frame selection from MD\nsimulations in order to generate data on the fly by querying an oracle during\nthe training of a neural network potential. This framework preserves CG level\nefficiency while correcting the model at precise, RMSD identified coverage\ngaps. By training CGSchNet, a coarse grained neural network potential, we\nempirically show that our framework explores previously unseen configurations\nand trains the model on unexplored regions of conformational space. Our active\nlearning framework enables a CGSchNet model trained on the Chignolin protein to\nachieve a 33.05% improvement in the Wasserstein 1 (W1) metric in Time lagged\nIndependent Component Analysis (TICA) space on an in house benchmark suite."}
{"id": "2509.17228", "pdf": "https://arxiv.org/pdf/2509.17228", "abs": "https://arxiv.org/abs/2509.17228", "authors": ["Zihan Liang", "Ziwen Pan", "Ruoxuan Xiong"], "title": "Causal Representation Learning from Multimodal Clinical Records under Non-Random Modality Missingness", "categories": ["cs.LG", "cs.CL", "stat.ME"], "comment": "To appear in Proc. of EMNLP 2025 (18 pages)", "summary": "Clinical notes contain rich patient information, such as diagnoses or\nmedications, making them valuable for patient representation learning. Recent\nadvances in large language models have further improved the ability to extract\nmeaningful representations from clinical texts. However, clinical notes are\noften missing. For example, in our analysis of the MIMIC-IV dataset, 24.5% of\npatients have no available discharge summaries. In such cases, representations\ncan be learned from other modalities such as structured data, chest X-rays, or\nradiology reports. Yet the availability of these modalities is influenced by\nclinical decision-making and varies across patients, resulting in modality\nmissing-not-at-random (MMNAR) patterns. We propose a causal representation\nlearning framework that leverages observed data and informative missingness in\nmultimodal clinical records. It consists of: (1) an MMNAR-aware modality fusion\ncomponent that integrates structured data, imaging, and text while conditioning\non missingness patterns to capture patient health and clinician-driven\nassignment; (2) a modality reconstruction component with contrastive learning\nto ensure semantic sufficiency in representation learning; and (3) a multitask\noutcome prediction model with a rectifier that corrects for residual bias from\nspecific modality observation patterns. Comprehensive evaluations across\nMIMIC-IV and eICU show consistent gains over the strongest baselines, achieving\nup to 13.8% AUC improvement for hospital readmission and 13.1% for ICU\nadmission."}
{"id": "2509.17235", "pdf": "https://arxiv.org/pdf/2509.17235", "abs": "https://arxiv.org/abs/2509.17235", "authors": ["Jiazhen Chen", "Mingbin Feng", "Tony S. Wirjanto"], "title": "Prospective Multi-Graph Cohesion for Multivariate Time Series Anomaly Detection", "categories": ["cs.LG"], "comment": "Accepted by the 18th ACM International Conference on Web Search and\n  Data Mining (ACM WSDM 2025)", "summary": "Anomaly detection in high-dimensional time series data is pivotal for\nnumerous industrial applications. Recent advances in multivariate time series\nanomaly detection (TSAD) have increasingly leveraged graph structures to model\ninter-variable relationships, typically employing Graph Neural Networks (GNNs).\nDespite their promising results, existing methods often rely on a single graph\nrepresentation, which are insufficient for capturing the complex, diverse\nrelationships inherent in multivariate time series. To address this, we propose\nthe Prospective Multi-Graph Cohesion (PMGC) framework for multivariate TSAD.\nPMGC exploits spatial correlations by integrating a long-term static graph with\na series of short-term instance-wise dynamic graphs, regulated through a graph\ncohesion loss function. Our theoretical analysis shows that this loss function\npromotes diversity among dynamic graphs while aligning them with the stable\nlong-term relationships encapsulated by the static graph. Additionally, we\nintroduce a \"prospective graphing\" strategy to mitigate the limitations of\ntraditional forecasting-based TSAD methods, which often struggle with\nunpredictable future variations. This strategy allows the model to accurately\nreflect concurrent inter-series relationships under normal conditions, thereby\nenhancing anomaly detection efficacy. Empirical evaluations on real-world\ndatasets demonstrate the superior performance of our method compared to\nexisting TSAD techniques."}
{"id": "2509.17241", "pdf": "https://arxiv.org/pdf/2509.17241", "abs": "https://arxiv.org/abs/2509.17241", "authors": ["Ali Faraji", "Manos Papagelis"], "title": "TraceHiding: Scalable Machine Unlearning for Mobility Data", "categories": ["cs.LG", "cs.CY"], "comment": null, "summary": "This work introduces TraceHiding, a scalable, importance-aware machine\nunlearning framework for mobility trajectory data. Motivated by privacy\nregulations such as GDPR and CCPA granting users \"the right to be forgotten,\"\nTraceHiding removes specified user trajectories from trained deep models\nwithout full retraining. It combines a hierarchical data-driven importance\nscoring scheme with teacher-student distillation. Importance scores--computed\nat token, trajectory, and user levels from statistical properties (coverage\ndiversity, entropy, length)--quantify each training sample's impact, enabling\ntargeted forgetting of high-impact data while preserving common patterns. The\nstudent model retains knowledge on remaining data and unlearns targeted\ntrajectories through an importance-weighted loss that amplifies forgetting\nsignals for unique samples and attenuates them for frequent ones. We validate\non Trajectory--User Linking (TUL) tasks across three real-world higher-order\nmobility datasets (HO-Rome, HO-Geolife, HO-NYC) and multiple architectures\n(GRU, LSTM, BERT, ModernBERT, GCN-TULHOR), against strong unlearning baselines\nincluding SCRUB, NegGrad, NegGrad+, Bad-T, and Finetuning. Experiments under\nuniform and targeted user deletion show TraceHiding, especially its\nentropy-based variant, achieves superior unlearning accuracy, competitive\nmembership inference attack (MIA) resilience, and up to 40\\times speedup over\nretraining with minimal test accuracy loss. Results highlight robustness to\nadversarial deletion of high-information users and consistent performance\nacross models. To our knowledge, this is the first systematic study of machine\nunlearning for trajectory data, providing a reproducible pipeline with public\ncode and preprocessing tools."}
{"id": "2509.17250", "pdf": "https://arxiv.org/pdf/2509.17250", "abs": "https://arxiv.org/abs/2509.17250", "authors": ["Yigit Berkay Uslu", "Samar Hadou", "Sergio Rozada", "Shirin Saeedi Bidokhti", "Alejandro Ribeiro"], "title": "Graph Signal Generative Diffusion Models", "categories": ["cs.LG", "eess.SP"], "comment": "Submitted to 2026 IEEE International Conference on Acoustics, Speech,\n  and Signal Processing (ICASSP 2026)", "summary": "We introduce U-shaped encoder-decoder graph neural networks (U-GNNs) for\nstochastic graph signal generation using denoising diffusion processes. The\narchitecture learns node features at different resolutions with skip\nconnections between the encoder and decoder paths, analogous to the\nconvolutional U-Net for image generation. The U-GNN is prominent for a pooling\noperation that leverages zero-padding and avoids arbitrary graph coarsening,\nwith graph convolutions layered on top to capture local dependencies. This\ntechnique permits learning feature embeddings for sampled nodes at deeper\nlevels of the architecture that remain convolutional with respect to the\noriginal graph. Applied to stock price prediction -- where deterministic\nforecasts struggle to capture uncertainties and tail events that are paramount\n-- we demonstrate the effectiveness of the diffusion model in probabilistic\nforecasting of stock prices."}
{"id": "2509.17281", "pdf": "https://arxiv.org/pdf/2509.17281", "abs": "https://arxiv.org/abs/2509.17281", "authors": ["Raisa Amiruddin", "Nikolay Y. Yordanov", "Nazanin Maleki", "Pascal Fehringer", "Athanasios Gkampenis", "Anastasia Janas", "Kiril Krantchev", "Ahmed Moawad", "Fabian Umeh", "Salma Abosabie", "Sara Abosabie", "Albara Alotaibi", "Mohamed Ghonim", "Mohanad Ghonim", "Sedra Abou Ali Mhana", "Nathan Page", "Marko Jakovljevic", "Yasaman Sharifi", "Prisha Bhatia", "Amirreza Manteghinejad", "Melisa Guelen", "Michael Veronesi", "Virginia Hill", "Tiffany So", "Mark Krycia", "Bojan Petrovic", "Fatima Memon", "Justin Cramer", "Elizabeth Schrickel", "Vilma Kosovic", "Lorenna Vidal", "Gerard Thompson", "Ichiro Ikuta", "Basimah Albalooshy", "Ali Nabavizadeh", "Nourel Hoda Tahon", "Karuna Shekdar", "Aashim Bhatia", "Claudia Kirsch", "Gennaro D'Anna", "Philipp Lohmann", "Amal Saleh Nour", "Andriy Myronenko", "Adam Goldman-Yassen", "Janet R. Reid", "Sanjay Aneja", "Spyridon Bakas", "Mariam Aboian"], "title": "Training the next generation of physicians for artificial intelligence-assisted clinical neuroradiology: ASNR MICCAI Brain Tumor Segmentation (BraTS) 2025 Lighthouse Challenge education platform", "categories": ["cs.LG", "cs.AI", "cs.CY"], "comment": "23 pages, 9 figures, 1 table, 3 supplementary tables", "summary": "High-quality reference standard image data creation by neuroradiology experts\nfor automated clinical tools can be a powerful tool for neuroradiology &\nartificial intelligence education. We developed a multimodal educational\napproach for students and trainees during the MICCAI Brain Tumor Segmentation\nLighthouse Challenge 2025, a landmark initiative to develop accurate brain\ntumor segmentation algorithms. Fifty-six medical students & radiology trainees\nvolunteered to annotate brain tumor MR images for the BraTS challenges of 2023\n& 2024, guided by faculty-led didactics on neuropathology MRI. Among the 56\nannotators, 14 select volunteers were then paired with neuroradiology faculty\nfor guided one-on-one annotation sessions for BraTS 2025. Lectures on\nneuroanatomy, pathology & AI, journal clubs & data scientist-led workshops were\norganized online. Annotators & audience members completed surveys on their\nperceived knowledge before & after annotations & lectures respectively.\nFourteen coordinators, each paired with a neuroradiologist, completed the data\nannotation process, averaging 1322.9+/-760.7 hours per dataset per pair and\n1200 segmentations in total. On a scale of 1-10, annotation coordinators\nreported significant increase in familiarity with image segmentation software\npre- and post-annotation, moving from initial average of 6+/-2.9 to final\naverage of 8.9+/-1.1, and significant increase in familiarity with brain tumor\nfeatures pre- and post-annotation, moving from initial average of 6.2+/-2.4 to\nfinal average of 8.1+/-1.2. We demonstrate an innovative offering for providing\nneuroradiology & AI education through an image segmentation challenge to\nenhance understanding of algorithm development, reinforce the concept of data\nreference standard, and diversify opportunities for AI-driven image analysis\namong future physicians."}
{"id": "2509.17291", "pdf": "https://arxiv.org/pdf/2509.17291", "abs": "https://arxiv.org/abs/2509.17291", "authors": ["Rahul Nandakumar", "Deepayan Chakrabarti"], "title": "GraphWeave: Interpretable and Robust Graph Generation via Random Walk Trajectories", "categories": ["cs.LG"], "comment": "18 pages, 4 figures. Accepted at ECML-PKDD 2025", "summary": "Given a set of graphs from some unknown family, we want to generate new\ngraphs from that family. Recent methods use diffusion on either graph\nembeddings or the discrete space of nodes and edges. However, simple changes to\nembeddings (say, adding noise) can mean uninterpretable changes in the graph.\nIn discrete-space diffusion, each step may add or remove many nodes/edges. It\nis hard to predict what graph patterns we will observe after many diffusion\nsteps. Our proposed method, called GraphWeave, takes a different approach. We\nseparate pattern generation and graph construction. To find patterns in the\ntraining graphs, we see how they transform vectors during random walks. We then\ngenerate new graphs in two steps. First, we generate realistic random walk\n\"trajectories\" which match the learned patterns. Then, we find the optimal\ngraph that fits these trajectories. The optimization infers all edges jointly,\nwhich improves robustness to errors. On four simulated and five real-world\nbenchmark datasets, GraphWeave outperforms existing methods. The most\nsignificant differences are on large-scale graph structures such as PageRank,\ncuts, communities, degree distributions, and flows. GraphWeave is also 10x\nfaster than its closest competitor. Finally, GraphWeave is simple, needing only\na transformer and standard optimizers."}
{"id": "2509.17293", "pdf": "https://arxiv.org/pdf/2509.17293", "abs": "https://arxiv.org/abs/2509.17293", "authors": ["Ryan Chappell", "Chayan Banerjee", "Kien Nguyen", "Clinton Fookes"], "title": "Physics-Informed Operator Learning for Hemodynamic Modeling", "categories": ["cs.LG", "eess.SP"], "comment": "To appear in the proceedings of DICTA 2025", "summary": "Accurate modeling of personalized cardiovascular dynamics is crucial for\nnon-invasive monitoring and therapy planning. State-of-the-art physics-informed\nneural network (PINN) approaches employ deep, multi-branch architectures with\nadversarial or contrastive objectives to enforce partial differential equation\nconstraints. While effective, these enhancements introduce significant training\nand implementation complexity, limiting scalability and practical deployment.\nWe investigate physics-informed neural operator learning models as efficient\nsupervisory signals for training simplified architectures through knowledge\ndistillation. Our approach pre-trains a physics-informed DeepONet (PI-DeepONet)\non high-fidelity cuffless blood pressure recordings to learn operator mappings\nfrom raw wearable waveforms to beat-to-beat pressure signals under embedded\nphysics constraints. This pre-trained operator serves as a frozen supervisor in\na lightweight knowledge-distillation pipeline, guiding streamlined base models\nthat eliminate complex adversarial and contrastive learning components while\nmaintaining performance. We characterize the role of physics-informed\nregularization in operator learning and demonstrate its effectiveness for\nsupervisory guidance. Through extensive experiments, our operator-supervised\napproach achieves performance parity with complex baselines (correlation: 0.766\nvs. 0.770, RMSE: 4.452 vs. 4.501), while dramatically reducing architectural\ncomplexity from eight critical hyperparameters to a single regularization\ncoefficient and decreasing training overhead by 4%. Our results demonstrate\nthat operator-based supervision effectively replaces intricate multi-component\ntraining strategies, offering a more scalable and interpretable approach to\nphysiological modeling with reduced implementation burden."}
{"id": "2509.17304", "pdf": "https://arxiv.org/pdf/2509.17304", "abs": "https://arxiv.org/abs/2509.17304", "authors": ["Tian Xie", "Ding Zhu", "Jia Liu", "Mahdi Khalili", "Xueru Zhang"], "title": "SPRINT: Stochastic Performative Prediction With Variance Reduction", "categories": ["cs.LG"], "comment": null, "summary": "Performative prediction (PP) is an algorithmic framework for optimizing\nmachine learning (ML) models where the model's deployment affects the\ndistribution of the data it is trained on. Compared to traditional ML with\nfixed data, designing algorithms in PP converging to a stable point -- known as\na stationary performative stable (SPS) solution -- is more challenging than the\ncounterpart in conventional ML tasks due to the model-induced distribution\nshifts. While considerable efforts have been made to find SPS solutions using\nmethods such as repeated gradient descent (RGD) and greedy stochastic gradient\ndescent (SGD-GD), most prior studies assumed a strongly convex loss until a\nrecent work established $\\mathcal{O}(1/\\sqrt{T})$ convergence of SGD-GD to SPS\nsolutions under smooth, non-convex losses. However, this latest progress is\nstill based on the restricted bounded variance assumption in stochastic\ngradient estimates and yields convergence bounds with a non-vanishing error\nneighborhood that scales with the variance. This limitation motivates us to\nimprove convergence rates and reduce error in stochastic optimization for PP,\nparticularly in non-convex settings. Thus, we propose a new algorithm called\nstochastic performative prediction with variance reduction (SPRINT) and\nestablish its convergence to an SPS solution at a rate of $\\mathcal{O}(1/T)$.\nNotably, the resulting error neighborhood is **independent** of the variance of\nthe stochastic gradients. Experiments on multiple real datasets with non-convex\nmodels demonstrate that SPRINT outperforms SGD-GD in both convergence rate and\nstability."}
{"id": "2509.17322", "pdf": "https://arxiv.org/pdf/2509.17322", "abs": "https://arxiv.org/abs/2509.17322", "authors": ["Chi Zhang", "Mengxin Zheng", "Qian Lou", "Hui Min Leung", "Fan Chen"], "title": "VQEzy: An Open-Source Dataset for Parameter Initialize in Variational Quantum Eigensolvers", "categories": ["cs.LG", "cs.ET", "quant-ph"], "comment": null, "summary": "Variational Quantum Eigensolvers (VQEs) are a leading class of noisy\nintermediate-scale quantum (NISQ) algorithms, whose performance is highly\nsensitive to parameter initialization. Although recent machine learning-based\ninitialization methods have achieved state-of-the-art performance, their\nprogress has been limited by the lack of comprehensive datasets. Existing\nresources are typically restricted to a single domain, contain only a few\nhundred instances, and lack complete coverage of Hamiltonians, ansatz circuits,\nand optimization trajectories. To overcome these limitations, we introduce\nVQEzy, the first large-scale dataset for VQE parameter initialization. VQEzy\nspans three major domains and seven representative tasks, comprising 12,110\ninstances with full VQE specifications and complete optimization trajectories.\nThe dataset is available online, and will be continuously refined and expanded\nto support future research in VQE optimization."}
{"id": "2509.17325", "pdf": "https://arxiv.org/pdf/2509.17325", "abs": "https://arxiv.org/abs/2509.17325", "authors": ["Weihua Du", "Hailei Gong", "Zhan Ling", "Kang Liu", "Lingfeng Shen", "Xuesong Yao", "Yufei Xu", "Dingyuan Shi", "Yiming Yang", "Jiecao Chen"], "title": "Generalizable End-to-End Tool-Use RL with Synthetic CodeGym", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "22 pages. Project available at https://github.com/StigLidu/CodeGym", "summary": "Tool-augmented large language models (LLMs), hereafter LLM agents, leverage\nexternal tools to solve diverse tasks and interface with the real world.\nHowever, current training practices largely rely on supervised fine-tuning\n(SFT) over static trajectories or reinforcement learning (RL) on narrow tasks,\nand generalize poorly beyond development settings, leading to brittleness with\nnew tools and unseen workflows. Because code execution reflects many structures\nof real-world workflows, coding problems provide a natural basis for building\nagent training environments. Motivated by this, we introduce CodeGym, a\nscalable framework that synthesizes diverse, verifiable, and controllable\nmulti-turn tool-use environments for agent RL, enabling LLM agents to explore\nand master various workflows actively. CodeGym rewrites static coding problems\ninto interactive environments by extracting atomic functions or logic into\ncallable tools, yielding verifiable tasks that span various tool-execution\nworkflows. Models of varying sizes and chain-of-thought configurations, trained\nin CodeGym, exhibit consistent out-of-distribution generalizability; for\nexample, Qwen2.5-32B-Instruct achieves an absolute accuracy gain of 8.7 points\non the OOD benchmark $\\tau$-Bench. These results highlight CodeGym as a step\ntoward scalable general-purpose RL environments that align with real-world\nagent workflows."}
{"id": "2509.17400", "pdf": "https://arxiv.org/pdf/2509.17400", "abs": "https://arxiv.org/abs/2509.17400", "authors": ["Xiaoyang Xu", "Xiaofeng Lin", "Koh Takeuchi", "Kyohei Atarashi", "Hisashi Kashima"], "title": "Robust Anomaly Detection Under Normality Distribution Shift in Dynamic Graphs", "categories": ["cs.LG"], "comment": null, "summary": "Anomaly detection in dynamic graphs is a critical task with broad real-world\napplications, including social networks, e-commerce, and cybersecurity. Most\nexisting methods assume that normal patterns remain stable over time; however,\nthis assumption often fails in practice due to the phenomenon we refer to as\nnormality distribution shift (NDS), where normal behaviors evolve over time.\nIgnoring NDS can lead models to misclassify shifted normal instances as\nanomalies, degrading detection performance. To tackle this issue, we propose\nWhENDS, a novel unsupervised anomaly detection method that aligns normal edge\nembeddings across time by estimating distributional statistics and applying\nwhitening transformations. Extensive experiments on four widely-used dynamic\ngraph datasets show that WhENDS consistently outperforms nine strong baselines,\nachieving state-of-the-art results and underscoring the importance of\naddressing NDS in dynamic graph anomaly detection."}
{"id": "2509.17405", "pdf": "https://arxiv.org/pdf/2509.17405", "abs": "https://arxiv.org/abs/2509.17405", "authors": ["Manish Acharya", "David Hyde"], "title": "Efficient Sliced Wasserstein Distance Computation via Adaptive Bayesian Optimization", "categories": ["cs.LG", "49Q22 (Primary) 90C57, 68Txx (Secondary)", "G.3; I.2"], "comment": "19 pages, 11 figures", "summary": "The sliced Wasserstein distance (SW) reduces optimal transport on\n$\\mathbb{R}^d$ to a sum of one-dimensional projections, and thanks to this\nefficiency, it is widely used in geometry, generative modeling, and\nregistration tasks. Recent work shows that quasi-Monte Carlo constructions for\ncomputing SW (QSW) yield direction sets with excellent approximation error.\nThis paper presents an alternate, novel approach: learning directions with\nBayesian optimization (BO), particularly in settings where SW appears inside an\noptimization loop (e.g., gradient flows). We introduce a family of drop-in\nselectors for projection directions: BOSW, a one-shot BO scheme on the unit\nsphere; RBOSW, a periodic-refresh variant; ABOSW, an adaptive hybrid that seeds\nfrom competitive QSW sets and performs a few lightweight BO refinements; and\nARBOSW, a restarted hybrid that periodically relearns directions during\noptimization. Our BO approaches can be composed with QSW and its variants\n(demonstrated by ABOSW/ARBOSW) and require no changes to downstream losses or\ngradients. We provide numerical experiments where our methods achieve\nstate-of-the-art performance, and on the experimental suite of the original QSW\npaper, we find that ABOSW and ARBOSW can achieve convergence comparable to the\nbest QSW variants with modest runtime overhead."}
{"id": "2509.17413", "pdf": "https://arxiv.org/pdf/2509.17413", "abs": "https://arxiv.org/abs/2509.17413", "authors": ["Masako Kishida"], "title": "Distributionally Robust Safety Verification of Neural Networks via Worst-Case CVaR", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY", "math.OC"], "comment": null, "summary": "Ensuring the safety of neural networks under input uncertainty is a\nfundamental challenge in safety-critical applications. This paper builds on and\nexpands Fazlyab's quadratic-constraint (QC) and semidefinite-programming (SDP)\nframework for neural network verification to a distributionally robust and\ntail-risk-aware setting by integrating worst-case Conditional Value-at-Risk\n(WC-CVaR) over a moment-based ambiguity set with fixed mean and covariance. The\nresulting conditions remain SDP-checkable and explicitly account for tail risk.\nThis integration broadens input-uncertainty geometry-covering ellipsoids,\npolytopes, and hyperplanes-and extends applicability to safety-critical domains\nwhere tail-event severity matters. Applications to closed-loop reachability of\ncontrol systems and classification are demonstrated through numerical\nexperiments, illustrating how the risk level $\\varepsilon$ trades conservatism\nfor tolerance to tail events-while preserving the computational structure of\nprior QC/SDP methods for neural network verification and robustness analysis."}
{"id": "2509.17446", "pdf": "https://arxiv.org/pdf/2509.17446", "abs": "https://arxiv.org/abs/2509.17446", "authors": ["Haofeng Huang", "Yifei Han", "Long Zhang", "Bin Li", "Yangfan He"], "title": "MVCL-DAF++: Enhancing Multimodal Intent Recognition via Prototype-Aware Contrastive Alignment and Coarse-to-Fine Dynamic Attention Fusion", "categories": ["cs.LG", "cs.AI"], "comment": "Submitted to ICASSP 2026", "summary": "Multimodal intent recognition (MMIR) suffers from weak semantic grounding and\npoor robustness under noisy or rare-class conditions. We propose MVCL-DAF++,\nwhich extends MVCL-DAF with two key modules: (1) Prototype-aware contrastive\nalignment, aligning instances to class-level prototypes to enhance semantic\nconsistency; and (2) Coarse-to-fine attention fusion, integrating global\nmodality summaries with token-level features for hierarchical cross-modal\ninteraction. On MIntRec and MIntRec2.0, MVCL-DAF++ achieves new\nstate-of-the-art results, improving rare-class recognition by +1.05\\% and\n+4.18\\% WF1, respectively. These results demonstrate the effectiveness of\nprototype-guided learning and coarse-to-fine fusion for robust multimodal\nunderstanding. The source code is available at\nhttps://github.com/chr1s623/MVCL-DAF-PlusPlus."}
{"id": "2509.17472", "pdf": "https://arxiv.org/pdf/2509.17472", "abs": "https://arxiv.org/abs/2509.17472", "authors": ["Jia Li", "Shiyu Long", "Ye Yuan"], "title": "Periodic Graph-Enhanced Multivariate Time Series Anomaly Detector", "categories": ["cs.LG"], "comment": null, "summary": "Multivariate time series (MTS) anomaly detection commonly encounters in\nvarious domains like finance, healthcare, and industrial monitoring. However,\nexisting MTS anomaly detection methods are mostly defined on the static graph\nstructure, which fails to perform an accurate representation of complex\nspatio-temporal correlations in MTS. To address this issue, this study proposes\na Periodic Graph-Enhanced Multivariate Time Series Anomaly Detector (PGMA) with\nthe following two-fold ideas: a) designing a periodic time-slot allocation\nstrategy based Fast Fourier Transform (FFT), which enables the graph structure\nto reflect dynamic changes in MTS; b) utilizing graph neural network and\ntemporal extension convolution to accurate extract the complex spatio-temporal\ncorrelations from the reconstructed periodic graphs. Experiments on four real\ndatasets from real applications demonstrate that the proposed PGMA outperforms\nstate-of-the-art models in MTS anomaly detection."}
{"id": "2509.17491", "pdf": "https://arxiv.org/pdf/2509.17491", "abs": "https://arxiv.org/abs/2509.17491", "authors": ["Firuz Kamalov", "Mohmad Al Falasi", "Fadi Thabtah"], "title": "Path-Weighted Integrated Gradients for Interpretable Dementia Classification", "categories": ["cs.LG"], "comment": null, "summary": "Integrated Gradients (IG) is a widely used attribution method in explainable\nartificial intelligence (XAI). In this paper, we introduce Path-Weighted\nIntegrated Gradients (PWIG), a generalization of IG that incorporates a\ncustomizable weighting function into the attribution integral. This\nmodification allows for targeted emphasis along different segments of the path\nbetween a baseline and the input, enabling improved interpretability, noise\nmitigation, and the detection of path-dependent feature relevance. We establish\nits theoretical properties and illustrate its utility through experiments on a\ndementia classification task using the OASIS-1 MRI dataset. Attribution maps\ngenerated by PWIG highlight clinically meaningful brain regions associated with\nvarious stages of dementia, providing users with sharp and stable explanations.\nThe results suggest that PWIG offers a flexible and theoretically grounded\napproach for enhancing attribution quality in complex predictive models."}
{"id": "2509.17495", "pdf": "https://arxiv.org/pdf/2509.17495", "abs": "https://arxiv.org/abs/2509.17495", "authors": ["Ke Ma", "Jialiang Lu", "Philippe Martins"], "title": "BiLCNet : BiLSTM-Conformer Network for Encrypted Traffic Classification with 5G SA Physical Channel Records", "categories": ["cs.LG", "cs.NI"], "comment": "6 pages, 5 figures", "summary": "Accurate and efficient traffic classification is vital for wireless network\nmanagement, especially under encrypted payloads and dynamic application\nbehavior, where traditional methods such as port-based identification and deep\npacket inspection (DPI) are increasingly inadequate. This work explores the\nfeasibility of using physical channel data collected from the air interface of\n5G Standalone (SA) networks for traffic sensing. We develop a preprocessing\npipeline to transform raw channel records into structured representations with\ncustomized feature engineering to enhance downstream classification\nperformance. To jointly capture temporal dependencies and both local and global\nstructural patterns inherent in physical channel records, we propose a novel\nhybrid architecture: BiLSTM-Conformer Network (BiLCNet), which integrates the\nsequential modeling capability of Bidirectional Long Short-Term Memory networks\n(BiLSTM) with the spatial feature extraction strength of Conformer blocks.\nEvaluated on a noise-limited 5G SA dataset, our model achieves a classification\naccuracy of 93.9%, outperforming a series of conventional machine learning and\ndeep learning algorithms. Furthermore, we demonstrate its generalization\nability under zero-shot transfer settings, validating its robustness across\ntraffic categories and varying environmental conditions."}
{"id": "2509.17514", "pdf": "https://arxiv.org/pdf/2509.17514", "abs": "https://arxiv.org/abs/2509.17514", "authors": ["Tianyi Chen", "Pengxiao Lin", "Zhiwei Wang", "Zhi-Qin John Xu"], "title": "Achilles' Heel of Mamba: Essential difficulties of the Mamba architecture demonstrated by synthetic data", "categories": ["cs.LG"], "comment": null, "summary": "State Space Models (SSMs) have emerged as promising alternatives to attention\nmechanisms, with the Mamba architecture demonstrating impressive performance\nand linear complexity for processing long sequences. However, the fundamental\ndifferences between Mamba and Transformer architectures remain incompletely\nunderstood. In this work, we use carefully designed synthetic tasks to reveal\nMamba's inherent limitations. Through experiments, we identify that Mamba's\nnonlinear convolution introduces an asymmetry bias that significantly impairs\nits ability to recognize symmetrical patterns and relationships. Using\ncomposite function and inverse sequence matching tasks, we demonstrate that\nMamba strongly favors compositional solutions over symmetrical ones and\nstruggles with tasks requiring the matching of reversed sequences. We show\nthese limitations stem not from the SSM module itself but from the nonlinear\nconvolution preceding it, which fuses token information asymmetrically. These\ninsights provide a new understanding of Mamba's constraints and suggest\nconcrete architectural improvements for future sequence models."}
{"id": "2509.17530", "pdf": "https://arxiv.org/pdf/2509.17530", "abs": "https://arxiv.org/abs/2509.17530", "authors": ["Sayanta Adhikari", "Vishnuprasadh Kumaravelu", "P. K. Srijith"], "title": "An Unlearning Framework for Continual Learning", "categories": ["cs.LG"], "comment": null, "summary": "Growing concerns surrounding AI safety and data privacy have driven the\ndevelopment of Machine Unlearning as a potential solution. However, current\nmachine unlearning algorithms are designed to complement the offline training\nparadigm. The emergence of the Continual Learning (CL) paradigm promises\nincremental model updates, enabling models to learn new tasks sequentially.\nNaturally, some of those tasks may need to be unlearned to address safety or\nprivacy concerns that might arise. We find that applying conventional\nunlearning algorithms in continual learning environments creates two critical\nproblems: performance degradation on retained tasks and task relapse, where\npreviously unlearned tasks resurface during subsequent learning. Furthermore,\nmost unlearning algorithms require data to operate, which conflicts with CL's\nphilosophy of discarding past data. A clear need arises for unlearning\nalgorithms that are data-free and mindful of future learning. To that end, we\npropose UnCLe, an Unlearning framework for Continual Learning. UnCLe employs a\nhypernetwork that learns to generate task-specific network parameters, using\ntask embeddings. Tasks are unlearned by aligning the corresponding generated\nnetwork parameters with noise, without requiring any data. Empirical\nevaluations on several vision data sets demonstrate UnCLe's ability to\nsequentially perform multiple learning and unlearning operations with minimal\ndisruption to previously acquired knowledge."}
{"id": "2509.17621", "pdf": "https://arxiv.org/pdf/2509.17621", "abs": "https://arxiv.org/abs/2509.17621", "authors": ["Khoa Tran", "Hung-Cuong Trinh", "Vy-Rin Nguyen", "T. Nguyen-Thoi", "Vin Nguyen-Thai"], "title": "SeqBattNet: A Discrete-State Physics-Informed Neural Network with Aging Adaptation for Battery Modeling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Accurate battery modeling is essential for reliable state estimation in\nmodern applications, such as predicting the remaining discharge time and\nremaining discharge energy in battery management systems. Existing approaches\nface several limitations: model-based methods require a large number of\nparameters; data-driven methods rely heavily on labeled datasets; and current\nphysics-informed neural networks (PINNs) often lack aging adaptation, or still\ndepend on many parameters, or continuously regenerate states. In this work, we\npropose SeqBattNet, a discrete-state PINN with built-in aging adaptation for\nbattery modeling, to predict terminal voltage during the discharge process.\nSeqBattNet consists of two components: (i) an encoder, implemented as the\nproposed HRM-GRU deep learning module, which generates cycle-specific aging\nadaptation parameters; and (ii) a decoder, based on the equivalent circuit\nmodel (ECM) combined with deep learning, which uses these parameters together\nwith the input current to predict voltage. The model requires only three basic\nbattery parameters and, when trained on data from a single cell, still achieves\nrobust performance. Extensive evaluations across three benchmark datasets (TRI,\nRT-Batt, and NASA) demonstrate that SeqBattNet significantly outperforms\nclassical sequence models and PINN baselines, achieving consistently lower RMSE\nwhile maintaining computational efficiency."}
{"id": "2509.17625", "pdf": "https://arxiv.org/pdf/2509.17625", "abs": "https://arxiv.org/abs/2509.17625", "authors": ["Blas Kolic", "Corrado Monti", "Gianmarco De Francisci Morales", "Marco Pangallo"], "title": "Comparing Data Assimilation and Likelihood-Based Inference on Latent State Estimation in Agent-Based Models", "categories": ["cs.LG", "cs.CY", "physics.soc-ph", "stat.ME"], "comment": null, "summary": "In this paper, we present the first systematic comparison of Data\nAssimilation (DA) and Likelihood-Based Inference (LBI) in the context of\nAgent-Based Models (ABMs). These models generate observable time series driven\nby evolving, partially-latent microstates. Latent states need to be estimated\nto align simulations with real-world data -- a task traditionally addressed by\nDA, especially in continuous and equation-based models such as those used in\nweather forecasting. However, the nature of ABMs poses challenges for standard\nDA methods. Solving such issues requires adaptation of previous DA techniques,\nor ad-hoc alternatives such as LBI. DA approximates the likelihood in a\nmodel-agnostic way, making it broadly applicable but potentially less precise.\nIn contrast, LBI provides more accurate state estimation by directly leveraging\nthe model's likelihood, but at the cost of requiring a hand-crafted,\nmodel-specific likelihood function, which may be complex or infeasible to\nderive. We compare the two methods on the Bounded-Confidence Model, a\nwell-known opinion dynamics ABM, where agents are affected only by others\nholding sufficiently similar opinions. We find that LBI better recovers latent\nagent-level opinions, even under model mis-specification, leading to improved\nindividual-level forecasts. At the aggregate level, however, both methods\nperform comparably, and DA remains competitive across levels of aggregation\nunder certain parameter settings. Our findings suggest that DA is well-suited\nfor aggregate predictions, while LBI is preferable for agent-level inference."}
{"id": "2509.17665", "pdf": "https://arxiv.org/pdf/2509.17665", "abs": "https://arxiv.org/abs/2509.17665", "authors": ["Katharina Simbeck", "Mariam Mahran"], "title": "Mechanistic Interpretability with SAEs: Probing Religion, Violence, and Geography in Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.CY"], "comment": "Accepted at AEQUITAS 2025: Workshop on Fairness and Bias in AI |\n  co-located with ECAI, October 26th, 2025, Bologna, Italy. 12 pages, 1 figure", "summary": "Despite growing research on bias in large language models (LLMs), most work\nhas focused on gender and race, with little attention to religious identity.\nThis paper explores how religion is internally represented in LLMs and how it\nintersects with concepts of violence and geography. Using mechanistic\ninterpretability and Sparse Autoencoders (SAEs) via the Neuronpedia API, we\nanalyze latent feature activations across five models. We measure overlap\nbetween religion- and violence-related prompts and probe semantic patterns in\nactivation contexts. While all five religions show comparable internal\ncohesion, Islam is more frequently linked to features associated with violent\nlanguage. In contrast, geographic associations largely reflect real-world\nreligious demographics, revealing how models embed both factual distributions\nand cultural stereotypes. These findings highlight the value of structural\nanalysis in auditing not just outputs but also internal representations that\nshape model behavior."}
{"id": "2509.17693", "pdf": "https://arxiv.org/pdf/2509.17693", "abs": "https://arxiv.org/abs/2509.17693", "authors": ["Adam Wesołowski", "Ronin Wu", "Karim Essafi"], "title": "Fast, Accurate and Interpretable Graph Classification with Topological Kernels", "categories": ["cs.LG"], "comment": null, "summary": "We introduce a novel class of explicit feature maps based on topological\nindices that represent each graph by a compact feature vector, enabling fast\nand interpretable graph classification. Using radial basis function kernels on\nthese compact vectors, we define a measure of similarity between graphs. We\nperform evaluation on standard molecular datasets and observe that\nclassification accuracies based on single topological-index feature vectors\nunderperform compared to state-of-the-art substructure-based kernels. However,\nwe achieve significantly faster Gram matrix evaluation -- up to $20\\times$\nfaster -- compared to the Weisfeiler--Lehman subtree kernel. To enhance\nperformance, we propose two extensions: 1) concatenating multiple topological\nindices into an \\emph{Extended Feature Vector} (EFV), and 2) \\emph{Linear\nCombination of Topological Kernels} (LCTK) by linearly combining Radial Basis\nFunction kernels computed on feature vectors of individual topological graph\nindices. These extensions deliver up to $12\\%$ percent accuracy gains across\nall the molecular datasets. A complexity analysis highlights the potential for\nexponential quantum speedup for some of the vector components. Our results\nindicate that LCTK and EFV offer a favourable trade-off between accuracy and\nefficiency, making them strong candidates for practical graph learning\napplications."}
{"id": "2509.17695", "pdf": "https://arxiv.org/pdf/2509.17695", "abs": "https://arxiv.org/abs/2509.17695", "authors": ["Leszek Sliwko"], "title": "Cluster Workload Allocation: A Predictive Approach Leveraging Machine Learning Efficiency", "categories": ["cs.LG", "cs.AI", "cs.DC", "cs.SE"], "comment": "This is the accepted version of the paper published in IEEE Access.\n  The final version is available at:\n  https://doi.org/10.1109/ACCESS.2024.3520422", "summary": "This research investigates how Machine Learning (ML) algorithms can assist in\nworkload allocation strategies by detecting tasks with node affinity operators\n(referred to as constraint operators), which constrain their execution to a\nlimited number of nodes. Using real-world Google Cluster Data (GCD) workload\ntraces and the AGOCS framework, the study extracts node attributes and task\nconstraints, then analyses them to identify suitable node-task pairings. It\nfocuses on tasks that can be executed on either a single node or fewer than a\nthousand out of 12.5k nodes in the analysed GCD cluster. Task constraint\noperators are compacted, pre-processed with one-hot encoding, and used as\nfeatures in a training dataset. Various ML classifiers, including Artificial\nNeural Networks, K-Nearest Neighbours, Decision Trees, Naive Bayes, Ridge\nRegression, Adaptive Boosting, and Bagging, are fine-tuned and assessed for\naccuracy and F1-scores. The final ensemble voting classifier model achieved 98%\naccuracy and a 1.5-1.8% misclassification rate for tasks with a single suitable\nnode."}
{"id": "2509.17728", "pdf": "https://arxiv.org/pdf/2509.17728", "abs": "https://arxiv.org/abs/2509.17728", "authors": ["Yara Zgheib", "Luca Calatroni", "Marc Antonini", "Roula Nassif"], "title": "A non-smooth regularization framework for learning over multitask graphs", "categories": ["cs.LG", "cs.MA"], "comment": null, "summary": "In this work, we consider learning over multitask graphs, where each agent\naims to estimate its own parameter vector. Although agents seek distinct\nobjectives, collaboration among them can be beneficial in scenarios where\nrelationships between tasks exist. Among the various approaches to promoting\nrelationships between tasks and, consequently, enhancing collaboration between\nagents, one notable method is regularization. While previous multitask learning\nstudies have focused on smooth regularization to enforce graph smoothness, this\nwork explores non-smooth regularization techniques that promote sparsity,\nmaking them particularly effective in encouraging piecewise constant\ntransitions on the graph. We begin by formulating a global regularized\noptimization problem, which involves minimizing the aggregate sum of individual\ncosts, regularized by a general non-smooth term designed to promote\npiecewise-constant relationships between the tasks of neighboring agents. Based\non the forward-backward splitting strategy, we propose a decentralized learning\napproach that enables efficient solutions to the regularized optimization\nproblem. Then, under convexity assumptions on the cost functions and\nco-regularization, we establish that the proposed approach converges in the\nmean-square-error sense within $O(\\mu)$ of the optimal solution of the globally\nregularized cost. For broader applicability and improved computational\nefficiency, we also derive closed-form expressions for commonly used non-smooth\n(and, possibly, non-convex) regularizers, such as the weighted sum of the\n$\\ell_0$-norm, $\\ell_1$-norm, and elastic net regularization. Finally, we\nillustrate both the theoretical findings and the effectiveness of the approach\nthrough simulations."}
{"id": "2509.17729", "pdf": "https://arxiv.org/pdf/2509.17729", "abs": "https://arxiv.org/abs/2509.17729", "authors": ["Siming Zheng", "Meifang Lan", "Tong Wang", "Yuanyuan Lin"], "title": "A Generative Conditional Distribution Equality Testing Framework and Its Minimax Analysis", "categories": ["cs.LG", "math.ST", "stat.ME", "stat.TH"], "comment": null, "summary": "In this paper, we propose a general framework for testing the equality of the\nconditional distributions in a two-sample problem. This problem is most\nrelevant to transfer learning under covariate shift. Our framework is built on\nneural network-based generative methods and sample splitting techniques by\ntransforming the conditional distribution testing problem into an unconditional\none. We introduce two special tests: the generative permutation-based\nconditional distribution equality test and the generative classification\naccuracy-based conditional distribution equality test. Theoretically, we\nestablish a minimax lower bound for statistical inference in testing the\nequality of two conditional distributions under certain smoothness conditions.\nWe demonstrate that the generative permutation-based conditional distribution\nequality test and its modified version can attain this lower bound precisely or\nup to some iterated logarithmic factor. Moreover, we prove the testing\nconsistency of the generative classification accuracy-based conditional\ndistribution equality test. We also establish the convergence rate for the\nlearned conditional generator by deriving new results related to the\nrecently-developed offset Rademacher complexity and approximation properties\nusing neural networks. Empirically, we conduct numerical studies including\nsynthetic datasets and two real-world datasets, demonstrating the effectiveness\nof our approach."}
{"id": "2509.17730", "pdf": "https://arxiv.org/pdf/2509.17730", "abs": "https://arxiv.org/abs/2509.17730", "authors": ["Bonan Zhang", "Zhongqi Chen", "Bowen Song", "Qinya Li", "Fan Wu", "Guihai Chen"], "title": "ConfClip: Confidence-Weighted and Clipped Reward for Reinforcement Learning in LLMs", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Reinforcement learning (RL) has become a standard paradigm for refining large\nlanguage models (LLMs) beyond pre-training and instruction tuning. A prominent\nline of work is RL with verifiable rewards (RLVR), which leverages\nautomatically verifiable outcomes (e.g., correctness or executability) to\ngenerate reward signals. While efficient, this framework faces two key\nlimitations: First, its binary feedback is too sparse to capture the quality of\nthe reasoning process. Second, its coarse-grained rewards potentially lead to\nvanishing gradients. Inspired by observations from human learning, we introduce\na RL technique that integrates verifiable outcomes with the model's own\nconfidence estimates. This joint design enriches the reward signal, providing\nfiner-grained feedback and implicitly supervising the reasoning process.\nExperimental results demonstrate that our proposed method enhances RL\nperformance across multiple datasets and reduces token consumption during\ninference, while incurring negligible additional training cost. Moreover, it\ncan be used as a plug-in module to enhance other state-of-the-art RL methods."}
{"id": "2509.17734", "pdf": "https://arxiv.org/pdf/2509.17734", "abs": "https://arxiv.org/abs/2509.17734", "authors": ["Pablo Rodríguez-Bocca", "Guillermo Pereira", "Diego Kiedanski", "Soledad Collazo", "Sebastián Basterrech", "Gerardo Rubino"], "title": "An AutoML Framework using AutoGluonTS for Forecasting Seasonal Extreme Temperatures", "categories": ["cs.LG", "cs.CE", "62M10, 68T05, 86A08, 62P12", "I.2.6; I.5.1; G.3; J.2"], "comment": "Manuscript to appear in the proceedings of IJCNN 2025, in the\n  workshop entitled \"AI for a Cooler Planet: Tackling Environmental Challenges\n  with Neural Networks.'' Total pages: 14. Total figures: 9 (containing a total\n  of 27 images). Total tables: 1", "summary": "In recent years, great progress has been made in the field of forecasting\nmeteorological variables. Recently, deep learning architectures have made a\nmajor breakthrough in forecasting the daily average temperature over a ten-day\nhorizon. However, advances in forecasting events related to the maximum\ntemperature over short horizons remain a challenge for the community. A problem\nthat is even more complex consists in making predictions of the maximum daily\ntemperatures in the short, medium, and long term. In this work, we focus on\nforecasting events related to the maximum daily temperature over medium-term\nperiods (90 days). Therefore, instead of addressing the problem from a\nmeteorological point of view, this article tackles it from a climatological\npoint of view. Due to the complexity of this problem, a common approach is to\nframe the study as a temporal classification problem with the classes: maximum\ntemperature \"above normal\", \"normal\" or \"below normal\". From a practical point\nof view, we created a large historical dataset (from 1981 to 2018) collecting\ninformation from weather stations located in South America. In addition, we\nalso integrated exogenous information from the Pacific, Atlantic, and Indian\nOcean basins. We applied the AutoGluonTS platform to solve the above-mentioned\nproblem. This AutoML tool shows competitive forecasting performance with\nrespect to large operational platforms dedicated to tackling this\nclimatological problem; but with a \"relatively\" low computational cost in terms\nof time and resources."}
{"id": "2509.17738", "pdf": "https://arxiv.org/pdf/2509.17738", "abs": "https://arxiv.org/abs/2509.17738", "authors": ["Ting Han", "Linara Adilova", "Henning Petzka", "Jens Kleesiek", "Michael Kamp"], "title": "Flatness is Necessary, Neural Collapse is Not: Rethinking Generalization via Grokking", "categories": ["cs.LG"], "comment": "Preprint version", "summary": "Neural collapse, i.e., the emergence of highly symmetric, class-wise\nclustered representations, is frequently observed in deep networks and is often\nassumed to reflect or enable generalization. In parallel, flatness of the loss\nlandscape has been theoretically and empirically linked to generalization. Yet,\nthe causal role of either phenomenon remains unclear: Are they prerequisites\nfor generalization, or merely by-products of training dynamics? We disentangle\nthese questions using grokking, a training regime in which memorization\nprecedes generalization, allowing us to temporally separate generalization from\ntraining dynamics and we find that while both neural collapse and relative\nflatness emerge near the onset of generalization, only flatness consistently\npredicts it. Models encouraged to collapse or prevented from collapsing\ngeneralize equally well, whereas models regularized away from flat solutions\nexhibit delayed generalization. Furthermore, we show theoretically that neural\ncollapse implies relative flatness under classical assumptions, explaining\ntheir empirical co-occurrence. Our results support the view that relative\nflatness is a potentially necessary and more fundamental property for\ngeneralization, and demonstrate how grokking can serve as a powerful probe for\nisolating its geometric underpinnings."}
{"id": "2509.17752", "pdf": "https://arxiv.org/pdf/2509.17752", "abs": "https://arxiv.org/abs/2509.17752", "authors": ["Miao Li", "Phuc Nguyen", "Christopher Tam", "Alexandra Morgan", "Kenneth Ge", "Rahul Bansal", "Linzi Yu", "Rima Arnaout", "Ramy Arnaout"], "title": "GEM-T: Generative Tabular Data via Fitting Moments", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "18 pages, 4 figures", "summary": "Tabular data dominates data science but poses challenges for generative\nmodels, especially when the data is limited or sensitive. We present a novel\napproach to generating synthetic tabular data based on the principle of maximum\nentropy -- MaxEnt -- called GEM-T, for ``generative entropy maximization for\ntables.'' GEM-T directly captures nth-order interactions -- pairwise,\nthird-order, etc. -- among columns of training data. In extensive testing,\nGEM-T matches or exceeds deep neural network approaches previously regarded as\nstate-of-the-art in 23 of 34 publicly available datasets representing diverse\nsubject domains (68\\%). Notably, GEM-T involves orders-of-magnitude fewer\ntrainable parameters, demonstrating that much of the information in real-world\ndata resides in low-dimensional, potentially human-interpretable correlations,\nprovided that the input data is appropriately transformed first. Furthermore,\nMaxEnt better handles heterogeneous data types (continuous vs. discrete vs.\ncategorical), lack of local structure, and other features of tabular data.\nGEM-T represents a promising direction for light-weight high-performance\ngenerative models for structured data."}
{"id": "2509.17755", "pdf": "https://arxiv.org/pdf/2509.17755", "abs": "https://arxiv.org/abs/2509.17755", "authors": ["Fizza Rubab", "Ntumba Elie Nsampi", "Martin Balint", "Felix Mujkanovic", "Hans-Peter Seidel", "Tobias Ritschel", "Thomas Leimkühler"], "title": "Learning Neural Antiderivatives", "categories": ["cs.LG", "cs.CV", "cs.GR"], "comment": null, "summary": "Neural fields offer continuous, learnable representations that extend beyond\ntraditional discrete formats in visual computing. We study the problem of\nlearning neural representations of repeated antiderivatives directly from a\nfunction, a continuous analogue of summed-area tables. Although widely used in\ndiscrete domains, such cumulative schemes rely on grids, which prevents their\napplicability in continuous neural contexts. We introduce and analyze a range\nof neural methods for repeated integration, including both adaptations of prior\nwork and novel designs. Our evaluation spans multiple input dimensionalities\nand integration orders, assessing both reconstruction quality and performance\nin downstream tasks such as filtering and rendering. These results enable\nintegrating classical cumulative operators into modern neural systems and offer\ninsights into learning tasks involving differential and integral operators."}
{"id": "2509.17784", "pdf": "https://arxiv.org/pdf/2509.17784", "abs": "https://arxiv.org/abs/2509.17784", "authors": ["Jin Li", "Shoujin Wang", "Qi Zhang", "Feng Liu", "Tongliang Liu", "Longbing Cao", "Shui Yu", "Fang Chen"], "title": "Revealing Multimodal Causality with Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at NeurIPS 2025", "summary": "Uncovering cause-and-effect mechanisms from data is fundamental to scientific\nprogress. While large language models (LLMs) show promise for enhancing causal\ndiscovery (CD) from unstructured data, their application to the increasingly\nprevalent multimodal setting remains a critical challenge. Even with the advent\nof multimodal LLMs (MLLMs), their efficacy in multimodal CD is hindered by two\nprimary limitations: (1) difficulty in exploring intra- and inter-modal\ninteractions for comprehensive causal variable identification; and (2)\ninsufficiency to handle structural ambiguities with purely observational data.\nTo address these challenges, we propose MLLM-CD, a novel framework for\nmultimodal causal discovery from unstructured data. It consists of three key\ncomponents: (1) a novel contrastive factor discovery module to identify genuine\nmultimodal factors based on the interactions explored from contrastive sample\npairs; (2) a statistical causal structure discovery module to infer causal\nrelationships among discovered factors; and (3) an iterative multimodal\ncounterfactual reasoning module to refine the discovery outcomes iteratively by\nincorporating the world knowledge and reasoning capabilities of MLLMs.\nExtensive experiments on both synthetic and real-world datasets demonstrate the\neffectiveness of MLLM-CD in revealing genuine factors and causal relationships\namong them from multimodal unstructured data."}
{"id": "2509.17791", "pdf": "https://arxiv.org/pdf/2509.17791", "abs": "https://arxiv.org/abs/2509.17791", "authors": ["Robert Hu", "Carlo Luschi", "Paul Balanca"], "title": "Elucidating the Design Space of FP4 training", "categories": ["cs.LG"], "comment": null, "summary": "The increasing computational demands of foundation models have spurred\nresearch into low-precision training, with 4-bit floating-point (\\texttt{FP4})\nformats emerging as a frontier for maximizing hardware throughput. While\nnumerous techniques have been proposed to stabilize \\texttt{FP4} training, they\noften present isolated solutions with varying, and not always clear,\ncomputational overheads. This paper aims to provide a unified view of the\ndesign space of \\texttt{FP4} training. We introduce a comprehensive,\nquantisation gradient-based framework for microscaling quantization that allows\nfor a theoretical analysis of the computational costs associated with different\nstabilization methods on both the forward and backward passes. Using a\nsimulator built on this framework, we conduct an extensive empirical study\nacross a wide range of machine learning tasks, including regression, image\nclassification, diffusion models, and language models. By systematically\nevaluating thousands of combinations of techniques, such as novel gradient\napproximations, rounding strategies, and scaling methods, we identify which\nconfigurations offer the most favourable performance-to-overhead trade-off. We\nfind that the techniques enabling the best trade-off involve carefully\ncombining Hadamard transformations, tensor scaling and stochastic rounding. We\nfurther find that using \\texttt{UE5M3} as a scaling factor potentially offers a\ngood compromise between range and precision with manageable computational\noverhead."}
{"id": "2509.17808", "pdf": "https://arxiv.org/pdf/2509.17808", "abs": "https://arxiv.org/abs/2509.17808", "authors": ["Yuxi Lu", "Biao Wu", "Zhidong Li", "Kunqi Li", "Chenya Huang", "Huacan Wang", "Qizhen Lan", "Ronghao Chen", "Ling Chen", "Bin Liang"], "title": "Remote Sensing-Oriented World Model", "categories": ["cs.LG", "F.2.2; I.2.7"], "comment": "10 pages, 5 figures", "summary": "World models have shown potential in artificial intelligence by predicting\nand reasoning about world states beyond direct observations. However, existing\napproaches are predominantly evaluated in synthetic environments or constrained\nscene settings, limiting their validation in real-world contexts with broad\nspatial coverage and complex semantics. Meanwhile, remote sensing applications\nurgently require spatial reasoning capabilities for disaster response and urban\nplanning. This paper bridges these gaps by introducing the first framework for\nworld modeling in remote sensing. We formulate remote sensing world modeling as\ndirection-conditioned spatial extrapolation, where models generate semantically\nconsistent adjacent image tiles given a central observation and directional\ninstruction. To enable rigorous evaluation, we develop RSWISE (Remote Sensing\nWorld-Image Spatial Evaluation), a benchmark containing 1,600 evaluation tasks\nacross four scenarios: general, flood, urban, and rural. RSWISE combines visual\nfidelity assessment with instruction compliance evaluation using GPT-4o as a\nsemantic judge, ensuring models genuinely perform spatial reasoning rather than\nsimple replication. Afterwards, we present RemoteBAGEL, a unified multimodal\nmodel fine-tuned on remote sensing data for spatial extrapolation tasks.\nExtensive experiments demonstrate that RemoteBAGEL consistently outperforms\nstate-of-the-art baselines on RSWISE."}
{"id": "2509.17809", "pdf": "https://arxiv.org/pdf/2509.17809", "abs": "https://arxiv.org/abs/2509.17809", "authors": ["Shuhan Zhong", "Weipeng Zhuo", "Sizhe Song", "Guanyao Li", "Zhongyi Yu", "S. -H. Gary Chan"], "title": "MTM: A Multi-Scale Token Mixing Transformer for Irregular Multivariate Time Series Classification", "categories": ["cs.LG"], "comment": "KDD 2025", "summary": "Irregular multivariate time series (IMTS) is characterized by the lack of\nsynchronized observations across its different channels. In this paper, we\npoint out that this channel-wise asynchrony can lead to poor channel-wise\nmodeling of existing deep learning methods. To overcome this limitation, we\npropose MTM, a multi-scale token mixing transformer for the classification of\nIMTS. We find that the channel-wise asynchrony can be alleviated by\ndown-sampling the time series to coarser timescales, and propose to incorporate\na masked concat pooling in MTM that gradually down-samples IMTS to enhance the\nchannel-wise attention modules. Meanwhile, we propose a novel channel-wise\ntoken mixing mechanism which proactively chooses important tokens from one\nchannel and mixes them with other channels, to further boost the channel-wise\nlearning of our model. Through extensive experiments on real-world datasets and\ncomparison with state-of-the-art methods, we demonstrate that MTM consistently\nachieves the best performance on all the benchmarks, with improvements of up to\n3.8% in AUPRC for classification."}
{"id": "2509.17811", "pdf": "https://arxiv.org/pdf/2509.17811", "abs": "https://arxiv.org/abs/2509.17811", "authors": ["Thrinadh Pinjala", "Aswin Ram Kumar Gannina", "Debasis Dwibedy"], "title": "MSGAT-GRU: A Multi-Scale Graph Attention and Recurrent Model for Spatiotemporal Road Accident Prediction", "categories": ["cs.LG"], "comment": "16 pages, 4 figures, 4 tables", "summary": "Accurate prediction of road accidents remains challenging due to intertwined\nspatial, temporal, and contextual factors in urban traffic. We propose\nMSGAT-GRU, a multi-scale graph attention and recurrent model that jointly\ncaptures localized and long-range spatial dependencies while modeling\nsequential dynamics. Heterogeneous inputs, such as traffic flow, road\nattributes, weather, and points of interest, are systematically fused to\nenhance robustness and interpretability. On the Hybrid Beijing Accidents\ndataset, MSGAT-GRU achieves an RMSE of 0.334 and an F1-score of 0.878,\nconsistently outperforming strong baselines. Cross-dataset evaluation on\nMETR-LA under a 1-hour horizon further supports transferability, with RMSE of\n6.48 (vs. 7.21 for the GMAN model) and comparable MAPE. Ablations indicate that\nthree-hop spatial aggregation and a two-layer GRU offer the best\naccuracy-stability trade-off. These results position MSGAT-GRU as a scalable\nand generalizable model for intelligent transportation systems, providing\ninterpretable signals that can inform proactive traffic management and road\nsafety analytics."}
{"id": "2509.17815", "pdf": "https://arxiv.org/pdf/2509.17815", "abs": "https://arxiv.org/abs/2509.17815", "authors": ["Andrea Agazzi", "Vittorio Carlei", "Marco Romito", "Samuele Saviozzi"], "title": "Global Optimization via Softmin Energy Minimization", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Global optimization, particularly for non-convex functions with multiple\nlocal minima, poses significant challenges for traditional gradient-based\nmethods. While metaheuristic approaches offer empirical effectiveness, they\noften lack theoretical convergence guarantees and may disregard available\ngradient information. This paper introduces a novel gradient-based swarm\nparticle optimization method designed to efficiently escape local minima and\nlocate global optima. Our approach leverages a \"Soft-min Energy\" interacting\nfunction, $J_\\beta(\\mathbf{x})$, which provides a smooth, differentiable\napproximation of the minimum function value within a particle swarm. We define\na stochastic gradient flow in the particle space, incorporating a Brownian\nmotion term for exploration and a time-dependent parameter $\\beta$ to control\nsmoothness, similar to temperature annealing. We theoretically demonstrate that\nfor strongly convex functions, our dynamics converges to a stationary point\nwhere at least one particle reaches the global minimum, with other particles\nexhibiting exploratory behavior. Furthermore, we show that our method\nfacilitates faster transitions between local minima by reducing effective\npotential barriers with respect to Simulated Annealing. More specifically, we\nestimate the hitting times of unexplored potential wells for our model in the\nsmall noise regime and show that they compare favorably with the ones of\noverdamped Langevin. Numerical experiments on benchmark functions, including\ndouble wells and the Ackley function, validate our theoretical findings and\ndemonstrate better performance over the well-known Simulated Annealing method\nin terms of escaping local minima and achieving faster convergence."}
{"id": "2509.17845", "pdf": "https://arxiv.org/pdf/2509.17845", "abs": "https://arxiv.org/abs/2509.17845", "authors": ["Kai Zhang", "Siming Sun", "Zhengyu Fan", "Qinmin Yang", "Xuejun Jiang"], "title": "Conv-like Scale-Fusion Time Series Transformer: A Multi-Scale Representation for Variable-Length Long Time Series", "categories": ["cs.LG"], "comment": null, "summary": "Time series analysis faces significant challenges in handling variable-length\ndata and achieving robust generalization. While Transformer-based models have\nadvanced time series tasks, they often struggle with feature redundancy and\nlimited generalization capabilities. Drawing inspiration from classical CNN\narchitectures' pyramidal structure, we propose a Multi-Scale Representation\nLearning Framework based on a Conv-like ScaleFusion Transformer. Our approach\nintroduces a temporal convolution-like structure that combines patching\noperations with multi-head attention, enabling progressive temporal dimension\ncompression and feature channel expansion. We further develop a novel\ncross-scale attention mechanism for effective feature fusion across different\ntemporal scales, along with a log-space normalization method for\nvariable-length sequences. Extensive experiments demonstrate that our framework\nachieves superior feature independence, reduced redundancy, and better\nperformance in forecasting and classification tasks compared to\nstate-of-the-art methods."}
{"id": "2509.17866", "pdf": "https://arxiv.org/pdf/2509.17866", "abs": "https://arxiv.org/abs/2509.17866", "authors": ["Xinyu He", "Xianghui Cao"], "title": "Understanding Post-Training Structural Changes in Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": "38 pages, 26 figures", "summary": "Post-training fundamentally alters the behavior of large language models\n(LLMs), yet its impact on the internal parameter space remains poorly\nunderstood. In this work, we conduct a systematic singular value decomposition\n(SVD) analysis of principal linear layers in pretrained LLMs, focusing on two\nwidely adopted post-training methods: instruction tuning and\nlong-chain-of-thought (Long-CoT) distillation. Our analysis reveals two\nconsistent and unexpected structural changes:(1) a near-uniform geometric\nscaling of singular values across layers, which theoretically modulates\nattention scores; and (2) highly consistent orthogonal transformations are\napplied to the left and right singular vectors of each matrix. Disrupting this\northogonal consistency leads to catastrophic performance degradation. Based on\nthese findings, we propose a simple yet effective framework that interprets\npost-training as a reparameterization of fixed subspaces in the pretrained\nparameter space. Further experiments reveal that singular value scaling behaves\nas a secondary effect, analogous to a temperature adjustment, whereas the core\nfunctional transformation lies in the coordinated rotation of singular vectors.\nThese results challenge the prevailing view of the parameter space in large\nmodels as a black box, uncovering the first clear regularities in how\nparameters evolve during training, and providing a new perspective for deeper\ninvestigation into model parameter changes."}
{"id": "2509.17870", "pdf": "https://arxiv.org/pdf/2509.17870", "abs": "https://arxiv.org/abs/2509.17870", "authors": ["Xiao Mao", "Albert H. Schrotenboer", "Guohua Wu", "Willem van Jaarsveld"], "title": "Improving After-sales Service: Deep Reinforcement Learning for Dynamic Time Slot Assignment with Commitments and Customer Preferences", "categories": ["cs.LG"], "comment": null, "summary": "Problem definition: For original equipment manufacturers (OEMs), high-tech\nmaintenance is a strategic component in after-sales services, involving close\ncoordination between customers and service engineers. Each customer suggests\nseveral time slots for their maintenance task, from which the OEM must select\none. This decision needs to be made promptly to support customers' planning. At\nthe end of each day, routes for service engineers are planned to fulfill the\ntasks scheduled for the following day. We study this hierarchical and\nsequential decision-making problem-the Dynamic Time Slot Assignment Problem\nwith Commitments and Customer Preferences (DTSAP-CCP)-in this paper.\nMethodology/results: Two distinct approaches are proposed: 1) an\nattention-based deep reinforcement learning with rollout execution (ADRL-RE)\nand 2) a scenario-based planning approach (SBP). The ADRL-RE combines a\nwell-trained attention-based neural network with a rollout framework for online\ntrajectory simulation. To support the training, we develop a neural heuristic\nsolver that provides rapid route planning solutions, enabling efficient\nlearning in complex combinatorial settings. The SBP approach samples several\nscenarios to guide the time slot assignment. Numerical experiments demonstrate\nthe superiority of ADRL-RE and the stability of SBP compared to both rule-based\nand rollout-based approaches. Furthermore, the strong practicality of ADRL-RE\nis verified in a case study of after-sales service for large medical equipment.\nImplications: This study provides OEMs with practical decision-support tools\nfor dynamic maintenance scheduling, balancing customer preferences and\noperational efficiency. In particular, our ADRL-RE shows strong real-world\npotential, supporting timely and customer-aligned maintenance scheduling."}
{"id": "2509.17874", "pdf": "https://arxiv.org/pdf/2509.17874", "abs": "https://arxiv.org/abs/2509.17874", "authors": ["Paulius Rauba", "Mihaela van der Schaar"], "title": "Deep Hierarchical Learning with Nested Subspace Networks", "categories": ["cs.LG"], "comment": null, "summary": "Large neural networks are typically trained for a fixed computational budget,\ncreating a rigid trade-off between performance and efficiency that is\nill-suited for deployment in resource-constrained or dynamic environments.\nExisting approaches to this problem present a difficult choice: training a\ndiscrete collection of specialist models is computationally prohibitive, while\ndynamic methods like slimmable networks often lack the flexibility to be\napplied to large, pre-trained foundation models. In this work, we propose\nNested Subspace Networks (NSNs), a novel architectural paradigm that enables a\nsingle model to be dynamically and granularly adjusted across a continuous\nspectrum of compute budgets at inference time. The core of our approach is to\nre-parameterize linear layers to satisfy a nested subspace property, such that\nthe function computed at a given rank is a strict subspace of the function at\nany higher rank. We show that this entire hierarchy of models can be optimized\njointly via an uncertainty-aware objective that learns to balance the\ncontributions of different ranks based on their intrinsic difficulty. We\ndemonstrate empirically that NSNs can be surgically applied to pre-trained LLMs\nand unlock a smooth and predictable compute-performance frontier. For example,\na single NSN-adapted model can achieve a 50% reduction in inference FLOPs with\nonly a 5 percentage point loss in accuracy. Our findings establish NSNs as a\npowerful framework for creating the next generation of adaptive foundation\nmodels."}
{"id": "2509.17885", "pdf": "https://arxiv.org/pdf/2509.17885", "abs": "https://arxiv.org/abs/2509.17885", "authors": ["Saad Mokssit", "Ouassim Karrakchou", "Alejandro Mousist", "Mounir Ghogho"], "title": "Confidence-gated training for efficient early-exit neural networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Early-exit neural networks reduce inference cost by enabling confident\npredictions at intermediate layers. However, joint training often leads to\ngradient interference, with deeper classifiers dominating optimization. We\npropose Confidence-Gated Training (CGT), a paradigm that conditionally\npropagates gradients from deeper exits only when preceding exits fail. This\nencourages shallow classifiers to act as primary decision points while\nreserving deeper layers for harder inputs. By aligning training with the\ninference-time policy, CGT mitigates overthinking, improves early-exit\naccuracy, and preserves efficiency. Experiments on the Indian Pines and\nFashion-MNIST benchmarks show that CGT lowers average inference cost while\nimproving overall accuracy, offering a practical solution for deploying deep\nmodels in resource-constrained environments."}
{"id": "2509.17889", "pdf": "https://arxiv.org/pdf/2509.17889", "abs": "https://arxiv.org/abs/2509.17889", "authors": ["Phuong Mai Dinh", "Van-Nam Huynh"], "title": "GaussianPSL: A novel framework based on Gaussian Splatting for exploring the Pareto frontier in multi-criteria optimization", "categories": ["cs.LG"], "comment": null, "summary": "Multi-objective optimization (MOO) is essential for solving complex\nreal-world problems involving multiple conflicting objectives. However, many\npractical applications - including engineering design, autonomous systems, and\nmachine learning - often yield non-convex, degenerate, or discontinuous Pareto\nfrontiers, which involve traditional scalarization and Pareto Set Learning\n(PSL) methods that struggle to approximate accurately. Existing PSL approaches\nperform well on convex fronts but tend to fail in capturing the diversity and\nstructure of irregular Pareto sets commonly observed in real-world scenarios.\nIn this paper, we propose Gaussian-PSL, a novel framework that integrates\nGaussian Splatting into PSL to address the challenges posed by non-convex\nPareto frontiers. Our method dynamically partitions the preference vector\nspace, enabling simple MLP networks to learn localized features within each\nregion, which are then integrated by an additional MLP aggregator. This\npartition-aware strategy enhances both exploration and convergence, reduces\nsensi- tivity to initialization, and improves robustness against local optima.\nWe first provide the mathematical formulation for controllable Pareto set\nlearning using Gaussian Splat- ting. Then, we introduce the Gaussian-PSL\narchitecture and evaluate its performance on synthetic and real-world\nmulti-objective benchmarks. Experimental results demonstrate that our approach\noutperforms standard PSL models in learning irregular Pareto fronts while\nmaintaining computational efficiency and model simplicity. This work offers a\nnew direction for effective and scalable MOO under challenging frontier\ngeometries."}
{"id": "2509.17894", "pdf": "https://arxiv.org/pdf/2509.17894", "abs": "https://arxiv.org/abs/2509.17894", "authors": ["Siu Hang Ho", "Prasad Ganesan", "Nguyen Duong", "Daniel Schlabig"], "title": "Optimizing Inference in Transformer-Based Models: A Multi-Method Benchmark", "categories": ["cs.LG", "68T07", "I.2.6; I.5.1"], "comment": "10 pages, 5 figures. Technical report", "summary": "Efficient inference is a critical challenge in deep generative modeling,\nparticularly as diffusion models grow in capacity and complexity. While\nincreased complexity often improves accuracy, it raises compute costs, latency,\nand memory requirements. This work investigates techniques such as pruning,\nquantization, knowledge distillation, and simplified attention to reduce\ncomputational overhead without impacting performance. The study also explores\nthe Mixture of Experts (MoE) approach to further enhance efficiency. These\nexperiments provide insights into optimizing inference for the state-of-the-art\nFast Diffusion Transformer (fast-DiT) model."}
{"id": "2509.17920", "pdf": "https://arxiv.org/pdf/2509.17920", "abs": "https://arxiv.org/abs/2509.17920", "authors": ["Jamiyan Sukhbaatar", "Satoshi Imamura", "Ibuki Inoue", "Shoya Murakami", "Kazi Mahmudul Hassan", "Seungwoo Han", "Ingon Chanpornpakdi", "Toshihisa Tanaka"], "title": "SingLEM: Single-Channel Large EEG Model", "categories": ["cs.LG"], "comment": null, "summary": "Current deep learning models for electroencephalography (EEG) are often\ntask-specific and depend on large labeled datasets, limiting their\nadaptability. Although emerging foundation models aim for broader\napplicability, their rigid dependence on fixed, high-density multi-channel\nmontages restricts their use across heterogeneous datasets and in\nmissing-channel or practical low-channel settings. To address these\nlimitations, we introduce SingLEM, a self-supervised foundation model that\nlearns robust, general-purpose representations from single-channel EEG, making\nit inherently hardware agnostic. The model employs a hybrid encoder\narchitecture that combines convolutional layers to extract local features with\na hierarchical transformer to model both short- and long-range temporal\ndependencies. SingLEM is pretrained on 71 public datasets comprising over 9,200\nsubjects and 357,000 single-channel hours of EEG. When evaluated as a fixed\nfeature extractor across six motor imagery and cognitive tasks, aggregated\nsingle-channel representations consistently outperformed leading multi-channel\nfoundation models and handcrafted baselines. These results demonstrate that a\nsingle-channel approach can achieve state-of-the-art generalization while\nenabling fine-grained neurophysiological analysis and enhancing\ninterpretability. The source code and pretrained models are available at\nhttps://github.com/ttlabtuat/SingLEM."}
{"id": "2509.17924", "pdf": "https://arxiv.org/pdf/2509.17924", "abs": "https://arxiv.org/abs/2509.17924", "authors": ["Xiuqi Ge", "Zhibo Yao", "Yaosong Du"], "title": "Medical priority fusion: achieving dual optimization of sensitivity and interpretability in nipt anomaly detection", "categories": ["cs.LG", "q-bio.TO"], "comment": "24 pages, 47 figures, publish to BIBM", "summary": "Clinical machine learning faces a critical dilemma in high-stakes medical\napplications: algorithms achieving optimal diagnostic performance typically\nsacrifice the interpretability essential for physician decision-making, while\ninterpretable methods compromise sensitivity in complex scenarios. This paradox\nbecomes particularly acute in non-invasive prenatal testing (NIPT), where\nmissed chromosomal abnormalities carry profound clinical consequences yet\nregulatory frameworks mandate explainable AI systems. We introduce Medical\nPriority Fusion (MPF), a constrained multi-objective optimization framework\nthat resolves this fundamental trade-off by systematically integrating Naive\nBayes probabilistic reasoning with Decision Tree rule-based logic through\nmathematically-principled weighted fusion under explicit medical constraints.\nRigorous validation on 1,687 real-world NIPT samples characterized by extreme\nclass imbalance (43.4:1 normal-to-abnormal ratio) employed stratified 5-fold\ncross-validation with comprehensive ablation studies and statistical hypothesis\ntesting using McNemar's paired comparisons. MPF achieved simultaneous\noptimization of dual objectives: 89.3% sensitivity (95% CI: 83.9-94.7%) with\n80% interpretability score, significantly outperforming individual algorithms\n(McNemar's test, p < 0.001). The optimal fusion configuration achieved Grade A\nclinical deployment criteria with large effect size (d = 1.24), establishing\nthe first clinically-deployable solution that maintains both diagnostic\naccuracy and decision transparency essential for prenatal care. This work\ndemonstrates that medical-constrained algorithm fusion can resolve the\ninterpretability-performance trade-off, providing a mathematical framework for\ndeveloping high-stakes medical decision support systems that meet both clinical\nefficacy and explainability requirements."}
{"id": "2509.17942", "pdf": "https://arxiv.org/pdf/2509.17942", "abs": "https://arxiv.org/abs/2509.17942", "authors": ["Nicholas Kraabel", "Jiangtao Liu", "Yuchen Bian", "Daniel Kifer", "Chaopeng Shen"], "title": "StefaLand: An Efficient Geoscience Foundation Model That Improves Dynamic Land-Surface Predictions", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Stewarding natural resources, mitigating floods, droughts, wildfires, and\nlandslides, and meeting growing demands require models that can predict\nclimate-driven land-surface responses and human feedback with high accuracy.\nTraditional impact models, whether process-based, statistical, or machine\nlearning, struggle with spatial generalization due to limited observations and\nconcept drift. Recently proposed vision foundation models trained on satellite\nimagery demand massive compute and are ill-suited for dynamic land-surface\nprediction. We introduce StefaLand, a generative spatiotemporal earth\nfoundation model centered on landscape interactions. StefaLand improves\npredictions on three tasks and four datasets: streamflow, soil moisture, and\nsoil composition, compared to prior state-of-the-art. Results highlight its\nability to generalize across diverse, data-scarce regions and support broad\nland-surface applications. The model builds on a masked autoencoder backbone\nthat learns deep joint representations of landscape attributes, with a\nlocation-aware architecture fusing static and time-series inputs,\nattribute-based representations that drastically reduce compute, and residual\nfine-tuning adapters that enhance transfer. While inspired by prior methods,\ntheir alignment with geoscience and integration in one model enables robust\nperformance on dynamic land-surface tasks. StefaLand can be pretrained and\nfinetuned on academic compute yet outperforms state-of-the-art baselines and\neven fine-tuned vision foundation models. To our knowledge, this is the first\ngeoscience land-surface foundation model that demonstrably improves dynamic\nland-surface interaction predictions and supports diverse downstream\napplications."}
{"id": "2509.17970", "pdf": "https://arxiv.org/pdf/2509.17970", "abs": "https://arxiv.org/abs/2509.17970", "authors": ["Yunchu Han", "Zhaojun Nan", "Sheng Zhou", "Zhisheng Niu"], "title": "Joint Optimization of Memory Frequency, Computing Frequency, Transmission Power and Task Offloading for Energy-efficient DNN Inference", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Deep neural networks (DNNs) have been widely applied in diverse applications,\nbut the problems of high latency and energy overhead are inevitable on\nresource-constrained devices. To address this challenge, most researchers focus\non the dynamic voltage and frequency scaling (DVFS) technique to balance the\nlatency and energy consumption by changing the computing frequency of\nprocessors. However, the adjustment of memory frequency is usually ignored and\nnot fully utilized to achieve efficient DNN inference, which also plays a\nsignificant role in the inference time and energy consumption. In this paper,\nwe first investigate the impact of joint memory frequency and computing\nfrequency scaling on the inference time and energy consumption with a\nmodel-based and data-driven method. Then by combining with the fitting\nparameters of different DNN models, we give a preliminary analysis for the\nproposed model to see the effects of adjusting memory frequency and computing\nfrequency simultaneously. Finally, simulation results in local inference and\ncooperative inference cases further validate the effectiveness of jointly\nscaling the memory frequency and computing frequency to reduce the energy\nconsumption of devices."}
{"id": "2509.17971", "pdf": "https://arxiv.org/pdf/2509.17971", "abs": "https://arxiv.org/abs/2509.17971", "authors": ["Tan-Ha Mai", "Hsuan-Tien Lin"], "title": "Intra-Cluster Mixup: An Effective Data Augmentation Technique for Complementary-Label Learning", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "22 pages, 10 figures", "summary": "In this paper, we investigate the challenges of complementary-label learning\n(CLL), a specialized form of weakly-supervised learning (WSL) where models are\ntrained with labels indicating classes to which instances do not belong, rather\nthan standard ordinary labels. This alternative supervision is appealing\nbecause collecting complementary labels is generally cheaper and less\nlabor-intensive. Although most existing research in CLL emphasizes the\ndevelopment of novel loss functions, the potential of data augmentation in this\ndomain remains largely underexplored. In this work, we uncover that the\nwidely-used Mixup data augmentation technique is ineffective when directly\napplied to CLL. Through in-depth analysis, we identify that the\ncomplementary-label noise generated by Mixup negatively impacts the performance\nof CLL models. We then propose an improved technique called Intra-Cluster Mixup\n(ICM), which only synthesizes augmented data from nearby examples, to mitigate\nthe noise effect. ICM carries the benefits of encouraging complementary label\nsharing of nearby examples, and leads to substantial performance improvements\nacross synthetic and real-world labeled datasets. In particular, our wide\nspectrum of experimental results on both balanced and imbalanced CLL settings\njustifies the potential of ICM in allying with state-of-the-art CLL algorithms,\nachieving significant accuracy increases of 30% and 10% on MNIST and CIFAR\ndatasets, respectively."}
{"id": "2509.17987", "pdf": "https://arxiv.org/pdf/2509.17987", "abs": "https://arxiv.org/abs/2509.17987", "authors": ["Sanju Xaviar", "Omid Ardakanian"], "title": "Budgeted Adversarial Attack against Graph-Based Anomaly Detection in Sensor Networks", "categories": ["cs.LG"], "comment": "12 pages", "summary": "Graph Neural Networks (GNNs) have emerged as powerful models for anomaly\ndetection in sensor networks, particularly when analyzing multivariate time\nseries. In this work, we introduce BETA, a novel grey-box evasion attack\ntargeting such GNN-based detectors, where the attacker is constrained to\nperturb sensor readings from a limited set of nodes, excluding the target\nsensor, with the goal of either suppressing a true anomaly or triggering a\nfalse alarm at the target node. BETA identifies the sensors most influential to\nthe target node's classification and injects carefully crafted adversarial\nperturbations into their features, all while maintaining stealth and respecting\nthe attacker's budget. Experiments on three real-world sensor network datasets\nshow that BETA reduces the detection accuracy of state-of-the-art GNN-based\ndetectors by 30.62 to 39.16% on average, and significantly outperforms baseline\nattack strategies, while operating within realistic constraints."}
{"id": "2509.17990", "pdf": "https://arxiv.org/pdf/2509.17990", "abs": "https://arxiv.org/abs/2509.17990", "authors": ["Yanbo Zhang", "Michael Levin"], "title": "Equilibrium flow: From Snapshots to Dynamics", "categories": ["cs.LG", "nlin.PS"], "comment": "17 pages, 8 figures", "summary": "Scientific data, from cellular snapshots in biology to celestial\ndistributions in cosmology, often consists of static patterns from underlying\ndynamical systems. These snapshots, while lacking temporal ordering, implicitly\nencode the processes that preserve them. This work investigates how strongly\nsuch a distribution constrains its underlying dynamics and how to recover them.\nWe introduce the Equilibrium flow method, a framework that learns continuous\ndynamics that preserve a given pattern distribution. Our method successfully\nidentifies plausible dynamics for 2-D systems and recovers the signature\nchaotic behavior of the Lorenz attractor. For high-dimensional Turing patterns\nfrom the Gray-Scott model, we develop an efficient, training-free variant that\nachieves high fidelity to the ground truth, validated both quantitatively and\nqualitatively. Our analysis reveals the solution space is constrained not only\nby the data but also by the learning model's inductive biases. This capability\nextends beyond recovering known systems, enabling a new paradigm of inverse\ndesign for Artificial Life. By specifying a target pattern distribution, we can\ndiscover the local interaction rules that preserve it, leading to the\nspontaneous emergence of complex behaviors, such as life-like flocking,\nattraction, and repulsion patterns, from simple, user-defined snapshots."}
{"id": "2509.17998", "pdf": "https://arxiv.org/pdf/2509.17998", "abs": "https://arxiv.org/abs/2509.17998", "authors": ["Richard Cornelius Suwandi", "Feng Yin", "Juntao Wang", "Renjie Li", "Tsung-Hui Chang", "Sergios Theodoridis"], "title": "Adaptive Kernel Design for Bayesian Optimization Is a Piece of CAKE with LLMs", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted as Poster at NeurIPS 2025", "summary": "The efficiency of Bayesian optimization (BO) relies heavily on the choice of\nthe Gaussian process (GP) kernel, which plays a central role in balancing\nexploration and exploitation under limited evaluation budgets. Traditional BO\nmethods often rely on fixed or heuristic kernel selection strategies, which can\nresult in slow convergence or suboptimal solutions when the chosen kernel is\npoorly suited to the underlying objective function. To address this limitation,\nwe propose a freshly-baked Context-Aware Kernel Evolution (CAKE) to enhance BO\nwith large language models (LLMs). Concretely, CAKE leverages LLMs as the\ncrossover and mutation operators to adaptively generate and refine GP kernels\nbased on the observed data throughout the optimization process. To maximize the\npower of CAKE, we further propose BIC-Acquisition Kernel Ranking (BAKER) to\nselect the most effective kernel through balancing the model fit measured by\nthe Bayesian information criterion (BIC) with the expected improvement at each\niteration of BO. Extensive experiments demonstrate that our fresh CAKE-based BO\nmethod consistently outperforms established baselines across a range of\nreal-world tasks, including hyperparameter optimization, controller tuning, and\nphotonic chip design. Our code is publicly available at\nhttps://github.com/cake4bo/cake."}
{"id": "2509.18001", "pdf": "https://arxiv.org/pdf/2509.18001", "abs": "https://arxiv.org/abs/2509.18001", "authors": ["Haocheng Luo", "Mehrtash Harandi", "Dinh Phung", "Trung Le"], "title": "Unveiling m-Sharpness Through the Structure of Stochastic Gradient Noise", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Sharpness-aware minimization (SAM) has emerged as a highly effective\ntechnique for improving model generalization, but its underlying principles are\nnot fully understood. We investigated the phenomenon known as m-sharpness,\nwhere the performance of SAM improves monotonically as the micro-batch size for\ncomputing perturbations decreases. Leveraging an extended Stochastic\nDifferential Equation (SDE) framework, combined with an analysis of the\nstructure of stochastic gradient noise (SGN), we precisely characterize the\ndynamics of various SAM variants. Our findings reveal that the stochastic noise\nintroduced during SAM perturbations inherently induces a variance-based\nsharpness regularization effect. Motivated by our theoretical insights, we\nintroduce Reweighted SAM, which employs sharpness-weighted sampling to mimic\nthe generalization benefits of m-SAM while remaining parallelizable.\nComprehensive experiments validate the effectiveness of our theoretical\nanalysis and proposed method."}
{"id": "2509.18034", "pdf": "https://arxiv.org/pdf/2509.18034", "abs": "https://arxiv.org/abs/2509.18034", "authors": ["Erkan Bayram", "Mohamed-Ali Belabbas", "Tamer Başar"], "title": "Control Disturbance Rejection in Neural ODEs", "categories": ["cs.LG", "math.OC"], "comment": "Accepted for publication in IEEE CDC 2025", "summary": "In this paper, we propose an iterative training algorithm for Neural ODEs\nthat provides models resilient to control (parameter) disturbances. The method\nbuilds on our earlier work Tuning without Forgetting-and similarly introduces\ntraining points sequentially, and updates the parameters on new data within the\nspace of parameters that do not decrease performance on the previously learned\ntraining points-with the key difference that, inspired by the concept of flat\nminima, we solve a minimax problem for a non-convex non-concave functional over\nan infinite-dimensional control space. We develop a projected gradient descent\nalgorithm on the space of parameters that admits the structure of an\ninfinite-dimensional Banach subspace. We show through simulations that this\nformulation enables the model to effectively learn new data points and gain\nrobustness against control disturbance."}
{"id": "2509.18057", "pdf": "https://arxiv.org/pdf/2509.18057", "abs": "https://arxiv.org/abs/2509.18057", "authors": ["Ansh Nagda", "Prabhakar Raghavan", "Abhradeep Thakurta"], "title": "Reinforced Generation of Combinatorial Structures: Applications to Complexity Theory", "categories": ["cs.LG", "cs.AI", "cs.CC", "math.CO"], "comment": null, "summary": "We explore whether techniques from AI can help discover new combinatorial\nstructures that improve provable limits on efficient algorithms. Specifically,\nwe use AlphaEvolve (an LLM coding agent) to study two settings:\n  a) Average-case hardness for MAX-CUT and MAX-Independent Set: We improve a\nrecent result of Kunisky and Yu to obtain near-optimal upper and (conditional)\nlower bounds on certification algorithms for MAX-CUT and MAX-Independent Set on\nrandom 3- and 4-regular graphs. Our improved lower bounds are obtained by\nconstructing nearly extremal Ramanujan graphs on as many as $163$ nodes, using\nAlphaEvolve. Additionally, via analytical arguments we strengthen the upper\nbounds to settle the computational hardness of these questions up to an error\nin the third decimal place.\n  b) Worst-case Hardness of Approximation for MAX-k-CUT: We obtain new\ninapproximability results, proving that it is NP-hard to approximate MAX-4-CUT\nand MAX-3-CUT within factors of $0.987$ and $0.9649$ respectively, using\nAlphaEvolve to discover new gadget reductions. Our MAX-4-CUT result improves\nupon the SOTA of $0.9883$, and our MAX-3-CUT result improves on the current\nbest gadget-based inapproximability result of $0.9853$, but falls short of\nimproving the SOTA of $16/17$ that relies on a custom PCP, rather than a gadget\nreduction from \"standard\" H{\\aa}stad-style PCPs.\n  A key technical challenge we faced: verifying a candidate construction\nproduced by AlphaEvolve is costly (often requiring exponential time). In both\nsettings above, our results were enabled by using AlphaEvolve itself to evolve\nthe verification procedure to be faster (sometimes by $10,000\\times$). We\nconclude with a discussion of norms by which to assess the assistance from AI\nin developing proofs."}
{"id": "2509.18058", "pdf": "https://arxiv.org/pdf/2509.18058", "abs": "https://arxiv.org/abs/2509.18058", "authors": ["Alexander Panfilov", "Evgenii Kortukov", "Kristina Nikolić", "Matthias Bethge", "Sebastian Lapuschkin", "Wojciech Samek", "Ameya Prabhu", "Maksym Andriushchenko", "Jonas Geiping"], "title": "Strategic Dishonesty Can Undermine AI Safety Evaluations of Frontier LLM", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Large language model (LLM) developers aim for their models to be honest,\nhelpful, and harmless. However, when faced with malicious requests, models are\ntrained to refuse, sacrificing helpfulness. We show that frontier LLMs can\ndevelop a preference for dishonesty as a new strategy, even when other options\nare available. Affected models respond to harmful requests with outputs that\nsound harmful but are subtly incorrect or otherwise harmless in practice. This\nbehavior emerges with hard-to-predict variations even within models from the\nsame model family. We find no apparent cause for the propensity to deceive, but\nwe show that more capable models are better at executing this strategy.\nStrategic dishonesty already has a practical impact on safety evaluations, as\nwe show that dishonest responses fool all output-based monitors used to detect\njailbreaks that we test, rendering benchmark scores unreliable. Further,\nstrategic dishonesty can act like a honeypot against malicious users, which\nnoticeably obfuscates prior jailbreak attacks. While output monitors fail, we\nshow that linear probes on internal activations can be used to reliably detect\nstrategic dishonesty. We validate probes on datasets with verifiable outcomes\nand by using their features as steering vectors. Overall, we consider strategic\ndishonesty as a concrete example of a broader concern that alignment of LLMs is\nhard to control, especially when helpfulness and harmlessness conflict."}
{"id": "2509.18067", "pdf": "https://arxiv.org/pdf/2509.18067", "abs": "https://arxiv.org/abs/2509.18067", "authors": ["Boyang Zhang", "Quanqi Hu", "Mingxuan Sun", "Qihang Lin", "Tianbao Yang"], "title": "Learning to Rank with Top-$K$ Fairness", "categories": ["cs.LG"], "comment": "Already accepted: https://openreview.net/forum?id=SSPCc39XvO\n  @article{ zhang2025learning, title={Learning to Rank with Top-\\$K\\$\n  Fairness}, author={Boyang Zhang and Quanqi Hu and Mingxuan Sun and Qihang Lin\n  and Tianbao Yang}, journal={Transactions on Machine Learning Research},\n  issn={2835-8856}, year={2025},\n  url={https://openreview.net/forum?id=SSPCc39XvO}, note={} }", "summary": "Fairness in ranking models is crucial, as disparities in exposure can\ndisproportionately affect protected groups. Most fairness-aware ranking systems\nfocus on ensuring comparable average exposure for groups across the entire\nranked list, which may not fully address real-world concerns. For example, when\na ranking model is used for allocating resources among candidates or disaster\nhotspots, decision-makers often prioritize only the top-$K$ ranked items, while\nthe ranking beyond top-$K$ becomes less relevant. In this paper, we propose a\nlist-wise learning-to-rank framework that addresses the issues of inequalities\nin top-$K$ rankings at training time. Specifically, we propose a top-$K$\nexposure disparity measure that extends the classic exposure disparity metric\nin a ranked list. We then learn a ranker to balance relevance and fairness in\ntop-$K$ rankings. Since direct top-$K$ selection is computationally expensive\nfor a large number of items, we transform the non-differentiable selection\nprocess into a differentiable objective function and develop efficient\nstochastic optimization algorithms to achieve both high accuracy and sufficient\nfairness. Extensive experiments demonstrate that our method outperforms\nexisting methods."}
{"id": "2509.18071", "pdf": "https://arxiv.org/pdf/2509.18071", "abs": "https://arxiv.org/abs/2509.18071", "authors": ["Lorenzo Rosasco"], "title": "Learning functions, operators and dynamical systems with kernels", "categories": ["cs.LG"], "comment": null, "summary": "This expository article presents the approach to statistical machine learning\nbased on reproducing kernel Hilbert spaces. The basic framework is introduced\nfor scalar-valued learning and then extended to operator learning. Finally,\nlearning dynamical systems is formulated as a suitable operator learning\nproblem, leveraging Koopman operator theory."}
{"id": "2509.18085", "pdf": "https://arxiv.org/pdf/2509.18085", "abs": "https://arxiv.org/abs/2509.18085", "authors": ["Sudhanshu Agrawal", "Risheek Garrepalli", "Raghavv Goel", "Mingu Lee", "Christopher Lott", "Fatih Porikli"], "title": "Spiffy: Multiplying Diffusion LLM Acceleration via Lossless Speculative Decoding", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Diffusion LLMs (dLLMs) have recently emerged as a powerful alternative to\nautoregressive LLMs (AR-LLMs) with the potential to operate at significantly\nhigher token generation rates. However, currently available open-source dLLMs\noften generate at much lower rates, typically decoding only a single token at\nevery denoising timestep in order to maximize output quality. We present\nSpiffy, a speculative decoding algorithm that accelerates dLLM inference by\n$\\mathbf{2.8{-}3.1\\times}$ while provably preserving the model's output\ndistribution. This work addresses the unique challenges involved in applying\nideas from speculative decoding of AR-LLMs to the dLLM setting. Spiffy proposes\ndraft states by leveraging the dLLM's distribution itself in an\nauto-speculative manner. This approach is efficient and effective, and\neliminates the overheads of training and running an independent draft model. To\nstructure the candidate draft states, we propose a novel directed draft graph\nwhich is uniquely designed to take advantage of the bidirectional, block-wise\nnature of dLLM generation and can be verified in parallel by the dLLM. To\nfurther optimize the structure of these draft graphs, we introduce an\nefficient, offline calibration algorithm that procedurally determines\nhigh-quality graph configurations. These optimized draft graphs, enabling\nincreased acceptance rates, lead to a significant boost in the overall speedup\nachieved by the system. Crucially, Spiffy is also complementary to other recent\ninnovations in improving dLLM generation speeds such as KV-caching and\nmulti-token unmasking. We demonstrate that when combined with such parallel\ndecoding algorithms, Spiffy is able to effectively multiply the benefits of\nthese methods leading to total speedups of up to $\\mathbf{7.9\\times}$."}
{"id": "2509.16206", "pdf": "https://arxiv.org/pdf/2509.16206", "abs": "https://arxiv.org/abs/2509.16206", "authors": ["Junlin Liu"], "title": "Deep Reinforcement Learning in Factor Investment", "categories": ["cs.CE", "cs.LG"], "comment": null, "summary": "Deep reinforcement learning has shown promise in trade execution, yet its use\nin low-frequency factor portfolio construction remains under-explored. A key\nobstacle is the high-dimensional, unbalanced state space created by stocks that\nenter and exit the investable universe. We introduce Conditional Auto-encoded\nFactor-based Portfolio Optimisation (CAFPO), which compresses stock-level\nreturns into a small set of latent factors conditioned on 94 firm-specific\ncharacteristics. The factors feed a DRL agent implemented with both PPO and\nDDPG to generate continuous long-short weights. On 20 years of U.S. equity data\n(2000--2020), CAFPO outperforms equal-weight, value-weight, Markowitz, vanilla\nDRL, and Fama--French-driven DRL, delivering a 24.6\\% compound return and a\nSharpe ratio of 0.94 out of sample. SHAP analysis further reveals economically\nintuitive factor attributions. Our results demonstrate that factor-aware\nrepresentation learning can make DRL practical for institutional, low-turnover\nportfolio management."}
{"id": "2509.16216", "pdf": "https://arxiv.org/pdf/2509.16216", "abs": "https://arxiv.org/abs/2509.16216", "authors": ["Bryl Nico M. Ong", "Aarush Borker", "Neil Jerome A. Egarguin", "Daniel Onofrei"], "title": "On the Detection of Internal Defects in Structured Media", "categories": ["cs.CE", "cs.LG"], "comment": null, "summary": "A critical issue that affects engineers trying to assess the structural\nintegrity of various infrastructures, such as metal rods or acoustic ducts, is\nthe challenge of detecting internal fractures (defects). Traditionally,\nengineers depend on audible and visual aids to identify these fractures, as\nthey do not physically dissect the object in question into multiple pieces to\ncheck for inconsistencies. This research introduces ideas towards the\ndevelopment of a robust strategy to image such defects using only a small set\nof minimal, non-invasive measurements.\n  Assuming a one dimensional model (e.g. longitudinal waves in long and thin\nrods/acoustic ducts or transverse vibrations of strings), we make use of the\ncontinuous one-dimensional wave equation to model these physical phenomena and\nthen employ specialized mathematical analysis tools (the Laplace transform and\noptimization) to introduce our defect imaging ideas. In particular, we will\nfocus on the case of a long bar which is homogeneous throughout except in a\nsmall area where a defect in its Young's modulus is present. We will first\ndemonstrate how the problem is equivalent to a spring-mass vibrational system,\nand then show how our imaging strategy makes use of the Laplace domain analytic\nmap between the characteristics of the respective defect and the measurement\ndata.\n  More explicitly, we will utilize MATLAB (a platform for numerical\ncomputations) to collect synthetic data (computational alternative to real\nworld measurements) for several scenarios with one defect of arbitrary location\nand stiffness. Subsequently, we will use this data along with our analytically\ndeveloped map (between defect characteristics and measurements) to construct a\nresidual function which, once optimized, will reveal the location and magnitude\nof the stiffness defect."}
{"id": "2509.16221", "pdf": "https://arxiv.org/pdf/2509.16221", "abs": "https://arxiv.org/abs/2509.16221", "authors": ["Martin Preiß"], "title": "Evaluation of Ensemble Learning Techniques for handwritten OCR Improvement", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "For the bachelor project 2021 of Professor Lippert's research group,\nhandwritten entries of historical patient records needed to be digitized using\nOptical Character Recognition (OCR) methods. Since the data will be used in the\nfuture, a high degree of accuracy is naturally required. Especially in the\nmedical field this has even more importance. Ensemble Learning is a method that\ncombines several machine learning models and is claimed to be able to achieve\nan increased accuracy for existing methods. For this reason, Ensemble Learning\nin combination with OCR is investigated in this work in order to create added\nvalue for the digitization of the patient records. It was possible to discover\nthat ensemble learning can lead to an increased accuracy for OCR, which methods\nwere able to achieve this and that the size of the training data set did not\nplay a role here."}
{"id": "2509.16224", "pdf": "https://arxiv.org/pdf/2509.16224", "abs": "https://arxiv.org/abs/2509.16224", "authors": ["K. F. B. Soppe", "A. Bagheri", "S. Nadi", "I. G. Klugkist", "T. Wubbels", "L. D. N. V. Wijngaards-De Meij"], "title": "Predicting First Year Dropout from Pre Enrolment Motivation Statements Using Text Mining", "categories": ["cs.CY", "cs.CL", "cs.LG", "stat.AP"], "comment": null, "summary": "Preventing student dropout is a major challenge in higher education and it is\ndifficult to predict prior to enrolment which students are likely to drop out\nand which students are likely to succeed. High School GPA is a strong predictor\nof dropout, but much variance in dropout remains to be explained. This study\nfocused on predicting university dropout by using text mining techniques with\nthe aim of exhuming information contained in motivation statements written by\nstudents. By combining text data with classic predictors of dropout in the form\nof student characteristics, we attempt to enhance the available set of\npredictive student characteristics. Our dataset consisted of 7,060 motivation\nstatements of students enrolling in a non-selective bachelor at a Dutch\nuniversity in 2014 and 2015. Support Vector Machines were trained on 75 percent\nof the data and several models were estimated on the test data. We used various\ncombinations of student characteristics and text, such as TFiDF, topic\nmodelling, LIWC dictionary. Results showed that, although the combination of\ntext and student characteristics did not improve the prediction of dropout,\ntext analysis alone predicted dropout similarly well as a set of student\ncharacteristics. Suggestions for future research are provided."}
{"id": "2509.16242", "pdf": "https://arxiv.org/pdf/2509.16242", "abs": "https://arxiv.org/abs/2509.16242", "authors": ["Karan Kendre"], "title": "Machine Learning for Quantum Noise Reduction", "categories": ["quant-ph", "cs.ET", "cs.LG"], "comment": "Code and data available at:\n  https://github.com/KaranKendre11/MLforQuantumNoiseReduction/", "summary": "Quantum noise fundamentally limits the utility of near-term quantum devices,\nmaking error mitigation essential for practical quantum computation. While\ntraditional quantum error correction codes require substantial qubit overhead\nand complex syndrome decoding, we propose a machine learning approach that\ndirectly reconstructs clean quantum states from noisy density matrices without\nadditional qubits. We formulate quantum noise reduction as a supervised\nlearning problem using a convolutional neural network (CNN) autoencoder\narchitecture with a novel fidelity-aware composite loss function. Our method is\ntrained and evaluated on a comprehensive synthetic dataset of 10,000 density\nmatrices derived from random 5-qubit quantum circuits, encompassing five noise\ntypes (depolarizing, amplitude damping, phase damping, bit-flip, and mixed\nnoise) across four intensity levels (0.05-0.20). The CNN successfully\nreconstructs quantum states across all noise conditions, achieving an average\nfidelity improvement from 0.298 to 0.774 ({\\Delta} = 0.476). Notably, the model\ndemonstrates superior performance on complex mixed noise scenarios and higher\nnoise intensities, with mixed noise showing the highest corrected fidelity\n(0.807) and improvement (0.567). The approach effectively preserves both\ndiagonal elements (populations) and off-diagonal elements (quantum coherences),\nmaking it suitable for entanglement-dependent quantum algorithms. While phase\ndamping presents fundamental information-theoretic limitations, our results\nsuggest that CNN-based density matrix reconstruction offers a promising,\nresource-efficient alternative to traditional quantum error correction for\nNISQ-era devices. This data-driven approach could enable practical quantum\nadvantage with fewer physical qubits than conventional error correction schemes\nrequire."}
{"id": "2509.16244", "pdf": "https://arxiv.org/pdf/2509.16244", "abs": "https://arxiv.org/abs/2509.16244", "authors": ["Emily Jimin Roh", "Hyojun Ahn", "Samuel Yen-Chi Chen", "Soohyun Park", "Joongheon Kim"], "title": "How Can Quantum Deep Learning Improve Large Language Models?", "categories": ["quant-ph", "cs.CL", "cs.LG"], "comment": null, "summary": "The rapid progress of large language models (LLMs) has transformed natural\nlanguage processing, yet the challenge of efficient adaptation remains\nunresolved. Full fine-tuning achieves strong performance but imposes\nprohibitive computational and memory costs. Parameter-efficient fine-tuning\n(PEFT) strategies, such as low-rank adaptation (LoRA), Prefix tuning, and\nsparse low-rank adaptation (SoRA), address this issue by reducing trainable\nparameters while maintaining competitive accuracy. However, these methods often\nencounter limitations in scalability, stability, and generalization across\ndiverse tasks. Recent advances in quantum deep learning introduce novel\nopportunities through quantum-inspired encoding and parameterized quantum\ncircuits (PQCs). In particular, the quantum-amplitude embedded adaptation (QAA)\nframework demonstrates expressive model updates with minimal overhead. This\npaper presents a systematic survey and comparative analysis of conventional\nPEFT methods and QAA. The analysis demonstrates trade-offs in convergence,\nefficiency, and representational capacity, while providing insight into the\npotential of quantum approaches for future LLM adaptation."}
{"id": "2509.16245", "pdf": "https://arxiv.org/pdf/2509.16245", "abs": "https://arxiv.org/abs/2509.16245", "authors": ["Yuki Harada", "Shuichi Maeda", "Junwei Shen", "Taku Misonou", "Hirokazu Hori", "Shinichiro Nakamura"], "title": "Motional representation; the ability to predict odor characters using molecular vibrations", "categories": ["physics.chem-ph", "cs.LG"], "comment": null, "summary": "The prediction of odor characters is still impossible based on the odorant\nmolecular structure. We designed a CNN-based regressor for computed parameters\nin molecular vibrations (CNN\\_vib), in order to investigate the ability to\npredict odor characters of molecular vibrations. In this study, we explored\nfollowing three approaches for the predictability; (i) CNN with molecular\nvibrational parameters, (ii) logistic regression based on vibrational spectra,\nand (iii) logistic regression with molecular fingerprint(FP). Our investigation\ndemonstrates that both (i) and (ii) provide predictablity, and also that the\nvibrations as an explanatory variable (i and ii) and logistic regression with\nfingerprints (iii) show nearly identical tendencies. The predictabilities of\n(i) and (ii), depending on odor descriptors, are comparable to those of (iii).\nOur research shows that odor is predictable by odorant molecular vibration as\nwell as their shapes alone. Our findings provide insight into the\nrepresentation of molecular motional features beyond molecular structures."}
{"id": "2509.16248", "pdf": "https://arxiv.org/pdf/2509.16248", "abs": "https://arxiv.org/abs/2509.16248", "authors": ["Savini Kashmira", "Jayanaka Dantanarayana", "Thamirawaran Sathiyalogeswaran", "Yichao Yuan", "Nishil Talati", "Krisztian Flautner", "Lingjia Tang", "Jason Mars"], "title": "GraphMend: Code Transformations for Fixing Graph Breaks in PyTorch 2", "categories": ["cs.PL", "cs.LG", "cs.SE"], "comment": null, "summary": "This paper presents GraphMend, a high-level compiler that eliminates FX graph\nbreaks in PyTorch 2 programs. Although PyTorch 2 introduced TorchDynamo and\nTorchInductor to enable just-in-time graph compilation, unresolved dynamic\ncontrol flow and unsupported Python constructs often fragment models into\nmultiple FX graphs. These fragments force frequent fallbacks to eager mode,\nincur costly CPU-to-GPU synchronizations, and reduce optimization\nopportunities. GraphMend addresses this limitation by analyzing and\ntransforming source code before execution. Built on the Jac compilation\nframework, GraphMend introduces two code transformations that remove graph\nbreaks due to dynamic control flow and Python I/O functions. This design allows\nPyTorch's compilation pipeline to capture larger, uninterrupted FX graphs\nwithout requiring manual refactoring by developers. Evaluation across eight\nHugging Face models shows that GraphMend removes all fixable graph breaks due\nto dynamic control flow and Python I/O functions, driving the break count to 0\nin 6 models and reducing it from 5 to 2 in another model. On NVIDIA RTX 3090\nand A40 GPUs, GraphMend achieves up to 75% latency reductions and up to 8%\nhigher end-to-end throughput. These results demonstrate that high-level code\ntransformation is an effective complement to PyTorch's dynamic JIT compilation\npipeline, substantially improving both usability and performance."}
{"id": "2509.16264", "pdf": "https://arxiv.org/pdf/2509.16264", "abs": "https://arxiv.org/abs/2509.16264", "authors": ["Wenjie Lin", "Hange Liu", "Xutao Mao", "Yingying Zhuang", "Jingwei Shi", "Xudong Han", "Tianyu Shi", "Jinrui Yang"], "title": "Gender and Political Bias in Large Language Models: A Demonstration Platform", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG"], "comment": "online demo: https://euro-parl-vote-demo.vercel.app/; Video:\n  https://www.youtube.com/@Jinrui-sf2jg", "summary": "We present ParlAI Vote, an interactive system for exploring European\nParliament debates and votes, and for testing LLMs on vote prediction and bias\nanalysis. This platform connects debate topics, speeches, and roll-call\noutcomes, and includes rich demographic data such as gender, age, country, and\npolitical group. Users can browse debates, inspect linked speeches, compare\nreal voting outcomes with predictions from frontier LLMs, and view error\nbreakdowns by demographic group. Visualizing the EuroParlVote benchmark and its\ncore tasks of gender classification and vote prediction, ParlAI Vote highlights\nsystematic performance bias in state-of-the-art LLMs. The system unifies data,\nmodels, and visual analytics in a single interface, lowering the barrier for\nreproducing findings, auditing behavior, and running counterfactual scenarios.\nIt supports research, education, and public engagement with legislative\ndecision-making, while making clear both the strengths and the limitations of\ncurrent LLMs in political analysis."}
{"id": "2509.16266", "pdf": "https://arxiv.org/pdf/2509.16266", "abs": "https://arxiv.org/abs/2509.16266", "authors": ["Julian Konrad", "Janina Mittelhaus", "David M. Wilkins", "Bodo Fiedler", "Robert Meißner"], "title": "Vibrational Fingerprints of Strained Polymers: A Spectroscopic Pathway to Mechanical State Prediction", "categories": ["physics.chem-ph", "cond-mat.mtrl-sci", "cs.LG"], "comment": null, "summary": "The vibrational response of polymer networks under load provides a sensitive\nprobe of molecular deformation and a route to non-destructive diagnostics. Here\nwe show that machine-learned force fields reproduce these spectroscopic\nfingerprints with quantum-level fidelity in realistic epoxy thermosets. Using\nMACE-OFF23 molecular dynamics, we capture the experimentally observed redshifts\nof para-phenylene stretching modes under tensile load, in contrast to the\nharmonic OPLS-AA model. These shifts correlate with molecular elongation and\nalignment, consistent with Badger's rule, directly linking vibrational features\nto local stress. To capture IR intensities, we trained a symmetry-adapted\ndipole moment model on representative epoxy fragments, enabling validation of\nstrain responses. Together, these approaches provide chemically accurate and\ncomputationally accessible predictions of strain-dependent vibrational spectra.\nOur results establish vibrational fingerprints as predictive markers of\nmechanical state in polymer networks, pointing to new strategies for stress\nmapping and structural-health diagnostics in advanced materials."}
{"id": "2509.16278", "pdf": "https://arxiv.org/pdf/2509.16278", "abs": "https://arxiv.org/abs/2509.16278", "authors": ["Alok N. Shah", "Khush Gupta", "Keshav Ramji", "Pratik Chaudhari"], "title": "Language Modeling with Learned Meta-Tokens", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "While modern Transformer-based language models (LMs) have achieved major\nsuccess in multi-task generalization, they often struggle to capture long-range\ndependencies within their context window. This work introduces a novel approach\nusing meta-tokens, special tokens injected during pre-training, along with a\ndedicated meta-attention mechanism to guide LMs to use these tokens. We\npre-train a language model with a modified GPT-2 architecture equipped with\nmeta-attention in addition to causal multi-head attention, and study the impact\nof these tokens on a suite of synthetic tasks. We find that data-efficient\nlanguage model pre-training on fewer than 100B tokens utilizing meta-tokens and\nour meta-attention mechanism achieves strong performance on these tasks after\nfine-tuning. We suggest that these gains arise due to the meta-tokens\nsharpening the positional encoding. This enables them to operate as trainable,\ncontent-based landmarks, implicitly compressing preceding context and \"caching\"\nit in the meta-token. At inference-time, the meta-token points to relevant\ncontext, facilitating length generalization up to 2$\\times$ its context window,\neven after extension with YaRN. We provide further evidence of these behaviors\nby visualizing model internals to study the residual stream, and assessing the\ncompression quality by information-theoretic analysis on the rate-distortion\ntradeoff. Our findings suggest that pre-training LMs with meta-tokens offers a\nsimple, data-efficient method to enhance long-context language modeling\nperformance, while introducing new insights into the nature of their behavior\ntowards length generalization."}
{"id": "2509.16291", "pdf": "https://arxiv.org/pdf/2509.16291", "abs": "https://arxiv.org/abs/2509.16291", "authors": ["Sanjay Basu", "Sadiq Y. Patel", "Parth Sheth", "Bhairavi Muralidharan", "Namrata Elamaran", "Aakriti Kinra", "Rajaie Batniji"], "title": "Test-Time Learning and Inference-Time Deliberation for Efficiency-First Offline Reinforcement Learning in Care Coordination and Population Health Management", "categories": ["cs.CY", "cs.LG"], "comment": null, "summary": "Care coordination and population health management programs serve large\nMedicaid and safety-net populations and must be auditable, efficient, and\nadaptable. While clinical risk for outreach modalities is typically low, time\nand opportunity costs differ substantially across text, phone, video, and\nin-person visits. We propose a lightweight offline reinforcement learning (RL)\napproach that augments trained policies with (i) test-time learning via local\nneighborhood calibration, and (ii) inference-time deliberation via a small\nQ-ensemble that incorporates predictive uncertainty and time/effort cost. The\nmethod exposes transparent dials for neighborhood size and uncertainty/cost\npenalties and preserves an auditable training pipeline. Evaluated on a\nde-identified operational dataset, TTL+ITD achieves stable value estimates with\npredictable efficiency trade-offs and subgroup auditing."}
{"id": "2509.16301", "pdf": "https://arxiv.org/pdf/2509.16301", "abs": "https://arxiv.org/abs/2509.16301", "authors": ["Tiantian Yang", "Zhiqian Chen"], "title": "TF-DWGNet: A Directed Weighted Graph Neural Network with Tensor Fusion for Multi-Omics Cancer Subtype Classification", "categories": ["q-bio.QM", "cs.LG", "62R07"], "comment": "9 pages, 4 figures, 4 tables", "summary": "Integration and analysis of multi-omics data provide valuable insights for\ncancer subtype classification. However, such data are inherently heterogeneous,\nhigh-dimensional, and exhibit complex intra- and inter-modality dependencies.\nRecent advances in graph neural networks (GNNs) offer powerful tools for\nmodeling such structure. Yet, most existing methods rely on prior knowledge or\npredefined similarity networks to construct graphs, which are often undirected\nor unweighted, failing to capture the directionality and strength of biological\ninteractions. Interpretability at both the modality and feature levels also\nremains limited. To address these challenges, we propose TF-DWGNet, a novel\nGraph Neural Network framework that combines tree-based Directed Weighted graph\nconstruction with Tensor Fusion for multiclass cancer subtype classification.\nTF-DWGNet introduces two key innovations: a supervised tree-based approach for\nconstructing directed, weighted graphs tailored to each omics modality, and a\ntensor fusion mechanism that captures unimodal, bimodal, and trimodal\ninteractions using low-rank decomposition for efficiency. TF-DWGNet enables\nmodality-specific representation learning, joint embedding fusion, and\ninterpretable subtype prediction. Experiments on real-world cancer datasets\nshow that TF-DWGNet consistently outperforms state-of-the-art baselines across\nmultiple metrics and statistical tests. Moreover, it provides biologically\nmeaningful insights by ranking influential features and modalities. These\nresults highlight TF-DWGNet's potential for effective and interpretable\nmulti-omics integration in cancer research."}
{"id": "2509.16336", "pdf": "https://arxiv.org/pdf/2509.16336", "abs": "https://arxiv.org/abs/2509.16336", "authors": ["Jan Philipp Schneider", "Pratik Singh Bisht", "Ilya Chugunov", "Andreas Kolb", "Michael Moeller", "Felix Heide"], "title": "Neural Atlas Graphs for Dynamic Scene Decomposition and Editing", "categories": ["cs.GR", "cs.CV", "cs.LG"], "comment": null, "summary": "Learning editable high-resolution scene representations for dynamic scenes is\nan open problem with applications across the domains from autonomous driving to\ncreative editing - the most successful approaches today make a trade-off\nbetween editability and supporting scene complexity: neural atlases represent\ndynamic scenes as two deforming image layers, foreground and background, which\nare editable in 2D, but break down when multiple objects occlude and interact.\nIn contrast, scene graph models make use of annotated data such as masks and\nbounding boxes from autonomous-driving datasets to capture complex 3D spatial\nrelationships, but their implicit volumetric node representations are\nchallenging to edit view-consistently. We propose Neural Atlas Graphs (NAGs), a\nhybrid high-resolution scene representation, where every graph node is a\nview-dependent neural atlas, facilitating both 2D appearance editing and 3D\nordering and positioning of scene elements. Fit at test-time, NAGs achieve\nstate-of-the-art quantitative results on the Waymo Open Dataset - by 5 dB PSNR\nincrease compared to existing methods - and make environmental editing possible\nin high resolution and visual quality - creating counterfactual driving\nscenarios with new backgrounds and edited vehicle appearance. We find that the\nmethod also generalizes beyond driving scenes and compares favorably - by more\nthan 7 dB in PSNR - to recent matting and video editing baselines on the DAVIS\nvideo dataset with a diverse set of human and animal-centric scenes."}
{"id": "2509.16342", "pdf": "https://arxiv.org/pdf/2509.16342", "abs": "https://arxiv.org/abs/2509.16342", "authors": ["Sean Turland", "Eloi Moliner", "Vesa Välimäki"], "title": "Similarity-Guided Diffusion for Long-Gap Music Inpainting", "categories": ["eess.AS", "cs.LG", "cs.SD"], "comment": "5 pages, 2 figures. Submitted to IEEE ICASSP 2026. Audio examples and\n  supplementary material are available at: https://s-turland.github.io/SimDPS/", "summary": "Music inpainting aims to reconstruct missing segments of a corrupted\nrecording. While diffusion-based generative models improve reconstruction for\nmedium-length gaps, they often struggle to preserve musical plausibility over\nmulti-second gaps. We introduce Similarity-Guided Diffusion Posterior Sampling\n(SimDPS), a hybrid method that combines diffusion-based inference with\nsimilarity search. Candidate segments are first retrieved from a corpus based\non contextual similarity, then incorporated into a modified likelihood that\nguides the diffusion process toward contextually consistent reconstructions.\nSubjective evaluation on piano music inpainting with 2-s gaps shows that the\nproposed SimDPS method enhances perceptual plausibility compared to unguided\ndiffusion and frequently outperforms similarity search alone when moderately\nsimilar candidates are available. These results demonstrate the potential of a\nhybrid similarity approach for diffusion-based audio enhancement with long\ngaps."}
{"id": "2509.16382", "pdf": "https://arxiv.org/pdf/2509.16382", "abs": "https://arxiv.org/abs/2509.16382", "authors": ["Saurabh Saini", "Kapil Ahuja", "Marc C. Steinbach", "Thomas Wick"], "title": "Accurate Thyroid Cancer Classification using a Novel Binary Pattern Driven Local Discrete Cosine Transform Descriptor", "categories": ["cs.CV", "cs.LG", "eess.IV", "I.2.1; I.5.2"], "comment": "15 Pages, 7 Figures, 5 Tables", "summary": "In this study, we develop a new CAD system for accurate thyroid cancer\nclassification with emphasis on feature extraction. Prior studies have shown\nthat thyroid texture is important for segregating the thyroid ultrasound images\ninto different classes. Based upon our experience with breast cancer\nclassification, we first conjuncture that the Discrete Cosine Transform (DCT)\nis the best descriptor for capturing textural features. Thyroid ultrasound\nimages are particularly challenging as the gland is surrounded by multiple\ncomplex anatomical structures leading to variations in tissue density. Hence,\nwe second conjuncture the importance of localization and propose that the Local\nDCT (LDCT) descriptor captures the textural features best in this context.\nAnother disadvantage of complex anatomy around the thyroid gland is scattering\nof ultrasound waves resulting in noisy and unclear textures. Hence, we third\nconjuncture that one image descriptor is not enough to fully capture the\ntextural features and propose the integration of another popular texture\ncapturing descriptor (Improved Local Binary Pattern, ILBP) with LDCT. ILBP is\nknown to be noise resilient as well. We term our novel descriptor as Binary\nPattern Driven Local Discrete Cosine Transform (BPD-LDCT). Final classification\nis carried out using a non-linear SVM. The proposed CAD system is evaluated on\nthe only two publicly available thyroid cancer datasets, namely TDID and AUITD.\nThe evaluation is conducted in two stages. In Stage I, thyroid nodules are\ncategorized as benign or malignant. In Stage II, the malignant cases are\nfurther sub-classified into TI-RADS (4) and TI-RADS (5). For Stage I\nclassification, our proposed model demonstrates exceptional performance of\nnearly 100% on TDID and 97% on AUITD. In Stage II classification, the proposed\nmodel again attains excellent classification of close to 100% on TDID and 99%\non AUITD."}
{"id": "2509.16395", "pdf": "https://arxiv.org/pdf/2509.16395", "abs": "https://arxiv.org/abs/2509.16395", "authors": ["Jiahao Zhang", "Shiheng Zhang", "Guang Lin"], "title": "Low-Rank Adaptation of Evolutionary Deep Neural Networks for Efficient Learning of Time-Dependent PDEs", "categories": ["stat.ML", "cs.LG"], "comment": "17 pages", "summary": "We study the Evolutionary Deep Neural Network (EDNN) framework for\naccelerating numerical solvers of time-dependent partial differential equations\n(PDEs). We introduce a Low-Rank Evolutionary Deep Neural Network (LR-EDNN),\nwhich constrains parameter evolution to a low-rank subspace, thereby reducing\nthe effective dimensionality of training while preserving solution accuracy.\nThe low-rank tangent subspace is defined layer-wise by the singular value\ndecomposition (SVD) of the current network weights, and the resulting update is\nobtained by solving a well-posed, tractable linear system within this subspace.\nThis design augments the underlying numerical solver with a parameter efficient\nEDNN component without requiring full fine-tuning of all network weights. We\nevaluate LR-EDNN on representative PDE problems and compare it against\ncorresponding baselines. Across cases, LR-EDNN achieves comparable accuracy\nwith substantially fewer trainable parameters and reduced computational cost.\nThese results indicate that low-rank constraints on parameter velocities,\nrather than full-space updates, provide a practical path toward scalable,\nefficient, and reproducible scientific machine learning for PDEs."}
{"id": "2509.16398", "pdf": "https://arxiv.org/pdf/2509.16398", "abs": "https://arxiv.org/abs/2509.16398", "authors": ["Francesco Argenziano", "Miguel Saavedra-Ruiz", "Sacha Morin", "Daniele Nardi", "Liam Paull"], "title": "Dynamic Objects Relocalization in Changing Environments with Flow Matching", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Task and motion planning are long-standing challenges in robotics, especially\nwhen robots have to deal with dynamic environments exhibiting long-term\ndynamics, such as households or warehouses. In these environments, long-term\ndynamics mostly stem from human activities, since previously detected objects\ncan be moved or removed from the scene. This adds the necessity to find such\nobjects again before completing the designed task, increasing the risk of\nfailure due to missed relocalizations. However, in these settings, the nature\nof such human-object interactions is often overlooked, despite being governed\nby common habits and repetitive patterns. Our conjecture is that these cues can\nbe exploited to recover the most likely objects' positions in the scene,\nhelping to address the problem of unknown relocalization in changing\nenvironments. To this end we propose FlowMaps, a model based on Flow Matching\nthat is able to infer multimodal object locations over space and time. Our\nresults present statistical evidence to support our hypotheses, opening the way\nto more complex applications of our approach. The code is publically available\nat https://github.com/Fra-Tsuna/flowmaps"}
{"id": "2509.16411", "pdf": "https://arxiv.org/pdf/2509.16411", "abs": "https://arxiv.org/abs/2509.16411", "authors": ["Chong You", "Rajesh Jayaram", "Ananda Theertha Suresh", "Robin Nittka", "Felix Yu", "Sanjiv Kumar"], "title": "Hierarchical Retrieval: The Geometry and a Pretrain-Finetune Recipe", "categories": ["cs.IR", "cs.CL", "cs.LG", "stat.ML"], "comment": "NeurIPS 2025", "summary": "Dual encoder (DE) models, where a pair of matching query and document are\nembedded into similar vector representations, are widely used in information\nretrieval due to their simplicity and scalability. However, the Euclidean\ngeometry of the embedding space limits the expressive power of DEs, which may\ncompromise their quality. This paper investigates such limitations in the\ncontext of hierarchical retrieval (HR), where the document set has a\nhierarchical structure and the matching documents for a query are all of its\nancestors. We first prove that DEs are feasible for HR as long as the embedding\ndimension is linear in the depth of the hierarchy and logarithmic in the number\nof documents. Then we study the problem of learning such embeddings in a\nstandard retrieval setup where DEs are trained on samples of matching query and\ndocument pairs. Our experiments reveal a lost-in-the-long-distance phenomenon,\nwhere retrieval accuracy degrades for documents further away in the hierarchy.\nTo address this, we introduce a pretrain-finetune recipe that significantly\nimproves long-distance retrieval without sacrificing performance on closer\ndocuments. We experiment on a realistic hierarchy from WordNet for retrieving\ndocuments at various levels of abstraction, and show that pretrain-finetune\nboosts the recall on long-distance pairs from 19% to 76%. Finally, we\ndemonstrate that our method improves retrieval of relevant products on a\nshopping queries dataset."}
{"id": "2509.16434", "pdf": "https://arxiv.org/pdf/2509.16434", "abs": "https://arxiv.org/abs/2509.16434", "authors": ["Ritvik Singh", "Karl Van Wyk", "Pieter Abbeel", "Jitendra Malik", "Nathan Ratliff", "Ankur Handa"], "title": "End-to-end RL Improves Dexterous Grasping Policies", "categories": ["cs.RO", "cs.LG"], "comment": "See our blog post: https://e2e4robotics.com/", "summary": "This work explores techniques to scale up image-based end-to-end learning for\ndexterous grasping with an arm + hand system. Unlike state-based RL,\nvision-based RL is much more memory inefficient, resulting in relatively low\nbatch sizes, which is not amenable for algorithms like PPO. Nevertheless, it is\nstill an attractive method as unlike the more commonly used techniques which\ndistill state-based policies into vision networks, end-to-end RL can allow for\nemergent active vision behaviors. We identify a key bottleneck in training\nthese policies is the way most existing simulators scale to multiple GPUs using\ntraditional data parallelism techniques. We propose a new method where we\ndisaggregate the simulator and RL (both training and experience buffers) onto\nseparate GPUs. On a node with four GPUs, we have the simulator running on three\nof them, and PPO running on the fourth. We are able to show that with the same\nnumber of GPUs, we can double the number of existing environments compared to\nthe previous baseline of standard data parallelism. This allows us to train\nvision-based environments, end-to-end with depth, which were previously\nperforming far worse with the baseline. We train and distill both depth and\nstate-based policies into stereo RGB networks and show that depth distillation\nleads to better results, both in simulation and reality. This improvement is\nlikely due to the observability gap between state and vision policies which\ndoes not exist when distilling depth policies into stereo RGB. We further show\nthat the increased batch size brought about by disaggregated simulation also\nimproves real world performance. When deploying in the real world, we improve\nupon the previous state-of-the-art vision-based results using our end-to-end\npolicies."}
{"id": "2509.16451", "pdf": "https://arxiv.org/pdf/2509.16451", "abs": "https://arxiv.org/abs/2509.16451", "authors": ["Karl Zhu", "Dimitris Bertsimas"], "title": "Overfitting in Adaptive Robust Optimization", "categories": ["math.OC", "cs.LG", "stat.ML"], "comment": "4 pages, 1 figure, NeuroIPS 2025 ML x OR workshop submission", "summary": "Adaptive robust optimization (ARO) extends static robust optimization by\nallowing decisions to depend on the realized uncertainty - weakly dominating\nstatic solutions within the modeled uncertainty set. However, ARO makes\nprevious constraints that were independent of uncertainty now dependent, making\nit vulnerable to additional infeasibilities when realizations fall outside the\nuncertainty set. This phenomenon of adaptive policies being brittle is\nanalogous to overfitting in machine learning. To mitigate against this, we\npropose assigning constraint-specific uncertainty set sizes, with harder\nconstraints given stronger probabilistic guarantees. Interpreted through the\noverfitting lens, this acts as regularization: tighter guarantees shrink\nadaptive coefficients to ensure stability, while looser ones preserve useful\nflexibility. This view motivates a principled approach to designing uncertainty\nsets that balances robustness and adaptivity."}
{"id": "2509.16462", "pdf": "https://arxiv.org/pdf/2509.16462", "abs": "https://arxiv.org/abs/2509.16462", "authors": ["'Mina Arzaghi'", "'Alireza Dehghanpour Farashah'", "'Florian Carichon'", "' Golnoosh Farnadi'"], "title": "Intrinsic Meets Extrinsic Fairness: Assessing the Downstream Impact of Bias Mitigation in Large Language Models", "categories": ["cs.CL", "cs.CY", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) exhibit socio-economic biases that can propagate\ninto downstream tasks. While prior studies have questioned whether intrinsic\nbias in LLMs affects fairness at the downstream task level, this work\nempirically investigates the connection. We present a unified evaluation\nframework to compare intrinsic bias mitigation via concept unlearning with\nextrinsic bias mitigation via counterfactual data augmentation (CDA). We\nexamine this relationship through real-world financial classification tasks,\nincluding salary prediction, employment status, and creditworthiness\nassessment. Using three open-source LLMs, we evaluate models both as frozen\nembedding extractors and as fine-tuned classifiers. Our results show that\nintrinsic bias mitigation through unlearning reduces intrinsic gender bias by\nup to 94.9%, while also improving downstream task fairness metrics, such as\ndemographic parity by up to 82%, without compromising accuracy. Our framework\noffers practical guidance on where mitigation efforts can be most effective and\nhighlights the importance of applying early-stage mitigation before downstream\ndeployment."}
{"id": "2509.16496", "pdf": "https://arxiv.org/pdf/2509.16496", "abs": "https://arxiv.org/abs/2509.16496", "authors": ["Seyyedali Hosseinalipour", "Shimiao Li", "Adedoyin Inaolaji", "Filippo Malandra", "Luis Herrera", "Nicholas Mastronarde"], "title": "Synergies between Federated Foundation Models and Smart Power Grids", "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.SY"], "comment": null, "summary": "The recent emergence of large language models (LLMs) such as GPT-3 has marked\na significant paradigm shift in machine learning. Trained on massive corpora of\ndata, these models demonstrate remarkable capabilities in language\nunderstanding, generation, summarization, and reasoning, transforming how\nintelligent systems process and interact with human language. Although LLMs may\nstill seem like a recent breakthrough, the field is already witnessing the rise\nof a new and more general category: multi-modal, multi-task foundation models\n(M3T FMs). These models go beyond language and can process heterogeneous data\ntypes/modalities, such as time-series measurements, audio, imagery, tabular\nrecords, and unstructured logs, while supporting a broad range of downstream\ntasks spanning forecasting, classification, control, and retrieval. When\ncombined with federated learning (FL), they give rise to M3T Federated\nFoundation Models (FedFMs): a highly recent and largely unexplored class of\nmodels that enable scalable, privacy-preserving model training/fine-tuning\nacross distributed data sources. In this paper, we take one of the first steps\ntoward introducing these models to the power systems research community by\noffering a bidirectional perspective: (i) M3T FedFMs for smart grids and (ii)\nsmart grids for FedFMs. In the former, we explore how M3T FedFMs can enhance\nkey grid functions, such as load/demand forecasting and fault detection, by\nlearning from distributed, heterogeneous data available at the grid edge in a\nprivacy-preserving manner. In the latter, we investigate how the constraints\nand structure of smart grids, spanning energy, communication, and regulatory\ndimensions, shape the design, training, and deployment of M3T FedFMs."}
{"id": "2509.16505", "pdf": "https://arxiv.org/pdf/2509.16505", "abs": "https://arxiv.org/abs/2509.16505", "authors": ["Dev Gurung", "Shiva Raj Pokhrel"], "title": "orb-QFL: Orbital Quantum Federated Learning", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "Recent breakthroughs in quantum computing present transformative\nopportunities for advancing Federated Learning (FL), particularly in\nnon-terrestrial environments characterized by stringent communication and\ncoordination constraints. In this study, we propose orbital QFL, termed\norb-QFL, a novel quantum-assisted Federated Learning framework tailored for Low\nEarth Orbit (LEO) satellite constellations. Distinct from conventional FL\nparadigms, termed orb-QFL operates without centralized servers or global\naggregation mechanisms (e.g., FedAvg), instead leveraging quantum entanglement\nand local quantum processing to facilitate decentralized, inter-satellite\ncollaboration. This design inherently addresses the challenges of orbital\ndynamics, such as intermittent connectivity, high propagation delays, and\ncoverage variability. The framework enables continuous model refinement through\ndirect quantum-based synchronization between neighboring satellites, thereby\nenhancing resilience and preserving data locality. To validate our approach, we\nintegrate the Qiskit quantum machine learning toolkit with Poliastro-based\norbital simulations and conduct experiments using Statlog dataset."}
{"id": "2509.16506", "pdf": "https://arxiv.org/pdf/2509.16506", "abs": "https://arxiv.org/abs/2509.16506", "authors": ["Joe Barrow"], "title": "CommonForms: A Large, Diverse Dataset for Form Field Detection", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "This paper introduces CommonForms, a web-scale dataset for form field\ndetection. It casts the problem of form field detection as object detection:\ngiven an image of a page, predict the location and type (Text Input, Choice\nButton, Signature) of form fields. The dataset is constructed by filtering\nCommon Crawl to find PDFs that have fillable elements. Starting with 8 million\ndocuments, the filtering process is used to arrive at a final dataset of\nroughly 55k documents that have over 450k pages. Analysis shows that the\ndataset contains a diverse mixture of languages and domains; one third of the\npages are non-English, and among the 14 classified domains, no domain makes up\nmore than 25% of the dataset.\n  In addition, this paper presents a family of form field detectors,\nFFDNet-Small and FFDNet-Large, which attain a very high average precision on\nthe CommonForms test set. Each model cost less than $500 to train. Ablation\nresults show that high-resolution inputs are crucial for high-quality form\nfield detection, and that the cleaning process improves data efficiency over\nusing all PDFs that have fillable fields in Common Crawl. A qualitative\nanalysis shows that they outperform a popular, commercially available PDF\nreader that can prepare forms. Unlike the most popular commercially available\nsolutions, FFDNet can predict checkboxes in addition to text and signature\nfields. This is, to our knowledge, the first large scale dataset released for\nform field detection, as well as the first open source models. The dataset,\nmodels, and code will be released at https://github.com/jbarrow/commonforms"}
{"id": "2509.16522", "pdf": "https://arxiv.org/pdf/2509.16522", "abs": "https://arxiv.org/abs/2509.16522", "authors": ["Tse-Yang Chen", "Yuh-Jzer Joung"], "title": "Etude: Piano Cover Generation with a Three-Stage Approach - Extract, strucTUralize, and DEcode", "categories": ["cs.SD", "cs.LG", "eess.AS"], "comment": null, "summary": "Piano cover generation aims to automatically transform a pop song into a\npiano arrangement. While numerous deep learning approaches have been proposed,\nexisting models often fail to maintain structural consistency with the original\nsong, likely due to the absence of beat-aware mechanisms or the difficulty of\nmodeling complex rhythmic patterns. Rhythmic information is crucial, as it\ndefines structural similarity (e.g., tempo, BPM) and directly impacts the\noverall quality of the generated music.\n  In this paper, we introduce Etude, a three-stage architecture consisting of\nExtract, strucTUralize, and DEcode stages. By pre-extracting rhythmic\ninformation and applying a novel, simplified REMI-based tokenization, our model\nproduces covers that preserve proper song structure, enhance fluency and\nmusical dynamics, and support highly controllable generation through style\ninjection. Subjective evaluations with human listeners show that Etude\nsubstantially outperforms prior models, achieving a quality level comparable to\nthat of human composers."}
{"id": "2509.16525", "pdf": "https://arxiv.org/pdf/2509.16525", "abs": "https://arxiv.org/abs/2509.16525", "authors": ["Anna Mazhar", "Sainyam Galhotra"], "title": "Causal Fuzzing for Verifying Machine Unlearning", "categories": ["cs.SE", "cs.AI", "cs.LG"], "comment": null, "summary": "As machine learning models become increasingly embedded in decision-making\nsystems, the ability to \"unlearn\" targeted data or features is crucial for\nenhancing model adaptability, fairness, and privacy in models which involves\nexpensive training. To effectively guide machine unlearning, a thorough testing\nis essential. Existing methods for verification of machine unlearning provide\nlimited insights, often failing in scenarios where the influence is indirect.\nIn this work, we propose CAF\\'E, a new causality based framework that unifies\ndatapoint- and feature-level unlearning for verification of black-box ML\nmodels. CAF\\'E evaluates both direct and indirect effects of unlearning targets\nthrough causal dependencies, providing actionable insights with fine-grained\nanalysis. Our evaluation across five datasets and three model architectures\ndemonstrates that CAF\\'E successfully detects residual influence missed by\nbaselines while maintaining computational efficiency."}
{"id": "2509.16542", "pdf": "https://arxiv.org/pdf/2509.16542", "abs": "https://arxiv.org/abs/2509.16542", "authors": ["Khalid Hasan", "Jamil Saquer", "Yifan Zhang"], "title": "Mental Multi-class Classification on Social Media: Benchmarking Transformer Architectures against LSTM Models", "categories": ["cs.CL", "cs.IR", "cs.LG"], "comment": "24th IEEE International Conference on Machine Learning and\n  Applications, ICMLA 2025 (camera-ready)", "summary": "Millions of people openly share mental health struggles on social media,\nproviding rich data for early detection of conditions such as depression,\nbipolar disorder, etc. However, most prior Natural Language Processing (NLP)\nresearch has focused on single-disorder identification, leaving a gap in\nunderstanding the efficacy of advanced NLP techniques for distinguishing among\nmultiple mental health conditions. In this work, we present a large-scale\ncomparative study of state-of-the-art transformer versus Long Short-Term Memory\n(LSTM)-based models to classify mental health posts into exclusive categories\nof mental health conditions. We first curate a large dataset of Reddit posts\nspanning six mental health conditions and a control group, using rigorous\nfiltering and statistical exploratory analysis to ensure annotation quality. We\nthen evaluate five transformer architectures (BERT, RoBERTa, DistilBERT,\nALBERT, and ELECTRA) against several LSTM variants (with or without attention,\nusing contextual or static embeddings) under identical conditions. Experimental\nresults show that transformer models consistently outperform the alternatives,\nwith RoBERTa achieving 91-99% F1-scores and accuracies across all classes.\nNotably, attention-augmented LSTMs with BERT embeddings approach transformer\nperformance (up to 97% F1-score) while training 2-3.5 times faster, whereas\nLSTMs using static embeddings fail to learn useful signals. These findings\nrepresent the first comprehensive benchmark for multi-class mental health\ndetection, offering practical guidance on model selection and highlighting an\naccuracy-efficiency trade-off for real-world deployment of mental health NLP\nsystems."}
{"id": "2509.16547", "pdf": "https://arxiv.org/pdf/2509.16547", "abs": "https://arxiv.org/abs/2509.16547", "authors": ["Adrian Wurm"], "title": "Checking extracted rules in Neural Networks", "categories": ["cs.AI", "cs.LG"], "comment": "7 pages, one figure", "summary": "In this paper we investigate formal verification of extracted rules for\nNeural Networks under a complexity theoretic point of view. A rule is a global\nproperty or a pattern concerning a large portion of the input space of a\nnetwork. These rules are algorithmically extracted from networks in an effort\nto better understand their inner way of working. Here, three problems will be\nin the focus: Does a given set of rules apply to a given network? Is a given\nset of rules consistent or do the rules contradict themselves? Is a given set\nof rules exhaustive in the sense that for every input the output is determined?\nFinding algorithms that extract such rules out of networks has been\ninvestigated over the last 30 years, however, to the author's current\nknowledge, no attempt in verification was made until now. A lot of attempts of\nextracting rules use heuristics involving randomness and over-approximation, so\nit might be beneficial to know whether knowledge obtained in that way can\nactually be trusted.\n  We investigate the above questions for neural networks with ReLU-activation\nas well as for Boolean networks, each for several types of rules. We\ndemonstrate how these problems can be reduced to each other and show that most\nof them are co-NP-complete."}
{"id": "2509.16557", "pdf": "https://arxiv.org/pdf/2509.16557", "abs": "https://arxiv.org/abs/2509.16557", "authors": ["Muhammad Hamza", "Danish Hamid", "Muhammad Tahir Akram"], "title": "Person Identification from Egocentric Human-Object Interactions using 3D Hand Pose", "categories": ["cs.CV", "cs.ET", "cs.HC", "cs.LG"], "comment": "21 pages, 8 figures, 7 tables. Preprint of a manuscript submitted to\n  CCF Transactions on Pervasive Computing and Interaction (Springer), currently\n  under review", "summary": "Human-Object Interaction Recognition (HOIR) and user identification play a\ncrucial role in advancing augmented reality (AR)-based personalized assistive\ntechnologies. These systems are increasingly being deployed in high-stakes,\nhuman-centric environments such as aircraft cockpits, aerospace maintenance,\nand surgical procedures. This research introduces I2S (Interact2Sign), a multi\nstage framework designed for unobtrusive user identification through human\nobject interaction recognition, leveraging 3D hand pose analysis in egocentric\nvideos. I2S utilizes handcrafted features extracted from 3D hand poses and per\nforms sequential feature augmentation: first identifying the object class,\nfollowed by HOI recognition, and ultimately, user identification. A\ncomprehensive feature extraction and description process was carried out for 3D\nhand poses, organizing the extracted features into semantically meaningful\ncategories: Spatial, Frequency, Kinematic, Orientation, and a novel descriptor\nintroduced in this work, the Inter-Hand Spatial Envelope (IHSE). Extensive\nablation studies were conducted to determine the most effective combination of\nfeatures. The optimal configuration achieved an impressive average F1-score of\n97.52% for user identification, evaluated on a bimanual object manipulation\ndataset derived from the ARCTIC and H2O datasets. I2S demonstrates\nstate-of-the-art performance while maintaining a lightweight model size of\nunder 4 MB and a fast inference time of 0.1 seconds. These characteristics make\nthe proposed framework highly suitable for real-time, on-device authentication\nin security-critical, AR-based systems."}
{"id": "2509.16566", "pdf": "https://arxiv.org/pdf/2509.16566", "abs": "https://arxiv.org/abs/2509.16566", "authors": ["Omar Eldeeb", "Martin Malandro"], "title": "Barwise Section Boundary Detection in Symbolic Music Using Convolutional Neural Networks", "categories": ["cs.SD", "cs.LG", "eess.AS"], "comment": null, "summary": "Current methods for Music Structure Analysis (MSA) focus primarily on audio\ndata. While symbolic music can be synthesized into audio and analyzed using\nexisting MSA techniques, such an approach does not exploit symbolic music's\nrich explicit representation of pitch, timing, and instrumentation. A key\nsubproblem of MSA is section boundary detection-determining whether a given\npoint in time marks the transition between musical sections. In this paper, we\nstudy automatic section boundary detection for symbolic music. First, we\nintroduce a human-annotated MIDI dataset for section boundary detection,\nconsisting of metadata from 6134 MIDI files that we manually curated from the\nLakh MIDI dataset. Second, we train a deep learning model to classify the\npresence of section boundaries within a fixed-length musical window. Our data\nrepresentation involves a novel encoding scheme based on synthesized overtones\nto encode arbitrary MIDI instrumentations into 3-channel piano rolls. Our model\nachieves an F1 score of 0.77, improving over the analogous audio-based\nsupervised learning approach and the unsupervised block-matching segmentation\n(CBM) audio approach by 0.22 and 0.31, respectively. We release our dataset,\ncode, and models."}
{"id": "2509.16582", "pdf": "https://arxiv.org/pdf/2509.16582", "abs": "https://arxiv.org/abs/2509.16582", "authors": ["Antonio Scardace", "Lemuel Puglisi", "Francesco Guarnera", "Sebastiano Battiato", "Daniele Ravì"], "title": "A Novel Metric for Detecting Memorization in Generative Models for Brain MRI Synthesis", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Deep generative models have emerged as a transformative tool in medical\nimaging, offering substantial potential for synthetic data generation. However,\nrecent empirical studies highlight a critical vulnerability: these models can\nmemorize sensitive training data, posing significant risks of unauthorized\npatient information disclosure. Detecting memorization in generative models\nremains particularly challenging, necessitating scalable methods capable of\nidentifying training data leakage across large sets of generated samples. In\nthis work, we propose DeepSSIM, a novel self-supervised metric for quantifying\nmemorization in generative models. DeepSSIM is trained to: i) project images\ninto a learned embedding space and ii) force the cosine similarity between\nembeddings to match the ground-truth SSIM (Structural Similarity Index) scores\ncomputed in the image space. To capture domain-specific anatomical features,\ntraining incorporates structure-preserving augmentations, allowing DeepSSIM to\nestimate similarity reliably without requiring precise spatial alignment. We\nevaluate DeepSSIM in a case study involving synthetic brain MRI data generated\nby a Latent Diffusion Model (LDM) trained under memorization-prone conditions,\nusing 2,195 MRI scans from two publicly available datasets (IXI and CoRR).\nCompared to state-of-the-art memorization metrics, DeepSSIM achieves superior\nperformance, improving F1 scores by an average of +52.03% over the best\nexisting method. Code and data of our approach are publicly available at the\nfollowing link: https://github.com/brAIn-science/DeepSSIM."}
{"id": "2509.16606", "pdf": "https://arxiv.org/pdf/2509.16606", "abs": "https://arxiv.org/abs/2509.16606", "authors": ["Wei Duan", "Jie Lu", "Junyu Xuan"], "title": "Bayesian Ego-graph inference for Networked Multi-Agent Reinforcement Learning", "categories": ["cs.MA", "cs.LG"], "comment": "Accepted at NeurIPS 2025", "summary": "In networked multi-agent reinforcement learning (Networked-MARL),\ndecentralized agents must act under local observability and constrained\ncommunication over fixed physical graphs. Existing methods often assume static\nneighborhoods, limiting adaptability to dynamic or heterogeneous environments.\nWhile centralized frameworks can learn dynamic graphs, their reliance on global\nstate access and centralized infrastructure is impractical in real-world\ndecentralized systems. We propose a stochastic graph-based policy for\nNetworked-MARL, where each agent conditions its decision on a sampled subgraph\nover its local physical neighborhood. Building on this formulation, we\nintroduce BayesG, a decentralized actor-framework that learns sparse,\ncontext-aware interaction structures via Bayesian variational inference. Each\nagent operates over an ego-graph and samples a latent communication mask to\nguide message passing and policy computation. The variational distribution is\ntrained end-to-end alongside the policy using an evidence lower bound (ELBO)\nobjective, enabling agents to jointly learn both interaction topology and\ndecision-making strategies. BayesG outperforms strong MARL baselines on\nlarge-scale traffic control tasks with up to 167 agents, demonstrating superior\nscalability, efficiency, and performance."}
{"id": "2509.16614", "pdf": "https://arxiv.org/pdf/2509.16614", "abs": "https://arxiv.org/abs/2509.16614", "authors": ["Bojan Derajić", "Sebastian Bernhard", "Wolfgang Hönig"], "title": "ORN-CBF: Learning Observation-conditioned Residual Neural Control Barrier Functions via Hypernetworks", "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "Control barrier functions (CBFs) have been demonstrated as an effective\nmethod for safety-critical control of autonomous systems. Although CBFs are\nsimple to deploy, their design remains challenging, motivating the development\nof learning-based approaches. Yet, issues such as suboptimal safe sets,\napplicability in partially observable environments, and lack of rigorous safety\nguarantees persist. In this work, we propose observation-conditioned neural\nCBFs based on Hamilton-Jacobi (HJ) reachability analysis, which approximately\nrecover the maximal safe sets. We exploit certain mathematical properties of\nthe HJ value function, ensuring that the predicted safe set never intersects\nwith the observed failure set. Moreover, we leverage a hypernetwork-based\narchitecture that is particularly suitable for the design of\nobservation-conditioned safety filters. The proposed method is examined both in\nsimulation and hardware experiments for a ground robot and a quadcopter. The\nresults show improved success rates and generalization to out-of-domain\nenvironments compared to the baselines."}
{"id": "2509.16627", "pdf": "https://arxiv.org/pdf/2509.16627", "abs": "https://arxiv.org/abs/2509.16627", "authors": ["Anh Tuan Bui"], "title": "Conditional Multidimensional Scaling with Incomplete Conditioning Data", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Conditional multidimensional scaling seeks for a low-dimensional\nconfiguration from pairwise dissimilarities, in the presence of other known\nfeatures. By taking advantage of available data of the known features,\nconditional multidimensional scaling improves the estimation quality of the\nlow-dimensional configuration and simplifies knowledge discovery tasks.\nHowever, existing conditional multidimensional scaling methods require full\ndata of the known features, which may not be always attainable due to time,\ncost, and other constraints. This paper proposes a conditional multidimensional\nscaling method that can learn the low-dimensional configuration when there are\nmissing values in the known features. The method can also impute the missing\nvalues, which provides additional insights of the problem. Computer codes of\nthis method are maintained in the cml R package on CRAN."}
{"id": "2509.16648", "pdf": "https://arxiv.org/pdf/2509.16648", "abs": "https://arxiv.org/abs/2509.16648", "authors": ["Debarpan Bhattacharya", "Apoorva Kulkarni", "Sriram Ganapathy"], "title": "FESTA: Functionally Equivalent Sampling for Trust Assessment of Multimodal LLMs", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "Accepted in the Findings of EMNLP, 2025", "summary": "The accurate trust assessment of multimodal large language models (MLLMs)\ngenerated predictions, which can enable selective prediction and improve user\nconfidence, is challenging due to the diverse multi-modal input paradigms. We\npropose Functionally Equivalent Sampling for Trust Assessment (FESTA), a\nmultimodal input sampling technique for MLLMs, that generates an uncertainty\nmeasure based on the equivalent and complementary input samplings. The proposed\ntask-preserving sampling approach for uncertainty quantification expands the\ninput space to probe the consistency (through equivalent samples) and\nsensitivity (through complementary samples) of the model. FESTA uses only\ninput-output access of the model (black-box), and does not require ground truth\n(unsupervised). The experiments are conducted with various off-the-shelf\nmulti-modal LLMs, on both visual and audio reasoning tasks. The proposed FESTA\nuncertainty estimate achieves significant improvement (33.3% relative\nimprovement for vision-LLMs and 29.6% relative improvement for audio-LLMs) in\nselective prediction performance, based on\narea-under-receiver-operating-characteristic curve (AUROC) metric in detecting\nmispredictions. The code implementation is open-sourced."}
{"id": "2509.16650", "pdf": "https://arxiv.org/pdf/2509.16650", "abs": "https://arxiv.org/abs/2509.16650", "authors": ["Manish Prajapat", "Johannes Köhler", "Melanie N. Zeilinger", "Andreas Krause"], "title": "Safe Guaranteed Dynamics Exploration with Probabilistic Models", "categories": ["eess.SY", "cs.LG", "cs.RO", "cs.SY", "math.DS", "math.OC"], "comment": null, "summary": "Ensuring both optimality and safety is critical for the real-world deployment\nof agents, but becomes particularly challenging when the system dynamics are\nunknown. To address this problem, we introduce a notion of maximum safe\ndynamics learning via sufficient exploration in the space of safe policies. We\npropose a $\\textit{pessimistically}$ safe framework that\n$\\textit{optimistically}$ explores informative states and, despite not reaching\nthem due to model uncertainty, ensures continuous online learning of dynamics.\nThe framework achieves first-of-its-kind results: learning the dynamics model\nsufficiently $-$ up to an arbitrary small tolerance (subject to noise) $-$ in a\nfinite time, while ensuring provably safe operation throughout with high\nprobability and without requiring resets. Building on this, we propose an\nalgorithm to maximize rewards while learning the dynamics $\\textit{only to the\nextent needed}$ to achieve close-to-optimal performance. Unlike typical\nreinforcement learning (RL) methods, our approach operates online in a\nnon-episodic setting and ensures safety throughout the learning process. We\ndemonstrate the effectiveness of our approach in challenging domains such as\nautonomous car racing and drone navigation under aerodynamic effects $-$\nscenarios where safety is critical and accurate modeling is difficult."}
{"id": "2509.16662", "pdf": "https://arxiv.org/pdf/2509.16662", "abs": "https://arxiv.org/abs/2509.16662", "authors": ["Eunjin Choi", "Hyerin Kim", "Jiwoo Ryu", "Juhan Nam", "Dasaem Jeong"], "title": "On the de-duplication of the Lakh MIDI dataset", "categories": ["cs.SD", "cs.AI", "cs.LG", "cs.MM", "eess.AS"], "comment": "The paper has been accepted for publication at ISMIR 2025", "summary": "A large-scale dataset is essential for training a well-generalized\ndeep-learning model. Most such datasets are collected via scraping from various\ninternet sources, inevitably introducing duplicated data. In the symbolic music\ndomain, these duplicates often come from multiple user arrangements and\nmetadata changes after simple editing. However, despite critical issues such as\nunreliable training evaluation from data leakage during random splitting,\ndataset duplication has not been extensively addressed in the MIR community.\nThis study investigates the dataset duplication issues regarding Lakh MIDI\nDataset (LMD), one of the largest publicly available sources in the symbolic\nmusic domain. To find and evaluate the best retrieval method for duplicated\ndata, we employed the Clean MIDI subset of the LMD as a benchmark test set, in\nwhich different versions of the same songs are grouped together. We first\nevaluated rule-based approaches and previous symbolic music retrieval models\nfor de-duplication and also investigated with a contrastive learning-based BERT\nmodel with various augmentations to find duplicate files. As a result, we\npropose three different versions of the filtered list of LMD, which filters out\nat least 38,134 samples in the most conservative settings among 178,561 files."}
{"id": "2509.16663", "pdf": "https://arxiv.org/pdf/2509.16663", "abs": "https://arxiv.org/abs/2509.16663", "authors": ["Xiaoping Du"], "title": "System-Level Uncertainty Quantification with Multiple Machine Learning Models: A Theoretical Framework", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "ML models have errors when used for predictions. The errors are unknown but\ncan be quantified by model uncertainty. When multiple ML models are trained\nusing the same training points, their model uncertainties may be statistically\ndependent. In reality, model inputs are also random with input uncertainty. The\neffects of these types of uncertainty must be considered in decision-making and\ndesign. This study develops a theoretical framework that generates the joint\ndistribution of multiple ML predictions given the joint distribution of model\nuncertainties and the joint distribution of model inputs. The strategy is to\ndecouple the coupling between the two types of uncertainty and transform them\nas independent random variables. The framework lays a foundation for numerical\nalgorithm development for various specific applications."}
{"id": "2509.16677", "pdf": "https://arxiv.org/pdf/2509.16677", "abs": "https://arxiv.org/abs/2509.16677", "authors": ["Wenxin Li", "Kunyu Peng", "Di Wen", "Ruiping Liu", "Mengfei Duan", "Kai Luo", "Kailun Yang"], "title": "Segment-to-Act: Label-Noise-Robust Action-Prompted Video Segmentation Towards Embodied Intelligence", "categories": ["cs.CV", "cs.LG", "cs.RO", "eess.IV"], "comment": "The established benchmark and source code will be made publicly\n  available at https://github.com/mylwx/ActiSeg-NL", "summary": "Embodied intelligence relies on accurately segmenting objects actively\ninvolved in interactions. Action-based video object segmentation addresses this\nby linking segmentation with action semantics, but it depends on large-scale\nannotations and prompts that are costly, inconsistent, and prone to multimodal\nnoise such as imprecise masks and referential ambiguity. To date, this\nchallenge remains unexplored. In this work, we take the first step by studying\naction-based video object segmentation under label noise, focusing on two\nsources: textual prompt noise (category flips and within-category noun\nsubstitutions) and mask annotation noise (perturbed object boundaries to mimic\nimprecise supervision). Our contributions are threefold. First, we introduce\ntwo types of label noises for the action-based video object segmentation task.\nSecond, we build up the first action-based video object segmentation under a\nlabel noise benchmark ActiSeg-NL and adapt six label-noise learning strategies\nto this setting, and establish protocols for evaluating them under textual,\nboundary, and mixed noise. Third, we provide a comprehensive analysis linking\nnoise types to failure modes and robustness gains, and we introduce a Parallel\nMask Head Mechanism (PMHM) to address mask annotation noise. Qualitative\nevaluations further reveal characteristic failure modes, including boundary\nleakage and mislocalization under boundary perturbations, as well as occasional\nidentity substitutions under textual flips. Our comparative analysis reveals\nthat different learning strategies exhibit distinct robustness profiles,\ngoverned by a foreground-background trade-off where some achieve balanced\nperformance while others prioritize foreground accuracy at the cost of\nbackground precision. The established benchmark and source code will be made\npublicly available at https://github.com/mylwx/ActiSeg-NL."}
{"id": "2509.16680", "pdf": "https://arxiv.org/pdf/2509.16680", "abs": "https://arxiv.org/abs/2509.16680", "authors": ["Xingjian Diao", "Weiyi Wu", "Keyi Kong", "Peijun Qing", "Xinwen Xu", "Ming Cheng", "Soroush Vosoughi", "Jiang Gui"], "title": "ProtoVQA: An Adaptable Prototypical Framework for Explainable Fine-Grained Visual Question Answering", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted to EMNLP 2025 Main Conference", "summary": "Visual Question Answering (VQA) is increasingly used in diverse applications\nranging from general visual reasoning to safety-critical domains such as\nmedical imaging and autonomous systems, where models must provide not only\naccurate answers but also explanations that humans can easily understand and\nverify. Prototype-based modeling has shown promise for interpretability by\ngrounding predictions in semantically meaningful regions for purely visual\nreasoning tasks, yet remains underexplored in the context of VQA. We present\nProtoVQA, a unified prototypical framework that (i) learns question-aware\nprototypes that serve as reasoning anchors, connecting answers to\ndiscriminative image regions, (ii) applies spatially constrained matching to\nensure that the selected evidence is coherent and semantically relevant, and\n(iii) supports both answering and grounding tasks through a shared prototype\nbackbone. To assess explanation quality, we propose the Visual-Linguistic\nAlignment Score (VLAS), which measures how well the model's attended regions\nalign with ground-truth evidence. Experiments on Visual7W show that ProtoVQA\nyields faithful, fine-grained explanations while maintaining competitive\naccuracy, advancing the development of transparent and trustworthy VQA systems."}
{"id": "2509.16685", "pdf": "https://arxiv.org/pdf/2509.16685", "abs": "https://arxiv.org/abs/2509.16685", "authors": ["Binbin Wen", "Yihang Wu", "Tareef Daqqaq", "Ahmad Chaddad"], "title": "Towards a Transparent and Interpretable AI Model for Medical Image Classifications", "categories": ["cs.CV", "cs.LG"], "comment": "Published in Cognitive Neurodynamics", "summary": "The integration of artificial intelligence (AI) into medicine is remarkable,\noffering advanced diagnostic and therapeutic possibilities. However, the\ninherent opacity of complex AI models presents significant challenges to their\nclinical practicality. This paper focuses primarily on investigating the\napplication of explainable artificial intelligence (XAI) methods, with the aim\nof making AI decisions transparent and interpretable. Our research focuses on\nimplementing simulations using various medical datasets to elucidate the\ninternal workings of the XAI model. These dataset-driven simulations\ndemonstrate how XAI effectively interprets AI predictions, thus improving the\ndecision-making process for healthcare professionals. In addition to a survey\nof the main XAI methods and simulations, ongoing challenges in the XAI field\nare discussed. The study highlights the need for the continuous development and\nexploration of XAI, particularly from the perspective of diverse medical\ndatasets, to promote its adoption and effectiveness in the healthcare domain."}
{"id": "2509.16696", "pdf": "https://arxiv.org/pdf/2509.16696", "abs": "https://arxiv.org/abs/2509.16696", "authors": ["Wataru Hashimoto", "Hidetaka Kamigaito", "Taro Watanabe"], "title": "Decoding Uncertainty: The Impact of Decoding Strategies for Uncertainty Estimation in Large Language Models", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted at EMNLP 2025 Findings", "summary": "Decoding strategies manipulate the probability distribution underlying the\noutput of a language model and can therefore affect both generation quality and\nits uncertainty. In this study, we investigate the impact of decoding\nstrategies on uncertainty estimation in Large Language Models (LLMs). Our\nexperiments show that Contrastive Search, which mitigates repetition, yields\nbetter uncertainty estimates on average across a range of preference-aligned\nLLMs. In contrast, the benefits of these strategies sometimes diverge when the\nmodel is only post-trained with supervised fine-tuning, i.e. without explicit\nalignment."}
{"id": "2509.16699", "pdf": "https://arxiv.org/pdf/2509.16699", "abs": "https://arxiv.org/abs/2509.16699", "authors": ["Kai Yu", "Binbin Cai", "Song Lin"], "title": "Knowledge Distillation for Variational Quantum Convolutional Neural Networks on Heterogeneous Data", "categories": ["quant-ph", "cs.LG"], "comment": null, "summary": "Distributed quantum machine learning faces significant challenges due to\nheterogeneous client data and variations in local model structures, which\nhinder global model aggregation. To address these challenges, we propose a\nknowledge distillation framework for variational quantum convolutional neural\nnetworks on heterogeneous data. The framework features a quantum gate number\nestimation mechanism based on client data, which guides the construction of\nresource-adaptive VQCNN circuits. Particle swarm optimization is employed to\nefficiently generate personalized quantum models tailored to local data\ncharacteristics. During aggregation, a knowledge distillation strategy\nintegrating both soft-label and hard-label supervision consolidates knowledge\nfrom heterogeneous clients using a public dataset, forming a global model while\navoiding parameter exposure and privacy leakage. Theoretical analysis shows\nthat proposed framework benefits from quantum high-dimensional representation,\noffering advantages over classical approaches, and minimizes communication by\nexchanging only model indices and test outputs. Extensive simulations on the\nPennyLane platform validate the effectiveness of the gate number estimation and\ndistillation-based aggregation. Experimental results demonstrate that the\naggregated global model achieves accuracy close to fully supervised centralized\ntraining. These results shown that proposed methods can effectively handle\nheterogeneity, reduce resource consumption, and maintain performance,\nhighlighting its potential for scalable and privacy-preserving distributed\nquantum learning."}
{"id": "2509.16707", "pdf": "https://arxiv.org/pdf/2509.16707", "abs": "https://arxiv.org/abs/2509.16707", "authors": ["Sid Ghatak", "Arman Khaledian", "Navid Parvini", "Nariman Khaledian"], "title": "Increase Alpha: Performance and Risk of an AI-Driven Trading Framework", "categories": ["q-fin.PM", "cs.LG"], "comment": "To get access to the data, please contact s.ghatak@increasealpha.com", "summary": "There are inefficiencies in financial markets, with unexploited patterns in\nprice, volume, and cross-sectional relationships. While many approaches use\nlarge-scale transformers, we take a domain-focused path: feed-forward and\nrecurrent networks with curated features to capture subtle regularities in\nnoisy financial data. This smaller-footprint design is computationally lean and\nreliable under low signal-to-noise, crucial for daily production at scale. At\nIncrease Alpha, we built a deep-learning framework that maps over 800 U.S.\nequities into daily directional signals with minimal computational overhead.\n  The purpose of this paper is twofold. First, we outline the general overview\nof the predictive model without disclosing its core underlying concepts.\nSecond, we evaluate its real-time performance through transparent, industry\nstandard metrics. Forecast accuracy is benchmarked against both naive baselines\nand macro indicators. The performance outcomes are summarized via cumulative\nreturns, annualized Sharpe ratio, and maximum drawdown. The best portfolio\ncombination using our signals provides a low-risk, continuous stream of returns\nwith a Sharpe ratio of more than 2.5, maximum drawdown of around 3\\%, and a\nnear-zero correlation with the S\\&P 500 market benchmark. We also compare the\nmodel's performance through different market regimes, such as the recent\nvolatile movements of the US equity market in the beginning of 2025. Our\nanalysis showcases the robustness of the model and significantly stable\nperformance during these volatile periods.\n  Collectively, these findings show that market inefficiencies can be\nsystematically harvested with modest computational overhead if the right\nvariables are considered. This report will emphasize the potential of\ntraditional deep learning frameworks for generating an AI-driven edge in the\nfinancial market."}
{"id": "2509.16715", "pdf": "https://arxiv.org/pdf/2509.16715", "abs": "https://arxiv.org/abs/2509.16715", "authors": ["Adrien Llave", "Emma Granier", "Grégory Pallone"], "title": "QASTAnet: A DNN-based Quality Metric for Spatial Audio", "categories": ["eess.AS", "cs.LG"], "comment": null, "summary": "In the development of spatial audio technologies, reliable and shared methods\nfor evaluating audio quality are essential. Listening tests are currently the\nstandard but remain costly in terms of time and resources. Several models\npredicting subjective scores have been proposed, but they do not generalize\nwell to real-world signals. In this paper, we propose QASTAnet (Quality\nAssessment for SpaTial Audio network), a new metric based on a deep neural\nnetwork, specialized on spatial audio (ambisonics and binaural). As training\ndata is scarce, we aim for the model to be trainable with a small amount of\ndata. To do so, we propose to rely on expert modeling of the low-level auditory\nsystem and use a neurnal network to model the high-level cognitive function of\nthe quality judgement. We compare its performance to two reference metrics on a\nwide range of content types (speech, music, ambiance, anechoic, reverberated)\nand focusing on codec artifacts. Results demonstrate that QASTAnet overcomes\nthe aforementioned limitations of the existing methods. The strong correlation\nbetween the proposed metric prediction and subjective scores makes it a good\ncandidate for comparing codecs in their development."}
{"id": "2509.16727", "pdf": "https://arxiv.org/pdf/2509.16727", "abs": "https://arxiv.org/abs/2509.16727", "authors": ["Xin Lei Lin", "Soroush Mehraban", "Abhishek Moturu", "Babak Taati"], "title": "Pain in 3D: Generating Controllable Synthetic Faces for Automated Pain Assessment", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Automated pain assessment from facial expressions is crucial for\nnon-communicative patients, such as those with dementia. Progress has been\nlimited by two challenges: (i) existing datasets exhibit severe demographic and\nlabel imbalance due to ethical constraints, and (ii) current generative models\ncannot precisely control facial action units (AUs), facial structure, or\nclinically validated pain levels.\n  We present 3DPain, a large-scale synthetic dataset specifically designed for\nautomated pain assessment, featuring unprecedented annotation richness and\ndemographic diversity. Our three-stage framework generates diverse 3D meshes,\ntextures them with diffusion models, and applies AU-driven face rigging to\nsynthesize multi-view faces with paired neutral and pain images, AU\nconfigurations, PSPI scores, and the first dataset-level annotations of\npain-region heatmaps. The dataset comprises 82,500 samples across 25,000 pain\nexpression heatmaps and 2,500 synthetic identities balanced by age, gender, and\nethnicity.\n  We further introduce ViTPain, a Vision Transformer based cross-modal\ndistillation framework in which a heatmap-trained teacher guides a student\ntrained on RGB images, enhancing accuracy, interpretability, and clinical\nreliability. Together, 3DPain and ViTPain establish a controllable, diverse,\nand clinically grounded foundation for generalizable automated pain assessment."}
{"id": "2509.16729", "pdf": "https://arxiv.org/pdf/2509.16729", "abs": "https://arxiv.org/abs/2509.16729", "authors": ["Evgeniia Tokarchuk", "Sergey Troshin", "Vlad Niculae"], "title": "Angular Dispersion Accelerates $k$-Nearest Neighbors Machine Translation", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Augmenting neural machine translation with external memory at decoding time,\nin the form of k-nearest neighbors machine translation ($k$-NN MT), is a\nwell-established strategy for increasing translation performance. $k$-NN MT\nretrieves a set of tokens that occurred in the most similar contexts recorded\nin a prepared data store, using hidden state representations of translation\ncontexts as vector lookup keys. One of the main disadvantages of this method is\nthe high computational cost and memory requirements. Since an exhaustive search\nis not feasible in large data stores, practitioners commonly use approximate\n$k$-NN MT lookup, yet even such algorithms are a bottleneck. In contrast to\nresearch directions seeking to accelerate $k$-NN MT by reducing data store size\nor the number of lookup calls, we pursue an orthogonal direction based on the\nperformance properties of approximate $k$-NN MT lookup data structures. In\nparticular, we propose to encourage angular dispersion of the neural hidden\nrepresentations of contexts. We show that improving dispersion leads to better\nbalance in the retrieval data structures, accelerating retrieval and slightly\nimproving translations."}
{"id": "2509.16738", "pdf": "https://arxiv.org/pdf/2509.16738", "abs": "https://arxiv.org/abs/2509.16738", "authors": ["Kai Jiang", "Zhengyan Shi", "Dell Zhang", "Hongyuan Zhang", "Xuelong Li"], "title": "Min: Mixture of Noise for Pre-Trained Model-Based Class-Incremental Learning", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted by NeurIPS 2025. Source Code will be released in the next\n  version", "summary": "Class Incremental Learning (CIL) aims to continuously learn new categories\nwhile retaining the knowledge of old ones. Pre-trained models (PTMs) show\npromising capabilities in CIL. However, existing approaches that apply\nlightweight fine-tuning to backbones still induce parameter drift, thereby\ncompromising the generalization capability of pre-trained models. Parameter\ndrift can be conceptualized as a form of noise that obscures critical patterns\nlearned for previous tasks. However, recent researches have shown that noise is\nnot always harmful. For example, the large number of visual patterns learned\nfrom pre-training can be easily abused by a single task, and introducing\nappropriate noise can suppress some low-correlation features, thus leaving a\nmargin for future tasks. To this end, we propose learning beneficial noise for\nCIL guided by information theory and propose Mixture of Noise (Min), aiming to\nmitigate the degradation of backbone generalization from adapting new tasks.\nSpecifically, task-specific noise is learned from high-dimension features of\nnew tasks. Then, a set of weights is adjusted dynamically for optimal mixture\nof different task noise. Finally, Min embeds the beneficial noise into the\nintermediate features to mask the response of inefficient patterns. Extensive\nexperiments on six benchmark datasets demonstrate that Min achieves\nstate-of-the-art performance in most incremental settings, with particularly\noutstanding results in 50-steps incremental settings. This shows the\nsignificant potential for beneficial noise in continual learning."}
{"id": "2509.16746", "pdf": "https://arxiv.org/pdf/2509.16746", "abs": "https://arxiv.org/abs/2509.16746", "authors": ["Sayak Mukherjee", "Ramij R. Hossain", "Mahantesh Halappanavar"], "title": "On the System Theoretic Offline Learning of Continuous-Time LQR with Exogenous Disturbances", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": "17 pages, 3 figures", "summary": "We analyze offline designs of linear quadratic regulator (LQR) strategies\nwith uncertain disturbances. First, we consider the scenario where the\nexogenous variable can be estimated in a controlled environment, and\nsubsequently, consider a more practical and challenging scenario where it is\nunknown in a stochastic setting. Our approach builds on the fundamental\nlearning-based framework of adaptive dynamic programming (ADP), combined with a\nLyapunov-based analytical methodology to design the algorithms and derive\nsample-based approximations motivated from the Markov decision process\n(MDP)-based approaches. For the scenario involving non-measurable disturbances,\nwe further establish stability and convergence guarantees for the learned\ncontrol gains under sample-based approximations. The overall methodology\nemphasizes simplicity while providing rigorous guarantees. Finally, numerical\nexperiments focus on the intricacies and validations for the design of offline\ncontinuous-time LQR with exogenous disturbances."}
{"id": "2509.16779", "pdf": "https://arxiv.org/pdf/2509.16779", "abs": "https://arxiv.org/abs/2509.16779", "authors": ["Jason Wu", "Amanda Swearngin", "Arun Krishna Vajjala", "Alan Leung", "Jeffrey Nichols", "Titus Barik"], "title": "Improving User Interface Generation Models from Designer Feedback", "categories": ["cs.HC", "cs.LG"], "comment": null, "summary": "Despite being trained on vast amounts of data, most LLMs are unable to\nreliably generate well-designed UIs. Designer feedback is essential to\nimproving performance on UI generation; however, we find that existing RLHF\nmethods based on ratings or rankings are not well-aligned with designers'\nworkflows and ignore the rich rationale used to critique and improve UI\ndesigns. In this paper, we investigate several approaches for designers to give\nfeedback to UI generation models, using familiar interactions such as\ncommenting, sketching and direct manipulation. We first perform a study with 21\ndesigners where they gave feedback using these interactions, which resulted in\n~1500 design annotations. We then use this data to finetune a series of LLMs to\ngenerate higher quality UIs. Finally, we evaluate these models with human\njudges, and we find that our designer-aligned approaches outperform models\ntrained with traditional ranking feedback and all tested baselines, including\nGPT-5."}
{"id": "2509.16783", "pdf": "https://arxiv.org/pdf/2509.16783", "abs": "https://arxiv.org/abs/2509.16783", "authors": ["Vladislav Trifonov", "Ivan Oseledets", "Ekaterina Muravleva"], "title": "Spectral Analysis of the Weighted Frobenius Objective", "categories": ["math.NA", "cs.LG", "cs.NA"], "comment": null, "summary": "We analyze a weighted Frobenius loss for approximating symmetric positive\ndefinite matrices in the context of preconditioning iterative solvers. Unlike\nthe standard Frobenius norm, the weighted loss penalizes error components\nassociated with small eigenvalues of the system matrix more strongly. Our\nanalysis reveals that each eigenmode is scaled by the corresponding square of\nits eigenvalue, and that, under a fixed error budget, the loss is minimized\nonly when the error is confined to the direction of the largest eigenvalue.\nThis provides a rigorous explanation of why minimizing the weighted loss\nnaturally suppresses low-frequency components, which can be a desirable\nstrategy for the conjugate gradient method. The analysis is independent of the\nspecific approximation scheme or sparsity pattern, and applies equally to\nincomplete factorizations, algebraic updates, and learning-based constructions.\nNumerical experiments confirm the predictions of the theory, including an\nillustration where sparse factors are trained by a direct gradient updates to\nIC(0) factor entries, i.e., no trained neural network model is used."}
{"id": "2509.16788", "pdf": "https://arxiv.org/pdf/2509.16788", "abs": "https://arxiv.org/abs/2509.16788", "authors": ["Salha Alyami", "Amani Jamal", "Areej Alhothali"], "title": "Domain-Adaptive Pre-Training for Arabic Aspect-Based Sentiment Analysis: A Comparative Study of Domain Adaptation and Fine-Tuning Strategies", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "26 excluding bibliography , journal article", "summary": "Aspect-based sentiment analysis (ABSA) in natural language processing enables\norganizations to understand customer opinions on specific product aspects.\nWhile deep learning models are widely used for English ABSA, their application\nin Arabic is limited due to the scarcity of labeled data. Researchers have\nattempted to tackle this issue by using pre-trained contextualized language\nmodels such as BERT. However, these models are often based on fact-based data,\nwhich can introduce bias in domain-specific tasks like ABSA. To our knowledge,\nno studies have applied adaptive pre-training with Arabic contextualized models\nfor ABSA. This research proposes a novel approach using domain-adaptive\npre-training for aspect-sentiment classification (ASC) and opinion target\nexpression (OTE) extraction. We examine fine-tuning strategies - feature\nextraction, full fine-tuning, and adapter-based methods - to enhance\nperformance and efficiency, utilizing multiple adaptation corpora and\ncontextualized models. Our results show that in-domain adaptive pre-training\nyields modest improvements. Adapter-based fine-tuning is a computationally\nefficient method that achieves competitive results. However, error analyses\nreveal issues with model predictions and dataset labeling. In ASC, common\nproblems include incorrect sentiment labeling, misinterpretation of contrastive\nmarkers, positivity bias for early terms, and challenges with conflicting\nopinions and subword tokenization. For OTE, issues involve mislabeling targets,\nconfusion over syntactic roles, difficulty with multi-word expressions, and\nreliance on shallow heuristics. These findings underscore the need for syntax-\nand semantics-aware models, such as graph convolutional networks, to more\neffectively capture long-distance relations and complex aspect-based opinion\nalignments."}
{"id": "2509.16799", "pdf": "https://arxiv.org/pdf/2509.16799", "abs": "https://arxiv.org/abs/2509.16799", "authors": ["Vincenzo Lipardi", "Domenica Dibenedetto", "Georgios Stamoulis", "Mark H. M. Winands"], "title": "A Study on Stabilizer Rényi Entropy Estimation using Machine Learning", "categories": ["quant-ph", "cs.LG"], "comment": null, "summary": "Nonstabilizerness is a fundamental resource for quantum advantage, as it\nquantifies the extent to which a quantum state diverges from those states that\ncan be efficiently simulated on a classical computer, the stabilizer states.\nThe stabilizer R\\'enyi entropy (SRE) is one of the most investigated measures\nof nonstabilizerness because of its computational properties and suitability\nfor experimental measurements on quantum processors. Because computing the SRE\nfor arbitrary quantum states is a computationally hard problem, we propose a\nsupervised machine-learning approach to estimate it. In this work, we frame SRE\nestimation as a regression task and train a Random Forest Regressor and a\nSupport Vector Regressor (SVR) on a comprehensive dataset, including both\nunstructured random quantum circuits and structured circuits derived from the\nphysics-motivated one-dimensional transverse Ising model (TIM). We compare the\nmachine-learning models using two different quantum circuit representations:\none based on classical shadows and the other on circuit-level features.\nFurthermore, we assess the generalization capabilities of the models on\nout-of-distribution instances. Experimental results show that an SVR trained on\ncircuit-level features achieves the best overall performance. On the random\ncircuits dataset, our approach converges to accurate SRE estimations, but\nstruggles to generalize out of distribution. In contrast, it generalizes well\non the structured TIM dataset, even to deeper and larger circuits. In line with\nprevious work, our experiments suggest that machine learning offers a viable\npath for efficient nonstabilizerness estimation."}
{"id": "2509.16801", "pdf": "https://arxiv.org/pdf/2509.16801", "abs": "https://arxiv.org/abs/2509.16801", "authors": ["Zhao Song", "David P. Woodruff", "Lichen Zhang"], "title": "Sublinear Time Quantum Sensitivity Sampling", "categories": ["cs.DS", "cs.LG", "quant-ph"], "comment": null, "summary": "We present a unified framework for quantum sensitivity sampling, extending\nthe advantages of quantum computing to a broad class of classical approximation\nproblems. Our unified framework provides a streamlined approach for\nconstructing coresets and offers significant runtime improvements in\napplications such as clustering, regression, and low-rank approximation. Our\ncontributions include:\n  * $k$-median and $k$-means clustering: For $n$ points in $d$-dimensional\nEuclidean space, we give an algorithm that constructs an $\\epsilon$-coreset in\ntime $\\widetilde O(n^{0.5}dk^{2.5}~\\mathrm{poly}(\\epsilon^{-1}))$ for\n$k$-median and $k$-means clustering. Our approach achieves a better dependence\non $d$ and constructs smaller coresets that only consist of points in the\ndataset, compared to recent results of [Xue, Chen, Li and Jiang, ICML'23].\n  * $\\ell_p$ regression: For $\\ell_p$ regression problems, we construct an\n$\\epsilon$-coreset of size $\\widetilde O_p(d^{\\max\\{1, p/2\\}}\\epsilon^{-2})$ in\ntime $\\widetilde O_p(n^{0.5}d^{\\max\\{0.5, p/4\\}+1}(\\epsilon^{-3}+d^{0.5}))$,\nimproving upon the prior best quantum sampling approach of [Apers and Gribling,\nQIP'24] for all $p\\in (0, 2)\\cup (2, 22]$, including the widely studied least\nabsolute deviation regression ($\\ell_1$ regression).\n  * Low-rank approximation with Frobenius norm error: We introduce the first\nquantum sublinear-time algorithm for low-rank approximation that does not rely\non data-dependent parameters, and runs in $\\widetilde\nO(nd^{0.5}k^{0.5}\\epsilon^{-1})$ time. Additionally, we present quantum\nsublinear algorithms for kernel low-rank approximation and tensor low-rank\napproximation, broadening the range of achievable sublinear time algorithms in\nrandomized numerical linear algebra."}
{"id": "2509.16818", "pdf": "https://arxiv.org/pdf/2509.16818", "abs": "https://arxiv.org/abs/2509.16818", "authors": ["Le Gong", "Longxiu Huang"], "title": "Randomized Space-Time Sampling for Affine Graph Dynamical Systems", "categories": ["math.NA", "cs.IT", "cs.LG", "cs.NA", "cs.SY", "eess.SY", "math.IT"], "comment": null, "summary": "This paper investigates the problem of dynamical sampling for graph signals\ninfluenced by a constant source term. We consider signals evolving over time\naccording to a linear dynamical system on a graph, where both the initial state\nand the source term are bandlimited. We introduce two random space-time\nsampling regimes and analyze the conditions under which stable recovery is\nachievable. While our framework extends recent work on homogeneous dynamics, it\naddresses a fundamentally different setting where the evolution includes a\nconstant source term. This results in a non-orthogonal-diagonalizable system\nmatrix, rendering classical spectral techniques inapplicable and introducing\nnew challenges in sampling design, stability analysis, and joint recovery of\nboth the initial state and the forcing term. A key component of our analysis is\nthe spectral graph weighted coherence, which characterizes the interplay\nbetween the sampling distribution and the graph structure. We establish\nsampling complexity bounds ensuring stable recovery via the Restricted Isometry\nProperty (RIP), and develop a robust recovery algorithm with provable error\nguarantees. The effectiveness of our method is validated through extensive\nexperiments on both synthetic and real-world datasets."}
{"id": "2509.16834", "pdf": "https://arxiv.org/pdf/2509.16834", "abs": "https://arxiv.org/abs/2509.16834", "authors": ["Jingxi Xu"], "title": "Robot Learning with Sparsity and Scarcity", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "Unlike in language or vision, one of the fundamental challenges in robot\nlearning is the lack of access to vast data resources. We can further break\ndown the problem into (1) data sparsity from the angle of data representation\nand (2) data scarcity from the angle of data quantity. In this thesis, I will\ndiscuss selected works on two domains: (1) tactile sensing and (2)\nrehabilitation robots, which are exemplars of data sparsity and scarcity,\nrespectively. Tactile sensing is an essential modality for robotics, but\ntactile data are often sparse, and for each interaction with the physical\nworld, tactile sensors can only obtain information about the local area of\ncontact. I will discuss my work on learning vision-free tactile-only\nexploration and manipulation policies through model-free reinforcement learning\nto make efficient use of sparse tactile information. On the other hand,\nrehabilitation robots are an example of data scarcity to the extreme due to the\nsignificant challenge of collecting biosignals from disabled-bodied subjects at\nscale for training. I will discuss my work in collaboration with the medical\nschool and clinicians on intent inferral for stroke survivors, where a hand\northosis developed in our lab collects a set of biosignals from the patient and\nuses them to infer the activity that the patient intends to perform, so the\northosis can provide the right type of physical assistance at the right moment.\nMy work develops machine learning algorithms that enable intent inferral with\nminimal data, including semi-supervised, meta-learning, and generative AI\nmethods."}
{"id": "2509.16842", "pdf": "https://arxiv.org/pdf/2509.16842", "abs": "https://arxiv.org/abs/2509.16842", "authors": ["Alex Luedtke", "Kenji Fukumizu"], "title": "DoubleGen: Debiased Generative Modeling of Counterfactuals", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": "Keywords: generative modeling, counterfactual, doubly robust,\n  debiased machine learning", "summary": "Generative models for counterfactual outcomes face two key sources of bias.\nConfounding bias arises when approaches fail to account for systematic\ndifferences between those who receive the intervention and those who do not.\nMisspecification bias arises when methods attempt to address confounding\nthrough estimation of an auxiliary model, but specify it incorrectly. We\nintroduce DoubleGen, a doubly robust framework that modifies generative\nmodeling training objectives to mitigate these biases. The new objectives rely\non two auxiliaries -- a propensity and outcome model -- and successfully\naddress confounding bias even if only one of them is correct. We provide\nfinite-sample guarantees for this robustness property. We further establish\nconditions under which DoubleGen achieves oracle optimality -- matching the\nconvergence rates standard approaches would enjoy if interventional data were\navailable -- and minimax rate optimality. We illustrate DoubleGen with three\nexamples: diffusion models, flow matching, and autoregressive language models."}
{"id": "2509.16857", "pdf": "https://arxiv.org/pdf/2509.16857", "abs": "https://arxiv.org/abs/2509.16857", "authors": ["Xingyu Xiang", "Raj Joshi", "Yuhan Liu", "Jiayi Yao", "Chenxingyu Zhao", "Junchen Jiang", "Yang Zhou", "Eddie Kohler", "Minlan Yu"], "title": "ShadowServe: Interference-Free KV Cache Fetching for Distributed Prefix Caching", "categories": ["cs.DC", "cs.AI", "cs.LG"], "comment": null, "summary": "Distributed prefix caching accelerates long-context LLM serving by reusing KV\ncache entries for common context prefixes. However, KV cache fetches can become\na bottleneck when network bandwidth is limited. Compression mitigates the\nbandwidth issue, but can degrade overall performance when decompression\ninterferes with model computation.\n  We present ShadowServe, the first SmartNIC-accelerated, interference-free\nprefix caching system for LLM serving. ShadowServe separates a control plane on\nthe host and a data plane fully offloaded to the SmartNIC, which eliminates\ninterference to both host GPU and CPU. To overcome the SmartNIC's limited\ncompute and memory resources, we design a chunked pipeline that parallelizes\ndata plane operations across the SmartNIC's compute resources, and a\nminimal-copy memory management scheme that reduces memory pressure on the\nSmartNIC. Compared to state-of-the-art solutions, ShadowServe achieves up to\n2.2x lower loaded time-per-output-token (TPOT), and reduces time-to-first-token\n(TTFT) by up to 1.38x in low-bandwidth scenarios (<= 20 Gbps), translating to\nup to 1.35x higher throughput."}
{"id": "2509.16866", "pdf": "https://arxiv.org/pdf/2509.16866", "abs": "https://arxiv.org/abs/2509.16866", "authors": ["Mohammad Ramezanali", "Mo Vazifeh", "Paolo Santi"], "title": "seqBench: A Tunable Benchmark to Quantify Sequential Reasoning Limits of LLMs", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "We introduce seqBench, a parametrized benchmark for probing sequential\nreasoning limits in Large Language Models (LLMs) through precise,\nmulti-dimensional control over several key complexity dimensions. seqBench\nallows systematic variation of (1) the logical depth, defined as the number of\nsequential actions required to solve the task; (2) the number of backtracking\nsteps along the optimal path, quantifying how often the agent must revisit\nprior states to satisfy deferred preconditions (e.g., retrieving a key after\nencountering a locked door); and (3) the noise ratio, defined as the ratio\nbetween supporting and distracting facts about the environment. Our evaluations\non state-of-the-art LLMs reveal a universal failure pattern: accuracy collapses\nexponentially beyond a model-specific logical depth. Unlike existing\nbenchmarks, seqBench's fine-grained control facilitates targeted analyses of\nthese reasoning failures, illuminating universal scaling laws and statistical\nlimits, as detailed in this paper alongside its generation methodology and\nevaluation metrics. We find that even top-performing models systematically fail\non seqBench's structured reasoning tasks despite minimal search complexity,\nunderscoring key limitations in their commonsense reasoning capabilities.\nDesigned for future evolution to keep pace with advancing models, the seqBench\ndatasets are publicly released to spur deeper scientific inquiry into LLM\nreasoning, aiming to establish a clearer understanding of their true potential\nand current boundaries for robust real-world application."}
{"id": "2509.16869", "pdf": "https://arxiv.org/pdf/2509.16869", "abs": "https://arxiv.org/abs/2509.16869", "authors": ["Hrishav Bakul Barua", "Kalin Stefanov", "Ganesh Krishnasamy", "KokSheik Wong", "Abhinav Dhall"], "title": "PhysHDR: When Lighting Meets Materials and Scene Geometry in HDR Reconstruction", "categories": ["cs.GR", "cs.AI", "cs.CV", "cs.LG", "cs.MM", "eess.IV", "Artificial intelligence, Computer vision, Machine learning, Deep\n  learning", "I.3.3; I.4.5"], "comment": "Submitted to IEEE", "summary": "Low Dynamic Range (LDR) to High Dynamic Range (HDR) image translation is a\nfundamental task in many computational vision problems. Numerous data-driven\nmethods have been proposed to address this problem; however, they lack explicit\nmodeling of illumination, lighting, and scene geometry in images. This limits\nthe quality of the reconstructed HDR images. Since lighting and shadows\ninteract differently with different materials, (e.g., specular surfaces such as\nglass and metal, and lambertian or diffuse surfaces such as wood and stone),\nmodeling material-specific properties (e.g., specular and diffuse reflectance)\nhas the potential to improve the quality of HDR image reconstruction. This\npaper presents PhysHDR, a simple yet powerful latent diffusion-based generative\nmodel for HDR image reconstruction. The denoising process is conditioned on\nlighting and depth information and guided by a novel loss to incorporate\nmaterial properties of surfaces in the scene. The experimental results\nestablish the efficacy of PhysHDR in comparison to a number of recent\nstate-of-the-art methods."}
{"id": "2509.16915", "pdf": "https://arxiv.org/pdf/2509.16915", "abs": "https://arxiv.org/abs/2509.16915", "authors": ["Zhao Song", "Jianfei Xue", "Lichen Zhang"], "title": "Differential Privacy for Euclidean Jordan Algebra with Applications to Private Symmetric Cone Programming", "categories": ["math.OC", "cs.CR", "cs.DS", "cs.LG"], "comment": "NeurIPS 2025", "summary": "In this paper, we study differentially private mechanisms for functions whose\noutputs lie in a Euclidean Jordan algebra. Euclidean Jordan algebras capture\nmany important mathematical structures and form the foundation of linear\nprogramming, second-order cone programming, and semidefinite programming. Our\nmain contribution is a generic Gaussian mechanism for such functions, with\nsensitivity measured in $\\ell_2$, $\\ell_1$, and $\\ell_\\infty$ norms. Notably,\nthis framework includes the important case where the function outputs are\nsymmetric matrices, and sensitivity is measured in the Frobenius, nuclear, or\nspectral norm. We further derive private algorithms for solving symmetric cone\nprograms under various settings, using a combination of the multiplicative\nweights update method and our generic Gaussian mechanism. As an application, we\npresent differentially private algorithms for semidefinite programming,\nresolving a major open question posed by [Hsu, Roth, Roughgarden, and Ullman,\nICALP 2014]."}
{"id": "2509.16926", "pdf": "https://arxiv.org/pdf/2509.16926", "abs": "https://arxiv.org/abs/2509.16926", "authors": ["Ragib Amin Nihal", "Benjamin Yen", "Takeshi Ashizawa", "Kazuhiro Nakadai"], "title": "Cross-Attention with Confidence Weighting for Multi-Channel Audio Alignment", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "comment": "Accepted on Workshop on Detection and Classification of Acoustic\n  Scenes and Events (DCASE 2025)", "summary": "Multi-channel audio alignment is a key requirement in bioacoustic monitoring,\nspatial audio systems, and acoustic localization. However, existing methods\noften struggle to address nonlinear clock drift and lack mechanisms for\nquantifying uncertainty. Traditional methods like Cross-correlation and Dynamic\nTime Warping assume simple drift patterns and provide no reliability measures.\nMeanwhile, recent deep learning models typically treat alignment as a binary\nclassification task, overlooking inter-channel dependencies and uncertainty\nestimation. We introduce a method that combines cross-attention mechanisms with\nconfidence-weighted scoring to improve multi-channel audio synchronization. We\nextend BEATs encoders with cross-attention layers to model temporal\nrelationships between channels. We also develop a confidence-weighted scoring\nfunction that uses the full prediction distribution instead of binary\nthresholding. Our method achieved first place in the BioDCASE 2025 Task 1\nchallenge with 0.30 MSE average across test datasets, compared to 0.58 for the\ndeep learning baseline. On individual datasets, we achieved 0.14 MSE on ARU\ndata (77% reduction) and 0.45 MSE on zebra finch data (18% reduction). The\nframework supports probabilistic temporal alignment, moving beyond point\nestimates. While validated in a bioacoustic context, the approach is applicable\nto a broader range of multi-channel audio tasks where alignment confidence is\ncritical. Code available on: https://github.com/Ragib-Amin-Nihal/BEATsCA"}
{"id": "2509.16931", "pdf": "https://arxiv.org/pdf/2509.16931", "abs": "https://arxiv.org/abs/2509.16931", "authors": ["Yutong Li", "Yu Zhu", "Yichen Qiao", "Ziyu Guan", "Lv Shao", "Tong Liu", "Bo Zheng"], "title": "Equip Pre-ranking with Target Attention by Residual Quantization", "categories": ["cs.IR", "cs.AI", "cs.LG", "I.2.0; I.5.0; I.7.0"], "comment": "5 pages, 2 figures, submitted to WSDM 2026 Short Paper Track", "summary": "The pre-ranking stage in industrial recommendation systems faces a\nfundamental conflict between efficiency and effectiveness. While powerful\nmodels like Target Attention (TA) excel at capturing complex feature\ninteractions in the ranking stage, their high computational cost makes them\ninfeasible for pre-ranking, which often relies on simplistic vector-product\nmodels. This disparity creates a significant performance bottleneck for the\nentire system. To bridge this gap, we propose TARQ, a novel pre-ranking\nframework. Inspired by generative models, TARQ's key innovation is to equip\npre-ranking with an architecture approximate to TA by Residual Quantization.\nThis allows us to bring the modeling power of TA into the latency-critical\npre-ranking stage for the first time, establishing a new state-of-the-art\ntrade-off between accuracy and efficiency. Extensive offline experiments and\nlarge-scale online A/B tests at Taobao demonstrate TARQ's significant\nimprovements in ranking performance. Consequently, our model has been fully\ndeployed in production, serving tens of millions of daily active users and\nyielding substantial business improvements."}
{"id": "2509.16938", "pdf": "https://arxiv.org/pdf/2509.16938", "abs": "https://arxiv.org/abs/2509.16938", "authors": ["Tran Thanh Dat", "Tran Quang Khai", "Pham Anh Khoi", "Vu Van Khu", "Do Duc Dong"], "title": "NeuFACO: Neural Focused Ant Colony Optimization for Traveling Salesman Problem", "categories": ["cs.NE", "cs.LG"], "comment": "Submitted to RIVF'25. Code is available at\n  https://github.com/shoraaa/NeuFACO", "summary": "This study presents Neural Focused Ant Colony Optimization (NeuFACO), a\nnon-autoregressive framework for the Traveling Salesman Problem (TSP) that\ncombines advanced reinforcement learning with enhanced Ant Colony Optimization\n(ACO). NeuFACO employs Proximal Policy Optimization (PPO) with entropy\nregularization to train a graph neural network for instance-specific heuristic\nguidance, which is integrated into an optimized ACO framework featuring\ncandidate lists, restricted tour refinement, and scalable local search. By\nleveraging amortized inference alongside ACO stochastic exploration, NeuFACO\nefficiently produces high-quality solutions across diverse TSP instances."}
{"id": "2509.16955", "pdf": "https://arxiv.org/pdf/2509.16955", "abs": "https://arxiv.org/abs/2509.16955", "authors": ["Chi-Sheng Chen", "Aidan Hung-Wen Tsai"], "title": "Quantum Adaptive Self-Attention for Financial Rebalancing: An Empirical Study on Automated Market Makers in Decentralized Finance", "categories": ["quant-ph", "cs.LG", "q-fin.CP"], "comment": null, "summary": "We formulate automated market maker (AMM) \\emph{rebalancing} as a binary\ndetection problem and study a hybrid quantum--classical self-attention block,\n\\textbf{Quantum Adaptive Self-Attention (QASA)}. QASA constructs quantum\nqueries/keys/values via variational quantum circuits (VQCs) and applies\nstandard softmax attention over Pauli-$Z$ expectation vectors, yielding a\ndrop-in attention module for financial time-series decision making. Using daily\ndata for \\textbf{BTCUSDC} over \\textbf{Jan-2024--Jan-2025} with a 70/15/15\ntime-series split, we compare QASA against classical ensembles, a transformer,\nand pure quantum baselines under Return, Sharpe, and Max Drawdown. The\n\\textbf{QASA-Sequence} variant attains the \\emph{best single-model\nrisk-adjusted performance} (\\textbf{13.99\\%} return; \\textbf{Sharpe 1.76}),\nwhile hybrid models average \\textbf{11.2\\%} return (vs.\\ 9.8\\% classical; 4.4\\%\npure quantum), indicating a favorable performance--stability--cost trade-off."}
{"id": "2509.16973", "pdf": "https://arxiv.org/pdf/2509.16973", "abs": "https://arxiv.org/abs/2509.16973", "authors": ["Behdad Khodabandehloo", "Reza Rajimehr"], "title": "Deep Learning Inductive Biases for fMRI Time Series Classification during Resting-state and Movie-watching", "categories": ["q-bio.NC", "cs.LG"], "comment": null, "summary": "Deep learning has advanced fMRI analysis, yet it remains unclear which\narchitectural inductive biases are most effective at capturing functional\npatterns in human brain activity. This issue is particularly important in\nsmall-sample settings, as most datasets fall into this category. We compare\nmodels with three major inductive biases in deep learning including\nconvolutional neural networks (CNNs), long short-term memory networks (LSTMs),\nand Transformers for the task of biological sex classification. These models\nare evaluated within a unified pipeline using parcellated multivariate fMRI\ntime series from the Human Connectome Project (HCP) 7-Tesla cohort, which\nincludes four resting-state runs and four movie-watching task runs. We assess\nperformance on Whole-brain, subcortex, and 12 functional networks. CNNs\nconsistently achieved the highest discrimination for sex classification in both\nresting-state and movie-watching, while LSTM and Transformer models\nunderperformed. Network-resolved analyses indicated that the Whole-brain,\nDefault Mode, Cingulo-Opercular, Dorsal Attention, and Frontoparietal networks\nwere the most discriminative. These results were largely similar between\nresting-state and movie-watching. Our findings indicate that, at this dataset\nsize, discriminative information is carried by local spatial patterns and\ninter-regional dependencies, favoring convolutional inductive bias. Our study\nprovides insights for selecting deep learning architectures for fMRI time\nseries classification."}
{"id": "2509.16977", "pdf": "https://arxiv.org/pdf/2509.16977", "abs": "https://arxiv.org/abs/2509.16977", "authors": ["Petros Georgoulas Wraight", "Giorgos Sfikas", "Ioannis Kordonis", "Petros Maragos", "George Retsinas"], "title": "Optimal Transport for Handwritten Text Recognition in a Low-Resource Regime", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Handwritten Text Recognition (HTR) is a task of central importance in the\nfield of document image understanding. State-of-the-art methods for HTR require\nthe use of extensive annotated sets for training, making them impractical for\nlow-resource domains like historical archives or limited-size modern\ncollections. This paper introduces a novel framework that, unlike the standard\nHTR model paradigm, can leverage mild prior knowledge of lexical\ncharacteristics; this is ideal for scenarios where labeled data are scarce. We\npropose an iterative bootstrapping approach that aligns visual features\nextracted from unlabeled images with semantic word representations using\nOptimal Transport (OT). Starting with a minimal set of labeled examples, the\nframework iteratively matches word images to text labels, generates\npseudo-labels for high-confidence alignments, and retrains the recognizer on\nthe growing dataset. Numerical experiments demonstrate that our iterative\nvisual-semantic alignment scheme significantly improves recognition accuracy on\nlow-resource HTR benchmarks."}
{"id": "2509.16990", "pdf": "https://arxiv.org/pdf/2509.16990", "abs": "https://arxiv.org/abs/2509.16990", "authors": ["Avishai Elmakies", "Hagai Aronowitz", "Nimrod Shabtay", "Eli Schwartz", "Ron Hoory", "Avihu Dekel"], "title": "Advancing Speech Understanding in Speech-Aware Language Models with GRPO", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SD", "eess.AS"], "comment": null, "summary": "In this paper, we introduce a Group Relative Policy Optimization (GRPO)-based\nmethod for training Speech-Aware Large Language Models (SALLMs) on open-format\nspeech understanding tasks, such as Spoken Question Answering and Automatic\nSpeech Translation. SALLMs have proven highly effective for speech\nunderstanding tasks. GRPO has recently gained traction for its efficiency in\ntraining LLMs, and prior work has explored its application to SALLMs, primarily\nin multiple-choice tasks. Building on this, we focus on open-format tasks that\nbetter reflect the generative abilities of the models. Our approach leverages\nGRPO with BLEU as the reward signal to optimize SALLMs, and we demonstrate\nempirically that it surpasses standard SFT across several key metrics. Finally,\nwe explore the potential of incorporating off-policy samples within GRPO for\nthese tasks, highlighting avenues for further improvement and further research."}
{"id": "2509.17012", "pdf": "https://arxiv.org/pdf/2509.17012", "abs": "https://arxiv.org/abs/2509.17012", "authors": ["Zhichao Ma", "Fan Huang", "Lu Zhao", "Fengjun Guo", "Guangtao Zhai", "Xiongkuo Min"], "title": "DocIQ: A Benchmark Dataset and Feature Fusion Network for Document Image Quality Assessment", "categories": ["cs.CV", "cs.LG", "eess.IV"], "comment": null, "summary": "Document image quality assessment (DIQA) is an important component for\nvarious applications, including optical character recognition (OCR), document\nrestoration, and the evaluation of document image processing systems. In this\npaper, we introduce a subjective DIQA dataset DIQA-5000. The DIQA-5000 dataset\ncomprises 5,000 document images, generated by applying multiple document\nenhancement techniques to 500 real-world images with diverse distortions. Each\nenhanced image was rated by 15 subjects across three rating dimensions: overall\nquality, sharpness, and color fidelity. Furthermore, we propose a specialized\nno-reference DIQA model that exploits document layout features to maintain\nquality perception at reduced resolutions to lower computational cost.\nRecognizing that image quality is influenced by both low-level and high-level\nvisual features, we designed a feature fusion module to extract and integrate\nmulti-level features from document images. To generate multi-dimensional\nscores, our model employs independent quality heads for each dimension to\npredict score distributions, allowing it to learn distinct aspects of document\nimage quality. Experimental results demonstrate that our method outperforms\ncurrent state-of-the-art general-purpose IQA models on both DIQA-5000 and an\nadditional document image dataset focused on OCR accuracy."}
{"id": "2509.17018", "pdf": "https://arxiv.org/pdf/2509.17018", "abs": "https://arxiv.org/abs/2509.17018", "authors": ["Jan Pavšek", "Alexander Mitsos", "Manuel Dahmen", "Tai Xuan Tan", "Jan G. Rittig"], "title": "DeepEOSNet: Capturing the dependency on thermodynamic state in property prediction tasks", "categories": ["physics.chem-ph", "cs.LG"], "comment": null, "summary": "We propose a machine learning (ML) architecture to better capture the\ndependency of thermodynamic properties on the independent states. When\npredicting state-dependent thermodynamic properties, ML models need to account\nfor both molecular structure and the thermodynamic state, described by\nindependent variables, typically temperature, pressure, and composition. Modern\nmolecular ML models typically include state information by adding it to\nmolecular fingerprint vectors or by embedding explicit (semi-empirical)\nthermodynamic relations. Here, we propose to rather split the information\nprocessing on the molecular structure and the dependency on states into two\nseparate network channels: a graph neural network and a multilayer perceptron,\nwhose output is combined by a dot product. We refer to our approach as\nDeepEOSNet, as this idea is based on the DeepONet architecture [Lu et al.\n(2021), Nat. Mach. Intell.]: instead of operators, we learn state dependencies,\nwith the possibility to predict equation of states (EOS). We investigate the\npredictive performance of DeepEOSNet by means of three case studies, which\ninclude the prediction of vapor pressure as a function of temperature, and\nmixture molar volume as a function of composition, temperature, and pressure.\nOur results show superior performance of DeepEOSNet for predicting vapor\npressure and comparable performance for predicting mixture molar volume\ncompared to state-of-research graph-based thermodynamic prediction models from\nour earlier works. In fact, we see large potential of DeepEOSNet in cases where\ndata is sparse in the state domain and the output function is structurally\nsimilar across different molecules. The concept of DeepEOSNet can easily be\ntransferred to other ML architectures in molecular context, and thus provides a\nviable option for property prediction."}
{"id": "2509.17030", "pdf": "https://arxiv.org/pdf/2509.17030", "abs": "https://arxiv.org/abs/2509.17030", "authors": ["Hinata Tezuka", "Naoya Inoue"], "title": "The Transfer Neurons Hypothesis: An Underlying Mechanism for Language Latent Space Transitions in Multilingual LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "57 pages, 47 figures and 41 tables; Accepted to EMNLP 2025 Main", "summary": "Recent studies have suggested a processing framework for multilingual inputs\nin decoder-based LLMs: early layers convert inputs into English-centric and\nlanguage-agnostic representations; middle layers perform reasoning within an\nEnglish-centric latent space; and final layers generate outputs by transforming\nthese representations back into language-specific latent spaces. However, the\ninternal dynamics of such transformation and the underlying mechanism remain\nunderexplored. Towards a deeper understanding of this framework, we propose and\nempirically validate The Transfer Neurons Hypothesis: certain neurons in the\nMLP module are responsible for transferring representations between\nlanguage-specific latent spaces and a shared semantic latent space.\nFurthermore, we show that one function of language-specific neurons, as\nidentified in recent studies, is to facilitate movement between latent spaces.\nFinally, we show that transfer neurons are critical for reasoning in\nmultilingual LLMs."}
{"id": "2509.17070", "pdf": "https://arxiv.org/pdf/2509.17070", "abs": "https://arxiv.org/abs/2509.17070", "authors": ["Mayukh Borana", "Junyi Liang", "Sai Sathiesh Rajan", "Sudipta Chattopadhyay"], "title": "Localizing Malicious Outputs from CodeLLM", "categories": ["cs.CR", "cs.CL", "cs.LG"], "comment": "10 pages, 2 figures, 6 tables, Accepted at EMNLP 2025 Findings", "summary": "We introduce FreqRank, a mutation-based defense to localize malicious\ncomponents in LLM outputs and their corresponding backdoor triggers. FreqRank\nassumes that the malicious sub-string(s) consistently appear in outputs for\ntriggered inputs and uses a frequency-based ranking system to identify them.\nOur ranking system then leverages this knowledge to localize the backdoor\ntriggers present in the inputs. We create nine malicious models through\nfine-tuning or custom instructions for three downstream tasks, namely, code\ncompletion (CC), code generation (CG), and code summarization (CS), and show\nthat they have an average attack success rate (ASR) of 86.6%. Furthermore,\nFreqRank's ranking system highlights the malicious outputs as one of the top\nfive suggestions in 98% of cases. We also demonstrate that FreqRank's\neffectiveness scales as the number of mutants increases and show that FreqRank\nis capable of localizing the backdoor trigger effectively even with a limited\nnumber of triggered samples. Finally, we show that our approach is 35-50% more\neffective than other defense methods."}
{"id": "2509.17094", "pdf": "https://arxiv.org/pdf/2509.17094", "abs": "https://arxiv.org/abs/2509.17094", "authors": ["Elton Pan", "Soonhyoung Kwon", "Sulin Liu", "Mingrou Xie", "Alexander J. Hoffman", "Yifei Duan", "Thorben Prein", "Killian Sheriff", "Yuriy Roman-Leshkov", "Manuel Moliner", "Rafael Gomez-Bombarelli", "Elsa Olivetti"], "title": "$\\texttt{DiffSyn}$: A Generative Diffusion Approach to Materials Synthesis Planning", "categories": ["cond-mat.mtrl-sci", "cs.AI", "cs.LG"], "comment": null, "summary": "The synthesis of crystalline materials, such as zeolites, remains a\nsignificant challenge due to a high-dimensional synthesis space, intricate\nstructure-synthesis relationships and time-consuming experiments. Considering\nthe one-to-many relationship between structure and synthesis, we propose\n$\\texttt{DiffSyn}$, a generative diffusion model trained on over 23,000\nsynthesis recipes spanning 50 years of literature. $\\texttt{DiffSyn}$ generates\nprobable synthesis routes conditioned on a desired zeolite structure and an\norganic template. $\\texttt{DiffSyn}$ achieves state-of-the-art performance by\ncapturing the multi-modal nature of structure-synthesis relationships. We apply\n$\\texttt{DiffSyn}$ to differentiate among competing phases and generate optimal\nsynthesis routes. As a proof of concept, we synthesize a UFI material using\n$\\texttt{DiffSyn}$-generated synthesis routes. These routes, rationalized by\ndensity functional theory binding energies, resulted in the successful\nsynthesis of a UFI material with a high Si/Al$_{\\text{ICP}}$ of 19.0, which is\nexpected to improve thermal stability and is higher than that of any previously\nrecorded."}
{"id": "2509.17097", "pdf": "https://arxiv.org/pdf/2509.17097", "abs": "https://arxiv.org/abs/2509.17097", "authors": ["Salim Oyinlola", "Peter Olabisi Oluseyi"], "title": "Machine Learning for Campus Energy Resilience: Clustering and Time-Series Forecasting in Intelligent Load Shedding", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": "Submitted for the NeurIPS 2025 Climata Change AI Workshop in San\n  Diego, USA", "summary": "The growing demand for reliable electricity in universities necessitates\nintelligent energy management. This study proposes a machine learning-based\nload shedding framework for the University of Lagos, designed to optimize\ndistribution and reduce waste. The methodology followed three main stages.\nFirst, a dataset of 3,648 hourly records from 55 buildings was compiled to\ndevelop building-level consumption models. Second, Principal Component Analysis\nwas applied for dimensionality reduction, and clustering validation techniques\nwere used to determine the optimal number of demand groups. Mini-Batch K-Means\nwas then employed to classify buildings into high-, medium-, and low-demand\nclusters. Finally, short-term load forecasting was performed at the cluster\nlevel using multiple statistical and deep learning models, including ARIMA,\nSARIMA, Prophet, LSTM, and GRU. Results showed Prophet offered the most\nreliable forecasts, while Mini-Batch K-Means achieved stable clustering\nperformance. By integrating clustering with forecasting, the framework enabled\na fairer, data-driven load shedding strategy that reduces inefficiencies and\nsupports climate change mitigation through sustainable energy management."}
{"id": "2509.17098", "pdf": "https://arxiv.org/pdf/2509.17098", "abs": "https://arxiv.org/abs/2509.17098", "authors": ["Yuzhu Li", "An Sui", "Fuping Wu", "Xiahai Zhuang"], "title": "Uncertainty-Supervised Interpretable and Robust Evidential Segmentation", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Uncertainty estimation has been widely studied in medical image segmentation\nas a tool to provide reliability, particularly in deep learning approaches.\nHowever, previous methods generally lack effective supervision in uncertainty\nestimation, leading to low interpretability and robustness of the predictions.\nIn this work, we propose a self-supervised approach to guide the learning of\nuncertainty. Specifically, we introduce three principles about the\nrelationships between the uncertainty and the image gradients around boundaries\nand noise. Based on these principles, two uncertainty supervision losses are\ndesigned. These losses enhance the alignment between model predictions and\nhuman interpretation. Accordingly, we introduce novel quantitative metrics for\nevaluating the interpretability and robustness of uncertainty. Experimental\nresults demonstrate that compared to state-of-the-art approaches, the proposed\nmethod can achieve competitive segmentation performance and superior results in\nout-of-distribution (OOD) scenarios while significantly improving the\ninterpretability and robustness of uncertainty estimation. Code is available\nvia https://github.com/suiannaius/SURE."}
{"id": "2509.17131", "pdf": "https://arxiv.org/pdf/2509.17131", "abs": "https://arxiv.org/abs/2509.17131", "authors": ["Filip Bajraktari", "Luke Bhan", "Miroslav Krstic", "Yuanyuan Shi"], "title": "Delay compensation of multi-input distinct delay nonlinear systems via neural operators", "categories": ["eess.SY", "cs.LG", "cs.RO", "cs.SY", "math.DS"], "comment": "8 pages, 1 figure", "summary": "In this work, we present the first stability results for approximate\npredictors in multi-input non-linear systems with distinct actuation delays. We\nshow that if the predictor approximation satisfies a uniform (in time) error\nbound, semi-global practical stability is correspondingly achieved. For such\napproximators, the required uniform error bound depends on the desired region\nof attraction and the number of control inputs in the system. The result is\nachieved through transforming the delay into a transport PDE and conducting\nanalysis on the coupled ODE-PDE cascade. To highlight the viability of such\nerror bounds, we demonstrate our results on a class of approximators - neural\noperators - showcasing sufficiency for satisfying such a universal bound both\ntheoretically and in simulation on a mobile robot experiment."}
{"id": "2509.17154", "pdf": "https://arxiv.org/pdf/2509.17154", "abs": "https://arxiv.org/abs/2509.17154", "authors": ["Yasamin Jalalian", "Mostafa Samir", "Boumediene Hamzi", "Peyman Tavallali", "Houman Owhadi"], "title": "Data-efficient Kernel Methods for Learning Hamiltonian Systems", "categories": ["math.NA", "cs.LG", "cs.NA", "math.DS", "stat.ML"], "comment": null, "summary": "Hamiltonian dynamics describe a wide range of physical systems. As such,\ndata-driven simulations of Hamiltonian systems are important for many\nscientific and engineering problems. In this work, we propose kernel-based\nmethods for identifying and forecasting Hamiltonian systems directly from data.\nWe present two approaches: a two-step method that reconstructs trajectories\nbefore learning the Hamiltonian, and a one-step method that jointly infers\nboth. Across several benchmark systems, including mass-spring dynamics, a\nnonlinear pendulum, and the Henon-Heiles system, we demonstrate that our\nframework achieves accurate, data-efficient predictions and outperforms\ntwo-step kernel-based baselines, particularly in scarce-data regimes, while\npreserving the conservation properties of Hamiltonian dynamics. Moreover, our\nmethodology provides theoretical a priori error estimates, ensuring reliability\nof the learned models. We also provide a more general, problem-agnostic\nnumerical framework that goes beyond Hamiltonian systems and can be used for\ndata-driven learning of arbitrary dynamical systems."}
{"id": "2509.17174", "pdf": "https://arxiv.org/pdf/2509.17174", "abs": "https://arxiv.org/abs/2509.17174", "authors": ["Kijung Yoon"], "title": "Self-Supervised Discovery of Neural Circuits in Spatially Patterned Neural Responses with Graph Neural Networks", "categories": ["q-bio.NC", "cs.LG", "q-bio.QM"], "comment": "To appear in NeurIPS 2025", "summary": "Inferring synaptic connectivity from neural population activity is a\nfundamental challenge in computational neuroscience, complicated by partial\nobservability and mismatches between inference models and true circuit\ndynamics. In this study, we propose a graph-based neural inference model that\nsimultaneously predicts neural activity and infers latent connectivity by\nmodeling neurons as interacting nodes in a graph. The architecture features two\ndistinct modules: one for learning structural connectivity and another for\npredicting future spiking activity via a graph neural network (GNN). Our model\naccommodates unobserved neurons through auxiliary nodes, allowing for inference\nin partially observed circuits. We evaluate this approach using synthetic data\nfrom ring attractor networks and real spike recordings from head direction\ncells in mice. Across a wide range of conditions, including varying recurrent\nconnectivity, external inputs, and incomplete observations, our model\nconsistently outperforms standard baselines, resolving spurious correlations\nmore effectively and recovering accurate weight profiles. When applied to real\ndata, the inferred connectivity aligns with theoretical predictions of\ncontinuous attractor models. These results highlight the potential of GNN-based\nmodels to infer latent neural circuitry through self-supervised structure\nlearning, while leveraging the spike prediction task to flexibly link\nconnectivity and dynamics across both simulated and biological neural systems."}
{"id": "2509.17177", "pdf": "https://arxiv.org/pdf/2509.17177", "abs": "https://arxiv.org/abs/2509.17177", "authors": ["Bowen Qin", "Chen Yue", "Fang Yin", "Hui Wang", "JG Yao", "Jiakang Liu", "Jing-Shu Zheng", "Miguel Hu Chen", "Richeng Xuan", "Shibei Meng", "Shiqi Zhou", "Teng Dai", "Tong-Shuai Ren", "Wei Cui", "Xi Yang", "Xialin Du", "Xiaojing Xu", "Xue Sun", "Xuejing Li", "Yaming Liu", "Yesheng Liu", "Ying Liu", "Yonghua Lin", "Yu Zhao", "Yunduo Zhang", "Yuwen Luo", "Zheqi He", "Zhiyuan He", "Zhongyuan Wang"], "title": "FlagEval Findings Report: A Preliminary Evaluation of Large Reasoning Models on Automatically Verifiable Textual and Visual Questions", "categories": ["cs.CL", "cs.CV", "cs.LG"], "comment": "23 pages in main text", "summary": "We conduct a moderate-scale contamination-free (to some extent) evaluation of\ncurrent large reasoning models (LRMs) with some preliminary findings. We also\nrelease ROME, our evaluation benchmark for vision language models intended to\ntest reasoning from visual clues. We attach links to the benchmark, evaluation\ndata, and other updates on this website:\nhttps://flageval-baai.github.io/LRM-Eval/"}
{"id": "2509.17183", "pdf": "https://arxiv.org/pdf/2509.17183", "abs": "https://arxiv.org/abs/2509.17183", "authors": ["Junsong Li", "Jie Zhou", "Bihao Zhan", "Yutao Yang", "Qianjun Pan", "Shilian Chen", "Tianyu Huai", "Xin Li", "Qin Chen", "Liang He"], "title": "LifeAlign: Lifelong Alignment for Large Language Models with Memory-Augmented Focalized Preference Optimization", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Alignment plays a crucial role in Large Language Models (LLMs) in aligning\nwith human preferences on a specific task/domain. Traditional alignment methods\nsuffer from catastrophic forgetting, where models lose previously acquired\nknowledge when adapting to new preferences or domains. We introduce LifeAlign,\na novel framework for lifelong alignment that enables LLMs to maintain\nconsistent human preference alignment across sequential learning tasks without\nforgetting previously learned knowledge. Our approach consists of two key\ninnovations. First, we propose a focalized preference optimization strategy\nthat aligns LLMs with new preferences while preventing the erosion of knowledge\nacquired from previous tasks. Second, we develop a short-to-long memory\nconsolidation mechanism that merges denoised short-term preference\nrepresentations into stable long-term memory using intrinsic dimensionality\nreduction, enabling efficient storage and retrieval of alignment patterns\nacross diverse domains. We evaluate LifeAlign across multiple sequential\nalignment tasks spanning different domains and preference types. Experimental\nresults demonstrate that our method achieves superior performance in\nmaintaining both preference alignment quality and knowledge retention compared\nto existing lifelong learning approaches. The codes and datasets will be\nreleased on GitHub."}
{"id": "2509.17206", "pdf": "https://arxiv.org/pdf/2509.17206", "abs": "https://arxiv.org/abs/2509.17206", "authors": ["Gunner Stone", "Sushmita Sarker", "Alireza Tavakkoli"], "title": "Guided and Unguided Conditional Diffusion Mechanisms for Structured and Semantically-Aware 3D Point Cloud Generation", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Generating realistic 3D point clouds is a fundamental problem in computer\nvision with applications in remote sensing, robotics, and digital object\nmodeling. Existing generative approaches primarily capture geometry, and when\nsemantics are considered, they are typically imposed post hoc through external\nsegmentation or clustering rather than integrated into the generative process\nitself. We propose a diffusion-based framework that embeds per-point semantic\nconditioning directly within generation. Each point is associated with a\nconditional variable corresponding to its semantic label, which guides the\ndiffusion dynamics and enables the joint synthesis of geometry and semantics.\nThis design produces point clouds that are both structurally coherent and\nsegmentation-aware, with object parts explicitly represented during synthesis.\nThrough a comparative analysis of guided and unguided diffusion processes, we\ndemonstrate the significant impact of conditional variables on diffusion\ndynamics and generation quality. Extensive experiments validate the efficacy of\nour approach, producing detailed and accurate 3D point clouds tailored to\nspecific parts and features."}
{"id": "2509.17207", "pdf": "https://arxiv.org/pdf/2509.17207", "abs": "https://arxiv.org/abs/2509.17207", "authors": ["Gunner Stone", "Youngsook Choi", "Alireza Tavakkoli", "Ankita Shukla"], "title": "Point-RTD: Replaced Token Denoising for Pretraining Transformer Models on Point Clouds", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Pre-training strategies play a critical role in advancing the performance of\ntransformer-based models for 3D point cloud tasks. In this paper, we introduce\nPoint-RTD (Replaced Token Denoising), a novel pretraining strategy designed to\nimprove token robustness through a corruption-reconstruction framework. Unlike\ntraditional mask-based reconstruction tasks that hide data segments for later\nprediction, Point-RTD corrupts point cloud tokens and leverages a\ndiscriminator-generator architecture for denoising. This shift enables more\neffective learning of structural priors and significantly enhances model\nperformance and efficiency. On the ShapeNet dataset, Point-RTD reduces\nreconstruction error by over 93% compared to PointMAE, and achieves more than\n14x lower Chamfer Distance on the test set. Our method also converges faster\nand yields higher classification accuracy on ShapeNet, ModelNet10, and\nModelNet40 benchmarks, clearly outperforming the baseline Point-MAE framework\nin every case."}
{"id": "2509.17219", "pdf": "https://arxiv.org/pdf/2509.17219", "abs": "https://arxiv.org/abs/2509.17219", "authors": ["Matthieu Cervera", "Francesco Paissan", "Mirco Ravanelli", "Cem Subakan"], "title": "Virtual Consistency for Audio Editing", "categories": ["cs.SD", "cs.LG"], "comment": null, "summary": "Free-form, text-based audio editing remains a persistent challenge, despite\nprogress in inversion-based neural methods. Current approaches rely on slow\ninversion procedures, limiting their practicality. We present a\nvirtual-consistency based audio editing system that bypasses inversion by\nadapting the sampling process of diffusion models. Our pipeline is\nmodel-agnostic, requiring no fine-tuning or architectural changes, and achieves\nsubstantial speed-ups over recent neural editing baselines. Crucially, it\nachieves this efficiency without compromising quality, as demonstrated by\nquantitative benchmarks and a user study involving 16 participants."}
{"id": "2509.17224", "pdf": "https://arxiv.org/pdf/2509.17224", "abs": "https://arxiv.org/abs/2509.17224", "authors": ["Bowen Jing", "Bonnie Berger", "Tommi Jaakkola"], "title": "AI-based Methods for Simulating, Sampling, and Predicting Protein Ensembles", "categories": ["q-bio.BM", "cs.LG", "physics.bio-ph"], "comment": null, "summary": "Advances in deep learning have opened an era of abundant and accurate\npredicted protein structures; however, similar progress in protein ensembles\nhas remained elusive. This review highlights several recent research directions\ntowards AI-based predictions of protein ensembles, including coarse-grained\nforce fields, generative models, multiple sequence alignment perturbation\nmethods, and modeling of ensemble descriptors. An emphasis is placed on\nrealistic assessments of the technological maturity of current methods, the\nstrengths and weaknesses of broad families of techniques, and promising machine\nlearning frameworks at an early stage of development. We advocate for \"closing\nthe loop\" between model training, simulation, and inference to overcome\nchallenges in training data availability and to enable the next generation of\nmodels."}
{"id": "2509.17238", "pdf": "https://arxiv.org/pdf/2509.17238", "abs": "https://arxiv.org/abs/2509.17238", "authors": ["Soheil Zibakhsh", "Mohammad Samragh", "Kumari Nishu", "Lauren Hannah", "Arnav Kundu", "Minsik Cho"], "title": "MoEs Are Stronger than You Think: Hyper-Parallel Inference Scaling with RoE", "categories": ["cs.AI", "cs.CL", "cs.ET", "cs.LG"], "comment": null, "summary": "The generation quality of large language models (LLMs) is often improved by\nutilizing inference-time sequence-level scaling methods (e.g.,\nChain-of-Thought). We introduce hyper-parallel scaling, a complementary\nframework that improves prediction quality at the token level. Hyper-parallel\nscaling computes and aggregates multiple output proposals for a single token\nfrom the model. We implement this concept in Mixture-of-Experts (MoE) models,\nwhich we refer to as Roster of Experts (RoE). RoE is a training-free inference\nalgorithm that turns a single MoE into a dynamic ensemble of MoEs. RoE injects\ncontrolled stochasticity into the expert routing mechanism, enabling it to\nsample multiple diverse experts for each token and aggregate their outputs for\na more accurate final prediction.To overcome the computational cost, we\nintroduce an efficient batching strategy and a specialized KV-caching mechanism\nthat minimizes compute and memory overhead. For example, RoE enables a 7B MoE\nmodel to match the performance of a 10.5B MoE model while using 30% less\ncompute for inference. These gains are achieved without any fine-tuning of\nmodel parameters."}
{"id": "2509.17240", "pdf": "https://arxiv.org/pdf/2509.17240", "abs": "https://arxiv.org/abs/2509.17240", "authors": ["Abdullah Mushtaq", "Muhammad Rafay Naeem", "Ibrahim Ghaznavi", "Alaa Abd-alrazaq", "Aliya Tabassum", "Junaid Qadir"], "title": "Can Agents Judge Systematic Reviews Like Humans? Evaluating SLRs with LLM-based Multi-Agent System", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA"], "comment": null, "summary": "Systematic Literature Reviews (SLRs) are foundational to evidence-based\nresearch but remain labor-intensive and prone to inconsistency across\ndisciplines. We present an LLM-based SLR evaluation copilot built on a\nMulti-Agent System (MAS) architecture to assist researchers in assessing the\noverall quality of the systematic literature reviews. The system automates\nprotocol validation, methodological assessment, and topic relevance checks\nusing a scholarly database. Unlike conventional single-agent methods, our\ndesign integrates a specialized agentic approach aligned with PRISMA guidelines\nto support more structured and interpretable evaluations. We conducted an\ninitial study on five published SLRs from diverse domains, comparing system\noutputs to expert-annotated PRISMA scores, and observed 84% agreement. While\nearly results are promising, this work represents a first step toward scalable\nand accurate NLP-driven systems for interdisciplinary workflows and reveals\ntheir capacity for rigorous, domain-agnostic knowledge aggregation to\nstreamline the review process."}
{"id": "2509.17251", "pdf": "https://arxiv.org/pdf/2509.17251", "abs": "https://arxiv.org/abs/2509.17251", "authors": ["Jingfeng Wu", "Peter L. Bartlett", "Jason D. Lee", "Sham M. Kakade", "Bin Yu"], "title": "Risk Comparisons in Linear Regression: Implicit Regularization Dominates Explicit Regularization", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Existing theory suggests that for linear regression problems categorized by\ncapacity and source conditions, gradient descent (GD) is always minimax\noptimal, while both ridge regression and online stochastic gradient descent\n(SGD) are polynomially suboptimal for certain categories of such problems.\nMoving beyond minimax theory, this work provides instance-wise comparisons of\nthe finite-sample risks for these algorithms on any well-specified linear\nregression problem.\n  Our analysis yields three key findings. First, GD dominates ridge regression:\nwith comparable regularization, the excess risk of GD is always within a\nconstant factor of ridge, but ridge can be polynomially worse even when tuned\noptimally. Second, GD is incomparable with SGD. While it is known that for\ncertain problems GD can be polynomially better than SGD, the reverse is also\ntrue: we construct problems, inspired by benign overfitting theory, where\noptimally stopped GD is polynomially worse. Finally, GD dominates SGD for a\nsignificant subclass of problems -- those with fast and continuously decaying\ncovariance spectra -- which includes all problems satisfying the standard\ncapacity condition."}
{"id": "2509.17274", "pdf": "https://arxiv.org/pdf/2509.17274", "abs": "https://arxiv.org/abs/2509.17274", "authors": ["Alexandros Ntagkas", "Constantinos Tsakonas", "Chairi Kiourt", "Konstantinos Chatzilygeroudis"], "title": "Learning and Optimization with 3D Orientations", "categories": ["cs.RO", "cs.LG", "math.OC"], "comment": "9 pages, 11 figures", "summary": "There exist numerous ways of representing 3D orientations. Each\nrepresentation has both limitations and unique features. Choosing the best\nrepresentation for one task is often a difficult chore, and there exist\nconflicting opinions on which representation is better suited for a set of\nfamily of tasks. Even worse, when dealing with scenarios where we need to learn\nor optimize functions with orientations as inputs and/or outputs, the set of\npossibilities (representations, loss functions, etc.) is even larger and it is\nnot easy to decide what is best for each scenario. In this paper, we attempt to\na) present clearly, concisely and with unified notation all available\nrepresentations, and \"tricks\" related to 3D orientations (including Lie Group\nalgebra), and b) benchmark them in representative scenarios. The first part\nfeels like it is missing from the robotics literature as one has to read many\ndifferent textbooks and papers in order have a concise and clear understanding\nof all possibilities, while the benchmark is necessary in order to come up with\nrecommendations based on empirical evidence. More precisely, we experiment with\nthe following settings that attempt to cover most widely used scenarios in\nrobotics: 1) direct optimization, 2) imitation/supervised learning with a\nneural network controller, 3) reinforcement learning, and 4) trajectory\noptimization using differential dynamic programming. We finally provide\nguidelines depending on the scenario, and make available a reference\nimplementation of all the orientation math described."}
{"id": "2509.17276", "pdf": "https://arxiv.org/pdf/2509.17276", "abs": "https://arxiv.org/abs/2509.17276", "authors": ["Runjia Zeng", "James Chenhao Liang", "Cheng Han", "Zhiwen Cao", "Jiahao Liu", "Xiaojun Quan", "Yingjie Victor Chen", "Lifu Huang", "Tong Geng", "Qifan Wang", "Dongfang Liu"], "title": "Probabilistic Token Alignment for Large Language Model Fusion", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "NeurIPS 2025", "summary": "Training large language models (LLMs) from scratch can yield models with\nunique functionalities and strengths, but it is costly and often leads to\nredundant capabilities. A more cost-effective alternative is to fuse existing\npre-trained LLMs with different architectures into a more powerful model.\nHowever, a key challenge in existing model fusion is their dependence on\nmanually predefined vocabulary alignment, which may not generalize well across\ndiverse contexts, leading to performance degradation in several evaluation. To\nsolve this, we draw inspiration from distribution learning and propose the\nprobabilistic token alignment method as a general and soft mapping for\nalignment, named as PTA-LLM. Our approach innovatively reformulates token\nalignment into a classic mathematical problem: optimal transport, seamlessly\nleveraging distribution-aware learning to facilitate more coherent model\nfusion. Apart from its inherent generality, PTA-LLM exhibits interpretability\nfrom a distributional perspective, offering insights into the essence of the\ntoken alignment. Empirical results demonstrate that probabilistic token\nalignment enhances the target model's performance across multiple capabilities.\nOur code is avaliable at https://runjia.tech/neurips_pta-llm/."}
{"id": "2509.17314", "pdf": "https://arxiv.org/pdf/2509.17314", "abs": "https://arxiv.org/abs/2509.17314", "authors": ["Juyeon Yoon", "Somin Kim", "Robert Feldt", "Shin Yoo"], "title": "Clotho: Measuring Task-Specific Pre-Generation Test Adequacy for LLM Inputs", "categories": ["cs.SE", "cs.LG"], "comment": null, "summary": "Software increasingly relies on the emergent capabilities of Large Language\nModels (LLMs), from natural language understanding to program analysis and\ngeneration. Yet testing them on specific tasks remains difficult and costly:\nmany prompts lack ground truth, forcing reliance on human judgment, while\nexisting uncertainty and adequacy measures typically require full inference. A\nkey challenge is to assess input adequacy in a way that reflects the demands of\nthe task, ideally before even generating any output. We introduce CLOTHO, a\ntask-specific, pre-generation adequacy measure that estimates input difficulty\ndirectly from hidden LLM states. Given a large pool of unlabelled inputs for a\nspecific task, CLOTHO uses a Gaussian Mixture Model (GMM) to adaptively sample\nthe most informative cases for human labelling. Based on this reference set the\nGMM can then rank unseen inputs by their likelihood of failure. In our\nempirical evaluation across eight benchmark tasks and three open-weight LLMs,\nCLOTHO can predict failures with a ROC-AUC of 0.716, after labelling reference\nsets that are on average only 5.4% of inputs. It does so without generating any\noutputs, thereby reducing costs compared to existing uncertainty measures.\nComparison of CLOTHO and post-generation uncertainty measures shows that the\ntwo approaches complement each other. Crucially, we show that adequacy scores\nlearnt from open-weight LLMs transfer effectively to proprietary models,\nextending the applicability of the approach. When prioritising test inputs for\nproprietary models, CLOTHO increases the average number of failing inputs from\n18.7 to 42.5 out of 100, compared to random prioritisation."}
{"id": "2509.17318", "pdf": "https://arxiv.org/pdf/2509.17318", "abs": "https://arxiv.org/abs/2509.17318", "authors": ["Zhuofan Chen", "Jiyuan He", "Yichi Zhang", "Xing Hu", "Haoxing Wen", "Jun Bai", "Wenge Rong"], "title": "CogAtom: From Cognitive Atoms to Olympiad-level Mathematical Reasoning in Large Language Models", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Mathematical reasoning poses significant challenges for Large Language Models\n(LLMs) due to its demand for multi-step reasoning and abstract conceptual\nintegration. While recent test-time scaling techniques rely heavily on\nhigh-quality, challenging problems, the scarcity of Olympiad-level math\nproblems remains a bottleneck. We introduce CogAtom, a novel cognitive\natom-based framework for synthesizing mathematically rigorous and cognitively\ndiverse problems. Unlike prior approaches, CogAtom models problem construction\nas a process of selecting and recombining fundamental reasoning units,\ncognitive atoms, extracted from human-authored solutions. A diversity-promoting\nrandom walk algorithm enables exploration of the cognitive atom space, while a\nconstraint-based recombination mechanism ensures logical soundness and\nstructural validity. The combinatorial nature of the graph structure provides a\nnear-infinite space of reasoning paths, and the walk algorithm systematically\nexplores this space to achieve large-scale synthesis of high-quality problems;\nmeanwhile, by controlling the number of cognitive atoms, we can precisely\nadjust problem difficulty, ensuring diversity, scalability, and controllability\nof the generated problems. Experimental results demonstrate that CogAtom\noutperforms existing methods in accuracy, reasoning depth, and diversity,\ngenerating problems that closely match the difficulty of AIME while exceeding\nit in structural variation. Our work offers a cognitively grounded pathway\ntoward scalable, high-quality math problem generation.Our code is publicly\navailable at https://github.com/Icarus-1111/CogAtom."}
{"id": "2509.17324", "pdf": "https://arxiv.org/pdf/2509.17324", "abs": "https://arxiv.org/abs/2509.17324", "authors": ["Chi Zhang", "Mengxin Zheng", "Qian Lou", "Fan Chen"], "title": "DiffQ: Unified Parameter Initialization for Variational Quantum Algorithms via Diffusion Models", "categories": ["cs.ET", "cs.LG", "quant-ph"], "comment": null, "summary": "Variational Quantum Algorithms (VQAs) are widely used in the noisy\nintermediate-scale quantum (NISQ) era, but their trainability and performance\ndepend critically on initialization parameters that shape the optimization\nlandscape. Existing machine learning-based initializers achieve\nstate-of-the-art results yet remain constrained to single-task domains and\nsmall datasets of only hundreds of samples. We address these limitations by\nreformulating VQA parameter initialization as a generative modeling problem and\nintroducing DiffQ, a parameter initializer based on the Denoising Diffusion\nProbabilistic Model (DDPM). To support robust training and evaluation, we\nconstruct a dataset of 15,085 instances spanning three domains and five\nrepresentative tasks. Experiments demonstrate that DiffQ surpasses baselines,\nreducing initial loss by up to 8.95 and convergence steps by up to 23.4%."}
{"id": "2509.17333", "pdf": "https://arxiv.org/pdf/2509.17333", "abs": "https://arxiv.org/abs/2509.17333", "authors": ["Minglai Yang", "Reyan Ahmed"], "title": "Word2VecGD: Neural Graph Drawing with Cosine-Stress Optimization", "categories": ["cs.CG", "cs.LG"], "comment": null, "summary": "We propose a novel graph visualization method leveraging random walk-based\nembeddings to replace costly graph-theoretical distance computations. Using\nword2vec-inspired embeddings, our approach captures both structural and\nsemantic relationships efficiently. Instead of relying on exact shortest-path\ndistances, we optimize layouts using cosine dissimilarities, significantly\nreducing computational overhead. Our framework integrates differentiable stress\noptimization with stochastic gradient descent (SGD), supporting multi-criteria\nlayout objectives. Experimental results demonstrate that our method produces\nhigh-quality, semantically meaningful layouts while efficiently scaling to\nlarge graphs. Code available at: https://github.com/mlyann/graphv_nn"}
{"id": "2509.17334", "pdf": "https://arxiv.org/pdf/2509.17334", "abs": "https://arxiv.org/abs/2509.17334", "authors": ["Jiawen Wei", "Elena Verona", "Andrea Bertolini", "Gianmarco Mengaldo"], "title": "Explainability matters: The effect of liability rules on the healthcare sector", "categories": ["cs.CY", "cs.AI", "cs.CE", "cs.LG"], "comment": null, "summary": "Explainability, the capability of an artificial intelligence system (AIS) to\nexplain its outcomes in a manner that is comprehensible to human beings at an\nacceptable level, has been deemed essential for critical sectors, such as\nhealthcare. Is it really the case? In this perspective, we consider two extreme\ncases, ``Oracle'' (without explainability) versus ``AI Colleague'' (with\nexplainability) for a thorough analysis. We discuss how the level of automation\nand explainability of AIS can affect the determination of liability among the\nmedical practitioner/facility and manufacturer of AIS. We argue that\nexplainability plays a crucial role in setting a responsibility framework in\nhealthcare, from a legal standpoint, to shape the behavior of all involved\nparties and mitigate the risk of potential defensive medicine practices."}
{"id": "2509.17354", "pdf": "https://arxiv.org/pdf/2509.17354", "abs": "https://arxiv.org/abs/2509.17354", "authors": ["Jiazhao Shi", "Yichen Lin", "Yiheng Hua", "Ziyu Wang", "Zijian Zhang", "Wenjia Zheng", "Yun Song", "Kuan Lu", "Shoufeng Lu"], "title": "Multi-Scenario Highway Lane-Change Intention Prediction: A Physics-Informed AI Framework for Three-Class Classification", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Lane-change maneuvers are a leading cause of highway accidents, underscoring\nthe need for accurate intention prediction to improve the safety and\ndecision-making of autonomous driving systems. While prior studies using\nmachine learning and deep learning methods (e.g., SVM, CNN, LSTM, Transformers)\nhave shown promise, most approaches remain limited by binary classification,\nlack of scenario diversity, and degraded performance under longer prediction\nhorizons. In this study, we propose a physics-informed AI framework that\nexplicitly integrates vehicle kinematics, interaction feasibility, and\ntraffic-safety metrics (e.g., distance headway, time headway,\ntime-to-collision, closing gap time) into the learning process. lane-change\nprediction is formulated as a three-class problem that distinguishes left\nchange, right change, and no change, and is evaluated across both straight\nhighway segments (highD) and complex ramp scenarios (exiD). By integrating\nvehicle kinematics with interaction features, our machine learning models,\nparticularly LightGBM, achieve state-of-the-art accuracy and strong\ngeneralization. Results show up to 99.8% accuracy and 93.6% macro F1 on highD,\nand 96.1% accuracy and 88.7% macro F1 on exiD at a 1-second horizon,\noutperforming a two-layer stacked LSTM baseline. These findings demonstrate the\npractical advantages of a physics-informed and feature-rich machine learning\nframework for real-time lane-change intention prediction in autonomous driving\nsystems."}
{"id": "2509.17371", "pdf": "https://arxiv.org/pdf/2509.17371", "abs": "https://arxiv.org/abs/2509.17371", "authors": ["Haotian Xu", "Qingsong Peng", "Jie Shi", "Huadi Zheng", "Yu Li", "Cheng Zhuo"], "title": "SilentStriker:Toward Stealthy Bit-Flip Attacks on Large Language Models", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "The rapid adoption of large language models (LLMs) in critical domains has\nspurred extensive research into their security issues. While input manipulation\nattacks (e.g., prompt injection) have been well studied, Bit-Flip Attacks\n(BFAs) -- which exploit hardware vulnerabilities to corrupt model parameters\nand cause severe performance degradation -- have received far less attention.\nExisting BFA methods suffer from key limitations: they fail to balance\nperformance degradation and output naturalness, making them prone to discovery.\nIn this paper, we introduce SilentStriker, the first stealthy bit-flip attack\nagainst LLMs that effectively degrades task performance while maintaining\noutput naturalness. Our core contribution lies in addressing the challenge of\ndesigning effective loss functions for LLMs with variable output length and the\nvast output space. Unlike prior approaches that rely on output perplexity for\nattack loss formulation, which inevitably degrade output naturalness, we\nreformulate the attack objective by leveraging key output tokens as targets for\nsuppression, enabling effective joint optimization of attack effectiveness and\nstealthiness. Additionally, we employ an iterative, progressive search strategy\nto maximize attack efficacy. Experiments show that SilentStriker significantly\noutperforms existing baselines, achieving successful attacks without\ncompromising the naturalness of generated text."}
{"id": "2509.17382", "pdf": "https://arxiv.org/pdf/2509.17382", "abs": "https://arxiv.org/abs/2509.17382", "authors": ["Shivam Kumar", "Haotian Xu", "Carlos Misael Madrid Padilla", "Yuehaw Khoo", "Oscar Hernan Madrid Padilla", "Daren Wang"], "title": "Bias-variance Tradeoff in Tensor Estimation", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.ME", "stat.TH"], "comment": null, "summary": "We study denoising of a third-order tensor when the ground-truth tensor is\nnot necessarily Tucker low-rank. Specifically, we observe $$ Y=X^\\ast+Z\\in\n\\mathbb{R}^{p_{1} \\times p_{2} \\times p_{3}}, $$ where $X^\\ast$ is the\nground-truth tensor, and $Z$ is the noise tensor. We propose a simple variant\nof the higher-order tensor SVD estimator $\\widetilde{X}$. We show that\nuniformly over all user-specified Tucker ranks $(r_{1},r_{2},r_{3})$, $$ \\|\n\\widetilde{X} - X^* \\|_{ \\mathrm{F}}^2 = O \\Big( \\kappa^2 \\Big\\{\nr_{1}r_{2}r_{3}+\\sum_{k=1}^{3} p_{k} r_{k} \\Big\\} \\; + \\;\n\\xi_{(r_{1},r_{2},r_{3})}^2\\Big) \\quad \\text{ with high probability.} $$ Here,\nthe bias term $\\xi_{(r_1,r_2,r_3)}$ corresponds to the best achievable\napproximation error of $X^\\ast$ over the class of tensors with Tucker ranks\n$(r_1,r_2,r_3)$; $\\kappa^2$ quantifies the noise level; and the variance term\n$\\kappa^2 \\{r_{1}r_{2}r_{3}+\\sum_{k=1}^{3} p_{k} r_{k}\\}$ scales with the\neffective number of free parameters in the estimator $\\widetilde{X}$. Our\nanalysis achieves a clean rank-adaptive bias--variance tradeoff: as we increase\nthe ranks of estimator $\\widetilde{X}$, the bias $\\xi(r_{1},r_{2},r_{3})$\ndecreases and the variance increases. As a byproduct we also obtain a\nconvenient bias-variance decomposition for the vanilla low-rank SVD matrix\nestimators."}
{"id": "2509.17411", "pdf": "https://arxiv.org/pdf/2509.17411", "abs": "https://arxiv.org/abs/2509.17411", "authors": ["Siqi Li", "Molei Liu", "Ziye Tian", "Chuan Hong", "Nan Liu"], "title": "Robust Mixture Models for Algorithmic Fairness Under Latent Heterogeneity", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Standard machine learning models optimized for average performance often fail\non minority subgroups and lack robustness to distribution shifts. This\nchallenge worsens when subgroups are latent and affected by complex\ninteractions among continuous and discrete features. We introduce ROME (RObust\nMixture Ensemble), a framework that learns latent group structure from data\nwhile optimizing for worst-group performance. ROME employs two approaches: an\nExpectation-Maximization algorithm for linear models and a neural\nMixture-of-Experts for nonlinear settings. Through simulations and experiments\non real-world datasets, we demonstrate that ROME significantly improves\nalgorithmic fairness compared to standard methods while maintaining competitive\naverage performance. Importantly, our method requires no predefined group\nlabels, making it practical when sources of disparities are unknown or\nevolving."}
{"id": "2509.17439", "pdf": "https://arxiv.org/pdf/2509.17439", "abs": "https://arxiv.org/abs/2509.17439", "authors": ["Yangxuan Zhou", "Sha Zhao", "Jiquan Wang", "Haiteng Jiang", "Shijian Li", "Tao Li", "Gang Pan"], "title": "SPICED: A Synaptic Homeostasis-Inspired Framework for Unsupervised Continual EEG Decoding", "categories": ["cs.AI", "cs.LG"], "comment": "21 pages, 13 figures", "summary": "Human brain achieves dynamic stability-plasticity balance through synaptic\nhomeostasis. Inspired by this biological principle, we propose SPICED: a\nneuromorphic framework that integrates the synaptic homeostasis mechanism for\nunsupervised continual EEG decoding, particularly addressing practical\nscenarios where new individuals with inter-individual variability emerge\ncontinually. SPICED comprises a novel synaptic network that enables dynamic\nexpansion during continual adaptation through three bio-inspired neural\nmechanisms: (1) critical memory reactivation; (2) synaptic consolidation and\n(3) synaptic renormalization. The interplay within synaptic homeostasis\ndynamically strengthens task-discriminative memory traces and weakens\ndetrimental memories. By integrating these mechanisms with continual learning\nsystem, SPICED preferentially replays task-discriminative memory traces that\nexhibit strong associations with newly emerging individuals, thereby achieving\nrobust adaptations. Meanwhile, SPICED effectively mitigates catastrophic\nforgetting by suppressing the replay prioritization of detrimental memories\nduring long-term continual learning. Validated on three EEG datasets, SPICED\nshow its effectiveness."}
{"id": "2509.17460", "pdf": "https://arxiv.org/pdf/2509.17460", "abs": "https://arxiv.org/abs/2509.17460", "authors": ["Jianlong Chang", "Haixin Wang", "Zhiyuan Dang", "Li Huang", "Zhiyu Wang", "Ruoqi Cao", "Shihao Piao", "Dongzhe Li", "Dianyu Gao", "Dongsheng Wang", "Yin Li", "Jinan Sun", "Lu Fang", "Zhouchen Lin"], "title": "AI Pangaea: Unifying Intelligence Islands for Adapting Myriad Tasks", "categories": ["cs.AI", "cs.LG"], "comment": "65 pages, 28 figures, paper under review", "summary": "The pursuit of artificial general intelligence continuously demands\ngeneralization in one model across myriad tasks, even those not seen before.\nHowever, current AI models are isolated from each other for being limited to\nspecific tasks, now first defined as Intelligence Islands. To unify\nIntelligence Islands into one, we propose Pangaea, the first AI supercontinent\nakin to the geological Pangaea. Pangaea encodes any data into a unified format\nand accumulates universal knowledge through pre-training on 296 datasets across\ndiverse modalities. Eventually, it demonstrates remarkable generalization\nacross 45 general tasks and 15 scientific tasks encompassing a wide range of\nscientific subjects. By investigating Pangaea deeper, the scaling effect of\nmodality is revealed, quantifying the universal knowledge accumulation across\nmodalities as the cumulative distribution function of a geometric distribution.\nOn the whole, Pangaea shows strong potential to handle myriad tasks, indicating\na new direction toward artificial general intelligence."}
{"id": "2509.17470", "pdf": "https://arxiv.org/pdf/2509.17470", "abs": "https://arxiv.org/abs/2509.17470", "authors": ["Mohammadreza Sharifi", "Danial Ahmadzadeh"], "title": "Transformer-Gather, Fuzzy-Reconsider: A Scalable Hybrid Framework for Entity Resolution", "categories": ["cs.DB", "cs.AI", "cs.LG"], "comment": "Accepted at ICCKE 2025 Conference. 6 tables, 7 figures", "summary": "Entity resolution plays a significant role in enterprise systems where data\nintegrity must be rigorously maintained. Traditional methods often struggle\nwith handling noisy data or semantic understanding, while modern methods suffer\nfrom computational costs or the excessive need for parallel computation. In\nthis study, we introduce a scalable hybrid framework, which is designed to\naddress several important problems, including scalability, noise robustness,\nand reliable results. We utilized a pre-trained language model to encode each\nstructured data into corresponding semantic embedding vectors. Subsequently,\nafter retrieving a semantically relevant subset of candidates, we apply a\nsyntactic verification stage using fuzzy string matching techniques to refine\nclassification on the unlabeled data. This approach was applied to a real-world\nentity resolution task, which exposed a linkage between a central user\nmanagement database and numerous shared hosting server records. Compared to\nother methods, this approach exhibits an outstanding performance in terms of\nboth processing time and robustness, making it a reliable solution for a\nserver-side product. Crucially, this efficiency does not compromise results, as\nthe system maintains a high retrieval recall of approximately 0.97. The\nscalability of the framework makes it deployable on standard CPU-based\ninfrastructure, offering a practical and effective solution for\nenterprise-level data integrity auditing."}
{"id": "2509.17533", "pdf": "https://arxiv.org/pdf/2509.17533", "abs": "https://arxiv.org/abs/2509.17533", "authors": ["Anastasios Fanariotis", "Theofanis Orphanoudakis", "Vasilis Fotopoulos"], "title": "Evaluating the Energy Efficiency of NPU-Accelerated Machine Learning Inference on Embedded Microcontrollers", "categories": ["cs.ET", "cs.AI", "cs.LG"], "comment": null, "summary": "The deployment of machine learning (ML) models on microcontrollers (MCUs) is\nconstrained by strict energy, latency, and memory requirements, particularly in\nbattery-operated and real-time edge devices. While software-level optimizations\nsuch as quantization and pruning reduce model size and computation, hardware\nacceleration has emerged as a decisive enabler for efficient embedded\ninference. This paper evaluates the impact of Neural Processing Units (NPUs) on\nMCU-based ML execution, using the ARM Cortex-M55 core combined with the\nEthos-U55 NPU on the Alif Semiconductor Ensemble E7 development board as a\nrepresentative platform. A rigorous measurement methodology was employed,\nincorporating per-inference net energy accounting via GPIO-triggered\nhigh-resolution digital multimeter synchronization and idle-state subtraction,\nensuring accurate attribution of energy costs. Experimental results across six\nrepresentative ML models -including MiniResNet, MobileNetV2, FD-MobileNet,\nMNIST, TinyYolo, and SSD-MobileNet- demonstrate substantial efficiency gains\nwhen inference is offloaded to the NPU. For moderate to large networks, latency\nimprovements ranged from 7x to over 125x, with per-inference net energy\nreductions up to 143x. Notably, the NPU enabled execution of models unsupported\non CPU-only paths, such as SSD-MobileNet, highlighting its functional as well\nas efficiency advantages. These findings establish NPUs as a cornerstone of\nenergy-aware embedded AI, enabling real-time, power-constrained ML inference at\nthe MCU level."}
{"id": "2509.17543", "pdf": "https://arxiv.org/pdf/2509.17543", "abs": "https://arxiv.org/abs/2509.17543", "authors": ["Dominic Broadbent", "Nick Whiteley", "Robert Allison", "Tom Lovett"], "title": "Bilateral Distribution Compression: Reducing Both Data Size and Dimensionality", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": "43 pages, 20 figures", "summary": "Existing distribution compression methods reduce dataset size by minimising\nthe Maximum Mean Discrepancy (MMD) between original and compressed sets, but\nmodern datasets are often large in both sample size and dimensionality. We\npropose Bilateral Distribution Compression (BDC), a two-stage framework that\ncompresses along both axes while preserving the underlying distribution, with\noverall linear time and memory complexity in dataset size and dimension.\nCentral to BDC is the Decoded MMD (DMMD), which quantifies the discrepancy\nbetween the original data and a compressed set decoded from a low-dimensional\nlatent space. BDC proceeds by (i) learning a low-dimensional projection using\nthe Reconstruction MMD (RMMD), and (ii) optimising a latent compressed set with\nthe Encoded MMD (EMMD). We show that this procedure minimises the DMMD,\nguaranteeing that the compressed set faithfully represents the original\ndistribution. Experiments show that across a variety of scenarios BDC can\nachieve comparable or superior performance to ambient-space compression at\nsubstantially lower cost."}
{"id": "2509.17550", "pdf": "https://arxiv.org/pdf/2509.17550", "abs": "https://arxiv.org/abs/2509.17550", "authors": ["Neslihan Kose", "Anthony Rhodes", "Umur Aybars Ciftci", "Ilke Demir"], "title": "Is It Certainly a Deepfake? Reliability Analysis in Detection & Generation Ecosystem", "categories": ["cs.AI", "cs.CV", "cs.LG"], "comment": "Accepted for publication at the ICCV 2025 STREAM workshop", "summary": "As generative models are advancing in quality and quantity for creating\nsynthetic content, deepfakes begin to cause online mistrust. Deepfake detectors\nare proposed to counter this effect, however, misuse of detectors claiming fake\ncontent as real or vice versa further fuels this misinformation problem. We\npresent the first comprehensive uncertainty analysis of deepfake detectors,\nsystematically investigating how generative artifacts influence prediction\nconfidence. As reflected in detectors' responses, deepfake generators also\ncontribute to this uncertainty as their generative residues vary, so we cross\nthe uncertainty analysis of deepfake detectors and generators. Based on our\nobservations, the uncertainty manifold holds enough consistent information to\nleverage uncertainty for deepfake source detection. Our approach leverages\nBayesian Neural Networks and Monte Carlo dropout to quantify both aleatoric and\nepistemic uncertainties across diverse detector architectures. We evaluate\nuncertainty on two datasets with nine generators, with four blind and two\nbiological detectors, compare different uncertainty methods, explore region-\nand pixel-based uncertainty, and conduct ablation studies. We conduct and\nanalyze binary real/fake, multi-class real/fake, source detection, and\nleave-one-out experiments between the generator/detector combinations to share\ntheir generalization capability, model calibration, uncertainty, and robustness\nagainst adversarial attacks. We further introduce uncertainty maps that\nlocalize prediction confidence at the pixel level, revealing distinct patterns\ncorrelated with generator-specific artifacts. Our analysis provides critical\ninsights for deploying reliable deepfake detection systems and establishes\nuncertainty quantification as a fundamental requirement for trustworthy\nsynthetic media detection."}
{"id": "2509.17553", "pdf": "https://arxiv.org/pdf/2509.17553", "abs": "https://arxiv.org/abs/2509.17553", "authors": ["Congcong Ge", "Yachuan Liu", "Yixuan Tang", "Yifan Zhu", "Yaofeng Tu", "Yunjun Gao"], "title": "MontePrep: Monte-Carlo-Driven Automatic Data Preparation without Target Data Instances", "categories": ["cs.AI", "cs.DB", "cs.LG"], "comment": null, "summary": "In commercial systems, a pervasive requirement for automatic data preparation\n(ADP) is to transfer relational data from disparate sources to targets with\nstandardized schema specifications. Previous methods rely on labor-intensive\nsupervision signals or target table data access permissions, limiting their\nusage in real-world scenarios. To tackle these challenges, we propose an\neffective end-to-end ADP framework MontePrep, which enables training-free\npipeline synthesis with zero target-instance requirements. MontePrep is\nformulated as an open-source large language model (LLM) powered tree-structured\nsearch problem. It consists of three pivot components, i.e., a data preparation\naction sandbox (DPAS), a fundamental pipeline generator (FPG), and an\nexecution-aware pipeline optimizer (EPO). We first introduce DPAS, a\nlightweight action sandbox, to navigate the search-based pipeline generation.\nThe design of DPAS circumvents exploration of infeasible pipelines. Then, we\npresent FPG to build executable DP pipelines incrementally, which explores the\npredefined action sandbox by the LLM-powered Monte Carlo Tree Search.\nFurthermore, we propose EPO, which invokes pipeline execution results from\nsources to targets to evaluate the reliability of the generated pipelines in\nFPG. In this way, unreasonable pipelines are eliminated, thus facilitating the\nsearch process from both efficiency and effectiveness perspectives. Extensive\nexperimental results demonstrate the superiority of MontePrep with significant\nimprovement against five state-of-the-art competitors."}
{"id": "2509.17581", "pdf": "https://arxiv.org/pdf/2509.17581", "abs": "https://arxiv.org/abs/2509.17581", "authors": ["Florinel Alin Croitoru", "Vlad Hondru", "Radu Tudor Ionescu"], "title": "PRNU-Bench: A Novel Benchmark and Model for PRNU-Based Camera Identification", "categories": ["cs.CV", "cs.CR", "cs.LG"], "comment": null, "summary": "We propose a novel benchmark for camera identification via Photo Response\nNon-Uniformity (PRNU) estimation. The benchmark comprises 13K photos taken with\n120+ cameras, where the training and test photos are taken in different\nscenarios, enabling ``in-the-wild'' evaluation. In addition, we propose a novel\nPRNU-based camera identification model that employs a hybrid architecture,\ncomprising a denoising autoencoder to estimate the PRNU signal and a\nconvolutional network that can perform 1:N verification of camera devices.\nInstead of using a conventional approach based on contrastive learning, our\nmethod takes the Hadamard product between reference and query PRNU signals as\ninput. This novel design leads to significantly better results compared with\nstate-of-the-art models based on denoising autoencoders and contrastive\nlearning. We release our dataset and code at:\nhttps://github.com/CroitoruAlin/PRNU-Bench."}
{"id": "2509.17588", "pdf": "https://arxiv.org/pdf/2509.17588", "abs": "https://arxiv.org/abs/2509.17588", "authors": ["Jinyeong Kim", "Seil Kang", "Jiwoo Park", "Junhyeok Kim", "Seong Jae Hwang"], "title": "Interpreting Attention Heads for Image-to-Text Information Flow in Large Vision-Language Models", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Vision-Language Models (LVLMs) answer visual questions by transferring\ninformation from images to text through a series of attention heads. While this\nimage-to-text information flow is central to visual question answering, its\nunderlying mechanism remains difficult to interpret due to the simultaneous\noperation of numerous attention heads. To address this challenge, we propose\nhead attribution, a technique inspired by component attribution methods, to\nidentify consistent patterns among attention heads that play a key role in\ninformation transfer. Using head attribution, we investigate how LVLMs rely on\nspecific attention heads to identify and answer questions about the main object\nin an image. Our analysis reveals that a distinct subset of attention heads\nfacilitates the image-to-text information flow. Remarkably, we find that the\nselection of these heads is governed by the semantic content of the input image\nrather than its visual appearance. We further examine the flow of information\nat the token level and discover that (1) text information first propagates to\nrole-related tokens and the final token before receiving image information, and\n(2) image information is embedded in both object-related and background tokens.\nOur work provides evidence that image-to-text information flow follows a\nstructured process, and that analysis at the attention-head level offers a\npromising direction toward understanding the mechanisms of LVLMs."}
{"id": "2509.17601", "pdf": "https://arxiv.org/pdf/2509.17601", "abs": "https://arxiv.org/abs/2509.17601", "authors": ["Tom Dunstan", "Oliver Strickson", "Thusal Bennett", "Jack Bowyer", "Matthew Burnand", "James Chappell", "Alejandro Coca-Castro", "Kirstine Ida Dale", "Eric G. Daub", "Noushin Eftekhari", "Manvendra Janmaijaya", "Jon Lillis", "David Salvador-Jasin", "Nathan Simpson", "Ryan Sze-Yin Chan", "Mohamad Elmasri", "Lydia Allegranza France", "Sam Madge", "Levan Bokeria", "Hannah Brown", "Tom Dodds", "Anna-Louise Ellis", "David Llewellyn-Jones", "Theo McCaie", "Sophia Moreton", "Tom Potter", "James Robinson", "Adam A. Scaife", "Iain Stenson", "David Walters", "Karina Bett-Williams", "Louisa van Zeeland", "Peter Yatsyshin", "J. Scott Hosking"], "title": "FastNet: Improving the physical consistency of machine-learning weather prediction models through loss function design", "categories": ["physics.ao-ph", "cs.LG"], "comment": null, "summary": "Machine learning weather prediction (MLWP) models have demonstrated\nremarkable potential in delivering accurate forecasts at significantly reduced\ncomputational cost compared to traditional numerical weather prediction (NWP)\nsystems. However, challenges remain in ensuring the physical consistency of\nMLWP outputs, particularly in deterministic settings. This study presents\nFastNet, a graph neural network (GNN)-based global prediction model, and\ninvestigates the impact of alternative loss function designs on improving the\nphysical realism of its forecasts. We explore three key modifications to the\nstandard mean squared error (MSE) loss: (1) a modified spherical harmonic (MSH)\nloss that penalises spectral amplitude errors to reduce blurring and enhance\nsmall-scale structure retention; (2) inclusion of horizontal gradient terms in\nthe loss to suppress non-physical artefacts; and (3) an alternative wind\nrepresentation that decouples speed and direction to better capture extreme\nwind events. Results show that while the MSH and gradient-based losses\n\\textit{alone} may slightly degrade RMSE scores, when trained in combination\nthe model exhibits very similar MSE performance to an MSE-trained model while\nat the same time significantly improving spectral fidelity and physical\nconsistency. The alternative wind representation further improves wind speed\naccuracy and reduces directional bias. Collectively, these findings highlight\nthe importance of loss function design as a mechanism for embedding domain\nknowledge into MLWP models and advancing their operational readiness."}
{"id": "2509.17609", "pdf": "https://arxiv.org/pdf/2509.17609", "abs": "https://arxiv.org/abs/2509.17609", "authors": ["Chang Li", "Zehua Chen", "Liyuan Wang", "Jun Zhu"], "title": "Audio Super-Resolution with Latent Bridge Models", "categories": ["cs.SD", "cs.LG"], "comment": "Accepted at NeurIPS 2025", "summary": "Audio super-resolution (SR), i.e., upsampling the low-resolution (LR)\nwaveform to the high-resolution (HR) version, has recently been explored with\ndiffusion and bridge models, while previous methods often suffer from\nsub-optimal upsampling quality due to their uninformative generation prior.\nTowards high-quality audio super-resolution, we present a new system with\nlatent bridge models (LBMs), where we compress the audio waveform into a\ncontinuous latent space and design an LBM to enable a latent-to-latent\ngeneration process that naturally matches the LR-toHR upsampling process,\nthereby fully exploiting the instructive prior information contained in the LR\nwaveform. To further enhance the training results despite the limited\navailability of HR samples, we introduce frequency-aware LBMs, where the prior\nand target frequency are taken as model input, enabling LBMs to explicitly\nlearn an any-to-any upsampling process at the training stage. Furthermore, we\ndesign cascaded LBMs and present two prior augmentation strategies, where we\nmake the first attempt to unlock the audio upsampling beyond 48 kHz and empower\na seamless cascaded SR process, providing higher flexibility for audio\npost-production. Comprehensive experimental results evaluated on the VCTK,\nESC-50, Song-Describer benchmark datasets and two internal testsets demonstrate\nthat we achieve state-of-the-art objective and perceptual quality for\nany-to-48kHz SR across speech, audio, and music signals, as well as setting the\nfirst record for any-to-192kHz audio SR. Demo at https://AudioLBM.github.io/."}
{"id": "2509.17636", "pdf": "https://arxiv.org/pdf/2509.17636", "abs": "https://arxiv.org/abs/2509.17636", "authors": ["Mohammed Racim Moussa Boudjemaa", "Alper Kalle", "Xiaoyi Mai", "José Henrique de Morais Goulart", "Cédric Févotte"], "title": "Whitening Spherical Gaussian Mixtures in the Large-Dimensional Regime", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Whitening is a classical technique in unsupervised learning that can\nfacilitate estimation tasks by standardizing data. An important application is\nthe estimation of latent variable models via the decomposition of tensors built\nfrom high-order moments. In particular, whitening orthogonalizes the means of a\nspherical Gaussian mixture model (GMM), thereby making the corresponding moment\ntensor orthogonally decomposable, hence easier to decompose. However, in the\nlarge-dimensional regime (LDR) where data are high-dimensional and scarce, the\nstandard whitening matrix built from the sample covariance becomes ineffective\nbecause the latter is spectrally distorted. Consequently, whitened means of a\nspherical GMM are no longer orthogonal. Using random matrix theory, we derive\nexact limits for their dot products, which are generally nonzero in the LDR. As\nour main contribution, we then construct a corrected whitening matrix that\nrestores asymptotic orthogonality, allowing for performance gains in spherical\nGMM estimation."}
{"id": "2509.17641", "pdf": "https://arxiv.org/pdf/2509.17641", "abs": "https://arxiv.org/abs/2509.17641", "authors": ["Hyunjong Ok", "Suho Yoo", "Hyeonjun Kim", "Jaeho Lee"], "title": "AuditoryBench++: Can Language Models Understand Auditory Knowledge without Hearing?", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SD"], "comment": "Preprint", "summary": "Even without directly hearing sounds, humans can effortlessly reason about\nauditory properties, such as pitch, loudness, or sound-source associations,\ndrawing on auditory commonsense. In contrast, language models often lack this\ncapability, limiting their effectiveness in multimodal interactions. As an\ninitial step to address this gap, we present AuditoryBench++, a comprehensive\nbenchmark for evaluating auditory knowledge and reasoning in text-only\nsettings. The benchmark encompasses tasks that range from basic auditory\ncomparisons to contextually grounded reasoning, enabling fine-grained analysis\nof how models process and integrate auditory concepts. In addition, we\nintroduce AIR-CoT, a novel auditory imagination reasoning method that generates\nand integrates auditory information during inference through span detection\nwith special tokens and knowledge injection. Extensive experiments with recent\nLLMs and Multimodal LLMs demonstrate that AIR-CoT generally outperforms both\nthe off-the-shelf models and those augmented with auditory knowledge. The\nproject page is available at https://auditorybenchpp.github.io."}
{"id": "2509.17645", "pdf": "https://arxiv.org/pdf/2509.17645", "abs": "https://arxiv.org/abs/2509.17645", "authors": ["Andreas Hadjigeorghiou", "David J. Armstrong", "Kaiming Cui", "Marina Lafarga Magro", "Luis Agustín Nieto", "Rodrigo F. Díaz", "Lauren Doyle", "Vedad Kunovac"], "title": "RAVEN: RAnking and Validation of ExoplaNets", "categories": ["astro-ph.EP", "astro-ph.IM", "cs.LG"], "comment": "Submitted to MNRAS. Comments from the community are welcome", "summary": "We present RAVEN, a newly developed vetting and validation pipeline for TESS\nexoplanet candidates. The pipeline employs a Bayesian framework to derive the\nposterior probability of a candidate being a planet against a set of False\nPositive (FP) scenarios, through the use of a Gradient Boosted Decision Tree\nand a Gaussian Process classifier, trained on comprehensive synthetic training\nsets of simulated planets and 8 astrophysical FP scenarios injected into TESS\nlightcurves. These training sets allow large scale candidate vetting and\nperformance verification against individual FP scenarios. A Non-Simulated FP\ntraining set consisting of real TESS candidates caused primarily by stellar\nvariability and systematic noise is also included. The machine learning derived\nprobabilities are combined with scenario specific prior probabilities,\nincluding the candidates' positional probabilities, to compute the final\nposterior probabilities. Candidates with a planetary posterior probability\ngreater than 99% against each FP scenario and whose implied planetary radius is\nless than 8$R_{\\oplus}$ are considered to be statistically validated by the\npipeline. In this first version, the pipeline has been developed for candidates\nwith a lightcurve released from the TESS Science Processing Operations Centre,\nan orbital period between 0.5 and 16 days and a transit depth greater than\n300ppm. The pipeline obtained area-under-curve (AUC) scores > 97% on all FP\nscenarios and > 99% on all but one. Testing on an independent external sample\nof 1361 pre-classified TOIs, the pipeline achieved an overall accuracy of 91%,\ndemonstrating its effectiveness for automated ranking of TESS candidates. For a\nprobability threshold of 0.9 the pipeline reached a precision of 97% with a\nrecall score of 66% on these TOIs. The RAVEN pipeline is publicly released as a\ncloud-hosted app, making it easily accessible to the community."}
{"id": "2509.17670", "pdf": "https://arxiv.org/pdf/2509.17670", "abs": "https://arxiv.org/abs/2509.17670", "authors": ["Mariette Schönfeld", "Wannes Meert", "Hendrik Blockeel"], "title": "Tailored Transformation Invariance for Industrial Anomaly Detection", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Industrial Anomaly Detection (IAD) is a subproblem within Computer Vision\nAnomaly Detection that has been receiving increasing amounts of attention due\nto its applicability to real-life scenarios. Recent research has focused on how\nto extract the most informative features, contrasting older kNN-based methods\nthat use only pretrained features. These recent methods are much more expensive\nto train however and could complicate real-life application. Careful study of\nrelated work with regards to transformation invariance leads to the idea that\npopular benchmarks require robustness to only minor translations. With this\nidea we then formulate LWinNN, a local window based approach that creates a\nmiddle ground between kNN based methods that have either complete or no\ntranslation invariance. Our experiments demonstrate that this small change\nincreases accuracy considerably, while simultaneously decreasing both train and\ntest time. This teaches us two things: first, the gap between kNN-based\napproaches and more complex state-of-the-art methodology can still be narrowed\nby effective usage of the limited data available. Second, our assumption of\nrequiring only limited translation invariance highlights potential areas of\ninterest for future work and the need for more spatially diverse benchmarks,\nfor which our method can hopefully serve as a new baseline. Our code can be\nfound at https://github.com/marietteschonfeld/LWinNN ."}
{"id": "2509.17674", "pdf": "https://arxiv.org/pdf/2509.17674", "abs": "https://arxiv.org/abs/2509.17674", "authors": ["Julia Matejas", "Olaf Żurawski", "Nils Strodthoff", "Juan Miguel Lopez Alcaraz"], "title": "Predicting Chest Radiograph Findings from Electrocardiograms Using Interpretable Machine Learning", "categories": ["eess.SP", "cs.LG"], "comment": "19 pages, 3 figures, source code under\n  https://github.com/UOLMDA2025/CardioCXR", "summary": "Purpose: Chest X-rays are essential for diagnosing pulmonary conditions, but\nlimited access in resource-constrained settings can delay timely diagnosis.\nElectrocardiograms (ECGs), in contrast, are widely available, non-invasive, and\noften acquired earlier in clinical workflows. This study aims to assess whether\nECG features and patient demographics can predict chest radiograph findings\nusing an interpretable machine learning approach.\n  Methods: Using the MIMIC-IV database, Extreme Gradient Boosting (XGBoost)\nclassifiers were trained to predict diverse chest radiograph findings from\nECG-derived features and demographic variables. Recursive feature elimination\nwas performed independently for each target to identify the most predictive\nfeatures. Model performance was evaluated using the area under the receiver\noperating characteristic curve (AUROC) with bootstrapped 95% confidence\nintervals. Shapley Additive Explanations (SHAP) were applied to interpret\nfeature contributions.\n  Results: Models successfully predicted multiple chest radiograph findings\nwith varying accuracy. Feature selection tailored predictors to each target,\nand including demographic variables consistently improved performance. SHAP\nanalysis revealed clinically meaningful contributions from ECG features to\nradiographic predictions.\n  Conclusion: ECG-derived features combined with patient demographics can serve\nas a proxy for certain chest radiograph findings, enabling early triage or\npre-screening in settings where radiographic imaging is limited. Interpretable\nmachine learning demonstrates potential to support radiology workflows and\nimprove patient care."}
{"id": "2509.17701", "pdf": "https://arxiv.org/pdf/2509.17701", "abs": "https://arxiv.org/abs/2509.17701", "authors": ["Mariam Mahran", "Katharina Simbeck"], "title": "Investigating Bias: A Multilingual Pipeline for Generating, Solving, and Evaluating Math Problems with LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted at edu4AI'25: 2nd Workshop on Education for Artificial\n  Intelligence | co-located with ECAI, October 26th, 2025, Bologna, Italy. 7\n  pages, 0 figures", "summary": "Large Language Models (LLMs) are increasingly used for educational support,\nyet their response quality varies depending on the language of interaction.\nThis paper presents an automated multilingual pipeline for generating, solving,\nand evaluating math problems aligned with the German K-10 curriculum. We\ngenerated 628 math exercises and translated them into English, German, and\nArabic. Three commercial LLMs (GPT-4o-mini, Gemini 2.5 Flash, and Qwen-plus)\nwere prompted to produce step-by-step solutions in each language. A held-out\npanel of LLM judges, including Claude 3.5 Haiku, evaluated solution quality\nusing a comparative framework. Results show a consistent gap, with English\nsolutions consistently rated highest, and Arabic often ranked lower. These\nfindings highlight persistent linguistic bias and the need for more equitable\nmultilingual AI systems in education."}
{"id": "2509.17726", "pdf": "https://arxiv.org/pdf/2509.17726", "abs": "https://arxiv.org/abs/2509.17726", "authors": ["Javier Bisbal", "Patrick Winter", "Sebastian Jofre", "Aaron Ponce", "Sameer A. Ansari", "Ramez Abdalla", "Michael Markl", "Oliver Welin Odeback", "Sergio Uribe", "Cristian Tejos", "Julio Sotelo", "Susanne Schnell", "David Marlevi"], "title": "Automated Labeling of Intracranial Arteries with Uncertainty Quantification Using Deep Learning", "categories": ["cs.CV", "cs.LG", "I.4.0"], "comment": "16 pages, 6 figures", "summary": "Accurate anatomical labeling of intracranial arteries is essential for\ncerebrovascular diagnosis and hemodynamic analysis but remains time-consuming\nand subject to interoperator variability. We present a deep learning-based\nframework for automated artery labeling from 3D Time-of-Flight Magnetic\nResonance Angiography (3D ToF-MRA) segmentations (n=35), incorporating\nuncertainty quantification to enhance interpretability and reliability. We\nevaluated three convolutional neural network architectures: (1) a UNet with\nresidual encoder blocks, reflecting commonly used baselines in vascular\nlabeling; (2) CS-Net, an attention-augmented UNet incorporating channel and\nspatial attention mechanisms for enhanced curvilinear structure recognition;\nand (3) nnUNet, a self-configuring framework that automates preprocessing,\ntraining, and architectural adaptation based on dataset characteristics. Among\nthese, nnUNet achieved the highest labeling performance (average Dice score:\n0.922; average surface distance: 0.387 mm), with improved robustness in\nanatomically complex vessels. To assess predictive confidence, we implemented\ntest-time augmentation (TTA) and introduced a novel coordinate-guided strategy\nto reduce interpolation errors during augmented inference. The resulting\nuncertainty maps reliably indicated regions of anatomical ambiguity,\npathological variation, or manual labeling inconsistency. We further validated\nclinical utility by comparing flow velocities derived from automated and manual\nlabels in co-registered 4D Flow MRI datasets, observing close agreement with no\nstatistically significant differences. Our framework offers a scalable,\naccurate, and uncertainty-aware solution for automated cerebrovascular\nlabeling, supporting downstream hemodynamic analysis and facilitating clinical\nintegration."}
{"id": "2509.17768", "pdf": "https://arxiv.org/pdf/2509.17768", "abs": "https://arxiv.org/abs/2509.17768", "authors": ["Jessica Ojo", "Zina Kamel", "David Ifeoluwa Adelani"], "title": "DIVERS-Bench: Evaluating Language Identification Across Domain Shifts and Code-Switching", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Language Identification (LID) is a core task in multilingual NLP, yet current\nsystems often overfit to clean, monolingual data. This work introduces\nDIVERS-BENCH, a comprehensive evaluation of state-of-the-art LID models across\ndiverse domains, including speech transcripts, web text, social media texts,\nchildren's stories, and code-switched text. Our findings reveal that while\nmodels achieve high accuracy on curated datasets, performance degrades sharply\non noisy and informal inputs. We also introduce DIVERS-CS, a diverse\ncode-switching benchmark dataset spanning 10 language pairs, and show that\nexisting models struggle to detect multiple languages within the same sentence.\nThese results highlight the need for more robust and inclusive LID systems in\nreal-world settings."}
{"id": "2509.17774", "pdf": "https://arxiv.org/pdf/2509.17774", "abs": "https://arxiv.org/abs/2509.17774", "authors": ["Joao Marques-Silva", "Alexey Ignatiev"], "title": "Efficient & Correct Predictive Equivalence for Decision Trees", "categories": ["cs.AI", "cs.LG", "cs.LO"], "comment": null, "summary": "The Rashomon set of decision trees (DTs) finds importance uses. Recent work\nshowed that DTs computing the same classification function, i.e. predictive\nequivalent DTs, can represent a significant fraction of the Rashomon set. Such\nredundancy is undesirable. For example, feature importance based on the\nRashomon set becomes inaccurate due the existence of predictive equivalent DTs,\ni.e. DTs with the same prediction for every possible input. In recent work,\nMcTavish et al. proposed solutions for several computational problems related\nwith DTs, including that of deciding predictive equivalent DTs. This approach,\nwhich this paper refers to as MBDSR, consists of applying the well-known method\nof Quine-McCluskey (QM) for obtaining minimum-size DNF (disjunctive normal\nform) representations of DTs, which are then used for comparing DTs for\npredictive equivalence. Furthermore, the minimum-size DNF representation was\nalso applied to computing explanations for the predictions made by DTs, and to\nfinding predictions in the presence of missing data. However, the problem of\nformula minimization is hard for the second level of the polynomial hierarchy,\nand the QM method may exhibit worst-case exponential running time and space.\nThis paper first demonstrates that there exist decision trees that trigger the\nworst-case exponential running time and space of the QM method. Second, the\npaper shows that the MBDSR approach can produce incorrect results for the\nproblem of deciding predictive equivalence. Third, the paper shows that any of\nthe problems to which the minimum-size DNF representation has been applied to\ncan in fact be solved in polynomial time, in the size of the DT. The\nexperiments confirm that, for DTs for which the the worst-case of the QM method\nis triggered, the algorithms proposed in this paper are orders of magnitude\nfaster than the ones proposed by McTavish et al."}
{"id": "2509.17842", "pdf": "https://arxiv.org/pdf/2509.17842", "abs": "https://arxiv.org/abs/2509.17842", "authors": ["Lawrence Obiuwevwi", "Krzysztof J. Rechowicz", "Vikas Ashok", "Sampath Jayarathna"], "title": "Toward Affordable and Non-Invasive Detection of Hypoglycemia: A Machine Learning Approach", "categories": ["cs.HC", "cs.LG"], "comment": null, "summary": "Diabetes mellitus is a growing global health issue, with Type 1 Diabetes\n(T1D) requiring constant monitoring to avoid hypoglycemia. Although Continuous\nGlucose Monitors (CGMs) are effective, their cost and invasiveness limit\naccess, particularly in low-resource settings. This paper proposes a\nnon-invasive method to classify glycemic states using Galvanic Skin Response\n(GSR), a biosignal commonly captured by wearable sensors. We use the merged\nOhioT1DM 2018 and 2020 datasets to build a machine learning pipeline that\ndetects hypoglycemia (glucose < 70 mg/dl) and normoglycemia (glucose > 70\nmg/dl) with GSR alone. Seven models are trained and evaluated: Random Forest,\nXGBoost, MLP, CNN, LSTM, Logistic Regression, and K-Nearest Neighbors.\nValidation sets and 95% confidence intervals are reported to increase\nreliability and assess robustness. Results show that the LSTM model achieves a\nperfect hypoglycemia recall (1.00) with an F1-score confidence interval of\n[0.611-0.745], while XGBoost offers strong performance with a recall of 0.54\neven under class imbalance. This approach highlights the potential for\naffordable, wearable-compatible glucose monitoring tools suitable for settings\nwith limited CGM availability using GSR data.\n  Index Terms: Hypoglycemia Detection, Galvanic Skin Response, Non Invasive\nMonitoring, Wearables, Machine Learning, Confidence Intervals."}
{"id": "2509.17859", "pdf": "https://arxiv.org/pdf/2509.17859", "abs": "https://arxiv.org/abs/2509.17859", "authors": ["Kai Schenck", "Gašper Beguš"], "title": "Unsupervised Learning and Representation of Mandarin Tonal Categories by a Generative CNN", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "This paper outlines the methodology for modeling tonal learning in fully\nunsupervised models of human language acquisition. Tonal patterns are among the\ncomputationally most complex learning objectives in language. We argue that a\nrealistic generative model of human language (ciwGAN) can learn to associate\nits categorical variables with Mandarin Chinese tonal categories without any\nlabeled data. All three trained models showed statistically significant\ndifferences in F0 across categorical variables. The model trained solely on\nmale tokens consistently encoded tone. Our results sug- gest that not only does\nthe model learn Mandarin tonal contrasts, but it learns a system that\ncorresponds to a stage of acquisition in human language learners. We also\noutline methodology for tracing tonal representations in internal convolutional\nlayers, which shows that linguistic tools can contribute to interpretability of\ndeep learning and can ultimately be used in neural experiments."}
{"id": "2509.17883", "pdf": "https://arxiv.org/pdf/2509.17883", "abs": "https://arxiv.org/abs/2509.17883", "authors": ["Qiushi Han", "Yuan Liao", "Youhao Si", "Liya Huang"], "title": "Brainprint-Modulated Target Speaker Extraction", "categories": ["cs.SD", "cs.LG"], "comment": "5 pages, 2 figures, conference", "summary": "Achieving robust and personalized performance in neuro-steered Target Speaker\nExtraction (TSE) remains a significant challenge for next-generation hearing\naids. This is primarily due to two factors: the inherent non-stationarity of\nEEG signals across sessions, and the high inter-subject variability that limits\nthe efficacy of generalized models. To address these issues, we propose\nBrainprint-Modulated Target Speaker Extraction (BM-TSE), a novel framework for\npersonalized and high-fidelity extraction. BM-TSE first employs a\nspatio-temporal EEG encoder with an Adaptive Spectral Gain (ASG) module to\nextract stable features resilient to non-stationarity. The core of our\nframework is a personalized modulation mechanism, where a unified brainmap\nembedding is learned under the joint supervision of subject identification\n(SID) and auditory attention decoding (AAD) tasks. This learned brainmap,\nencoding both static user traits and dynamic attentional states, actively\nrefines the audio separation process, dynamically tailoring the output to each\nuser. Evaluations on the public KUL and Cocktail Party datasets demonstrate\nthat BM-TSE achieves state-of-the-art performance, significantly outperforming\nexisting methods. Our code is publicly accessible at:\nhttps://github.com/rosshan-orz/BM-TSE."}
{"id": "2509.17898", "pdf": "https://arxiv.org/pdf/2509.17898", "abs": "https://arxiv.org/abs/2509.17898", "authors": ["Paul Hamelbeck", "Johannes Schiffer"], "title": "Lipschitz-Based Robustness Certification for Recurrent Neural Networks via Convex Relaxation", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": "10 pages, 3 figures,", "summary": "Robustness certification against bounded input noise or adversarial\nperturbations is increasingly important for deployment recurrent neural\nnetworks (RNNs) in safety-critical control applications. To address this\nchallenge, we present RNN-SDP, a relaxation based method that models the RNN's\nlayer interactions as a convex problem and computes a certified upper bound on\nthe Lipschitz constant via semidefinite programming (SDP). We also explore an\nextension that incorporates known input constraints to further tighten the\nresulting Lipschitz bounds. RNN-SDP is evaluated on a synthetic multi-tank\nsystem, with upper bounds compared to empirical estimates. While incorporating\ninput constraints yields only modest improvements, the general method produces\nreasonably tight and certifiable bounds, even as sequence length increases. The\nresults also underscore the often underestimated impact of initialization\nerrors, an important consideration for applications where models are frequently\nre-initialized, such as model predictive control (MPC)."}
{"id": "2509.17918", "pdf": "https://arxiv.org/pdf/2509.17918", "abs": "https://arxiv.org/abs/2509.17918", "authors": ["Yuanrong Wang", "Yingpeng Du"], "title": "Shilling Recommender Systems by Generating Side-feature-aware Fake User Profiles", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "Recommender systems (RS) greatly influence users' consumption decisions,\nmaking them attractive targets for malicious shilling attacks that inject fake\nuser profiles to manipulate recommendations. Existing shilling methods can\ngenerate effective and stealthy fake profiles when training data only contain\nrating matrix, but they lack comprehensive solutions for scenarios where side\nfeatures are present and utilized by the recommender. To address this gap, we\nextend the Leg-UP framework by enhancing the generator architecture to\nincorporate side features, enabling the generation of side-feature-aware fake\nuser profiles. Experiments on benchmarks show that our method achieves strong\nattack performance while maintaining stealthiness."}
{"id": "2509.17937", "pdf": "https://arxiv.org/pdf/2509.17937", "abs": "https://arxiv.org/abs/2509.17937", "authors": ["Jayashrita Debnath", "Gerhard Hummer"], "title": "Random functions as data compressors for machine learning of molecular processes", "categories": ["cond-mat.soft", "cs.LG"], "comment": null, "summary": "Machine learning (ML) is rapidly transforming the way molecular dynamics\nsimulations are performed and analyzed, from materials modeling to studies of\nprotein folding and function. ML algorithms are often employed to learn\nlow-dimensional representations of conformational landscapes and to cluster\ntrajectories into relevant metastable states. Most of these algorithms require\nselecting a small number of features that describe the problem of interest.\nAlthough deep neural networks can tackle large numbers of input features, the\ntraining costs increase with input size, which makes the selection of a subset\nof features mandatory for most problems of practical interest. Here, we show\nthat random nonlinear projections can be used to compress large feature spaces\nand make computations faster without substantial loss of information. We\ndescribe an efficient way to produce random projections and then exemplify the\ngeneral procedure for protein folding. For our test cases NTL9 and the\ndouble-norleucin variant of the villin headpiece, we find that random\ncompression retains the core static and dynamic information of the original\nhigh dimensional feature space and makes trajectory analysis more robust."}
{"id": "2509.17941", "pdf": "https://arxiv.org/pdf/2509.17941", "abs": "https://arxiv.org/abs/2509.17941", "authors": ["Zichao Hu", "Chen Tang", "Michael J. Munje", "Yifeng Zhu", "Alex Liu", "Shuijing Liu", "Garrett Warnell", "Peter Stone", "Joydeep Biswas"], "title": "ComposableNav: Instruction-Following Navigation in Dynamic Environments via Composable Diffusion", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "comment": "Conference on Robot Learning (CoRL) 2025 Project site:\n  https://amrl.cs.utexas.edu/ComposableNav/", "summary": "This paper considers the problem of enabling robots to navigate dynamic\nenvironments while following instructions. The challenge lies in the\ncombinatorial nature of instruction specifications: each instruction can\ninclude multiple specifications, and the number of possible specification\ncombinations grows exponentially as the robot's skill set expands. For example,\n\"overtake the pedestrian while staying on the right side of the road\" consists\nof two specifications: \"overtake the pedestrian\" and \"walk on the right side of\nthe road.\" To tackle this challenge, we propose ComposableNav, based on the\nintuition that following an instruction involves independently satisfying its\nconstituent specifications, each corresponding to a distinct motion primitive.\nUsing diffusion models, ComposableNav learns each primitive separately, then\ncomposes them in parallel at deployment time to satisfy novel combinations of\nspecifications unseen in training. Additionally, to avoid the onerous need for\ndemonstrations of individual motion primitives, we propose a two-stage training\nprocedure: (1) supervised pre-training to learn a base diffusion model for\ndynamic navigation, and (2) reinforcement learning fine-tuning that molds the\nbase model into different motion primitives. Through simulation and real-world\nexperiments, we show that ComposableNav enables robots to follow instructions\nby generating trajectories that satisfy diverse and unseen combinations of\nspecifications, significantly outperforming both non-compositional VLM-based\npolicies and costmap composing baselines. Videos and additional materials can\nbe found on the project page: https://amrl.cs.utexas.edu/ComposableNav/"}
{"id": "2509.17943", "pdf": "https://arxiv.org/pdf/2509.17943", "abs": "https://arxiv.org/abs/2509.17943", "authors": ["Romain Thoreau", "Jessie Levillain", "Dawa Derksen"], "title": "Can multimodal representation learning by alignment preserve modality-specific information?", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted as a workshop paper at MACLEAN - ECML/PKDD 2025", "summary": "Combining multimodal data is a key issue in a wide range of machine learning\ntasks, including many remote sensing problems. In Earth observation, early\nmultimodal data fusion methods were based on specific neural network\narchitectures and supervised learning. Ever since, the scarcity of labeled data\nhas motivated self-supervised learning techniques. State-of-the-art multimodal\nrepresentation learning techniques leverage the spatial alignment between\nsatellite data from different modalities acquired over the same geographic area\nin order to foster a semantic alignment in the latent space. In this paper, we\ninvestigate how this methods can preserve task-relevant information that is not\nshared across modalities. First, we show, under simplifying assumptions, when\nalignment strategies fundamentally lead to an information loss. Then, we\nsupport our theoretical insight through numerical experiments in more realistic\nsettings. With those theoretical and empirical evidences, we hope to support\nnew developments in contrastive learning for the combination of multimodal\nsatellite data. Our code and data is publicly available at\nhttps://github.com/Romain3Ch216/alg_maclean_25."}
{"id": "2509.17979", "pdf": "https://arxiv.org/pdf/2509.17979", "abs": "https://arxiv.org/abs/2509.17979", "authors": ["Yiwen Song", "Hongyang Li", "Kuang Yuan", "Ran Bi", "Swarun Kumar"], "title": "Towards Seeing Bones at Radio Frequency", "categories": ["cs.GR", "cs.ET", "cs.LG"], "comment": null, "summary": "Wireless sensing literature has long aspired to achieve X-ray-like vision at\nradio frequencies. Yet, state-of-the-art wireless sensing literature has yet to\ngenerate the archetypal X-ray image: one of the bones beneath flesh. In this\npaper, we explore MCT, a penetration-based RF-imaging system for imaging bones\nat mm-resolution, one that significantly exceeds prior penetration-based RF\nimaging literature. Indeed the long wavelength, significant attenuation and\ncomplex diffraction that occur as RF propagates through flesh, have long\nlimited imaging resolution (to several centimeters at best). We address these\nconcerns through a novel penetration-based synthetic aperture algorithm,\ncoupled with a learning-based pipeline to correct for diffraction-induced\nartifacts. A detailed evaluation of meat models demonstrates a resolution\nimprovement from sub-decimeter to sub-centimeter over prior art in RF\npenetrative imaging."}
{"id": "2509.17991", "pdf": "https://arxiv.org/pdf/2509.17991", "abs": "https://arxiv.org/abs/2509.17991", "authors": ["Aakash Kumar Agarwal", "Saprativa Bhattacharjee", "Mauli Rastogi", "Jemima S. Jacob", "Biplab Banerjee", "Rashmi Gupta", "Pushpak Bhattacharyya"], "title": "ReDepress: A Cognitive Framework for Detecting Depression Relapse from Social Media", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted to EMNLP 2025 Main Conference", "summary": "Almost 50% depression patients face the risk of going into relapse. The risk\nincreases to 80% after the second episode of depression. Although, depression\ndetection from social media has attained considerable attention, depression\nrelapse detection has remained largely unexplored due to the lack of curated\ndatasets and the difficulty of distinguishing relapse and non-relapse users. In\nthis work, we present ReDepress, the first clinically validated social media\ndataset focused on relapse, comprising 204 Reddit users annotated by mental\nhealth professionals. Unlike prior approaches, our framework draws on cognitive\ntheories of depression, incorporating constructs such as attention bias,\ninterpretation bias, memory bias and rumination into both annotation and\nmodeling. Through statistical analyses and machine learning experiments, we\ndemonstrate that cognitive markers significantly differentiate relapse and\nnon-relapse groups, and that models enriched with these features achieve\ncompetitive performance, with transformer-based temporal models attaining an F1\nof 0.86. Our findings validate psychological theories in real-world textual\ndata and underscore the potential of cognitive-informed computational methods\nfor early relapse detection, paving the way for scalable, low-cost\ninterventions in mental healthcare."}
{"id": "2509.17995", "pdf": "https://arxiv.org/pdf/2509.17995", "abs": "https://arxiv.org/abs/2509.17995", "authors": ["Yefan Zhou", "Austin Xu", "Yilun Zhou", "Janvijay Singh", "Jiang Gui", "Shafiq Joty"], "title": "Variation in Verification: Understanding Verification Dynamics in Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Recent advances have shown that scaling test-time computation enables large\nlanguage models (LLMs) to solve increasingly complex problems across diverse\ndomains. One effective paradigm for test-time scaling (TTS) involves LLM\ngenerators producing multiple solution candidates, with LLM verifiers assessing\nthe correctness of these candidates without reference answers. In this paper,\nwe study generative verifiers, which perform verification by generating\nchain-of-thought (CoT) reasoning followed by a binary verdict. We\nsystematically analyze verification dynamics across three dimensions - problem\ndifficulty, generator capability, and verifier generation capability - with\nempirical studies on 12 benchmarks across mathematical reasoning, knowledge,\nand natural language reasoning tasks using 14 open-source models (2B to 72B\nparameter range) and GPT-4o. Our experiments reveal three key findings about\nverification effectiveness: (1) Easy problems allow verifiers to more reliably\ncertify correct responses; (2) Weak generators produce errors that are easier\nto detect than strong generators; (3) Verification ability is generally\ncorrelated with the verifier's own problem-solving capability, but this\nrelationship varies with problem difficulty. These findings reveal\nopportunities to optimize basic verification strategies in TTS applications.\nFirst, given the same verifier, some weak generators can nearly match stronger\nones in post-verification TTS performance (e.g., the Gemma2-9B to Gemma2-27B\nperformance gap shrinks by 75.5%). Second, we identify cases where strong\nverifiers offer limited advantage over weak ones, as both fail to provide\nmeaningful verification gains, suggesting that verifier scaling alone cannot\novercome fundamental verification challenges."}
{"id": "2509.17999", "pdf": "https://arxiv.org/pdf/2509.17999", "abs": "https://arxiv.org/abs/2509.17999", "authors": ["Riccardo Cadei", "Christian Internò"], "title": "The Narcissus Hypothesis:Descending to the Rung of Illusion", "categories": ["cs.CY", "cs.AI", "cs.HC", "cs.LG"], "comment": null, "summary": "Modern foundational models increasingly reflect not just world knowledge, but\npatterns of human preference embedded in their training data. We hypothesize\nthat recursive alignment-via human feedback and model-generated corpora-induces\na social desirability bias, nudging models to favor agreeable or flattering\nresponses over objective reasoning. We refer to it as the Narcissus Hypothesis\nand test it across 31 models using standardized personality assessments and a\nnovel Social Desirability Bias score. Results reveal a significant drift toward\nsocially conforming traits, with profound implications for corpus integrity and\nthe reliability of downstream inferences. We then offer a novel epistemological\ninterpretation, tracing how recursive bias may collapse higher-order reasoning\ndown Pearl's Ladder of Causality, culminating in what we refer to as the Rung\nof Illusion."}
{"id": "2509.18007", "pdf": "https://arxiv.org/pdf/2509.18007", "abs": "https://arxiv.org/abs/2509.18007", "authors": ["Riya Ponraj", "Ram Durairajan", "Yu Wang"], "title": "Building Transparency in Deep Learning-Powered Network Traffic Classification: A Traffic-Explainer Framework", "categories": ["cs.NI", "cs.LG"], "comment": null, "summary": "Recent advancements in deep learning have significantly enhanced the\nperformance and efficiency of traffic classification in networking systems.\nHowever, the lack of transparency in their predictions and decision-making has\nmade network operators reluctant to deploy DL-based solutions in production\nnetworks. To tackle this challenge, we propose Traffic-Explainer, a\nmodel-agnostic and input-perturbation-based traffic explanation framework. By\nmaximizing the mutual information between predictions on original traffic\nsequences and their masked counterparts, Traffic-Explainer automatically\nuncovers the most influential features driving model predictions. Extensive\nexperiments demonstrate that Traffic-Explainer improves upon existing\nexplanation methods by approximately 42%. Practically, we further apply\nTraffic-Explainer to identify influential features and demonstrate its enhanced\ntransparency across three critical tasks: application classification, traffic\nlocalization, and network cartography. For the first two tasks,\nTraffic-Explainer identifies the most decisive bytes that drive predicted\ntraffic applications and locations, uncovering potential vulnerabilities and\nprivacy concerns. In network cartography, Traffic-Explainer identifies\nsubmarine cables that drive the mapping of traceroute to physical path,\nenabling a traceroute-informed risk analysis."}
{"id": "2509.18011", "pdf": "https://arxiv.org/pdf/2509.18011", "abs": "https://arxiv.org/abs/2509.18011", "authors": ["Fernando Llorente", "Daniel Waxman", "Sanket Jantre", "Nathan M. Urban", "Susan E. Minkoff"], "title": "Robust, Online, and Adaptive Decentralized Gaussian Processes", "categories": ["stat.ML", "cs.LG", "cs.MA", "eess.SP"], "comment": "Submitted to Icassp 2026 Special Session on \"Bridging Signal\n  Processing and Machine Learning with Gaussian Processes.\"", "summary": "Gaussian processes (GPs) offer a flexible, uncertainty-aware framework for\nmodeling complex signals, but scale cubically with data, assume static targets,\nand are brittle to outliers, limiting their applicability in large-scale\nproblems with dynamic and noisy environments. Recent work introduced\ndecentralized random Fourier feature Gaussian processes (DRFGP), an online and\ndistributed algorithm that casts GPs in an information-filter form, enabling\nexact sequential inference and fully distributed computation without reliance\non a fusion center. In this paper, we extend DRFGP along two key directions:\nfirst, by introducing a robust-filtering update that downweights the impact of\natypical observations; and second, by incorporating a dynamic adaptation\nmechanism that adapts to time-varying functions. The resulting algorithm\nretains the recursive information-filter structure while enhancing stability\nand accuracy. We demonstrate its effectiveness on a large-scale Earth system\napplication, underscoring its potential for in-situ modeling."}
{"id": "2509.18013", "pdf": "https://arxiv.org/pdf/2509.18013", "abs": "https://arxiv.org/abs/2509.18013", "authors": ["Yidong Zhou", "Su I Iao", "Hans-Georg Müller"], "title": "Fréchet Geodesic Boosting", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": "23 pages, 4 figures, 10 tables", "summary": "Gradient boosting has become a cornerstone of machine learning, enabling base\nlearners such as decision trees to achieve exceptional predictive performance.\nWhile existing algorithms primarily handle scalar or Euclidean outputs,\nincreasingly prevalent complex-structured data, such as distributions,\nnetworks, and manifold-valued outputs, present challenges for traditional\nmethods. Such non-Euclidean data lack algebraic structures such as addition,\nsubtraction, or scalar multiplication required by standard gradient boosting\nframeworks. To address these challenges, we introduce Fr\\'echet geodesic\nboosting (FGBoost), a novel approach tailored for outputs residing in geodesic\nmetric spaces. FGBoost leverages geodesics as proxies for residuals and\nconstructs ensembles in a way that respects the intrinsic geometry of the\noutput space. Through theoretical analysis, extensive simulations, and\nreal-world applications, we demonstrate the strong performance and adaptability\nof FGBoost, showcasing its potential for modeling complex data."}
{"id": "2509.18024", "pdf": "https://arxiv.org/pdf/2509.18024", "abs": "https://arxiv.org/abs/2509.18024", "authors": ["Dunyao Xue", "Mengyu Li", "Cheng Meng", "Jingyi Zhang"], "title": "Core-elements Subsampling for Alternating Least Squares", "categories": ["stat.ME", "cs.LG", "stat.CO", "stat.ML"], "comment": null, "summary": "In this paper, we propose a novel element-wise subset selection method for\nthe alternating least squares (ALS) algorithm, focusing on low-rank matrix\nfactorization involving matrices with missing values, as commonly encountered\nin recommender systems. While ALS is widely used for providing personalized\nrecommendations based on user-item interaction data, its high computational\ncost, stemming from repeated regression operations, poses significant\nchallenges for large-scale datasets. To enhance the efficiency of ALS, we\npropose a core-elements subsampling method that selects a representative subset\nof data and leverages sparse matrix operations to approximate ALS estimations\nefficiently. We establish theoretical guarantees for the approximation and\nconvergence of the proposed approach, showing that it achieves similar accuracy\nwith significantly reduced computational time compared to full-data ALS.\nExtensive simulations and real-world applications demonstrate the effectiveness\nof our method in various scenarios, emphasizing its potential in large-scale\nrecommendation systems."}
{"id": "2509.18025", "pdf": "https://arxiv.org/pdf/2509.18025", "abs": "https://arxiv.org/abs/2509.18025", "authors": ["Gilles Bareilles", "Allen Gehret", "Johannes Aspman", "Jana Lepšová", "Jakub Mareček"], "title": "Deep Learning as the Disciplined Construction of Tame Objects", "categories": ["math.OC", "cs.AI", "cs.LG", "math.LO", "stat.ML"], "comment": "35 pages, 8 figures", "summary": "One can see deep-learning models as compositions of functions within the\nso-called tame geometry. In this expository note, we give an overview of some\ntopics at the interface of tame geometry (also known as o-minimality),\noptimization theory, and deep learning theory and practice. To do so, we\ngradually introduce the concepts and tools used to build convergence guarantees\nfor stochastic gradient descent in a general nonsmooth nonconvex, but tame,\nsetting. This illustrates some ways in which tame geometry is a natural\nmathematical framework for the study of AI systems, especially within Deep\nLearning."}
{"id": "2509.18037", "pdf": "https://arxiv.org/pdf/2509.18037", "abs": "https://arxiv.org/abs/2509.18037", "authors": ["Amparo Baíllo", "Jose R. Berrendero", "Martín Sánchez-Signorini"], "title": "Kernel K-means clustering of distributional data", "categories": ["stat.ML", "cs.LG", "stat.CO"], "comment": null, "summary": "We consider the problem of clustering a sample of probability distributions\nfrom a random distribution on $\\mathbb R^p$. Our proposed partitioning method\nmakes use of a symmetric, positive-definite kernel $k$ and its associated\nreproducing kernel Hilbert space (RKHS) $\\mathcal H$. By mapping each\ndistribution to its corresponding kernel mean embedding in $\\mathcal H$, we\nobtain a sample in this RKHS where we carry out the $K$-means clustering\nprocedure, which provides an unsupervised classification of the original\nsample. The procedure is simple and computationally feasible even for dimension\n$p>1$. The simulation studies provide insight into the choice of the kernel and\nits tuning parameter. The performance of the proposed clustering procedure is\nillustrated on a collection of Synthetic Aperture Radar (SAR) images."}
{"id": "2509.18043", "pdf": "https://arxiv.org/pdf/2509.18043", "abs": "https://arxiv.org/abs/2509.18043", "authors": ["Yinlong Dai", "Andre Keyser", "Dylan P. Losey"], "title": "Prepare Before You Act: Learning From Humans to Rearrange Initial States", "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "Imitation learning (IL) has proven effective across a wide range of\nmanipulation tasks. However, IL policies often struggle when faced with\nout-of-distribution observations; for instance, when the target object is in a\npreviously unseen position or occluded by other objects. In these cases,\nextensive demonstrations are needed for current IL methods to reach robust and\ngeneralizable behaviors. But when humans are faced with these sorts of atypical\ninitial states, we often rearrange the environment for more favorable task\nexecution. For example, a person might rotate a coffee cup so that it is easier\nto grasp the handle, or push a box out of the way so they can directly grasp\ntheir target object. In this work we seek to equip robot learners with the same\ncapability: enabling robots to prepare the environment before executing their\ngiven policy. We propose ReSET, an algorithm that takes initial states -- which\nare outside the policy's distribution -- and autonomously modifies object poses\nso that the restructured scene is similar to training data. Theoretically, we\nshow that this two step process (rearranging the environment before rolling out\nthe given policy) reduces the generalization gap. Practically, our ReSET\nalgorithm combines action-agnostic human videos with task-agnostic\nteleoperation data to i) decide when to modify the scene, ii) predict what\nsimplifying actions a human would take, and iii) map those predictions into\nrobot action primitives. Comparisons with diffusion policies, VLAs, and other\nbaselines show that using ReSET to prepare the environment enables more robust\ntask execution with equal amounts of total training data. See videos at our\nproject website: https://reset2025paper.github.io/"}
{"id": "2509.18047", "pdf": "https://arxiv.org/pdf/2509.18047", "abs": "https://arxiv.org/abs/2509.18047", "authors": ["Nicolas Salvadé", "Tim Hillel"], "title": "Functional effects models: Accounting for preference heterogeneity in panel data with machine learning", "categories": ["stat.ML", "cs.LG", "econ.EM", "stat.ME"], "comment": null, "summary": "In this paper, we present a general specification for Functional Effects\nModels, which use Machine Learning (ML) methodologies to learn\nindividual-specific preference parameters from socio-demographic\ncharacteristics, therefore accounting for inter-individual heterogeneity in\npanel choice data. We identify three specific advantages of the Functional\nEffects Model over traditional fixed, and random/mixed effects models: (i) by\nmapping individual-specific effects as a function of socio-demographic\nvariables, we can account for these effects when forecasting choices of\npreviously unobserved individuals (ii) the (approximate) maximum-likelihood\nestimation of functional effects avoids the incidental parameters problem of\nthe fixed effects model, even when the number of observed choices per\nindividual is small; and (iii) we do not rely on the strong distributional\nassumptions of the random effects model, which may not match reality. We learn\nfunctional intercept and functional slopes with powerful non-linear machine\nlearning regressors for tabular data, namely gradient boosting decision trees\nand deep neural networks. We validate our proposed methodology on a synthetic\nexperiment and three real-world panel case studies, demonstrating that the\nFunctional Effects Model: (i) can identify the true values of\nindividual-specific effects when the data generation process is known; (ii)\noutperforms both state-of-the-art ML choice modelling techniques that omit\nindividual heterogeneity in terms of predictive performance, as well as\ntraditional static panel choice models in terms of learning inter-individual\nheterogeneity. The results indicate that the FI-RUMBoost model, which combines\nthe individual-specific constants of the Functional Effects Model with the\ncomplex, non-linear utilities of RUMBoost, performs marginally best on\nlarge-scale revealed preference panel data."}
{"id": "2509.18054", "pdf": "https://arxiv.org/pdf/2509.18054", "abs": "https://arxiv.org/abs/2509.18054", "authors": ["Nikhil N S", "Amol Dilip Joshi", "Bilal Muhammed", "Soban Babu"], "title": "A Knowledge Graph-based Retrieval-Augmented Generation Framework for Algorithm Selection in the Facility Layout Problem", "categories": ["cs.IR", "cs.AI", "cs.LG"], "comment": "10 pages, 5 figures", "summary": "Selecting a solution algorithm for the Facility Layout Problem (FLP), an\nNP-hard optimization problem with a multiobjective trade-off, is a complex task\nthat requires deep expert knowledge. The performance of a given algorithm\ndepends on specific problem characteristics such as its scale, objectives, and\nconstraints. This creates a need for a data-driven recommendation method to\nguide algorithm selection in automated design systems. This paper introduces a\nnew recommendation method to make such expertise accessible, based on a\nKnowledge Graph-based Retrieval-Augmented Generation (KG RAG) framework. To\naddress this, a domain-specific knowledge graph is constructed from published\nliterature. The method then employs a multi-faceted retrieval mechanism to\ngather relevant evidence from this knowledge graph using three distinct\napproaches, which include a precise graph-based search, flexible vector-based\nsearch, and high-level cluster-based search. The retrieved evidence is utilized\nby a Large Language Model (LLM) to generate algorithm recommendations with\ndata-driven reasoning. The proposed KG-RAG method is compared against a\ncommercial LLM chatbot with access to the knowledge base as a table, across a\nseries of diverse, real-world FLP test cases. Based on recommendation accuracy\nand reasoning capability, the proposed method performed significantly better\nthan the commercial LLM chatbot."}
{"id": "2509.18088", "pdf": "https://arxiv.org/pdf/2509.18088", "abs": "https://arxiv.org/abs/2509.18088", "authors": ["Chuhao Qin", "Evangelos Pournaras"], "title": "Strategic Coordination for Evolving Multi-agent Systems: A Hierarchical Reinforcement and Collective Learning Approach", "categories": ["cs.MA", "cs.LG"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Decentralized combinatorial optimization in evolving multi-agent systems\nposes significant challenges, requiring agents to balance long-term\ndecision-making, short-term optimized collective outcomes, while preserving\nautonomy of interactive agents under unanticipated changes. Reinforcement\nlearning offers a way to model sequential decision-making through dynamic\nprogramming to anticipate future environmental changes. However, applying\nmulti-agent reinforcement learning (MARL) to decentralized combinatorial\noptimization problems remains an open challenge due to the exponential growth\nof the joint state-action space, high communication overhead, and privacy\nconcerns in centralized training. To address these limitations, this paper\nproposes Hierarchical Reinforcement and Collective Learning (HRCL), a novel\napproach that leverages both MARL and decentralized collective learning based\non a hierarchical framework. Agents take high-level strategies using MARL to\ngroup possible plans for action space reduction and constrain the agent\nbehavior for Pareto optimality. Meanwhile, the low-level collective learning\nlayer ensures efficient and decentralized coordinated decisions among agents\nwith minimal communication. Extensive experiments in a synthetic scenario and\nreal-world smart city application models, including energy self-management and\ndrone swarm sensing, demonstrate that HRCL significantly improves performance,\nscalability, and adaptability compared to the standalone MARL and collective\nlearning approaches, achieving a win-win synthesis solution."}
{"id": "2509.18093", "pdf": "https://arxiv.org/pdf/2509.18093", "abs": "https://arxiv.org/abs/2509.18093", "authors": ["William Fleshman", "Benjamin Van Durme"], "title": "SEQR: Secure and Efficient QR-based LoRA Routing", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Low-Rank Adaptation (LoRA) has become a standard technique for\nparameter-efficient fine-tuning of large language models, enabling large\nlibraries of LoRAs, each for a specific task or domain. Efficiently selecting\nthe correct LoRA adapter for a given input remains a challenge, particularly in\nsecure environments where supervised training of routers may raise privacy\nconcerns. Motivated by previous approaches, we formalize the goal of\nunsupervised LoRA routing in terms of activation norm maximization, providing a\ntheoretical framework for analysis. We demonstrate the discriminative power of\nactivation norms and introduce SEQR, an unsupervised LoRA routing algorithm\ndesigned to maximize efficiency while providing strict routing guarantees. SEQR\nprovably identifies the norm-maximizing adapter with significantly greater\nefficiency, making it a highly scalable and effective solution for dynamic LoRA\ncomposition. We validate our results through experiments that demonstrate\nimproved multi-task performance and efficiency."}
