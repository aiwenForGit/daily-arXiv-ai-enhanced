{"id": "2508.10926", "pdf": "https://arxiv.org/pdf/2508.10926", "abs": "https://arxiv.org/abs/2508.10926", "authors": ["DongSeong-Yoon"], "title": "A Cooperative Game-Based Multi-Criteria Weighted Ensemble Approach for Multi-Class Classification", "categories": ["cs.LG"], "comment": "English translation of the author's pre-revision version of the\n  article published in J-KICS 50(4):561-571 (2025), DOI\n  10.7840/kics.2025.50.4.561. Posted with permission from KICS (Aug 7, 2025).\n  The published version may differ", "summary": "Since the Fourth Industrial Revolution, AI technology has been widely used in\nmany fields, but there are several limitations that need to be overcome,\nincluding overfitting/underfitting, class imbalance, and the limitations of\nrepresentation (hypothesis space) due to the characteristics of different\nmodels. As a method to overcome these problems, ensemble, commonly known as\nmodel combining, is being extensively used in the field of machine learning.\nAmong ensemble learning methods, voting ensembles have been studied with\nvarious weighting methods, showing performance improvements. However, the\nexisting methods that reflect the pre-information of classifiers in weights\nconsider only one evaluation criterion, which limits the reflection of various\ninformation that should be considered in a model realistically. Therefore, this\npaper proposes a method of making decisions considering various information\nthrough cooperative games in multi-criteria situations. Using this method,\nvarious types of information known beforehand in classifiers can be\nsimultaneously considered and reflected, leading to appropriate weight\ndistribution and performance improvement. The machine learning algorithms were\napplied to the Open-ML-CC18 dataset and compared with existing ensemble\nweighting methods. The experimental results showed superior performance\ncompared to other weighting methods."}
{"id": "2508.10948", "pdf": "https://arxiv.org/pdf/2508.10948", "abs": "https://arxiv.org/abs/2508.10948", "authors": ["Shruthan Radhakrishna", "Soham Parikh", "Gopal Sarda", "Anil Turkkan", "Quaizar Vohra", "Raymond Li", "Dhruv Jhamb", "Kelechi Ogueji", "Aanjaneya Shukla", "Oluwanifemi Bamgbose", "Toby Liang", "Luke Kumar", "Oleksiy Ostapenko", "Shiva Krishna Reddy Malay", "Aman Tiwari", "Tara Bogavelli", "Vikas Yadav", "Jash Mehta", "Saloni Mittal", "Akshay Kalkunte", "Pulkit Pattnaik", "Khalil Slimi", "Anirudh Sreeram", "Jishnu Nair", "Akintunde Oladipo", "Shashank Maiya", "Khyati Mahajan", "Rishabh Maheshwary", "Masoud Hashemi", "Sai Rajeswar Mudumba", "Sathwik Tejaswi Madhusudhan", "Torsten Scholak", "Sebastien Paquet", "Sagar Davasam", "Srinivas Sunkara"], "title": "Apriel-Nemotron-15B-Thinker", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "While large language models (LLMs) have achieved remarkable reasoning\ncapabilities across domains like code, math and other enterprise tasks, their\nsignificant memory and computational costs often preclude their use in\npractical enterprise settings. To this end, we introduce\nApriel-Nemotron-15B-Thinker, a 15-billion parameter model in the ServiceNow\nApriel SLM series that achieves performance against medium sized\nstate-of-the-art models such as o1-mini, QWQ32B, and EXAONE-Deep-32B while\nmaintaining only half the memory footprint of those alternatives.\nApriel-Nemotron-15B-Thinker model is trained in a four stage training pipeline\nincluding 1) Base Model upscaling, 2) Continual Pre-training 3) Supervised\nFine-tuning (SFT) and 4) Reinforcement Learning using GRPO. Comprehensive\nevaluations across a diverse suite of benchmarks consistently demonstrate that\nour Apriel-Nemotron-15B-Thinker model matches or exceeds the performance of its\n32-billion parameter counterparts, despite being less than half their size."}
{"id": "2508.10954", "pdf": "https://arxiv.org/pdf/2508.10954", "abs": "https://arxiv.org/abs/2508.10954", "authors": ["Gyutae Oh", "Jitae Shin"], "title": "Towards Efficient Prompt-based Continual Learning in Distributed Medical AI", "categories": ["cs.LG", "cs.AI"], "comment": "10p", "summary": "Modern AI models achieve state-of-the-art performance with large-scale,\nhigh-quality datasets; however, ethical, social, and institutional constraints\nin the medical domain severely restrict data sharing, rendering centralized\nlearning nearly impossible. Each institution must incrementally update models\nusing only local data. Traditional training overfits new samples and suffers\nfrom catastrophic forgetting, losing previously acquired knowledge. Medical\ndata distributions also shift due to varying diagnostic equipment and\ndemographics. Although continual learning (CL) has advanced, most methods\naddress natural images, leaving medical-domain-specific CL underexplored. We\npropose a prompt-based continual learning (PCL) approach featuring a unified\nprompt pool with a minimal expansion strategy: by expanding and freezing a\nsubset of prompts, our method reduces computational overhead, and a novel\nregularization term balances retention and adaptation. Experiments on three\ndiabetic retinopathy datasets Aptos2019, LI2019, and Diabetic Retinopathy\nDetection show our model improves final classification accuracy by at least 10%\nand F1-score by 9 points over state-of-the-art approaches while lowering\ninference cost. We anticipate this study will drive sustainable medical AI\nadvances, enabling real-time diagnosis, patient monitoring, and telemedicine\napplications in distributed healthcare. Code will be released upon acceptance"}
{"id": "2508.10967", "pdf": "https://arxiv.org/pdf/2508.10967", "abs": "https://arxiv.org/abs/2508.10967", "authors": ["Xinyi Li", "Sai Wang", "Yutian Lin", "Yu Wu", "Yi Yang"], "title": "Retro-Expert: Collaborative Reasoning for Interpretable Retrosynthesis", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Retrosynthesis prediction aims to infer the reactant molecule based on a\ngiven product molecule, which is a fundamental task in chemical synthesis.\nHowever, existing models rely on static pattern-matching paradigm, which limits\ntheir ability to perform effective logic decision-making, leading to black-box\ndecision-making. Building on this, we propose Retro-Expert, an interpretable\nretrosynthesis framework that performs collaborative reasoning by combining the\ncomplementary reasoning strengths of Large Language Models and specialized\nmodels via reinforcement learning. It outputs natural language explanations\ngrounded in chemical logic through three components: (1) specialized models\nperform shallow reasoning to construct high-quality chemical decision space,\n(2) LLM-driven critical reasoning to generate predictions and corresponding\ninterpretable reasoning path, and (3) reinforcement learning optimizing\ninterpretable decision policy. Experiments show that Retro-Expert not only\nsurpasses both LLM-based and specialized models across different metrics but\nalso provides expert-aligned explanations that bridge the gap between AI\npredictions and actionable chemical insights."}
{"id": "2508.10975", "pdf": "https://arxiv.org/pdf/2508.10975", "abs": "https://arxiv.org/abs/2508.10975", "authors": ["Pratyush Maini", "Vineeth Dorna", "Parth Doshi", "Aldo Carranza", "Fan Pan", "Jack Urbanek", "Paul Burstein", "Alex Fang", "Alvin Deng", "Amro Abbas", "Brett Larsen", "Cody Blakeney", "Charvi Bannur", "Christina Baek", "Darren Teh", "David Schwab", "Haakon Mongstad", "Haoli Yin", "Josh Wills", "Kaleigh Mentzer", "Luke Merrick", "Ricardo Monti", "Rishabh Adiga", "Siddharth Joshi", "Spandan Das", "Zhengping Wang", "Bogdan Gaza", "Ari Morcos", "Matthew Leavitt"], "title": "BeyondWeb: Lessons from Scaling Synthetic Data for Trillion-scale Pretraining", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Recent advances in large language model (LLM) pretraining have shown that\nsimply scaling data quantity eventually leads to diminishing returns, hitting a\ndata wall. In response, the use of synthetic data for pretraining has emerged\nas a promising paradigm for pushing the frontier of performance. Despite this,\nthe factors affecting synthetic data quality remain poorly understood. In this\nwork, we introduce BeyondWeb, a synthetic data generation framework that\nproduces high-quality synthetic data for pretraining. BeyondWeb significantly\nextends the capabilities of traditional web-scale datasets, outperforming\nstate-of-the-art synthetic pretraining datasets such as Cosmopedia and\nNemotron-CC's high-quality synthetic subset (Nemotron-Synth) by up to 5.1\npercentage points (pp) and 2.6pp, respectively, when averaged across a suite of\n14 benchmark evaluations. It delivers up to 7.7x faster training than open web\ndata and 2.7x faster than Nemotron-Synth. Remarkably, a 3B model trained for\n180B tokens on BeyondWeb outperforms an 8B model trained for the same token\nbudget on Cosmopedia. We also present several insights from BeyondWeb on\nsynthetic data for pretraining: what drives its benefits, which data to\nrephrase and how, and the impact of model size and family on data quality.\nOverall, our work shows that there's no silver bullet for generating\nhigh-quality synthetic pretraining data. The best outcomes require jointly\noptimizing many factors, a challenging task that requires rigorous science and\npractical expertise. Naive approaches can yield modest improvements,\npotentially at great cost, while well-executed methods can yield transformative\nimprovements, as exemplified by BeyondWeb."}
{"id": "2508.10993", "pdf": "https://arxiv.org/pdf/2508.10993", "abs": "https://arxiv.org/abs/2508.10993", "authors": ["Basile Lewandowski", "Robert Birke", "Lydia Y. Chen"], "title": "Match & Choose: Model Selection Framework for Fine-tuning Text-to-Image Diffusion Models", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "Text-to-image (T2I) models based on diffusion and transformer architectures\nadvance rapidly. They are often pretrained on large corpora, and openly shared\non a model platform, such as HuggingFace. Users can then build up AI\napplications, e.g., generating media contents, by adopting pretrained T2I\nmodels and fine-tuning them on the target dataset. While public pretrained T2I\nmodels facilitate the democratization of the models, users face a new\nchallenge: which model can be best fine-tuned based on the target data domain?\nModel selection is well addressed in classification tasks, but little is known\nin (pretrained) T2I models and their performance indication on the target\ndomain. In this paper, we propose the first model selection framework, M&C,\nwhich enables users to efficiently choose a pretrained T2I model from a model\nplatform without exhaustively fine-tuning them all on the target dataset. The\ncore of M&C is a matching graph, which consists of: (i) nodes of available\nmodels and profiled datasets, and (ii) edges of model-data and data-data pairs\ncapturing the fine-tuning performance and data similarity, respectively. We\nthen build a model that, based on the inputs of model/data feature, and,\ncritically, the graph embedding feature, extracted from the matching graph,\npredicts the model achieving the best quality after fine-tuning for the target\ndomain. We evaluate M&C on choosing across ten T2I models for 32 datasets\nagainst three baselines. Our results show that M&C successfully predicts the\nbest model for fine-tuning in 61.3% of the cases and a closely performing model\nfor the rest."}
{"id": "2508.11016", "pdf": "https://arxiv.org/pdf/2508.11016", "abs": "https://arxiv.org/abs/2508.11016", "authors": ["Qingbin Li", "Rongkun Xue", "Jie Wang", "Ming Zhou", "Zhi Li", "Xiaofeng Ji", "Yongqi Wang", "Miao Liu", "Zheming Yang", "Minghui Qiu", "Jing Yang"], "title": "CURE: Critical-Token-Guided Re-concatenation for Entropy-collapse Prevention", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent advances in Reinforcement Learning with Verified Reward (RLVR) have\ndriven the emergence of more sophisticated cognitive behaviors in large\nlanguage models (LLMs), thereby enhancing their reasoning capabilities.\nHowever, in prior RLVR pipelines, the repeated use of static initial-state\nsampling drawn exactly from the dataset distribution during each sampling phase\nproduced overly deterministic, low diversity model behavior, which manifested\nas rapid entropy collapse and hindered sustained performance gains during\nprolonged training. To address this issue, we introduce CURE\n(Critical-token-gUided Re concatenation for Entropy-collapse prevention), a\ntwo-stage framework that balances exploration and exploitation. Specifically,\nin the first stage, to deliberately steer the model toward novel yet coherent\ncontexts, we re-generate at high-entropy critical tokens and jointly optimize\nthe original and the branched trajectories. The further comparison with vanilla\nDAPO shows that the regeneration process achieves a better performance on math\nreasoning tasks while sustaining a high-level entropy degree for exploration.\nIn the second stage, we continue training with static initial-state sampling by\nDAPO, intentionally placing the model in a familiar state to gradually\nstrengthen exploitation. Extensive experiments on Qwen-2.5-Math-7B show that,\ncompared to other RLVR methods, CURE achieves a 5% performance gain across six\nmath benchmarks, establishing state-of-the-art performance in both entropy and\naccuracy. A series of experiments further validate the effectiveness of our\napproach. Code is available at https://github.com/CURE-Project/CURE."}
{"id": "2508.11020", "pdf": "https://arxiv.org/pdf/2508.11020", "abs": "https://arxiv.org/abs/2508.11020", "authors": ["Aakash Kumar", "Emanuele Natale"], "title": "Quantization vs Pruning: Insights from the Strong Lottery Ticket Hypothesis", "categories": ["cs.LG"], "comment": null, "summary": "Quantization is an essential technique for making neural networks more\nefficient, yet our theoretical understanding of it remains limited. Previous\nworks demonstrated that extremely low-precision networks, such as binary\nnetworks, can be constructed by pruning large, randomly-initialized networks,\nand showed that the ratio between the size of the original and the pruned\nnetworks is at most polylogarithmic.\n  The specific pruning method they employed inspired a line of theoretical work\nknown as the Strong Lottery Ticket Hypothesis (SLTH), which leverages insights\nfrom the Random Subset Sum Problem. However, these results primarily address\nthe continuous setting and cannot be applied to extend SLTH results to the\nquantized setting.\n  In this work, we build on foundational results by Borgs et al. on the Number\nPartitioning Problem to derive new theoretical results for the Random Subset\nSum Problem in a quantized setting.\n  Using these results, we then extend the SLTH framework to finite-precision\nnetworks. While prior work on SLTH showed that pruning allows approximation of\na certain class of neural networks, we demonstrate that, in the quantized\nsetting, the analogous class of target discrete neural networks can be\nrepresented exactly, and we prove optimal bounds on the necessary\noverparameterization of the initial network as a function of the precision of\nthe target network."}
{"id": "2508.11025", "pdf": "https://arxiv.org/pdf/2508.11025", "abs": "https://arxiv.org/abs/2508.11025", "authors": ["Laura Lützow", "Michael Eichelbeck", "Mykel J. Kochenderfer", "Matthias Althoff"], "title": "Zono-Conformal Prediction: Zonotope-Based Uncertainty Quantification for Regression and Classification Tasks", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "comment": "Preprint. Under review", "summary": "Conformal prediction is a popular uncertainty quantification method that\naugments a base predictor with prediction sets with statistically valid\ncoverage guarantees. However, current methods are often computationally\nexpensive and data-intensive, as they require constructing an uncertainty model\nbefore calibration. Moreover, existing approaches typically represent the\nprediction sets with intervals, which limits their ability to capture\ndependencies in multi-dimensional outputs. We address these limitations by\nintroducing zono-conformal prediction, a novel approach inspired by interval\npredictor models and reachset-conformant identification that constructs\nprediction zonotopes with assured coverage. By placing zonotopic uncertainty\nsets directly into the model of the base predictor, zono-conformal predictors\ncan be identified via a single, data-efficient linear program. While we can\napply zono-conformal prediction to arbitrary nonlinear base predictors, we\nfocus on feed-forward neural networks in this work. Aside from regression\ntasks, we also construct optimal zono-conformal predictors in classification\nsettings where the output of an uncertain predictor is a set of possible\nclasses. We provide probabilistic coverage guarantees and present methods for\ndetecting outliers in the identification data. In extensive numerical\nexperiments, we show that zono-conformal predictors are less conservative than\ninterval predictor models and standard conformal prediction methods, while\nachieving a similar coverage over the test data."}
{"id": "2508.11037", "pdf": "https://arxiv.org/pdf/2508.11037", "abs": "https://arxiv.org/abs/2508.11037", "authors": ["Oliver Ethan Richardson"], "title": "Learning with Confidence", "categories": ["cs.LG", "cs.AI", "math.DG"], "comment": "Accepted for oral UAI 2025, plus some additional modifications for\n  clarity", "summary": "We characterize a notion of confidence that arises in learning or updating\nbeliefs: the amount of trust one has in incoming information and its impact on\nthe belief state. This learner's confidence can be used alongside (and is\neasily mistaken for) probability or likelihood, but it is fundamentally a\ndifferent concept -- one that captures many familiar concepts in the\nliterature, including learning rates and number of training epochs, Shafer's\nweight of evidence, and Kalman gain. We formally axiomatize what it means to\nlearn with confidence, give two canonical ways of measuring confidence on a\ncontinuum, and prove that confidence can always be represented in this way.\nUnder additional assumptions, we derive more compact representations of\nconfidence-based learning in terms of vector fields and loss functions. These\nrepresentations induce an extended language of compound \"parallel\"\nobservations. We characterize Bayes Rule as the special case of an optimizing\nlearner whose loss representation is a linear expectation."}
{"id": "2508.11050", "pdf": "https://arxiv.org/pdf/2508.11050", "abs": "https://arxiv.org/abs/2508.11050", "authors": ["Ujas Shah", "Manuel Lladser", "Rebecca Morrison"], "title": "Conditional Independence Estimates for the Generalized Nonparanormal", "categories": ["cs.LG", "stat.ML"], "comment": "22 pages, 7 figures, 3 tables", "summary": "For general non-Gaussian distributions, the covariance and precision matrices\ndo not encode the independence structure of the variables, as they do for the\nmultivariate Gaussian. This paper builds on previous work to show that for a\nclass of non-Gaussian distributions -- those derived from diagonal\ntransformations of a Gaussian -- information about the conditional independence\nstructure can still be inferred from the precision matrix, provided the data\nmeet certain criteria, analogous to the Gaussian case. We call such\ntransformations of the Gaussian as the generalized nonparanormal. The functions\nthat define these transformations are, in a broad sense, arbitrary. We also\nprovide a simple and computationally efficient algorithm that leverages this\ntheory to recover conditional independence structure from the generalized\nnonparanormal data. The effectiveness of the proposed algorithm is demonstrated\nvia synthetic experiments and applications to real-world data."}
{"id": "2508.11053", "pdf": "https://arxiv.org/pdf/2508.11053", "abs": "https://arxiv.org/abs/2508.11053", "authors": ["Sam Chauhan", "Estelle Duguet", "Karthik Ramakrishnan", "Hugh Van Deventer", "Jack Kruger", "Ranjan Subbaraman"], "title": "SHLIME: Foiling adversarial attacks fooling SHAP and LIME", "categories": ["cs.LG", "cs.CR"], "comment": "7 pages, 7 figures", "summary": "Post hoc explanation methods, such as LIME and SHAP, provide interpretable\ninsights into black-box classifiers and are increasingly used to assess model\nbiases and generalizability. However, these methods are vulnerable to\nadversarial manipulation, potentially concealing harmful biases. Building on\nthe work of Slack et al. (2020), we investigate the susceptibility of LIME and\nSHAP to biased models and evaluate strategies for improving robustness. We\nfirst replicate the original COMPAS experiment to validate prior findings and\nestablish a baseline. We then introduce a modular testing framework enabling\nsystematic evaluation of augmented and ensemble explanation approaches across\nclassifiers of varying performance. Using this framework, we assess multiple\nLIME/SHAP ensemble configurations on out-of-distribution models, comparing\ntheir resistance to bias concealment against the original methods. Our results\nidentify configurations that substantially improve bias detection, highlighting\ntheir potential for enhancing transparency in the deployment of high-stakes\nmachine learning systems."}
{"id": "2508.11075", "pdf": "https://arxiv.org/pdf/2508.11075", "abs": "https://arxiv.org/abs/2508.11075", "authors": ["Hyunwoo Yoo", "Gail Rosen"], "title": "Abundance-Aware Set Transformer for Microbiome Sample Embedding", "categories": ["cs.LG"], "comment": null, "summary": "Microbiome sample representation to input into LLMs is essential for\ndownstream tasks such as phenotype prediction and environmental classification.\nWhile prior studies have explored embedding-based representations of each\nmicrobiome sample, most rely on simple averaging over sequence embeddings,\noften overlooking the biological importance of taxa abundance. In this work, we\npropose an abundance-aware variant of the Set Transformer to construct\nfixed-size sample-level embeddings by weighting sequence embeddings according\nto their relative abundance. Without modifying the model architecture, we\nreplicate embedding vectors proportional to their abundance and apply\nself-attention-based aggregation. Our method outperforms average pooling and\nunweighted Set Transformers on real-world microbiome classification tasks,\nachieving perfect performance in some cases. These results demonstrate the\nutility of abundance-aware aggregation for robust and biologically informed\nmicrobiome representation. To the best of our knowledge, this is one of the\nfirst approaches to integrate sequence-level abundance into Transformer-based\nsample embeddings."}
{"id": "2508.11084", "pdf": "https://arxiv.org/pdf/2508.11084", "abs": "https://arxiv.org/abs/2508.11084", "authors": ["Thanasis Schoinas", "Ghulam Qadir"], "title": "A Feasibility Experiment on the Application of Predictive Coding to Instant Messaging Corpora", "categories": ["cs.LG"], "comment": null, "summary": "Predictive coding, the term used in the legal industry for document\nclassification using machine learning, presents additional challenges when the\ndataset comprises instant messages, due to their informal nature and smaller\nsizes. In this paper, we exploit a data management workflow to group messages\ninto day chats, followed by feature selection and a logistic regression\nclassifier to provide an economically feasible predictive coding solution. We\nalso improve the solution's baseline model performance by dimensionality\nreduction, with focus on quantitative features. We test our methodology on an\nInstant Bloomberg dataset, rich in quantitative information. In parallel, we\nprovide an example of the cost savings of our approach."}
{"id": "2508.11086", "pdf": "https://arxiv.org/pdf/2508.11086", "abs": "https://arxiv.org/abs/2508.11086", "authors": ["Emily Liu", "Kuan Han", "Minfeng Zhan", "Bocheng Zhao", "Guanyu Mu", "Yang Song"], "title": "Relative Advantage Debiasing for Watch-Time Prediction in Short-Video Recommendation", "categories": ["cs.LG", "cs.IR"], "comment": null, "summary": "Watch time is widely used as a proxy for user satisfaction in video\nrecommendation platforms. However, raw watch times are influenced by\nconfounding factors such as video duration, popularity, and individual user\nbehaviors, potentially distorting preference signals and resulting in biased\nrecommendation models. We propose a novel relative advantage debiasing\nframework that corrects watch time by comparing it to empirically derived\nreference distributions conditioned on user and item groups. This approach\nyields a quantile-based preference signal and introduces a two-stage\narchitecture that explicitly separates distribution estimation from preference\nlearning. Additionally, we present distributional embeddings to efficiently\nparameterize watch-time quantiles without requiring online sampling or storage\nof historical data. Both offline and online experiments demonstrate significant\nimprovements in recommendation accuracy and robustness compared to existing\nbaseline methods."}
{"id": "2508.11090", "pdf": "https://arxiv.org/pdf/2508.11090", "abs": "https://arxiv.org/abs/2508.11090", "authors": ["Daniel Mas Montserrat", "David Bonet", "Maria Perera", "Xavier Giró-i-Nieto", "Alexander G. Ioannidis"], "title": "Compressive Meta-Learning", "categories": ["cs.LG", "cs.AI", "cs.CE", "cs.DB", "68T07, 68T05, 68T09", "I.2.6; I.5.1; G.3; H.2.8"], "comment": "Extended version of a paper accepted at KDD '25", "summary": "The rapid expansion in the size of new datasets has created a need for fast\nand efficient parameter-learning techniques. Compressive learning is a\nframework that enables efficient processing by using random, non-linear\nfeatures to project large-scale databases onto compact, information-preserving\nrepresentations whose dimensionality is independent of the number of samples\nand can be easily stored, transferred, and processed. These database-level\nsummaries are then used to decode parameters of interest from the underlying\ndata distribution without requiring access to the original samples, offering an\nefficient and privacy-friendly learning framework. However, both the encoding\nand decoding techniques are typically randomized and data-independent, failing\nto exploit the underlying structure of the data. In this work, we propose a\nframework that meta-learns both the encoding and decoding stages of compressive\nlearning methods by using neural networks that provide faster and more accurate\nsystems than the current state-of-the-art approaches. To demonstrate the\npotential of the presented Compressive Meta-Learning framework, we explore\nmultiple applications -- including neural network-based compressive PCA,\ncompressive ridge regression, compressive k-means, and autoencoders."}
{"id": "2508.11092", "pdf": "https://arxiv.org/pdf/2508.11092", "abs": "https://arxiv.org/abs/2508.11092", "authors": ["Cindy Shih-Ting Huang", "Clarence Boon Liang Ng", "Marek Rei"], "title": "Predictive Multimodal Modeling of Diagnoses and Treatments in EHR", "categories": ["cs.LG"], "comment": "10 pages, 1 figure", "summary": "While the ICD code assignment problem has been widely studied, most works\nhave focused on post-discharge document classification. Models for early\nforecasting of this information could be used for identifying health risks,\nsuggesting effective treatments, or optimizing resource allocation. To address\nthe challenge of predictive modeling using the limited information at the\nbeginning of a patient stay, we propose a multimodal system to fuse clinical\nnotes and tabular events captured in electronic health records. The model\nintegrates pre-trained encoders, feature pooling, and cross-modal attention to\nlearn optimal representations across modalities and balance their presence at\nevery temporal point. Moreover, we present a weighted temporal loss that\nadjusts its contribution at each point in time. Experiments show that these\nstrategies enhance the early prediction model, outperforming the current\nstate-of-the-art systems."}
{"id": "2508.11105", "pdf": "https://arxiv.org/pdf/2508.11105", "abs": "https://arxiv.org/abs/2508.11105", "authors": ["Sajjad Saed", "Babak Teimourpour"], "title": "Hybrid-Hierarchical Fashion Graph Attention Network for Compatibility-Oriented and Personalized Outfit Recommendation", "categories": ["cs.LG", "cs.IR"], "comment": null, "summary": "The rapid expansion of the fashion industry and the growing variety of\nproducts have made it challenging for users to find compatible items on\ne-commerce platforms. Effective fashion recommendation systems are crucial for\nfiltering irrelevant items and suggesting suitable ones. However,\nsimultaneously addressing outfit compatibility and personalized recommendations\nremains a significant challenge, as these aspects are often treated\nindependently in existing studies, often overlooking the complex interactions\nbetween items and user preferences. This research introduces a new framework\nnamed FGAT, inspired by the HFGN model, which leverages graph neural networks\nand graph attention mechanisms to tackle this issue. The proposed framework\nconstructs a three-tier hierarchical graph of users, outfits, and items,\nintegrating visual and textual features to simultaneously model outfit\ncompatibility and user preferences. A graph attention mechanism dynamically\nweights node importance during representation propagation, enabling the capture\nof key interactions and generating precise representations for both user\npreferences and outfit compatibility. Evaluated on the POG dataset, FGAT\noutperforms baseline models such as HFGN, achieving improved results in\nprecision, HR, recall, NDCG, and accuracy.These results demonstrate that\ncombining multimodal visual-textual features with a hierarchical graph\nstructure and attention mechanisms significantly enhances the accuracy and\nefficiency of personalized fashion recommendation systems."}
{"id": "2508.11112", "pdf": "https://arxiv.org/pdf/2508.11112", "abs": "https://arxiv.org/abs/2508.11112", "authors": ["Jianhao Ma", "Lin Xiao"], "title": "Quantization through Piecewise-Affine Regularization: Optimization and Statistical Guarantees", "categories": ["cs.LG", "cs.AI", "math.OC", "stat.ML"], "comment": null, "summary": "Optimization problems over discrete or quantized variables are very\nchallenging in general due to the combinatorial nature of their search space.\nPiecewise-affine regularization (PAR) provides a flexible modeling and\ncomputational framework for quantization based on continuous optimization. In\nthis work, we focus on the setting of supervised learning and investigate the\ntheoretical foundations of PAR from optimization and statistical perspectives.\nFirst, we show that in the overparameterized regime, where the number of\nparameters exceeds the number of samples, every critical point of the\nPAR-regularized loss function exhibits a high degree of quantization. Second,\nwe derive closed-form proximal mappings for various (convex, quasi-convex, and\nnon-convex) PARs and show how to solve PAR-regularized problems using the\nproximal gradient method, its accelerated variant, and the Alternating\nDirection Method of Multipliers. Third, we study statistical guarantees of\nPAR-regularized linear regression problems; specifically, we can approximate\nclassical formulations of $\\ell_1$-, squared $\\ell_2$-, and nonconvex\nregularizations using PAR and obtain similar statistical guarantees with\nquantized solutions."}
{"id": "2508.11144", "pdf": "https://arxiv.org/pdf/2508.11144", "abs": "https://arxiv.org/abs/2508.11144", "authors": ["Gauri Jain", "Dominik Rothenhäusler", "Kirk Bansak", "Elisabeth Paulson"], "title": "CTRL Your Shift: Clustered Transfer Residual Learning for Many Small Datasets", "categories": ["cs.LG"], "comment": null, "summary": "Machine learning (ML) tasks often utilize large-scale data that is drawn from\nseveral distinct sources, such as different locations, treatment arms, or\ngroups. In such settings, practitioners often desire predictions that not only\nexhibit good overall accuracy, but also remain reliable within each source and\npreserve the differences that matter across sources. For instance, several\nasylum and refugee resettlement programs now use ML-based employment\npredictions to guide where newly arriving families are placed within a host\ncountry, which requires generating informative and differentiated predictions\nfor many and often small source locations. However, this task is made\nchallenging by several common characteristics of the data in these settings:\nthe presence of numerous distinct data sources, distributional shifts between\nthem, and substantial variation in sample sizes across sources. This paper\nintroduces Clustered Transfer Residual Learning (CTRL), a meta-learning method\nthat combines the strengths of cross-domain residual learning and adaptive\npooling/clustering in order to simultaneously improve overall accuracy and\npreserve source-level heterogeneity. We provide theoretical results that\nclarify how our objective navigates the trade-off between data quantity and\ndata quality. We evaluate CTRL alongside other state-of-the-art benchmarks on 5\nlarge-scale datasets. This includes a dataset from the national asylum program\nin Switzerland, where the algorithmic geographic assignment of asylum seekers\nis currently being piloted. CTRL consistently outperforms the benchmarks across\nseveral key metrics and when using a range of different base learners."}
{"id": "2508.11145", "pdf": "https://arxiv.org/pdf/2508.11145", "abs": "https://arxiv.org/abs/2508.11145", "authors": ["Huan Zhang", "Daokun Zhang", "Kexin Meng", "Geoffrey I. Webb"], "title": "Towards the Next-generation Bayesian Network Classifiers", "categories": ["cs.LG"], "comment": null, "summary": "Bayesian network classifiers provide a feasible solution to tabular data\nclassification, with a number of merits like high time and memory efficiency,\nand great explainability. However, due to the parameter explosion and data\nsparsity issues, Bayesian network classifiers are restricted to low-order\nfeature dependency modeling, making them struggle in extrapolating the\noccurrence probabilities of complex real-world data. In this paper, we propose\na novel paradigm to design high-order Bayesian network classifiers, by learning\ndistributional representations for feature values, as what has been done in\nword embedding and graph representation learning. The learned distributional\nrepresentations are encoded with the semantic relatedness between different\nfeatures through their observed co-occurrence patterns in training data, which\nthen serve as a hallmark to extrapolate the occurrence probabilities of new\ntest samples. As a classifier design realization, we remake the K-dependence\nBayesian classifier (KDB) by extending it into a neural version, i.e.,\nNeuralKDB, where a novel neural network architecture is designed to learn\ndistributional representations of feature values and parameterize the\nconditional probabilities between interdependent features. A stochastic\ngradient descent based algorithm is designed to train the NeuralKDB model\nefficiently. Extensive classification experiments on 60 UCI datasets\ndemonstrate that the proposed NeuralKDB classifier excels in capturing\nhigh-order feature dependencies and significantly outperforms the conventional\nBayesian network classifiers, as well as other competitive classifiers,\nincluding two neural network based classifiers without distributional\nrepresentation learning."}
{"id": "2508.11159", "pdf": "https://arxiv.org/pdf/2508.11159", "abs": "https://arxiv.org/abs/2508.11159", "authors": ["Heqiang Wang", "Weihong Yang", "Xiaoxiong Zhong", "Jia Zhou", "Fangming Liu", "Weizhe Zhang"], "title": "Mitigating Modality Quantity and Quality Imbalance in Multimodal Online Federated Learning", "categories": ["cs.LG"], "comment": "arXiv admin note: text overlap with arXiv:2505.16138", "summary": "The Internet of Things (IoT) ecosystem produces massive volumes of multimodal\ndata from diverse sources, including sensors, cameras, and microphones. With\nadvances in edge intelligence, IoT devices have evolved from simple data\nacquisition units into computationally capable nodes, enabling localized\nprocessing of heterogeneous multimodal data. This evolution necessitates\ndistributed learning paradigms that can efficiently handle such data.\nFurthermore, the continuous nature of data generation and the limited storage\ncapacity of edge devices demand an online learning framework. Multimodal Online\nFederated Learning (MMO-FL) has emerged as a promising approach to meet these\nrequirements. However, MMO-FL faces new challenges due to the inherent\ninstability of IoT devices, which often results in modality quantity and\nquality imbalance (QQI) during data collection. In this work, we systematically\ninvestigate the impact of QQI within the MMO-FL framework and present a\ncomprehensive theoretical analysis quantifying how both types of imbalance\ndegrade learning performance. To address these challenges, we propose the\nModality Quantity and Quality Rebalanced (QQR) algorithm, a prototype learning\nbased method designed to operate in parallel with the training process.\nExtensive experiments on two real-world multimodal datasets show that the\nproposed QQR algorithm consistently outperforms benchmarks under modality\nimbalance conditions with promising learning performance."}
{"id": "2508.11180", "pdf": "https://arxiv.org/pdf/2508.11180", "abs": "https://arxiv.org/abs/2508.11180", "authors": ["Yiyang Shen", "Weiran Wang"], "title": "A Semi-supervised Generative Model for Incomplete Multi-view Data Integration with Missing Labels", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Multi-view learning is widely applied to real-life datasets, such as multiple\nomics biological data, but it often suffers from both missing views and missing\nlabels. Prior probabilistic approaches addressed the missing view problem by\nusing a product-of-experts scheme to aggregate representations from present\nviews and achieved superior performance over deterministic classifiers, using\nthe information bottleneck (IB) principle. However, the IB framework is\ninherently fully supervised and cannot leverage unlabeled data. In this work,\nwe propose a semi-supervised generative model that utilizes both labeled and\nunlabeled samples in a unified framework. Our method maximizes the likelihood\nof unlabeled samples to learn a latent space shared with the IB on labeled\ndata. We also perform cross-view mutual information maximization in the latent\nspace to enhance the extraction of shared information across views. Compared to\nexisting approaches, our model achieves better predictive and imputation\nperformance on both image and multi-omics data with missing views and limited\nlabeled samples."}
{"id": "2508.11190", "pdf": "https://arxiv.org/pdf/2508.11190", "abs": "https://arxiv.org/abs/2508.11190", "authors": ["Feng-ao Wang", "Shaobo Chen", "Yao Xuan", "Junwei Liu", "Qi Gao", "Hongdong Zhu", "Junjie Hou", "Lixin Yuan", "Jinyu Cheng", "Chenxin Yi", "Hai Wei", "Yin Ma", "Tao Xu", "Kai Wen", "Yixue Li"], "title": "Quantum-Boosted High-Fidelity Deep Learning", "categories": ["cs.LG", "cs.AI", "q-bio.GN"], "comment": null, "summary": "A fundamental limitation of probabilistic deep learning is its predominant\nreliance on Gaussian priors. This simplistic assumption prevents models from\naccurately capturing the complex, non-Gaussian landscapes of natural data,\nparticularly in demanding domains like complex biological data, severely\nhindering the fidelity of the model for scientific discovery. The\nphysically-grounded Boltzmann distribution offers a more expressive\nalternative, but it is computationally intractable on classical computers. To\ndate, quantum approaches have been hampered by the insufficient qubit scale and\noperational stability required for the iterative demands of deep learning.\nHere, we bridge this gap by introducing the Quantum Boltzmann\nMachine-Variational Autoencoder (QBM-VAE), a large-scale and long-time stable\nhybrid quantum-classical architecture. Our framework leverages a quantum\nprocessor for efficient sampling from the Boltzmann distribution, enabling its\nuse as a powerful prior within a deep generative model. Applied to\nmillion-scale single-cell datasets from multiple sources, the QBM-VAE generates\na latent space that better preserves complex biological structures,\nconsistently outperforming conventional Gaussian-based deep learning models\nlike VAE and SCVI in essential tasks such as omics data integration, cell-type\nclassification, and trajectory inference. It also provides a typical example of\nintroducing a physics priori into deep learning to drive the model to acquire\nscientific discovery capabilities that breaks through data limitations. This\nwork provides the demonstration of a practical quantum advantage in deep\nlearning on a large-scale scientific problem and offers a transferable\nblueprint for developing hybrid quantum AI models."}
{"id": "2508.11205", "pdf": "https://arxiv.org/pdf/2508.11205", "abs": "https://arxiv.org/abs/2508.11205", "authors": ["Cheng Jing", "Uvini Balasuriya Mudiyanselage", "Woojin Cho", "Minju Jo", "Anthony Gruber", "Kookjin Lee"], "title": "Meta-learning Structure-Preserving Dynamics", "categories": ["cs.LG"], "comment": null, "summary": "Structure-preserving approaches to dynamics modeling have demonstrated great\npotential for modeling physical systems due to their strong inductive biases\nthat enforce conservation laws and dissipative behavior. However, the resulting\nmodels are typically trained for fixed system configurations, requiring\nexplicit knowledge of system parameters as well as costly retraining for each\nnew set of parameters -- a major limitation in many-query or parameter-varying\nscenarios. Meta-learning offers a potential solution, but existing approaches\nlike optimization-based meta-learning often suffer from training instability or\nlimited generalization capability. Inspired by ideas from computer vision, we\nintroduce a modulation-based meta-learning framework that directly conditions\nstructure-preserving models on compact latent representations of potentially\nunknown system parameters, avoiding the need for gray-box system knowledge and\nexplicit optimization during adaptation. Through the application of novel\nmodulation strategies to parametric energy-conserving and dissipative systems,\nwe enable scalable and generalizable learning across parametric families of\ndynamical systems. Experiments on standard benchmark problems demonstrate that\nour approach achieves accurate predictions in few-shot learning settings,\nwithout compromising on the essential physical constraints necessary for\ndynamical stability and effective generalization performance across parameter\nspace."}
{"id": "2508.11210", "pdf": "https://arxiv.org/pdf/2508.11210", "abs": "https://arxiv.org/abs/2508.11210", "authors": ["Minghui Sun", "Matthew M. Engelhard", "Benjamin A. Goldstein"], "title": "Borrowing From the Future: Enhancing Early Risk Assessment through Contrastive Learning", "categories": ["cs.LG", "stat.ML"], "comment": "accepted by Machine Learning for Healthcare 2025", "summary": "Risk assessments for a pediatric population are often conducted across\nmultiple stages. For example, clinicians may evaluate risks prenatally, at\nbirth, and during Well-Child visits. Although predictions made at later stages\ntypically achieve higher precision, it is clinically desirable to make reliable\nrisk assessments as early as possible. Therefore, this study focuses on\nimproving prediction performance in early-stage risk assessments. Our solution,\n\\textbf{Borrowing From the Future (BFF)}, is a contrastive multi-modal\nframework that treats each time window as a distinct modality. In BFF, a model\nis trained on all available data throughout the time while performing a risk\nassessment using up-to-date information. This contrastive framework allows the\nmodel to ``borrow'' informative signals from later stages (e.g., Well-Child\nvisits) to implicitly supervise the learning at earlier stages (e.g.,\nprenatal/birth stages). We validate BFF on two real-world pediatric outcome\nprediction tasks, demonstrating consistent improvements in early risk\nassessments. The code is available at https://github.com/scotsun/bff."}
{"id": "2508.11214", "pdf": "https://arxiv.org/pdf/2508.11214", "abs": "https://arxiv.org/abs/2508.11214", "authors": ["Atticus Geiger", "Jacqueline Harding", "Thomas Icard"], "title": "How Causal Abstraction Underpins Computational Explanation", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Explanations of cognitive behavior often appeal to computations over\nrepresentations. What does it take for a system to implement a given\ncomputation over suitable representational vehicles within that system? We\nargue that the language of causality -- and specifically the theory of causal\nabstraction -- provides a fruitful lens on this topic. Drawing on current\ndiscussions in deep learning with artificial neural networks, we illustrate how\nclassical themes in the philosophy of computation and cognition resurface in\ncontemporary machine learning. We offer an account of computational\nimplementation grounded in causal abstraction, and examine the role for\nrepresentation in the resulting picture. We argue that these issues are most\nprofitably explored in connection with generalization and prediction."}
{"id": "2508.11215", "pdf": "https://arxiv.org/pdf/2508.11215", "abs": "https://arxiv.org/abs/2508.11215", "authors": ["Zicheng Guo", "Shuqi Wu", "Meixing Zhu", "He Guandi"], "title": "Air Quality PM2.5 Index Prediction Model Based on CNN-LSTM", "categories": ["cs.LG"], "comment": null, "summary": "With the intensification of global climate change, accurate prediction of air\nquality indicators, especially PM2.5 concentration, has become increasingly\nimportant in fields such as environmental protection, public health, and urban\nmanagement. To address this, we propose an air quality PM2.5 index prediction\nmodel based on a hybrid CNN-LSTM architecture. The model effectively combines\nConvolutional Neural Networks (CNN) for local spatial feature extraction and\nLong Short-Term Memory (LSTM) networks for modeling temporal dependencies in\ntime series data. Using a multivariate dataset collected from an industrial\narea in Beijing between 2010 and 2015 -- which includes hourly records of PM2.5\nconcentration, temperature, dew point, pressure, wind direction, wind speed,\nand precipitation -- the model predicts the average PM2.5 concentration over\n6-hour intervals. Experimental results show that the model achieves a root mean\nsquare error (RMSE) of 5.236, outperforming traditional time series models in\nboth accuracy and generalization. This demonstrates its strong potential in\nreal-world applications such as air pollution early warning systems. However,\ndue to the complexity of multivariate inputs, the model demands high\ncomputational resources, and its ability to handle diverse atmospheric factors\nstill requires optimization. Future work will focus on enhancing scalability\nand expanding support for more complex multivariate weather prediction tasks."}
{"id": "2508.11235", "pdf": "https://arxiv.org/pdf/2508.11235", "abs": "https://arxiv.org/abs/2508.11235", "authors": ["William Alemanni", "Arianna Burzacchi", "Davide Colombi", "Elena Giarratano"], "title": "Enhancing Interactive Voting-Based Map Matching: Improving Efficiency and Robustness for Heterogeneous GPS Trajectories", "categories": ["cs.LG"], "comment": null, "summary": "This paper presents an enhanced version of the Interactive Voting-Based Map\nMatching algorithm, designed to efficiently process trajectories with varying\nsampling rates. The main aim is to reconstruct GPS trajectories with high\naccuracy, independent of input data quality. Building upon the original\nalgorithm, developed exclusively for aligning GPS signals to road networks, we\nextend its capabilities by integrating trajectory imputation. Our improvements\nalso include the implementation of a distance-bounded interactive voting\nstrategy to reduce computational complexity, as well as modifications to\naddress missing data in the road network. Furthermore, we incorporate a\ncustom-built asset derived from OpenStreetMap, enabling this approach to be\nsmoothly applied in any geographic region covered by OpenStreetMap's road\nnetwork. These advancements preserve the core strengths of the original\nalgorithm while significantly extending its applicability to diverse real-world\nscenarios."}
{"id": "2508.11249", "pdf": "https://arxiv.org/pdf/2508.11249", "abs": "https://arxiv.org/abs/2508.11249", "authors": ["Asela Hevapathige", "Asiri Wijesinghe", "Ahad N. Zehmakan"], "title": "Graph Neural Diffusion via Generalized Opinion Dynamics", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "There has been a growing interest in developing diffusion-based Graph Neural\nNetworks (GNNs), building on the connections between message passing mechanisms\nin GNNs and physical diffusion processes. However, existing methods suffer from\nthree critical limitations: (1) they rely on homogeneous diffusion with static\ndynamics, limiting adaptability to diverse graph structures; (2) their depth is\nconstrained by computational overhead and diminishing interpretability; and (3)\ntheoretical understanding of their convergence behavior remains limited. To\naddress these challenges, we propose GODNF, a Generalized Opinion Dynamics\nNeural Framework, which unifies multiple opinion dynamics models into a\nprincipled, trainable diffusion mechanism. Our framework captures heterogeneous\ndiffusion patterns and temporal dynamics via node-specific behavior modeling\nand dynamic neighborhood influence, while ensuring efficient and interpretable\nmessage propagation even at deep layers. We provide a rigorous theoretical\nanalysis demonstrating GODNF's ability to model diverse convergence\nconfigurations. Extensive empirical evaluations of node classification and\ninfluence estimation tasks confirm GODNF's superiority over state-of-the-art\nGNNs."}
{"id": "2508.11258", "pdf": "https://arxiv.org/pdf/2508.11258", "abs": "https://arxiv.org/abs/2508.11258", "authors": ["Ruicheng Xian", "Yuxuan Wan", "Han Zhao"], "title": "Group Fairness Meets the Black Box: Enabling Fair Algorithms on Closed LLMs via Post-Processing", "categories": ["cs.LG", "cs.CL", "cs.CY"], "comment": null, "summary": "Instruction fine-tuned large language models (LLMs) enable a simple zero-shot\nor few-shot prompting paradigm, also known as in-context learning, for building\nprediction models. This convenience, combined with continued advances in LLM\ncapability, has the potential to drive their adoption across a broad range of\ndomains, including high-stakes applications where group fairness -- preventing\ndisparate impacts across demographic groups -- is essential. The majority of\nexisting approaches to enforcing group fairness on LLM-based classifiers rely\non traditional fair algorithms applied via model fine-tuning or head-tuning on\nfinal-layer embeddings, but they are no longer applicable to closed-weight LLMs\nunder the in-context learning setting, which include some of the most capable\ncommercial models today, such as GPT-4, Gemini, and Claude. In this paper, we\npropose a framework for deriving fair classifiers from closed-weight LLMs via\nprompting: the LLM is treated as a feature extractor, and features are elicited\nfrom its probabilistic predictions (e.g., token log probabilities) using\nprompts strategically designed for the specified fairness criterion to obtain\nsufficient statistics for fair classification; a fair algorithm is then applied\nto these features to train a lightweight fair classifier in a post-hoc manner.\nExperiments on five datasets, including three tabular ones, demonstrate strong\naccuracy-fairness tradeoffs for the classifiers derived by our framework from\nboth open-weight and closed-weight LLMs; in particular, our framework is\ndata-efficient and outperforms fair classifiers trained on LLM embeddings\n(i.e., head-tuning) or from scratch on raw tabular features."}
{"id": "2508.11279", "pdf": "https://arxiv.org/pdf/2508.11279", "abs": "https://arxiv.org/abs/2508.11279", "authors": ["Jihang Wang", "Dongcheng Zhao", "Ruolin Chen", "Qian Zhang", "Yi Zeng"], "title": "Boosting the Robustness-Accuracy Trade-off of SNNs by Robust Temporal Self-Ensemble", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Spiking Neural Networks (SNNs) offer a promising direction for\nenergy-efficient and brain-inspired computing, yet their vulnerability to\nadversarial perturbations remains poorly understood. In this work, we revisit\nthe adversarial robustness of SNNs through the lens of temporal ensembling,\ntreating the network as a collection of evolving sub-networks across discrete\ntimesteps. This formulation uncovers two critical but underexplored\nchallenges-the fragility of individual temporal sub-networks and the tendency\nfor adversarial vulnerabilities to transfer across time. To overcome these\nlimitations, we propose Robust Temporal self-Ensemble (RTE), a training\nframework that improves the robustness of each sub-network while reducing the\ntemporal transferability of adversarial perturbations. RTE integrates both\nobjectives into a unified loss and employs a stochastic sampling strategy for\nefficient optimization. Extensive experiments across multiple benchmarks\ndemonstrate that RTE consistently outperforms existing training methods in\nrobust-accuracy trade-off. Additional analyses reveal that RTE reshapes the\ninternal robustness landscape of SNNs, leading to more resilient and temporally\ndiversified decision boundaries. Our study highlights the importance of\ntemporal structure in adversarial learning and offers a principled foundation\nfor building robust spiking models."}
{"id": "2508.11328", "pdf": "https://arxiv.org/pdf/2508.11328", "abs": "https://arxiv.org/abs/2508.11328", "authors": ["Haitong Luo", "Suhang Wang", "Weiyao Zhang", "Ruiqi Meng", "Xuying Meng", "Yujun Zhang"], "title": "Generalize across Homophily and Heterophily: Hybrid Spectral Graph Pre-Training and Prompt Tuning", "categories": ["cs.LG", "cs.CL"], "comment": "Under Review", "summary": "Graph ``pre-training and prompt-tuning'' aligns downstream tasks with\npre-trained objectives to enable efficient knowledge transfer under limited\nsupervision. However, existing methods rely on homophily-based low-frequency\nknowledge, failing to handle diverse spectral distributions in real-world\ngraphs with varying homophily. Our theoretical analysis reveals a spectral\nspecificity principle: optimal knowledge transfer requires alignment between\npre-trained spectral filters and the intrinsic spectrum of downstream graphs.\nUnder limited supervision, large spectral gaps between pre-training and\ndownstream tasks impede effective adaptation. To bridge this gap, we propose\nthe HS-GPPT model, a novel framework that ensures spectral alignment throughout\nboth pre-training and prompt-tuning. We utilize a hybrid spectral filter\nbackbone and local-global contrastive learning to acquire abundant spectral\nknowledge. Then we design prompt graphs to align the spectral distribution with\npretexts, facilitating spectral knowledge transfer across homophily and\nheterophily. Extensive experiments validate the effectiveness under both\ntransductive and inductive learning settings. Our code is available at\nhttps://anonymous.4open.science/r/HS-GPPT-62D2/."}
{"id": "2508.11338", "pdf": "https://arxiv.org/pdf/2508.11338", "abs": "https://arxiv.org/abs/2508.11338", "authors": ["Prathamesh Devadiga", "Yashmitha Shailesh"], "title": "RegimeNAS: Regime-Aware Differentiable Architecture Search With Theoretical Guarantees for Financial Trading", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We introduce RegimeNAS, a novel differentiable architecture search framework\nspecifically designed to enhance cryptocurrency trading performance by\nexplicitly integrating market regime awareness. Addressing the limitations of\nstatic deep learning models in highly dynamic financial environments, RegimeNAS\nfeatures three core innovations: (1) a theoretically grounded Bayesian search\nspace optimizing architectures with provable convergence properties; (2)\nspecialized, dynamically activated neural modules (Volatility, Trend, and Range\nblocks) tailored for distinct market conditions; and (3) a multi-objective loss\nfunction incorporating market-specific penalties (e.g., volatility matching,\ntransition smoothness) alongside mathematically enforced Lipschitz stability\nconstraints. Regime identification leverages multi-head attention across\nmultiple timeframes for improved accuracy and uncertainty estimation. Rigorous\nempirical evaluation on extensive real-world cryptocurrency data demonstrates\nthat RegimeNAS significantly outperforms state-of-the-art benchmarks, achieving\nan 80.3% Mean Absolute Error reduction compared to the best traditional\nrecurrent baseline and converging substantially faster (9 vs. 50+ epochs).\nAblation studies and regime-specific analysis confirm the critical contribution\nof each component, particularly the regime-aware adaptation mechanism. This\nwork underscores the imperative of embedding domain-specific knowledge, such as\nmarket regimes, directly within the NAS process to develop robust and adaptive\nmodels for challenging financial applications."}
{"id": "2508.11345", "pdf": "https://arxiv.org/pdf/2508.11345", "abs": "https://arxiv.org/abs/2508.11345", "authors": ["Shuqi Liu", "Jianguo Huang", "Luke Ong"], "title": "Conformal Prediction Meets Long-tail Classification", "categories": ["cs.LG"], "comment": null, "summary": "Conformal Prediction (CP) is a popular method for uncertainty quantification\nthat converts a pretrained model's point prediction into a prediction set, with\nthe set size reflecting the model's confidence. Although existing CP methods\nare guaranteed to achieve marginal coverage, they often exhibit imbalanced\ncoverage across classes under long-tail label distributions, tending to over\ncover the head classes at the expense of under covering the remaining tail\nclasses. This under coverage is particularly concerning, as it undermines the\nreliability of the prediction sets for minority classes, even with coverage\nensured on average. In this paper, we propose the Tail-Aware Conformal\nPrediction (TACP) method to mitigate the under coverage of the tail classes by\nutilizing the long-tail structure and narrowing the head-tail coverage gap.\nTheoretical analysis shows that it consistently achieves a smaller head-tail\ncoverage gap than standard methods. To further improve coverage balance across\nall classes, we introduce an extension of TACP: soft TACP (sTACP) via a\nreweighting mechanism. The proposed framework can be combined with various\nnon-conformity scores, and experiments on multiple long-tail benchmark datasets\ndemonstrate the effectiveness of our methods."}
{"id": "2508.11348", "pdf": "https://arxiv.org/pdf/2508.11348", "abs": "https://arxiv.org/abs/2508.11348", "authors": ["Xiaohan Bi", "Binhang Qi", "Hailong Sun", "Xiang Gao", "Yue Yu", "Xiaojun Liang"], "title": "NeMo: A Neuron-Level Modularizing-While-Training Approach for Decomposing DNN Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "With the growing incorporation of deep neural network (DNN) models into\nmodern software systems, the prohibitive construction costs have become a\nsignificant challenge. Model reuse has been widely applied to reduce training\ncosts, but indiscriminately reusing entire models may incur significant\ninference overhead. Consequently, DNN modularization has gained attention,\nenabling module reuse by decomposing DNN models. The emerging\nmodularizing-while-training (MwT) paradigm, which incorporates modularization\ninto training, outperforms modularizing-after-training approaches. However,\nexisting MwT methods focus on small-scale CNN models at the convolutional\nkernel level and struggle with diverse DNNs and large-scale models,\nparticularly Transformer-based models. To address these limitations, we propose\nNeMo, a scalable and generalizable MwT approach. NeMo operates at the neuron\nlevel fundamental component common to all DNNs-ensuring applicability to\nTransformers and various architectures. We design a contrastive learning-based\nmodular training method with an effective composite loss function, enabling\nscalability to large-scale models. Comprehensive experiments on two\nTransformer-based models and four CNN models across two classification datasets\ndemonstrate NeMo's superiority over state-of-the-art MwT methods. Results show\naverage gains of 1.72% in module classification accuracy and 58.10% reduction\nin module size, demonstrating efficacy across both CNN and large-scale\nTransformer-based models. A case study on open-source projects shows NeMo's\npotential benefits in practical scenarios, offering a promising approach for\nscalable and generalizable DNN modularization."}
{"id": "2508.11349", "pdf": "https://arxiv.org/pdf/2508.11349", "abs": "https://arxiv.org/abs/2508.11349", "authors": ["Angela John", "Selvyn Allotey", "Till Koebe", "Alexandra Tyukavina", "Ingmar Weber"], "title": "A Global Dataset of Location Data Integrity-Assessed Reforestation Efforts", "categories": ["cs.LG"], "comment": "10 figures", "summary": "Afforestation and reforestation are popular strategies for mitigating climate\nchange by enhancing carbon sequestration. However, the effectiveness of these\nefforts is often self-reported by project developers, or certified through\nprocesses with limited external validation. This leads to concerns about data\nreliability and project integrity. In response to increasing scrutiny of\nvoluntary carbon markets, this study presents a dataset on global afforestation\nand reforestation efforts compiled from primary (meta-)information and\naugmented with time-series satellite imagery and other secondary data. Our\ndataset covers 1,289,068 planting sites from 45,628 projects spanning 33 years.\nSince any remote sensing-based validation effort relies on the integrity of a\nplanting site's geographic boundary, this dataset introduces a standardized\nassessment of the provided site-level location information, which we summarize\nin one easy-to-communicate key indicator: LDIS -- the Location Data Integrity\nScore. We find that approximately 79\\% of the georeferenced planting sites\nmonitored fail on at least 1 out of 10 LDIS indicators, while 15\\% of the\nmonitored projects lack machine-readable georeferenced data in the first place.\nIn addition to enhancing accountability in the voluntary carbon market, the\npresented dataset also holds value as training data for e.g. computer\nvision-related tasks with millions of linked Sentinel-2 and Planetscope\nsatellite images."}
{"id": "2508.11353", "pdf": "https://arxiv.org/pdf/2508.11353", "abs": "https://arxiv.org/abs/2508.11353", "authors": ["Han Zhou", "Hongpeng Yin", "Xuanhong Deng", "Yuyu Huang", "Hao Ren"], "title": "Harmonized Gradient Descent for Class Imbalanced Data Stream Online Learning", "categories": ["cs.LG"], "comment": null, "summary": "Many real-world data are sequentially collected over time and often exhibit\nskewed class distributions, resulting in imbalanced data streams. While\nexisting approaches have explored several strategies, such as resampling and\nreweighting, for imbalanced data stream learning, our work distinguishes itself\nby addressing the imbalance problem through training modification, particularly\nfocusing on gradient descent techniques. We introduce the harmonized gradient\ndescent (HGD) algorithm, which aims to equalize the norms of gradients across\ndifferent classes. By ensuring the gradient norm balance, HGD mitigates\nunder-fitting for minor classes and achieves balanced online learning. Notably,\nHGD operates in a streamlined implementation process, requiring no data-buffer,\nextra parameters, or prior knowledge, making it applicable to any learning\nmodels utilizing gradient descent for optimization. Theoretical analysis, based\non a few common and mild assumptions, shows that HGD achieves a satisfied\nsub-linear regret bound. The proposed algorithm are compared with the commonly\nused online imbalance learning methods under several imbalanced data stream\nscenarios. Extensive experimental evaluations demonstrate the efficiency and\neffectiveness of HGD in learning imbalanced data streams."}
{"id": "2508.11356", "pdf": "https://arxiv.org/pdf/2508.11356", "abs": "https://arxiv.org/abs/2508.11356", "authors": ["Jia Liu", "ChangYi He", "YingQiao Lin", "MingMin Yang", "FeiYang Shen", "ShaoGuo Liu", "TingTing Gao"], "title": "ETTRL: Balancing Exploration and Exploitation in LLM Test-Time Reinforcement Learning Via Entropy Mechanism", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent advancements in Large Language Models have yielded significant\nimprovements in complex reasoning tasks such as mathematics and programming.\nHowever, these models remain heavily dependent on annotated data and exhibit\nlimited adaptability in unsupervised scenarios. To address these limitations,\ntest-time reinforcement learning (TTRL) has been proposed, which enables\nself-optimization by leveraging model-generated pseudo-labels. Despite its\npromise, TTRL faces several key challenges, including high inference costs due\nto parallel rollouts and early-stage estimation bias that fosters\noverconfidence, reducing output diversity and causing performance plateaus. To\naddress these challenges, we introduce an entropy-based mechanism to enhance\nthe exploration-exploitation balance in test-time reinforcement learning\nthrough two strategies: Entropy-fork Tree Majority Rollout (ETMR) and\nEntropy-based Advantage Reshaping (EAR). Compared with the baseline, our\napproach enables Llama3.1-8B to achieve a 68 percent relative improvement in\nPass at 1 metric on the AIME 2024 benchmark, while consuming only 60 percent of\nthe rollout tokens budget. This highlights our method's ability to effectively\noptimize the trade-off between inference efficiency, diversity, and estimation\nrobustness, thereby advancing unsupervised reinforcement learning for\nopen-domain reasoning tasks."}
{"id": "2508.11357", "pdf": "https://arxiv.org/pdf/2508.11357", "abs": "https://arxiv.org/abs/2508.11357", "authors": ["Changhong Jing", "Yan Liu", "Shuqiang Wang", "Bruce X. B. Yu", "Gong Chen", "Zhejing Hu", "Zhi Zhang", "Yanyan Shen"], "title": "PTSM: Physiology-aware and Task-invariant Spatio-temporal Modeling for Cross-Subject EEG Decoding", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Cross-subject electroencephalography (EEG) decoding remains a fundamental\nchallenge in brain-computer interface (BCI) research due to substantial\ninter-subject variability and the scarcity of subject-invariant\nrepresentations. This paper proposed PTSM (Physiology-aware and Task-invariant\nSpatio-temporal Modeling), a novel framework for interpretable and robust EEG\ndecoding across unseen subjects. PTSM employs a dual-branch masking mechanism\nthat independently learns personalized and shared spatio-temporal patterns,\nenabling the model to preserve individual-specific neural characteristics while\nextracting task-relevant, population-shared features. The masks are factorized\nacross temporal and spatial dimensions, allowing fine-grained modulation of\ndynamic EEG patterns with low computational overhead. To further address\nrepresentational entanglement, PTSM enforces information-theoretic constraints\nthat decompose latent embeddings into orthogonal task-related and\nsubject-related subspaces. The model is trained end-to-end via a\nmulti-objective loss integrating classification, contrastive, and\ndisentanglement objectives. Extensive experiments on cross-subject motor\nimagery datasets demonstrate that PTSM achieves strong zero-shot\ngeneralization, outperforming state-of-the-art baselines without\nsubject-specific calibration. Results highlight the efficacy of disentangled\nneural representations for achieving both personalized and transferable\ndecoding in non-stationary neurophysiological settings."}
{"id": "2508.11363", "pdf": "https://arxiv.org/pdf/2508.11363", "abs": "https://arxiv.org/abs/2508.11363", "authors": ["Sadegh Khorasani", "Saber Salehkaleybar", "Negar Kiyavash", "Matthias Grossglauser"], "title": "Fusing Rewards and Preferences in Reinforcement Learning", "categories": ["cs.LG", "I.2.6"], "comment": null, "summary": "We present Dual-Feedback Actor (DFA), a reinforcement learning algorithm that\nfuses both individual rewards and pairwise preferences (if available) into a\nsingle update rule. DFA uses the policy's log-probabilities directly to model\nthe preference probability, avoiding a separate reward-modeling step.\nPreferences can be provided by human-annotators (at state-level or\ntrajectory-level) or be synthesized online from Q-values stored in an\noff-policy replay buffer. Under a Bradley-Terry model, we prove that minimizing\nDFA's preference loss recovers the entropy-regularized Soft Actor-Critic (SAC)\npolicy. Our simulation results show that DFA trained on generated preferences\nmatches or exceeds SAC on six control environments and demonstrates a more\nstable training process. With only a semi-synthetic preference dataset under\nBradley-Terry model, our algorithm outperforms reward-modeling reinforcement\nlearning from human feedback (RLHF) baselines in a stochastic GridWorld and\napproaches the performance of an oracle with true rewards."}
{"id": "2508.11365", "pdf": "https://arxiv.org/pdf/2508.11365", "abs": "https://arxiv.org/abs/2508.11365", "authors": ["Jayanta Mandi", "Ali İrfan Mahmutoğulları", "Senne Berden", "Tias Guns"], "title": "Minimizing Surrogate Losses for Decision-Focused Learning using Differentiable Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Decision-focused learning (DFL) trains a machine learning (ML) model to\npredict parameters of an optimization problem, to directly minimize decision\nregret, i.e., maximize decision quality. Gradient-based DFL requires computing\nthe derivative of the solution to the optimization problem with respect to the\npredicted parameters. However, for many optimization problems, such as linear\nprograms (LPs), the gradient of the regret with respect to the predicted\nparameters is zero almost everywhere. Existing gradient-based DFL approaches\nfor LPs try to circumvent this issue in one of two ways: (a) smoothing the LP\ninto a differentiable optimization problem by adding a quadratic regularizer\nand then minimizing the regret directly or (b) minimizing surrogate losses that\nhave informative (sub)gradients. In this paper, we show that the former\napproach still results in zero gradients, because even after smoothing the\nregret remains constant across large regions of the parameter space. To address\nthis, we propose minimizing surrogate losses -- even when a differentiable\noptimization layer is used and regret can be minimized directly. Our\nexperiments demonstrate that minimizing surrogate losses allows differentiable\noptimization layers to achieve regret comparable to or better than\nsurrogate-loss based DFL methods. Further, we demonstrate that this also holds\nfor DYS-Net, a recently proposed differentiable optimization technique for LPs,\nthat computes approximate solutions and gradients through operations that can\nbe performed using feedforward neural network layers. Because DYS-Net executes\nthe forward and the backward pass very efficiently, by minimizing surrogate\nlosses using DYS-Net, we are able to attain regret on par with the\nstate-of-the-art while reducing training time by a significant margin."}
{"id": "2508.11390", "pdf": "https://arxiv.org/pdf/2508.11390", "abs": "https://arxiv.org/abs/2508.11390", "authors": ["Michael Banf", "Dominik Filipiak", "Max Schattauer", "Liliya Imasheva"], "title": "A Remedy for Over-Squashing in Graph Learning via Forman-Ricci Curvature based Graph-to-Hypergraph Structural Lifting", "categories": ["cs.LG"], "comment": null, "summary": "Graph Neural Networks are highly effective at learning from relational data,\nleveraging node and edge features while maintaining the symmetries inherent to\ngraph structures. However, many real-world systems, such as social or\nbiological networks, exhibit complex interactions that are more naturally\nrepresented by higher-order topological domains. The emerging field of\nGeometric and Topological Deep Learning addresses this challenge by introducing\nmethods that utilize and benefit from higher-order structures. Central to TDL\nis the concept of lifting, which transforms data representations from basic\ngraph forms to more expressive topologies before the application of GNN models\nfor learning. In this work, we propose a structural lifting strategy using\nForman-Ricci curvature, which defines an edge-based network characteristic\nbased on Riemannian geometry. Curvature reveals local and global properties of\na graph, such as a network's backbones, i.e. coarse, structure-preserving graph\ngeometries that form connections between major communities - most suitably\nrepresented as hyperedges to model information flows between clusters across\nlarge distances in the network. To this end, our approach provides a remedy to\nthe problem of information distortion in message passing across long distances\nand graph bottlenecks - a phenomenon known in graph learning as over-squashing."}
{"id": "2508.11408", "pdf": "https://arxiv.org/pdf/2508.11408", "abs": "https://arxiv.org/abs/2508.11408", "authors": ["Wenhao Zhang", "Yuexiang Xie", "Yuchang Sun", "Yanxi Chen", "Guoyin Wang", "Yaliang Li", "Bolin Ding", "Jingren Zhou"], "title": "On-Policy RL Meets Off-Policy Experts: Harmonizing Supervised Fine-Tuning and Reinforcement Learning via Dynamic Weighting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) are two\nprominent post-training paradigms for refining the capabilities and aligning\nthe behavior of Large Language Models (LLMs). Existing approaches that\nintegrate SFT and RL often face the risk of disrupting established model\npatterns and inducing overfitting to expert data. To address this, we present a\nnovel investigation into the unified view of SFT and RL through an off-policy\nversus on-policy lens. We propose CHORD, a framework for the Controllable\nHarmonization of On- and Off-Policy Reinforcement Learning via Dynamic\nWeighting, which reframes SFT not as a separate stage but as a dynamically\nweighted auxiliary objective within the on-policy RL process. Based on an\nanalysis of off-policy expert data's influence at both holistic and granular\nlevels, we incorporate a dual-control mechanism in CHORD. Specifically, the\nframework first employs a global coefficient to holistically guide the\ntransition from off-policy imitation to on-policy exploration, and then applies\na token-wise weighting function that enables granular learning from expert\ntokens, which preserves on-policy exploration and mitigates disruption from\noff-policy data. We conduct extensive experiments on widely used benchmarks,\nproviding empirical evidence that CHORD achieves a stable and efficient\nlearning process. By effectively harmonizing off-policy expert data with\non-policy exploration, CHORD demonstrates significant improvements over\nbaselines. We release the implementation at\nhttps://github.com/modelscope/Trinity-RFT/tree/main/examples/mix_chord to\ninspire further research."}
{"id": "2508.11424", "pdf": "https://arxiv.org/pdf/2508.11424", "abs": "https://arxiv.org/abs/2508.11424", "authors": ["Yinghua Yao", "Yuangang Pan", "Xixian Chen"], "title": "Generative Co-Design of Antibody Sequences and Structures via Black-Box Guidance in a Shared Latent Space", "categories": ["cs.LG"], "comment": "Accepted by IJCAI 2025", "summary": "Advancements in deep generative models have enabled the joint modeling of\nantibody sequence and structure, given the antigen-antibody complex as context.\nHowever, existing approaches for optimizing complementarity-determining regions\n(CDRs) to improve developability properties operate in the raw data space,\nleading to excessively costly evaluations due to the inefficient search\nprocess. To address this, we propose LatEnt blAck-box Design (LEAD), a\nsequence-structure co-design framework that optimizes both sequence and\nstructure within their shared latent space. Optimizing shared latent codes can\nnot only break through the limitations of existing methods, but also ensure\nsynchronization of different modality designs. Particularly, we design a\nblack-box guidance strategy to accommodate real-world scenarios where many\nproperty evaluators are non-differentiable. Experimental results demonstrate\nthat our LEAD achieves superior optimization performance for both single and\nmulti-property objectives. Notably, LEAD reduces query consumption by a half\nwhile surpassing baseline methods in property optimization. The code is\navailable at https://github.com/EvaFlower/LatEnt-blAck-box-Design."}
{"id": "2508.11432", "pdf": "https://arxiv.org/pdf/2508.11432", "abs": "https://arxiv.org/abs/2508.11432", "authors": ["Muhammad Zakwan", "Liang Xu", "Giancarlo Ferrari-Trecate"], "title": "Robust Convolution Neural ODEs via Contractivity-promoting regularization", "categories": ["cs.LG", "cs.CV", "cs.SY", "eess.SY"], "comment": "Accepted in IEEE CDC2025, Rio de Janeiro, Brazil", "summary": "Neural networks can be fragile to input noise and adversarial attacks.\n  In this work, we consider Convolutional Neural Ordinary Differential\nEquations (NODEs), a family of continuous-depth neural networks represented by\ndynamical systems, and propose to use contraction theory to improve their\nrobustness.\n  For a contractive dynamical system two trajectories starting from different\ninitial conditions converge to each other exponentially fast.\n  Contractive Convolutional NODEs can enjoy increased robustness as slight\nperturbations of the features do not cause a significant change in the output.\n  Contractivity can be induced during training by using a regularization term\ninvolving the Jacobian of the system dynamics.\n  To reduce the computational burden, we show that it can also be promoted\nusing carefully selected weight regularization terms for a class of NODEs with\nslope-restricted activation functions.\n  The performance of the proposed regularizers is illustrated through benchmark\nimage classification tasks on MNIST and FashionMNIST datasets, where images are\ncorrupted by different kinds of noise and attacks."}
{"id": "2508.11436", "pdf": "https://arxiv.org/pdf/2508.11436", "abs": "https://arxiv.org/abs/2508.11436", "authors": ["Mayssa Soussia", "Mohamed Ali Mahjoub", "Islem Rekik"], "title": "Multi-Sensory Cognitive Computing for Learning Population-level Brain Connectivity", "categories": ["cs.LG"], "comment": null, "summary": "The generation of connectional brain templates (CBTs) has recently garnered\nsignificant attention for its potential to identify unique connectivity\npatterns shared across individuals. However, existing methods for CBT learning\nsuch as conventional machine learning and graph neural networks (GNNs) are\nhindered by several limitations. These include: (i) poor interpretability due\nto their black-box nature, (ii) high computational cost, and (iii) an exclusive\nfocus on structure and topology, overlooking the cognitive capacity of the\ngenerated CBT. To address these challenges, we introduce mCOCO (multi-sensory\nCOgnitive COmputing), a novel framework that leverages Reservoir Computing (RC)\nto learn population-level functional CBT from BOLD\n(Blood-Oxygen-level-Dependent) signals. RC's dynamic system properties allow\nfor tracking state changes over time, enhancing interpretability and enabling\nthe modeling of brain-like dynamics, as demonstrated in prior literature. By\nintegrating multi-sensory inputs (e.g., text, audio, and visual data), mCOCO\ncaptures not only structure and topology but also how brain regions process\ninformation and adapt to cognitive tasks such as sensory processing, all in a\ncomputationally efficient manner. Our mCOCO framework consists of two phases:\n(1) mapping BOLD signals into the reservoir to derive individual functional\nconnectomes, which are then aggregated into a group-level CBT - an approach, to\nthe best of our knowledge, not previously explored in functional connectivity\nstudies - and (2) incorporating multi-sensory inputs through a cognitive\nreservoir, endowing the CBT with cognitive traits. Extensive evaluations show\nthat our mCOCO-based template significantly outperforms GNN-based CBT in terms\nof centeredness, discriminativeness, topological soundness, and multi-sensory\nmemory retention. Our source code is available at\nhttps://github.com/basiralab/mCOCO."}
{"id": "2508.11441", "pdf": "https://arxiv.org/pdf/2508.11441", "abs": "https://arxiv.org/abs/2508.11441", "authors": ["Eric Günther", "Balázs Szabados", "Robi Bhattacharjee", "Sebastian Bordt", "Ulrike von Luxburg"], "title": "Informative Post-Hoc Explanations Only Exist for Simple Functions", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Many researchers have suggested that local post-hoc explanation algorithms\ncan be used to gain insights into the behavior of complex machine learning\nmodels. However, theoretical guarantees about such algorithms only exist for\nsimple decision functions, and it is unclear whether and under which\nassumptions similar results might exist for complex models. In this paper, we\nintroduce a general, learning-theory-based framework for what it means for an\nexplanation to provide information about a decision function. We call an\nexplanation informative if it serves to reduce the complexity of the space of\nplausible decision functions. With this approach, we show that many popular\nexplanation algorithms are not informative when applied to complex decision\nfunctions, providing a rigorous mathematical rejection of the idea that it\nshould be possible to explain any model. We then derive conditions under which\ndifferent explanation algorithms become informative. These are often stronger\nthan what one might expect. For example, gradient explanations and\ncounterfactual explanations are non-informative with respect to the space of\ndifferentiable functions, and SHAP and anchor explanations are not informative\nwith respect to the space of decision trees. Based on these results, we discuss\nhow explanation algorithms can be modified to become informative. While the\nproposed analysis of explanation algorithms is mathematical, we argue that it\nholds strong implications for the practical applicability of these algorithms,\nparticularly for auditing, regulation, and high-risk applications of AI."}
{"id": "2508.11460", "pdf": "https://arxiv.org/pdf/2508.11460", "abs": "https://arxiv.org/abs/2508.11460", "authors": ["Aurora Grefsrud", "Nello Blaser", "Trygve Buanes"], "title": "Calibrated and uncertain? Evaluating uncertainty estimates in binary classification models", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Rigorous statistical methods, including parameter estimation with\naccompanying uncertainties, underpin the validity of scientific discovery,\nespecially in the natural sciences. With increasingly complex data models such\nas deep learning techniques, uncertainty quantification has become exceedingly\ndifficult and a plethora of techniques have been proposed. In this case study,\nwe use the unifying framework of approximate Bayesian inference combined with\nempirical tests on carefully created synthetic classification datasets to\ninvestigate qualitative properties of six different probabilistic machine\nlearning algorithms for class probability and uncertainty estimation: (i) a\nneural network ensemble, (ii) neural network ensemble with conflictual loss,\n(iii) evidential deep learning, (iv) a single neural network with Monte Carlo\nDropout, (v) Gaussian process classification and (vi) a Dirichlet process\nmixture model. We check if the algorithms produce uncertainty estimates which\nreflect commonly desired properties, such as being well calibrated and\nexhibiting an increase in uncertainty for out-of-distribution data points. Our\nresults indicate that all algorithms are well calibrated, but none of the deep\nlearning based algorithms provide uncertainties that consistently reflect lack\nof experimental evidence for out-of-distribution data points. We hope our study\nmay serve as a clarifying example for researchers developing new methods of\nuncertainty estimation for scientific data-driven modeling."}
{"id": "2508.11504", "pdf": "https://arxiv.org/pdf/2508.11504", "abs": "https://arxiv.org/abs/2508.11504", "authors": ["Andrea Castellani", "Zacharias Papadovasilakis", "Giorgos Papoutsoglou", "Mary Cole", "Brian Bautsch", "Tobias Rodemann", "Ioannis Tsamardinos", "Angela Harden"], "title": "Predicting and Explaining Traffic Crash Severity Through Crash Feature Selection", "categories": ["cs.LG", "cs.CY"], "comment": "Preprint. Manuscript under review at \"Accident Analysis & Prevention\"\n  journal", "summary": "Motor vehicle crashes remain a leading cause of injury and death worldwide,\nnecessitating data-driven approaches to understand and mitigate crash severity.\nThis study introduces a curated dataset of more than 3 million people involved\nin accidents in Ohio over six years (2017-2022), aggregated to more than 2.3\nmillion vehicle-level records for predictive analysis. The primary contribution\nis a transparent and reproducible methodology that combines Automated Machine\nLearning (AutoML) and explainable artificial intelligence (AI) to identify and\ninterpret key risk factors associated with severe crashes. Using the JADBio\nAutoML platform, predictive models were constructed to distinguish between\nsevere and non-severe crash outcomes. The models underwent rigorous feature\nselection across stratified training subsets, and their outputs were\ninterpreted using SHapley Additive exPlanations (SHAP) to quantify the\ncontribution of individual features. A final Ridge Logistic Regression model\nachieved an AUC-ROC of 85.6% on the training set and 84.9% on a hold-out test\nset, with 17 features consistently identified as the most influential\npredictors. Key features spanned demographic, environmental, vehicle, human,\nand operational categories, including location type, posted speed, minimum\noccupant age, and pre-crash action. Notably, certain traditionally emphasized\nfactors, such as alcohol or drug impairment, were less influential in the final\nmodel compared to environmental and contextual variables. Emphasizing\nmethodological rigor and interpretability over mere predictive performance,\nthis study offers a scalable framework to support Vision Zero with aligned\ninterventions and advanced data-informed traffic safety policy."}
{"id": "2508.11513", "pdf": "https://arxiv.org/pdf/2508.11513", "abs": "https://arxiv.org/abs/2508.11513", "authors": ["Fanzhen Liu", "Xiaoxiao Ma", "Jian Yang", "Alsharif Abuadbba", "Kristen Moore", "Surya Nepal", "Cecile Paris", "Quan Z. Sheng", "Jia Wu"], "title": "Towards Faithful Class-level Self-explainability in Graph Neural Networks by Subgraph Dependencies", "categories": ["cs.LG", "cs.AI"], "comment": "14 pages, 12 figures", "summary": "Enhancing the interpretability of graph neural networks (GNNs) is crucial to\nensure their safe and fair deployment. Recent work has introduced\nself-explainable GNNs that generate explanations as part of training, improving\nboth faithfulness and efficiency. Some of these models, such as ProtGNN and\nPGIB, learn class-specific prototypes, offering a potential pathway toward\nclass-level explanations. However, their evaluations focus solely on\ninstance-level explanations, leaving open the question of whether these\nprototypes meaningfully generalize across instances of the same class. In this\npaper, we introduce GraphOracle, a novel self-explainable GNN framework\ndesigned to generate and evaluate class-level explanations for GNNs. Our model\njointly learns a GNN classifier and a set of structured, sparse subgraphs that\nare discriminative for each class. We propose a novel integrated training that\ncaptures graph$\\unicode{x2013}$subgraph$\\unicode{x2013}$prediction dependencies\nefficiently and faithfully, validated through a masking-based evaluation\nstrategy. This strategy enables us to retroactively assess whether prior\nmethods like ProtGNN and PGIB deliver effective class-level explanations. Our\nresults show that they do not. In contrast, GraphOracle achieves superior\nfidelity, explainability, and scalability across a range of graph\nclassification tasks. We further demonstrate that GraphOracle avoids the\ncomputational bottlenecks of previous methods$\\unicode{x2014}$like Monte Carlo\nTree Search$\\unicode{x2014}$by using entropy-regularized subgraph selection and\nlightweight random walk extraction, enabling faster and more scalable training.\nThese findings position GraphOracle as a practical and principled solution for\nfaithful class-level self-explainability in GNNs."}
{"id": "2508.11514", "pdf": "https://arxiv.org/pdf/2508.11514", "abs": "https://arxiv.org/abs/2508.11514", "authors": ["Qitong Chu", "Yufeng Yue", "Danya Yao", "Huaxin Pei"], "title": "DiCriTest: Testing Scenario Generation for Decision-Making Agents Considering Diversity and Criticality", "categories": ["cs.LG"], "comment": null, "summary": "The growing deployment of decision-making agents in dynamic environments\nincreases the demand for safety verification. While critical testing scenario\ngeneration has emerged as an appealing verification methodology, effectively\nbalancing diversity and criticality remains a key challenge for existing\nmethods, particularly due to local optima entrapment in high-dimensional\nscenario spaces. To address this limitation, we propose a dual-space guided\ntesting framework that coordinates scenario parameter space and agent behavior\nspace, aiming to generate testing scenarios considering diversity and\ncriticality. Specifically, in the scenario parameter space, a hierarchical\nrepresentation framework combines dimensionality reduction and\nmulti-dimensional subspace evaluation to efficiently localize diverse and\ncritical subspaces. This guides dynamic coordination between two generation\nmodes: local perturbation and global exploration, optimizing critical scenario\nquantity and diversity. Complementarily, in the agent behavior space,\nagent-environment interaction data are leveraged to quantify behavioral\ncriticality/diversity and adaptively support generation mode switching, forming\na closed feedback loop that continuously enhances scenario characterization and\nexploration within the parameter space. Experiments show our framework improves\ncritical scenario generation by an average of 56.23\\% and demonstrates greater\ndiversity under novel parameter-behavior co-driven metrics when tested on five\ndecision-making agents, outperforming state-of-the-art baselines."}
{"id": "2508.11522", "pdf": "https://arxiv.org/pdf/2508.11522", "abs": "https://arxiv.org/abs/2508.11522", "authors": ["Max Guillen", "Philipp Misof", "Jan E. Gerken"], "title": "Finite-Width Neural Tangent Kernels from Feynman Diagrams", "categories": ["cs.LG", "hep-th"], "comment": "11 pages + appendices", "summary": "Neural tangent kernels (NTKs) are a powerful tool for analyzing deep,\nnon-linear neural networks. In the infinite-width limit, NTKs can easily be\ncomputed for most common architectures, yielding full analytic control over the\ntraining dynamics. However, at infinite width, important properties of training\nsuch as NTK evolution or feature learning are absent. Nevertheless, finite\nwidth effects can be included by computing corrections to the Gaussian\nstatistics at infinite width. We introduce Feynman diagrams for computing\nfinite-width corrections to NTK statistics. These dramatically simplify the\nnecessary algebraic manipulations and enable the computation of layer-wise\nrecursive relations for arbitrary statistics involving preactivations, NTKs and\ncertain higher-derivative tensors (dNTK and ddNTK) required to predict the\ntraining dynamics at leading order. We demonstrate the feasibility of our\nframework by extending stability results for deep networks from preactivations\nto NTKs and proving the absence of finite-width corrections for scale-invariant\nnonlinearities such as ReLU on the diagonal of the Gram matrix of the NTK. We\nvalidate our results with numerical experiments."}
{"id": "2508.11528", "pdf": "https://arxiv.org/pdf/2508.11528", "abs": "https://arxiv.org/abs/2508.11528", "authors": ["Juhi Soni", "Markus Lange-Hegermann", "Stefan Windmann"], "title": "Physics-Informed Diffusion Models for Unsupervised Anomaly Detection in Multivariate Time Series", "categories": ["cs.LG"], "comment": "16 pages, 5 figures", "summary": "We propose an unsupervised anomaly detection approach based on a\nphysics-informed diffusion model for multivariate time series data. Over the\npast years, diffusion model has demonstrated its effectiveness in forecasting,\nimputation, generation, and anomaly detection in the time series domain. In\nthis paper, we present a new approach for learning the physics-dependent\ntemporal distribution of multivariate time series data using a weighted\nphysics-informed loss during diffusion model training. A weighted\nphysics-informed loss is constructed using a static weight schedule. This\napproach enables a diffusion model to accurately approximate underlying data\ndistribution, which can influence the unsupervised anomaly detection\nperformance. Our experiments on synthetic and real-world datasets show that\nphysics-informed training improves the F1 score in anomaly detection; it\ngenerates better data diversity and log-likelihood. Our model outperforms\nbaseline approaches, additionally, it surpasses prior physics-informed work and\npurely data-driven diffusion models on a synthetic dataset and one real-world\ndataset while remaining competitive on others."}
{"id": "2508.11529", "pdf": "https://arxiv.org/pdf/2508.11529", "abs": "https://arxiv.org/abs/2508.11529", "authors": ["George Paterakis", "Andrea Castellani", "George Papoutsoglou", "Tobias Rodemann", "Ioannis Tsamardinos"], "title": "A Comprehensive Perspective on Explainable AI across the Machine Learning Workflow", "categories": ["cs.LG", "cs.AI"], "comment": "Preprint. Currently under review at \"Artificial Intelligence Review\"\n  journal", "summary": "Artificial intelligence is reshaping science and industry, yet many users\nstill regard its models as opaque \"black boxes\". Conventional explainable\nartificial-intelligence methods clarify individual predictions but overlook the\nupstream decisions and downstream quality checks that determine whether\ninsights can be trusted. In this work, we present Holistic Explainable\nArtificial Intelligence (HXAI), a user-centric framework that embeds\nexplanation into every stage of the data-analysis workflow and tailors those\nexplanations to users. HXAI unifies six components (data, analysis set-up,\nlearning process, model output, model quality, communication channel) into a\nsingle taxonomy and aligns each component with the needs of domain experts,\ndata analysts and data scientists. A 112-item question bank covers these needs;\nour survey of contemporary tools highlights critical coverage gaps. Grounded in\ntheories of human explanation, principles from human-computer interaction and\nfindings from empirical user studies, HXAI identifies the characteristics that\nmake explanations clear, actionable and cognitively manageable. A comprehensive\ntaxonomy operationalises these insights, reducing terminological ambiguity and\nenabling rigorous coverage analysis of existing toolchains. We further\ndemonstrate how AI agents that embed large-language models can orchestrate\ndiverse explanation techniques, translating technical artifacts into\nstakeholder-specific narratives that bridge the gap between AI developers and\ndomain experts. Departing from traditional surveys or perspective articles,\nthis work melds concepts from multiple disciplines, lessons from real-world\nprojects and a critical synthesis of the literature to advance a novel,\nend-to-end viewpoint on transparency, trustworthiness and responsible AI\ndeployment."}
{"id": "2508.11530", "pdf": "https://arxiv.org/pdf/2508.11530", "abs": "https://arxiv.org/abs/2508.11530", "authors": ["Lianshuai Guo", "Zhongzheng Yuan", "Xunkai Li", "Yinlin Zhu", "Meixia Qu", "Wenyu Wang"], "title": "DFed-SST: Building Semantic- and Structure-aware Topologies for Decentralized Federated Graph Learning", "categories": ["cs.LG"], "comment": null, "summary": "Decentralized Federated Learning (DFL) has emerged as a robust distributed\nparadigm that circumvents the single-point-of-failure and communication\nbottleneck risks of centralized architectures. However, a significant challenge\narises as existing DFL optimization strategies, primarily designed for tasks\nsuch as computer vision, fail to address the unique topological information\ninherent in the local subgraph. Notably, while Federated Graph Learning (FGL)\nis tailored for graph data, it is predominantly implemented in a centralized\nserver-client model, failing to leverage the benefits of decentralization.To\nbridge this gap, we propose DFed-SST, a decentralized federated graph learning\nframework with adaptive communication. The core of our method is a\ndual-topology adaptive communication mechanism that leverages the unique\ntopological features of each client's local subgraph to dynamically construct\nand optimize the inter-client communication topology. This allows our framework\nto guide model aggregation efficiently in the face of heterogeneity. Extensive\nexperiments on eight real-world datasets consistently demonstrate the\nsuperiority of DFed-SST, achieving 3.26% improvement in average accuracy over\nbaseline methods."}
{"id": "2508.11542", "pdf": "https://arxiv.org/pdf/2508.11542", "abs": "https://arxiv.org/abs/2508.11542", "authors": ["Nicole Aretz", "Karen Willcox"], "title": "Nested Operator Inference for Adaptive Data-Driven Learning of Reduced-order Models", "categories": ["cs.LG", "cs.CE", "cs.NA", "math.NA"], "comment": null, "summary": "This paper presents a data-driven, nested Operator Inference (OpInf) approach\nfor learning physics-informed reduced-order models (ROMs) from snapshot data of\nhigh-dimensional dynamical systems. The approach exploits the inherent\nhierarchy within the reduced space to iteratively construct initial guesses for\nthe OpInf learning problem that prioritize the interactions of the dominant\nmodes. The initial guess computed for any target reduced dimension corresponds\nto a ROM with provably smaller or equal snapshot reconstruction error than with\nstandard OpInf. Moreover, our nested OpInf algorithm can be warm-started from\npreviously learned models, enabling versatile application scenarios involving\ndynamic basis and model form updates. We demonstrate the performance of our\nalgorithm on a cubic heat conduction problem, with nested OpInf achieving a\nfour times smaller error than standard OpInf at a comparable offline time.\nFurther, we apply nested OpInf to a large-scale, parameterized model of the\nGreenland ice sheet where, despite model form approximation errors, it learns a\nROM with, on average, 3% error and computational speed-up factor above 19,000."}
{"id": "2508.11553", "pdf": "https://arxiv.org/pdf/2508.11553", "abs": "https://arxiv.org/abs/2508.11553", "authors": ["Jinghui Wang", "Shaojie Wang", "Yinghan Cui", "Xuxing Chen", "Chao Wang", "Xiaojiang Zhang", "Minglei Zhang", "Jiarong Zhang", "Wenhao Zhuang", "Yuchen Cao", "Wankang Bao", "Haimo Li", "Zheng Lin", "Huiming Wang", "Haoyang Huang", "Zongxian Feng", "Zizheng Zhan", "Ken Deng", "Wen Xiang", "Huaixi Tang", "Kun Wu", "Mengtong Li", "Mengfei Xie", "Junyi Peng", "Haotian Zhang", "Bin Chen", "Bing Yu"], "title": "SeamlessFlow: A Trainer Agent Isolation RL Framework Achieving Bubble-Free Pipelines via Tag Scheduling", "categories": ["cs.LG"], "comment": null, "summary": "We introduce SeamlessFlow, a server based reinforcement learning (RL)\nframework that addresses two core challenges in industrial scale RL: (1)\ndecoupling RL training from the complex execution flow of agents; (2)\nmaximizing GPU utilization with minimal idle time while preserving the\nstability and scalability required for large-scale deployments. First,\nSeamlessFlow introduces a data plane that decouples the RL trainer from\ndiverse, complex agent implementations while sustaining high throughput. A\ncentral trajectory manager maintains complete interaction histories and\nsupports partial rollout, allowing rollout to pause for weight updates and\nresume seamlessly, keeping agents unaware of service interruptions. Second, we\npropose a tag driven scheduling paradigm that abstracts hardware into\ncapability tagged resources, unifying colocated and disaggregated\narchitectures. Based on this, SeamlessFlow introduces a spatiotemporal\nmultiplexing pipeline that dynamically reassigns idle training nodes to rollout\nin a train rollout separated setup, eliminating pipeline bubbles and fully\nexploiting heterogeneous cluster resources. By combining these innovations,\nSeamlessFlow delivers both stability and high performance, making it well\nsuited for multi agent, long horizon, and other complex RL tasks."}
{"id": "2508.11618", "pdf": "https://arxiv.org/pdf/2508.11618", "abs": "https://arxiv.org/abs/2508.11618", "authors": ["Jungang Chen", "Seyyed A. Hosseini"], "title": "Optimal CO2 storage management considering safety constraints in multi-stakeholder multi-site CCS projects: a game theoretic perspective", "categories": ["cs.LG"], "comment": "38 pages, 16 figures", "summary": "Carbon capture and storage (CCS) projects typically involve a diverse array\nof stakeholders or players from public, private, and regulatory sectors, each\nwith different objectives and responsibilities. Given the complexity, scale,\nand long-term nature of CCS operations, determining whether individual\nstakeholders can independently maximize their interests or whether\ncollaborative coalition agreements are needed remains a central question for\neffective CCS project planning and management. CCS projects are often\nimplemented in geologically connected sites, where shared geological features\nsuch as pressure space and reservoir pore capacity can lead to competitive\nbehavior among stakeholders. Furthermore, CO2 storage sites are often located\nin geologically mature basins that previously served as sites for hydrocarbon\nextraction or wastewater disposal in order to leverage existing\ninfrastructures, which makes unilateral optimization even more complicated and\nunrealistic.\n  In this work, we propose a paradigm based on Markov games to quantitatively\ninvestigate how different coalition structures affect the goals of\nstakeholders. We frame this multi-stakeholder multi-site problem as a\nmulti-agent reinforcement learning problem with safety constraints. Our\napproach enables agents to learn optimal strategies while compliant with safety\nregulations. We present an example where multiple operators are injecting CO2\ninto their respective project areas in a geologically connected basin. To\naddress the high computational cost of repeated simulations of high-fidelity\nmodels, a previously developed surrogate model based on the Embed-to-Control\n(E2C) framework is employed. Our results demonstrate the effectiveness of the\nproposed framework in addressing optimal management of CO2 storage when\nmultiple stakeholders with various objectives and goals are involved."}
{"id": "1504.08319", "pdf": "https://arxiv.org/pdf/1504.08319", "abs": "https://arxiv.org/abs/1504.08319", "authors": ["Changshuai Wei", "Robert C. Elston", "Qing Lu"], "title": "A weighted U statistic for association analysis considering genetic heterogeneity", "categories": ["stat.ME", "cs.AI", "cs.LG"], "comment": null, "summary": "Converging evidence suggests that common complex diseases with the same or\nsimilar clinical manifestations could have different underlying genetic\netiologies. While current research interests have shifted toward uncovering\nrare variants and structural variations predisposing to human diseases, the\nimpact of heterogeneity in genetic studies of complex diseases has been largely\noverlooked. Most of the existing statistical methods assume the disease under\ninvestigation has a homogeneous genetic effect and could, therefore, have low\npower if the disease undergoes heterogeneous pathophysiological and etiological\nprocesses. In this paper, we propose a heterogeneity weighted U (HWU) method\nfor association analyses considering genetic heterogeneity. HWU can be applied\nto various types of phenotypes (e.g., binary and continuous) and is\ncomputationally effcient for high- dimensional genetic data. Through\nsimulations, we showed the advantage of HWU when the underlying genetic\netiology of a disease was heterogeneous, as well as the robustness of HWU\nagainst different model assumptions (e.g., phenotype distributions). Using HWU,\nwe conducted a genome-wide analysis of nicotine dependence from the Study of\nAddiction: Genetics and Environments (SAGE) dataset. The genome-wide analysis\nof nearly one million genetic markers took 7 hours, identifying heterogeneous\neffects of two new genes (i.e., CYP3A5 and IKBKB) on nicotine dependence."}
{"id": "1505.01179", "pdf": "https://arxiv.org/pdf/1505.01179", "abs": "https://arxiv.org/abs/1505.01179", "authors": ["Changshuai Wei", "Qing Lu"], "title": "A Generalized Similarity U Test for Multivariate Analysis of Sequencing Data", "categories": ["stat.ME", "cs.AI", "cs.LG"], "comment": null, "summary": "Sequencing-based studies are emerging as a major tool for genetic association\nstudies of complex diseases. These studies pose great challenges to the\ntraditional statistical methods (e.g., single-locus analyses based on\nregression methods) because of the high-dimensionality of data and the low\nfrequency of genetic variants. In addition, there is a great interest in\nbiology and epidemiology to identify genetic risk factors contributed to\nmultiple disease phenotypes. The multiple phenotypes can often follow different\ndistributions, which violates the assumptions of most current methods. In this\npaper, we propose a generalized similarity U test, referred to as GSU. GSU is a\nsimilarity-based test and can handle high-dimensional genotypes and phenotypes.\nWe studied the theoretical properties of GSU, and provided the efficient\np-value calculation for association test as well as the sample size and power\ncalculation for the study design. Through simulation, we found that GSU had\nadvantages over existing methods in terms of power and robustness to phenotype\ndistributions. Finally, we used GSU to perform a multivariate analysis of\nsequencing data in the Dallas Heart Study and identified a joint association of\n4 genes with 5 metabolic related phenotypes."}
{"id": "1505.01204", "pdf": "https://arxiv.org/pdf/1505.01204", "abs": "https://arxiv.org/abs/1505.01204", "authors": ["Changshuai Wei", "Ming Li", "Zihuai He", "Olga Vsevolozhskaya", "Daniel J. Schaid", "Qing Lu"], "title": "A Weighted U Statistic for Genetic Association Analyses of Sequencing Data", "categories": ["stat.ME", "cs.AI", "cs.LG", "q-bio.QM"], "comment": null, "summary": "With advancements in next generation sequencing technology, a massive amount\nof sequencing data are generated, offering a great opportunity to\ncomprehensively investigate the role of rare variants in the genetic etiology\nof complex diseases. Nevertheless, this poses a great challenge for the\nstatistical analysis of high-dimensional sequencing data. The association\nanalyses based on traditional statistical methods suffer substantial power loss\nbecause of the low frequency of genetic variants and the extremely high\ndimensionality of the data. We developed a weighted U statistic, referred to as\nWU-seq, for the high-dimensional association analysis of sequencing data. Based\non a non-parametric U statistic, WU-SEQ makes no assumption of the underlying\ndisease model and phenotype distribution, and can be applied to a variety of\nphenotypes. Through simulation studies and an empirical study, we showed that\nWU-SEQ outperformed a commonly used SKAT method when the underlying assumptions\nwere violated (e.g., the phenotype followed a heavy-tailed distribution). Even\nwhen the assumptions were satisfied, WU-SEQ still attained comparable\nperformance to SKAT. Finally, we applied WU-seq to sequencing data from the\nDallas Heart Study (DHS), and detected an association between ANGPTL 4 and very\nlow density lipoprotein cholesterol."}
{"id": "1505.01206", "pdf": "https://arxiv.org/pdf/1505.01206", "abs": "https://arxiv.org/abs/1505.01206", "authors": ["Changshuai Wei", "Daniel J. Schaid", "Qing Lu"], "title": "Trees Assembling Mann Whitney Approach for Detecting Genome-wide Joint Association among Low Marginal Effect loci", "categories": ["q-bio.QM", "cs.AI", "cs.LG", "stat.CO", "stat.ML"], "comment": null, "summary": "Common complex diseases are likely influenced by the interplay of hundreds,\nor even thousands, of genetic variants. Converging evidence shows that genetic\nvariants with low marginal effects (LME) play an important role in disease\ndevelopment. Despite their potential significance, discovering LME genetic\nvariants and assessing their joint association on high dimensional data (e.g.,\ngenome wide association studies) remain a great challenge. To facilitate joint\nassociation analysis among a large ensemble of LME genetic variants, we\nproposed a computationally efficient and powerful approach, which we call Trees\nAssembling Mann whitney (TAMW). Through simulation studies and an empirical\ndata application, we found that TAMW outperformed multifactor dimensionality\nreduction (MDR) and the likelihood ratio based Mann whitney approach (LRMW)\nwhen the underlying complex disease involves multiple LME loci and their\ninteractions. For instance, in a simulation with 20 interacting LME loci, TAMW\nattained a higher power (power=0.931) than both MDR (power=0.599) and LRMW\n(power=0.704). In an empirical study of 29 known Crohn's disease (CD) loci,\nTAMW also identified a stronger joint association with CD than those detected\nby MDR and LRMW. Finally, we applied TAMW to Wellcome Trust CD GWAS to conduct\na genome wide analysis. The analysis of 459K single nucleotide polymorphisms\nwas completed in 40 hours using parallel computing, and revealed a joint\nassociation predisposing to CD (p-value=2.763e-19). Further analysis of the\nnewly discovered association suggested that 13 genes, such as ATG16L1 and\nLACC1, may play an important role in CD pathophysiological and etiological\nprocesses."}
{"id": "1801.01220", "pdf": "https://arxiv.org/pdf/1801.01220", "abs": "https://arxiv.org/abs/1801.01220", "authors": ["Changshuai Wei", "Qing Lu"], "title": "Generalized Similarity U: A Non-parametric Test of Association Based on Similarity", "categories": ["stat.ME", "cs.AI", "cs.LG", "q-bio.GN", "stat.ML"], "comment": null, "summary": "Second generation sequencing technologies are being increasingly used for\ngenetic association studies, where the main research interest is to identify\nsets of genetic variants that contribute to various phenotype. The phenotype\ncan be univariate disease status, multivariate responses and even\nhigh-dimensional outcomes. Considering the genotype and phenotype as two\ncomplex objects, this also poses a general statistical problem of testing\nassociation between complex objects. We here proposed a similarity-based test,\ngeneralized similarity U (GSU), that can test the association between complex\nobjects. We first studied the theoretical properties of the test in a general\nsetting and then focused on the application of the test to sequencing\nassociation studies. Based on theoretical analysis, we proposed to use\nLaplacian kernel based similarity for GSU to boost power and enhance\nrobustness. Through simulation, we found that GSU did have advantages over\nexisting methods in terms of power and robustness. We further performed a whole\ngenome sequencing (WGS) scan for Alzherimer Disease Neuroimaging Initiative\n(ADNI) data, identifying three genes, APOE, APOC1 and TOMM40, associated with\nimaging phenotype. We developed a C++ package for analysis of whole genome\nsequencing data using GSU. The source codes can be downloaded at\nhttps://github.com/changshuaiwei/gsu."}
{"id": "2508.10908", "pdf": "https://arxiv.org/pdf/2508.10908", "abs": "https://arxiv.org/abs/2508.10908", "authors": ["Jeong-Hwan Kim", "Daehyun Kang", "Young-Min Yang", "Jae-Heung Park", "Yoo-Geun Ham"], "title": "Data-driven global ocean model resolving ocean-atmosphere coupling dynamics", "categories": ["physics.ao-ph", "cs.LG", "I.2.1"], "comment": "The manuscript contains 4 main figures. The Extended Data contains 7\n  figures and 3 tables. The Supplementary Information contains 3 text sections,\n  7 figures, 1 table", "summary": "Artificial intelligence has advanced global weather forecasting,\noutperforming traditional numerical models in both accuracy and computational\nefficiency. Nevertheless, extending predictions beyond subseasonal timescales\nrequires the development of deep learning (DL)-based ocean-atmosphere coupled\nmodels that can realistically simulate complex oceanic responses to atmospheric\nforcing. This study presents KIST-Ocean, a DL-based global three-dimensional\nocean general circulation model using a U-shaped visual attention adversarial\nnetwork architecture. KIST-Ocean integrates partial convolution, adversarial\ntraining, and transfer learning to address coastal complexity and predictive\ndistribution drift in auto-regressive models. Comprehensive evaluations\nconfirmed the model's robust ocean predictive skill and efficiency. Moreover,\nit accurately captures realistic ocean response, such as Kelvin and Rossby wave\npropagation in the tropical Pacific, and vertical motions induced by cyclonic\nand anticyclonic wind stress, demonstrating its ability to represent key\nocean-atmosphere coupling mechanisms underlying climate phenomena, including\nthe El Nino-Southern Oscillation. These findings reinforce confidence in\nDL-based global weather and climate models and their extending DL-based\napproaches to broader Earth system modeling, offering potential for enhancing\nclimate prediction capabilities."}
{"id": "2508.10911", "pdf": "https://arxiv.org/pdf/2508.10911", "abs": "https://arxiv.org/abs/2508.10911", "authors": ["Luis Vitor Zerkowski", "Nina S. T. Hirata"], "title": "Uncovering Latent Connections in Indigenous Heritage: Semantic Pipelines for Cultural Preservation in Brazil", "categories": ["cs.HC", "cs.CY", "cs.LG", "I.2.m"], "comment": "8 tables, 7 figures, submitted to AAAI2026", "summary": "Indigenous communities face ongoing challenges in preserving their cultural\nheritage, particularly in the face of systemic marginalization and urban\ndevelopment. In Brazil, the Museu Nacional dos Povos Indigenas through the\nTainacan platform hosts the country's largest online collection of Indigenous\nobjects and iconographies, providing a critical resource for cultural\nengagement. Using publicly available data from this repository, we present a\ndata-driven initiative that applies artificial intelligence to enhance\naccessibility, interpretation, and exploration. We develop two semantic\npipelines: a visual pipeline that models image-based similarity and a textual\npipeline that captures semantic relationships from item descriptions. These\nembedding spaces are projected into two dimensions and integrated into an\ninteractive visualization tool we also developed. In addition to\nsimilarity-based navigation, users can explore the collection through temporal\nand geographic lenses, enabling both semantic and contextualized perspectives.\nThe system supports curatorial tasks, aids public engagement, and reveals\nlatent connections within the collection. This work demonstrates how AI can\nethically contribute to cultural preservation practices."}
{"id": "2508.10915", "pdf": "https://arxiv.org/pdf/2508.10915", "abs": "https://arxiv.org/abs/2508.10915", "authors": ["Jacob Clouse", "Thomas Ramsey", "Samitha Somathilaka", "Nicholas Kleinsasser", "Sangjin Ryu", "Sasitharan Balasubramaniam"], "title": "Insect-Wing Structured Microfluidic System for Reservoir Computing", "categories": ["cs.NE", "cs.ET", "cs.LG"], "comment": null, "summary": "As the demand for more efficient and adaptive computing grows,\nnature-inspired architectures offer promising alternatives to conventional\nelectronic designs. Microfluidic platforms, drawing on biological forms and\nfluid dynamics, present a compelling foundation for low-power, high-resilience\ncomputing in environments where electronics are unsuitable. This study explores\na hybrid reservoir computing system based on a dragonfly-wing inspired\nmicrofluidic chip, which encodes temporal input patterns as fluid interactions\nwithin the micro channel network.\n  The system operates with three dye-based inlet channels and three\ncamera-monitored detection areas, transforming discrete spatial patterns into\ndynamic color output signals. These reservoir output signals are then modified\nand passed to a simple and trainable readout layer for pattern classification.\nUsing a combination of raw reservoir outputs and synthetically generated\noutputs, we evaluated system performance, system clarity, and data efficiency.\nThe results demonstrate consistent classification accuracies up to $91\\%$, even\nwith coarse resolution and limited training data, highlighting the viability of\nthe microfluidic reservoir computing."}
{"id": "2508.10927", "pdf": "https://arxiv.org/pdf/2508.10927", "abs": "https://arxiv.org/abs/2508.10927", "authors": ["Jiaxin Pei", "Soumya Vadlamannati", "Liang-Kang Huang", "Daniel Preotiuc-Pietro", "Xinyu Hua"], "title": "Modeling and Detecting Company Risks from News: A Case Study in Bloomberg News", "categories": ["cs.CL", "cs.AI", "cs.CE", "cs.LG"], "comment": null, "summary": "Identifying risks associated with a company is important to investors and the\nwell-being of the overall financial market. In this study, we build a\ncomputational framework to automatically extract company risk factors from news\narticles. Our newly proposed schema comprises seven distinct aspects, such as\nsupply chain, regulations, and competitions. We sample and annotate 744 news\narticles and benchmark various machine learning models. While large language\nmodels have achieved huge progress in various types of NLP tasks, our\nexperiment shows that zero-shot and few-shot prompting state-of-the-art LLMs\n(e.g. LLaMA-2) can only achieve moderate to low performances in identifying\nrisk factors. And fine-tuned pre-trained language models are performing better\non most of the risk factors. Using this model, we analyze over 277K Bloomberg\nnews articles and demonstrate that identifying risk factors from news could\nprovide extensive insight into the operations of companies and industries."}
{"id": "2508.10928", "pdf": "https://arxiv.org/pdf/2508.10928", "abs": "https://arxiv.org/abs/2508.10928", "authors": ["Sheng Wong", "Beth Albert", "Gabriel Davis Jones"], "title": "CleanCTG: A Deep Learning Model for Multi-Artefact Detection and Reconstruction in Cardiotocography", "categories": ["eess.AS", "cs.LG", "cs.SD"], "comment": null, "summary": "Cardiotocography (CTG) is essential for fetal monitoring but is frequently\ncompromised by diverse artefacts which obscure true fetal heart rate (FHR)\npatterns and can lead to misdiagnosis or delayed intervention. Current\ndeep-learning approaches typically bypass comprehensive noise handling,\napplying minimal preprocessing or focusing solely on downstream classification,\nwhile traditional methods rely on simple interpolation or rule-based filtering\nthat addresses only missing samples and fail to correct complex artefact types.\nWe present CleanCTG, an end-to-end dual-stage model that first identifies\nmultiple artefact types via multi-scale convolution and context-aware\ncross-attention, then reconstructs corrupted segments through artefact-specific\ncorrection branches. Training utilised over 800,000 minutes of physiologically\nrealistic, synthetically corrupted CTGs derived from expert-verified \"clean\"\nrecordings. On synthetic data, CleanCTG achieved perfect artefact detection\n(AU-ROC = 1.00) and reduced mean squared error (MSE) on corrupted segments to\n2.74 x 10^-4 (clean-segment MSE = 2.40 x 10^-6), outperforming the next best\nmethod by more than 60%. External validation on 10,190 minutes of\nclinician-annotated segments yielded AU-ROC = 0.95 (sensitivity = 83.44%,\nspecificity 94.22%), surpassing six comparator classifiers. Finally, when\nintegrated with the Dawes-Redman system on 933 clinical CTG recordings,\ndenoised traces increased specificity (from 80.70% to 82.70%) and shortened\nmedian time to decision by 33%. These findings suggest that explicit artefact\nremoval and signal reconstruction can both maintain diagnostic accuracy and\nenable shorter monitoring sessions, offering a practical route to more reliable\nCTG interpretation."}
{"id": "2508.10935", "pdf": "https://arxiv.org/pdf/2508.10935", "abs": "https://arxiv.org/abs/2508.10935", "authors": ["Qi Liu", "Yabei Li", "Hongsong Wang", "Lei He"], "title": "HQ-OV3D: A High Box Quality Open-World 3D Detection Framework based on Diffision Model", "categories": ["cs.CV", "cs.LG", "cs.RO"], "comment": null, "summary": "Traditional closed-set 3D detection frameworks fail to meet the demands of\nopen-world applications like autonomous driving. Existing open-vocabulary 3D\ndetection methods typically adopt a two-stage pipeline consisting of\npseudo-label generation followed by semantic alignment. While vision-language\nmodels (VLMs) recently have dramatically improved the semantic accuracy of\npseudo-labels, their geometric quality, particularly bounding box precision,\nremains commonly neglected.To address this issue, we propose a High Box Quality\nOpen-Vocabulary 3D Detection (HQ-OV3D) framework, dedicated to generate and\nrefine high-quality pseudo-labels for open-vocabulary classes. The framework\ncomprises two key components: an Intra-Modality Cross-Validated (IMCV) Proposal\nGenerator that utilizes cross-modality geometric consistency to generate\nhigh-quality initial 3D proposals, and an Annotated-Class Assisted (ACA)\nDenoiser that progressively refines 3D proposals by leveraging geometric priors\nfrom annotated categories through a DDIM-based denoising mechanism.Compared to\nthe state-of-the-art method, training with pseudo-labels generated by our\napproach achieves a 7.37% improvement in mAP on novel classes, demonstrating\nthe superior quality of the pseudo-labels produced by our framework. HQ-OV3D\ncan serve not only as a strong standalone open-vocabulary 3D detector but also\nas a plug-in high-quality pseudo-label generator for existing open-vocabulary\ndetection or annotation pipelines."}
{"id": "2508.10944", "pdf": "https://arxiv.org/pdf/2508.10944", "abs": "https://arxiv.org/abs/2508.10944", "authors": ["Mengze Li"], "title": "Non-asymptotic convergence bound of conditional diffusion models", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Learning and generating various types of data based on conditional diffusion\nmodels has been a research hotspot in recent years. Although conditional\ndiffusion models have made considerable progress in improving acceleration\nalgorithms and enhancing generation quality, the lack of non-asymptotic\nproperties has hindered theoretical research. To address this gap, we focus on\na conditional diffusion model within the domains of classification and\nregression (CARD), which aims to learn the original distribution with given\ninput x (denoted as Y|X). It innovatively integrates a pre-trained model\nf_{\\phi}(x) into the original diffusion model framework, allowing it to\nprecisely capture the original conditional distribution given f (expressed as\nY|f_{\\phi}(x)). Remarkably, when f_{\\phi}(x) performs satisfactorily,\nY|f_{\\phi}(x) closely approximates Y|X. Theoretically, we deduce the stochastic\ndifferential equations of CARD and establish its generalized form predicated on\nthe Fokker-Planck equation, thereby erecting a firm theoretical foundation for\nanalysis. Mainly under the Lipschitz assumptions, we utilize the second-order\nWasserstein distance to demonstrate the upper error bound between the original\nand the generated conditional distributions. Additionally, by appending\nassumptions such as light-tailedness to the original distribution, we derive\nthe convergence upper bound between the true value analogous to the score\nfunction and the corresponding network-estimated value."}
{"id": "2508.10945", "pdf": "https://arxiv.org/pdf/2508.10945", "abs": "https://arxiv.org/abs/2508.10945", "authors": ["Rishi Raj Sahoo", "Surbhi Saswati Mohanty", "Subhankar Mishra"], "title": "iWatchRoad: Scalable Detection and Geospatial Visualization of Potholes for Smart Cities", "categories": ["cs.CV", "cs.LG"], "comment": "Under review", "summary": "Potholes on the roads are a serious hazard and maintenance burden. This poses\na significant threat to road safety and vehicle longevity, especially on the\ndiverse and under-maintained roads of India. In this paper, we present a\ncomplete end-to-end system called iWatchRoad for automated pothole detection,\nGlobal Positioning System (GPS) tagging, and real time mapping using\nOpenStreetMap (OSM). We curated a large, self-annotated dataset of over 7,000\nframes captured across various road types, lighting conditions, and weather\nscenarios unique to Indian environments, leveraging dashcam footage. This\ndataset is used to fine-tune, Ultralytics You Only Look Once (YOLO) model to\nperform real time pothole detection, while a custom Optical Character\nRecognition (OCR) module was employed to extract timestamps directly from video\nframes. The timestamps are synchronized with GPS logs to geotag each detected\npotholes accurately. The processed data includes the potholes' details and\nframes as metadata is stored in a database and visualized via a user friendly\nweb interface using OSM. iWatchRoad not only improves detection accuracy under\nchallenging conditions but also provides government compatible outputs for road\nassessment and maintenance planning through the metadata visible on the\nwebsite. Our solution is cost effective, hardware efficient, and scalable,\noffering a practical tool for urban and rural road management in developing\nregions, making the system automated. iWatchRoad is available at\nhttps://smlab.niser.ac.in/project/iwatchroad"}
{"id": "2508.10995", "pdf": "https://arxiv.org/pdf/2508.10995", "abs": "https://arxiv.org/abs/2508.10995", "authors": ["Tejomay Kishor Padole", "Suyash P Awate", "Pushpak Bhattacharyya"], "title": "Improving Text Style Transfer using Masked Diffusion Language Models with Inference-time Scaling", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted as a main conference submission in the European Conference\n  on Artificial Intelligence (ECAI 2025)", "summary": "Masked diffusion language models (MDMs) have recently gained traction as a\nviable generative framework for natural language. This can be attributed to its\nscalability and ease of training compared to other diffusion model paradigms\nfor discrete data, establishing itself as the state-of-the-art\nnon-autoregressive generator for discrete data. Diffusion models, in general,\nhave shown excellent ability to improve the generation quality by leveraging\ninference-time scaling either by increasing the number of denoising steps or by\nusing external verifiers on top of the outputs of each step to guide the\ngeneration. In this work, we propose a verifier-based inference-time scaling\nmethod that aids in finding a better candidate generation during the denoising\nprocess of the MDM. Our experiments demonstrate the application of MDMs for\nstandard text-style transfer tasks and establish MDMs as a better alternative\nto autoregressive language models. Additionally, we show that a simple\nsoft-value-based verifier setup for MDMs using off-the-shelf pre-trained\nembedding models leads to significant gains in generation quality even when\nused on top of typical classifier-free guidance setups in the existing\nliterature."}
{"id": "2508.11060", "pdf": "https://arxiv.org/pdf/2508.11060", "abs": "https://arxiv.org/abs/2508.11060", "authors": ["Jeongjin Lee", "Jong-Min Kim"], "title": "Counterfactual Survival Q Learning for Longitudinal Randomized Trials via Buckley James Boosting", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": null, "summary": "We propose a Buckley James (BJ) Boost Q learning framework for estimating\noptimal dynamic treatment regimes under right censored survival data, tailored\nfor longitudinal randomized clinical trial settings. The method integrates\naccelerated failure time models with iterative boosting techniques, including\ncomponentwise least squares and regression trees, within a counterfactual Q\nlearning framework. By directly modeling conditional survival time, BJ Boost Q\nlearning avoids the restrictive proportional hazards assumption and enables\nunbiased estimation of stage specific Q functions. Grounded in potential\noutcomes, this framework ensures identifiability of the optimal treatment\nregime under standard causal assumptions. Compared to Cox based Q learning,\nwhich relies on hazard modeling and may suffer from bias under\nmisspecification, our approach provides robust and flexible estimation.\nSimulation studies and analysis of the ACTG175 HIV trial demonstrate that BJ\nBoost Q learning yields higher accuracy in treatment decision making,\nespecially in multistage settings where bias can accumulate."}
{"id": "2508.11062", "pdf": "https://arxiv.org/pdf/2508.11062", "abs": "https://arxiv.org/abs/2508.11062", "authors": ["Bhavishya Tarun", "Haoze Du", "Dinesh Kannan", "Edward F. Gehringer"], "title": "Human-in-the-Loop Systems for Adaptive Learning Using Generative AI", "categories": ["cs.HC", "cs.LG"], "comment": "Accepted for presentation at the Frontiers in Education Conference,\n  Nashville, Tennessee, USA, 2-5 November 2025", "summary": "A Human-in-the-Loop (HITL) approach leverages generative AI to enhance\npersonalized learning by directly integrating student feedback into\nAI-generated solutions. Students critique and modify AI responses using\npredefined feedback tags, fostering deeper engagement and understanding. This\nempowers students to actively shape their learning, with AI serving as an\nadaptive partner. The system uses a tagging technique and prompt engineering to\npersonalize content, informing a Retrieval-Augmented Generation (RAG) system to\nretrieve relevant educational material and adjust explanations in real time.\nThis builds on existing research in adaptive learning, demonstrating how\nstudent-driven feedback loops can modify AI-generated responses for improved\nstudent retention and engagement, particularly in STEM education. Preliminary\nfindings from a study with STEM students indicate improved learning outcomes\nand confidence compared to traditional AI tools. This work highlights AI's\npotential to create dynamic, feedback-driven, and personalized learning\nenvironments through iterative refinement."}
{"id": "2508.11069", "pdf": "https://arxiv.org/pdf/2508.11069", "abs": "https://arxiv.org/abs/2508.11069", "authors": ["Olga A. Vsevolozhskaya", "Dmitri V. Zaykin", "Mark C. Greenwood", "Changshuai Wei", "Qing Lu"], "title": "Functional Analysis of Variance for Association Studies", "categories": ["stat.AP", "cs.LG", "stat.ME"], "comment": null, "summary": "While progress has been made in identifying common genetic variants\nassociated with human diseases, for most of common complex diseases, the\nidentified genetic variants only account for a small proportion of\nheritability. Challenges remain in finding additional unknown genetic variants\npredisposing to complex diseases. With the advance in next-generation\nsequencing technologies, sequencing studies have become commonplace in genetic\nresearch. The ongoing exome-sequencing and whole-genome-sequencing studies\ngenerate a massive amount of sequencing variants and allow researchers to\ncomprehensively investigate their role in human diseases. The discovery of new\ndisease-associated variants can be enhanced by utilizing powerful and\ncomputationally efficient statistical methods. In this paper, we propose a\nfunctional analysis of variance (FANOVA) method for testing an association of\nsequence variants in a genomic region with a qualitative trait. The FANOVA has\na number of advantages: (1) it tests for a joint effect of gene variants,\nincluding both common and rare; (2) it fully utilizes linkage disequilibrium\nand genetic position information; and (3) allows for either protective or\nrisk-increasing causal variants. Through simulations, we show that FANOVA\noutperform two popularly used methods - SKAT and a previously proposed method\nbased on functional linear models (FLM), - especially if a sample size of a\nstudy is small and/or sequence variants have low to moderate effects. We\nconduct an empirical study by applying three methods (FANOVA, SKAT and FLM) to\nsequencing data from Dallas Heart Study. While SKAT and FLM respectively\ndetected ANGPTL 4 and ANGPTL 3 associated with obesity, FANOVA was able to\nidentify both genes associated with obesity."}
{"id": "2508.11085", "pdf": "https://arxiv.org/pdf/2508.11085", "abs": "https://arxiv.org/abs/2508.11085", "authors": ["Qingqing Wang", "Liqiang Xiao", "Chang Chang"], "title": "Learn to optimize for automatic proton PBS treatment planning for H&N cancers", "categories": ["cs.AI", "cs.LG"], "comment": "27 pages, 4 figures", "summary": "Proton PBS treatment planning for H&N cancers involves numerous conflicting\nobjectives, requiring significant effort from human planners to balance and\nsatisfy multiple clinical goals during planning. To achieve this,\nexperience-demanding objective parameter adjustment and computationally\nexpensive inverse optimization are performed iteratively. Extensive efforts\nhave been made to automatically adjust objective parameters, but the most\ntime-consuming component, i.e., inverse optimization, still relies heavily on\ntheory-driven approaches. We propose a data-driven inverse optimizer and\nintegrate it into a PPO-based automatic treatment planning framework to\nautomatically generate high-quality plans within a clinical acceptable planning\ntime. The inverse optimizer is a L2O method that predicts update steps by\nlearning from the task-specific data distribution. For the first time, we\nintegrate techniques designed for long-context processing, originally developed\nfor LLMs, into a Transformer-based L2O framework to address the scalability\nissue of existing L2O methods. The PPO framework functions as an outer-loop\nvirtual planner, autonomously adjusting objective parameters through a policy\nnetwork, and the dose predictor is used to initialize objective parameters. The\ninner-loop L2O inverse optimizer computes machine-deliverable MU values based\non objectives refined by the PPO policy network. 97 patients are collected in\nthis study, and compared with L-BFGSB, our L2O-based inverse optimizer improves\nthe effectiveness and efficiency by 22.97% and 36.41%, respectively. In\nconjunction with the PPO-based learned virtual planner, plans generated by our\nframework within an average of 2.55 hours show improved or comparable OAR\nsparing with superior target coverage for patients with different prescription\ndose levels, number of target volumes, beam angles, etc., compared with\nhuman-generated plans."}
{"id": "2508.11175", "pdf": "https://arxiv.org/pdf/2508.11175", "abs": "https://arxiv.org/abs/2508.11175", "authors": ["Ali Karimi", "Hadi Zadeh-Haghighi", "Youssef Kora", "Christoph Simon"], "title": "The Role of Entanglement in Quantum Reservoir Computing with Coupled Kerr Nonlinear Oscillators", "categories": ["quant-ph", "cs.LG", "eess.SP"], "comment": null, "summary": "Quantum Reservoir Computing (QRC) uses quantum dynamics to efficiently\nprocess temporal data. In this work, we investigate a QRC framework based on\ntwo coupled Kerr nonlinear oscillators, a system well-suited for time-series\nprediction tasks due to its complex nonlinear interactions and potentially\nhigh-dimensional state space. We explore how its performance in time-series\nprediction depends on key physical parameters: input drive strength, Kerr\nnonlinearity, and oscillator coupling, and analyze the role of entanglement in\nimproving the reservoir's computational performance, focusing on its effect on\npredicting non-trivial time series. Using logarithmic negativity to quantify\nentanglement and normalized root mean square error (NRMSE) to evaluate\npredictive accuracy, our results suggest that entanglement provides a\ncomputational advantage on average-up to a threshold in the input\nfrequency-that persists under some levels of dissipation and dephasing. In\nparticular, we find that higher dissipation rates can enhance performance.\nWhile the entanglement advantage manifests as improvements in both average and\nworst-case performance, it does not lead to improvements in the best-case\nerror. These findings contribute to the broader understanding of quantum\nreservoirs for high performance, efficient quantum machine learning and\ntime-series forecasting."}
{"id": "2508.11181", "pdf": "https://arxiv.org/pdf/2508.11181", "abs": "https://arxiv.org/abs/2508.11181", "authors": ["Faisal Ahmed"], "title": "HistoViT: Vision Transformer for Accurate and Scalable Histopathological Cancer Diagnosis", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": "13 pages, 3 Figures", "summary": "Accurate and scalable cancer diagnosis remains a critical challenge in modern\npathology, particularly for malignancies such as breast, prostate, bone, and\ncervical, which exhibit complex histological variability. In this study, we\npropose a transformer-based deep learning framework for multi-class tumor\nclassification in histopathological images. Leveraging a fine-tuned Vision\nTransformer (ViT) architecture, our method addresses key limitations of\nconventional convolutional neural networks, offering improved performance,\nreduced preprocessing requirements, and enhanced scalability across tissue\ntypes. To adapt the model for histopathological cancer images, we implement a\nstreamlined preprocessing pipeline that converts tiled whole-slide images into\nPyTorch tensors and standardizes them through data normalization. This ensures\ncompatibility with the ViT architecture and enhances both convergence stability\nand overall classification performance. We evaluate our model on four benchmark\ndatasets: ICIAR2018 (breast), SICAPv2 (prostate), UT-Osteosarcoma (bone), and\nSipakMed (cervical) dataset -- demonstrating consistent outperformance over\nexisting deep learning methods. Our approach achieves classification accuracies\nof 99.32%, 96.92%, 95.28%, and 96.94% for breast, prostate, bone, and cervical\ncancers respectively, with area under the ROC curve (AUC) scores exceeding 99%\nacross all datasets. These results confirm the robustness, generalizability,\nand clinical potential of transformer-based architectures in digital pathology.\nOur work represents a significant advancement toward reliable, automated, and\ninterpretable cancer diagnosis systems that can alleviate diagnostic burdens\nand improve healthcare outcomes."}
{"id": "2508.11185", "pdf": "https://arxiv.org/pdf/2508.11185", "abs": "https://arxiv.org/abs/2508.11185", "authors": ["Abhinav Kumar", "Yuliang Guo", "Zhihao Zhang", "Xinyu Huang", "Liu Ren", "Xiaoming Liu"], "title": "CHARM3R: Towards Unseen Camera Height Robust Monocular 3D Detector", "categories": ["cs.CV", "cs.LG"], "comment": "ICCV 2025", "summary": "Monocular 3D object detectors, while effective on data from one ego camera\nheight, struggle with unseen or out-of-distribution camera heights. Existing\nmethods often rely on Plucker embeddings, image transformations or data\naugmentation. This paper takes a step towards this understudied problem by\nfirst investigating the impact of camera height variations on state-of-the-art\n(SoTA) Mono3D models. With a systematic analysis on the extended CARLA dataset\nwith multiple camera heights, we observe that depth estimation is a primary\nfactor influencing performance under height variations. We mathematically prove\nand also empirically observe consistent negative and positive trends in mean\ndepth error of regressed and ground-based depth models, respectively, under\ncamera height changes. To mitigate this, we propose Camera Height Robust\nMonocular 3D Detector (CHARM3R), which averages both depth estimates within the\nmodel. CHARM3R improves generalization to unseen camera heights by more than\n$45\\%$, achieving SoTA performance on the CARLA dataset. Codes and Models at\nhttps://github.com/abhi1kumar/CHARM3R"}
{"id": "2508.11197", "pdf": "https://arxiv.org/pdf/2508.11197", "abs": "https://arxiv.org/abs/2508.11197", "authors": ["Ahmad Mousavi", "Yeganeh Abdollahinejad", "Roberto Corizzo", "Nathalie Japkowicz", "Zois Boukouvalas"], "title": "E-CaTCH: Event-Centric Cross-Modal Attention with Temporal Consistency and Class-Imbalance Handling for Misinformation Detection", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SI"], "comment": null, "summary": "Detecting multimodal misinformation on social media remains challenging due\nto inconsistencies between modalities, changes in temporal patterns, and\nsubstantial class imbalance. Many existing methods treat posts independently\nand fail to capture the event-level structure that connects them across time\nand modality. We propose E-CaTCH, an interpretable and scalable framework for\nrobustly detecting misinformation. If needed, E-CaTCH clusters posts into\npseudo-events based on textual similarity and temporal proximity, then\nprocesses each event independently. Within each event, textual and visual\nfeatures are extracted using pre-trained BERT and ResNet encoders, refined via\nintra-modal self-attention, and aligned through bidirectional cross-modal\nattention. A soft gating mechanism fuses these representations to form\ncontextualized, content-aware embeddings of each post. To model temporal\nevolution, E-CaTCH segments events into overlapping time windows and uses a\ntrend-aware LSTM, enhanced with semantic shift and momentum signals, to encode\nnarrative progression over time. Classification is performed at the event\nlevel, enabling better alignment with real-world misinformation dynamics. To\naddress class imbalance and promote stable learning, the model integrates\nadaptive class weighting, temporal consistency regularization, and hard-example\nmining. The total loss is aggregated across all events. Extensive experiments\non Fakeddit, IND, and COVID-19 MISINFOGRAPH demonstrate that E-CaTCH\nconsistently outperforms state-of-the-art baselines. Cross-dataset evaluations\nfurther demonstrate its robustness, generalizability, and practical\napplicability across diverse misinformation scenarios."}
{"id": "2508.11218", "pdf": "https://arxiv.org/pdf/2508.11218", "abs": "https://arxiv.org/abs/2508.11218", "authors": ["Jialin Li", "Shuqi Wu", "Ning Wang"], "title": "A CLIP-based Uncertainty Modal Modeling (UMM) Framework for Pedestrian Re-Identification in Autonomous Driving", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Re-Identification (ReID) is a critical technology in intelligent perception\nsystems, especially within autonomous driving, where onboard cameras must\nidentify pedestrians across views and time in real-time to support safe\nnavigation and trajectory prediction. However, the presence of uncertain or\nmissing input modalities--such as RGB, infrared, sketches, or textual\ndescriptions--poses significant challenges to conventional ReID approaches.\nWhile large-scale pre-trained models offer strong multimodal semantic modeling\ncapabilities, their computational overhead limits practical deployment in\nresource-constrained environments. To address these challenges, we propose a\nlightweight Uncertainty Modal Modeling (UMM) framework, which integrates a\nmultimodal token mapper, synthetic modality augmentation strategy, and\ncross-modal cue interactive learner. Together, these components enable unified\nfeature representation, mitigate the impact of missing modalities, and extract\ncomplementary information across different data types. Additionally, UMM\nleverages CLIP's vision-language alignment ability to fuse multimodal inputs\nefficiently without extensive finetuning. Experimental results demonstrate that\nUMM achieves strong robustness, generalization, and computational efficiency\nunder uncertain modality conditions, offering a scalable and practical solution\nfor pedestrian re-identification in autonomous driving scenarios."}
{"id": "2508.11274", "pdf": "https://arxiv.org/pdf/2508.11274", "abs": "https://arxiv.org/abs/2508.11274", "authors": ["Paul Dommel", "Rajmadan Lakshmanan"], "title": "Uniform convergence for Gaussian kernel ridge regression", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "This paper establishes the first polynomial convergence rates for Gaussian\nkernel ridge regression (KRR) with a fixed hyperparameter in both the uniform\nand the $L^{2}$-norm. The uniform convergence result closes a gap in the\ntheoretical understanding of KRR with the Gaussian kernel, where no such rates\nwere previously known. In addition, we prove a polynomial $L^{2}$-convergence\nrate in the case, where the Gaussian kernel's width parameter is fixed. This\nalso contributes to the broader understanding of smooth kernels, for which\npreviously only sub-polynomial $L^{2}$-rates were known in similar settings.\nTogether, these results provide new theoretical justification for the use of\nGaussian KRR with fixed hyperparameters in nonparametric regression."}
{"id": "2508.11277", "pdf": "https://arxiv.org/pdf/2508.11277", "abs": "https://arxiv.org/abs/2508.11277", "authors": ["Matthew Lyle Olson", "Musashi Hinck", "Neale Ratzlaff", "Changbai Li", "Phillip Howard", "Vasudev Lal", "Shao-Yen Tseng"], "title": "Probing the Representational Power of Sparse Autoencoders in Vision Models", "categories": ["cs.CV", "cs.LG"], "comment": "ICCV 2025 Findings", "summary": "Sparse Autoencoders (SAEs) have emerged as a popular tool for interpreting\nthe hidden states of large language models (LLMs). By learning to reconstruct\nactivations from a sparse bottleneck layer, SAEs discover interpretable\nfeatures from the high-dimensional internal representations of LLMs. Despite\ntheir popularity with language models, SAEs remain understudied in the visual\ndomain. In this work, we provide an extensive evaluation the representational\npower of SAEs for vision models using a broad range of image-based tasks. Our\nexperimental results demonstrate that SAE features are semantically meaningful,\nimprove out-of-distribution generalization, and enable controllable generation\nacross three vision model architectures: vision embedding models, multi-modal\nLMMs and diffusion models. In vision embedding models, we find that learned SAE\nfeatures can be used for OOD detection and provide evidence that they recover\nthe ontological structure of the underlying model. For diffusion models, we\ndemonstrate that SAEs enable semantic steering through text encoder\nmanipulation and develop an automated pipeline for discovering\nhuman-interpretable attributes. Finally, we conduct exploratory experiments on\nmulti-modal LLMs, finding evidence that SAE features reveal shared\nrepresentations across vision and language modalities. Our study provides a\nfoundation for SAE evaluation in vision models, highlighting their strong\npotential improving interpretability, generalization, and steerability in the\nvisual domain."}
{"id": "2508.11287", "pdf": "https://arxiv.org/pdf/2508.11287", "abs": "https://arxiv.org/abs/2508.11287", "authors": ["Xuran Liu", "Nan Xue", "Rui Bao", "Yaping Sun", "Zhiyong Chen", "Meixia Tao", "Xiaodong Xu", "Shuguang Cui"], "title": "CSGO: Generalized Optimization for Cold Start in Wireless Collaborative Edge LLM Systems", "categories": ["cs.IT", "cs.AI", "cs.LG", "math.IT"], "comment": "submitted to Journal of Communications and Information Networks", "summary": "While deploying large language models on edge devices promises low-latency\nand privacy-preserving AI services, it is hindered by limited device resources.\nAlthough pipeline parallelism facilitates distributed inference, existing\napproaches often ignore the cold-start latency caused by on-demand model\nloading. In this paper, we propose a latency-aware scheduling framework that\noverlaps model loading with computation and communication to minimize total\ninference latency. Based on device and model parameters, the framework\ndynamically adjusts layer partitioning and allocation to effectively hide\nloading time, thereby eliminating as many idle periods as possible. We\nformulate the problem as a Mixed-Integer Non-Linear Program and design an\nefficient dynamic programming algorithm to optimize model partitioning and\ndevice assignment. Experimental results show that the proposed method\nsignificantly reduces cold-start latency compared to baseline strategies."}
{"id": "2508.11291", "pdf": "https://arxiv.org/pdf/2508.11291", "abs": "https://arxiv.org/abs/2508.11291", "authors": ["Rui Bao", "Nan Xue", "Yaping Sun", "Zhiyong Chen"], "title": "Dynamic Quality-Latency Aware Routing for LLM Inference in Wireless Edge-Device Networks", "categories": ["cs.IT", "cs.AI", "cs.LG", "math.IT"], "comment": "accepted by IEEE/CIC ICCC workshop", "summary": "The integration of wireless communications and Large Language Models (LLMs)\nis poised to unlock ubiquitous intelligent services, yet deploying them in\nwireless edge-device collaborative environments presents a critical trade-off\nbetween inference quality and end-to-end latency. A fundamental mismatch exists\nbetween task complexity and resource allocation: offloading simple queries\ninvites prohibitive latency, while on-device models lack the capacity for\ndemanding computations. To address this challenge, we propose a dynamic,\nquality-latency aware routing framework that orchestrates inference between a\nlightweight model on the mobile device and a powerful model on the edge server.\nOur framework employs two distinct cost models: for single-turn queries, it\nfuses a BERT-predicted semantic score with communication and computation\noverheads; for multi-turn dialogues, it further quantifies context-aware costs\narising from model switching and KV-cache management. While maintaining full\ninference quality, extensive experiments demonstrate that our framework cuts\naverage response latency by 5-15% and reduces large model invocations by 10-20%\nagainst competitive baselines on MMLU, GSM8K, and MT-Bench-101 benchmarks."}
{"id": "2508.11307", "pdf": "https://arxiv.org/pdf/2508.11307", "abs": "https://arxiv.org/abs/2508.11307", "authors": ["Sabin Roman", "Gregor Skok", "Ljupco Todorovski", "Saso Dzeroski"], "title": "Approximating the universal thermal climate index using sparse regression with orthogonal polynomials", "categories": ["physics.ao-ph", "cs.LG", "physics.data-an"], "comment": null, "summary": "This article explores novel data-driven modeling approaches for analyzing and\napproximating the Universal Thermal Climate Index (UTCI), a\nphysiologically-based metric integrating multiple atmospheric variables to\nassess thermal comfort. Given the nonlinear, multivariate structure of UTCI, we\ninvestigate symbolic and sparse regression techniques as tools for\ninterpretable and efficient function approximation. In particular, we highlight\nthe benefits of using orthogonal polynomial bases-such as Legendre\npolynomials-in sparse regression frameworks, demonstrating their advantages in\nstability, convergence, and hierarchical interpretability compared to standard\npolynomial expansions. We demonstrate that our models achieve significantly\nlower root-mean squared losses than the widely used sixth-degree polynomial\nbenchmark-while using the same or fewer parameters. By leveraging Legendre\npolynomial bases, we construct models that efficiently populate a Pareto front\nof accuracy versus complexity and exhibit stable, hierarchical coefficient\nstructures across varying model capacities. Training on just 20% of the data,\nour models generalize robustly to the remaining 80%, with consistent\nperformance under bootstrapping. The decomposition effectively approximates the\nUTCI as a Fourier-like expansion in an orthogonal basis, yielding results near\nthe theoretical optimum in the L2 (least squares) sense. We also connect these\nfindings to the broader context of equation discovery in environmental\nmodeling, referencing probabilistic grammar-based methods that enforce domain\nconsistency and compactness in symbolic expressions. Taken together, these\nresults illustrate how combining sparsity, orthogonality, and symbolic\nstructure enables robust, interpretable modeling of complex environmental\nindices like UTCI - and significantly outperforms the state-of-the-art\napproximation in both accuracy and efficiency."}
{"id": "2508.11312", "pdf": "https://arxiv.org/pdf/2508.11312", "abs": "https://arxiv.org/abs/2508.11312", "authors": ["Ziyi Zeng", "Yun-Hsuan Chen", "Xurong Gao", "Wenyao Zheng", "Hemmings Wu", "Zhoule Zhu", "Jie Yang", "Chengkai Wang", "Lihua Zhong", "Weiwei Cheng", "Mohamad Sawan"], "title": "Repetitive TMS-based Identification of Methamphetamine-Dependent Individuals Using EEG Spectra", "categories": ["q-bio.NC", "cs.LG", "eess.SP"], "comment": "10 pages, 9 figures", "summary": "The impact of repetitive transcranial magnetic stimulation (rTMS) on\nmethamphetamine (METH) users' craving levels is often assessed using\nquestionnaires. This study explores the feasibility of using neural signals to\nobtain more objective results. EEG signals recorded from 20 METH-addicted\nparticipants Before and After rTMS (MBT and MAT) and from 20 healthy\nparticipants (HC) are analyzed. In each EEG paradigm, participants are shown 15\nMETH-related and 15 neutral pictures randomly, and the relative band power\n(RBP) of each EEG sub-band frequency is derived. The average RBP across all 31\nchannels, as well as individual brain regions, is analyzed. Statistically,\nMAT's alpha, beta, and gamma RBPs are more like those of HC compared to MBT, as\nindicated by the power topographies. Utilizing a random forest (RF), the gamma\nRBP is identified as the optimal frequency band for distinguishing between MBT\nand HC with a 90% accuracy. The performance of classifying MAT versus HC is\nlower than that of MBT versus HC, suggesting that the efficacy of rTMS can be\nvalidated using RF with gamma RBP. Furthermore, the gamma RBP recorded by the\nTP10 and CP2 channels dominates the classification task of MBT versus HC when\nreceiving METH-related image cues. The gamma RBP during exposure to\nMETH-related cues can serve as a biomarker for distinguishing between MBT and\nHC and for evaluating the effectiveness of rTMS. Therefore, real-time\nmonitoring of gamma RBP variations holds promise as a parameter for\nimplementing a customized closed-loop neuromodulation system for treating METH\naddiction."}
{"id": "2508.11341", "pdf": "https://arxiv.org/pdf/2508.11341", "abs": "https://arxiv.org/abs/2508.11341", "authors": ["Katarzyna Filus", "Jorge M. Cruz-Duarte"], "title": "Semantically Guided Adversarial Testing of Vision Models Using Language Models", "categories": ["cs.CV", "cs.CR", "cs.LG", "68T45, 68T01, 68T07, 68T10, 68M25", "I.2.10; I.5.4; I.2.6; I.2.7; K.6.5"], "comment": "12 pages, 4 figures, 3 tables. Submitted for peer review", "summary": "In targeted adversarial attacks on vision models, the selection of the target\nlabel is a critical yet often overlooked determinant of attack success. This\ntarget label corresponds to the class that the attacker aims to force the model\nto predict. Now, existing strategies typically rely on randomness, model\npredictions, or static semantic resources, limiting interpretability,\nreproducibility, or flexibility. This paper then proposes a semantics-guided\nframework for adversarial target selection using the cross-modal knowledge\ntransfer from pretrained language and vision-language models. We evaluate\nseveral state-of-the-art models (BERT, TinyLLAMA, and CLIP) as similarity\nsources to select the most and least semantically related labels with respect\nto the ground truth, forming best- and worst-case adversarial scenarios. Our\nexperiments on three vision models and five attack methods reveal that these\nmodels consistently render practical adversarial targets and surpass static\nlexical databases, such as WordNet, particularly for distant class\nrelationships. We also observe that static testing of target labels offers a\npreliminary assessment of the effectiveness of similarity sources, \\textit{a\npriori} testing. Our results corroborate the suitability of pretrained models\nfor constructing interpretable, standardized, and scalable adversarial\nbenchmarks across architectures and datasets."}
{"id": "2508.11347", "pdf": "https://arxiv.org/pdf/2508.11347", "abs": "https://arxiv.org/abs/2508.11347", "authors": ["Yifei Li", "Lingling Zhang", "Hang Yan", "Tianzhe Zhao", "Zihan Ma", "Muye Huang", "Jun Liu"], "title": "SAGE: Scale-Aware Gradual Evolution for Continual Knowledge Graph Embedding", "categories": ["cs.AI", "cs.LG", "I.2.4; I.2.6; H.2.8"], "comment": "10 pages, 5 figures, Accepted at KDD 2025, code available at\n  https://github.com/lyfxjtu/Dynamic-Embedding", "summary": "Traditional knowledge graph (KG) embedding methods aim to represent entities\nand relations in a low-dimensional space, primarily focusing on static graphs.\nHowever, real-world KGs are dynamically evolving with the constant addition of\nentities, relations and facts. To address such dynamic nature of KGs, several\ncontinual knowledge graph embedding (CKGE) methods have been developed to\nefficiently update KG embeddings to accommodate new facts while maintaining\nlearned knowledge. As KGs grow at different rates and scales in real-world\nscenarios, existing CKGE methods often fail to consider the varying scales of\nupdates and lack systematic evaluation throughout the entire update process. In\nthis paper, we propose SAGE, a scale-aware gradual evolution framework for\nCKGE. Specifically, SAGE firstly determine the embedding dimensions based on\nthe update scales and expand the embedding space accordingly. The Dynamic\nDistillation mechanism is further employed to balance the preservation of\nlearned knowledge and the incorporation of new facts. We conduct extensive\nexperiments on seven benchmarks, and the results show that SAGE consistently\noutperforms existing baselines, with a notable improvement of 1.38% in MRR,\n1.25% in H@1 and 1.6% in H@10. Furthermore, experiments comparing SAGE with\nmethods using fixed embedding dimensions show that SAGE achieves optimal\nperformance on every snapshot, demonstrating the importance of adaptive\nembedding dimensions in CKGE. The codes of SAGE are publicly available at:\nhttps://github.com/lyfxjtu/Dynamic-Embedding."}
{"id": "2508.11354", "pdf": "https://arxiv.org/pdf/2508.11354", "abs": "https://arxiv.org/abs/2508.11354", "authors": ["Zhenyi Zhao", "Muthu Rama Krishnan Mookiah", "Emanuele Trucco"], "title": "Leveraging the RETFound foundation model for optic disc segmentation in retinal images", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "RETFound is a well-known foundation model (FM) developed for fundus camera\nand optical coherence tomography images. It has shown promising performance\nacross multiple datasets in diagnosing diseases, both eye-specific and\nsystemic, from retinal images. However, to our best knowledge, it has not been\nused for other tasks. We present the first adaptation of RETFound for optic\ndisc segmentation, a ubiquitous and foundational task in retinal image\nanalysis. The resulting segmentation system outperforms state-of-the-art,\nsegmentation-specific baseline networks after training a head with only a very\nmodest number of task-specific examples. We report and discuss results with\nfour public datasets, IDRID, Drishti-GS, RIM-ONE-r3, and REFUGE, and a private\ndataset, GoDARTS, achieving about 96% Dice consistently across all datasets.\nOverall, our method obtains excellent performance in internal verification,\ndomain generalization and domain adaptation, and exceeds most of the\nstate-of-the-art baseline results. We discuss the results in the framework of\nthe debate about FMs as alternatives to task-specific architectures. The code\nis available at: [link to be added after the paper is accepted]"}
{"id": "2508.11376", "pdf": "https://arxiv.org/pdf/2508.11376", "abs": "https://arxiv.org/abs/2508.11376", "authors": ["Durgesh Mishra", "Rishabh Uikey"], "title": "Unified Knowledge Distillation Framework: Fine-Grained Alignment and Geometric Relationship Preservation for Deep Face Recognition", "categories": ["cs.CV", "cs.LG"], "comment": "The paper spans a total of 14 pages, 10 pages for the main content\n  (including references) and 4 pages for the appendix. The main paper contains\n  3 figures and 1 table, while the appendix includes 1 pseudo-code algorithm\n  and 4 tables. The work was recently accepted for publication at IJCB 2025", "summary": "Knowledge Distillation is crucial for optimizing face recognition models for\ndeployment in computationally limited settings, such as edge devices.\nTraditional KD methods, such as Raw L2 Feature Distillation or Feature\nConsistency loss, often fail to capture both fine-grained instance-level\ndetails and complex relational structures, leading to suboptimal performance.\nWe propose a unified approach that integrates two novel loss functions,\nInstance-Level Embedding Distillation and Relation-Based Pairwise Similarity\nDistillation. Instance-Level Embedding Distillation focuses on aligning\nindividual feature embeddings by leveraging a dynamic hard mining strategy,\nthereby enhancing learning from challenging examples. Relation-Based Pairwise\nSimilarity Distillation captures relational information through pairwise\nsimilarity relationships, employing a memory bank mechanism and a sample mining\nstrategy. This unified framework ensures both effective instance-level\nalignment and preservation of geometric relationships between samples, leading\nto a more comprehensive distillation process. Our unified framework outperforms\nstate-of-the-art distillation methods across multiple benchmark face\nrecognition datasets, as demonstrated by extensive experimental evaluations.\nInterestingly, when using strong teacher networks compared to the student, our\nunified KD enables the student to even surpass the teacher's accuracy."}
{"id": "2508.11388", "pdf": "https://arxiv.org/pdf/2508.11388", "abs": "https://arxiv.org/abs/2508.11388", "authors": ["Marc Brinner", "Sina Zarriess"], "title": "Model Interpretability and Rationale Extraction by Input Mask Optimization", "categories": ["cs.CL", "cs.CV", "cs.LG"], "comment": null, "summary": "Concurrent to the rapid progress in the development of neural-network based\nmodels in areas like natural language processing and computer vision, the need\nfor creating explanations for the predictions of these black-box models has\nrisen steadily. We propose a new method to generate extractive explanations for\npredictions made by neural networks, that is based on masking parts of the\ninput which the model does not consider to be indicative of the respective\nclass. The masking is done using gradient-based optimization combined with a\nnew regularization scheme that enforces sufficiency, comprehensiveness and\ncompactness of the generated explanation, three properties that are known to be\ndesirable from the related field of rationale extraction in natural language\nprocessing. In this way, we bridge the gap between model interpretability and\nrationale extraction, thereby proving that the latter of which can be performed\nwithout training a specialized model, only on the basis of a trained\nclassifier. We further apply the same method to image inputs and obtain high\nquality explanations for image classifications, which indicates that the\nconditions proposed for rationale extraction in natural language processing are\nmore broadly applicable to different input types."}
{"id": "2508.11393", "pdf": "https://arxiv.org/pdf/2508.11393", "abs": "https://arxiv.org/abs/2508.11393", "authors": ["Marc Brinner", "Sina Zarrieß"], "title": "Rationalizing Transformer Predictions via End-To-End Differentiable Self-Training", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "We propose an end-to-end differentiable training paradigm for stable training\nof a rationalized transformer classifier. Our approach results in a single\nmodel that simultaneously classifies a sample and scores input tokens based on\ntheir relevance to the classification. To this end, we build on the widely-used\nthree-player-game for training rationalized models, which typically relies on\ntraining a rationale selector, a classifier and a complement classifier. We\nsimplify this approach by making a single model fulfill all three roles,\nleading to a more efficient training paradigm that is not susceptible to the\ncommon training instabilities that plague existing approaches. Further, we\nextend this paradigm to produce class-wise rationales while incorporating\nrecent advances in parameterizing and regularizing the resulting rationales,\nthus leading to substantially improved and state-of-the-art alignment with\nhuman annotations without any explicit supervision."}
{"id": "2508.11411", "pdf": "https://arxiv.org/pdf/2508.11411", "abs": "https://arxiv.org/abs/2508.11411", "authors": ["Fabian H. Reith", "Jannik Franzen", "Dinesh R. Palli", "J. Lorenz Rumberger", "Dagmar Kainmueller"], "title": "SelfAdapt: Unsupervised Domain Adaptation of Cell Segmentation Models", "categories": ["cs.CV", "cs.LG"], "comment": "8 pages, 3 figures. To appear in the proceedings of the BioImage\n  Computing (BIC) Workshop @ ICCVW 2025. This is the accepted author manuscript\n  (camera-ready version)", "summary": "Deep neural networks have become the go-to method for biomedical instance\nsegmentation. Generalist models like Cellpose demonstrate state-of-the-art\nperformance across diverse cellular data, though their effectiveness often\ndegrades on domains that differ from their training data. While supervised\nfine-tuning can address this limitation, it requires annotated data that may\nnot be readily available. We propose SelfAdapt, a method that enables the\nadaptation of pre-trained cell segmentation models without the need for labels.\nOur approach builds upon student-teacher augmentation consistency training,\nintroducing L2-SP regularization and label-free stopping criteria. We evaluate\nour method on the LiveCell and TissueNet datasets, demonstrating relative\nimprovements in AP0.5 of up to 29.64% over baseline Cellpose. Additionally, we\nshow that our unsupervised adaptation can further improve models that were\npreviously fine-tuned with supervision. We release SelfAdapt as an easy-to-use\nextension of the Cellpose framework. The code for our method is publicly\navailable at https: //github.com/Kainmueller-Lab/self_adapt."}
{"id": "2508.11472", "pdf": "https://arxiv.org/pdf/2508.11472", "abs": "https://arxiv.org/abs/2508.11472", "authors": ["Yang Wang", "Yaxin Zhao", "Xinyu Jiao", "Sihan Xu", "Xiangrui Cai", "Ying Zhang", "Xiaojie Yuan"], "title": "RMSL: Weakly-Supervised Insider Threat Detection with Robust Multi-sphere Learning", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": "15 pages", "summary": "Insider threat detection aims to identify malicious user behavior by\nanalyzing logs that record user interactions. Due to the lack of fine-grained\nbehavior-level annotations, detecting specific behavior-level anomalies within\nuser behavior sequences is challenging. Unsupervised methods face high false\npositive rates and miss rates due to the inherent ambiguity between normal and\nanomalous behaviors. In this work, we instead introduce weak labels of behavior\nsequences, which have lower annotation costs, i.e., the training labels\n(anomalous or normal) are at sequence-level instead of behavior-level, to\nenhance the detection capability for behavior-level anomalies by learning\ndiscriminative features. To achieve this, we propose a novel framework called\nRobust Multi-sphere Learning (RMSL). RMSL uses multiple hyper-spheres to\nrepresent the normal patterns of behaviors. Initially, a one-class classifier\nis constructed as a good anomaly-supervision-free starting point. Building on\nthis, using multiple instance learning and adaptive behavior-level\nself-training debiasing based on model prediction confidence, the framework\nfurther refines hyper-spheres and feature representations using weak\nsequence-level labels. This approach enhances the model's ability to\ndistinguish between normal and anomalous behaviors. Extensive experiments\ndemonstrate that RMSL significantly improves the performance of behavior-level\ninsider threat detection."}
{"id": "2508.11499", "pdf": "https://arxiv.org/pdf/2508.11499", "abs": "https://arxiv.org/abs/2508.11499", "authors": ["Erez Meoded"], "title": "Handwritten Text Recognition of Historical Manuscripts Using Transformer-Based Models", "categories": ["cs.CV", "cs.AI", "cs.DL", "cs.LG"], "comment": null, "summary": "Historical handwritten text recognition (HTR) is essential for unlocking the\ncultural and scholarly value of archival documents, yet digitization is often\nhindered by scarce transcriptions, linguistic variation, and highly diverse\nhandwriting styles. In this study, we apply TrOCR, a state-of-the-art\ntransformer-based HTR model, to 16th-century Latin manuscripts authored by\nRudolf Gwalther. We investigate targeted image preprocessing and a broad suite\nof data augmentation techniques, introducing four novel augmentation methods\ndesigned specifically for historical handwriting characteristics. We also\nevaluate ensemble learning approaches to leverage the complementary strengths\nof augmentation-trained models. On the Gwalther dataset, our best single-model\naugmentation (Elastic) achieves a Character Error Rate (CER) of 1.86, while a\ntop-5 voting ensemble achieves a CER of 1.60 - representing a 50% relative\nimprovement over the best reported TrOCR_BASE result and a 42% improvement over\nthe previous state of the art. These results highlight the impact of\ndomain-specific augmentations and ensemble strategies in advancing HTR\nperformance for historical manuscripts."}
{"id": "2508.11503", "pdf": "https://arxiv.org/pdf/2508.11503", "abs": "https://arxiv.org/abs/2508.11503", "authors": ["Andrej Orsula", "Matthieu Geist", "Miguel Olivares-Mendez", "Carol Martinez"], "title": "Sim2Dust: Mastering Dynamic Waypoint Tracking on Granular Media", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "The source code is available at\n  https://github.com/AndrejOrsula/space_robotics_bench", "summary": "Reliable autonomous navigation across the unstructured terrains of distant\nplanetary surfaces is a critical enabler for future space exploration. However,\nthe deployment of learning-based controllers is hindered by the inherent\nsim-to-real gap, particularly for the complex dynamics of wheel interactions\nwith granular media. This work presents a complete sim-to-real framework for\ndeveloping and validating robust control policies for dynamic waypoint tracking\non such challenging surfaces. We leverage massively parallel simulation to\ntrain reinforcement learning agents across a vast distribution of procedurally\ngenerated environments with randomized physics. These policies are then\ntransferred zero-shot to a physical wheeled rover operating in a lunar-analogue\nfacility. Our experiments systematically compare multiple reinforcement\nlearning algorithms and action smoothing filters to identify the most effective\ncombinations for real-world deployment. Crucially, we provide strong empirical\nevidence that agents trained with procedural diversity achieve superior\nzero-shot performance compared to those trained on static scenarios. We also\nanalyze the trade-offs of fine-tuning with high-fidelity particle physics,\nwhich offers minor gains in low-speed precision at a significant computational\ncost. Together, these contributions establish a validated workflow for creating\nreliable learning-based navigation systems, marking a critical step towards\ndeploying autonomous robots in the final frontier."}
{"id": "2508.11511", "pdf": "https://arxiv.org/pdf/2508.11511", "abs": "https://arxiv.org/abs/2508.11511", "authors": ["Siyamalan Manivannan"], "title": "Semi-Supervised Learning with Online Knowledge Distillation for Skin Lesion Classification", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": null, "summary": "Deep Learning has emerged as a promising approach for skin lesion analysis.\nHowever, existing methods mostly rely on fully supervised learning, requiring\nextensive labeled data, which is challenging and costly to obtain. To alleviate\nthis annotation burden, this study introduces a novel semi-supervised deep\nlearning approach that integrates ensemble learning with online knowledge\ndistillation for enhanced skin lesion classification. Our methodology involves\ntraining an ensemble of convolutional neural network models, using online\nknowledge distillation to transfer insights from the ensemble to its members.\nThis process aims to enhance the performance of each model within the ensemble,\nthereby elevating the overall performance of the ensemble itself.\nPost-training, any individual model within the ensemble can be deployed at test\ntime, as each member is trained to deliver comparable performance to the\nensemble. This is particularly beneficial in resource-constrained environments.\nExperimental results demonstrate that the knowledge-distilled individual model\nperforms better than independently trained models. Our approach demonstrates\nsuperior performance on both the \\emph{International Skin Imaging\nCollaboration} 2018 and 2019 public benchmark datasets, surpassing current\nstate-of-the-art results. By leveraging ensemble learning and online knowledge\ndistillation, our method reduces the need for extensive labeled data while\nproviding a more resource-efficient solution for skin lesion classification in\nreal-world scenarios."}
{"id": "2508.11532", "pdf": "https://arxiv.org/pdf/2508.11532", "abs": "https://arxiv.org/abs/2508.11532", "authors": ["Jingsong Xia", "Yue Yin", "Xiuhan Li"], "title": "An Efficient Medical Image Classification Method Based on a Lightweight Improved ConvNeXt-Tiny Architecture", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Intelligent analysis of medical imaging plays a crucial role in assisting\nclinical diagnosis. However, achieving efficient and high-accuracy image\nclassification in resource-constrained computational environments remains\nchallenging. This study proposes a medical image classification method based on\nan improved ConvNeXt-Tiny architecture. Through structural optimization and\nloss function design, the proposed method enhances feature extraction\ncapability and classification performance while reducing computational\ncomplexity. Specifically, the method introduces a dual global pooling (Global\nAverage Pooling and Global Max Pooling) feature fusion strategy into the\nConvNeXt-Tiny backbone to simultaneously preserve global statistical features\nand salient response information. A lightweight channel attention module,\ntermed Squeeze-and-Excitation Vector (SEVector), is designed to improve the\nadaptive allocation of channel weights while minimizing parameter overhead.\nAdditionally, a Feature Smoothing Loss is incorporated into the loss function\nto enhance intra-class feature consistency and suppress intra-class variance.\nUnder CPU-only conditions (8 threads), the method achieves a maximum\nclassification accuracy of 89.10% on the test set within 10 training epochs,\nexhibiting a stable convergence trend in loss values. Experimental results\ndemonstrate that the proposed method effectively improves medical image\nclassification performance in resource-limited settings, providing a feasible\nand efficient solution for the deployment and promotion of medical imaging\nanalysis models."}
{"id": "2508.11551", "pdf": "https://arxiv.org/pdf/2508.11551", "abs": "https://arxiv.org/abs/2508.11551", "authors": ["Shengzhuang Chen", "Xu Ouyang", "Michael Arthur Leopold Pearce", "Thomas Hartvigsen", "Jonathan Richard Schwarz"], "title": "ADMIRE-BayesOpt: Accelerated Data MIxture RE-weighting for Language Models with Bayesian Optimization", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "Determining the optimal data mixture for large language model training\nremains a challenging problem with an outsized impact on performance. In\npractice, language model developers continue to rely on heuristic exploration\nsince no learning-based approach has emerged as a reliable solution. In this\nwork, we propose to view the selection of training data mixtures as a black-box\nhyperparameter optimization problem, for which Bayesian Optimization is a\nwell-established class of appropriate algorithms. Firstly, we cast data mixture\nlearning as a sequential decision-making problem, in which we aim to find a\nsuitable trade-off between the computational cost of training exploratory\n(proxy-) models and final mixture performance. Secondly, we systematically\nexplore the properties of transferring mixtures learned at a small scale to\nlarger-scale experiments, providing insights and highlighting opportunities for\nresearch at a modest scale. By proposing Multi-fidelity Bayesian Optimization\nas a suitable method in this common scenario, we introduce a natural framework\nto balance experiment cost with model fit, avoiding the risks of overfitting to\nsmaller scales while minimizing the number of experiments at high cost. We\npresent results for pre-training and instruction finetuning across models\nranging from 1 million to 7 billion parameters, varying from simple\narchitectures to state-of-the-art models and benchmarks spanning dozens of\ndatasets. We demonstrate consistently strong results relative to a wide range\nof benchmarks, showingspeed-ups of over 500% in determining the best data\nmixture on our largest experiments relative to recent baselines. In addition,\nwe broaden access to research by sharing ADMIRE IFT Runs, a dataset of 460 full\ntraining & evaluation runs across various model sizes worth over 13,000 GPU\nhours, greatly reducing the cost of conducting research in this area."}
{"id": "2508.11584", "pdf": "https://arxiv.org/pdf/2508.11584", "abs": "https://arxiv.org/abs/2508.11584", "authors": ["Jakub Łucki", "Jonathan Becktor", "Georgios Georgakis", "Robert Royce", "Shehryar Khattak"], "title": "Visual Perception Engine: Fast and Flexible Multi-Head Inference for Robotic Vision Tasks", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "comment": "6 pages, 6 figures, 2 tables", "summary": "Deploying multiple machine learning models on resource-constrained robotic\nplatforms for different perception tasks often results in redundant\ncomputations, large memory footprints, and complex integration challenges. In\nresponse, this work presents Visual Perception Engine (VPEngine), a modular\nframework designed to enable efficient GPU usage for visual multitasking while\nmaintaining extensibility and developer accessibility. Our framework\narchitecture leverages a shared foundation model backbone that extracts image\nrepresentations, which are efficiently shared, without any unnecessary GPU-CPU\nmemory transfers, across multiple specialized task-specific model heads running\nin parallel. This design eliminates the computational redundancy inherent in\nfeature extraction component when deploying traditional sequential models while\nenabling dynamic task prioritization based on application demands. We\ndemonstrate our framework's capabilities through an example implementation\nusing DINOv2 as the foundation model with multiple task (depth, object\ndetection and semantic segmentation) heads, achieving up to 3x speedup compared\nto sequential execution. Building on CUDA Multi-Process Service (MPS), VPEngine\noffers efficient GPU utilization and maintains a constant memory footprint\nwhile allowing per-task inference frequencies to be adjusted dynamically during\nruntime. The framework is written in Python and is open source with ROS2 C++\n(Humble) bindings for ease of use by the robotics community across diverse\nrobotic platforms. Our example implementation demonstrates end-to-end real-time\nperformance at $\\geq$50 Hz on NVIDIA Jetson Orin AGX for TensorRT optimized\nmodels."}
{"id": "2508.11588", "pdf": "https://arxiv.org/pdf/2508.11588", "abs": "https://arxiv.org/abs/2508.11588", "authors": ["Benjamin Walt", "Jordan Westphal", "Girish Krishnan"], "title": "Investigating Sensors and Methods in Grasp State Classification in Agricultural Manipulation", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Effective and efficient agricultural manipulation and harvesting depend on\naccurately understanding the current state of the grasp. The agricultural\nenvironment presents unique challenges due to its complexity, clutter, and\nocclusion. Additionally, fruit is physically attached to the plant, requiring\nprecise separation during harvesting. Selecting appropriate sensors and\nmodeling techniques is critical for obtaining reliable feedback and correctly\nidentifying grasp states. This work investigates a set of key sensors, namely\ninertial measurement units (IMUs), infrared (IR) reflectance, tension, tactile\nsensors, and RGB cameras, integrated into a compliant gripper to classify grasp\nstates. We evaluate the individual contribution of each sensor and compare the\nperformance of two widely used classification models: Random Forest and Long\nShort-Term Memory (LSTM) networks. Our results demonstrate that a Random Forest\nclassifier, trained in a controlled lab environment and tested on real cherry\ntomato plants, achieved 100% accuracy in identifying slip, grasp failure, and\nsuccessful picks, marking a substantial improvement over baseline performance.\nFurthermore, we identify a minimal viable sensor combination, namely IMU and\ntension sensors that effectively classifies grasp states. This classifier\nenables the planning of corrective actions based on real-time feedback, thereby\nenhancing the efficiency and reliability of fruit harvesting operations."}
{"id": "2508.11597", "pdf": "https://arxiv.org/pdf/2508.11597", "abs": "https://arxiv.org/abs/2508.11597", "authors": ["Arnab Ganguly", "Riten Mitra", "Jinpu Zhou"], "title": "Nonparametric learning of stochastic differential equations from sparse and noisy data", "categories": ["stat.ML", "cs.LG", "math.PR", "stat.ME", "62G05, 62M05, 60H10, 60J60, 46E22, 65C05, 65C35"], "comment": "35 pages, 6 figures", "summary": "The paper proposes a systematic framework for building data-driven stochastic\ndifferential equation (SDE) models from sparse, noisy observations. Unlike\ntraditional parametric approaches, which assume a known functional form for the\ndrift, our goal here is to learn the entire drift function directly from data\nwithout strong structural assumptions, making it especially relevant in\nscientific disciplines where system dynamics are partially understood or highly\ncomplex. We cast the estimation problem as minimization of the penalized\nnegative log-likelihood functional over a reproducing kernel Hilbert space\n(RKHS). In the sparse observation regime, the presence of unobserved trajectory\nsegments makes the SDE likelihood intractable. To address this, we develop an\nExpectation-Maximization (EM) algorithm that employs a novel Sequential Monte\nCarlo (SMC) method to approximate the filtering distribution and generate Monte\nCarlo estimates of the E-step objective. The M-step then reduces to a penalized\nempirical risk minimization problem in the RKHS, whose minimizer is given by a\nfinite linear combination of kernel functions via a generalized representer\ntheorem. To control model complexity across EM iterations, we also develop a\nhybrid Bayesian variant of the algorithm that uses shrinkage priors to identify\nsignificant coefficients in the kernel expansion. We establish important\ntheoretical convergence results for both the exact and approximate EM\nsequences. The resulting EM-SMC-RKHS procedure enables accurate estimation of\nthe drift function of stochastic dynamical systems in low-data regimes and is\nbroadly applicable across domains requiring continuous-time modeling under\nobservational constraints. We demonstrate the effectiveness of our method\nthrough a series of numerical experiments."}
{"id": "2508.11616", "pdf": "https://arxiv.org/pdf/2508.11616", "abs": "https://arxiv.org/abs/2508.11616", "authors": ["Oscar Mañas", "Pierluca D'Oro", "Koustuv Sinha", "Adriana Romero-Soriano", "Michal Drozdzal", "Aishwarya Agrawal"], "title": "Controlling Multimodal LLMs via Reward-guided Decoding", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": "Published at ICCV 2025", "summary": "As Multimodal Large Language Models (MLLMs) gain widespread applicability, it\nis becoming increasingly desirable to adapt them for diverse user needs. In\nthis paper, we study the adaptation of MLLMs through controlled decoding. To\nachieve this, we introduce the first method for reward-guided decoding of MLLMs\nand demonstrate its application in improving their visual grounding. Our method\ninvolves building reward models for visual grounding and using them to guide\nthe MLLM's decoding process. Concretely, we build two separate reward models to\nindependently control the degree of object precision and recall in the model's\noutput. Our approach enables on-the-fly controllability of an MLLM's inference\nprocess in two ways: first, by giving control over the relative importance of\neach reward function during decoding, allowing a user to dynamically trade off\nobject precision for recall in image captioning tasks; second, by giving\ncontrol over the breadth of the search during decoding, allowing the user to\ncontrol the trade-off between the amount of test-time compute and the degree of\nvisual grounding. We evaluate our method on standard object hallucination\nbenchmarks, showing that it provides significant controllability over MLLM\ninference, while consistently outperforming existing hallucination mitigation\nmethods."}
